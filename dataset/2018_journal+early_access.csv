"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,"Reference Count","License","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Applications of Deep Learning and Reinforcement Learning to Biological Data","M. Mahmud; M. S. Kaiser; A. Hussain; S. Vassanelli","Department of Biomedical Sciences, NeuroChip Lab, University of Padova, Padua, Italy; Institute of Information Technology, Jahangirnagar University, Dhaka, Bangladesh; Division of Computing Science and Maths, School of Natural Sciences, University of Stirling, Stirling, U.K.; Department of Biomedical Sciences, NeuroChip Lab, University of Padova, Padua, Italy","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","6","2063","2079","Rapid advances in hardware-based technologies during the past decades have opened up new possibilities for life scientists to gather multimodal data in various application domains, such as omics, bioimaging, medical imaging, and (brain/body)-machine interfaces. These have generated novel opportunities for development of dedicated data-intensive machine learning techniques. In particular, recent research in deep learning (DL), reinforcement learning (RL), and their combination (deep RL) promise to revolutionize the future of artificial intelligence. The growth in computational power accompanied by faster and increased data storage, and declining computing costs have already allowed scientists in various fields to apply these techniques on data sets that were previously intractable owing to their size and complexity. This paper provides a comprehensive survey on the application of DL, RL, and deep RL techniques in mining biological data. In addition, we compare the performances of DL techniques when applied to different data sets across various application domains. Finally, we outline open issues in this challenging research area and discuss future development perspectives.","","","10.1109/TNNLS.2018.2790388","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8277160","Bioimaging;brain–machine interfaces;convolutional neural network (CNN);deep autoencoder (DA);deep belief network (DBN);deep learning performance;medical imaging;omics;recurrent neural network (RNN)","Biology;Feature extraction;Recurrent neural networks;Data models;Biomedical imaging;Computer architecture;Machine learning","biology computing;data mining;learning (artificial intelligence)","deep RL techniques;DL techniques;deep learning;reinforcement learning;multimodal data;medical imaging;computational power;data-intensive machine learning techniques;hardware-based technologies;artificial intelligence;biological data mining","","42","211","","","","","IEEE","IEEE Journals"
"Review on the research and practice of deep learning and reinforcement learning in smart grids","D. Zhang; X. Han; C. Deng","China Electric Power Research Institute, Beijing 100192, China; Department of Electrical Engineering, Taiyuan University of Technology, Taiyuan 030024, China; China Electric Power Research Institute, Beijing 100192, China","CSEE Journal of Power and Energy Systems","","2018","4","3","362","370","Smart grids are the developmental trend of power systems and they have attracted much attention all over the world. Due to their complexities, and the uncertainty of the smart grid and high volume of information being collected, artificial intelligence techniques represent some of the enabling technologies for its future development and success. Owing to the decreasing cost of computing power, the profusion of data, and better algorithms, AI has entered into its new developmental stage and AI 2.0 is developing rapidly. Deep learning (DL), reinforcement learning (RL) and their combination-deep reinforcement learning (DRL) are representative methods and relatively mature methods in the family of AI 2.0. This article introduces the concept and status quo of the above three methods, summarizes their potential for application in smart grids, and provides an overview of the research work on their application in smart grids.","","","10.17775/CSEEJPES.2018.00520","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8468674","Deep learning;deep reinforcement learning;reinforcement learning;smart grid","Smart grids;Machine learning;Power system stability;Learning (artificial intelligence);Uncertainty;Neural networks","learning (artificial intelligence);power engineering computing;smart power grids","deep learning;smart grid;combination-deep reinforcement learning;DL;RL;power systems;artificial intelligence techniques;data profusion;power computing;AI 2.0;DRL","","16","","","","","","CSEE","CSEE Journals"
"Deep Learning Computed Tomography: Learning Projection-Domain Weights From Image Domain in Limited Angle Problems","T. Würfl; M. Hoffmann; V. Christlein; K. Breininger; Y. Huang; M. Unberath; A. K. Maier","Department Informatik, Pattern Recognition Lab, Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany; Department Informatik, Pattern Recognition Lab, Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany; Department Informatik, Pattern Recognition Lab, Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany; Department Informatik, Pattern Recognition Lab, Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany; Department Informatik, Pattern Recognition Lab, Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany; Computer Aided Medical Procedures, Johns Hopkins University, Baltimore, MD, USA; Department Informatik, Pattern Recognition Lab, Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany","IEEE Transactions on Medical Imaging","","2018","37","6","1454","1463","In this paper, we present a new deep learning framework for 3-D tomographic reconstruction. To this end, we map filtered back-projection-type algorithms to neural networks. However, the back-projection cannot be implemented as a fully connected layer due to its memory requirements. To overcome this problem, we propose a new type of cone-beam back-projection layer, efficiently calculating the forward pass. We derive this layer's backward pass as a projection operation. Unlike most deep learning approaches for reconstruction, our new layer permits joint optimization of correction steps in volume and projection domain. Evaluation is performed numerically on a public data set in a limited angle setting showing a consistent improvement over analytical algorithms while keeping the same computational test-time complexity by design. In the region of interest, the peak signal-to-noise ratio has increased by 23%. In addition, we show that the learned algorithm can be interpreted using known concepts from cone beam reconstruction: the network is able to automatically learn strategies such as compensation weights and apodization windows.","","","10.1109/TMI.2018.2833499","National Institute of Biomedical Imaging and Bioengineering; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8355700","Reconstruction algorithms;neural networks;machine learning","Image reconstruction;Neural networks;Machine learning;Geometry;Reconstruction algorithms;Iterative methods;Computed tomography","computational complexity;computerised tomography;image reconstruction;learning (artificial intelligence);medical image processing;neural nets","computed tomography;projection-domain weights;image domain;limited angle problems;deep learning framework;3-D tomographic reconstruction;back-projection-type algorithms;neural networks;fully connected layer;memory requirements;back-projection layer;forward pass;backward pass;projection operation;joint optimization;correction steps;public data;analytical algorithms;computational test-time complexity;peak signal-to-noise ratio;learned algorithm;cone beam reconstruction;compensation weights","","2","38","","","","","IEEE","IEEE Journals"
"Self-Paced Prioritized Curriculum Learning With Coverage Penalty in Deep Reinforcement Learning","Z. Ren; D. Dong; H. Li; C. Chen","Department of Control and Systems Engineering, School of Management and Engineering, Nanjing University, Nanjing, China; School of Engineering and Information Technology, University of New South Wales, Canberra, ACT, Australia; Department of Control and Systems Engineering, School of Management and Engineering, Nanjing University, Nanjing, China; Department of Control and Systems Engineering, School of Management and Engineering, Nanjing University, Nanjing, China","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","6","2216","2226","In this paper, a new training paradigm is proposed for deep reinforcement learning using self-paced prioritized curriculum learning with coverage penalty. The proposed deep curriculum reinforcement learning (DCRL) takes the most advantage of experience replay by adaptively selecting appropriate transitions from replay memory based on the complexity of each transition. The criteria of complexity in DCRL consist of self-paced priority as well as coverage penalty. The self-paced priority reflects the relationship between the temporal-difference error and the difficulty of the current curriculum for sample efficiency. The coverage penalty is taken into account for sample diversity. With comparison to deep Q network (DQN) and prioritized experience replay (PER) methods, the DCRL algorithm is evaluated on Atari 2600 games, and the experimental results show that DCRL outperforms DQN and PER on most of these games. More results further show that the proposed curriculum training paradigm of DCRL is also applicable and effective for other memory-based deep reinforcement learning approaches, such as double DQN and dueling network. All the experimental results demonstrate that DCRL can achieve improved training efficiency and robustness for deep reinforcement learning.","","","10.1109/TNNLS.2018.2790981","National Key Research and Development Program of China; National Natural Science Foundation of China; Australian Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8278851","Coverage penalty;curriculum learning;deep reinforcement learning;self-paced priority","Training;Learning (artificial intelligence);Machine learning;Complexity theory;Training data;Games;Robustness","computer based training;computer games;learning (artificial intelligence)","curriculum training paradigm;DCRL;deep curriculum reinforcement learning;coverage penalty;Atari 2600 games;temporal-difference error;replay memory;self-paced prioritized curriculum learning","","8","49","","","","","IEEE","IEEE Journals"
"Reinforced Imitation: Sample Efficient Deep Reinforcement Learning for Mapless Navigation by Leveraging Prior Demonstrations","M. Pfeiffer; S. Shukla; M. Turchetta; C. Cadena; A. Krause; R. Siegwart; J. Nieto","Autonomous Systems Lab, Computer Vision Lab, Learning and Adaptive Systems Group, and Max Planck ETH Center for Learning Systems, ETH Zurich, Zurich, Switzerland; Autonomous Systems Lab, Computer Vision Lab, Learning and Adaptive Systems Group, and Max Planck ETH Center for Learning Systems, ETH Zurich, Zurich, Switzerland; Autonomous Systems Lab, Computer Vision Lab, Learning and Adaptive Systems Group, and Max Planck ETH Center for Learning Systems, ETH Zurich, Zurich, Switzerland; Autonomous Systems Lab, Computer Vision Lab, Learning and Adaptive Systems Group, and Max Planck ETH Center for Learning Systems, ETH Zurich, Zurich, Switzerland; Autonomous Systems Lab, Computer Vision Lab, Learning and Adaptive Systems Group, and Max Planck ETH Center for Learning Systems, ETH Zurich, Zurich, Switzerland; Autonomous Systems Lab, Computer Vision Lab, Learning and Adaptive Systems Group, and Max Planck ETH Center for Learning Systems, ETH Zurich, Zurich, Switzerland; Autonomous Systems Lab, Computer Vision Lab, Learning and Adaptive Systems Group, and Max Planck ETH Center for Learning Systems, ETH Zurich, Zurich, Switzerland","IEEE Robotics and Automation Letters","","2018","3","4","4423","4430","This letter presents a case study of a learning-based approach for target-driven mapless navigation. The underlying navigation model is an end-to-end neural network, which is trained using a combination of expert demonstrations, imitation learning (IL) and reinforcement learning (RL). While RL and IL suffer from a large sample complexity and the distribution mismatch problem, respectively, we show that leveraging prior expert demonstrations for pretraining can reduce the training time to reach at least the same level of the performance compared to plain RL by a factor of 5. We present a thorough evaluation of different combinations of expert demonstrations, different RL algorithms, and reward functions, both in simulation and on a real robotic platform. Our results show that the final model outperforms both standalone approaches in the amount of successful navigation tasks. In addition, the RL reward function can be significantly simplified when using pretraining, e.g., by using a sparse reward only. The learned navigation policy is able to generalize to unseen and real-world environments.","","","10.1109/LRA.2018.2869644","European Union Horizon 2020 project CROWDBOT; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8458422","Navigation;deep reinforcement learning;end-to-end planning","Navigation;Training;Robots;Task analysis;Collision avoidance;Neural networks;Planning","learning (artificial intelligence);mobile robots;navigation;neural nets","learning-based approach;sample efficient deep reinforcement learning;reinforced imitation;learned navigation policy;RL reward function;successful navigation tasks;standalone approaches;final model;plain RL;leveraging prior expert demonstrations;distribution mismatch problem;sample complexity;IL;end-to-end neural network;underlying navigation model;target-driven mapless navigation","","2","33","","","","","IEEE","IEEE Journals"
"Row-Sparse Discriminative Deep Dictionary Learning for Hyperspectral Image Classification","V. Singhal; A. Majumdar","Indraprastha Institute of Information Technology, New Delhi, India; Indraprastha Institute of Information Technology, New Delhi, India","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2018","11","12","5019","5028","In recent studies in hyperspectral imaging, biometrics, and energy analytics, the framework of deep dictionary learning has shown promise. Deep dictionary learning outperforms other traditional deep learning tools when training data are limited; therefore, hyperspectral imaging is one such example that benefits from this framework. Most of the prior studies were based on the unsupervised formulation; and in all cases, the training algorithm was greedy and hence suboptimal. This is the first work that shows how to learn the deep dictionary learning problem in a joint fashion. Moreover, we propose a new discriminative penalty to the said framework. The third contribution of this work is showing how to incorporate stochastic regularization techniques into the deep dictionary learning framework. Experimental results on hyperspectral image classification shows that the proposed technique excels over all state-of-the-art deep and shallow (traditional) learning based methods published in recent times.","","","10.1109/JSTARS.2018.2877769","Infosys Center for Artificial Intelligence @ IIIT Delhi; Indo-French CEFIPRA; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8536455","Classification;deep learning;dictionary learning;hyperspectral imaging;supervised learning","Hyperspectral imaging;Supervised learning;Classification;Training data;Deep learning","hyperspectral imaging;image classification;knowledge representation;learning (artificial intelligence)","discriminative penalty;deep dictionary learning framework;hyperspectral image classification;row-sparse discriminative deep dictionary;hyperspectral imaging;deep dictionary learning problem;stochastic regularization techniques","","","38","","","","","IEEE","IEEE Journals"
"Exploring the Cross-Domain Action Recognition Problem by Deep Feature Learning and Cross-Domain Learning","Z. Gao; T. T. Han; L. Zhu; H. Zhang; Y. Wang","Qilu University of Technology (Shandong Academy of Sciences), Shandong Computer Science Center (National Supercomputer Center in Jinan), Shandong Artificial Intelligence Institute, Jinan, China; Key Laboratory of Computer Vision and System, Tianjin University of Technology, Ministry of Education, Tianjin, China; School of Information Science and Engineering, Shandong Normal University, Jinan, China; Key Laboratory of Computer Vision and System, Tianjin University of Technology, Ministry of Education, Tianjin, China; Qilu University of Technology (Shandong Academy of Sciences), Shandong Computer Science Center (National Supercomputer Center in Jinan), Shandong Artificial Intelligence Institute, Jinan, China","IEEE Access","","2018","6","","68989","69008","Action recognition has received increasing attention from the computer vision and machine learning communities in the last decade. Although many related action recognition algorithms have been proposed, similar environments conditions are often required in the training and testing stages, which limits the application of the related technologies. In order to accelerate the generalization of action recognition, in this paper, the cross-domain action recognition problem are explored by three different kinds of aspects: 1) feature learning, hand-crafted feature and deep learning feature are extracted, respectively, and then the generalization ability of them are assessed and discussed on controlled and uncontrolled environments, respectively; 2) unsupervised cross-domain learning, since it is difficult for us to obtain the labeled samples in the target domain, thus, unsupervised cross-domain learning methods can be borrowed. In order to discuss which one is suitable for open domain action recognition problem, thus, three kind of unsupervised cross-domain learning methods are assessed on open domain action recognition dataset, respectively; 3) supervised cross-domain learning, if there are some labeled samples in the target domain, but the number of them is very limited, thus, supervised cross-domain learning method should be a good choice, but, how do we make the decision for them? Therefore, these methods are also appraised on the same dataset. Moreover, we contribute a novel multi-view and multi-modality human action recognition dataset (abbreviated as ”MMA”). It consists of 7,080 action samples from 25 action categories, including 15 singlesubject actions and 10 double-subject interactive actions in three views of two different scenarios, which can be utilized to simultaneously explore single-view learning, multi-view learning, multi-modality learning, and cross-domain learning problems. We further explore the same learning problems on the MMA dataset. The extensive experimental results on two different datasets show that the deep feature learning method has much better generalization ability than the hand-crafted feature, such as improved dense trajectory if there are enough labeled samples in the training dataset to be used to fine-tune the network, and both unsupervised cross-domain learning method and supervised cross-domain learning method can improve the performance, but the latter can obtain much bigger improvement, in other words, the labeled samples in the target domain are very helpful. Finally, we also attended the open domain action recognition challenge which was held in CVPR 2017 workshop, and our supervised cross-domain learning scheme obtained the best performance in all teams.","","","10.1109/ACCESS.2018.2878313","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8514106","Open set action recognition;cross domain learning;hand-crafted feature;deep learning feature;improved dense trajectory;MMA dataset","Videos;Learning systems;Trajectory;Target recognition;Feature extraction;Training","computer vision;feature extraction;image recognition;neural nets;supervised learning;unsupervised learning","open domain action recognition dataset;supervised cross-domain learning method;multimodality human action recognition dataset;single-view learning;multiview learning;multimodality learning;deep feature learning method;unsupervised cross-domain learning method;supervised cross-domain learning scheme;cross-domain action recognition problem;open domain action recognition problem","","3","77","","","","","IEEE","IEEE Journals"
"Hierarchical Deep Reinforcement Learning for Continuous Action Control","Z. Yang; K. Merrick; L. Jin; H. A. Abbass","School of Engineering and Information Technology, University of New South Wales, Canberra, ACT, Australia; School of Engineering and Information Technology, University of New South Wales, Canberra, ACT, Australia; School of Electronic and Information Engineering, South China University of Technology, Guangzhou, China; School of Engineering and Information Technology, University of New South Wales, Canberra, ACT, Australia","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","11","5174","5184","Robotic control in a continuous action space has long been a challenging topic. This is especially true when controlling robots to solve compound tasks, as both basic skills and compound skills need to be learned. In this paper, we propose a hierarchical deep reinforcement learning algorithm to learn basic skills and compound skills simultaneously. In the proposed algorithm, compound skills and basic skills are learned by two levels of hierarchy. In the first level of hierarchy, each basic skill is handled by its own actor, overseen by a shared basic critic. Then, in the second level of hierarchy, compound skills are learned by a meta critic by reusing basic skills. The proposed algorithm was evaluated on a Pioneer 3AT robot in three different navigation scenarios with fully observable tasks. The simulations were built in Gazebo 2 in a robot operating system Indigo environment. The results show that the proposed algorithm can learn both high performance basic skills and compound skills through the same learning process. The compound skills learned outperform those learned by a discrete action space deep reinforcement learning algorithm.","","","10.1109/TNNLS.2018.2805379","Australian Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8310962","Continuous control;deep learning;hierarchical learning;reinforcement learning","Compounds;Machine learning;Task analysis;Learning (artificial intelligence);Approximation algorithms;Robot sensing systems","collision avoidance;control engineering computing;learning (artificial intelligence);mobile robots;robot dynamics","continuous action control;basic skill;compound skills;hierarchical deep reinforcement learning algorithm;high performance basic skills;discrete action space deep reinforcement learning algorithm","","10","46","","","","","IEEE","IEEE Journals"
"Deep Learning for Household Load Forecasting—A Novel Pooling Deep RNN","H. Shi; M. Xu; R. Li","Department of Electronic and Electrical Engineering, University of Bath, Bath, U.K.; Department of Electronic and Electrical Engineering, University of Bath, Bath, U.K.; Department of Electronic and Electrical Engineering, University of Bath, Bath, U.K.","IEEE Transactions on Smart Grid","","2018","9","5","5271","5280","The key challenge for household load forecasting lies in the high volatility and uncertainty of load profiles. Traditional methods tend to avoid such uncertainty by load aggregation (to offset uncertainties), customer classification (to cluster uncertainties) and spectral analysis (to filter out uncertainties). This paper, for the first time, aims to directly learn the uncertainty by applying a new breed of machine learning algorithms-deep learning. However, simply adding layers in neural networks will cap the forecasting performance due to the occurrence of over-fitting. A novel pooling-based deep recurrent neural network is proposed in this paper which batches a group of customers' load profiles into a pool of inputs. Essentially the model could address the over-fitting issue by increasing data diversity and volume. This paper reports the first attempts to develop a bespoke deep learning application for household load forecasting and achieved preliminary success. The developed method is implemented on Tensorflow deep learning platform and tested on 920 smart metered customers from Ireland. Compared with the state-of-the-art techniques in household load forecasting, the proposed method outperforms ARIMA by 19.5%, SVR by 13.1% and classical deep RNN by 6.5% in terms of RMSE.","","","10.1109/TSG.2017.2686012","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7885096","Big data;deep learning;load forecasting;long short-term memory;machine learning;neural network;smart meter","Machine learning;Uncertainty;Load forecasting;Neural networks;Training;Computer architecture;Forecasting","learning (artificial intelligence);load forecasting;power engineering computing;recurrent neural nets;regression analysis","household load forecasting;load profiles;load aggregation;cluster uncertainties;novel pooling-based deep recurrent neural network;bespoke deep learning application;Tensorflow deep learning platform;classical deep RNN","","43","42","","","","","IEEE","IEEE Journals"
"On Intelligent Traffic Control for Large-Scale Heterogeneous Networks: A Value Matrix-Based Deep Learning Approach","Z. Md. Fadlullah; F. Tang; B. Mao; J. Liu; N. Kato","Graduate School of Information Sciences, Tohoku University, Sendai, Japan; Graduate School of Information Sciences, Tohoku University, Sendai, Japan; Graduate School of Information Sciences, Tohoku University, Sendai, Japan; School of Cyber Engineering, Xidian University, Xi’an, China; Graduate School of Information Sciences, Tohoku University, Sendai, Japan","IEEE Communications Letters","","2018","22","12","2479","2482","Recently, deep learning has emerged as an attractive technique to intelligently control network traffic. However, the contemporary researches only focused on small-/medium-scale networks, since the computational complexity of deep learning based traffic control algorithm significantly increases with the network size. In this paper, we address this issue and envision a reward-based deep learning structure, which jointly employs deep convolutional neural network (CNN) and a deep belief network (DBN) to predict the traffic load value matrix and construct the final action matrix, respectively. In our proposal, the deep CNN is used to construct the award prediction network, while the deep DBN constructs the action decision network. Thus, the final action space is simplified to a next destination action matrix, and the computational complexity is substantially reduced. Computer-based simulation results demonstrate that our proposal is able to achieve an improved performance in the large-scale network in terms of the packets loss rate and throughput in contrast with those in the conventional routing method.","","","10.1109/LCOMM.2018.2875431","Japan Society for the Promotion of Science; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8489985","Deep learning;packets forwarding;routing protocol;non-supervised learning;convolutional neural network (CNN);deep belief network (DBN)","Machine learning;Training data;Telecommunication traffic;Computational complexity;Convolutional neural networks;Heterogeneous networks;Routing protocols;Semisupervised learning","belief networks;control engineering computing;intelligent control;learning (artificial intelligence);neural nets;routing protocols;telecommunication computing;telecommunication control;telecommunication traffic","intelligent traffic control;large-scale heterogeneous networks;computational complexity;deep convolutional neural network;deep belief network;deep CNN;award prediction network;action decision network;value matrix;traffic control algorithm;computer-based simulation;deep learning;deep DBN;routing protocol","","6","17","","","","","IEEE","IEEE Journals"
"Deep Metric Learning for Crowdedness Regression","Q. Wang; J. Wan; Y. Yuan","School of Computer Science and the Center for OPTical IMagery Analysis and Learning; School of Computer Science and the Center for OPTical IMagery Analysis and Learning, Northwestern Polytechnical University, Xi’an, China; School of Computer Science and the Center for OPTical IMagery Analysis and Learning, Northwestern Polytechnical University, Xi’an, China","IEEE Transactions on Circuits and Systems for Video Technology","","2018","28","10","2633","2643","Cross-scene regression tasks, such as congestion level detection and crowd counting, are useful but challenging. There are two main problems, which limit the performance of existing algorithms. The first one is that no appropriate congestion-related feature can reflect the real density in scenes. Though deep learning has been proved to be capable of extracting high level semantic representations, it is hard to converge on regression tasks, since the label is too weak to guide the learning of parameters in practice. Thus, many approaches utilize additional information, such as a density map, to guide the learning, which increases the effort of labeling. Another problem is that most existing methods are composed of several steps, for example, feature extraction and regression. Since the steps in the pipeline are separated, these methods face the problem of complex optimization. To remedy it, a deep metric learning-based regression method is proposed to extract density related features, and learn better distance measurement simultaneously. The proposed networks trained end-to-end for better optimization can be used for crowdedness regression tasks, including congestion level detection and crowd counting. Extensive experiments confirm the effectiveness of the proposed method.","","","10.1109/TCSVT.2017.2703920","National Natural Science Foundation of China; Chinese Academy of Sciences; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7927432","Deep learning;metric learning;regression;congestion detection;crowd counting","Feature extraction;Training;Machine learning;Distance measurement;Learning systems;Algorithm design and analysis","feature extraction;image representation;learning (artificial intelligence);regression analysis","crowdedness regression tasks;congestion level detection;crowd counting;cross-scene regression tasks;high level semantic representations;density map;feature extraction;deep metric learning-based regression method;complex optimization","","24","51","","","","","IEEE","IEEE Journals"
"Deep Logic Networks: Inserting and Extracting Knowledge From Deep Belief Networks","S. N. Tran; A. S. d’Avila Garcez","Department of Computer Science, City University London, London, U.K.; Department of Computer Science, City University London, London, U.K.","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","2","246","258","Developments in deep learning have seen the use of layerwise unsupervised learning combined with supervised learning for fine-tuning. With this layerwise approach, a deep network can be seen as a more modular system that lends itself well to learning representations. In this paper, we investigate whether such modularity can be useful to the insertion of background knowledge into deep networks, whether it can improve learning performance when it is available, and to the extraction of knowledge from trained deep networks, and whether it can offer a better understanding of the representations learned by such networks. To this end, we use a simple symbolic language-a set of logical rules that we call confidence rules-and show that it is suitable for the representation of quantitative reasoning in deep networks. We show by knowledge extraction that confidence rules can offer a low-cost representation for layerwise networks (or restricted Boltzmann machines). We also show that layerwise extraction can produce an improvement in the accuracy of deep belief networks. Furthermore, the proposed symbolic characterization of deep networks provides a novel method for the insertion of prior knowledge and training of deep networks. With the use of this method, a deep neural-symbolic system is proposed and evaluated, with the experimental results indicating that modularity through the use of confidence rules and knowledge insertion can be beneficial to network performance.","","","10.1109/TNNLS.2016.2603784","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7738566","Deep belief networks (DBNs);deep learning;knowledge extraction;knowledge representation and reasoning;neural–symbolic integration","Knowledge engineering;Markov random fields;Cognition;Training;Neural networks;Computational modeling","belief networks;inference mechanisms;knowledge acquisition;learning (artificial intelligence)","deep logic networks;deep belief networks;deep learning;layerwise unsupervised learning;learning representations;confidence rules;layerwise networks;deep neural-symbolic system;knowledge extraction;symbolic language;logical rules;quantitative reasoning;layerwise extraction","","6","43","","","","","IEEE","IEEE Journals"
"Power of Deep Learning for Channel Estimation and Signal Detection in OFDM Systems","H. Ye; G. Y. Li; B. Juang","Department of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; Department of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; Department of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA","IEEE Wireless Communications Letters","","2018","7","1","114","117","This letter presents our initial results in deep learning for channel estimation and signal detection in orthogonal frequency-division multiplexing (OFDM) systems. In this letter, we exploit deep learning to handle wireless OFDM channels in an end-to-end manner. Different from existing OFDM receivers that first estimate channel state information (CSI) explicitly and then detect/recover the transmitted symbols using the estimated CSI, the proposed deep learning-based approach estimates CSI implicitly and recovers the transmitted symbols directly. To address channel distortion, a deep learning model is first trained offline using the data generated from simulation based on channel statistics and then used for recovering the online transmitted data directly. From our simulation results, the deep learning based approach can address channel distortion and detect the transmitted symbols with performance comparable to the minimum mean-square error estimator. Furthermore, the deep learning-based approach is more robust than conventional methods when fewer training pilots are used, the cyclic prefix is omitted, and nonlinear clipping noise exists. In summary, deep learning is a promising tool for channel estimation and signal detection in wireless communications with complicated channel distortion and interference.","","","10.1109/LWC.2017.2757490","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8052521","Deep learning;channel estimation;OFDM","Machine learning;OFDM;Channel estimation;Data models;Wireless communication;Training;Nonlinear distortion","channel estimation;learning (artificial intelligence);OFDM modulation;signal detection","complicated channel distortion;channel estimation;signal detection;orthogonal frequency-division multiplexing systems;wireless OFDM channels;estimate channel state information;transmitted symbols;deep learning based approach","","125","10","","","","","IEEE","IEEE Journals"
"A New Learning Automata-Based Pruning Method to Train Deep Neural Networks","H. Guo; S. Li; B. Li; Y. Ma; X. Ren","School of Cyber Space Security, Shanghai Jiao Tong University, Shanghai, China; School of Cyber Space Security, Shanghai Jiao Tong University, Shanghai, China; School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China; School of Cyber Space Security, Shanghai Jiao Tong University, Shanghai, China; School of Cyber Space Security, Shanghai Jiao Tong University, Shanghai, China","IEEE Internet of Things Journal","","2018","5","5","3263","3269","Deep neural network are one of the most powerful model for machine learning, which can learn the underlying patterns automatically from a large amount of data. So it can be extensively used in more and more Internet-of-Things (IoT) applications. However, the training of deep models is difficult, suffering from overfitting and gradient vanishing problem. Besides, the large amount of parameters and multiplication operations make it impractical for most deep learning models to directly execute on target hardware. In this paper, we propose a method of gradually pruning the weakly connected weights to improve the traditional stochastic gradient descent. And we adopt a reinforcement learning method called learning automata to find the weakly connected weights on account of its strong policy-making ability in stochastic and nonstationary environment. Our proposed method can learn a more effective and sparsely connected architecture during training from the initially fully connected neural networks. The experiments on MNIST show that our method have stronger power to defeat overfitting and can get better generalization performance on test set. Meanwhile, the thin and sparsely connected model we get can be more suitable for IoT applications.","","","10.1109/JIOT.2017.2711426","National Key Research and Development Project of China; Science and Technology Project of the State Grid Corporation of China; Key Laboratory for Shanghai Integrated Information Security Management Technology Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7939970","Deep neural network;learning automata;overfitting;stochastic gradient descent","Training;Neural networks;Learning automata;Machine learning;Learning (artificial intelligence);Stochastic processes;Computational modeling","gradient methods;Internet of Things;learning (artificial intelligence);learning automata;neural nets;stochastic processes","sparsely connected architecture;initially fully connected neural networks;thin connected model;sparsely connected model;IoT applications;neural network;powerful model;machine learning;underlying patterns;Internet-of-Things applications;deep models;overfitting vanishing problem;gradient vanishing problem;multiplication operations;deep learning models;target hardware;weakly connected weights;traditional stochastic gradient descent;reinforcement learning method;strong policy-making ability;stochastic environment;nonstationary environment;effective connected architecture;MNIST;learning automata-based pruning method;deep neural network training","","2","28","","","","","IEEE","IEEE Journals"
"Deep Learning-Based Inversion Method for Imaging Problems in Electrical Capacitance Tomography","J. Lei; Q. Liu; X. Wang","School of Energy, Power and Mechanical Engineering, North China Electric Power University, Beijing, China; Institute of Engineering Thermophysics, Chinese Academy of Sciences, Beijing, China; School of Control and Computer Engineering, North China Electric Power University, Beijing, China","IEEE Transactions on Instrumentation and Measurement","","2018","67","9","2107","2118","Electrical capacitance tomography exhibits great potentials in the visualization measurement of industrial processes, and high-precision images are of great significance for the reliability and usefulness of measurement results. In this paper, we propose a deep learning-based inversion method to ameliorate the reconstruction accuracy. With the aid of the deep learning methodology, the prior from the images reconstructed by a certain imaging technique to the true images is abstracted and stored in the deep extreme learning machine. A new cost function is constructed to encapsulate the prior from the proposed deep learning model and the domain expertise about imaging targets, and the split Bregman algorithm and the fast iterative shrinkage thresholding technique are combined into a new numerical method to effectively solve it to get the final reconstruction. The numerical and experimental results validate that the inversion method proposed in this paper reduces the reconstruction artifacts and deformations and leads to the much improvement in the imaging quality.","","","10.1109/TIM.2018.2811228","National Natural Science Foundation of China; National Key Research and Development Program of China; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8319916","Deep extreme learning machine (DELM);deep learning;electrical capacitance tomography (ECT);image reconstruction;inverse problem;reconstruction method","Imaging;Image reconstruction;Machine learning;Training;Cost function;Numerical models;Iterative methods","deformation;image reconstruction;image segmentation;iterative methods;learning (artificial intelligence);production engineering computing;tomography","imaging problems;visualization measurement;high-precision images;deep learning methodology;imaging technique;deep extreme learning machine;deep learning model;imaging quality;deep learning;electrical capacitance tomography;industrial processes;split Bregman algorithm;deformations;iterative shrinkage thresholding","","2","38","","","","","IEEE","IEEE Journals"
"When Deep Learning Meets Metric Learning: Remote Sensing Image Scene Classification via Learning Discriminative CNNs","G. Cheng; C. Yang; X. Yao; L. Guo; J. Han","School of Automation, Northwestern Polytechnical University, Xi’an, China; School of Automation, Northwestern Polytechnical University, Xi’an, China; School of Automation, Northwestern Polytechnical University, Xi’an, China; School of Automation, Northwestern Polytechnical University, Xi’an, China; School of Automation, Northwestern Polytechnical University, Xi’an, China","IEEE Transactions on Geoscience and Remote Sensing","","2018","56","5","2811","2821","Remote sensing image scene classification is an active and challenging task driven by many applications. More recently, with the advances of deep learning models especially convolutional neural networks (CNNs), the performance of remote sensing image scene classification has been significantly improved due to the powerful feature representations learnt through CNNs. Although great success has been obtained so far, the problems of within-class diversity and between-class similarity are still two big challenges. To address these problems, in this paper, we propose a simple but effective method to learn discriminative CNNs (D-CNNs) to boost the performance of remote sensing image scene classification. Different from the traditional CNN models that minimize only the cross entropy loss, our proposed D-CNN models are trained by optimizing a new discriminative objective function. To this end, apart from minimizing the classification error, we also explicitly impose a metric learning regularization term on the CNN features. The metric learning regularization enforces the D-CNN models to be more discriminative so that, in the new D-CNN feature spaces, the images from the same scene class are mapped closely to each other and the images of different classes are mapped as farther apart as possible. In the experiments, we comprehensively evaluate the proposed method on three publicly available benchmark data sets using three off-the-shelf CNN models. Experimental results demonstrate that our proposed D-CNN methods outperform the existing baseline methods and achieve state-of-the-art results on all three data sets.","","","10.1109/TGRS.2017.2783902","National Science Foundation of China; Natural Science Basic Research Plan in Shaanxi Province of China; Science and Technology Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8252784","Convolutional neural networks (CNNs);deep learning;discriminative CNNs (D-CNNs);metric learning;remote sensing image scene classification","Remote sensing;Feature extraction;Measurement;Learning systems;Machine learning;Image color analysis;Computer architecture","entropy;feature extraction;geophysical image processing;image classification;image representation;learning (artificial intelligence);minimisation;neural nets;remote sensing","learning discriminative CNNs;convolutional neural networks;feature representations;within-class diversity;between-class similarity;cross entropy loss;discriminative objective function;classification error minimization;benchmark data sets;off-the-shelf CNN models;scene class;metric learning regularization term;D-CNN models;deep learning models;remote sensing image scene classification","","78","65","","","","","IEEE","IEEE Journals"
"Integrating State Representation Learning Into Deep Reinforcement Learning","T. de Bruin; J. Kober; K. Tuyls; R. Babuška","Cognitive Robotics Department, Delft University of Technology, Delft, The Netherlands; Cognitive Robotics Department, Delft University of Technology, Delft, The Netherlands; Google Deepmind, London, U.K.; Cognitive Robotics Department, Delft University of Technology, Delft, The Netherlands","IEEE Robotics and Automation Letters","","2018","3","3","1394","1401","Most deep reinforcement learning techniques are unsuitable for robotics, as they require too much interaction time to learn useful, general control policies. This problem can be largely attributed to the fact that a state representation needs to be learned as a part of learning control policies, which can only be done through fitting expected returns based on observed rewards. While the reward function provides information on the desirability of the state of the world, it does not necessarily provide information on how to distill a good, general representation of that state from the sensory observations. State representation learning objectives can be used to help learn such a representation. While many of these objectives have been proposed, they are typically not directly combined with reinforcement learning algorithms. We investigate several methods for integrating state representation learning into reinforcement learning. In these methods, the state representation learning objectives help regularize the state representation during the reinforcement learning, and the reinforcement learning itself is viewed as a crucial state representation learning objective and allowed to help shape the representation. Using autonomous racing tests in the TORCS simulator, we show how the integrated methods quickly learn policies that generalize to new environments much better than deep reinforcement learning without state representation learning.","","","10.1109/LRA.2018.2800101","Robust Robot Control (DL-Force); Netherlands Organisation for Scientific Research (NWO); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8276247","Deep learning in robotics and automation;learning and adaptive systems;sensor fusion","Robot sensing systems;Learning (artificial intelligence);Task analysis;Machine learning;Shape;Training","learning (artificial intelligence)","deep reinforcement learning techniques;robotics;state representation learning integration;learning control policies;desirability;autonomous racing tests;TORCS simulator;sensory observations","","8","32","","","","","IEEE","IEEE Journals"
"Deep Air Learning: Interpolation, Prediction, and Feature Analysis of Fine-Grained Air Quality","Z. Qi; T. Wang; G. Song; W. Hu; X. Li; Z. Zhang","Oregon State University, Corvallis, OR; Singapore Management University, Singapore; Peking University, Beijing, China; NEC Laboratories China, Beijing, China; Zhejiang University, Hangzhou, China; Computer Science Department, State University of New York, Binghamton, NY","IEEE Transactions on Knowledge and Data Engineering","","2018","30","12","2285","2297","The interpolation, prediction, and feature analysis of fine-gained air quality are three important topics in the area of urban air computing. The solutions to these topics can provide extremely useful information to support air pollution control, and consequently generate great societal and technical impacts. Most of the existing work solves the three problems separately by different models. In this paper, we propose a general and effective approach to solve the three problems in one model called the Deep Air Learning (DAL). The main idea of DAL lies in embedding feature selection and semi-supervised learning in different layers of the deep learning network. The proposed approach utilizes the information pertaining to the unlabeled spatio-temporal data to improve the performance of the interpolation and the prediction, and performs feature selection and association analysis to reveal the main relevant features to the variation of the air quality. We evaluate our approach with extensive experiments based on real data sources obtained in Beijing, China. Experiments show that DAL is superior to the peer models from the recent literature when solving the topics of interpolation, prediction, and feature analysis of fine-gained air quality.","","","10.1109/TKDE.2018.2823740","NEC Laboratories China; National Basic Research Program of China; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8333777","Feature selection;feature analysis;spatio-temporal semi-supervised learning;deep learning","Atmospheric modeling;Feature extraction;Semisupervised learning;Predictive models;Deep learning;Analytical models","air pollution control;air quality;data analysis;environmental science computing;interpolation;learning (artificial intelligence)","interpolation;feature analysis;fine-gained air quality;urban air computing;air pollution control;DAL;feature selection;semisupervised learning;deep learning network;association analysis;deep air learning","","9","36","","","","","IEEE","IEEE Journals"
"Broad Learning System: An Effective and Efficient Incremental Learning System Without the Need for Deep Architecture","C. L. P. Chen; Z. Liu","Department of Computer and Information Science, Faculty of Science and Technology, University of Macau, Macau, China; Department of Computer and Information Science, Faculty of Science and Technology, University of Macau, Macau, China","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","1","10","24","Broad Learning System (BLS) that aims to offer an alternative way of learning in deep structure is proposed in this paper. Deep structure and learning suffer from a time-consuming training process because of a large number of connecting parameters in filters and layers. Moreover, it encounters a complete retraining process if the structure is not sufficient to model the system. The BLS is established in the form of a flat network, where the original inputs are transferred and placed as “mapped features” in feature nodes and the structure is expanded in wide sense in the “enhancement nodes.” The incremental learning algorithms are developed for fast remodeling in broad expansion without a retraining process if the network deems to be expanded. Two incremental learning algorithms are given for both the increment of the feature nodes (or filters in deep structure) and the increment of the enhancement nodes. The designed model and algorithms are very versatile for selecting a model rapidly. In addition, another incremental learning is developed for a system that has been modeled encounters a new incoming input. Specifically, the system can be remodeled in an incremental way without the entire retraining from the beginning. Satisfactory result for model reduction using singular value decomposition is conducted to simplify the final structure. Compared with existing deep neural networks, experimental results on the Modified National Institute of Standards and Technology database and NYU NORB object recognition dataset benchmark data demonstrate the effectiveness of the proposed BLS.","","","10.1109/TNNLS.2017.2716952","Fundo para o Desenvolvimento das Ciências e da Tecnologia; UM Research Grants; National Nature Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7987745","Big data;big data modeling;broad learning system (BLS);deep learning;incremental learning;random vector functional-link neural networks (RVFLNN);single layer feedforward neural networks (SLFN);singular value decomposition (SVD)","Algorithm design and analysis;Neural networks;Learning systems;Feature extraction;Training;Approximation algorithms;Heuristic algorithms","Big Data;learning (artificial intelligence);singular value decomposition","incremental learning algorithms;feature nodes;enhancement nodes;BLS;Broad Learning System;mapped features;model reduction;singular value decomposition;Modified National Institute of Standards and Technology database;NYU NORB object recognition dataset","","73","55","","","","","IEEE","IEEE Journals"
"Joint Feature and Similarity Deep Learning for Vehicle Re-identification","J. Zhu; H. Zeng; Y. Du; Z. Lei; L. Zheng; C. Cai","Fujian Provincial Academic Engineering Research Centre in Industrial Intellectual Techniques and Systems, College of Engineering, Huaqiao University, Quanzhou, China; College of Information Science and Engineering, Huaqiao University, Xiamen, China; Fujian Provincial Academic Engineering Research Centre in Industrial Intellectual Techniques and Systems, College of Engineering, Huaqiao University, Quanzhou, China; Center for Biometrics and Security Research and the National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Fujian Provincial Academic Engineering Research Centre in Industrial Intellectual Techniques and Systems, College of Engineering, Huaqiao University, Quanzhou, China; Fujian Provincial Academic Engineering Research Centre in Industrial Intellectual Techniques and Systems, College of Engineering, Huaqiao University, Quanzhou, China","IEEE Access","","2018","6","","43724","43731","In this paper, a joint feature and similarity deep learning (JFSDL) method for vehicle reidentification is proposed. The proposed JFSDL method applies a siamese deep network to extract deep learning features for an input vehicle image pair simultaneously. The siamese deep network is learned under the joint identification and verification supervision. The joint identification and verification supervision is realized by linearly combining two softmax functions and one hybrid similarity learning function. Moreover, based on the hybrid similarity learning function, the similarity score between the input vehicle image pair is also obtained by simultaneously projecting the element-wise absolute difference and multiplication of the corresponding deep learning feature pair with a group of learned weight coefficients. Extensive experiments show that the proposed JFSDL method is superior to multiple state-of-the-art vehicle re-identification methods on both the VehicleID and VeRi data sets.","","","10.1109/ACCESS.2018.2862382","National Natural Science Foundation of China; Natural Science Foundation of Fujian Province; Science and Technology Bureau of Quanzhou; Xiamen Municipal Bureau of Science and Technology; Promotion Program for Young and Middle-aged Teacher in Science and Technology Research of Huaqiao University; Huaqiao University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8424333","Vehicle re-identification;feature representation;similarity learning;deep learning","Machine learning;Feature extraction;Training;Face recognition;Euclidean distance;Security","feature extraction;image recognition;learning (artificial intelligence);traffic engineering computing","JFSDL method;siamese deep network;input vehicle image pair;hybrid similarity learning function;similarity score;corresponding deep learning feature pair;learned weight coefficients;multiple state-of-the-art vehicle re-identification methods;joint feature;deep learning feature extraction;joint feature and similarity deep learning method;joint identification and verification supervision;vehicle reidentification method;VeRi data sets;VehicleID data set;softmax functions","","5","26","","","","","IEEE","IEEE Journals"
"Deep Learning for Intelligent Wireless Networks: A Comprehensive Survey","Q. Mao; F. Hu; Q. Hao","Department of Electrical and Computer Engineering, University of Alabama, Tuscaloosa, AL, USA; Department of Electrical and Computer Engineering, University of Alabama, Tuscaloosa, AL, USA; Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, China","IEEE Communications Surveys & Tutorials","","2018","20","4","2595","2621","As a promising machine learning tool to handle the accurate pattern recognition from complex raw data, deep learning (DL) is becoming a powerful method to add intelligence to wireless networks with large-scale topology and complex radio conditions. DL uses many neural network layers to achieve a brain-like acute feature extraction from high-dimensional raw data. It can be used to find the network dynamics (such as hotspots, interference distribution, congestion points, traffic bottlenecks, spectrum availability, etc.) based on the analysis of a large amount of network parameters (such as delay, loss rate, link signal-to-noise ratio, etc.). Therefore, DL can analyze extremely complex wireless networks with many nodes and dynamic link quality. This paper performs a comprehensive survey of the applications of DL algorithms for different network layers, including physical layer modulation/coding, data link layer access control/resource allocation, and routing layer path search, and traffic balancing. The use of DL to enhance other network functions, such as network security, sensing data compression, etc., is also discussed. Moreover, the challenging unsolved research issues in this field are discussed in detail, which represent the future research trends of DL-based wireless networks. This paper can help the readers to deeply understand the state-of-the-art of the DL-based wireless network designs, and select interesting unsolved issues to pursue in their research.","","","10.1109/COMST.2018.2846401","Science and Technology Innovation Commission of Shenzhen; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8382166","Wireless networks;deep learning (DL);deep reinforcement learning (DRL);protocol layers;performance optimization","Machine learning;Wireless networks;Feature extraction;Routing;Computers;Interference;Deep learning","data compression;feature extraction;learning (artificial intelligence);neural nets;pattern recognition;resource allocation;telecommunication traffic","intelligent wireless networks;deep learning;large-scale topology;complex radio conditions;neural network layers;brain-like acute feature extraction;high-dimensional raw data;interference distribution;congestion points;traffic bottlenecks;spectrum availability;network parameters;signal-to-noise ratio;dynamic link quality;layer path search;traffic balancing;network functions;network security;data compression;DL-based wireless networks;wireless network designs;pattern recognition;layer access control;resource allocation;physical layer modulation-coding;complex wireless networks;machine learning tool;data link layer access control;sensing data compression","","40","122","","","","","IEEE","IEEE Journals"
"Build the Structure of WFSless AO System Through Deep Reinforcement Learning","K. Hu; Z. X. Xu; W. Yang; B. Xu","Key Laboratory of Adaptive Optics, Chinese Academy of Sciences, Chengdu, China; Key Laboratory of Adaptive Optics, Chinese Academy of Sciences, Chengdu, China; University of Chinese Academy of Sciences, Beijing, China; Key Laboratory of Adaptive Optics, Chinese Academy of Sciences, Chengdu, China","IEEE Photonics Technology Letters","","2018","30","23","2033","2036","We report on an aberration correction algorithm for a wavefront sensorless adaptive optics (WFSless AO) system based on deep reinforcement learning. First, it is verified that the reinforcement learning theory can be applied in our system. In addition, the deep deterministic policy gradient algorithm is introduced to build the control structure. After that, deep learning is used to deal with the messy raw images of far-field intensity distribution. We emphatically present how to design a feature extraction with the convolutional neural network in the control structure. To demonstrate the performance of this structure, some comparisons are made with the stochastic parallel gradient descent algorithm and the WFSless AO based on general modes algorithm. The results indicate that the correction speed of our method improves about 9 times and 2.5 times, respectively, for the similar correction effect.","","","10.1109/LPT.2018.2874998","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8487017","WFSless AO;deep reinforcement learning;DDPG;CNN;SPGD;AOG","Feature extraction;Task analysis;Neural networks;Adaptive optics;Stochastic processes;Indexes","aberrations;adaptive optics;convolution;feature extraction;feedforward neural nets;gradient methods;image processing;learning (artificial intelligence);optical information processing;stochastic processes;Zernike polynomials","WFSless AO system;deep reinforcement learning;aberration correction algorithm;wavefront sensorless adaptive optics system;reinforcement learning theory;deep deterministic policy gradient algorithm;deep learning;stochastic parallel gradient descent algorithm;feature extraction;convolutional neural network","","","15","","","","","IEEE","IEEE Journals"
"Optimizing Kernel Machines Using Deep Learning","H. Song; J. J. Thiagarajan; P. Sattigeri; A. Spanias","SenSIP Center, School of Electrical, Computer and Energy Engineering, Arizona State University, Tempe, AZ, USA; Lawrence Livermore National Laboratory, Livermore, CA, USA; IBM T. J. Watson Research Center, Yorktown Heights, NY, USA; SenSIP Center, School of Electrical, Computer and Energy Engineering, Arizona State University, Tempe, AZ, USA","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","11","5528","5540","Building highly nonlinear and nonparametric models is central to several state-of-the-art machine learning systems. Kernel methods form an important class of techniques that induce a reproducing kernel Hilbert space (RKHS) for inferring non-linear models through the construction of similarity functions from data. These methods are particularly preferred in cases where the training data sizes are limited and when prior knowledge of the data similarities is available. Despite their usefulness, they are limited by the computational complexity and their inability to support end-to-end learning with a task-specific objective. On the other hand, deep neural networks have become the de facto solution for end-to-end inference in several learning paradigms. In this paper, we explore the idea of using deep architectures to perform kernel machine optimization, for both computational efficiency and end-to-end inferencing. To this end, we develop the deep kernel machine optimization framework, that creates an ensemble of dense embeddings using Nyström kernel approximations and utilizes deep learning to generate task-specific representations through the fusion of the embeddings. Intuitively, the filters of the network are trained to fuse information from an ensemble of linear subspaces in the RKHS. Furthermore, we introduce the kernel dropout regularization to enable improved training convergence. Finally, we extend this framework to the multiple kernel case, by coupling a global fusion layer with pretrained deep kernel machines for each of the constituent kernels. Using case studies with limited training data, and lack of explicit feature sources, we demonstrate the effectiveness of our framework over conventional model inferencing techniques.","","","10.1109/TNNLS.2018.2804895","Arizona State University; U.S. Department of Energy; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8307246","Deep neural networks (DNNs);kernel methods;multiple kernel learning (MKL);Nyström approximation","Kernel;Optimization;Machine learning;Task analysis;Computer architecture;Computational modeling;Data models","data analysis;Hilbert spaces;learning (artificial intelligence);neural nets","nonlinear models;nonparametric models;reproducing kernel Hilbert space;RKHS;similarity functions;training data sizes;data similarities;computational complexity;task-specific objective;deep neural networks;end-to-end inference;learning paradigms;deep architectures;computational efficiency;end-to-end inferencing;deep kernel machine optimization framework;Nyström kernel approximations;utilizes deep learning;task-specific representations;linear subspaces;kernel dropout regularization;improved training convergence;multiple kernel case;pretrained deep kernel machines;constituent kernels;conventional model inferencing techniques;machine learning systems","","10","71","","","","","IEEE","IEEE Journals"
"Deep Manifold Learning Combined With Convolutional Neural Networks for Action Recognition","X. Chen; J. Weng; W. Lu; J. Xu; J. Weng","Guangdong Key Laboratory of Data Security and Privacy Preserving, Guangdong Engineering Research Center of Data Security and Privacy Preserving, College of Information Science and Technology, Jinan University, Guangzhou, China; Guangdong Key Laboratory of Data Security and Privacy Preserving, Guangdong Engineering Research Center of Data Security and Privacy Preserving, College of Information Science and Technology, Jinan University, Guangzhou, China; Guangdong Key Laboratory of Information Security Technology, School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; Baiyun District Bureau of Justice, Guangzhou, China; Guangdong Key Laboratory of Data Security and Privacy Preserving, Guangdong Engineering Research Center of Data Security and Privacy Preserving, College of Information Science and Technology, Jinan University, Guangzhou, China","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","9","3938","3952","Learning deep representations have been applied in action recognition widely. However, there have been a few investigations on how to utilize the structural manifold information among different action videos to enhance the recognition accuracy and efficiency. In this paper, we propose to incorporate the manifold of training samples into deep learning, which is defined as deep manifold learning (DML). The proposed DML framework can be adapted to most existing deep networks to learn more discriminative features for action recognition. When applied to a convolutional neural network, DML embeds the previous convolutional layer's manifold into the next convolutional layer; thus, the discriminative capacity of the next layer can be promoted. We also apply the DML on a restricted Boltzmann machine, which can alleviate the overfitting problem. Experimental results on four standard action databases (i.e., UCF101, HMDB51, KTH, and UCF sports) show that the proposed method outperforms the state-of-the-art methods.","","","10.1109/TNNLS.2017.2740318","National Natural Science Foundation of China; Key Program for Guangdong Province Applied Science and Technology Research and Development Special Funds; Guangdong Key Laboratory of Data Security and Privacy Preserving; Guangzhou Key Laboratory of Data Security and Privacy Preserving; Guangdong Engineering Technology Research and Development Center of Network Security Detection and Protection; Guangdong Engineering Technology Research Center of Privacy Preservation and Data Security and the Guangdong Innovative and Entrepreneurial Research Team Program; National Natural Science Foundation of China; Natural Science Foundation of Guangdong Province; Special Funds for Science and Technology Development of Guangdong; Fundamental Research Funds for the Central Universities; Scientific and Technological Achievements Transformation Plan of Sun Yat-sen University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8038860","Action recognition;convolutional neural network (CNN);deep manifold learning (DML);restricted Boltzmann machine (RBM)","Training;Manifolds;Videos;Machine learning;Data security;Data privacy;Convergence","Boltzmann machines;image recognition;image representation;learning (artificial intelligence);video signal processing","overfitting problem;Boltzmann machine;convolutional layer;action videos;deep representations learning;recognition efficiency;convolutional neural networks;deep networks;DML framework;deep learning;recognition accuracy;structural manifold information;action recognition;deep manifold learning;standard action databases","","3","68","","","","","IEEE","IEEE Journals"
"Clinical Report Guided Retinal Microaneurysm Detection With Multi-Sieving Deep Learning","L. Dai; R. Fang; H. Li; X. Hou; B. Sheng; Q. Wu; W. Jia","Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Biomedical Engineering, University of Florida, Gainesville, FL, USA; Shanghai Jiao Tong University Affiliated Sixth People’s Hospital, Shanghai, China; Shanghai Jiao Tong University Affiliated Sixth People’s Hospital, Shanghai, China; Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China; Shanghai Jiao Tong University Affiliated Sixth People’s Hospital, Shanghai, China; Shanghai Jiao Tong University Affiliated Sixth People’s Hospital, Shanghai, China","IEEE Transactions on Medical Imaging","","2018","37","5","1149","1161","Timely detection and treatment of microaneurysms is a critical step to prevent the development of vision-threatening eye diseases such as diabetic retinopathy. However, detecting microaneurysms in fundus images is a highly challenging task due to the low image contrast, misleading cues of other red lesions, and the large variation of imaging conditions. Existing methods tend to fail in face of the large intra-class variation and small inter-class variations for microaneurysm detection in fundus images. Recently, hybrid text/image mining computer-aided diagnosis systems have emerged to offer a promise of bridging the semantic gap between images and diagnostic information. In this paper, we focus on developing an interleaved deep mining technique to cope intelligently with the unbalanced microaneurysm detection problem. Specifically, we present a clinical report guided multi-sieving convolutional neural network, which leverages a small amount of supervised information in clinical reports to identify the potential microaneurysm regions via the image-to-text mapping in the feature space. These potential microaneurysm regions are then interleaved with fundus image information for multi-sieving deep mining in a highly unbalanced classification problem. Critically, the clinical reports are employed to bridge the semantic gap between low-level image features and high-level diagnostic information. We build an efficient microaneurysm detection framework based on the hybrid text/image interleaving and validate its performance on challenging clinical data sets acquired from diabetic retinopathy patients. Extensive evaluations are carried out in terms of fundus detection and classification. Experimental results show that our framework achieves 99.7% precision and 87.8% recall, comparing favorably with the state-of-the-art algorithms. Integration of expert domain knowledge and image information demonstrates the feasibility of reducing the difficulty of training classifiers under extremely unbalanced data distributions.;Notice of Violation of IEEE Publication Principles<br><br> ""Clinical Report Guided Retinal Microaneurysm Detection With Multi-Sieving Deep Learning,""<br> by Ling Dai, Ruogu Fang, Huating Li, Xuhong Hou, Bin Sheng, Qiang Wu, and Weiping Jia<br> in the IEEE Transactions on Medical Imaging, vol. 37, no. 5, May 2018, pp. 1149-1161<br><br> After careful and considered review of the content and authorship of this paper by a duly constituted expert committee, this paper has been found to be in violation of IEEE's Publication Principles.<br><br> This paper contains significant portions of original text from the paper cited below. The original text was copied without attribution (including appropriate references to the original author(s) and/or paper title) and without permission.<br><br> ""Mapping Visual Features to Semantic Profiles for Retrieval in Medical Imaging,""<br> by Johannes Hofmanninger ; Georg Langs<br> in the Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2015, pp. 457-465.<br><br>","","","10.1109/TMI.2018.2794988","National Natural Science Foundation of China; National High-tech R&D Program of China (863 Program); Key Program for International S&T Cooperation Project, China; National Key Research and Development Program of China; Science and Technology Commission of Shanghai Municipality; National Science Foundation; National Center for Advancing Translational Sciences of the National Institute of Health; Interdisciplinary Program of Shanghai Jiao Tong University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8263115","Diabetic retinopathy;fundus image analysis;multi-sieving CNN;microaneurysm detection;clinical reports;deep learning","Image segmentation;Lesions;Hemorrhaging;Semantics;Retinopathy;Image color analysis;Retina","biomedical optical imaging;convolution;data mining;diseases;eye;feature extraction;feedforward neural nets;image classification;image segmentation;learning (artificial intelligence);medical image processing;text analysis","multisieving deep learning;hybrid text mining computer;hybrid image mining computer;microaneurysm regions;unbalanced classification problem;microaneurysm detection framework;diabetic retinopathy patients;clinical data;high-level diagnostic information;low-level image features;multisieving deep mining;fundus image information;image-to-text mapping;multisieving convolutional neural network;unbalanced microaneurysm detection problem;interleaved deep mining technique;low image contrast;fundus images;vision-threatening eye diseases;microaneurysms;deep learning;retinal microaneurysm detection;clinical report;expert domain knowledge","Deep Learning;Diabetic Retinopathy;Humans;Image Interpretation, Computer-Assisted;Microaneurysm;Retinal Vessels","2","50","","","","","IEEE","IEEE Journals"
"Hookworm Detection in Wireless Capsule Endoscopy Images With Deep Learning","J. He; X. Wu; Y. Jiang; Q. Peng; R. Jain","School of Information Science and Technology, Xipu Campus, Southwest Jiaotong University, Chengdu, China; School of Information Science and Technology, Xipu Campus, Southwest Jiaotong University, Chengdu, China; School of Computer Science, Fudan University, Shanghai, China; School of Information Science and Technology, Xipu Campus, Southwest Jiaotong University, Chengdu, China; School of Information and Computer Science, University of California at Irvine, Irvine, CA, USA","IEEE Transactions on Image Processing","","2018","27","5","2379","2392","As one of the most common human helminths, hookworm is a leading cause of maternal and child morbidity, which seriously threatens human health. Recently, wireless capsule endoscopy (WCE) has been applied to automatic hookworm detection. Unfortunately, it remains a challenging task. In recent years, deep convolutional neural network (CNN) has demonstrated impressive performance in various image and video analysis tasks. In this paper, a novel deep hookworm detection framework is proposed for WCE images, which simultaneously models visual appearances and tubular patterns of hookworms. This is the first deep learning framework specifically designed for hookworm detection in WCE images. Two CNN networks, namely edge extraction network and hookworm classification network, are seamlessly integrated in the proposed framework, which avoid the edge feature caching and speed up the classification. Two edge pooling layers are introduced to integrate the tubular regions induced from edge extraction network and the feature maps from hookworm classification network, leading to enhanced feature maps emphasizing the tubular regions. Experiments have been conducted on one of the largest WCE datasets with 440K WCE images, which demonstrate the effectiveness of the proposed hookworm detection framework. It significantly outperforms the state-of-the-art approaches. The high sensitivity and accuracy of the proposed method in detecting hookworms shows its potential for clinical application.","","","10.1109/TIP.2018.2801119","National Natural Science Foundation of China; Sichuan Science and Technology Innovation Seedling Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8279473","Hookworm detection;deep learning;convolutional neural network;computer-aided detection;wireless capsule endoscopy","Image edge detection;Feature extraction;Machine learning;Task analysis;Wireless sensor networks;Wireless communication;Endoscopes","biomedical optical imaging;biomedical telemetry;computer aided analysis;diseases;edge detection;endoscopes;feature extraction;gradient methods;image classification;learning (artificial intelligence);medical image processing;neural nets","wireless capsule endoscopy images;human health;automatic hookworm detection;deep convolutional neural network;video analysis tasks;deep hookworm detection framework;WCE images;deep learning framework;CNN networks;edge extraction network;hookworm classification network;edge feature caching;edge pooling layers;tubular regions;human helminths;child morbidity;maternal morbidity;image analysis tasks;WCE datasets;temperature 440.0 K","Adolescent;Adult;Aged;Capsule Endoscopy;Deep Learning;Hookworm Infections;Humans;Image Interpretation, Computer-Assisted;Middle Aged;Support Vector Machine;Young Adult","8","42","","","","","IEEE","IEEE Journals"
"A Greedy Deep Learning Method for Medical Disease Analysis","C. Wu; C. Luo; N. Xiong; W. Zhang; T. Kim","School of Optical-Electrical and Computer Engineering, University of Shanghai for Science and Technology, Shanghai, China; School of Optical-Electrical and Computer Engineering, University of Shanghai for Science and Technology, Shanghai, China; Department of Mathematics and Computer Science, Northeastern State University, Tahlequah, OK, USA; Department of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China; Department of Convergence Security, Sungshin Women’s University, Seongbuk-gu, South Korea","IEEE Access","","2018","6","","20021","20030","This paper proposes a new deep learning method, the greedy deep weighted dictionary learning for mobile multimedia for medical diseases analysis. Based on the traditional dictionary learning methods, which neglects the relationship between the sample and the dictionary atom, we propose the weighted mechanism to connect the sample with the dictionary atom in this paper. Meanwhile, the traditional dictionary learning method is prone to cause over-fitting for patient classification of the limited training data set. Therefore, this paper adopts l2-norm regularization constraint, which realizes the limitation of the model space, and enhances the generalization ability of the model and avoids over-fitting to some extent. Compared with the previous shallow dictionary learning, this paper proposed the greedy deep dictionary learning. We adopt the thinking of layer by layer training to increase the hidden layer, so that the local information between the layer and the layer can be trained to maintain their own characteristics, reduce the risk of overfitting and make sure that each layer of the network is convergent, which improves the accuracy of training and learning. With the development of Internet of Things and the soundness of healthcare monitoring system, the method proposed have better reliability in the field of mobile multimedia for healthcare. The results show that the learning method has a good effect on the classification of mobile multimedia for medical diseases, and the accuracy, sensitivity, and specificity of the classification have good performance, which may provide guidance for the diagnosis of disease in wisdom medical.","","","10.1109/ACCESS.2018.2823979","Shanghai Science and Technology Innovation Action Plan Project; Zhejiang Provincial Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8332933","Medical big data;machine learning;mobile multimedia;deep learning;dictionary learning;patient classification","Machine learning;Medical diagnostic imaging;Big Data;Medical services;Dictionaries;Training","diseases;greedy algorithms;health care;learning (artificial intelligence);medical diagnostic computing;mobile computing;multimedia systems;pattern classification","greedy deep learning method;medical disease analysis;greedy deep weighted dictionary;mobile multimedia;medical diseases analysis;traditional dictionary learning method;dictionary atom;greedy deep dictionary learning;shallow dictionary learning;patient classification;l2-norm regularization constraint;Internet of Things;healthcare;disease diagnosis","","7","40","","","","","IEEE","IEEE Journals"
"Multisource Transfer Double DQN Based on Actor Learning","J. Pan; X. Wang; Y. Cheng; Q. Yu","School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, China; School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, China; School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, China; School of Electrical and Power Engineering, China University of Mining and Technology, Xuzhou, China","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","6","2227","2238","Deep reinforcement learning (RL) comprehensively uses the psychological mechanisms of “trial and error” and “reward and punishment” in RL as well as powerful feature expression and nonlinear mapping in deep learning. Currently, it plays an essential role in the fields of artificial intelligence and machine learning. Since an RL agent needs to constantly interact with its surroundings, the deep Q network (DQN) is inevitably faced with the need to learn numerous network parameters, which results in low learning efficiency. In this paper, a multisource transfer double DQN (MTDDQN) based on actor learning is proposed. The transfer learning technique is integrated with deep RL to make the RL agent collect, summarize, and transfer action knowledge, including policy mimic and feature regression, to the training of related tasks. There exists action overestimation in DQN, i.e., the lower probability limit of action corresponding to the maximum Q value is nonzero. Therefore, the transfer network is trained by using double DQN to eliminate the error accumulation caused by action overestimation. In addition, to avoid negative transfer, i.e., to ensure strong correlations between source and target tasks, a multisource transfer learning mechanism is applied. The Atari2600 game is tested on the arcade learning environment platform to evaluate the feasibility and performance of MTDDQN by comparing it with some mainstream approaches, such as DQN and double DQN. Experiments prove that MTDDQN achieves not only human-like actor learning transfer capability, but also the desired learning efficiency and testing accuracy on target task.","","","10.1109/TNNLS.2018.2806087","National Natural Science Foundation of China; Natural Science Foundation of Jiangsu Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8310951","Actor learning;Atari2600 game;double deep Q network (DQN);multisource transfer","Task analysis;Games;Training;Learning systems;Neural networks;Optimization;Estimation","computer games;feature extraction;learning (artificial intelligence);neural nets;probability;psychology;regression analysis","multisource transfer double DQN;actor learning;deep reinforcement learning;deep learning;artificial intelligence;machine learning;RL agent;deep Q network;numerous network parameters;low learning efficiency;MTDDQN;transfer learning technique;deep RL;action knowledge;feature regression;action overestimation;transfer network;negative transfer;multisource transfer learning mechanism;arcade learning environment platform;transfer capability;testing accuracy;feature expression;learning efficiency;Atari2600 game","","","40","","","","","IEEE","IEEE Journals"
"Deep Localized Metric Learning","Y. Duan; J. Lu; J. Feng; J. Zhou","Department of Automation, Tsinghua University, Beijing, China; Department of Automation, Tsinghua University, Beijing, China; Department of Automation, Tsinghua University, Beijing, China; Department of Automation, Tsinghua University, Beijing, China","IEEE Transactions on Circuits and Systems for Video Technology","","2018","28","10","2644","2656","Metric learning has been widely used in many visual analysis applications, which learns new distance metrics to measure the similarities of samples effectively. Conventional metric learning methods learn a single linear Mahalanobis metric, yet such linear projections are not powerful enough to capture the nonlinear relationships. Recently, deep metric learning approaches, such as discriminative deep metric learning and deep transfer metric learning, have been introduced to fully exploit the nonlinearity of samples by learning hierarchical nonlinear transformations. However, these methods only learn holistic metrics over the input space and are limited for the heterogeneous data sets, where data varies locally. In this paper, we propose a deep localized metric learning approach for visual recognition by learning multiple fine-grained deep localized metrics. We first learn K local subspaces and one holistic subspace with the K-auto-encoders-based clustering. Then, given an input pair, we compute its localized distance on each learned subspace and obtain the final distance representation. Finally, we train the entire neural networks to ensure the distances of positive pairs smaller than negative pairs by a large margin. Experimental results on three visual recognition applications, including face recognition, person re-identification, and scene recognition, show that our DLML outperforms most existing metric learning approaches.","","","10.1109/TCSVT.2017.2711015","National Key Research and Development Program of China; National Natural Science Foundation of China; National 1000 Young Talents Plan Program; National Basic Research Program of China; Ministry of Education of China; Tsinghua University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7937828","Deep metric learning;local metric learning;K-auto-encoders;visual recognition","Measurement;Visualization;Learning systems;Face recognition;Training;Neural networks;Face","image recognition;learning (artificial intelligence);neural nets","K local subspaces;localized distance;distance metrics;single linear Mahalanobis metric;discriminative deep metric learning;deep transfer metric learning;holistic metrics;deep localized metric learning approach;fine-grained deep localized metrics;K-auto-encoders-based clustering;visual recognition;neural networks","","6","73","","","","","IEEE","IEEE Journals"
"A Deep Learning Architecture for Temporal Sleep Stage Classification Using Multivariate and Multimodal Time Series","S. Chambon; M. N. Galtier; P. J. Arnal; G. Wainrib; A. Gramfort","Research & Algorithms Team, Rythm Inc., Paris, France; Research & Algorithms Team, Rythm Inc., Paris, France; Research & Algorithms Team, Rythm Inc., Paris, France; Département d’Informatique, DATA Team, Ecole NormaleSupérieure, Paris, France; LTCI, Télécom ParisTech, Université Paris-Saclay, Paris, France","IEEE Transactions on Neural Systems and Rehabilitation Engineering","","2018","26","4","758","769","Sleep stage classification constitutes an important preliminary exam in the diagnosis of sleep disorders. It is traditionally performed by a sleep expert who assigns to each 30 s of the signal of a sleep stage, based on the visual inspection of signals such as electroencephalograms (EEGs), electrooculograms (EOGs), electrocardiograms, and electromyograms (EMGs). We introduce here the first deep learning approach for sleep stage classification that learns end-to-end without computing spectrograms or extracting handcrafted features, that exploits all multivariate and multimodal polysomnography (PSG) signals (EEG, EMG, and EOG), and that can exploit the temporal context of each 30-s window of data. For each modality, the first layer learns linear spatial filters that exploit the array of sensors to increase the signal-to-noise ratio, and the last layer feeds the learnt representation to a softmax classifier. Our model is compared to alternative automatic approaches based on convolutional networks or decisions trees. Results obtained on 61 publicly available PSG records with up to 20 EEG channels demonstrate that our network architecture yields the state-of-the-art performance. Our study reveals a number of insights on the spatiotemporal distribution of the signal of interest: a good tradeoff for optimal classification performance measured with balanced accuracy is to use 6 EEG with 2 EOG (left and right) and 3 EMG chin channels. Also exploiting 1 min of data before and after each data segment offers the strongest improvement when a limited number of channels are available. As sleep experts, our system exploits the multivariate and multimodal nature of PSG signals in order to deliver the state-of-the-art classification performance with a small computational cost.","","","10.1109/TNSRE.2018.2813138","French Association Nationale de la Recherche et de la Technologie; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8307462","Sleep stage classification;multivariate time series;deep learning;spatio-temporal data;transfer learning;EEG;EOG;EMG","Sleep;Electroencephalography;Electromyography;Electrooculography;Feature extraction;Machine learning;Time series analysis","decision trees;electroencephalography;electromyography;electro-oculography;feature extraction;learning (artificial intelligence);medical disorders;medical signal processing;signal classification;sleep;spatial filters;time series","temporal sleep stage classification;multimodal time series;sleep disorders;sleep expert;electrocardiograms;deep learning approach;signal-to-noise ratio;multivariate nature;multimodal nature;PSG signals;state-of-the-art classification performance;EMG chin channels;electroencephalograms;electrooculograms;electromyograms;handcrafted features;multimodal polysomnography signal;linear spatial filters;softmax classifier;decisions trees;convolutional networks","Algorithms;Computer Systems;Decision Trees;Deep Learning;Electroencephalography;Electromyography;Electrooculography;Expert Systems;Humans;Multivariate Analysis;Polysomnography;Signal Processing, Computer-Assisted;Sleep Stages","27","46","","","","","IEEE","IEEE Journals"
"Sparse Simultaneous Recurrent Deep Learning for Robust Facial Expression Recognition","M. Alam; L. S. Vidyaratne; K. M. Iftekharuddin","Department of Electrical and Computer Engineering, Vision Laboratory, Old Dominion University, Norfolk, VA, USA; Department of Electrical and Computer Engineering, Vision Laboratory, Old Dominion University, Norfolk, VA, USA; Department of Electrical and Computer Engineering, Vision Laboratory, Old Dominion University, Norfolk, VA, USA","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","10","4905","4916","Facial expression recognition is a challenging task that involves detection and interpretation of complex and subtle changes in facial muscles. Recent advances in feed-forward deep neural networks (DNNs) have offered improved object recognition performance. Sparse feature learning in feed-forward DNN models offers further improvement in performance when compared to the earlier handcrafted techniques. However, the depth of the feed-forward DNNs and the computational complexity of the models increase proportional to the challenges posed by the facial expression recognition problem. The feed-forward DNN architectures do not exploit another important learning paradigm, known as recurrency, which is ubiquitous in the human visual system. Consequently, this paper proposes a novel biologically relevant sparse-deep simultaneous recurrent network (S-DSRN) for robust facial expression recognition. The feature sparsity is obtained by adopting dropout learning in the proposed DSRN as opposed to usual handcrafting of additional penalty terms for the sparse representation of data. Theoretical analysis of S-DSRN shows that the dropout learning offers desirable properties such as sparsity, and prevents the model from overfitting. Experimental results also suggest that the proposed method yields better performance accuracy, requires reduced number of parameters, and offers reduced computational complexity than that of the previously reported state-of-the-art feed-forward DNNs using two of the most widely used publicly available facial expression data sets. Furthermore, we show that by combining the proposed neural architecture with a state-of-the-art metric learning technique significantly improves the overall recognition performance. Finally, a graphical processing unit (GPU)-based implementation of S-DSRN is obtained for real-time applications.","","","10.1109/TNNLS.2017.2776248","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8248664","Deep feed-forward network;dropout learning;graphical processing unit (GPU) acceleration;metric learning;simultaneous recurrent network (SRN);sparse feature learning","Measurement;Face recognition;Training;Feature extraction;Computer architecture;Robustness","computational complexity;emotion recognition;face recognition;feedforward neural nets;graphics processing units;learning (artificial intelligence);muscle;object detection;object recognition;recurrent neural nets","computational complexity;S-DSRN;robust facial expression recognition;facial muscles;feed-forward deep neural networks;object recognition performance;feed-forward DNN models;sparse-deep simultaneous recurrent network;dropout learning;facial expression data sets;handcrafted techniques;sparse simultaneous recurrent deep learning;human visual system;feature sparsity;graphical processing unit;GPU","","2","60","","","","","IEEE","IEEE Journals"
"Deep-learning-assisted network orchestration for on-demand and cost-effective VNF service chaining in inter-DC elastic optical networks","B. Li; W. Lu; S. Liu; Z. Zhu","School of Information Science and Technology, University of Science and Technology of China, Hefei, Anhui 230027, China; School of Information Science and Technology, University of Science and Technology of China, Hefei, Anhui 230027, China; School of Information Science and Technology, University of Science and Technology of China, Hefei, Anhui 230027, China; School of Information Science and Technology, University of Science and Technology of China, Hefei, Anhui 230027, China","IEEE/OSA Journal of Optical Communications and Networking","","2018","10","10","D29","D41","This work addresses the relatively long setup latency and complicated network control and management caused by on-demand virtual network function service chain (vNF-SC) provisioning in inter-datacenter elastic optical networks. We first design a provisioning framework with resource pre-deployment to resolve the aforementioned challenge. Specifically, the framework is designed as a discrete-time system, in which the operations are performed periodically in fixed time slots (TS). Each TS includes a pre-deployment phase followed by a provisioning phase. In the pre-deployment phase, a deep-learning (DL) model is designed to predict future vNF-SC requests, then lightpath establishment and vNF deployment are performed accordingly to pre-deploy resources for the predicted requests. Then, the system proceeds to the provisioning phase, which collects dynamic vNF-SC requests from clients and serves them in real-time by steering their traffic through the required vNFs in sequence. In order to forecast the high-dimensional data of future vNF-SC requests accurately, we design our DL model based on the long/short-term memory-based neural network and develop an effective training scheme for it. Then, the provisioning framework and DL model are optimized from several perspectives. We evaluate our proposed framework with simulations that leverage real traffic traces. The results indicate that our DL model achieves higher request prediction accuracy and lower blocking probability than two benchmarks that also predict vNF-SC requests and follow the principle of the proposed provisioning framework.","","","10.1364/JOCN.10.000D29","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8501525","Datacenter (DC); Deep learning; Elastic opticalnetworks (EONs); Long/short-term memory (LSTM);Network function virtualization (NFV); Service chaining","Optical fiber networks;Predictive models;Data models;Bandwidth;Real-time systems;Network function virtualization;Optical fibers","computer centres;learning (artificial intelligence);neural nets;optical fibre networks;probability;telecommunication traffic;virtual private networks","memory-based neural network;effective training scheme;DL model;dynamic vNF-SC requests;predicted requests;pre-deploy resources;future vNF-SC requests;deep-learning model;provisioning phase;pre-deployment phase;fixed time slots;discrete-time system;resource pre-deployment;inter-datacenter elastic optical networks;on-demand virtual network function service chain;network control;inter-DC elastic optical networks;cost-effective VNF service chaining;deep-learning-assisted network orchestration","","9","","","","","","IEEE","IEEE Journals"
"End-to-End Learning From Spectrum Data: A Deep Learning Approach for Wireless Signal Identification in Spectrum Monitoring Applications","M. Kulin; T. Kazaz; I. Moerman; E. De Poorter","Department of Information Technology, Ghent University, Ghent, Belgium; Faculty of EEMCS, Delft University of Technology, Delft, The Netherlands; Department of Information Technology, Ghent University, Ghent, Belgium; Department of Information Technology, Ghent University, Ghent, Belgium","IEEE Access","","2018","6","","18484","18501","This paper presents end-to-end learning from spectrum data-an umbrella term for new sophisticated wireless signal identification approaches in spectrum monitoring applications based on deep neural networks. End-to-end learning allows to: 1) automatically learn features directly from simple wireless signal representations, without requiring design of hand-crafted expert features like higher order cyclic moments and 2) train wireless signal classifiers in one end-to-end step which eliminates the need for complex multi-stage machine learning processing pipelines. The purpose of this paper is to present the conceptual framework of end-to-end learning for spectrum monitoring and systematically introduce a generic methodology to easily design and implement wireless signal classifiers. Furthermore, we investigate the importance of the choice of wireless data representation to various spectrum monitoring tasks. In particular, two case studies are elaborated: 1) modulation recognition and 2) wireless technology interference detection. For each case study three convolutional neural networks are evaluated for the following wireless signal representations: temporal IQ data, the amplitude/phase representation, and the frequency domain representation. From our analysis, we prove that the wireless data representation impacts the accuracy depending on the specifics and similarities of the wireless signals that need to be differentiated, with different data representations resulting in accuracy variations of up to 29%. Experimental results show that using the amplitude/phase representation for recognizing modulation formats can lead to performance improvements up to 2% and 12% for medium to high SNR compared to IQ and frequency domain data, respectively. For the task of detecting interference, frequency domain representation outperformed amplitude/phase and IQ data representation up to 20%.","","","10.1109/ACCESS.2018.2818794","EU H2020 eWINE Project; SBO SAMURAI Project; AWS Educate/GitHub Student Developer Pack; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8325299","Big spectrum data;spectrum monitoring;end-to-end learning;deep learning;convolutional neural networks;wireless signal identification;IoT","Wireless communication;Wireless sensor networks;Monitoring;Machine learning;Interference;Modulation;Pipelines","feedforward neural nets;frequency-domain analysis;learning (artificial intelligence);modulation;radio spectrum management;radiofrequency interference;signal classification;signal representation;telecommunication computing","spectrum monitoring tasks;frequency domain representation;wireless data representation;wireless signals;spectrum data;deep learning approach;spectrum monitoring applications;end-to-end learning;simple wireless signal representations;end-to-end step;complex multistage machine learning processing pipelines;wireless signal classifiers;amplitude representation;wireless signal identification approaches;deep neural networks;modulation recognition;wireless technology interference detection;convolutional neural networks;phase representation","","23","43","","","","","IEEE","IEEE Journals"
"Soft Memory Box: A Virtual Shared Memory Framework for Fast Deep Neural Network Training in Distributed High Performance Computing","S. Ahn; J. Kim; E. Lim; S. Kang","Department of Information and Communication Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; School of Software, Chung-Ang University, Seoul, South Korea; High Performance Computing Research Group, Electronics and Telecommunications Research Institute, Daejeon, South Korea; School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, South Korea","IEEE Access","","2018","6","","26493","26504","Deep learning is one of the major promising machine learning methodologies. Deep learning is widely used in various application domains, e.g., image recognition, voice recognition, and natural language processing. In order to improve learning accuracy, deep neural networks have evolved by: 1) increasing the number of layers and 2) increasing the number of parameters in massive models. This implies that distributed deep learning platforms need to evolve to: 1) deal with huge/complex deep neural networks and 2) process with high-performance computing resources for massive training data. This paper proposes a new virtual shared memory framework, called Soft Memory Box (SMB), which enables sharing the memory of remote node among distributed processes in the nodes so as to improve communication performance via parameter sharing. According to data-intensive performance evaluation results, the communication time of deep learning using the proposed SMB is 2.1 times faster than that using the massage passing interface (MPI). In addition, the communication time of the SMB-based asynchronous parameter update becomes 2-7 times faster than that using the MPI depending on deep learning models and the number of deep learning workers.","","","10.1109/ACCESS.2018.2834146","Institute for Information and Communications Technology Promotion through the Korea Government (MSIT) (Development of HPC System for Accelerating Large-Scale Deep Learning); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8356235","High performance computing;distributed computing;soft memory box;shared memory;deep neural network;distributed deep learning","Machine learning;Servers;Training;Neural networks;Computational modeling;Memory management;Training data","learning (artificial intelligence);neural nets;parallel processing;shared memory systems","distributed processes;communication performance;parameter sharing;data-intensive performance evaluation results;virtual shared memory framework;fast deep neural network training;distributed high performance computing;learning accuracy;distributed deep learning platforms;high-performance computing resources;massive training data;machine learning methodologies;Soft Memory Box","","2","28","","","","","IEEE","IEEE Journals"
"Applications of deep learning to MRI images: A survey","J. Liu; Y. Pan; M. Li; Z. Chen; L. Tang; C. Lu; J. Wang","School of Information Science and Engineering, Central South University, Changsha 410083, China; Department of Computer Science, Georgia State University, Atlanta, GA30302, USA; School of Information Science and Engineering, Central South University, Changsha 410083, China; Department of Computer Science, Georgia State University, Atlanta, GA30302, USA; School of Information Science and Engineering, Central South University, Changsha 410083, China; School of Information Science and Engineering, Central South University, Changsha 410083, China; School of Information Science and Engineering, Central South University, Changsha 410083, China","Big Data Mining and Analytics","","2018","1","1","1","18","Deep learning provides exciting solutions in many fields, such as image analysis, natural language processing, and expert system, and is seen as a key method for various future applications. On account of its non-invasive and good soft tissue contrast, in recent years, Magnetic Resonance Imaging (MRI) has been attracting increasing attention. With the development of deep learning, many innovative deep learning methods have been proposed to improve MRI image processing and analysis performance. The purpose of this article is to provide a comprehensive overview of deep learning-based MRI image processing and analysis. First, a brief introduction of deep learning and imaging modalities of MRI images is given. Then, common deep learning architectures are introduced. Next, deep learning applications of MRI images, such as image detection, image registration, image segmentation, and image classification are discussed. Subsequently, the advantages and weaknesses of several common tools are discussed, and several deep learning tools in the applications of MRI images are presented. Finally, an objective assessment of deep learning in MRI applications is presented, and future developments and trends with regard to deep learning for MRI images are addressed.","","","10.26599/BDMA.2018.9020001","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8268732","magnetic resonance imaging;deep learning;image detection;image registration;image segmentation;image classification","Machine learning;Magnetic resonance imaging;Biological neural networks;Computer architecture;Google;Feature extraction;Feedforward neural networks","biomedical MRI;image classification;image registration;image segmentation;learning (artificial intelligence);medical image processing","image segmentation;image classification;deep learning tools;Magnetic Resonance Imaging;analysis performance;imaging modalities;image detection;image registration;deep learning-based MRI image processing;deep learning-based MRI image analysis;deep learning architectures","","4","","","","","","TUP","TUP Journals"
"Semisupervised Deep Reinforcement Learning in Support of IoT and Smart City Services","M. Mohammadi; A. Al-Fuqaha; M. Guizani; J. Oh","Department of Computer Science, Western Michigan University, Kalamazoo, MI, USA; Department of Computer Science, Western Michigan University, Kalamazoo, MI, USA; Department of Electrical and Computer Engineering, University of Idaho, Moscow, ID, USA; Department of Civil and Construction Engineering, Western Michigan University, Kalamazoo, MI, USA","IEEE Internet of Things Journal","","2018","5","2","624","635","Smart services are an important element of the smart cities and the Internet of Things (IoT) ecosystems where the intelligence behind the services is obtained and improved through the sensory data. Providing a large amount of training data is not always feasible; therefore, we need to consider alternative ways that incorporate unlabeled data as well. In recent years, deep reinforcement learning (DRL) has gained great success in several application domains. It is an applicable method for IoT and smart city scenarios where auto-generated data can be partially labeled by users' feedback for training purposes. In this paper, we propose a semisupervised DRL model that fits smart city applications as it consumes both labeled and unlabeled data to improve the performance and accuracy of the learning agent. The model utilizes variational autoencoders as the inference engine for generalizing optimal policies. To the best of our knowledge, the proposed model is the first investigation that extends DRL to the semisupervised paradigm. As a case study of smart city applications, we focus on smart buildings and apply the proposed model to the problem of indoor localization based on Bluetooth low energy signal strength. Indoor localization is the main component of smart city services since people spend significant time in indoor environments. Our model learns the best action policies that lead to a close estimation of the target locations with an improvement of 23% in terms of distance to the target and at least 67% more received rewards compared to the supervised DRL model.","","","10.1109/JIOT.2017.2712560","NPRP from the Qatar National Research Fund (a member of Qatar Foundation); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7945258","Bluetooth low energy indoor localization;deep learning;deep reinforcement learning (DRL);indoor positioning;Internet of Things (IoT);IoT smart services;reinforcement learning;semisupervised deep reinforcement learning;smart city","Learning (artificial intelligence);Smart cities;Hidden Markov models;Internet of Things;Games;Data models;Smart buildings","Bluetooth;indoor radio;Internet of Things;learning (artificial intelligence);smart cities","IoT;sensory data;training data;deep reinforcement learning;application domains;smart city scenarios;semisupervised DRL model;smart city applications;labeled data;unlabeled data;learning agent;smart buildings;smart city services;supervised DRL model;Internet of Things ecosystems;variational autoencoders;inference engine;indoor localization;Bluetooth low energy signal strength","","32","42","","","","","IEEE","IEEE Journals"
"Large-Scale Metric Learning: A Voyage From Shallow to Deep","M. Faraki; M. T. Harandi; F. Porikli","Research School of Engineering, Australian National University, Canberra, ACT, Australia; Research School of Engineering, Australian National University, Canberra, ACT, Australia; Research School of Engineering, Australian National University, Canberra, ACT, Australia","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","9","4339","4346","Despite its attractive properties, the performance of the recently introduced Keep It Simple and Straightforward MEtric learning (KISSME) method is greatly dependent on principal component analysis as a preprocessing step. This dependence can lead to difficulties, e.g., when the dimensionality is not meticulously set. To address this issue, we devise a unified formulation for joint dimensionality reduction and metric learning based on the KISSME algorithm. Our joint formulation is expressed as an optimization problem on the Grassmann manifold, and hence enjoys the properties of Riemannian optimization techniques. Following the success of deep learning in recent years, we also devise end-to-end learning of a generic deep network for metric learning using our derivation.","","","10.1109/TNNLS.2017.2761773","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8098562","Deep metric learning;dimensionality reduction;Mahalanobis metric learning;Riemannian geometry","Principal component analysis;Training;Optimization;Extraterrestrial measurements;Algorithm design and analysis","learning (artificial intelligence);optimisation;principal component analysis","unified formulation;joint dimensionality reduction;KISSME algorithm;joint formulation;Riemannian optimization techniques;deep learning;end-to-end learning;generic deep network;scale metric learning;principal component analysis;straightforward metric learning method;Grassmann manifold","","1","38","","","","","IEEE","IEEE Journals"
"Deep Learning in Microscopy Image Analysis: A Survey","F. Xing; Y. Xie; H. Su; F. Liu; L. Yang","Department of Biostatistics and Informatics, Colorado School of Public Health, University of Colorado Denver, Denver, CO, USA; J. Crayton Pruitt Family Department of Biomedical Engineering, University of Florida, Gainesville, FL, USA; J. Crayton Pruitt Family Department of Biomedical Engineering, University of Florida, Gainesville, FL, USA; Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA; J. Crayton Pruitt Family Department of Biomedical Engineering, University of Florida, Gainesville, FL, USA","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","10","4550","4568","Computerized microscopy image analysis plays an important role in computer aided diagnosis and prognosis. Machine learning techniques have powered many aspects of medical investigation and clinical practice. Recently, deep learning is emerging as a leading machine learning tool in computer vision and has attracted considerable attention in biomedical image analysis. In this paper, we provide a snapshot of this fast-growing field, specifically for microscopy image analysis. We briefly introduce the popular deep neural networks and summarize current deep learning achievements in various tasks, such as detection, segmentation, and classification in microscopy image analysis. In particular, we explain the architectures and the principles of convolutional neural networks, fully convolutional networks, recurrent neural networks, stacked autoencoders, and deep belief networks, and interpret their formulations or modelings for specific tasks on various microscopy images. In addition, we discuss the open challenges and the potential trends of future research in microscopy image analysis using deep learning.","","","10.1109/TNNLS.2017.2766168","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8118310","Classification;deep learning;detection;microscopy image analysis;segmentation","Microscopy;Machine learning;Image analysis;Image segmentation;Biomedical imaging;Neural networks","belief networks;computer vision;convolution;feedforward neural nets;image classification;image segmentation;learning (artificial intelligence);medical image processing;microscopy;recurrent neural nets","computer aided diagnosis;machine learning techniques;biomedical image analysis;deep belief networks;microscopy image analysis;deep neural networks;deep learning achievements;computer aided prognosis;computer vision;snapshot;image detection;image segmentation;image classification;convolutional neural networks;recurrent neural networks;stacked autoencoders","","10","207","","","","","IEEE","IEEE Journals"
"Deep EHR: A Survey of Recent Advances in Deep Learning Techniques for Electronic Health Record (EHR) Analysis","B. Shickel; P. J. Tighe; A. Bihorac; P. Rashidi","Department of Computer and Information Science, University of Florida, Gainesville, FL, USA; Department of Anesthesiology, College of Medicine, University of Florida, Gainesville, FL, USA; Department of Nephrology, College of Medicine, University of Florida, Gainesville, FL, USA; J. Crayton Pruitt Department of Biomedical Engineering, University of Florida, Gainesville, FL, USA","IEEE Journal of Biomedical and Health Informatics","","2018","22","5","1589","1604","The past decade has seen an explosion in the amount of digital information stored in electronic health records (EHRs). While primarily designed for archiving patient information and performing administrative healthcare tasks like billing, many researchers have found secondary use of these records for various clinical informatics applications. Over the same period, the machine learning community has seen widespread advances in the field of deep learning. In this review, we survey the current research on applying deep learning to clinical tasks based on EHR data, where we find a variety of deep learning techniques and frameworks being applied to several types of clinical applications including information extraction, representation learning, outcome prediction, phenotyping, and deidentification. We identify several limitations of current research involving topics such as model interpretability, data heterogeneity, and lack of universal benchmarks. We conclude by summarizing the state of the field and identifying avenues of future deep EHR research.","","","10.1109/JBHI.2017.2767063","Division of Industrial Innovation and Partnerships; National Institute of General Medical Sciences; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8086133","Clinical informatics;deep learning;electronic health records;machine learning;survey","Machine learning;Electronic medical records;Medical diagnostic imaging;Informatics;Hospitals","electronic health records;health care;learning (artificial intelligence)","deep learning techniques;digital information;patient information;clinical informatics applications;machine learning community;EHR data;information extraction;electronic health record analysis;administrative healthcare tasks","","25","63","","","","","IEEE","IEEE Journals"
"Machine Learning and Deep Learning Methods for Cybersecurity","Y. Xin; L. Kong; Z. Liu; Y. Chen; Y. Li; H. Zhu; M. Gao; H. Hou; C. Wang","Centre of Information Security, Beijing University of Posts and Telecommunications, Beijing, China; School of Information Science and Engineering, Shandong University, Jinan, China; Guizhou Provincial Key Laboratory of Public Big Data, Guizhou University, Guiyang, China; Guizhou Provincial Key Laboratory of Public Big Data, Guizhou University, Guiyang, China; Centre of Information Security, Beijing University of Posts and Telecommunications, Beijing, China; Centre of Information Security, Beijing University of Posts and Telecommunications, Beijing, China; Centre of Information Security, Beijing University of Posts and Telecommunications, Beijing, China; Centre of Information Security, Beijing University of Posts and Telecommunications, Beijing, China; China Changfeng Science Technology Industry Group Corporation, Beijing, China","IEEE Access","","2018","6","","35365","35381","With the development of the Internet, cyber-attacks are changing rapidly and the cyber security situation is not optimistic. This survey report describes key literature surveys on machine learning (ML) and deep learning (DL) methods for network analysis of intrusion detection and provides a brief tutorial description of each ML/DL method. Papers representing each method were indexed, read, and summarized based on their temporal or thermal correlations. Because data are so important in ML/DL methods, we describe some of the commonly used network datasets used in ML/DL, discuss the challenges of using ML/DL for cybersecurity and provide suggestions for research directions.","","","10.1109/ACCESS.2018.2836950","National Key R&D Program of China; Foundation of Guizhou Provincial Key Laboratory of Public Big Data; Key Research and Development Plan of Shandong Province; Natural Science Foundation of Shandong Province; Shandong University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8359287","Cybersecurity;intrusion detection;deep learning;machine learning","Machine learning;Intrusion detection;Feature extraction;Machine learning algorithms;Computer security","Internet;learning (artificial intelligence);security of data","cyber security situation;cyber-attacks;machine learning;ML/DL;thermal correlation;temporal correlation;intrusion detection;network analysis;deep learning","","22","78","","","","","IEEE","IEEE Journals"
"Why Deep Learning Is Changing the Way to Approach NGS Data Processing: A Review","F. Celesti; A. Celesti; J. Wan; M. Villari","Department of Biomedical and Dental Sciences and Morphological and Functional Images, University of Messina, Messina, Italy; MIFT Department, University of Messina, Messina, Italy; School of Mechanical and Automotive Engineering, South China University of Technology, Guangzhou, China; MIFT Department, University of Messina, Messina, Italy","IEEE Reviews in Biomedical Engineering","","2018","11","","68","76","Nowadays, big data analytics in genomics is an emerging research topic. In fact, the large amount of genomics data originated by emerging next-generation sequencing (NGS) techniques requires more and more fast and sophisticated algorithms. In this context, deep learning is re-emerging as a possible approach to speed up the DNA sequencing process. In this review, we specifically discuss such a trend. In particular, starting from an analysis of the interest of the Internet community in both NGS and deep learning, we present a taxonomic analysis highlighting the major software solutions based on deep learning algorithms available for each specific NGS application field. We discuss future challenges in the perspective of cloud computing services aimed at deep learning based solutions for NGS.","","","10.1109/RBME.2018.2825987","Italian Healthcare Ministry; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8336918","Big data;biotechnology;deep learning;genomics;next-generation sequencing (NGS)","Machine learning;Bioinformatics;Sequential analysis;Genomics;DNA;Big Data;Market research","Big Data;biology computing;cloud computing;data analysis;DNA;genomics;learning (artificial intelligence)","approach NGS data processing;big data analytics;emerging research topic;genomics data;next-generation sequencing techniques;fast algorithms;sophisticated algorithms;possible approach;DNA sequencing process;deep learning algorithms;specific NGS application field","Algorithms;Animals;Big Data;Deep Learning;Genomics;High-Throughput Nucleotide Sequencing;Humans;Internet;Sequence Analysis, DNA;Software","","52","","","","","IEEE","IEEE Journals"
"Deep Learning of Semisupervised Process Data With Hierarchical Extreme Learning Machine and Soft Sensor Application","L. Yao; Z. Ge","Department of Control Science and Engineering, Zhejiang University, Hangzhou, China; Department of Control Science and Engineering, Zhejiang University, Hangzhou, China","IEEE Transactions on Industrial Electronics","","2018","65","2","1490","1498","Data-driven soft sensors have been widely utilized in industrial processes to estimate the critical quality variables which are intractable to directly measure online through physical devices. Due to the low sampling rate of quality variables, most of the soft sensors are developed on small number of labeled samples and the large number of unlabeled process data is discarded. The loss of information greatly limits the improvement of quality prediction accuracy. One of the main issues of data-driven soft sensor is to furthest exploit the information contained in all available process data. This paper proposes a semisupervised deep learning model for soft sensor development based on the hierarchical extreme learning machine (HELM). First, the deep network structure of autoencoders is implemented for unsupervised feature extraction with all the process samples. Then, extreme learning machine is utilized for regression through appending the quality variable. Meanwhile, the manifold regularization method is introduced for semisupervised model training. The new method can not only deeply extract the information that the data contains, but learn more from the extra unlabeled samples as well. The proposed semisupervised HELM method is applied in a high-low transformer to estimate the carbon monoxide content, which shows a significant improvement of the prediction accuracy, compared to traditional methods.","","","10.1109/TIE.2017.2733448","National Natural Science Foundation of China (NSFC); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8002611","Deep learning (DL);extreme learning machine (ELM);manifold regularization;semisupervised learning;soft sensor","Feature extraction;Training;Machine learning;Artificial neural networks;Neurons;Process control;Biological neural networks","feature extraction;feedforward neural nets;learning (artificial intelligence);production engineering computing;quality control;regression analysis","data-driven soft sensors;unsupervised feature extraction;regression;manifold regularization method;semisupervised HELM method;high-low transformer;carbon monoxide content;soft sensor application;semisupervised process data;semisupervised model training;hierarchical extreme learning machine;soft sensor development;semisupervised deep learning model;quality prediction accuracy;unlabeled process data","","21","26","Traditional","","","","IEEE","IEEE Journals"
"Deep Discrete Supervised Hashing","Q. Jiang; X. Cui; W. Li","Department of Computer Science and Technology, National Key Laboratory for Novel Software Technology, Collaborative Innovation Center of Novel Software Technology and Industrialization, Nanjing University, Nanjing, China; Department of Computer Science and Technology, National Key Laboratory for Novel Software Technology, Collaborative Innovation Center of Novel Software Technology and Industrialization, Nanjing University, Nanjing, China; Department of Computer Science and Technology, National Key Laboratory for Novel Software Technology, Collaborative Innovation Center of Novel Software Technology and Industrialization, Nanjing University, Nanjing, China","IEEE Transactions on Image Processing","","2018","27","12","5996","6009","Hashing has been widely used for large-scale search due to its low storage cost and fast query speed. By using supervised information, supervised hashing can significantly outperform unsupervised hashing. Recently, discrete supervised hashing and feature learning based deep hashing are two representative progresses in supervised hashing. On one hand, hashing is essentially a discrete optimization problem. Hence, utilizing supervised information to directly guide discrete (binary) coding procedure can avoid sub-optimal solution and improve the accuracy. On the other hand, feature learning based deep hashing, which integrates deep feature learning and hash-code learning into an end-to-end architecture, can enhance the feedback between feature learning and hash-code learning. The key in discrete supervised hashing is to adopt supervised information to directly guide the discrete coding procedure in hashing. The key in deep hashing is to adopt the supervised information to directly guide the deep feature learning procedure. However, most deep supervised hashing methods cannot use the supervised information to directly guide both discrete (binary) coding procedure and deep feature learning procedure in the same framework. In this paper, we propose a novel deep hashing method, called deep discrete supervised hashing (DDSH). DDSH is the first deep hashing method which can utilize pairwise supervised information to directly guide both discrete coding procedure and deep feature learning procedure and thus enhance the feedback between these two important procedures. Experiments on four real datasets show that DDSH can outperform other state-of-the-art baselines, including both discrete hashing and deep hashing baselines, for image retrieval.","","","10.1109/TIP.2018.2864894","National Natural Science Foundation of China; Key Research and Development Program of Jiangsu; Tencent; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8432451","Image retrieval;deep learning;deep supervised hashing","Binary codes;Image retrieval;Deep learning;Nearest neighbor methods","binary codes;file organisation;unsupervised learning","unsupervised hashing;discrete optimization problem;discrete coding procedure;hash-code learning;pairwise supervised information;deep feature learning;deep discrete supervised hashing;DDSH","","4","53","","","","","IEEE","IEEE Journals"
"Max-Margin Deep Generative Models for (Semi-)Supervised Learning","C. Li; J. Zhu; B. Zhang","Department of Computer Science and Technology, TNList Lab, State Key Lab for Intelligent Technology and Systems, Center for Bio-Inspired Computing Research, Tsinghua University, Beijing, China; Department of Computer Science and Technology, TNList Lab, State Key Lab for Intelligent Technology and Systems, Center for Bio-Inspired Computing Research, Tsinghua University, Beijing, China; Department of Computer Science and Technology, TNList Lab, State Key Lab for Intelligent Technology and Systems, Center for Bio-Inspired Computing Research, Tsinghua University, Beijing, China","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","11","2762","2775","Deep generative models (DGMs) can effectively capture the underlying distributions of complex data by learning multilayered representations and performing inference. However, it is relatively insufficient to boost the discriminative ability of DGMs. This paper presents max-margin deep generative models (mmDGMs) and a class-conditional variant (mmDCGMs), which explore the strongly discriminative principle of max-margin learning to improve the predictive performance of DGMs in both supervised and semi-supervised learning, while retaining the generative capability. In semi-supervised learning, we use the predictions of a max-margin classifier as the missing labels instead of performing full posterior inference for efficiency; we also introduce additional max-margin and label-balance regularization terms of unlabeled data for effectiveness. We develop an efficient doubly stochastic subgradient algorithm for the piecewise linear objectives in different settings. Empirical results on various datasets demonstrate that: (1) max-margin learning can significantly improve the prediction performance of DGMs and meanwhile retain the generative ability; (2) in supervised learning, mmDGMs are competitive to the best fully discriminative networks when employing convolutional neural networks as the generative and recognition models; and (3) in semi-supervised learning, mmDCGMs can perform efficient inference and achieve state-of-the-art classification results on several benchmarks.","","","10.1109/TPAMI.2017.2766142","National Basic Research Program (973 Program) of China; NSF; Youth Top-notch Talent Support Program; Tsinghua Tiangong Institute for Intelligent Computing and the NVIDIA NVAIL Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8081757","Deep generative models;max-margin learning;variational inference;supervised and semi-supervised learning","Data models;Semisupervised learning;Predictive models;Supervised learning;Gallium nitride;Markov random fields","convolution;feedforward neural nets;gradient methods;learning (artificial intelligence);pattern classification;stochastic processes","prediction performance;DGMs;supervised learning;semisupervised learning;max-margin deep generative models;performing inference;max-margin learning;max-margin classifier;learning multilayered representations;mmDGMs;doubly stochastic subgradient algorithm;label-balance regularization terms;unlabeled data;convolutional neural networks;recognition models;fully discriminative networks","","1","65","","","","","IEEE","IEEE Journals"
"Information Dropout: Learning Optimal Representations Through Noisy Computation","A. Achille; S. Soatto","Department of Computer Science, University of California, Los Angeles, CA; Department of Computer Science, University of California, Los Angeles, CA","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","12","2897","2905","The cross-entropy loss commonly used in deep learning is closely related to the defining properties of optimal representations, but does not enforce some of the key properties. We show that this can be solved by adding a regularization term, which is in turn related to injecting multiplicative noise in the activations of a Deep Neural Network, a special case of which is the common practice of dropout. We show that our regularized loss function can be efficiently minimized using Information Dropout, a generalization of dropout rooted in information theoretic principles that automatically adapts to the data and can better exploit architectures of limited capacity. When the task is the reconstruction of the input, we show that our loss function yields a Variational Autoencoder as a special case, thus providing a link between representation learning, information theory and variational inference. Finally, we prove that we can promote the creation of optimal disentangled representations simply by enforcing a factorized prior, a fact that has been observed empirically in recent work. Our experiments validate the theoretical intuitions behind our method, and we find that Information Dropout achieves a comparable or better generalization performance than binary dropout, especially on smaller models, since it can automatically adapt the noise to the structure of the network, as well as to the test sample.","","","10.1109/TPAMI.2017.2784440","Office of Naval Research; Air Force Office of Scientific Research; Army Research Office; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8253482","Representation learning;deep learning;information bottleneck;nuisances;invariants;minimality","Neural networks;Deep learning;Bayes methods;Machine learning;Information theory;Noise measurement;Learning systems","entropy;image processing;learning (artificial intelligence);neural nets;statistical analysis","noisy computation;cross-entropy loss;deep learning;injecting multiplicative noise;regularized loss function;representation learning;information theory;optimal disentangled representations;binary dropout;deep neural network;information dropout;learning optimal representations;variational autoencoder;variational inference","","1","27","","","","","IEEE","IEEE Journals"
"Learning to Navigate Through Complex Dynamic Environment With Modular Deep Reinforcement Learning","Y. Wang; H. He; C. Sun","School of Automation, Southeast University, Nanjing, China; Department of Electrical, Computer, and Biomedical Engineering, University of Rhode Island, Kingston, RI, USA; School of Automation, Southeast University, Nanjing, China","IEEE Transactions on Games","","2018","10","4","400","412","In this paper, we propose an end-to-end modular reinforcement learning architecture for a navigation task in complex dynamic environments with rapidly moving obstacles. In this architecture, the main task is divided into two subtasks: local obstacle avoidance and global navigation. For obstacle avoidance, we develop a two-stream Q-network, which processes spatial and temporal information separately and generates action values. The global navigation subtask is resolved by a conventional Q-network framework. An online learning network and an action scheduler are introduced to first combine two pretrained policies, and then continue exploring and optimizing until a stable policy is obtained. The two-stream Q-network obtains better performance than the conventional deep Q-learning approach in the obstacle avoidance subtask. Experiments on the main task demonstrate that the proposed architecture can efficiently avoid moving obstacles and complete the navigation task at a high success rate. The modular architecture enables parallel training and also demonstrates good generalization capability in different environments.","","","10.1109/TG.2018.2849942","National Natural Science Foundation of China; National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8395072","Deep learning;navigation;reinforcement learning;two-stream Q-network","Navigation;Task analysis;Robot sensing systems;Collision avoidance;Training","collision avoidance;control engineering computing;learning (artificial intelligence);mobile robots","modular deep reinforcement learning;end-to-end modular reinforcement learning architecture;local obstacle avoidance;two-stream Q-network;spatial information;temporal information;global navigation subtask;online learning network;action scheduler;obstacle avoidance subtask;modular architecture;parallel training;deep Q-learning approach","","3","56","","","","","IEEE","IEEE Journals"
"Predicting the Absorption Potential of Chemical Compounds Through a Deep Learning Approach","M. Shin; D. Jang; H. Nam; K. H. Lee; D. Lee","Department of Bio and Brain Engineering, Korea Advanced Institue of Science and Technology (KAIST), Dajeon, Korea; Department of Bio and Brain Engineering, Korea Advanced Institue of Science and Technology (KAIST), Dajeon, Korea; School of Information and Communications, Gwangju Institute of Science and Technology (GIST), Gwangju, Korea; Department of Bio and Brain Engineering, Korea Advanced Institue of Science and Technology (KAIST), Dajeon, Korea; Department of Bio and Brain Engineering, Korea Advanced Institue of Science and Technology (KAIST), Dajeon, Korea","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2018","15","2","432","440","The human colorectal carcinoma cell line (Caco-2) is a commonly used in-vitro test that predicts the absorption potential of orally administered drugs. In-silico prediction methods, based on the Caco-2 assay data, may increase the effectiveness of the high-throughput screening of new drug candidates. However, previously developed in-silico models that predict the Caco-2 cellular permeability of chemical compounds use handcrafted features that may be dataset-specific and induce over-fitting problems. Deep Neural Network (DNN) generates high-level features based on non-linear transformations for raw features, which provides high discriminant power and, therefore, creates a good generalized model. We present a DNN-based binary Caco-2 permeability classifier. Our model was constructed based on 663 chemical compounds with in-vitro Caco-2 apparent permeability data. Two hundred nine molecular descriptors are used for generating the high-level features during DNN model generation. Dropout regularization is applied to solve the over-fitting problem and the non-linear activation. The Rectified Linear Unit (ReLU) is adopted to reduce the vanishing gradient problem. The results demonstrate that the high-level features generated by the DNN are more robust than handcrafted features for predicting the cellular permeability of structurally diverse chemical compounds in Caco-2 cell lines.","","","10.1109/TCBB.2016.2535233","Bio-Synergy Research; Ministry of Science, ICT and Future Planning; National Research Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7420679","Machine learning;deep learning;neural nets;Caco-2 permeability;absorption prediction","Permeability;Compounds;Chemical compounds;Drugs;Chemicals;Absorption;Predictive models","bioinformatics;cancer;cellular biophysics;drugs;learning (artificial intelligence);neural nets;pattern classification;permeability","generalized model;chemical compounds;absorption potential prediction;high-throughput screening;DNN-based binary Caco-2 permeability classifier;dropout regularization;Caco-2 assay data;In-silico prediction methods;orally administered drugs;in-vitro test;human colorectal carcinoma cell line;deep learning approach;Caco-2 cell lines;structurally diverse chemical compounds;nonlinear activation;DNN model generation;in-vitro Caco-2 apparent permeability data;raw features;nonlinear transformations;high-level features;Deep Neural Network;over-fitting problem;handcrafted features;Caco-2 cellular permeability;drug candidates","Absorption, Physicochemical;Caco-2 Cells;Cell Membrane Permeability;Computational Biology;Computer Simulation;Deep Learning;Drug Evaluation, Preclinical;Humans;Models, Statistical;Pharmaceutical Preparations","2","40","","","","","IEEE","IEEE Journals"
"Citywide Cellular Traffic Prediction Based on Densely Connected Convolutional Neural Networks","C. Zhang; H. Zhang; D. Yuan; M. Zhang","Shandong Provincial Key Laboratory of Wireless Communication Technologies, Shandong University, Jinan, China; Shandong Provincial Key Laboratory of Wireless Communication Technologies, Shandong University, Jinan, China; Shandong Provincial Key Laboratory of Wireless Communication Technologies, Shandong University, Jinan, China; Shandong Provincial Key Laboratory of Wireless Communication Technologies, Shandong University, Jinan, China","IEEE Communications Letters","","2018","22","8","1656","1659","With accurate traffic prediction, future cellular networks can make self-management and embrace intelligent and efficient automation. This letter devotes itself to citywide cellular traffic prediction and proposes a deep learning approach to model the nonlinear dynamics of wireless traffic. By treating traffic data as images, both the spatial and temporal dependence of cell traffic are well captured utilizing densely connected convolutional neural networks. A parametric matrix based fusion scheme is further put forward to learn influence degrees of the spatial and temporal dependence. Experimental results show that the prediction performance in terms of root mean square error can be significantly improved compared with those existing algorithms. The prediction accuracy is also validated by using the data sets of Telecom Italia.","","","10.1109/LCOMM.2018.2841832","National Aerospace Science Foundation of China; National Aerospace Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8368274","Cellular traffic prediction;big data;deep learning;intelligent traffic management","Computer architecture;Microprocessors;Wireless communication;Correlation;Predictive models;Convolution;Machine learning","cellular radio;learning (artificial intelligence);mean square error methods;neural nets;telecommunication traffic","citywide cellular traffic prediction;intelligent automation;efficient automation;parametric matrix based fusion scheme;convolutional neural networks;cellular networks;deep learning","","7","13","","","","","IEEE","IEEE Journals"
"A Deep Hierarchical Reinforcement Learning Algorithm in Partially Observable Markov Decision Processes","T. P. Le; N. A. Vien; T. Chung","Computer Science and Engineering Department, Artificial Intelligence Laboratory, Kyung Hee University, Global Campus, Yongin, South Korea; EEECS/ECIT, Queen’s University Belfast, Belfast, U.K.; Computer Science and Engineering Department, Artificial Intelligence Laboratory, Kyung Hee University, Global Campus, Yongin, South Korea","IEEE Access","","2018","6","","49089","49102","In recent years, reinforcement learning (RL) has achieved remarkable success due to the growing adoption of deep learning techniques and the rapid growth of computing power. Nevertheless, it is well-known that flat reinforcement learning algorithms are often have trouble learning and are even data-efficient with respect to tasks having hierarchical structures, e.g., those consisting of multiple subtasks. Hierarchical reinforcement learning is a principled approach that can tackle such challenging tasks. On the other hand, many real-world tasks usually have only partial observability in which state measurements are often imperfect and partially observable. The problems of RL in such settings can be formulated as a partially observable Markov decision process (POMDP). In this paper, we study hierarchical RL in a POMDP in which the tasks have only partial observability and possess hierarchical properties. We propose a hierarchical deep reinforcement learning approach for learning in hierarchical POMDP. The deep hierarchical RL algorithm is proposed for domains to both MDP and POMDP learning. We evaluate the proposed algorithm using various challenging hierarchical POMDPs.","","","10.1109/ACCESS.2018.2854283","National Research Foundation of Korea; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8421749","Hierarchical deep reinforcement learning;partially observable MDP (POMDP);semi-MDP;partially observable semi-MDP (POSMDP)","Machine learning;Task analysis;Markov processes;Learning (artificial intelligence);Neural networks;Observability;Games","learning (artificial intelligence);Markov processes;observability","deep hierarchical reinforcement learning algorithm;partially observable Markov decision processes;deep learning techniques;partial observability;hierarchical POMDP;deep hierarchical RL algorithm;computing power","","4","62","","","","","IEEE","IEEE Journals"
"Deep Learning Coordinated Beamforming for Highly-Mobile Millimeter Wave Systems","A. Alkhateeb; S. Alex; P. Varkey; Y. Li; Q. Qu; D. Tujkovic","School of Electrical, Computer and Energy Engineering, Arizona State University, Tempe, AZ, USA; Facebook Inc., Menlo Park, CA, USA; Facebook Inc., Menlo Park, CA, USA; Facebook Inc., Menlo Park, CA, USA; Facebook Inc., Menlo Park, CA, USA; Facebook Inc., Menlo Park, CA, USA","IEEE Access","","2018","6","","37328","37348","Supporting high mobility in millimeter wave (mmWave) systems enables a wide range of important applications, such as vehicular communications and wireless virtual/augmented reality. Realizing this in practice, though, requires overcoming several challenges. First, the use of narrow beams and the sensitivity of mmWave signals to blockage greatly impact the coverage and reliability of highly-mobile links. Second, highly-mobile users in dense mmWave deployments need to frequently hand-off between base stations (BSs), which is associated with critical control and latency overhead. Furthermore, identifying the optimal beamforming vectors in large antenna array mmWave systems requires considerable training overhead, which significantly affects the efficiency of these mobile systems. In this paper, a novel integrated machine learning and coordinated beamforming solution is developed to overcome these challenges and enable highly-mobile mmWave applications. In the proposed solution, a number of distributed yet coordinating BSs simultaneously serve a mobile user. This user ideally needs to transmit only one uplink training pilot sequence that will be jointly received at the coordinating BSs using omni or quasi-omni beam patterns. These received signals draw a defining signature not only for the user location, but also for its interaction with the surrounding environment. The developed solution then leverages a deep learning model that learns how to use these signatures to predict the beamforming vectors at the BSs. This renders a comprehensive solution that supports highly mobile mmWave applications with reliable coverage, low latency, and negligible training overhead. Extensive simulation results based on accurate ray-tracing, show that the proposed deep-learning coordinated beamforming strategy approaches the achievable rate of the genie-aided solution that knows the optimal beamforming vectors with no training overhead. Compared with traditional beamforming solutions, the results show that the proposed deep learning-based strategy attains higher rates, especially in high-mobility large-array regimes.","","","10.1109/ACCESS.2018.2850226","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8395149","Millimeter wave;deep learning;machine learning;beamforming;channel estimation;vehicular communications;wireless virtual/augmented reality","Array signal processing;Training;Machine learning;Channel estimation;Radio frequency;Sensors;Wireless communication","array signal processing;learning (artificial intelligence);millimetre wave antenna arrays;millimetre wave communication;mobile radio;ray tracing;telecommunication computing;telecommunication network reliability","highly-mobile millimeter wave systems;highly-mobile users;optimal beamforming vectors;mobile user;deep learning model;negligible training overhead;deep learning-based strategy;high-mobility large-array regimes;MM-wave signals;dense MM-wave deployments;antenna array MM-wave systems;highly-mobile MM-wave applications;highly-mobile link reliability;integrated machine learning and coordinated beamforming solution;quasiomni beam patterns;ray tracing;vehicular communications;millimeter wave systems;integrated machine learning;uplink training pilot sequence","","33","52","","","","","IEEE","IEEE Journals"
"A New Deep-Q-Learning-Based Transmission Scheduling Mechanism for the Cognitive Internet of Things","J. Zhu; Y. Song; D. Jiang; H. Song","Chongqing Key Laboratory of Mobile Communications Technology, Chongqing University of Posts and Telecommunications, Chongqing, China; Chongqing Key Laboratory of Mobile Communications Technology, Chongqing University of Posts and Telecommunications, Chongqing, China; School of Astronautics and Aeronautic, University of Electronic Science and Technology of China, Chengdu, China; Department of Electrical, Computer, Software, and Systems Engineering, Embry–Riddle Aeronautical University, Daytona Beach, FL, USA","IEEE Internet of Things Journal","","2018","5","4","2375","2385","Cognitive networks (CNs) are one of the key enablers for the Internet of Things (IoT), where CNs will play an important role in the future Internet in several application scenarios, such as healthcare, agriculture, environment monitoring, and smart metering. However, the current low packet transmission efficiency of IoT faces a problem of the crowded spectrum for the rapidly increasing popularities of various wireless applications. Hence, the IoT that uses the advantages of cognitive technology, namely the cognitive radio-based IoT (CIoT), is a promising solution for IoT applications. A major challenge in CIoT is the packet transmission efficiency using CNs. Therefore, a new Q-learning-based transmission scheduling mechanism using deep learning for the CIoT is proposed to solve the problem of how to achieve the appropriate strategy to transmit packets of different buffers through multiple channels to maximize the system throughput. A Markov decision process-based model is formulated to describe the state transformation of the system. A relay is used to transmit packets to the sink for the other nodes. To maximize the system utility in different system states, the reinforcement learning method, i.e., the Q learning algorithm, is introduced to help the relay to find the optimal strategy. In addition, the stacked auto-encoders deep learning model is used to establish the mapping between the state and the action to accelerate the solution of the problem. Finally, the experimental results demonstrate that the new action selection method can converge after a certain number of iterations. Compared with other algorithms, the proposed method can better transmit packets with less power consumption and packet loss.","","","10.1109/JIOT.2017.2759728","National Natural Science Foundation of China; Key Project of Chinese Ministry of Education; Chongqing Science and Technology Commission; Science and Technology Research Project of Chongqing Education Commission; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8057766","Cognitive networks (CNs);deep learning;Internet of Things (IoT);Markov decision process;Q learning (QL)","Internet of Things;Relays;Wireless sensor networks;Throughput;Bit error rate;Scheduling;Machine learning","cognitive radio;Internet of Things;learning (artificial intelligence);scheduling","cognitive networks;crowded spectrum;wireless applications;cognitive technology;cognitive radio-based IoT;CIoT;IoT applications;system throughput;Markov decision process-based model;system utility;reinforcement learning method;Q learning algorithm;stacked auto-encoders deep learning model;power consumption;packet loss;cognitive Internet of Things;CN;deep-Q-learning-based transmission scheduling mechanism;packet transmission efficiency","","28","54","","","","","IEEE","IEEE Journals"
"Action-Driven Visual Object Tracking With Deep Reinforcement Learning","S. Yun; J. Choi; Y. Yoo; K. Yun; J. Y. Choi","Department of Electrical and Computer Engineering, Automation and Systems Research Institute, Seoul National University, Seoul, South Korea; Department of Electrical and Computer Engineering, Automation and Systems Research Institute, Seoul National University, Seoul, South Korea; CLOVA AI Research, Naver, Seoungnam-si, South Korea; Visual Intelligence Research Group, SW Contents Laboratory, Electronics and Telecommunications Research Institute, Daejeon, South Korea; Department of Electrical and Computer Engineering, Automation and Systems Research Institute, Seoul National University, Seoul, South Korea","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","6","2239","2252","In this paper, we propose an efficient visual tracker, which directly captures a bounding box containing the target object in a video by means of sequential actions learned using deep neural networks. The proposed deep neural network to control tracking actions is pretrained using various training video sequences and fine-tuned during actual tracking for online adaptation to a change of target and background. The pretraining is done by utilizing deep reinforcement learning (RL) as well as supervised learning. The use of RL enables even partially labeled data to be successfully utilized for semisupervised learning. Through the evaluation of the object tracking benchmark data set, the proposed tracker is validated to achieve a competitive performance at three times the speed of existing deep network-based trackers. The fast version of the proposed method, which operates in real time on graphics processing unit, outperforms the state-of-the-art real-time trackers with an accuracy improvement of more than 8%.","","","10.1109/TNNLS.2018.2801826","ICT R&D program of MSIP/IITP (Development of Predictive Visual Intelligence Technology); ICT R&D program of MSIP/IITP (Development of High Performance Visual BigData Discovery Platform); SNU-Samsung Smart Campus Research Center at Seoul National University; Brain Korea 21 Plus Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8306309","Deep neural network;reinforcement learning (RL);visual tracking","Target tracking;Visualization;Training;Object tracking;Video sequences;Search problems","image sequences;learning (artificial intelligence);neural nets;object tracking","deep reinforcement learning;bounding box;deep neural network;training video sequences;RL;supervised learning;sequential actions learning;action-driven visual object tracking;fine-tuning;online adaptation;object tracking benchmark data set;deep network-based trackers;graphics processing unit","","1","53","","","","","IEEE","IEEE Journals"
"Deep Spatiality: Unsupervised Learning of Spatially-Enhanced Global and Local 3D Features by Deep Neural Network With Coupled Softmax","Z. Han; Z. Liu; C. Vong; Y. Liu; S. Bu; J. Han; C. L. P. Chen","School of Software, Tsinghua University, Beijing, China; Shool of Aeronautics, Northwestern Polytechnical University, Xi’an, China; Department of Computer and Information Science, University of Macau, Macau, China; School of Software, Tsinghua University, Beijing, China; Shool of Aeronautics, Northwestern Polytechnical University, Xi’an, China; School of Automation, Northwestern Polytechnical University, Xi’an, China; Faculty of Science and Technology, University of Macau, Macau, China","IEEE Transactions on Image Processing","","2018","27","6","3049","3063","The discriminability of the bag-of-words representations can be increased via encoding the spatial relationship among virtual words on 3D shapes. However, this encoding task involves several issues, including arbitrary mesh resolutions, irregular vertex topology, orientation ambiguity on 3D surface, invariance to rigid, and non-rigid shape transformations. To address these issues, a novel unsupervised spatial learning framework based on deep neural network, deep spatiality (DS), is proposed. Specifically, DS employs two novel components: spatial context extractor and deep context learner. Spatial context extractor extracts the spatial relationship among virtual words in a local region into a raw spatial representation. Along a consistent circular direction, a directed circular graph is constructed to encode relative positions between pairwise virtual words in each face ring into a relative spatial matrix. By decomposing each relative spatial matrix using singular value decomposition, the raw spatial representation is formed, from which deep context learner conducts unsupervised learning of the global and local features. Deep context learner is a deep neural network with a novel model structure to adapt the proposed coupled softmax layer, which encodes not only the discriminative information among local regions but also the one among global shapes. Experimental results show that DS outperforms state-of-the-art methods.","","","10.1109/TIP.2018.2816821","National Natural Science Foundation of China; NWPU Basic Research Fund; University of Macau; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8318683","Deep spatial;spatially-enhanced 3D features;directed circular graph;coupled softmax","Three-dimensional displays;Shape;Face;Feature extraction;Neural networks;Image coding;Spatial resolution","feature extraction;graph theory;image representation;learning (artificial intelligence);neural nets;singular value decomposition;unsupervised learning","deep spatiality;DS;spatial context extractor;raw spatial representation;pairwise virtual words;relative spatial matrix;deep neural network;bag-of-words representations;nonrigid shape transformations;spatial learning framework;deep context learner;unsupervised learning;spatially-enhanced global 3D features;spatially-enhanced local 3D features;coupled softmax;arbitrary mesh resolutions;irregular vertex topology;directed circular graph;singular value decomposition","","3","39","","","","","IEEE","IEEE Journals"
"Learning Temporal Dynamics for Video Super-Resolution: A Deep Learning Approach","D. Liu; Z. Wang; Y. Fan; X. Liu; Z. Wang; S. Chang; X. Wang; T. S. Huang","Department of Electrical and Computer Engineering, Beckman Institute Advanced Science and Technology, University of Illinois at Urbana–Champaign, Urbana, IL, USA; Adobe Systems Inc., San Jose, CA, USA; Department of Electrical and Computer Engineering, Beckman Institute Advanced Science and Technology, University of Illinois at Urbana–Champaign, Urbana, IL, USA; Facebook Inc., San Francisco, CA, USA; Department of Computer Science and Engineering, Texas A&M University, College Station, TX, USA; IBM Thomas J. Watson Research Center, Yorktown Heights, NY, USA; Department of Electrical and Computer Engineering, Beckman Institute Advanced Science and Technology, University of Illinois at Urbana–Champaign, Urbana, IL, USA; Department of Electrical and Computer Engineering, Beckman Institute Advanced Science and Technology, University of Illinois at Urbana–Champaign, Urbana, IL, USA","IEEE Transactions on Image Processing","","2018","27","7","3432","3445","Video super-resolution (SR) aims at estimating a high-resolution video sequence from a low-resolution (LR) one. Given that the deep learning has been successfully applied to the task of single image SR, which demonstrates the strong capability of neural networks for modeling spatial relation within one single image, the key challenge to conduct video SR is how to efficiently and effectively exploit the temporal dependence among consecutive LR frames other than the spatial relation. However, this remains challenging because the complex motion is difficult to model and can bring detrimental effects if not handled properly. We tackle the problem of learning temporal dynamics from two aspects. First, we propose a temporal adaptive neural network that can adaptively determine the optimal scale of temporal dependence. Inspired by the inception module in GoogLeNet [1], filters of various temporal scales are applied to the input LR sequence before their responses are adaptively aggregated, in order to fully exploit the temporal relation among the consecutive LR frames. Second, we decrease the complexity of motion among neighboring frames using a spatial alignment network that can be end-to-end trained with the temporal adaptive network and has the merit of increasing the robustness to complex motion and the efficiency compared with the competing image alignment methods. We provide a comprehensive evaluation of the temporal adaptation and the spatial alignment modules. We show that the temporal adaptive design considerably improves the SR quality over its plain counterparts, and the spatial alignment network is able to attain comparable SR performance with the sophisticated optical flow-based approach, but requires a much less running time. Overall, our proposed model with learned temporal dynamics is shown to achieve the state-of-the-art SR results in terms of not only spatial consistency but also the temporal coherence on public video data sets. More information can be found in http://www.ifp.illinois.edu/~dingliu2/videoSR/.","","","10.1109/TIP.2018.2820807","U.S. Army Research Office; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8328914","Super-resolution;deep learning;deep neural networks","Neural networks;Adaptive systems;Motion compensation;Machine learning;Optical imaging;Image resolution;Adaptation models","image resolution;image sequences;learning (artificial intelligence);motion estimation;neural nets;object detection;video signal processing","input LR sequence;temporal relation;consecutive LR frames;neighboring frames;spatial alignment network;temporal adaptive network;complex motion;spatial alignment modules;temporal adaptive design;SR quality;comparable SR performance;learned temporal dynamics;spatial consistency;temporal coherence;public video data sets;video super-resolution;deep learning approach;high-resolution video sequence;single image SR;video SR;temporal dependence;temporal adaptive neural network;temporal scales;image alignment methods;spatial relation modeling;spatial relation modeling;optical flow-based approach","","10","40","","","","","IEEE","IEEE Journals"
"Learning Multiscale Deep Features for High-Resolution Satellite Image Scene Classification","Q. Liu; R. Hang; H. Song; Z. Li","Jiangsu Key Laboratory of Big Data Analysis Technology, School of Information and Control, Nanjing University of Information Science and Technology, Nanjing, China; Jiangsu Key Laboratory of Big Data Analysis Technology, School of Information and Control, Nanjing University of Information Science and Technology, Nanjing, China; Jiangsu Key Laboratory of Big Data Analysis Technology, School of Information and Control, Nanjing University of Information Science and Technology, Nanjing, China; Jiangsu Key Laboratory of Big Data Analysis Technology, School of Information and Control, Nanjing University of Information Science and Technology, Nanjing, China","IEEE Transactions on Geoscience and Remote Sensing","","2018","56","1","117","126","In this paper, we propose a multiscale deep feature learning method for high-resolution satellite image scene classification. Specifically, we first warp the original satellite image into multiple different scales. The images in each scale are employed to train a deep convolutional neural network (DCNN). However, simultaneously training multiple DCNNs is time-consuming. To address this issue, we explore DCNN with spatial pyramid pooling (SPP-net). Since different SPP-nets have the same number of parameters, which share the identical initial values, and only fine-tuning the parameters in fully connected layers ensures the effectiveness of each network, thereby greatly accelerating the training process. Then, the multiscale satellite images are fed into their corresponding SPP-nets, respectively, to extract multiscale deep features. Finally, a multiple kernel learning method is developed to automatically learn the optimal combination of such features. Experiments on two difficult data sets show that the proposed method achieves favorable performance compared with other state-of-the-art methods.","","","10.1109/TGRS.2017.2743243","Natural Science Foundation of China; Natural Science Foundation of Jiangsu Province, China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8036413","Deep convolutional neural networks (DCNNs);feature fusion;multiple kernel learning (MKL);multiscale deep features;satellite image classification;spatial pyramid pooling","Satellites;Feature extraction;Training;Visualization;Histograms;Spatial resolution;Learning systems","feature extraction;feedforward neural nets;geophysical image processing;image classification;image representation;learning (artificial intelligence);object detection","multiscale deep features;high-resolution satellite image scene classification;multiscale deep feature learning method;original satellite image;deep convolutional neural network;multiscale satellite images;multiple kernel learning method;SPP-nets;DCNN","","21","48","","","","","IEEE","IEEE Journals"
"Diversity-Promoting Deep Structural Metric Learning for Remote Sensing Scene Classification","Z. Gong; P. Zhong; Y. Yu; W. Hu","College of Electrical Science and Engineering, National University of Defense Technology, Changsha, China; College of Electrical Science and Engineering, National University of Defense Technology, Changsha, China; College of Electrical Science and Engineering, National University of Defense Technology, Changsha, China; College of Electrical Science and Engineering, National University of Defense Technology, Changsha, China","IEEE Transactions on Geoscience and Remote Sensing","","2018","56","1","371","390","Deep models with multiple layers have demonstrated their potential in learning abstract and invariant features for better representation and classification of remote sensing images. Moreover, metric learning (ML) is usually introduced into the deep models to further increase the discrimination of deep representations. However, the usual deep ML methods treat the training samples in each training batch in the stochastic gradient descent-based learning procedure independently, and thus, they neglect the important contextual (structural) information in the training samples. In this paper, we first introduce deep structural ML (DSML) into the literature of remote sensing scene classification and specifically capture and use the structural information during the training on the remote sensing images. Further analysis demonstrates that DSML usually makes many learned metric parameters similar. This similarity leads to obvious model redundancy and thus decreases the representational ability of the model. To address this problem, this paper proposes a new diversity-promoting DSML (D-DSML) method by regularizing the learning procedure by a diversity-promoting prior over the parameter factors. The proposed D-DSML encourages the parameter factors to be uncorrelated, such that each factor can model unique information, and thus, the model's description ability and classification performance would be significantly improved. Experiments over six real-world remote sensing scene data sets demonstrate that the proposed method obtains much better results than those obtained by the original deep models and has comparable or even better performances when compared with state-of-the-art methods.","","","10.1109/TGRS.2017.2748120","Natural Science Foundation of China; Foundation for the Author of National Excellent Doctoral Dissertation of China; Program for New Century Excellent Talents in University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8098555","Convolutional neural network (CNN);deep structural metric learning (DSML);diversity;scene classification","Training;Remote sensing;Feature extraction;Measurement;Redundancy;Machine learning","geophysical image processing;gradient methods;image classification;learning (artificial intelligence);remote sensing","contextual information;deep ML methods;real-world remote sensing scene datasets;classification performance;model unique information;parameter factors;D-DSML;diversity-promoting DSML method;learned metric parameters;structural information;deep structural ML;learning procedure;stochastic gradient descent;training batch;training samples;deep representations;remote sensing images;invariant features;abstract features;remote sensing scene classification;diversity-promoting deep structural metric learning","","14","61","","","","","IEEE","IEEE Journals"
"Deep Correlated Holistic Metric Learning for Sketch-Based 3D Shape Retrieval","G. Dai; J. Xie; Y. Fang","Department of Electrical and Computer Engineering, NYU Multimedia and Visual Computing Lab, New York University Abu Dhabi, United Arab Emirates; Department of Electrical and Computer Engineering, NYU Multimedia and Visual Computing Lab, New York University Abu Dhabi, United Arab Emirates; Department of Electrical and Computer Engineering, NYU Multimedia and Visual Computing Lab, New York University Abu Dhabi, United Arab Emirates","IEEE Transactions on Image Processing","","2018","27","7","3374","3386","How to effectively retrieve desired 3D models with simple queries is a long-standing problem in computer vision community. The model-based approach is quite straightforward but nontrivial, since people could not always have the desired 3D query model available by side. Recently, large amounts of wide-screen electronic devices are prevail in our daily lives, which makes the sketch-based 3D shape retrieval a promising candidate due to its simpleness and efficiency. The main challenge of sketch-based approach is the huge modality gap between sketch and 3D shape. In this paper, we proposed a novel deep correlated holistic metric learning (DCHML) method to mitigate the discrepancy between sketch and 3D shape domains. The proposed DCHML trains two distinct deep neural networks (one for each domain) jointly, which learns two deep nonlinear transformations to map features from both domains into a new feature space. The proposed loss, including discriminative loss and correlation loss, aims to increase the discrimination of features within each domain as well as the correlation between different domains. In the new feature space, the discriminative loss minimizes the intra-class distance of the deep transformed features and maximizes the inter-class distance of the deep transformed features to a large margin within each domain, while the correlation loss focused on mitigating the distribution discrepancy across different domains. Different from existing deep metric learning methods only with loss at the output layer, our proposed DCHML is trained with loss at both hidden layer and output layer to further improve the performance by encouraging features in the hidden layer also with desired properties. Our proposed method is evaluated on three benchmarks, including 3D Shape Retrieval Contest 2013, 2014, and 2016 benchmarks, and the experimental results demonstrate the superiority of our proposed method over the state-of-the-art methods.","","","10.1109/TIP.2018.2817042","ADEC Award for Research Excellence 2015, titled “Deep Cross-Domain Model for Conceptual Design.”; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8319427","Sketch-based 3D shape retrieval;deep correlated holistic metric learning;discrepancy across different domains;mitigate","Three-dimensional displays;Shape;Measurement;Solid modeling;Feature extraction;Computational modeling;Two dimensional displays","computer vision;image retrieval;learning (artificial intelligence);neural nets","deep correlated holistic metric learning;computer vision community;wide-screen electronic devices;DCHML;3D shape domains;distinct deep neural networks;deep nonlinear transformations;map features;feature space;correlation loss;deep transformed features;deep metric learning methods;discriminative loss;3D query model;3D Shape Retrieval Contest 2013 D Shape Retrieval Contest;sketch-based approach","","1","75","","","","","IEEE","IEEE Journals"
"Large-Scale JPEG Image Steganalysis Using Hybrid Deep-Learning Framework","J. Zeng; S. Tan; B. Li; J. Huang","College of Information Engineering, Shenzhen University, Shenzhen, China; Shenzhen Key Laboratory of Media Security, Guangdong Key Laboratory of Intelligent Information Processing, Shenzhen, China; College of Information Engineering, Shenzhen University, Shenzhen, China; College of Information Engineering, Shenzhen University, Shenzhen, China","IEEE Transactions on Information Forensics and Security","","2018","13","5","1200","1214","Adoption of deep learning in image steganalysis is still in its initial stage. In this paper, we propose a generic hybrid deep-learning framework for JPEG steganalysis incorporating the domain knowledge behind rich steganalytic models. Our proposed framework involves two main stages. The first stage is hand-crafted, corresponding to the convolution phase and the quantization and truncation phase of the rich models. The second stage is a compound deep-neural network containing multiple deep subnets, in which the model parameters are learned in the training procedure. We provided experimental evidence and theoretical reflections to argue that the introduction of threshold quantizers, though disabling the gradient-descent-based learning of the bottom convolution phase, is indeed cost-effective. We have conducted extensive experiments on a large-scale data set extracted from ImageNet. The primary data set used in our experiments contains 500 000 cover images, while our largest data set contains five million cover images. Our experiments show that the integration of quantization and truncation into deep-learning steganalyzers do boost the detection performance by a clear margin. Furthermore, we demonstrate that our framework is insensitive to JPEG blocking artifact alterations, and the learned model can be easily transferred to a different attacking target and even a different data set. These properties are of critical importance in practical applications.","","","10.1109/TIFS.2017.2779446","NSFC; Guangdong NSF; Shenzhen R&D Program; Alibaba Group through Alibaba Innovative Research Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8125774","Hybrid deep-learning framework;CNN network;steganalysis;steganography","Transform coding;Quantization (signal);Neurons;Convolution;Machine learning;Backpropagation;Training","convolution;data compression;gradient methods;image classification;image coding;learning (artificial intelligence);neural nets;steganography","cover images;steganalytic models;JPEG image steganalysis;deep-learning steganalyzers;model parameters;multiple deep subnets;compound deep-neural network;truncation phase;quantization;convolution phase;JPEG steganalysis;deep learning;hybrid deep-learning framework","","20","37","","","","","IEEE","IEEE Journals"
"Expert Level Control of Ramp Metering Based on Multi-Task Deep Reinforcement Learning","F. Belletti; D. Haziza; G. Gomes; A. M. Bayen","Computer Science Deptartment, University of California at Berkeley, Berkeley, CA, USA; Ecole Polytechnique, Palaiseau, France; Institute of Transportation Studies, University of California at Berkeley, Berkeley, CA, USA; Institute of Transportation Studies, University of California at Berkeley, Berkeley, CA, USA","IEEE Transactions on Intelligent Transportation Systems","","2018","19","4","1198","1207","This paper shows how the recent breakthroughs in reinforcement learning (RL) that have enabled robots to learn to play arcade video games, walk, or assemble colored bricks, can be used to perform other tasks that are currently at the core of engineering cyberphysical systems. We present the first use of RL for the control of systems modeled by discretized non-linear partial differential equations (PDEs) and devise a novel algorithm to use non-parametric control techniques for large multi-agent systems. Cyberphysical systems (e.g., hydraulic channels, transportation systems, the energy grid, and electromagnetic systems) are commonly modeled by PDEs, which historically have been a reliable way to enable engineering applications in these domains. However, it is known that the control of these PDE models is notoriously difficult. We show how neural network-based RL enables the control of discretized PDEs whose parameters are unknown, random, and time-varying. We introduce an algorithm of mutual weight regularization (MWR), which alleviates the curse of dimensionality of multi-agent control schemes by sharing experience between agents while giving each agent the opportunity to specialize its action policy so as to tailor it to the local parameters of the part of the system it is located in. A discretized PDE, such as the scalar Lighthill-Whitham-Richards PDE can indeed be considered as a macroscopic freeway traffic simulator and which presents the most salient challenges for learning to control large cyberphysical system with multiple agents. We consider two different discretization procedures and show the opportunities offered by applying deep reinforcement for continuous control on both. Using a neural RL PDE controller on a traffic flow simulation based on a Godunov discretization of the San Francisco Bay Bridge, we are able to achieve precise adaptive metering without model calibration thereby beating the state of the art in traffic metering. Furthermore, with the more accurate BeATS simulator, we manage to achieve a control performance on par with ALINEA, a state-of-the-art parametric control scheme, and show how using MWR improves the learning procedure.","","","10.1109/TITS.2017.2725912","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8011495","Deep learning;reinforcement learning;deep reinforcement learning;continuous control;transportation systems;macroscopic traffic models;partial differential equations","Learning (artificial intelligence);Neural networks;Cyber-physical systems;Control systems;Mathematical model;Biological system modeling;Transportation","computer games;digital simulation;learning (artificial intelligence);multi-agent systems;partial differential equations;road traffic;road traffic control;traffic control;traffic engineering computing","expert level control;ramp metering;multitask deep reinforcement learning;arcade video games;assemble colored bricks;engineering cyberphysical systems;nonlinear partial differential equations;nonparametric control techniques;multiagent systems;cyberphysical system;hydraulic channels;transportation systems;electromagnetic systems;engineering applications;PDE models;discretized PDE;mutual weight regularization;multiagent control schemes;scalar Lighthill-Whitham-Richards PDE;macroscopic freeway traffic simulator;multiple agents;different discretization procedures;continuous control;neural RL PDE controller;Godunov discretization;precise adaptive metering;model calibration;traffic metering;control performance;parametric control scheme;learning procedure;MWR","","6","27","","","","","IEEE","IEEE Journals"
"DANoC: An Efficient Algorithm and Hardware Codesign of Deep Neural Networks on Chip","X. Zhou; S. Li; F. Tang; S. Hu; Z. Lin; L. Zhang","Key Laboratory of Dependable Service Computing in Cyber Physical Society of Ministry of Education, College of Communication Engineering, Chongqing University, Chongqing, China; Chongqing Engineering Laboratory of High Performance Integrated Circuits, College of Communication Engineering, Chongqing University, Chongqing, China; Chongqing Engineering Laboratory of High Performance Integrated Circuits, College of Communication Engineering, Chongqing University, Chongqing, China; Chongqing Engineering Laboratory of High Performance Integrated Circuits, College of Communication Engineering, Chongqing University, Chongqing, China; Chongqing Engineering Laboratory of High Performance Integrated Circuits, College of Communication Engineering, Chongqing University, Chongqing, China; Chongqing Engineering Laboratory of High Performance Integrated Circuits, College of Communication Engineering, Chongqing University, Chongqing, China","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","7","3176","3187","Deep neural networks (NNs) are the state-of-the-art models for understanding the content of images and videos. However, implementing deep NNs in embedded systems is a challenging task, e.g., a typical deep belief network could exhaust gigabytes of memory and result in bandwidth and computational bottlenecks. To address this challenge, this paper presents an algorithm and hardware codesign for efficient deep neural computation. A hardware-oriented deep learning algorithm, named the deep adaptive network, is proposed to explore the sparsity of neural connections. By adaptively removing the majority of neural connections and robustly representing the reserved connections using binary integers, the proposed algorithm could save up to 99.9% memory utility and computational resources without undermining classification accuracy. An efficient sparse-mapping-memory-based hardware architecture is proposed to fully take advantage of the algorithmic optimization. Different from traditional Von Neumann architecture, the deep-adaptive network on chip (DANoC) brings communication and computation in close proximity to avoid power-hungry parameter transfers between on-board memory and on-chip computational units. Experiments over different image classification benchmarks show that the DANoC system achieves competitively high accuracy and efficiency comparing with the state-of-the-art approaches.","","","10.1109/TNNLS.2017.2717442","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7983385","Binary weights;deep belief network (DBN);deep learning;embedded system;field-programmable gate array (FPGA);sparse connections","Artificial neural networks;Hardware;Training;Algorithm design and analysis;Computer architecture;Machine learning;Robustness","belief networks;embedded systems;hardware-software codesign;image classification;learning (artificial intelligence);neural nets;optimisation","algorithmic optimization;DANoC;on-chip computational units;hardware codesign;deep neural networks;deep NNs;deep belief network;deep-adaptive network on chip;embedded systems;hardware-oriented deep learning algorithm;binary integers;sparse-mapping-memory-based hardware architecture;Von Neumann architecture;power-hungry parameter transfers;on-board memory;image classification","","2","50","","","","","IEEE","IEEE Journals"
"A Deep Machine Learning Method for Classifying Cyclic Time Series of Biological Signals Using Time-Growing Neural Network","A. Gharehbaghi; M. Lindén","Department of Innovation, Design and Technology, Mälardalen University, Västerås, Sweden; Department of Innovation, Design and Technology, Mälardalen University, Västerås, Sweden","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","9","4102","4115","This paper presents a novel method for learning the cyclic contents of stochastic time series: the deep time-growing neural network (DTGNN). The DTGNN combines supervised and unsupervised methods in different levels of learning for an enhanced performance. It is employed by a multiscale learning structure to classify cyclic time series (CTS), in which the dynamic contents of the time series are preserved in an efficient manner. This paper suggests a systematic procedure for finding the design parameter of the classification method for a one-versus-multiple class application. A novel validation method is also suggested for evaluating the structural risk, both in a quantitative and a qualitative manner. The effect of the DTGNN on the performance of the classifier is statistically validated through the repeated random subsampling using different sets of CTS, from different medical applications. The validation involves four medical databases, comprised of 108 recordings of the electroencephalogram signal, 90 recordings of the electromyogram signal, 130 recordings of the heart sound signal, and 50 recordings of the respiratory sound signal. Results of the statistical validations show that the DTGNN significantly improves the performance of the classification and also exhibits an optimal structural risk.","","","10.1109/TNNLS.2017.2754294","KKS financed research profile embedded sensor systems for health at Mälardalen University, Sweden; CAPIS Biomedical Research and Department Center, Mons, Belgium; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8066455","Deep learning;deep time-growing neural network (DTGNN);phonocardiogram (PCG);time-growing neural network (TGNN)","Hidden Markov models;Time series analysis;Biological system modeling;Neural networks;Phonocardiography;Medical services;Brain modeling","cardiology;electroencephalography;electromyography;learning (artificial intelligence);medical signal processing;neural nets;time series","biological signals;cyclic contents;stochastic time series;deep time-growing neural network;DTGNN;cyclic time series;dynamic contents;classification method;deep machine learning method;learning structure;validation method;medical applications;electroencephalogram signal;electromyogram signal;heart sound signal;respiratory sound signal;optimal structural risk;design parameter","","2","65","","","","","IEEE","IEEE Journals"
"Incremental Deep Learning for Robust Object Detection in Unknown Cluttered Environments","D. K. Shin; M. U. Ahmed; P. K. Rhee","Computer Engineering Department, Inha University, Incheon, South Korea; Computer Engineering Department, Inha University, Incheon, South Korea; Computer Engineering Department, Inha University, Incheon, South Korea","IEEE Access","","2018","6","","61748","61760","Object detection in streaming images is a major step in different detection-based applications, such as object tracking, action recognition, robot navigation, and visual surveillance applications. In most cases, image quality is noisy and biased, and as a result, the data distributions are disturbed and imbalanced. Most object detection approaches, such as the faster region-based convolutional neural network (RCNN), single shot multibox detector with 300Œ300 inputs (SSD300), and you only look once version 2 (YOLOv2), rely on simple sampling without considering distortions and noise under real-world changing environments, despite poor object labeling. In this paper, we propose an incremental active semi-supervised learning (IASSL) technology for unseen object detection. It combines batch-based active learning (AL) and bin-based semi-supervised learning (SSL) to leverage the strong points of AL's exploration and SSL's exploitation capabilities. A collaborative sampling method is also adopted to measure the uncertainty and diversity of AL and the confidence in SSL. Batch-based AL allows us to select more informative, confident, and representative samples with low cost. Bin-based SSL divides streaming image samples into several bins, and each bin repeatedly transfers the discriminative knowledge of convolutional neural network deep learning to the next bin until the performance criterion is reached. The IASSL can overcome noisy and biased labels in unknown, cluttered data distributions. We obtain superior performance, compared with the state-of-the-art technologies, such as Faster RCNN, SSD300, and YOLOv2.","","","10.1109/ACCESS.2018.2875720","Inha University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8490884","Object detection;convolutional neural network;incremental deep learning;active learning;semi-supervised learning","Object detection;Noise measurement;Training;Streaming media;Labeling;Semisupervised learning;Detectors","learning (artificial intelligence);neural nets;object detection;object tracking;sampling methods","YOLOv2;real-world changing environments;incremental active semisupervised learning;unseen object detection;batch-based active learning;collaborative sampling method;batch-based AL;informative samples;representative samples;bin-based SSL divides;image samples;convolutional neural network deep learning;noisy labels;biased labels;unknown data distributions;cluttered data distributions;SSD300;incremental deep;robust object detection;unknown cluttered environments;object tracking;action recognition;robot navigation;visual surveillance applications;image quality;single shot multibox detector;300Œ300 inputs;RCNN;confident samples;exploitation capabilities","","3","49","","","","","IEEE","IEEE Journals"
"Multimodal Neuroimaging Feature Learning With Multimodal Stacked Deep Polynomial Networks for Diagnosis of Alzheimer's Disease","J. Shi; X. Zheng; Y. Li; Q. Zhang; S. Ying","School of Communication and Information Engineering, Institute of Biomedical Engineering, Shanghai University, Shanghai, China; School of Communication and Information Engineering, Institute of Biomedical Engineering, Shanghai University, Shanghai, China; Shenzhen City Key Laboratory of Embedded System Design, Shenzhen Laboratory of IC Design for Internet of Things, College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China; School of Communication and Information Engineering, Institute of Biomedical Engineering, Shanghai University, Shanghai, China; Department of Mathematics, School of Science, Shanghai University, Shanghai, China","IEEE Journal of Biomedical and Health Informatics","","2018","22","1","173","183","The accurate diagnosis of Alzheimer's disease (AD) and its early stage, i.e., mild cognitive impairment, is essential for timely treatment and possible delay of AD. Fusion of multimodal neuroimaging data, such as magnetic resonance imaging (MRI) and positron emission tomography (PET), has shown its effectiveness for AD diagnosis. The deep polynomial networks (DPN) is a recently proposed deep learning algorithm, which performs well on both large-scale and small-size datasets. In this study, a multimodal stacked DPN (MM-SDPN) algorithm, which MM-SDPN consists of two-stage SDPNs, is proposed to fuse and learn feature representation from multimodal neuroimaging data for AD diagnosis. Specifically speaking, two SDPNs are first used to learn high-level features of MRI and PET, respectively, which are then fed to another SDPN to fuse multimodal neuroimaging information. The proposed MM-SDPN algorithm is applied to the ADNI dataset to conduct both binary classification and multiclass classification tasks. Experimental results indicate that MM-SDPN is superior over the state-of-the-art multimodal feature-learning-based algorithms for AD diagnosis.","","","10.1109/JBHI.2017.2655720","National Natural Science Foundation of China; Projects of Guangdong R/D Foundation and the Fundamental Science Projects of Shenzhen City; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7827160","Alzheimer's disease;deep learning;deep polynomial networks;multimodal stacked deep polynomial networks;multimodal neuroimaging","Neuroimaging;Feature extraction;Classification algorithms;Magnetic resonance imaging;Prediction algorithms;Diseases;Positron emission tomography","biomedical MRI;cognition;diseases;image classification;learning (artificial intelligence);medical image processing;neurophysiology;polynomials;positron emission tomography","feature learning;multimodal stacked deep polynomial networks;Alzheimer disease diagnosis;mild cognitive impairment;multimodal neuroimaging data;magnetic resonance imaging;positron emission tomography;AD diagnosis;deep polynomial networks;deep learning algorithm;multimodal stacked DPN algorithm;MM-SDPN algorithm;feature representation;to fed high-level features;MRI;PET;ADNI dataset;binary classification;multiclass classification;state-of-the-art multimodal feature-learning-based algorithm","","28","55","","","","","IEEE","IEEE Journals"
"Improving Recognition of Complex Aerial Scenes Using a Deep Weakly Supervised Learning Paradigm","P. Singh; N. Komodakis","Imagine Laboratory, École des Ponts ParisTech, Paris, France; Imagine Laboratory, École des Ponts ParisTech, Paris, France","IEEE Geoscience and Remote Sensing Letters","","2018","15","12","1932","1936","Categorizing highly complex aerial scenes is quite strenuous due to the presence of detailed information with a large number of distinctive objects. Recognition happens by first deriving a joint relationship within all these distinguishing objects, distilling finally to some meaningful knowledge that is subsequently employed to label the scene. However, something intriguing is whether all this captured information is actually relevant to classify such a complex scene? What if some objects just create uncertainty with respect to the target label, thereby causing ambiguity in the decision-making? In this letter, we investigate these questions and analyze as to which regions in an aerial scene are the most relevant and are inhibiting in determining the image label accurately. However, for such aerial scene classification (ASC) task, employing supervised knowledge of experts to annotate these discriminative regions is quite costly and laborious, especially when the data set is huge. To this end, we propose a deep weakly supervised learning (DWSL) technique. Our classification-trained convolutional neural network learns to identify discriminative region localizations in an aerial scene solely by utilizing image labels. Using the DWSL model, we significantly improve the recognition accuracies of highly complex scenes, thus validating that extra information causes uncertainty in decision-making. Moreover, our DWSL methodology can also be leveraged as a novel tool for concrete visualization of the most informative regions relevant to accurately classify an aerial scene. Finally, our proposed framework yields a state-of-the-art performance on the existing ASC data sets.","","","10.1109/LGRS.2018.2864216","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453884","Aerial scene classification (ASC);deep learning;multi-instance learning;scene complexity;weakly supervised","Training;Heating systems;Machine learning;Complexity theory;Feature extraction;Supervised learning;Task analysis","image classification;learning (artificial intelligence);neural nets;object recognition","decision-making;improving recognition;deep weakly supervised learning paradigm;highly complex aerial scenes;aerial scene classification task;deep weakly supervised learning technique","","1","19","","","","","IEEE","IEEE Journals"
"Deep Patient Similarity Learning for Personalized Healthcare","Q. Suo; F. Ma; Y. Yuan; M. Huai; W. Zhong; J. Gao; A. Zhang","Department of Computer Science, State University of New York at Buffalo, Buffalo, NY, USA; Department of Computer Science, State University of New York at Buffalo, Buffalo, NY, USA; College of Information and Communication Engineering, Beijing University of Technology, Beijing, China; Department of Computer Science, State University of New York at Buffalo, Buffalo, NY, USA; Department of Computer Science, State University of New York at Buffalo, Buffalo, NY, USA; Department of Computer Science, State University of New York at Buffalo, Buffalo, NY, USA; Department of Computer Science, State University of New York at Buffalo, Buffalo, NY, USA","IEEE Transactions on NanoBioscience","","2018","17","3","219","227","Predicting patients' risk of developing certain diseases is an important research topic in healthcare. Accurately identifying and ranking the similarity among patients based on their historical records is a key step in personalized healthcare. The electric health records (EHRs), which are irregularly sampled and have varied patient visit lengths, cannot be directly used to measure patient similarity due to the lack of an appropriate representation. Moreover, there needs an effective approach to measure patient similarity on EHRs. In this paper, we propose two novel deep similarity learning frameworks which simultaneously learn patient representations and measure pairwise similarity. We use a convolutional neural network (CNN) to capture local important information in EHRs and then feed the learned representation into triplet loss or softmax cross entropy loss. After training, we can obtain pairwise distances and similarity scores. Utilizing the similarity information, we then perform disease predictions and patient clustering. Experimental results show that CNN can better represent the longitudinal EHR sequences, and our proposed frameworks outperform state-of-the-art distance metric learning methods.","","","10.1109/TNB.2018.2837622","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8360146","Patient similarity;convolutional neural network;personalized healthcare","Measurement;Diseases;Predictive models;Nanobioscience;Convolution;Learning systems","convolution;diseases;electronic health records;entropy;feedforward neural nets;health care;learning (artificial intelligence)","deep similarity learning frameworks;patient representations;softmax cross entropy loss;disease predictions;patient clustering;deep patient similarity learning;distance metric learning methods;electronic health records;pairwise similarity;EHR;convolutional neural network;CNN","Algorithms;Computational Biology;Deep Learning;Electronic Health Records;Humans;Models, Statistical;Precision Medicine","5","45","","","","","IEEE","IEEE Journals"
"Deep Multiple Instance Learning-Based Spatial–Spectral Classification for PAN and MS Imagery","X. Liu; L. Jiao; J. Zhao; J. Zhao; D. Zhang; F. Liu; S. Yang; X. Tang","Key Laboratory of Intelligent Perception and Image Understanding of the Ministry of Education of China, International Research Center of Intelligent Perception and Computation, School of Electronic Engineering, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding of the Ministry of Education of China, International Research Center of Intelligent Perception and Computation, School of Electronic Engineering, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding of the Ministry of Education of China, International Research Center of Intelligent Perception and Computation, School of Electronic Engineering, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding of the Ministry of Education of China, International Research Center of Intelligent Perception and Computation, School of Electronic Engineering, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding of the Ministry of Education of China, International Research Center of Intelligent Perception and Computation, School of Electronic Engineering, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding of the Ministry of Education of China, International Research Center of Intelligent Perception and Computation, School of Electronic Engineering, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding of the Ministry of Education of China, International Research Center of Intelligent Perception and Computation, School of Electronic Engineering, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding of the Ministry of Education of China, International Research Center of Intelligent Perception and Computation, School of Electronic Engineering, Xidian University, Xi’an, China","IEEE Transactions on Geoscience and Remote Sensing","","2018","56","1","461","473","Panchromatic (PAN) and multispectral (MS) imagery classification is one of the hottest topics in the field of remote sensing. In recent years, deep learning techniques have been widely applied in many areas of image processing. In this paper, an end-to-end learning framework based on deep multiple instance learning (DMIL) is proposed for MS and PAN images' classification using the joint spectral and spatial information based on feature fusion. There are two instances in the proposed framework: one instance is used to capture the spatial information of PAN and the other is used to describe the spectral information of MS. The features obtained by the two instances are concatenated directly, which can be treated as simple fusion features. To fully fuse the spatial-spectral information for further classification, the simple fusion features are fed into a fusion network with three fully connected layers to learn the high-level fusion features. Classification experiments carried out on four different airborne MS and PAN images indicate that the classifier provides feasible and efficient solution. It demonstrates that DMIL performs better than using a convolutional neural network and a stacked autoencoder network separately. In addition, this paper shows that the DMIL model can learn and fuse spectral and spatial information effectively, and has huge potential for MS and PAN imagery classification.","","","10.1109/TGRS.2017.2750220","National Basic Research Program (973 Program) of China; Major Research Plan of the National Natural Science Foundation of China; Fund for Foreign Scholars in University Research and Teaching Programs (the 111 Project); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8048556","Deep learning;feature fusion;image classification;joint features;multiple instance learning","Feature extraction;Spatial resolution;Machine learning;Neural networks;Convolution;Fuses","feature extraction;geophysical image processing;image classification;image fusion;image resolution;learning (artificial intelligence);neural nets;remote sensing","deep multiple instance learning;deep learning techniques;end-to-end learning framework;feature fusion;spatial-spectral information;fusion network;high-level fusion features;spatial-spectral classification;panchromatic-and-multispectral imagery classification;MS imagery classification;PAN imagery classification","","11","52","","","","","IEEE","IEEE Journals"
"Deep Learning Meets Game Theory: Bregman-Based Algorithms for Interactive Deep Generative Adversarial Networks","H. Tembine","Learning and Game Theory Laboratory, New York University Abu Dhabi, Abu Dhabi, UAE (e-mail: tembine@ieee.org).","IEEE Transactions on Cybernetics","","2018","PP","99","1","14","This paper presents an interplay between deep learning and game theory. It models basic deep learning tasks as strategic games. Then, distributionally robust games and their relationship with deep generative adversarial networks (GANs) are presented. To achieve a higher order convergence rate without using a second derivative of the objective function, a Bregman discrepancy is used to construct a speed-up deep learning. Each player has a continuous action space which corresponds to weight space and aims to learn his/her optimal strategy. The convergence rate of the proposed deep learning algorithm is derived using a mean estimate. Experiments are carried out on a real dataset in both shallow and deep GANs. Both qualitative and quantitative evaluation results show that the generative model trained by the Bregman deep learning algorithm can speed up the state-of-the-art performance.","","","10.1109/TCYB.2018.2886238","Air Force Office of Scientific Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8598756","Big data;deep learning;distributional robustness;game theory;mean-field","Deep learning;Games;Game theory;Biological neural networks;Gallium nitride;Neurons;Heuristic algorithms","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Hyperspectral Image Sharpening","R. Dian; S. Li; A. Guo; L. Fang","College of Electrical and Information Engineering, Hunan University, Changsha, China; College of Electrical and Information Engineering, Hunan University, Changsha, China; College of Electrical and Information Engineering, Hunan University, Changsha, China; College of Electrical and Information Engineering, Hunan University, Changsha, China","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","11","5345","5355","Hyperspectral image (HSI) sharpening, which aims at fusing an observable low spatial resolution (LR) HSI (LR-HSI) with a high spatial resolution (HR) multispectral image (HR-MSI) of the same scene to acquire an HR-HSI, has recently attracted much attention. Most of the recent HSI sharpening approaches are based on image priors modeling, which are usually sensitive to the parameters selection and time-consuming. This paper presents a deep HSI sharpening method (named DHSIS) for the fusion of an LR-HSI with an HR-MSI, which directly learns the image priors via deep convolutional neural network-based residual learning. The DHSIS method incorporates the learned deep priors into the LR-HSI and HR-MSI fusion framework. Specifically, we first initialize the HR-HSI from the fusion framework via solving a Sylvester equation. Then, we map the initialized HR-HSI to the reference HR-HSI via deep residual learning to learn the image priors. Finally, the learned image priors are returned to the fusion framework to reconstruct the final HR-HSI. Experimental results demonstrate the superiority of the DHSIS approach over existing state-of-the-art HSI sharpening approaches in terms of reconstruction accuracy and running time.","","","10.1109/TNNLS.2018.2798162","National Natural Science Foundation of China; National Natural Science Fund of China for Distinguished Young Scholars; Fund of Hunan Province for Science and Technology Plan Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8295275","Deep convolutional neural network (CNN);fusion;hyperspectral imaging;residual learning;super-resolution","Spatial resolution;Mathematical model;Sensors;Hyperspectral imaging;Image reconstruction","feedforward neural nets;geophysical image processing;hyperspectral imaging;image fusion;image resolution;image sensors;learning (artificial intelligence)","deep hyperspectral image sharpening;observable low spatial resolution HSI;LR-HSI;high spatial resolution multispectral image;recent HSI sharpening approaches;deep HSI sharpening method;deep convolutional neural network-based residual learning;learned deep priors;HR-MSI fusion framework;initialized HR-HSI;reference HR-HSI;deep residual learning;learned image priors;final HR-HSI;HSI sharpening approaches","","14","59","","","","","IEEE","IEEE Journals"
"Her2Net: A Deep Framework for Semantic Segmentation and Classification of Cell Membranes and Nuclei in Breast Cancer Evaluation","M. Saha; C. Chakraborty","School of Medical Science and Technology, IIT Kharagpur, Kharagpur, India; School of Medical Science and Technology, IIT Kharagpur, Kharagpur, India","IEEE Transactions on Image Processing","","2018","27","5","2189","2200","We present an efficient deep learning framework for identifying, segmenting, and classifying cell membranes and nuclei from human epidermal growth factor receptor-2 (HER2)-stained breast cancer images with minimal user intervention. This is a long-standing issue for pathologists because the manual quantification of HER2 is error-prone, costly, and time-consuming. Hence, we propose a deep learning-based HER2 deep neural network (Her2Net) to solve this issue. The convolutional and deconvolutional parts of the proposed Her2Net framework consisted mainly of multiple convolution layers, max-pooling layers, spatial pyramid pooling layers, deconvolution layers, up-sampling layers, and trapezoidal long short-term memory (TLSTM). A fully connected layer and a softmax layer were also used for classification and error estimation. Finally, HER2 scores were calculated based on the classification results. The main contribution of our proposed Her2Net framework includes the implementation of TLSTM and a deep learning framework for cell membrane and nucleus detection, segmentation, and classification and HER2 scoring. Our proposed Her2Net achieved 96.64% precision, 96.79% recall, 96.71% F-score, 93.08% negative predictive value, 98.33% accuracy, and a 6.84% false-positive rate. Our results demonstrate the high accuracy and wide applicability of the proposed Her2Net in the context of HER2 scoring for breast cancer evaluation.","","","10.1109/TIP.2018.2795742","Department of Science and Technology (DST), Government of India, for providing the DST-Inspire fellowship; Ministry of Human Resource Development, Government of India, under Signals and Systems for Life Science, a megainitiative of IIT Kharagpur, India; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8264783","Breast cancer;HER2;LSTM;deep learning;cell membrane;nuclei","Machine learning;Biomembranes;Image color analysis;Image segmentation;Breast cancer;Fish;Software","cancer;feature extraction;image classification;image segmentation;learning (artificial intelligence);medical image processing;neural nets","error estimation;Her2Net framework;breast cancer evaluation;semantic segmentation;HER2 deep neural network;max-pooling layers;softmax layer;deep learning framework;cell membrane classification","Breast;Breast Neoplasms;Cell Membrane;Cell Nucleus;Deep Learning;Female;Histocytochemistry;Humans;Image Interpretation, Computer-Assisted;Receptor, ErbB-2","6","65","","","","","IEEE","IEEE Journals"
"Local Energy Trading Behavior Modeling With Deep Reinforcement Learning","T. Chen; W. Su","Department of Electrical and Computer Engineering, University of Michigan-Dearborn, Dearborn, MI, USA; Department of Electrical and Computer Engineering, University of Michigan-Dearborn, Dearborn, MI, USA","IEEE Access","","2018","6","","62806","62814","In this paper, we model prosumers' energy trading behavior, with the operation of an energy storage system, in a proposed event-driven local energy market. Through modeling local energy trading strategies of a prosumer in the proposed holistic market model, the prosumer's decision-making process will be built as a Markov decision process with many continuous variables. Then, this decision-making process of local market participation will be solved by deep reinforcement learning technology with experience replay mechanism. Specifically, a deep Q-learning for local energy trading algorithm is modified from deep Q-network to facilitate such a decision-making within an intelligent energy system and promote prosumers' willingness to participate in the localized energy ecosystem.","","","10.1109/ACCESS.2018.2876652","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8496766","Prosumer;energy trading;Markov decision process;deep reinforcement learning","Machine learning;Energy storage;Electricity supply industry;Companies;Decision making;Ecosystems;Learning (artificial intelligence)","decision making;learning (artificial intelligence);Markov processes;multi-agent systems;power engineering computing;power markets;power system management","holistic market model;Markov decision process;decision-making process;local market participation;deep reinforcement learning technology;deep Q-learning;local energy trading algorithm;deep Q-network;intelligent energy system;localized energy ecosystem;local energy trading behavior modeling;model prosumers;energy storage system;event-driven local energy market;local energy trading strategies","","3","26","","","","","IEEE","IEEE Journals"
"Deep Residual Learning for Accelerated MRI Using Magnitude and Phase Networks","D. Lee; J. Yoo; S. Tak; J. C. Ye","Department of Bio and Brain Engineering, KAIST, (KAIST), Daejeon, South Korea; Department of Bio and Brain Engineering, KAIST, (KAIST), Daejeon, South Korea; Bioimaging Research Team, Korea Basic Science Institute, Ochang, South Korea; Department of Bio and Brain Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, South Korea","IEEE Transactions on Biomedical Engineering","","2018","65","9","1985","1995","Objective: Accelerated magnetic resonance (MR) image acquisition with compressed sensing (CS) and parallel imaging is a powerful method to reduce MR imaging scan time. However, many reconstruction algorithms have high computational costs. To address this, we investigate deep residual learning networks to remove aliasing artifacts from artifact corrupted images. Methods: The deep residual learning networks are composed of magnitude and phase networks that are separately trained. If both phase and magnitude information are available, the proposed algorithm can work as an iterative k-space interpolation algorithm using framelet representation. When only magnitude data are available, the proposed approach works as an image domain postprocessing algorithm. Results: Even with strong coherent aliasing artifacts, the proposed network successfully learned and removed the aliasing artifacts, whereas current parallel and CS reconstruction methods were unable to remove these artifacts. Conclusion: Comparisons using single and multiple coil acquisition show that the proposed residual network provides good reconstruction results with orders of magnitude faster computational time than existing CS methods. Significance: The proposed deep learning framework may have a great potential for accelerated MR reconstruction by generating accurate results immediately.","","","10.1109/TBME.2018.2821699","Korea Science and Engineering Foundation; Human Connectome Project, MGH-USC Consortium; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8329428","Compressed sensing MRI;deep convolutional framelets;deep learning;parallel imaging","Image reconstruction;Magnetic resonance imaging;Acceleration;Machine learning;Interpolation;Iterative algorithms","biomedical MRI;compressed sensing;image reconstruction;image sampling;interpolation;learning (artificial intelligence);medical image processing;parallel processing","deep residual learning networks;phase networks;magnitude information;iterative k-space interpolation algorithm;magnitude data;image domain;CS reconstruction methods;CS methods;deep learning framework;accelerated MR reconstruction;accelerated MRI;Accelerated magnetic resonance image acquisition;parallel imaging;reconstruction algorithms;high computational costs;artifact corrupted images;computational time;framelet representation","","7","45","","","","","IEEE","IEEE Journals"
"Supervised Learning of Semantics-Preserving Hash via Deep Convolutional Neural Networks","H. Yang; K. Lin; C. Chen","Research Center for Information Technology Innovation, Academia Sinica, Taipei, Taiwan; Department of Electrical Engineering, University of Washington, Seattle, WA; Institute of Information Science, Academia Sinica, Taipei, Taiwan","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","2","437","451","This paper presents a simple yet effective supervised deep hash approach that constructs binary hash codes from labeled data for large-scale image search. We assume that the semantic labels are governed by several latent attributes with each attribute on or off, and classification relies on these attributes. Based on this assumption, our approach, dubbed supervised semantics-preserving deep hashing (SSDH), constructs hash functions as a latent layer in a deep network and the binary codes are learned by minimizing an objective function defined over classification error and other desirable hash codes properties. With this design, SSDH has a nice characteristic that classification and retrieval are unified in a single learning model. Moreover, SSDH performs joint learning of image representations, hash codes, and classification in a point-wised manner, and thus is scalable to large-scale datasets. SSDH is simple and can be realized by a slight enhancement of an existing deep architecture for classification; yet it is effective and outperforms other hashing approaches on several benchmarks and large datasets. Compared with state-of-the-art approaches, SSDH achieves higher retrieval accuracy, while the classification performance is not sacrificed.","","","10.1109/TPAMI.2017.2666812","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7849132","Image retrieval;supervised hashing;binary codes;deep learning;convolutional neural networks","Binary codes;Semantics;Training;Convolutional codes;Synchronous digital hierarchy;Neural networks;Machine learning","binary codes;file organisation;image classification;image representation;image retrieval;learning (artificial intelligence);neural nets","supervised learning;deep convolutional neural networks;effective supervised deep hash approach;large-scale image search;semantic labels;latent attributes;dubbed supervised semantics-preserving deep hashing;SSDH;latent layer;deep network;binary codes;objective function;classification error;desirable hash codes properties;single learning model;joint learning;existing deep architecture;hashing approaches;state-of-the-art approaches;classification performance","","41","66","","","","","IEEE","IEEE Journals"
"Learning Affective Features With a Hybrid Deep Model for Audio–Visual Emotion Recognition","S. Zhang; S. Zhang; T. Huang; W. Gao; Q. Tian","Institute of Digital Media, School of Electronic Engineering and Computer Science, Peking University, Beijing, China; Institute of Digital Media, School of Electronic Engineering and Computer Science, Peking University, Beijing, China; Institute of Digital Media, School of Electronic Engineering and Computer Science, Peking University, Beijing, China; Institute of Digital Media, School of Electronic Engineering and Computer Science, Peking University, Beijing, China; Department of Computer Science, The University of Texas at San Antonio, San Antonio, TX, USA","IEEE Transactions on Circuits and Systems for Video Technology","","2018","28","10","3030","3043","Emotion recognition is challenging due to the emotional gap between emotions and audio-visual features. Motivated by the powerful feature learning ability of deep neural networks, this paper proposes to bridge the emotional gap by using a hybrid deep model, which first produces audio-visual segment features with Convolutional Neural Networks (CNNs) and 3D-CNN, then fuses audio-visual segment features in a Deep Belief Networks (DBNs). The proposed method is trained in two stages. First, CNN and 3D-CNN models pre-trained on corresponding large-scale image and video classification tasks are fine-tuned on emotion recognition tasks to learn audio and visual segment features, respectively. Second, the outputs of CNN and 3D-CNN models are combined into a fusion network built with a DBN model. The fusion network is trained to jointly learn a discriminative audio-visual segment feature representation. After average-pooling segment features learned by DBN to form a fixed-length global video feature, a linear Support Vector Machine is used for video emotion classification. Experimental results on three public audio-visual emotional databases, including the acted RML database, the acted eNTERFACE05 database, and the spontaneous BAUM-1s database, demonstrate the promising performance of the proposed method. To the best of our knowledge, this is an early work fusing audio and visual cues with CNN, 3D-CNN, and DBN for audio-visual emotion recognition.","","","10.1109/TCSVT.2017.2719043","National Natural Science Foundation of China; ARO; Faculty Research Gift Awards by NEC Laboratories of America and Blippar; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7956190","Emotion recognition;deep learning;convolutional neural networks;deep belief networks;multimodality fusion","Feature extraction;Emotion recognition;Visualization;Image segmentation;Machine learning;Databases;Convolution","audio signal processing;belief networks;convolution;emotion recognition;feature extraction;feedforward neural nets;image classification;image fusion;image segmentation;learning (artificial intelligence);solid modelling;speech recognition;support vector machines;video signal processing","Convolutional Neural Networks;Deep Belief Networks;audio segment features;discriminative audio-visual segment feature representation;video emotion classification;audio-visual emotion recognition;audio-visual features;deep neural networks;emotion recognition;feature learning;audio-visual emotional databases;3D-CNN models;affective features learning;linear support vector machine","","16","68","","","","","IEEE","IEEE Journals"
"A Secure Mobile Crowdsensing Game With Deep Reinforcement Learning","L. Xiao; Y. Li; G. Han; H. Dai; H. V. Poor","School of Data and Computer Science, Sun Yat-sen University, Guangdong Key Laboratory of Big Data Analysis and Processing, Guangzhou, China; Department of Communication Engineering, Xiamen University, Xiamen, China; Department of Communication Engineering, Xiamen University, Xiamen, China; Department of Electrical and Computer Engineering, North Carolina State University, Raleigh, NC, USA; Department of Electrical Engineering, Princeton University, Princeton, NJ, USA","IEEE Transactions on Information Forensics and Security","","2018","13","1","35","47","Mobile crowdsensing (MCS) is vulnerable to faked sensing attacks, as selfish smartphone users sometimes provide faked sensing results to the MCS server to save their sensing costs and avoid privacy leakage. In this paper, the interactions between an MCS server and a number of smartphone users are formulated as a Stackelberg game, in which the server as the leader first determines and broadcasts its payment policy for each sensing accuracy. Each user as a follower chooses the sensing effort and thus the sensing accuracy afterward to receive the payment based on the payment policy and the sensing accuracy estimated by the server. The Stackelberg equilibria of the secure MCS game are presented, disclosing conditions to motivate accurate sensing. Without knowing the smartphone sensing models in a dynamic version of the MCS game, an MCS system can apply deep Q-network (DQN), which is a deep reinforcement learning technique combining reinforcement learning and deep learning techniques, to derive the optimal MCS policy against faked sensing attacks. The DQN-based MCS system uses a deep convolutional neural network to accelerate the learning process with a high-dimensional state space and action set, and thus improve the MCS performance against selfish users. Simulation results show that the proposed MCS system stimulates high-quality sensing services and suppresses faked sensing attacks, compared with a Q-learning-based MCS system.","","","10.1109/TIFS.2017.2737968","National Natural Science Foundation of China; U.S. National Science Foundation; U.S. Army Research Office; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8006228","Mobile crowdsensing;game theory;deep reinforcement learning;faked sensing attacks;deep Q-networks","Sensors;Servers;Games;Mobile communication;Learning (artificial intelligence);Mobile computing;Privacy","convolution;data privacy;game theory;learning (artificial intelligence);mobile computing;neural nets;sensor fusion;smart phones","secure mobile crowdsensing game;Stackelberg game;sensing accuracy;smartphone sensing models;deep reinforcement learning technique;deep convolutional neural network;smartphone users;Stackelberg equilibria;deep Q-network","","22","33","","","","","IEEE","IEEE Journals"
"Deep Visual Attention Prediction","W. Wang; J. Shen","Beijing Laboratory of Intelligent Information Technology, School of Computer Science, Beijing Institute of Technology, Beijing, China; Beijing Laboratory of Intelligent Information Technology, School of Computer Science, Beijing Institute of Technology, Beijing, China","IEEE Transactions on Image Processing","","2018","27","5","2368","2378","In this paper, we aim to predict human eye fixation with view-free scenes based on an end-to-end deep learning architecture. Although convolutional neural networks (CNNs) have made substantial improvement on human attention prediction, it is still needed to improve the CNN-based attention models by efficiently leveraging multi-scale features. Our visual attention network is proposed to capture hierarchical saliency information from deep, coarse layers with global saliency information to shallow, fine layers with local saliency response. Our model is based on a skip-layer network structure, which predicts human attention from multiple convolutional layers with various reception fields. Final saliency prediction is achieved via the cooperation of those global and local predictions. Our model is learned in a deep supervision manner, where supervision is directly fed into multi-level layers, instead of previous approaches of providing supervision only at the output layer and propagating this supervision back to earlier layers. Our model thus incorporates multi-level saliency predictions within a single network, which significantly decreases the redundancy of previous approaches of learning multiple network streams with different input scales. Extensive experimental analysis on various challenging benchmark data sets demonstrate our method yields the state-of-the-art performance with competitive inference time.","","","10.1109/TIP.2017.2787612","Beijing Natural Science Foundation; National Basic Research Program of China (973 Program); National Natural Science Foundation of China; Fok Ying-Tong Education Foundation for Young Teachers; Specialized Fund for Joint Building Program of Beijing Municipal Education Commission; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8240654","Visual attention;convolutional neural network;saliency detection;deep learning;human eye fixation","Visualization;Machine learning;Predictive models;Analytical models;Computer architecture;Computational modeling","learning (artificial intelligence);neural nets;object detection","visual attention prediction;human eye fixation;view-free scenes;end-to-end deep learning architecture;convolutional neural networks;human attention prediction;CNN-based attention models;multiscale features;visual attention network;hierarchical saliency information;global saliency information;fine layers;local saliency response;skip-layer network structure;multiple convolutional layers;final saliency prediction;global predictions;local predictions;deep supervision manner;multilevel layers;multilevel saliency predictions","Algorithms;Attention;Databases, Factual;Deep Learning;Fixation, Ocular;Humans;Image Processing, Computer-Assisted","38","68","","","","","IEEE","IEEE Journals"
"Unsupervised Deep Homography: A Fast and Robust Homography Estimation Model","T. Nguyen; S. W. Chen; S. S. Shivakumar; C. J. Taylor; V. Kumar","Philadelphia, PA, USA; Philadelphia, PA, USA; Philadelphia, PA, USA; Philadelphia, PA, USA; Philadelphia, PA, USA","IEEE Robotics and Automation Letters","","2018","3","3","2346","2353","Homography estimation between multiple aerial images can provide relative pose estimation for collaborative autonomous exploration and monitoring. The usage on a robotic system requires a fast and robust homography estimation algorithm. In this letter, we propose an unsupervised learning algorithm that trains a deep convolutional neural network to estimate planar homographies. We compare the proposed algorithm to traditional-feature-based and direct methods, as well as a corresponding supervised learning algorithm. Our empirical results demonstrate that compared to traditional approaches, the unsupervised algorithm achieves faster inference speed, while maintaining comparable or better accuracy and robustness to illumination variation. In addition, our unsupervised method has superior adaptability and performance compared to the corresponding supervised deep learning method. Our image dataset and a Tensorflow implementation of our work are available at https://github.com/tynguyen/unsupervisedDeepHomographyRAL2018.","","","10.1109/LRA.2018.2809549","Applied Research Laboratory; Army Research Laboratory; Defense Advanced Research Projects Agency; USDA; National Science Foundation; Qualcomm Research, United Technologies, and TerraSwarm, one of six centers of STARnet, a Semiconductor Research Corporation program; MARCO and Defense Advanced Research Projects Agency; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8302515","Computer vision for automation;deep learning in robotics and automation;computer vision for other robotic applications;image alignment;deep homography","Estimation;Machine learning;Lighting;Robots;Supervised learning;Training;Robustness","feature extraction;feedforward neural nets;pose estimation;robot vision;unsupervised learning","unsupervised deep homography;fast homography estimation model;robust homography estimation model;multiple aerial images;relative pose estimation;collaborative autonomous exploration;robotic system;fast homography estimation algorithm;robust homography estimation algorithm;unsupervised learning algorithm;deep convolutional neural network;planar homographies;unsupervised algorithm;supervised learning algorithm;supervised deep learning method","","7","36","","","","","IEEE","IEEE Journals"
"Deep Learning for Super-Resolution Channel Estimation and DOA Estimation Based Massive MIMO System","H. Huang; J. Yang; H. Huang; Y. Song; G. Gui","Nanjing University of Posts and Telecommunications, Nanjing, China; Nanjing University of Posts and Telecommunications, Nanjing, China; Nanjing University of Posts and Telecommunications, Nanjing, China; Nanjing University of Posts and Telecommunications, Nanjing, China; Nanjing University of Posts and Telecommunications, Nanjing, China","IEEE Transactions on Vehicular Technology","","2018","67","9","8549","8560","The recent concept of massive multiple-input multiple-output (MIMO) can significantly improve the capacity of the communication network, and it has been regarded as a promising technology for the next-generation wireless communications. However, the fundamental challenge of existing massive MIMO systems is that high computational complexity and complicated spatial structures bring great difficulties to exploit the characteristics of the channel and sparsity of these multi-antennas systems. To address this problem, in this paper, we focus on channel estimation and direction-of-arrival (DOA) estimation, and a novel framework that integrates the massive MIMO into deep learning is proposed. To realize end-to-end performance, a deep neural network (DNN) is employed to conduct offline learning and online learning procedures, which is effective to learn the statistics of the wireless channel and the spatial structures in the angle domain. Concretely, the DNN is first trained by simulated data in different channel conditions with the aids of the offline learning, and then corresponding output data can be obtained based on current input data during online learning process. In order to realize super-resolution channel estimation and DOA estimation, two algorithms based on the deep learning are developed, in which the DOA can be estimated in the angle domain without additional complexity directly. Furthermore, simulation results corroborate that the proposed deep learning based scheme can achieve better performance in terms of the DOA estimation and the channel estimation compared with conventional methods, and the proposed scheme is well investigated by extensive simulation in various cases for testing its robustness.","","","10.1109/TVT.2018.2851783","National Natural Science Foundation of China; Jiangsu Specially Appointed Professor; Innovation and Entrepreneurship of Jiangsu High-level Talent; NUPTSF; 1311 Talent Plan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8400482","Massive MIMO;deep learning;channel estimation;DOA estimation;offline training","MIMO communication;Machine learning;Channel estimation;Direction-of-arrival estimation;Estimation;Spatial resolution","antenna arrays;channel estimation;computational complexity;direction-of-arrival estimation;learning (artificial intelligence);MIMO communication;neural nets;next generation networks;telecommunication computing;wireless channels","super-resolution channel estimation;DOA estimation based massive MIMO system;communication network;next-generation wireless communications;massive MIMO systems;direction-of-arrival estimation;end-to-end performance;deep neural network;offline learning;online learning procedures;wireless channel;angle domain;online learning process;deep learning based scheme;massive multiple input multiple output;multiantenna system;complicated spatial structures;high computational complexity","","108","45","","","","","IEEE","IEEE Journals"
"A Physics-Based Deep Learning Approach to Shadow Invariant Representations of Hyperspectral Images","L. Windrim; R. Ramakrishnan; A. Melkumyan; R. J. Murphy","Australian Centre for Field Robotics, The University of Sydney, Sydney, NSW, Australia; Australian Centre for Field Robotics, The University of Sydney, Sydney, NSW, Australia; Australian Centre for Field Robotics, The University of Sydney, Sydney, NSW, Australia; Australian Centre for Field Robotics, The University of Sydney, Sydney, NSW, Australia","IEEE Transactions on Image Processing","","2018","27","2","665","677","This paper proposes the Relit Spectral AngleStacked Autoencoder, a novel unsupervised feature learning approach for mapping pixel reflectances to illumination invariant encodings. This work extends the Spectral Angle-Stacked Autoencoder so that it can learn a shadow-invariant mapping. The method is inspired by a deep learning technique, Denoising Autoencoders, with the incorporation of a physics-based model for illumination such that the algorithm learns a shadow invariant mapping without the need for any labelled training data, additional sensors, a priori knowledge of the scene or the assumption of Planckian illumination. The method is evaluated using datasets captured from several different cameras, with experiments to demonstrate the illumination invariance of the features and how they can be used practically to improve the performance of high-level perception algorithms that operate on images acquired outdoors.","","","10.1109/TIP.2017.2761542","Rio Tinto Centre for Mine Automation; Australian Centre for Field Robotics, The University of Sydney; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8063434","Autoencoders;Illumination invariance;unsupervised feature learning;hyperspectral;deep learning","Lighting;Sensors;Hyperspectral imaging;Geometry;Atmospheric modeling;Cameras","image classification;image coding;image denoising;learning (artificial intelligence);unsupervised learning","hyperspectral images;Relit Spectral AngleStacked Autoencoder;novel unsupervised feature learning approach;illumination invariant encodings;Spectral Angle-Stacked Autoencoder;shadow-invariant mapping;deep learning technique;shadow invariant mapping;Planckian illumination;illumination invariance;shadow invariant representations;physics-based deep learning;denoising autoencoders","","10","55","","","","","IEEE","IEEE Journals"
"Large-Scale Remote Sensing Image Retrieval by Deep Hashing Neural Networks","Y. Li; Y. Zhang; X. Huang; H. Zhu; J. Ma","Department of Photogrammetry, School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; Department of Photogrammetry, School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; Department of Remote Sensing, School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; Department of Radio and Television Engineering, College of Telecommunication and Information Engineering, Nanjing University of Posts and Telecommunications, Nanjing, China; Department of Communication Engineering, Electronic Information School, Wuhan University, Wuhan, China","IEEE Transactions on Geoscience and Remote Sensing","","2018","56","2","950","965","As one of the most challenging tasks of remote sensing big data mining, large-scale remote sensing image retrieval has attracted increasing attention from researchers. Existing large-scale remote sensing image retrieval approaches are generally implemented by using hashing learning methods, which take handcrafted features as inputs and map the high-dimensional feature vector to the low-dimensional binary feature vector to reduce feature-searching complexity levels. As a means of applying the merits of deep learning, this paper proposes a novel large-scale remote sensing image retrieval approach based on deep hashing neural networks (DHNNs). More specifically, DHNNs are composed of deep feature learning neural networks and hashing learning neural networks and can be optimized in an end-to-end manner. Rather than requiring to dedicate expertise and effort to the design of feature descriptors, we can automatically learn good feature extraction operations and feature hashing mapping under the supervision of labeled samples. To broaden the application field, DHNNs are evaluated under two representative remote sensing cases: scarce and sufficient labeled samples. To make up for a lack of labeled samples, DHNNs can be trained via transfer learning for the former case. For the latter case, DHNNs can be trained via supervised learning from scratch with the aid of a vast number of labeled samples. Extensive experiments on one public remote sensing image data set with a limited number of labeled samples and on another public data set with plenty of labeled samples show that the proposed remote sensing image retrieval approach based on DHNNs can remarkably outperform state-of-the-art methods under both of the examined conditions.","","","10.1109/TGRS.2017.2756911","National Natural Science Foundation of China; China Postdoctoral Science Foundation; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8067633","Deep hashing neural networks (DHNNs);large-scale remote sensing image retrieval;remote sensing big data (RSBD) mining;supervised learning from scratch;transfer learning","Remote sensing;Image retrieval;Neural networks;Learning systems;Machine learning;Manuals","Big Data;data mining;feature extraction;geophysical image processing;image retrieval;learning (artificial intelligence);neural nets;remote sensing;vectors","deep hashing neural networks;large-scale remote sensing image retrieval approaches;high-dimensional feature vector;low-dimensional binary feature vector;feature-searching complexity levels;deep learning;DHNNs;feature descriptors;good feature extraction operations;hashing mapping;representative remote sensing cases;remote sensing image retrieval approach;supervised learning;transfer learning","","17","59","","","","","IEEE","IEEE Journals"
"Anti-Jamming Communications Using Spectrum Waterfall: A Deep Reinforcement Learning Approach","X. Liu; Y. Xu; L. Jia; Q. Wu; A. Anpalagan","College of Information Science and Engineering, Guilin University of Technology, Guilin, China; College of Communication Engineering, Army Engineering University of PLA, Nanjing, China; College of Communication Engineering, Army Engineering University of PLA, Nanjing, China; College of Electronic and Information Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, China; Department of Electrical and Computer Engineering, Ryerson University, Toronto, ON, Canada","IEEE Communications Letters","","2018","22","5","998","1001","This letter investigates the problem of anti-jamming communications in a dynamic and intelligent jamming environment through machine learning. Different from existing studies which need to know (estimate) the jamming patterns and parameters, we use the temporal and spectral information, i.e., the spectrum waterfall, directly. First, to cope with the challenge of infinite state of spectrum waterfall, a recursive convolutional neural network is designed. Then, an anti-jamming deep reinforcement learning algorithm is proposed to obtain the optimal anti-jamming strategies. Finally, simulation results validate the proposed approach. The proposed algorithm does not need to model the jamming patterns, and naturally has the ability to explore the unknown environment, which implies that it can be widely used for combating dynamic and intelligent jamming.","","","10.1109/LCOMM.2018.2815018","Guang Xi Universities Key Laboratory Fund of Embedded Technology and Intelligent System (Guilin University of Technology); Natural Science Foundation for Distinguished Young Scholars of Jiangsu Province; National Natural Science Foundation of China; Open Research Foundation of Science and Technology on Communication Networks Laboratory; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8314744","Anti-jamming;deep Q-network;deep reinforcement learning","Jamming;Machine learning;Aerodynamics;Signal to noise ratio;Time-frequency analysis;Convolutional neural networks;Heuristic algorithms","feedforward neural nets;jamming;learning (artificial intelligence);radio spectrum management","anti-jamming communications;spectrum waterfall;deep reinforcement learning approach;dynamic jamming environment;intelligent jamming environment;machine learning;temporal information;spectral information;recursive convolutional neural network;deep reinforcement learning algorithm","","23","12","","","","","IEEE","IEEE Journals"
"Transfer Hashing: From Shallow to Deep","J. T. Zhou; H. Zhao; X. Peng; M. Fang; Z. Qin; R. S. M. Goh","Institute of High Performance Computing, A*STAR, Singapore; Institute of High Performance Computing, A*STAR, Singapore; College of Computer Science, Sichuan University, Chengdu, China; Tencent AI Lab, Shenzhen, China; Institute of High Performance Computing, A*STAR, Singapore; Institute of High Performance Computing, A*STAR, Singapore","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","12","6191","6201","One major assumption used in most existing hashing approaches is that the domain of interest (i.e., the target domain) could provide sufficient training data, either labeled or unlabeled. However, this assumption may be violated in practice. To address this so-called data sparsity issue in hashing, a new framework termed transfer hashing with privileged information (THPI) is proposed, which marriages hashing and transfer learning (TL). To show the efficacy of THPI, we propose three variants of the well-known iterative quantization (ITQ) [11] as a showcase. The proposed methods, ITQ+, LapITQ+, and deep transfer hashing (DTH), solve the aforementioned data sparsity issue from different aspects. Specifically, ITQ+ is a shallow model, which makes ITQ achieve hashing in a TL manner. ITQ+ learns a new slack function from the source domain to approximate the quantization error on the target domain given by ITQ. To further improve the performance of ITQ+, LapITQ+ is proposed by embedding the geometric relationship of the source domain into the target domain. Moreover, DTH is proposed to show the generality of our framework by utilizing the powerful representative capacity of deep learning. To the best of our knowledge, this could be one of the first DTH works. Extensive experiments on several popular data sets demonstrate the effectiveness of our shallow and DTH approaches comparing with several state-of-the-art hashing approaches.","","","10.1109/TNNLS.2018.2827036","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8356229","Deep transfer hashing (DTH);hashing;privileged information;transfer learning (TL)","Quantization (signal);DH-HEMTs;Machine learning;Binary codes;Training;Support vector machines;Learning systems","file organisation;iterative methods;learning (artificial intelligence)","shallow model;ITQ achieve hashing;source domain;target domain;deep learning;marriages hashing;transfer learning;deep transfer hashing;training data;data sparsity issue;THPI","","22","56","","","","","IEEE","IEEE Journals"
"Deep Co-Space: Sample Mining Across Feature Transformation for Semi-Supervised Learning","Z. Chen; K. Wang; X. Wang; P. Peng; E. Izquierdo; L. Lin","School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; School of Computer Science, Anhui University, Hefei, China; Youtu Laboratory, Tencent, Shanghai, China; School of Electronic Engineering and Computer Science, Queen Mary University of London, London, U.K.; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China","IEEE Transactions on Circuits and Systems for Video Technology","","2018","28","10","2667","2678","Aiming at improving the performance of visual classification in a cost-effective manner, this paper proposes an incremental semi-supervised learning paradigm called deep co-space (DCS). Unlike many conventional semi-supervised learning methods usually performed within a fixed feature space, our DCS gradually propagates information from labeled samples to unlabeled ones along with deep feature learning. We regard deep feature learning as a series of steps pursuing feature transformation, i.e., projecting the samples from a previous space into a new one, which tends to select the reliable unlabeled samples with respect to this setting. Specifically, for each unlabeled image instance, we measure its reliability by calculating the category variations of feature transformation from two different neighborhood variation perspectives and merged them into a unified sample mining criterion deriving from Hellinger distance. Then, those samples keeping stable correlation to their neighboring samples (i.e., having small category variation in distribution) across the successive feature space transformation are automatically received labels and incorporated into the model for incrementally training in terms of classification. Our extensive experiments on standard image classification benchmarks (e.g., Caltech-256 and SUN-397) demonstrate that the proposed framework is capable of effectively mining from large-scale unlabeled images, which boosts image classification performance and achieves promising results compared with other semi-supervised learning methods.","","","10.1109/TCSVT.2017.2710478","State Key Development Program; National Natural Science Foundation of China; Natural Science Foundation of Guangdong Province; Guangdong Science and Technology Program; CCF-Tencent Open Research Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7937922","Cost-effective model;visual classification;deep semi-supervised learning;incremental processing;visual feature learning","Semisupervised learning;Training;Visualization;Data models;Feature extraction;Electronic mail;Machine learning","data mining;feature extraction;image classification;image representation;nearest neighbour methods","fixed feature space;DCS;labeled samples;deep feature learning;feature transformation;reliable unlabeled samples;unlabeled image instance;category variation;unified sample mining criterion;neighboring samples;standard image classification benchmarks;large-scale unlabeled images;image classification performance;deep co-space;cost-effective manner;semisupervised learning paradigm;feature space transformation;neighborhood variation perspectives;visual classification","","","53","","","","","IEEE","IEEE Journals"
"LiftingNet: A Novel Deep Learning Network With Layerwise Feature Learning From Noisy Mechanical Data for Fault Classification","J. Pan; Y. Zi; J. Chen; Z. Zhou; B. Wang","State Key Laboratory for Manufacturing Systems Engineering, Xi'an Jiaotong University, Xi'an, China; State Key Laboratory for Manufacturing Systems Engineering, Xi'an Jiaotong University, Xi'an, China; State Key Laboratory for Manufacturing Systems Engineering, Xi'an Jiaotong University, Xi'an, China; State Key Laboratory for Manufacturing Systems Engineering, Xi'an Jiaotong University, Xi'an, China; National Institute Corporation of Additive Manufacturing, Xi'an, China","IEEE Transactions on Industrial Electronics","","2018","65","6","4973","4982","The key challenge of intelligent fault diagnosis is to develop features that can distinguish different categories. Because of the unique properties of mechanical data, predetermined features based on prior knowledge are usually used as inputs for fault classification. However, proper selection of features often requires expertise knowledge and becomes more difficult and time consuming when volume of data increases. In this paper, a novel deep learning network (LiftingNet) is proposed to learn features adaptively from raw mechanical data without prior knowledge. Inspired by convolutional neural network and second generation wavelet transform, the LiftingNet is constructed to classify mechanical data even though inputs contain considerable noise and randomness. The LiftingNet consists of split layer, predict layer, update layer, pooling layer, and full-connection layer. Different kernel sizes are allowed in convolutional layers to improve learning ability. As a multilayer neural network, deep features are learned from shallow ones to represent complex structures in raw data. Feasibility and effectiveness of the LiftingNet is validated by two motor bearing datasets. Results show that the proposed method could achieve layerwise feature learning and successfully classify mechanical data even with different rotating speed and under the influence of random noise.","","","10.1109/TIE.2017.2767540","National Natural Science Foundation of China; National Basic Research Program of China (973 Program); Shaanxi Industrial Science and Technology Project; Fundamental Research Funds for the Central Universities of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8089430","Convolutional neural network (CNN);deep learning;intelligent fault diagnosis;second generation wavelet transform (SGWT)","Machine learning;Fault diagnosis;Feature extraction;Neural networks;Convolution;Transforms;Support vector machines","fault diagnosis;feature extraction;learning (artificial intelligence);neural nets;wavelet transforms","deep learning network;second generation wavelet transform;SGWT;CNN;convolutional neural network;intelligent fault diagnosis;fault classification;noisy mechanical data;layerwise feature learning;LiftingNet","","19","38","","","","","IEEE","IEEE Journals"
"A Survey of Recommender Systems Based on Deep Learning","R. Mu","College of Computer and Information, Hohai University, Nanjing, China","IEEE Access","","2018","6","","69009","69022","In recent years, deep learning's revolutionary advances in speech recognition, image analysis, and natural language processing have gained significant attention. Deep learning technology has become a hotspot research field in the artificial intelligence and has been applied into recommender system. In contrast to traditional recommendation models, deep learning is able to effectively capture the non-linear and non-trivial user-item relationships and enables the codification of more complex abstractions as data representations in the higher layers. In this paper, we provide a comprehensive review of the related research contents of deep learning-based recommender systems. First, we introduce the basic terminologies and the background concepts of recommender systems and deep learning technology. Second, we describe the main current research on deep learning-based recommender systems. Third, we provide the possible research directions of deep learning-based recommender systems in the future. Finally, concludes this paper.","","","10.1109/ACCESS.2018.2880197","National Key Research and Development Plan Key Projects of China; National Natural Science Foundation of China; Natural Science Foundation of the Colleges and Universities in Jiangsu Province of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8529185","Deep learning;recommender systems;deep learning-based recommender systems;machine learning;terminology","Recommender systems;Collaboration;Feature extraction;Information filters","learning (artificial intelligence);recommender systems","recommender system;deep learning technology;artificial intelligence","","9","111","CCBY","","","","IEEE","IEEE Journals"
"Interactive Spoken Content Retrieval by Deep Reinforcement Learning","H. Lee; P. Chung; Y. Wu; T. Lin; T. Wen","Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan; National Taiwan University, Taipei, Taiwan; Cambridge University, Cambridge, U.K.; Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan; PolyAI, London, U.K.","IEEE/ACM Transactions on Audio, Speech, and Language Processing","","2018","26","12","2447","2459","For text content retrieval, the user can easily scan through and select from a list of retrieved items. This is impossible for spoken content retrieval, because the retrieved items are not easily displayed on-screen. In addition, due to the high degree of uncertainty for speech recognition, retrieval results can be very noisy. One way to counter such difficulties is through user-machine interaction. The machine can take different actions to interact with the user to obtain better retrieval results before showing them to the user. For example, the machine can request extra information from the user, return a list of topics for the user to select from, and so on. In this paper, we propose using deep-Q-network (DQN) to determine the machine actions for interactive spoken content retrieval. DQN bypasses the need to estimate hand-crafted states, and directly determines the best action based on the present retrieval results even without any human knowledge. It is shown to achieve significantly better performance as compared with the previous hand-crafted states. We further find that double DQN and dueling DQN improve the naive version.","","","10.1109/TASLP.2018.2852739","Ministry of Science and Technology, Taiwan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8403313","Spoken content retrieval;user-machine interaction;reinforcement learning;deep-Q-learning","Feature extraction;Learning (artificial intelligence);Multimedia communication;Speech processing;Machine learning;Speech recognition;User interfaces;Reinforcement learning","content-based retrieval;interactive systems;learning (artificial intelligence);speech recognition","hand-crafted states;DQN;deep-Q-network;speech recognition;machine actions;user-machine interaction;retrieval results;retrieved items;text content retrieval;deep reinforcement learning;interactive spoken content retrieval","","","61","","","","","IEEE","IEEE Journals"
"Deep Learning-Based Feature Representation and Its Application for Soft Sensor Modeling With Variable-Wise Weighted SAE","X. Yuan; B. Huang; Y. Wang; C. Yang; W. Gui","College of Information Science and Engineering, Central South University, Changsha, China; Department of Chemical and Materials Engineering, University of Alberta, Edmonton, AB, Canada; College of Information Science and Engineering, Central South University, Changsha, China; College of Information Science and Engineering, Central South University, Changsha, China; College of Information Science and Engineering, Central South University, Changsha, China","IEEE Transactions on Industrial Informatics","","2018","14","7","3235","3243","In modern industrial processes, soft sensors have played an important role for effective process control, optimization, and monitoring. Feature representation is one of the core factors to construct accurate soft sensors. Recently, deep learning techniques have been developed for high-level abstract feature extraction in pattern recognition areas, which also have great potential for soft sensing applications. Hence, deep stacked autoencoder (SAE) is introduced for soft sensor in this paper. As for output prediction purpose, traditional deep learning algorithms cannot extract high-level output-related features. Thus, a novel variable-wise weighted stacked autoencoder (VW-SAE) is proposed for hierarchical output-related feature representation layer by layer. By correlation analysis with the output variable, important variables are identified from other ones in the input layer of each autoencoder. The variables are assigned with different weights accordingly. Then, variable-wise weighted autoencoders are designed and stacked to form deep networks. An industrial application shows that the proposed VW-SAE can give better prediction performance than the traditional multilayer neural networks and SAE.","","","10.1109/TII.2018.2809730","National Natural Science Foundation of China; National Natural Science Foundation of China; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8302941","Deep learning;output prediction;soft sensor;stacked autoencoder (SAE);variable-wise weighted SAE (VW-SAE)","Machine learning;Feature extraction;Informatics;Training;Process control;Data mining;Monitoring","feature extraction;learning (artificial intelligence)","deep learning-based feature representation;deep learning techniques;high-level abstract feature extraction;deep stacked autoencoder;high-level output-related features;novel variable-wise weighted stacked autoencoder;VW-SAE;variable-wise weighted autoencoders;deep networks;soft sensor modeling;hierarchical output-related feature representation;correlation analysis","","30","30","","","","","IEEE","IEEE Journals"
"Deep Learning Image Reconstruction Simulation for Electromagnetic Tomography","J. Xiao; Z. Liu; P. Zhao; Y. Li; J. Huo","College of Electronic and Information Engineering, Beijing Jiaotong University, Beijing, China; College of Electronic and Information Engineering, Beijing Jiaotong University, Beijing, China; College of Electronic and Information Engineering, Beijing Jiaotong University, Beijing, China; College of Electronic and Information Engineering, Beijing Jiaotong University, Beijing, China; College of Electronic and Information Engineering, Beijing Jiaotong University, Beijing, China","IEEE Sensors Journal","","2018","18","8","3290","3298","In the inverse problem of tomography field, the solution of image reconstruction is often ill-posed and the prior information about imaging features is limited. We expect to learn imaging autonomously by learning algorithms and representative samples. So in this paper, two deep learning image reconstruction algorithms SSAE+RBF and optimized fully connected (FC) are proposed to learn imaging in electromagnetic tomography (EMT). It is a preliminary attempt of sample training algorithm in EMT. Furthermore, a loss function is proposed and 30000 image samples for training, verification, and test are designed. Simulation experiments show the following. First, for the 26000 training samples, both of two algorithms have the ability to basically reproduce the actual distribution of object field. Second, for the random 2000 test samples, which has similar type with training sample but doesn't learned, both of the two algorithms are superior to the traditional algorithms in image reconstruction. In addition, the mean value of image correlation coefficient (ICC) and relative image error are 0.817 and 0.530 for optimized FC network without noise. Third, when 0%-7% noise levels are added to the test set, the standard deviation of ICC in two algorithms are 0.007 and 0.040. To a certain extent, it proves the robustness of these networks. Fourth, in addition, our deep learning algorithm has an advantage in computing speed with graphic processing unit.","","","10.1109/JSEN.2018.2809485","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8302596","Electromagnetic tomography;inverse problem;image reconstruction algorithm;deep learning;neural network","Training;Machine learning;Image reconstruction;Tomography;Sensors;Inverse problems","computerised tomography;image reconstruction;image sampling;inverse problems;learning (artificial intelligence);medical image processing;optimisation;radial basis function networks","image reconstruction simulation;electromagnetic tomography;tomography field;representative samples;deep learning image reconstruction algorithms SSAE+RBF;EMT;sample training algorithm;relative image error;deep learning algorithm;deep learning;fully connected optimization","","3","28","","","","","IEEE","IEEE Journals"
"Privacy-Preserving Deep Learning via Additively Homomorphic Encryption","L. T. Phong; Y. Aono; T. Hayashi; L. Wang; S. Moriai","National Institute of Information and Communications Technology, Tokyo, Japan; National Institute of Information and Communications Technology, Tokyo, Japan; National Institute of Information and Communications Technology, Tokyo, Japan; National Institute of Information and Communications Technology, Tokyo, Japan; National Institute of Information and Communications Technology, Tokyo, Japan","IEEE Transactions on Information Forensics and Security","","2018","13","5","1333","1345","We present a privacy-preserving deep learning system in which many learning participants perform neural network-based deep learning over a combined dataset of all, without revealing the participants' local data to a central server. To that end, we revisit the previous work by Shokri and Shmatikov (ACM CCS 2015) and show that, with their method, local data information may be leaked to an honest-but-curious server. We then fix that problem by building an enhanced system with the following properties: 1) no information is leaked to the server and 2) accuracy is kept intact, compared with that of the ordinary deep learning system also over the combined dataset. Our system bridges deep learning and cryptography: we utilize asynchronous stochastic gradient descent as applied to neural networks, in combination with additively homomorphic encryption. We show that our usage of encryption adds tolerable overhead to the ordinary deep learning system.","","","10.1109/TIFS.2017.2787987","Japan Science and Technology Agency CREST; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8241854","Privacy;deep learning;neural network;additively homomorphic encryption;LWE-based encryption;Paillier encryption","Servers;Machine learning;Encryption;Neural networks;Privacy","cryptography;data privacy;gradient methods;learning (artificial intelligence);neural nets;stochastic processes","cryptography;asynchronous stochastic gradient descent;ordinary deep learning system;honest-but-curious server;local data information;central server;neural network;learning participants;privacy-preserving deep learning system;additively homomorphic encryption","","13","28","","","","","IEEE","IEEE Journals"
"Deep Facial Age Estimation Using Conditional Multitask Learning With Weak Label Expansion","B. Yoo; Y. Kwak; Y. Kim; C. Choi; J. Kim","School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Software Solution Laboratory, Samsung Advanced Institute of Technology, Suwon-si, South Korea; Software Solution Laboratory, Samsung Advanced Institute of Technology, Suwon-si, South Korea; Software Solution Laboratory, Samsung Advanced Institute of Technology, Suwon-si, South Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea","IEEE Signal Processing Letters","","2018","25","6","808","812","Accurate age estimation from a facial image is quite challenging, since physical age and apparent age can be quite different, and this difference is dependent on gender, ethnicity, and many other factors. Multitask deep learning is one of the approach to improve age estimation by employing auxiliary tasks, such as gender recognition, that are related to the primary task. However, in traditional multitask learning for age estimation, the relationship between the primary and auxiliary tasks is difficult to describe; how the auxiliary tasks enhance the model for the primary objective is ambiguous. In this letter, we propose a conditional multitask learning method that architecturally factorizes an age variable into gender-conditioned age probabilities in a deep neural network. The lack of accurate training labels with discrete age values is another critical limitation to training age estimation models. Therefore, we propose a label expansion method that increases the number of accurate labels from weakly supervised categorical labels. To verify the generality of the proposed method, we perform intensive experiments on the publicly available MORPH-II and FG-NET datasets. The proposed methods outperform state-of-the art methods in both age estimation and gender recognition accuracy. These performance gains are verified on well-known deep network architectures-VGG-16, CASIA-WebFace, and Alexnet-to confirm the proposed methods generality.","","","10.1109/LSP.2018.2822241","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8329236","Age estimation;conditional multitask (CMT) learning;deep network;gender recognition;label expansion","Estimation;Training;Task analysis;Machine learning;Face;Feature extraction;Face recognition","face recognition;image classification;learning (artificial intelligence);neural nets","deep facial age estimation;weak label expansion;physical age;deep learning;conditional multitask learning method;gender-conditioned age probabilities;deep neural network;training age estimation models;weakly supervised categorical labels;deep network architectures;gender recognition;VGG-16;CASIA-WebFace;Alexnet","","3","42","","","","","IEEE","IEEE Journals"
"A Supervised Learning Algorithm for Learning Precise Timing of Multiple Spikes in Multilayer Spiking Neural Networks","A. Taherkhani; A. Belatreche; Y. Li; L. P. Maguire","Computational Neuroscience and Cognitive Robotics Laboratory, Nottingham Trent University, Nottingham, U.K.; Department of Computer and Information Sciences, Northumbria University, Newcastle upon Tyne, U.K.; School of Computer Science and Informatics, Cardiff University, Cardiff, U.K.; Faculty of Computing and Engineering, Ulster University, Londonderry, U.K.","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","11","5394","5407","There is a biological evidence to prove information is coded through precise timing of spikes in the brain. However, training a population of spiking neurons in a multilayer network to fire at multiple precise times remains a challenging task. Delay learning and the effect of a delay on weight learning in a spiking neural network (SNN) have not been investigated thoroughly. This paper proposes a novel biologically plausible supervised learning algorithm for learning precisely timed multiple spikes in a multilayer SNNs. Based on the spike-timing-dependent plasticity learning rule, the proposed learning method trains an SNN through the synergy between weight and delay learning. The weights of the hidden and output neurons are adjusted in parallel. The proposed learning method captures the contribution of synaptic delays to the learning of synaptic weights. Interaction between different layers of the network is realized through biofeedback signals sent by the output neurons. The trained SNN is used for the classification of spatiotemporal input patterns. The proposed learning method also trains the spiking network not to fire spikes at undesired times which contribute to misclassification. Experimental evaluation on benchmark data sets from the UCI machine learning repository shows that the proposed method has comparable results with classical rate-based methods such as deep belief network and the autoencoder models. Moreover, the proposed method can achieve higher classification accuracies than single layer and a similar multilayer SNN.","","","10.1109/TNNLS.2018.2797801","Ulster University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8305661","Multilayer neural network;spiking neural network (SNN);supervised learning;synaptic delay","Neurons;Delays;Nonhomogeneous media;Encoding;Supervised learning","belief networks;brain;learning (artificial intelligence);neural nets;neurophysiology;pattern classification","learning method;synaptic delays;synaptic weights;trained SNN;spiking network;undesired times;UCI machine learning repository;deep belief network;similar multilayer SNN;learning precise timing;neural networks;multilayer network;multiple precise times;delay learning;weight learning;spiking neural network;novel biologically plausible supervised learning algorithm;learning precisely timed multiple spikes;multilayer SNNs;spike-timing-dependent plasticity learning rule;hidden output neurons","","","55","CCBY","","","","IEEE","IEEE Journals"
"Predicting Microblog Sentiments via Weakly Supervised Multimodal Deep Learning","F. Chen; R. Ji; J. Su; D. Cao; Y. Gao","Fujian Key Laboratory of Sensing and Computing for Smart City, School of Information Science and Engineering, Xiamen University, Xiamen, China; Fujian Key Laboratory of Sensing and Computing for Smart City, School of Information Science and Engineering, Xiamen University, Xiamen, China; School of Software, Xiamen University, Xiamen, China; Fujian Key Laboratory of Sensing and Computing for Smart City, School of Information Science and Engineering, Xiamen University, Xiamen, China; School of Software, Key Laboratory for Information System Security, Ministry of Education (KLISS), Tsinghua University, Beijing, China","IEEE Transactions on Multimedia","","2018","20","4","997","1007","Predicting sentiments of multimodal microblogs composed of text, image, and emoticon have attracted ever-increasing research focus recently. The key challenge lies in the difficulty of collecting a sufficient amount of training labels to train a discriminative model for multimodal prediction. One potential solution is to exploit the labels collected from social media users, which is, however, restricted by the negative effect of label noise. Besides, we have quantitatively found that sentiments in different modalities may be independent, which disables the usage of previous multimodal sentiment analysis schemes in our problem. In this paper, we introduce a weakly supervised multimodal deep learning (WS-MDL) scheme toward robust and scalable sentiment prediction. WS-MDL learns convolutional neural networks iteratively and selectively from “weak” emoticon labels, which are cheaply available and noise containing. In particular, to filter out the label noise and to capture the modality dependency, a probabilistic graphical model is introduced to simultaneously learn discriminative multimodal descriptors and infer the confidence of label noise. Extensive evaluations are conducted in a million-scale, real-world microblog sentiment dataset crawled from Sina Weibo. We have validated the merits of the proposed scheme by quantitatively showing its superior performance over several state-of-the-art and alternative approaches.","","","10.1109/TMM.2017.2757769","National Key R&D Program of China; Nature Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8052551","Sentiment prediction;weakly supervised learning;multi-modality;deep learning","Visualization;Machine learning;Noise measurement;Social network services;Sentiment analysis;Neural networks;Supervised learning","feedforward neural nets;graph theory;learning (artificial intelligence);probability;sentiment analysis;social networking (online)","probabilistic graphical model;real-world microblog sentiment dataset;multimodal microblogs;discriminative model;multimodal prediction;social media users;weakly supervised multimodal deep learning scheme;robust sentiment prediction;scalable sentiment prediction;weak emoticon labels;multimodal sentiment analysis;microblog sentiment prediction;convolutional neural networks;modality dependency;discriminative multimodal descriptors learning;Sina Weibo","","1","48","","","","","IEEE","IEEE Journals"
"Large Margin Learning in Set-to-Set Similarity Comparison for Person Reidentification","S. Zhou; J. Wang; R. Shi; Q. Hou; Y. Gong; N. Zheng","Institute of Artificial Intelligence and Robotics, Xi'an Jiaotong University, Xi'an, China; Institute of Artificial Intelligence and Robotics, Xi'an Jiaotong University, Xi'an, China; Institute of Artificial Intelligence and Robotics, Xi'an Jiaotong University, Xi'an, China; Institute of Artificial Intelligence and Robotics, Xi'an Jiaotong University, Xi'an, China; Institute of Artificial Intelligence and Robotics, Xi'an Jiaotong University, Xi'an, China; Institute of Artificial Intelligence and Robotics, Xi'an Jiaotong University, Xi'an, China","IEEE Transactions on Multimedia","","2018","20","3","593","604","Person reidentification aims at matching images of the same person across disjoint camera views, which is a challenging problem in multimedia analysis, multimedia editing, and content-based media retrieval communities. The major challenge lies in how to preserve similarity of the same person across video footages with large appearance variations, while discriminating different individuals. To address this problem, conventional methods usually consider the pairwise similarity between persons by only measuring the point-to-point distance. In this paper, we propose using a deep learning technique to model a novel set-to-set (S2S) distance, in which the underline objective focuses on preserving the compactness of intraclass samples for each camera view, while maximizing the margin between the intraclass set and interclass set. The S2S distance metric consists of three terms, namely, the class-identity term, the relative distance term, and the regularization term. The class-identity term keeps the intraclass samples within each camera view gathering together, the relative distance term maximizes the distance between the intraclass class set and interclass set across different camera views, and the regularization term smoothes the parameters of the deep convolutional neural network. As a result, the final learned deep model can effectively find out the matched target to the probe object among various candidates in the video gallery by learning discriminative and stable feature representations. Using the CUHK01, CUHK03, PRID2011, and Market1501 benchmark datasets, we extensively conducted comparative evaluations to demonstrate the advantages of our method over the state-of-the-art approaches.","","","10.1109/TMM.2017.2755983","National Science Foundation of China; National Key Research and Development Program of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8048520","Person re-identification;set to set similarity comparison;metric learning;deep learning","Feature extraction;Measurement;Cameras;Robustness;Learning systems;Machine learning;Neural networks","image matching;learning (artificial intelligence);neural nets;object recognition;optimisation;pedestrians","margin learning;set-to-set similarity comparison;person reidentification;matching images;disjoint camera views;multimedia analysis;multimedia editing;media retrieval communities;video footages;appearance variations;different individuals;pairwise similarity;point-to-point distance;deep learning technique;underline objective;intraclass samples;camera view;intraclass set;class-identity term;relative distance term;regularization term;intraclass class set;deep convolutional neural network;final learned deep model;matched target","","8","59","","","","","IEEE","IEEE Journals"
"A Deep Learning Approach to Network Intrusion Detection","N. Shone; T. N. Ngoc; V. D. Phai; Q. Shi","Department of Computer Science, Liverpool John Moores University, Liverpool, U.K.; Hanoi 100000, Vietnam; Hanoi 100000, Vietnam; Department of Computer Science, Liverpool John Moores University, Liverpool, U.K.","IEEE Transactions on Emerging Topics in Computational Intelligence","","2018","2","1","41","50","Network intrusion detection systems (NIDSs) play a crucial role in defending computer networks. However, there are concerns regarding the feasibility and sustainability of current approaches when faced with the demands of modern networks. More specifically, these concerns relate to the increasing levels of required human interaction and the decreasing levels of detection accuracy. This paper presents a novel deep learning technique for intrusion detection, which addresses these concerns. We detail our proposed nonsymmetric deep autoencoder (NDAE) for unsupervised feature learning. Furthermore, we also propose our novel deep learning classification model constructed using stacked NDAEs. Our proposed classifier has been implemented in graphics processing unit (GPU)-enabled TensorFlow and evaluated using the benchmark KDD Cup '99 and NSL-KDD datasets. Promising results have been obtained from our model thus far, demonstrating improvements over existing approaches and the strong potential for use in modern NIDSs.","","","10.1109/TETCI.2017.2772792","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8264962","Deep learning;anomaly detection;auto-encoders;KDD;network security","Machine learning;Intrusion detection;Anomaly detection;Training data;Communication networks;Monitoring","computer network security;graphics processing units;pattern classification;unsupervised learning","network intrusion detection systems;computer networks;deep learning technique;nonsymmetric deep autoencoder;NDAE;unsupervised feature learning;deep learning classification model;TensorFlow;GPU;graphics processing unit;NIDSs","","47","38","","","","","IEEE","IEEE Journals"
"Matching Software-Generated Sketches to Face Photographs With a Very Deep CNN, Morphed Faces, and Transfer Learning","C. Galea; R. A. Farrugia","Department of Communications and Computer Engineering, University of Malta, Msida, Malta; Department of Communications and Computer Engineering, University of Malta, Msida, Malta","IEEE Transactions on Information Forensics and Security","","2018","13","6","1421","1431","Sketches obtained from eyewitness descriptions of criminals have proven to be useful in apprehending criminals, particularly when there is a lack of evidence. Automated methods to identify subjects depicted in sketches have been proposed in the literature, but their performance is still unsatisfactory when using software-generated sketches and when tested using extensive galleries with a large amount of subjects. Despite the success of deep learning in several applications including face recognition, little work has been done in applying it for face photograph-sketch recognition. This is mainly a consequence of the need to ensure robust training of deep networks by using a large number of images, yet limited quantities are publicly available. Moreover, most algorithms have not been designed to operate on software-generated face composite sketches which are used by numerous law enforcement agencies worldwide. This paper aims to tackle these issues with the following contributions: 1) a very deep convolutional neural network is utilised to determine the identity of a subject in a composite sketch by comparing it to face photographs and is trained by applying transfer learning to a state-of-the-art model pretrained for face photograph recognition; 2) a 3-D morphable model is used to synthesise both photographs and sketches to augment the available training data, an approach that is shown to significantly aid performance; and 3) the UoM-SGFS database is extended to contain twice the number of subjects, now having 1200 sketches of 600 subjects. An extensive evaluation of popular and state-of-the-art algorithms is also performed due to the lack of such information in the literature, where it is demonstrated that the proposed approach comprehensively outperforms state-of-the-art methods on all publicly available composite sketch datasets.","","","10.1109/TIFS.2017.2788002","Malta Government Scholarship Scheme; NVIDIA Corporation through the donation of a Titan X Pascal GPU; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8241712","Deep learning;convolutional neural network;software-generated composite sketches;face photos;morphological model;augmentation;database","Face;Face recognition;Databases;Algorithm design and analysis;Feature extraction;Machine learning","face recognition;learning (artificial intelligence);neural nets","matching software-generated sketches;face photographs;deep CNN;transfer learning;deep learning;face photograph-sketch recognition;deep networks;face composite sketches;deep convolutional neural network;face photograph recognition;available training data;face recognition;composite sketch datasets","","2","53","","","","","IEEE","IEEE Journals"
"Deep Multi-View Feature Learning for Person Re-Identification","D. Tao; Y. Guo; B. Yu; J. Pang; Z. Yu","School of Information Science and Engineering, Yunnan University, Kumming, China; School of Mathematics and Statistics, Yunnan University, Kumming, China; UBTech Sydney Artificial Intelligence Institute; UBTECH Robotics, Shenzhen, China; School of Information Engineering and Automation, Kunming University of Science and Technology, Kunming, China","IEEE Transactions on Circuits and Systems for Video Technology","","2018","28","10","2657","2666","Person re-identification aims to identify the same pedestrians across different camera views at different locations. This important yet difficult intelligent video analysis problem remains a vigorous area of research due to demands for performance improvements. Person re-identification involves two main steps: feature representation and metric learning. Handcrafted features, such as color and texture histograms, are frequently used for person re-identification, but most handcrafted features are limited by not being directly applicable to practical problems. Deep learning methods have obtained the state-of-the-art performance in a wide variety of applications, including image annotation, face recognition, and speech recognition. However, deep learning features are heavily dependent on large-scale labeling of samples. In this paper, by utilizing the Cross-view Quadratic Discriminant Analysis (XQDA) metric learning, we propose a novel scheme called deep multi-view feature learning (DMVFL), which exploits the collaboration between handcrafted and deep learning features in a simple but effective way. Furthermore, we prove that the XQDA is a robust algorithm. Extensive experiments on two challenging person re-identification data sets (VIPeR and GRID) demonstrate that DMVFL improves on current state-of-the-art methods.","","","10.1109/TCSVT.2017.2726580","National Natural Science Foundation of China; Yunnan Natural Science Funds; Guangdong Natural Science Funds; Yunnan University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7979595","Person re-identification;multi-view;deep learning;intelligent video analysis","Feature extraction;Measurement;Image color analysis;Machine learning;Robustness;Collaboration;Electronic mail","face recognition;feature extraction;image representation;image texture;learning (artificial intelligence);video surveillance","cross-view quadratic discriminant analysis;deep multiview feature learning;XQDA metric learning;DMVFL;GRID;VIPeR;robust algorithm;intelligent video analysis problem;person re-identification data sets;camera views;deep learning features;handcrafted features;feature representation;performance improvements","","6","67","","","","","IEEE","IEEE Journals"
"Predicting Hospital Readmission via Cost-Sensitive Deep Learning","H. Wang; Z. Cui; Y. Chen; M. Avidan; A. B. Abdallah; A. Kronzer","Department of Computer Science and Engineering, Washington University in St. Louis, St. Louis, MO; Department of Computer Science and Engineering, Washington University in St. Louis, St. Louis, MO; Department of Computer Science and Engineering, Washington University in St. Louis, St. Louis, MO; Department of Anesthesiology, Washington University School of Medicine, St. Louis, MO; Department of Anesthesiology, Washington University School of Medicine, St. Louis, MO; Department of Anesthesiology, Washington University School of Medicine, St. Louis, MO","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2018","15","6","1968","1978","With increased use of electronic medical records (EMRs), data mining on medical data has great potential to improve the quality of hospital treatment and increase the survival rate of patients. Early readmission prediction enables early intervention, which is essential to preventing serious or life-threatening events, and act as a substantial contributor to reduce healthcare costs. Existing works on predicting readmission often focus on certain vital signs and diseases by extracting statistical features. They also fail to consider skewness of class labels in medical data and different costs of misclassification errors. In this paper, we recur to the merits of convolutional neural networks (CNN) to automatically learn features from time series of vital sign, and categorical feature embedding to effectively encode feature vectors with heterogeneous clinical features, such as demographics, hospitalization history, vital signs, and laboratory tests. Then, both learnt features via CNN and statistical features via feature embedding are fed into a multilayer perceptron (MLP) for prediction. We use a cost-sensitive formulation to train MLP during prediction to tackle the imbalance and skewness challenge. We validate the proposed approach on two real medical datasets from Barnes-Jewish Hospital, and all data is taken from historical EMR databases and reflects the kinds of data that would realistically be available at the clinical prediction system in hospitals. We find that early prediction of readmission is possible and when compared with state-of-the-art existing methods used by hospitals, our methods perform significantly better. For example, using the general hospital wards data for 30-day readmission prediction, the area under the curve (AUC) for the proposed model was 0.70, significantly higher than all the baseline methods. Based on these results, a system is being deployed in hospital settings with the proposed forecasting algorithms to support treatment.","","","10.1109/TCBB.2018.2827029","US National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8338085","Readmission prediction;deep learning;electronic medical records;cost-sensitive;categorical feature embedding","Feature extraction;Hospitals;Time series analysis;Prediction algorithms;Machine learning;Data models;Electronic medical records;Deep learning;Machine learning","convolution;data mining;diseases;electronic health records;feature extraction;health care;hospitals;learning (artificial intelligence);medical computing;multilayer perceptrons;pattern classification;statistical analysis;time series","CNN;feature embedding;MLP;cost-sensitive formulation;medical datasets;Barnes-Jewish Hospital;historical EMR databases;clinical prediction system;cost-sensitive deep learning;data mining;medical data;hospital treatment;life-threatening events;substantial contributor;healthcare costs;misclassification errors;convolutional neural networks;hospitalization history;statistical features extraction;hospital readmission prediction;electronic medical records;diseases;time series;demographics;laboratory tests;multilayer perceptron;AUC;forecasting algorithms;heterogeneous clinical features vectors;skewness class labels;hospital wards data","","3","32","","","","","IEEE","IEEE Journals"
"Deep Cascade Learning","E. S. Marquez; J. S. Hare; M. Niranjan","Department of Electronics and Computer Science, University of Southampton, Southampton, U.K.; Department of Electronics and Computer Science, University of Southampton, Southampton, U.K.; Department of Electronics and Computer Science, University of Southampton, Southampton, U.K.","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","11","5475","5485","In this paper, we propose a novel approach for efficient training of deep neural networks in a bottom-up fashion using a layered structure. Our algorithm, which we refer to as deep cascade learning, is motivated by the cascade correlation approach of Fahlman and Lebiere, who introduced it in the context of perceptrons. We demonstrate our algorithm on networks of convolutional layers, though its applicability is more general. Such training of deep networks in a cascade directly circumvents the well-known vanishing gradient problem by ensuring that the output is always adjacent to the layer being trained. We present empirical evaluations comparing our deep cascade training with standard end-end training using back propagation of two convolutional neural network architectures on benchmark image classification tasks (CIFAR-10 and CIFAR-100). We then investigate the features learned by the approach and find that better, domain-specific, representations are learned in early layers when compared to what is learned in end-end training. This is partially attributable to the vanishing gradient problem that inhibits early layer filters to change significantly from their initial settings. While both networks perform similarly overall, recognition accuracy increases progressively with each added layer, with discriminative features learned in every stage of the network, whereas in end-end training, no such systematic feature representation was observed. We also show that such cascade training has significant computational and memory advantages over end-end training, and can be used as a pretraining algorithm to obtain a better performance.","","","10.1109/TNNLS.2018.2805098","University of Southampton; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8307262","Adaptive learning;cascade correlation;convolutional neural networks (CNNs);deep learning;image classification","Training;Computer architecture;Correlation;Convolutional codes;Backpropagation;Convolution;Complexity theory","backpropagation;cascade systems;convolution;feature extraction;feedforward neural nets;gradient methods;image classification;image representation;perceptrons","deep cascade learning;deep neural networks;layered structure;cascade correlation approach;convolutional layers;vanishing gradient problem;deep cascade training;convolutional neural network architectures;layer filters;bottom-up fashion;perceptrons;back propagation;image classification tasks;recognition accuracy;systematic feature representation;end-end training","","1","35","CCBY","","","","IEEE","IEEE Journals"
"VLocNet++: Deep Multitask Learning for Semantic Visual Localization and Odometry","N. Radwan; A. Valada; W. Burgard","Department of Computer Science, University of Freiburg, Freiburg im Breisgau, Germany; Department of Computer Science, University of Freiburg, Freiburg im Breisgau, Germany; Department of Computer Science, University of Freiburg, Freiburg im Breisgau, Germany","IEEE Robotics and Automation Letters","","2018","3","4","4407","4414","Semantic understanding and localization are fundamental enablers of robot autonomy that have been tackled as disjoint problems for the most part. While deep learning has enabled recent breakthroughs across a wide spectrum of scene understanding tasks, its applicability to state estimation tasks has been limited due to the direct formulation that renders it incapable of encoding scene-specific constrains. In this letter, we propose the VLocNet++ architecture that employs a multitask learning approach to exploit the inter-task relationship between learning semantics, regressing 6-DoF global pose and odometry, for the mutual benefit of each of these tasks. Our network overcomes the aforementioned limitation by simultaneously embedding geometric and semantic knowledge of the world into the pose regression network. We propose a novel adaptive weighted fusion layer to aggregate motion-specific temporal information and to fuse semantic features into the localization stream based on region activations. Furthermore, we propose a self-supervised warping technique that uses the relative motion to warp intermediate network representations in the segmentation stream for learning consistent semantics. Finally, we introduce a first-of-a-kind urban outdoor localization dataset with pixel-level semantic labels and multiple loops for training deep networks. Extensive experiments on the challenging Microsoft 7-Scenes benchmark and our DeepLoc dataset demonstrate that our approach exceeds the state-of-the-art outperforming local feature-based methods while simultaneously performing multiple tasks and exhibiting substantial robustness in challenging scenarios.","","","10.1109/LRA.2018.2869640","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8458420","Deep learning in robotics and automation;visual learning;localization","Semantics;Task analysis;Image segmentation;Visualization;Streaming media;Adaptation models;Motion segmentation","feature extraction;image resolution;learning (artificial intelligence);mobile robots;regression analysis;robot vision;state estimation","deep multitask;semantic visual localization;odometry;fundamental enablers;robot autonomy;disjoint problems;deep learning;wide spectrum;scene understanding tasks;state estimation tasks;direct formulation;VLocNet++ architecture;multitask learning approach;inter-task relationship;learning semantics;6-DoF global pose;geometric knowledge;semantic knowledge;pose regression network;novel adaptive weighted fusion layer;motion-specific temporal information;semantic features;localization stream;self-supervised warping technique;relative motion;warp intermediate network representations;segmentation stream;consistent semantics;pixel-level semantic labels;deep networks;exhibiting substantial robustness;scene-specific constrains;urban outdoor localization dataset;Microsoft 7-Scenes benchmark;local feature-based methods","","5","24","","","","","IEEE","IEEE Journals"
"Sparse Deep Stacking Network for Fault Diagnosis of Motor","C. Sun; M. Ma; Z. Zhao; X. Chen","School of Mechanical Engineering, Xi'an Jiaotong University, Xi'an, China; School of Mechanical Engineering, Xi'an Jiaotong University, Xi'an, China; School of Mechanical Engineering, Xi'an Jiaotong University, Xi'an, China; School of Mechanical Engineering, Xi'an Jiaotong University, Xi'an, China","IEEE Transactions on Industrial Informatics","","2018","14","7","3261","3270","A sparse deep learning method is proposed to overcome overfitting risk of deep networks with a large number of nodes and layers. Deep stacking network (DSN) is a classic and effective deep learning method, and its sparse form is presented to generate the sparse deep learning method. In DSN, output labels are encoded as a series consisted of 1 and 0. This coding strategy makes output labels to be sparse. However, sparsity of output labels is not considered in DSN model. Considering this limitation, sparse DSN (SDSN) is developed in this paper. The SDSN extends tradition DSN in sparsity characterization using a sparse regularization term. By this term, predicted output label is constrained to be similar with ideal output label that is binary and consisted of continuous 1 and 0 with a sidestep shape. The sparse regularization term is used as a soft threshold strategy to set irrelevant element to be zero, by which effectiveness of SDSN is enhanced. Case studies about fault diagnosis of motor are used to validate performance of SDSN. Comparison between SDSN and commonly used deep networks is further conducted. The results show advance of SDSN for fault classification.","","","10.1109/TII.2018.2819674","National Key Basic Program of China; National Natural Science Foundation of China; Postdoctoral Science Foundation of China; Fundamental Research Funds for the Central Universities; Absorb Outcome Transformation Project of Science and Technology Department in Shaanxi Province of China; National Key Research Development Program of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8325506","Deep stacking network (DSN);kernel method;motor fault diagnosis;sparse deep learning;sparse regularization","Fault diagnosis;Stacking;Machine learning;Induction motors;Kernel;Feature extraction;Sun","electric motors;fault diagnosis;learning (artificial intelligence);mechanical engineering computing;neural nets","sparse deep stacking network;fault diagnosis;sparse deep learning method;deep networks;DSN model;sparse DSN;SDSN;sparse regularization term;deep learning method;fault classification","","25","31","","","","","IEEE","IEEE Journals"
"Seamless Integration and Coordination of Cognitive Skills in Humanoid Robots: A Deep Learning Approach","J. Hwang; J. Tani","School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea","IEEE Transactions on Cognitive and Developmental Systems","","2018","10","2","345","358","This paper investigates how adequate coordination among the different cognitive processes of a humanoid robot can be developed through end-to-end learning of direct perception of visuomotor stream. We propose a deep dynamic neural network model built on a dynamic vision network, a motor generation network, and a higher-level network. The proposed model was designed to process and to integrate direct perception of dynamic visuomotor patterns in a hierarchical model characterized by different spatial and temporal constraints imposed on each level. We conducted synthetic robotic experiments in which a robot learned to read human's intention through observing the gestures and then to generate the corresponding goal-directed actions. Results verify that the proposed model is able to learn the tutored skills and to generalize them to novel situations. The model showed synergic coordination of perception, action, and decision making, and it integrated and coordinated a set of cognitive skills including visual perception, intention reading, attention switching, working memory, action preparation, and execution in a seamless manner. Analysis reveals that coherent internal representations emerged at each level of the hierarchy. Higher-level representation reflecting actional intention developed by means of continuous integration of the lower-level visuo-proprioceptive stream.","","","10.1109/TCDS.2017.2714170","National Research Foundation of Korea through the Korea Government (MSIP); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7945519","Deep learning;neurorobotics;sensorimotor learning","Robot kinematics;Machine learning;Robot sensing systems;Neural networks;Computational modeling;Humanoid robots","cognition;cognitive systems;decision making;humanoid robots;learning (artificial intelligence);neural nets;neurophysiology;visual perception","hierarchical model;different spatial constraints;temporal constraints;synthetic robotic experiments;tutored skills;cognitive skills;visual perception;intention reading;action preparation;seamless manner;higher-level representation;actional intention;continuous integration;humanoid robot;deep learning approach;adequate coordination;different cognitive processes;end-to-end learning;direct perception;visuomotor stream;deep dynamic neural network model;dynamic vision network;motor generation network;higher-level network;dynamic visuomotor patterns;lower-level network;lower-level visuo-proprioceptive stream","","1","53","","","","","IEEE","IEEE Journals"
"Survey on encoding schemes for genomic data representation and feature learning—from signal processing to machine learning","N. Yu; Z. Li; Z. Yu","Department of Computing Sciences, College at Brockport, State University of New York, Brockport, NY 14422, USA; Department of Computer Science and Technology at Jiangnan University, Wuxi 214122, China; School of Information Science and Technology, Southwest Jiaotong University, Chengdu 611756, China.","Big Data Mining and Analytics","","2018","1","3","191","210","Data-driven machine learning, especially deep learning technology, is becoming an important tool for handling big data issues in bioinformatics. In machine learning, DNA sequences are often converted to numerical values for data representation and feature learning in various applications. Similar conversion occurs in Genomic Signal Processing (GSP), where genome sequences are transformed into numerical sequences for signal extraction and recognition. This kind of conversion is also called encoding scheme. The diverse encoding schemes can greatly affect the performance of GSP applications and machine learning models. This paper aims to collect, analyze, discuss, and summarize the existing encoding schemes of genome sequence particularly in GSP as well as other genome analysis applications to provide a comprehensive reference for the genomic data representation and feature learning in machine learning.","","","10.26599/BDMA.2018.9020018","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8361572","encoding scheme; data representation; feature learning; deep learning; genomic signal processing;machine learning; genome analysis","Encoding;Bioinformatics;Genomics;Machine learning;DNA;Atomic measurements;Thermodynamics","Big Data;bioinformatics;DNA;genomics;learning (artificial intelligence)","encoding scheme;data-driven machine learning;deep learning technology;DNA sequences;genome sequence;numerical sequences;signal extraction;genome analysis applications;genomic data representation;signal recognition;feature learning;genomic signal processing;GSP applications","","3","","","","","","TUP","TUP Journals"
"Threat of Adversarial Attacks on Deep Learning in Computer Vision: A Survey","N. Akhtar; A. Mian","Department of Computer Science and Software Engineering, The University of Western Australia, Crawley, WA, Australia; Department of Computer Science and Software Engineering, The University of Western Australia, Crawley, WA, Australia","IEEE Access","","2018","6","","14410","14430","Deep learning is at the heart of the current rise of artificial intelligence. In the field of computer vision, it has become the workhorse for applications ranging from self-driving cars to surveillance and security. Whereas, deep neural networks have demonstrated phenomenal success (often beyond human capabilities) in solving complex problems, recent studies show that they are vulnerable to adversarial attacks in the form of subtle perturbations to inputs that lead a model to predict incorrect outputs. For images, such perturbations are often too small to be perceptible, yet they completely fool the deep learning models. Adversarial attacks pose a serious threat to the success of deep learning in practice. This fact has recently led to a large influx of contributions in this direction. This paper presents the first comprehensive survey on adversarial attacks on deep learning in computer vision. We review the works that design adversarial attacks, analyze the existence of such attacks and propose defenses against them. To emphasize that adversarial attacks are possible in practical conditions, we separately review the contributions that evaluate adversarial attacks in the real-world scenarios. Finally, drawing on the reviewed literature, we provide a broader outlook of this research direction.","","","10.1109/ACCESS.2018.2807385","ARC; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8294186","Deep learning;adversarial perturbation;black-box attack;white-box attack;adversarial learning;perturbation detection","Machine learning;Perturbation methods;Computer vision;Computational modeling;Neural networks;Task analysis;Predictive models","computer vision;humanities;learning (artificial intelligence);neural nets","adversarial attacks;artificial intelligence;self-driving cars;deep learning models;deep neural networks;computer vision","","51","186","","","","","IEEE","IEEE Journals"
"TensorLightning: A Traffic-Efficient Distributed Deep Learning on Commodity Spark Clusters","S. Lee; H. Kim; J. Park; J. Jang; C. Jeong; S. Yoon","Department of Electrical and Computer Engineering, Seoul National University, Seoul, South Korea; Department of Electrical and Computer Engineering, Seoul National University, Seoul, South Korea; Element AI, Montreal, QC, Canada; Department of Electrical and Computer Engineering, Seoul National University, Seoul, South Korea; Department of Electrical Engineering, Korea University, Seoul, South Korea; Department of Electrical and Computer Engineering, Seoul National University, Seoul, South Korea","IEEE Access","","2018","6","","27671","27680","With the recent success of deep learning, the amount of data and computation continues to grow daily. Hence a distributed deep learning system that shares the training workload has been researched extensively. Although a scale-out distributed environment using commodity servers is widely used, not only is there a limit due to synchronous operation and communication traffic but also combining deep neural network (DNN) training with existing clusters often demands additional hardware and migration between different cluster frameworks or libraries, which is highly inefficient. Therefore, we propose TensorLightning which integrates the widely used data pipeline of Apache Spark with powerful deep learning libraries, Caffe and TensorFlow. TensorLightning embraces a brand-new parameter aggregation algorithm and parallel asynchronous parameter managing schemes to relieve communication discrepancies and overhead. We redesign the elastic averaging stochastic gradient descent algorithm with pruned and sparse form parameters. Our approach provides the fast and flexible DNN training with high accessibility. We evaluated our proposed framework with convolutional neural network and recurrent neural network models; the framework reduces network traffic by 67% with faster convergence.","","","10.1109/ACCESS.2018.2842103","National Research Foundation of Korea; Projects for Research and Development of Police Science and Technology under the Center for Research and Development of Police Science and Technology and the Korean National Police Agency through the Korean Government, MSIT; Institute for Information & Communications Technology Promotion through the Korea Government, MSIT; Brain Korea 21 Plus Project (Electrical and Computer Engineering, Seoul National University) in 2018; Ministry of Trade, Industry and Energy; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8369060","TensorLightning;deep learning;Apache Spark;distributed system;commodity servers","Sparks;Machine learning;Training;Computational modeling;Clustering algorithms;Government;Servers","feedforward neural nets;image classification;learning (artificial intelligence);pattern clustering;recurrent neural nets;stochastic processes","network traffic;TensorLightning;commodity Spark clusters;scale-out distributed environment;commodity servers;synchronous operation;communication traffic;deep neural network training;Apache Spark;asynchronous parameter managing schemes;communication discrepancies;elastic averaging stochastic gradient descent algorithm;sparse form parameters;convolutional neural network;recurrent neural network models;parameter aggregation algorithm;traffic-efficient distributed deep learning;DNN training;deep learning libraries;training workload","","1","29","","","","","IEEE","IEEE Journals"
"Deep Learning Approach Combining Sparse Autoencoder With SVM for Network Intrusion Detection","M. Al-Qatf; Y. Lasheng; M. Al-Habib; K. Al-Sabahi","School of Information Science and Engineering, Central South University, Changsha, China; School of Information Science and Engineering, Central South University, Changsha, China; School of Information Science and Engineering, Central South University, Changsha, China; School of Information Science and Engineering, Central South University, Changsha, China","IEEE Access","","2018","6","","52843","52856","Network intrusion detection systems (NIDSs) provide a better solution to network security than other traditional network defense technologies, such as firewall systems. The success of NIDS is highly dependent on the performance of the algorithms and improvement methods used to increase the classification accuracy and decrease the training and testing times of the algorithms. We propose an effective deep learning approach, self-taught learning (STL)-IDS, based on the STL framework. The proposed approach is used for feature learning and dimensionality reduction. It reduces training and testing time considerably and effectively improves the prediction accuracy of support vector machines (SVM) with regard to attacks. The proposed model is built using the sparse autoencoder mechanism, which is an effective learning algorithm for reconstructing a new feature representation in an unsupervised manner. After the pre-training stage, the new features are fed into the SVM algorithm to improve its detection capability for intrusion and classification accuracy. Moreover, the efficiency of the approach in binary and multiclass classification is studied and compared with that of shallow classification methods, such as J48, naive Bayesian, random forest, and SVM. Results show that our approach has accelerated SVM training and testing times and performed better than most of the previous approaches in terms of performance metrics in binary and multiclass classification. The proposed STL-IDS approach improves network intrusion detection and provides a new research method for intrusion detection.","","","10.1109/ACCESS.2018.2869577","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8463474","Network security;network intrusion detection system;deep learning;sparse autoencoder;SVM;self-taught learning;NSL-KDD","Support vector machines;Machine learning;Intrusion detection;Feature extraction;Training;Computational modeling;Classification algorithms","compressed sensing;feature extraction;pattern classification;security of data;support vector machines;unsupervised learning","SVM training;binary classification;multiclass classification;STL-IDS approach;network intrusion detection systems;network security;classification accuracy;feature learning;sparse autoencoder mechanism;feature representation;SVM algorithm;unsupervised learning;support vector machines;self-taught learning-IDS;deep learning approach;network defense technologies;learning algorithm","","11","44","","","","","IEEE","IEEE Journals"
"Automatic Bridge Bidding Using Deep Reinforcement Learning","C. Yeh; C. Hsieh; H. Lin","Department of Machine Learning, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Computer Science and Information Engineering, National Taiwan University, Taipei, Taiwan; Department of Computer Science and Information Engineering, National Taiwan University, Taipei, Taiwan","IEEE Transactions on Games","","2018","10","4","365","377","Bridge is among the zero-sum games for which artificial intelligence has not yet outperformed expert human players. The main difficulty lies in the bidding phase of bridge, which requires cooperative decision making with partial information. Existing artificial intelligence systems for bridge bidding rely on, and are thus restricted by, human-designed bidding systems or features. In this work, we propose a flexible and pioneering bridge-bidding system, which can learn either with or without the aid of human domain knowledge. The system is based on a novel deep reinforcement learning model, which extracts sophisticated features and learns to bid automatically based on raw card data. The model includes an upper-confidence-bound algorithm and additional techniques to achieve a balance between exploration and exploitation. We further study how different pieces of human knowledge can be exploited to assist the model. Our experiments demonstrate the promising performance of our proposed model. In particular, the model can advance from having no knowledge on bidding to achieving a superior performance compared with a champion-winning computer bridge program that implements a human-designed bidding system. In addition, further synergies can be extracted by incorporating expert knowledge into the proposed model.","","","10.1109/TG.2018.2866036","Air Force Office of Scientific Research; Asian Office of Aerospace Research and Development; Ministry of Science and Technology of Taiwan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8438937","Bridge;deep reinforcement learning;partial information games;Q-learning","Bridges;Games;Contracts;Machine learning;Feature extraction;Computational modeling","computer games;decision making;game theory;learning (artificial intelligence)","automatic bridge bidding;zero-sum games;artificial intelligence systems;human-designed bidding systems;flexible bridge-bidding system;human domain knowledge;deep reinforcement learning model;upper-confidence-bound algorithm;champion-winning computer bridge program;cooperative decision making","","1","25","","","","","IEEE","IEEE Journals"
"Confidence-Based Data Association and Discriminative Deep Appearance Learning for Robust Online Multi-Object Tracking","S. Bae; K. Yoon","Department of Computer Science and Engineering, Incheon National University, South Korea; School of Information and Communications, Gwangju Institute of Science and Technology, Buk-Gu, Gwangju, South Korea","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","3","595","610","Online multi-object tracking aims at estimating the tracks of multiple objects instantly with each incoming frame and the information provided up to the moment. It still remains a difficult problem in complex scenes, because of the large ambiguity in associating multiple objects in consecutive frames and the low discriminability between objects appearances. In this paper, we propose a robust online multi-object tracking method that can handle these difficulties effectively. We first define the tracklet confidence using the detectability and continuity of a tracklet, and decompose a multi-object tracking problem into small subproblems based on the tracklet confidence. We then solve the online multi-object tracking problem by associating tracklets and detections in different ways according to their confidence values. Based on this strategy, tracklets sequentially grow with online-provided detections, and fragmented tracklets are linked up with others without any iterative and expensive association steps. For more reliable association between tracklets and detections, we also propose a deep appearance learning method to learn a discriminative appearance model from large training datasets, since the conventional appearance learning methods do not provide rich representation that can distinguish multiple objects with large appearance variations. In addition, we combine online transfer learning for improving appearance discriminability by adapting the pre-trained deep model during online tracking. Experiments with challenging public datasets show distinct performance improvement over other state-of-the-arts batch and online tracking methods, and prove the effect and usefulness of the proposed methods for online multi-object tracking.","","","10.1109/TPAMI.2017.2691769","ICT R& D program of MSIP/IITP; Development of High Performance Visual BigData Discovery Platform; National Research Foundation of Korea (NRF); Korea government (MSIP); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7893777","Multi-object tracking;tracking-by-detection;tracklet confidence;confidence-based data association;deep appearance learning;online transfer learning;surveillance system","Target tracking;Robustness;Learning systems;Adaptation models;Trajectory;Machine learning","iterative methods;learning (artificial intelligence);object tracking;sensor fusion","discriminative deep appearance learning;robust online multiobject tracking method;Confidence-based data association;iterative association steps","","30","58","","","","","IEEE","IEEE Journals"
"Supervised Speech Separation Based on Deep Learning: An Overview","D. Wang; J. Chen","Department of Computer Science and Engineering and the Center for Cognitive and Brain Sciences, The Ohio State University, Columbus, OH, USA; Department of Computer Science and Engineering, The Ohio State University, Columbus, OH, USA","IEEE/ACM Transactions on Audio, Speech, and Language Processing","","2018","26","10","1702","1726","Speech separation is the task of separating target speech from background interference. Traditionally, speech separation is studied as a signal processing problem. A more recent approach formulates speech separation as a supervised learning problem, where the discriminative patterns of speech, speakers, and background noise are learned from training data. Over the past decade, many supervised separation algorithms have been put forward. In particular, the recent introduction of deep learning to supervised speech separation has dramatically accelerated progress and boosted separation performance. This paper provides a comprehensive overview of the research on deep learning based supervised speech separation in the last several years. We first introduce the background of speech separation and the formulation of supervised separation. Then, we discuss three main components of supervised separation: learning machines, training targets, and acoustic features. Much of the overview is on separation algorithms where we review monaural methods, including speech enhancement (speech-nonspeech separation), speaker separation (multitalker separation), and speech dereverberation, as well as multimicrophone techniques. The important issue of generalization, unique to supervised learning, is discussed. This overview provides a historical perspective on how advances are made. In addition, we discuss a number of conceptual issues, including what constitutes the target source.","","","10.1109/TASLP.2018.2842159","Air Force Office of Scientific Research; National Institute on Deafness and Other Communication Disorders; National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8369155","Seech separation;speaker separation;speech enhancement;supervised speech separation;deep learning;deep neural networks;speech dereverberation;time-frequency masking;array separation;beamforming","Speech enhancement;Interference;Noise measurement;Training;Supervised learning;Task analysis","learning (artificial intelligence);speech enhancement;speech intelligibility","supervised speech separation;deep learning;target speech;supervised learning problem;supervised separation algorithms;speech enhancement;speech-nonspeech separation;multitalker separation;speech dereverberation","","62","211","","","","","IEEE","IEEE Journals"
"End-to-End Deep Learning of Optical Fiber Communications","B. Karanov; M. Chagnon; F. Thouin; T. A. Eriksson; H. Bülow; D. Lavery; P. Bayvel; L. Schmalen","Nokia Bell Labs, Stuttgart, Germany; Nokia Bell Labs, Stuttgart, Germany; School of Physics, Georgia Institute of Technology, Atlanta, GA, USA; Quantum ICT Advanced Development Center, National Institute of Information and Communications Technology, Tokyo, Japan; Nokia Bell Labs, Stuttgart, Germany; Optical Networks Group, Department of Electronic and Electrical Engineering, University College London, London, U.K.; Optical Networks Group, Department of Electronic and Electrical Engineering, University College London, London, U.K.; Nokia Bell Labs, Stuttgart, Germany","Journal of Lightwave Technology","","2018","36","20","4843","4855","In this paper, we implement an optical fiber communication system as an end-to-end deep neural network, including the complete chain of transmitter, channel model, and receiver. This approach enables the optimization of the transceiver in a single end-to-end process. We illustrate the benefits of this method by applying it to intensity modulation/direct detection (IM/DD) systems and show that we can achieve bit error rates below the 6.7% hard-decision forward error correction (HD-FEC) threshold. We model all componentry of the transmitter and receiver, as well as the fiber channel, and apply deep learning to find transmitter and receiver configurations minimizing the symbol error rate. We propose and verify in simulations a training method that yields robust and flexible transceivers that allow-without reconfiguration-reliable transmission over a large range of link dispersions. The results from end-to-end deep learning are successfully verified for the first time in an experiment. In particular, we achieve information rates of 42 Gb/s below the HD-FEC threshold at distances beyond 40 km. We find that our results outperform conventional IM/DD solutions based on two- and four-level pulse amplitude modulation with feedforward equalization at the receiver. Our study is the first step toward end-to-end deep learning based optimization of optical fiber communication systems.","","","10.1109/JLT.2018.2865109","EU Marie Skłodowska-Curie project COIN; German Academic Exchange Council; DAAD-RISE Professional scholarship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8433895","Deep learning;detection;machine learning;modulation;neural networks;optical fiber communication","Training;Machine learning;Receivers;Optical transmitters;Transceivers;Optimization;Communication systems","error statistics;forward error correction;intensity modulation;learning (artificial intelligence);neural nets;optical fibre communication;optical fibre dispersion;optical modulation;pulse amplitude modulation","intensity modulation/direct detection systems;bit error rates;fiber channel;symbol error rate;end-to-end deep learning based optimization;optical fiber communication system;optical fiber communications;forward error correction;single end-to-end process;end-to-end deep neural network;size 40.0 km","","23","29","CCBY","","","","IEEE","IEEE Journals"
"Learning Deep Generative Models With Doubly Stochastic Gradient MCMC","C. Du; J. Zhu; B. Zhang","Department of Computer Science and Technology, State Key Laboratory of Intelligent Technology and Systems, Tsinghua National Laboratory of Information Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science and Technology, State Key Laboratory of Intelligent Technology and Systems, Tsinghua National Laboratory of Information Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science and Technology, State Key Laboratory of Intelligent Technology and Systems, Tsinghua National Laboratory of Information Science and Technology, Tsinghua University, Beijing, China","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","7","3084","3096","Deep generative models (DGMs), which are often organized in a hierarchical manner, provide a principled framework of capturing the underlying causal factors of data. Recent work on DGMs focussed on the development of efficient and scalable variational inference methods that learn a single model under some mean-field or parameterization assumptions. However, little work has been done on extending Markov chain Monte Carlo (MCMC) methods to Bayesian DGMs, which enjoy many advantages compared with variational methods. We present doubly stochastic gradient MCMC, a simple and generic method for (approximate) Bayesian inference of DGMs in a collapsed continuous parameter space. At each MCMC sampling step, the algorithm randomly draws a mini-batch of data samples to estimate the gradient of log-posterior and further estimates the intractable expectation over hidden variables via a neural adaptive importance sampler, where the proposal distribution is parameterized by a deep neural network and learnt jointly along with the sampling process. We demonstrate the effectiveness of learning various DGMs on a wide range of tasks, including density estimation, data generation, and missing data imputation. Our method outperforms many state-of-the-art competitors.","","","10.1109/TNNLS.2017.2688499","National Basic Research Program (973 Program) of China; National Natural Science Foundation of China; Tsinghua University; Collaborative Project with Tencent; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7961239","Bayesian methods;deep generative models (DGMs);deep learning;Markov chain Monte Carlo (MCMC);stochastic gradient","Stochastic processes;Bayes methods;Hidden Markov models;Data models;Monte Carlo methods;Neural networks;Probabilistic logic","Bayes methods;data analysis;learning (artificial intelligence);Markov processes;Monte Carlo methods;neural nets","deep neural network;data generation;deep generative models;doubly stochastic gradient MCMC;mean-field;variational methods;Bayesian inference;collapsed continuous parameter space;MCMC sampling step;variational inference methods;Markov chain Monte Carlo methods;Bayesian DGM;density estimation;missing data imputation","","1","62","","","","","IEEE","IEEE Journals"
"Learning the Hierarchical Parts of Objects by Deep Non-Smooth Nonnegative Matrix Factorization","J. Yu; G. Zhou; A. Cichocki; S. Xie","Faculty of Automation, Guangdong University of Technology, Guangzhou, China; Faculty of Automation, Guangdong University of Technology, Guangzhou, China; Skolkovo Institute of Science and Technology (SKOLTECH), Moscow, Russia; Faculty of Automation, Guangdong University of Technology, Guangzhou, China","IEEE Access","","2018","6","","58096","58105","Nonsmooth nonnegative matrix factorization (nsNMF) is capable of producing more localized, less overlapped feature representations than other variants of NMF while keeping satisfactory fit to data. However, nsNMF as well as other existing NMF methods are incompetent to learn hierarchical features of complex data due to its shallow structure. To fill this gap, we propose a deep nsNMF method coined by the fact that it possesses a deeper architecture compared with standard nsNMF. The deep nsNMF not only gives part-based features due to the nonnegativity constraints but also creates higher level, more abstract features by combing lower level ones. The in-depth description of how deep architecture can help to efficiently discover abstract features in dnsNMF is presented, suggesting that the proposed model inherits the major advantages from both deep learning and NMF. Extensive experiments demonstrate the standout performance of the proposed method in clustering analysis.","","","10.1109/ACCESS.2018.2873385","National Natural Science Foundation of China; Ministry of Education and Science of the Russian Federation; Polish National Science Center; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8481457","Nonnegative matrix factorization (NMF);nsNMF;deep nsNMF;face clustering;features learning;sparseness","Feature extraction;Data models;Machine learning;Sparse matrices;Nonhomogeneous media;Symmetric matrices;Data analysis","learning (artificial intelligence);matrix decomposition;pattern clustering","deep learning;deep nonsmooth nonnegative matrix factorization;deep nsNMF method;clustering analysis;overlapped feature representations;hierarchical feature learning;NMF methods","","","41","","","","","IEEE","IEEE Journals"
"MPCA SGD—A Method for Distributed Training of Deep Learning Models on Spark","M. Langer; A. Hall; Z. He; W. Rahayu","La Trobe University, VIC, Australia; La Trobe University, VIC, Australia; La Trobe University, VIC, Australia; La Trobe University, VIC, Australia","IEEE Transactions on Parallel and Distributed Systems","","2018","29","11","2540","2556","Many distributed deep learning systems have been published over the past few years, often accompanied by impressive performance claims. In practice these figures are often achieved in high performance computing (HPC) environments with fast InfiniBand network connections. For average deep learning practitioners this is usually an unrealistic scenario, since they cannot afford access to these facilities. Simple re-implementations of algorithms such as EASGD [1] for standard Ethernet environments often fail to replicate the scalability and performance of the original works [2] . In this paper, we explore this particular problem domain and present MPCA SGD, a method for distributed training of deep neural networks that is specifically designed to run in low-budget environments. MPCA SGD tries to make the best possible use of available resources, and can operate well if network bandwidth is constrained. Furthermore, MPCA SGD runs on top of the popular Apache Spark [3] framework. Thus, it can easily be deployed in existing data centers and office environments where Spark is already used. When training large deep learning models in a gigabit Ethernet cluster, MPCA SGD achieves significantly faster convergence rates than many popular alternatives. For example, MPCA SGD can train ResNet-152 [4] up to 5.3x faster than state-of-the-art systems like MXNet [5] , up to 5.3x faster than bulk-synchronous systems like SparkNet [6] and up to 5.3x faster than decentral asynchronous systems like EASGD [1] .","","","10.1109/TPDS.2018.2833074","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354695","Deep learning;distributed computing;machine learning;neural networks;spark;stochastic gradient descent","Machine learning;Computational modeling;Sparks;Training;Optimization;Servers;Bandwidth","learning (artificial intelligence);neural nets;optimisation;parallel processing;stochastic processes","deep neural networks;MPCA SGD;deep learning models;distributed training;high performance computing environments;standard Ethernet environments;HPC environments;EASGD;network bandwidth;gigabit Ethernet cluster;faster convergence rates;Apache Spark;InfiniBand network connections","","","39","","","","","IEEE","IEEE Journals"
"Impact of Approximate Multipliers on VGG Deep Learning Network","I. Hammad; K. El-Sankary","Department of Electrical and Computer Engineering, Dalhousie University, Halifax, Canada; Department of Electrical and Computer Engineering, Dalhousie University, Halifax, Canada","IEEE Access","","2018","6","","60438","60444","This paper presents a study on the applicability of using approximate multipliers to enhance the performance of the VGGNet deep learning network. Approximate multipliers are known to have reduced power, area, and delay with the cost of an inaccuracy in output. Improving the performance of the VGGNet in terms of power, area, and speed can be achieved by replacing exact multipliers with approximate multipliers as demonstrated in this paper. The simulation results show that approximate multiplication has a very little impact on the accuracy of VGGNet. However, using approximate multipliers can achieve significant performance gains. The simulation was completed using different generated error matrices that mimic the inaccuracy that approximate multipliers introduce to the data. The impact of various ranges of the mean relative error and the standard deviation was tested. The well-known data sets CIFAR-10 and CIFAR100 were used for testing the network's classification accuracy. The impact on the accuracy was assessed by simulating approximate multiplication in all the layers in the first set of tests, and in selective layers in the second set of tests. Using approximate multipliers in all the layers leads to very little impact on the network's accuracy. In addition, an alternative approach is to use a hybrid of exact and approximate multipliers. In the hybrid approach, 39.14% of the deeper layer's multiplications can be approximate while having a reduced negligible impact on the network's accuracy.","","","10.1109/ACCESS.2018.2875376","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8488463","AI accelerator;approximate computing;approximate multiplier;CNN;deep convolutional network;deep learning;VGGNet","Machine learning;Computer architecture;Delays;Training;Approximate computing;Probability density function;Error analysis","approximation theory;learning (artificial intelligence);matrix algebra;neural nets;pattern classification","approximate multipliers;approximate multiplication;VGG deep learning network;VGGNet deep learning network;error matrices;CIFAR-10;CIFAR100;network classification accuracy;generated error matrices","","1","14","","","","","IEEE","IEEE Journals"
"Signal Detection Scheme Based on Adaptive Ensemble Deep Learning Model","C. Ha; H. Song","Department of Information and Communication Engineering, Sejong University, Seoul, South Korea; Department of Information and Communication Engineering, Sejong University, Seoul, South Korea","IEEE Access","","2018","6","","21342","21349","Accurate signal detection is one of the most important requirements of wireless communication systems. The two most important processes of the signal detection are channel estimation and compensation. Since an orthogonal frequency-division multiplexing (OFDM) system among wireless communication systems uses orthogonal sub-carriers, the system has advantages of high bandwidth efficiency and simple channel compensation process compared with a single carrier system. However, due to the imperfect channel estimation and amplification of receiving noise by the channel compensation process, the reliability performance of the system is deteriorated according to the channel condition. This paper aims to introduce a new signal detection scheme based on deep learning. To address the challenges of signal detection, we propose the method which integrates the ensemble deep learning with the acquired received signals from multi-path channel according to the channel condition. The channel estimation corresponds to learning the deep neural network, and the channel compensation corresponds to assigning the received data to the learned network. Experiments on the OFDM symbol classification demonstrate that the proposed scheme has dramatically improved reliability performance compared with the conventional scheme.","","","10.1109/ACCESS.2018.2825463","Institute for Information and Communications Technology Promotion Grant through the Korean Government (MSIT) (Development of Immersive Signage Based on Variable Transparency and Multiple Layers); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8335275","OFDM;signal detection;channel estimation;channel compensation;deep learning;ensemble learning","Channel estimation;OFDM;Machine learning;Adaptation models;Signal detection;Neurons;Training","channel estimation;estimation theory;learning (artificial intelligence);multipath channels;neural nets;OFDM modulation;signal detection;telecommunication computing","signal detection scheme;adaptive ensemble deep learning model;wireless communication systems;orthogonal frequency-division multiplexing system;multipath channel;deep neural network;orthogonal subcarriers;bandwidth efficiency;channel estimation;OFDM system;channel compensation process;received signals acquisition","","6","19","","","","","IEEE","IEEE Journals"
"LEARN: Learned Experts’ Assessment-Based Reconstruction Network for Sparse-Data CT","H. Chen; Y. Zhang; Y. Chen; J. Zhang; W. Zhang; H. Sun; Y. Lv; P. Liao; J. Zhou; G. Wang","College of Computer Science, Sichuan University, Chengdu, China; College of Computer Science, Sichuan University, Chengdu, China; ULSee Inc., Hangzhou, China; School of Computer and Information Engineering, Henan University of Economics and Law, Zhengzhou, China; College of Computer Science, Sichuan University, Chengdu, China; Department of Radiology, West China Hospital of Sichuan University, Chengdu, China; Shanghai United Imaging Healthcare Co., Ltd., Shanghai, China; Department of Scientific Research and Education, The Sixth People’s Hospital of Chengdu, Chengdu, China; College of Computer Science, Sichuan University, Chengdu, China; Department of Biomedical Engineering, Rensselaer Polytechnic Institute, Troy, NY, USA","IEEE Transactions on Medical Imaging","","2018","37","6","1333","1347","Compressive sensing (CS) has proved effective for tomographic reconstruction from sparsely collected data or under-sampled measurements, which are practically important for few-view computed tomography (CT), tomosynthesis, interior tomography, and so on. To perform sparse-data CT, the iterative reconstruction commonly uses regularizers in the CS framework. Currently, how to choose the parameters adaptively for regularization is a major open problem. In this paper, inspired by the idea of machine learning especially deep learning, we unfold the state-of-the-art “fields of experts”-based iterative reconstruction scheme up to a number of iterations for data-driven training, construct a learned experts' assessment-based reconstruction network (LEARN) for sparse-data CT, and demonstrate the feasibility and merits of our LEARN network. The experimental results with our proposed LEARN network produces a superior performance with the well-known Mayo Clinic low-dose challenge data set relative to the several state-of-the-art methods, in terms of artifact reduction, feature preservation, and computational speed. This is consistent to our insight that because all the regularization terms and parameters used in the iterative reconstruction are now learned from the training data, our LEARN network utilizes application-oriented knowledge more effectively and recovers underlying images more favorably than competing algorithms. Also, the number of layers in the LEARN network is only 50, reducing the computational complexity of typical iterative algorithms by orders of magnitude.","","","10.1109/TMI.2018.2805692","National Natural Science Foundation of China; National Institute of Biomedical Imaging and Bioengineering/National Institutes of Health; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8290981","Computed tomography (CT);sparse-data CT;iterative reconstruction;compressive sensing;fields of experts;machine learning;deep learning","Image reconstruction;Computed tomography;Machine learning;Iterative methods;Biomedical imaging","compressed sensing;computerised tomography;image reconstruction;iterative methods;learning (artificial intelligence);medical image processing","sparse-data CT;tomographic reconstruction;sparsely collected data;interior tomography;iterative reconstruction;reconstruction scheme;data-driven training;LEARN network;Mayo Clinic low-dose challenge data;training data;machine learning;learned expert assessment-based reconstruction network;deep learning;computed tomography;compressive sensing","","16","73","","","","","IEEE","IEEE Journals"
"Remaining Useful Life Prediction for Lithium-Ion Battery: A Deep Learning Approach","L. Ren; L. Zhao; S. Hong; S. Zhao; H. Wang; L. Zhang","School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; School of Cyber Science and Technology, Beihang University, Beijing, China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; Department of ICT and Natural Sciences, Norwegian University of Science and Technology, Aalesund, Norway; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China","IEEE Access","","2018","6","","50587","50598","Accurate prediction of remaining useful life (RUL) of lithium-ion battery plays an increasingly crucial role in the intelligent battery health management systems. The advances in deep learning introduce new data-driven approaches to this problem. This paper proposes an integrated deep learning approach for RUL prediction of lithium-ion battery by integrating autoencoder with deep neural network (DNN). First, we present a multi-dimensional feature extraction method with autoencoder model to represent battery health degradation. Then, the RUL prediction model-based DNN is trained for multi-battery remaining cycle life estimation. The proposed approach is applied to the real data set of lithium-ion battery cycle life from NASA, and the experiment results show that the proposed approach can improve the accuracy of RUL prediction.","","","10.1109/ACCESS.2018.2858856","National Natural Science Foundation of China; National Key Research and Development Program of China; Beijing Natural Science Foundation-Rail Traffic Control Science and Technology Joint Fund; Natural Science Foundation of Beijing Municipality; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8418374","Lithium-ion battery;remaining useful life;RUL prediction model;deep learning;deep neural network","Lithium-ion batteries;Feature extraction;Predictive models;Voltage measurement;Temperature measurement;Machine learning","battery management systems;condition monitoring;feature extraction;learning (artificial intelligence);neural nets;power engineering computing;remaining life assessment;secondary cells","intelligent battery health management systems;data-driven approaches;integrated deep learning approach;deep neural network;battery health degradation;RUL prediction model-based DNN;multibattery remaining cycle life estimation;lithium-ion battery cycle life;useful life prediction","","10","39","","","","","IEEE","IEEE Journals"
"Deep Unfolding for Topic Models","J. Chien; C. Lee","Department of Electrical and Computer Engineering, National Chiao Tung University, Hsinchu, Taiwan; Department of Electrical and Computer Engineering, National Chiao Tung University, Hsinchu, Taiwan","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","2","318","331","Deep unfolding provides an approach to integrate the probabilistic generative models and the deterministic neural networks. Such an approach is benefited by deep representation, easy interpretation, flexible learning and stochastic modeling. This study develops the unsupervised and supervised learning of deep unfolded topic models for document representation and classification. Conventionally, the unsupervised and supervised topic models are inferred via the variational inference algorithm where the model parameters are estimated by maximizing the lower bound of logarithm of marginal likelihood using input documents without and with class labels, respectively. The representation capability or classification accuracy is constrained by the variational lower bound and the tied model parameters across inference procedure. This paper aims to relax these constraints by directly maximizing the end performance criterion and continuously untying the parameters in learning process via deep unfolding inference (DUI). The inference procedure is treated as the layer-wise learning in a deep neural network. The end performance is iteratively improved by using the estimated topic parameters according to the exponentiated updates. Deep learning of topic models is therefore implemented through a back-propagation procedure. Experimental results show the merits of DUI with increasing number of layers compared with variational inference in unsupervised as well as supervised topic models.","","","10.1109/TPAMI.2017.2677439","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7869412","Deep unfolding;topic model;variational inference;deep neural network;unsupervised/supervised learning","Probabilistic logic;Inference algorithms;Stochastic processes;Graphical models;Biological neural networks;Feature extraction","belief networks;document handling;inference mechanisms;learning (artificial intelligence);neural nets","layer-wise learning;deep neural network;estimated topic parameters;deep learning;probabilistic generative models;deterministic neural networks;deep representation;easy interpretation;flexible learning;stochastic modeling;unsupervised learning;deep unfolded topic models;document representation;unsupervised topic models;variational inference algorithm;deep unfolding inference;DUI","","5","39","","","","","IEEE","IEEE Journals"
"A Robust Transform-Domain Deep Convolutional Network for Voltage Dip Classification","A. Bagheri; I. Y. H. Gu; M. H. J. Bollen; E. Balouji","Electric Power Engineering, Luleå University of Technology, Skellefteå, Sweden; Department of Electrical Engineering, Chalmers University of Technology, Gothenburg, Sweden; Electric Power Engineering, Luleå University of Technology, Skellefteå, Sweden; Department of Electrical Engineering, Chalmers University of Technology, Gothenburg, Sweden","IEEE Transactions on Power Delivery","","2018","33","6","2794","2802","This paper proposes a novel method for voltage dip classification using deep convolutional neural networks. The main contributions of this paper include: 1) to propose a new effective deep convolutional neural network architecture for automatically learning voltage dip features, rather than extracting hand-crafted features; 2) to employ the deep learning in an effective two-dimensional (2-D) transform domain, under space-phasor model (SPM), for efficient learning of dip features; 3) to characterize voltage dips by 2-D SPM-based deep learning, which leads to voltage dip features independent of the duration and sampling frequency of dip recordings; and 4) to develop robust automatically-extracted features that are insensitive to training and test datasets measured from different countries/regions. Experiments were conducted on datasets containing about 6000 measured voltage dips spread over seven classes measured from several different countries. Results have shown good performance of the proposed method: average classification rate is about 97% and false alarm rate is about 0.50%. The test results from the proposed method are compared with the results from two existing dip classification methods. The proposed method is shown to outperform these existing methods.","","","10.1109/TPWRD.2018.2854677","Swedish Energy Administration; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8410408","Power quality;voltage dip;machine learning;deep learning;convolutional neural network","Voltage fluctuations;Feature extraction;Machine learning;Voltage measurement;Convolutional neural networks;Power quality;Convolution","convolution;feature extraction;learning (artificial intelligence);neural nets;pattern classification;power engineering computing;power supply quality","robust transform-domain deep convolutional network;voltage dip classification;deep convolutional neural networks;effective deep convolutional neural network architecture;voltage dip features;hand-crafted features;deep learning;efficient learning;dip recordings;average classification rate;existing dip classification methods;measured voltage dips","","6","46","","","","","IEEE","IEEE Journals"
"Deep Learning for IoT Big Data and Streaming Analytics: A Survey","M. Mohammadi; A. Al-Fuqaha; S. Sorour; M. Guizani","Department of Computer Science, Western Michigan University, Kalamazoo, MI, USA; Department of Computer Science, Western Michigan University, Kalamazoo, MI, USA; Department of Electrical and Computer Engineering, University of Idaho, Moscow, ID, USA; Department of Electrical and Computer Engineering, University of Idaho, Moscow, ID, USA","IEEE Communications Surveys & Tutorials","","2018","20","4","2923","2960","In the era of the Internet of Things (IoT), an enormous amount of sensing devices collect and/or generate various sensory data over time for a wide range of fields and applications. Based on the nature of the application, these devices will result in big or fast/real-time data streams. Applying analytics over such data streams to discover new information, predict future insights, and make control decisions is a crucial process that makes IoT a worthy paradigm for businesses and a quality-of-life improving technology. In this paper, we provide a thorough overview on using a class of advanced machine learning techniques, namely deep learning (DL), to facilitate the analytics and learning in the IoT domain. We start by articulating IoT data characteristics and identifying two major treatments for IoT data from a machine learning perspective, namely IoT big data analytics and IoT streaming data analytics. We also discuss why DL is a promising approach to achieve the desired analytics in these types of data and applications. The potential of using emerging DL techniques for IoT data analytics are then discussed, and its promises and challenges are introduced. We present a comprehensive background on different DL architectures and algorithms. We also analyze and summarize major reported research attempts that leveraged DL in the IoT domain. The smart IoT devices that have incorporated DL in their intelligence background are also discussed. DL implementation approaches on the fog and cloud centers in support of IoT applications are also surveyed. Finally, we shed light on some challenges and potential directions for future research. At the end of each section, we highlight the lessons learned based on our experiments and review of the recent literature.","","","10.1109/COMST.2018.2844341","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8373692","Deep learning;deep neural network;Internet of Things;on-device intelligence;IoT big data;fast data analytics;cloud-based analytics","Machine learning;Big Data;Data analysis;Economics;Internet of Things;Data mining;Tutorials","Big Data;data analysis;Internet of Things;learning (artificial intelligence)","quality-of-life;DL implementation;fog centers;cloud centers;Internet of Things;fast/real-time data streams;sensory data;streaming analytics;IoT applications;smart IoT devices;IoT big data analytics;machine learning perspective;IoT data characteristics;IoT domain;deep learning;advanced machine learning techniques","","42","229","","","","","IEEE","IEEE Journals"
"Learning Self-Informed Feature Contribution for Deep Learning-Based Acoustic Modeling","Y. Kim; M. Kim; J. Goo; H. Kim","School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Avoma, Inc., Palo Alto, CA, USA; School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea","IEEE/ACM Transactions on Audio, Speech, and Language Processing","","2018","26","11","2204","2214","In this paper, we introduce a new feature engineering approach for deep learning-based acoustic modeling, which utilizes input feature contributions. For this purpose, we propose an auxiliary deep neural network (DNN) called a feature contribution network (FCN) whose output layer is composed of sigmoid-based contribution gates. In our framework, the FCN tries to learn element-level discriminative contributions of input features and an acoustic model network (AMN) is trained by gated features generated by element-wise multiplication between contribution gate outputs and input features. In addition, we also propose a regularization method for the FCN, which helps the FCN to activate the minimum number of the gates. The proposed methods were evaluated on the TED-LIUM release 1 corpus. We applied the proposed methods to DNN- and long short-term memory-based AMNs. Experimental results results showed that AMNs with the FCNs consistently improved recognition performance compared with AMN-only frameworks.","","","10.1109/TASLP.2018.2858923","Ministry of Trade, Industry, and Energy, South Korea; Industrial Technology Innovation Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8418803","Acoustic modeling;deep learning;feature contribution network;speech recognition","Acoustics;Hidden Markov models;Logic gates;Feature extraction;Speech recognition;Training;Artificial neural networks","acoustic signal processing;feature extraction;learning (artificial intelligence);neural nets;speech recognition","deep learning-based acoustic modeling;feature engineering approach;input feature contributions;auxiliary deep neural network;feature contribution network;FCN;sigmoid-based contribution gates;element-level discriminative contributions;acoustic model network;gated features;contribution gate outputs;short-term memory-based AMNs;self-informed feature contribution learning;TED-LIUM release 1 corpus;DNN;regularization method","","1","47","","","","","IEEE","IEEE Journals"
"Deep Learning Based Communication Over the Air","S. Dörner; S. Cammerer; J. Hoydis; S. t. Brink","Institute of Telecommunications, University of Stuttgart, Stuttgart, Germany; Institute of Telecommunications, University of Stuttgart, Stuttgart, Germany; Nokia Bell Labs, Nozay, France; Institute of Telecommunications, University of Stuttgart, Stuttgart, Germany","IEEE Journal of Selected Topics in Signal Processing","","2018","12","1","132","143","End-to-end learning of communications systems is a fascinating novel concept that has so far only been validated by simulations for block-based transmissions. It allows learning of transmitter and receiver implementations as deep neural networks (NNs) that are optimized for an arbitrary differentiable end-to-end performance metric, e.g., block error rate (BLER). In this paper, we demonstrate that over-the-air transmissions are possible: We build, train, and run a complete communications system solely composed of NNs using unsynchronized off-the-shelf software-defined radios and open-source deep learning software libraries. We extend the existing ideas toward continuous data transmission, which eases their current restriction to short block lengths but also entails the issue of receiver synchronization. We overcome this problem by introducing a frame synchronization module based on another NN. A comparison of the BLER performance of the “learned” system with that of a practical baseline shows competitive performance close to 1 dB, even without extensive hyperparameter tuning. We identify several practical challenges of training such a system over actual channels, in particular, the missing channel gradient, and propose a two-step learning procedure based on the idea of transfer learning that circumvents this issue.","","","10.1109/JSTSP.2017.2784180","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8214233","Autoencoder;communication;deep learning;end-to-end learning;modulation;neural network;over-the-air;software-defined radio","Training;Receivers;Communication systems;Artificial neural networks;Hardware;Transmitters;Synchronization","learning (artificial intelligence);neural nets;radio receivers;software libraries;software radio;synchronisation;telecommunication computing","two-step learning procedure;end-to-end learning;communications systems;block-based transmissions;receiver implementations;deep neural networks;NNs;block error rate;over-the-air transmissions;open-source deep learning software libraries;continuous data transmission;receiver synchronization;frame synchronization module;transmitter implementations;off-the-shelf software-defined radios","","80","33","","","","","IEEE","IEEE Journals"
"Spectral–Spatial Residual Network for Hyperspectral Image Classification: A 3-D Deep Learning Framework","Z. Zhong; J. Li; Z. Luo; M. Chapman","Department of Geography and Environmental Management, University of Waterloo, ON, Canada; Department of Geography and Environmental Management, University of Waterloo, ON, Canada; Department of Cognitive Science, Xiamen University, Xiamen, China; Department of Civil Engineering, Ryerson University, Toronto, ON, Canada","IEEE Transactions on Geoscience and Remote Sensing","","2018","56","2","847","858","In this paper, we designed an end-to-end spectral-spatial residual network (SSRN) that takes raw 3-D cubes as input data without feature engineering for hyperspectral image classification. In this network, the spectral and spatial residual blocks consecutively learn discriminative features from abundant spectral signatures and spatial contexts in hyperspectral imagery (HSI). The proposed SSRN is a supervised deep learning framework that alleviates the declining-accuracy phenomenon of other deep learning models. Specifically, the residual blocks connect every other 3-D convolutional layer through identity mapping, which facilitates the backpropagation of gradients. Furthermore, we impose batch normalization on every convolutional layer to regularize the learning process and improve the classification performance of trained models. Quantitative and qualitative results demonstrate that the SSRN achieved the state-of-the-art HSI classification accuracy in agricultural, rural-urban, and urban data sets: Indian Pines, Kennedy Space Center, and University of Pavia.","","","10.1109/TGRS.2017.2755542","China Scholarship Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8061020","3-D deep learning;hyperspectral image classification;spectral–spatial feature extraction;spectral–spatial residual network (SSRN)","Feature extraction;Training;Machine learning;Hyperspectral imaging;Testing;Robustness","feature extraction;geophysical image processing;hyperspectral imaging;image classification;learning (artificial intelligence)","HSI classification accuracy;spectral signatures;3D deep learning models;Indian Pines;Kennedy Space Center;University of Pavia;supervised deep learning framework;hyperspectral imagery;spatial contexts;discriminative features;spatial residual blocks;spectral blocks;3-D cubes;end-to-end spectral-spatial residual network;hyperspectral image classification;SSRN;classification performance;learning process;convolutional layer;declining-accuracy phenomenon","","48","31","","","","","IEEE","IEEE Journals"
"Traffic Scene Segmentation Based on RGB-D Image and Deep Learning","L. Li; B. Qian; J. Lian; W. Zheng; Y. Zhou","Faculty of Vehicle Engineering and Mechanics, School of Automotive Engineering, Dalian University of Technology, Dalian, China; Faculty of Vehicle Engineering and Mechanics, School of Automotive Engineering, Dalian University of Technology, Dalian, China; Faculty of Vehicle Engineering and Mechanics, School of Automotive Engineering, Dalian University of Technology, Dalian, China; Faculty of Vehicle Engineering and Mechanics, School of Automotive Engineering, Dalian University of Technology, Dalian, China; Faculty of Vehicle Engineering and Mechanics, School of Automotive Engineering, Dalian University of Technology, Dalian, China","IEEE Transactions on Intelligent Transportation Systems","","2018","19","5","1664","1669","Semantic segmentation of traffic scenes has potential applications in intelligent transportation systems. Deep learning techniques can improve segmentation accuracy, especially when the information from depth maps is introduced. However, little research has been done on the application of depth maps to the segmentation of traffic scene. In this paper, we propose a method for semantic segmentation of traffic scenes based on RGB-D images and deep learning. The semi-global stereo matching algorithm and the fast global image smoothing method are employed to obtain a smooth disparity map. We present a new deep fully convolutional neural network architecture for semantic pixel-wise segmentation. We test the performance of the proposed network architecture using RGB-D images as input and compare the results with the method that only takes RGB images as input. The experimental results show that the introduction of the disparity map can help to improve the semantic segmentation accuracy and that our proposed network architecture achieves good real-time performance and competitive segmentation accuracy.","","","10.1109/TITS.2017.2724138","National Natural Science Foundation of China; China Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8007227","Deep learning;disparity map;traffic scene segmentation","Image segmentation;Semantics;Machine learning;Training;Decoding;Feature extraction;Network architecture","convolution;feedforward neural nets;image colour analysis;image matching;image segmentation;intelligent transportation systems;learning (artificial intelligence);neural net architecture;smoothing methods;stereo image processing;traffic engineering computing","intelligent transportation systems;deep learning techniques;depth maps;RGB-D image;semiglobal stereo matching algorithm;fast global image smoothing method;smooth disparity map;deep fully convolutional neural network architecture;semantic pixel-wise segmentation;semantic segmentation accuracy;competitive segmentation accuracy;traffic scene segmentation;deep learning","","3","30","","","","","IEEE","IEEE Journals"
"A Survey of Deep Learning: Platforms, Applications and Emerging Research Trends","W. G. Hatcher; W. Yu","Department of Computer and Information Sciences, Towson University, Towson, MD, USA; Department of Computer and Information Sciences, Towson University, Towson, MD, USA","IEEE Access","","2018","6","","24411","24432","Deep learning has exploded in the public consciousness, primarily as predictive and analytical products suffuse our world, in the form of numerous human-centered smart-world systems, including targeted advertisements, natural language assistants and interpreters, and prototype self-driving vehicle systems. Yet to most, the underlying mechanisms that enable such human-centered smart products remain obscure. In contrast, researchers across disciplines have been incorporating deep learning into their research to solve problems that could not have been approached before. In this paper, we seek to provide a thorough investigation of deep learning in its applications and mechanisms. Specifically, as a categorical collection of state of the art in deep learning research, we hope to provide a broad reference for those seeking a primer on deep learning and its various implementations, platforms, algorithms, and uses in a variety of smart-world systems. Furthermore, we hope to outline recent key advancements in the technology, and provide insight into areas, in which deep learning can improve investigation, as well as highlight new areas of research that have yet to see the application of deep learning, but could nonetheless benefit immensely. We hope this survey provides a valuable reference for new deep learning practitioners, as well as those seeking to innovate in the application of deep learning.","","","10.1109/ACCESS.2018.2830661","U.S. National Science Foundation (Faculty Career Award); University System of Maryland through the Wilson H. Elkins Professorship Award Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8351898","Human-centered smart systems;deep learning;platform;neural networks;emergent applications;Internet of Things;cyber-physical systems;survey;networking;security","Machine learning;Neurons;Neural networks;Task analysis;Learning systems;Computational modeling;Training","learning (artificial intelligence)","deep learning research;human-centered smart-world systems","","23","170","","","","","IEEE","IEEE Journals"
"Deep Learning-Aided SCMA","M. Kim; N. Kim; W. Lee; D. Cho","School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Department of Information and Communication Engineering, Institute of Marine Industry, Gyeongsang National University, Tongyeong, South Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea","IEEE Communications Letters","","2018","22","4","720","723","Sparse code multiple access (SCMA) is a promising code-based non-orthogonal multiple-access technique that can provide improved spectral efficiency and massive connectivity meeting the requirements of 5G wireless communication systems. We propose a deep learning-aided SCMA (D-SCMA) in which the codebook that minimizes the bit error rate (BER) is adaptively constructed, and a decoding strategy is learned using a deep neural network-based encoder and decoder. One benefit of D-SCMA is that the construction of an efficient codebook can be achieved in an automated manner, which is generally difficult due to the non-orthogonality and multi-dimensional traits of SCMA. We use simulations to show that our proposed scheme provides a lower BER with a smaller computation time than conventional schemes.","","","10.1109/LCOMM.2018.2792019","Basic Science Research Program through the National Research Foundation of Korea (NRF); Ministry of Education; ‘The Cross-Ministry Giga KOREA Project’; Korea Government(MSIT); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8254356","Sparse code multiple access (SCMA);deep neural network (DNN);autoencoder;deep learning","Bit error rate;Training;Machine learning;NOMA;Maximum likelihood decoding;5G mobile communication","5G mobile communication;decoding;error statistics;learning (artificial intelligence);multi-access systems;neural nets","decoding strategy;deep neural network;multiple-access technique;spectral efficiency;bit error rate;deep learning-aided SCMA;sparse code multiple access;nonorthogonal multiple-access technique;5G wireless communication systems;BER;SCMA nonorthogonality;SCMA multidimensional traits","","26","16","","","","","IEEE","IEEE Journals"
"Deep Belief Networks for Electroencephalography: A Review of Recent Contributions and Future Outlooks","F. Movahedi; J. L. Coyle; E. Sejdić","Department of Electrical and Computer Engineering, Swanson School of Engineering, University of Pittsburgh, Pittsburgh, PA, USA; Department of Communication Science and Disorders, School of Health and Rehabilitation Sciences, University of Pittsburgh, Pittsburgh, PA, USA; Department of Electrical and Computer Engineering, Swanson School of Engineering, University of Pittsburgh, Pittsburgh, PA, USA","IEEE Journal of Biomedical and Health Informatics","","2018","22","3","642","652","Deep learning, a relatively new branch of machine learning, has been investigated for use in a variety of biomedical applications. Deep learning algorithms have been used to analyze different physiological signals and gain a better understanding of human physiology for automated diagnosis of abnormal conditions. In this paper, we provide an overview of deep learning approaches with a focus on deep belief networks in electroencephalography applications. We investigate the state-of-the-art algorithms for deep belief networks and then cover the application of these algorithms and their performances in electroencephalographic applications. We covered various applications of electroencephalography in medicine, including emotion recognition, sleep stage classification, and seizure detection, in order to understand how deep learning algorithms could be modified to better suit the tasks desired. This review is intended to provide researchers with a broad overview of the currently existing deep belief network methodology for electroencephalography signals, as well as to highlight potential challenges for future research.","","","10.1109/JBHI.2017.2727218","Eunice Kennedy Shriver National Institute Of Child Health & Human Development of the National Institutes of Health; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7981315","Classification;deep learning;electroencephalography;machine learning","Electroencephalography;Machine learning;Feature extraction;Biological neural networks;Neurons;Signal processing algorithms;Training","belief networks;electroencephalography;emotion recognition;feature extraction;learning (artificial intelligence);medical signal processing;signal classification;sleep","state-of-the-art algorithms;deep belief networks;deep learning algorithms;deep belief network methodology;electroencephalography signals;machine learning;biomedical applications;physiological signals;emotion recognition;sleep stage classification;seizure detection","","5","97","","","","","IEEE","IEEE Journals"
"SAR Automatic Target Recognition Based on Multiview Deep Learning Framework","J. Pei; Y. Huang; W. Huo; Y. Zhang; J. Yang; T. Yeo","Department of Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, China; Department of Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, China; Department of Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, China; Department of Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, China; Department of Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, China; Department of Electrical and Computer Engineering, National University of Singapore, Singapore","IEEE Transactions on Geoscience and Remote Sensing","","2018","56","4","2196","2210","It is a feasible and promising way to utilize deep neural networks to learn and extract valuable features from synthetic aperture radar (SAR) images for SAR automatic target recognition (ATR). However, it is too difficult to effectively train the deep neural networks with limited raw SAR images. In this paper, we propose a new approach to do SAR ATR, in which a multiview deep learning framework was employed. Based on the multiview SAR ATR pattern, we first present a flexible mean to generate adequate multiview SAR data, which can guarantee a large amount of inputs for network training without needing many raw SAR images. Then, a unique deep convolutional neural network containing a parallel network topology with multiple inputs is adopted. The features of input SAR images from different views will be learned by the proposed network layer by layer; meanwhile, the learned features from the distinct views are fused in different layers progressively. Therefore, the proposed framework is able to achieve a superior recognition performance, and requires only a small number of raw SAR images for network training samples generation. Experimental results have shown the superiority of the proposed framework based on the Moving and Stationary Target Acquisition and Recognition data set.","","","10.1109/TGRS.2017.2776357","National Natural Science Foundation of China; Collaborative Innovation Center of Information Sensing and Understanding; China Scholarship Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8207785","Automatic target recognition (ATR);convolutional neural networks;deep learning;multiview;synthetic aperture radar (SAR)","Synthetic aperture radar;Feature extraction;Training;Machine learning;Neural networks;Target recognition;Image recognition","image recognition;learning (artificial intelligence);neural nets;radar computing;radar imaging;radar target recognition;synthetic aperture radar","valuable feature extraction;multiview SAR data generation;network training;network training sample generation;stationary target acquisition dataset;moving target acquisition dataset;stationary target recognition data set;moving target recognition dataset;network training samples generation;learned features;network layer;input SAR images;parallel network topology;unique deep convolutional neural network;multiview SAR ATR pattern;raw SAR images;SAR automatic target recognition;synthetic aperture radar images;multiview deep learning framework","","19","46","","","","","IEEE","IEEE Journals"
"Patch-Sorted Deep Feature Learning for High Resolution SAR Image Classification","Z. Ren; B. Hou; Z. Wen; L. Jiao","Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, International Research Center for Intelligent Perception and Computation, Joint International Research Laboratory of Intelligent Perception and Computation, Xidian University, Xi'an, Shaanxi Province, China; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, International Research Center for Intelligent Perception and Computation, Joint International Research Laboratory of Intelligent Perception and Computation, Xidian University, Xi'an, Shaanxi Province, China; Shaanxi Province, China; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, International Research Center for Intelligent Perception and Computation, Joint International Research Laboratory of Intelligent Perception and Computation, Xidian University, Xi'an, Shaanxi Province, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2018","11","9","3113","3126","Synthetic aperture radar (SAR) image classification is a fundamental process for SAR image understanding and interpretation. The traditional SAR classification methods extract shallow and handcrafted features, which cannot subtly depict the abundant modal information in high resolution SAR image. Inspired by deep learning, an effective feature learning tool, a novel method called patch-sorted deep neural network (PSDNN) to implement unsupervised discriminative feature learning is proposed. First, the randomly selected patches are measured and sorted by the meticulously designed patch-sorted strategy, which adopts instance-based prototypes learning. Then the sorted patches are delivered to a well-designed dual-sparse autoencoder to obtain desired weights in each layer. Convolutional neural network is followed to extract high-level spatial and structural features. At last, the features are fed to a linear support vector machine to generate predicted labels. The experimental results in three broad SAR images of different satellites confirm the effectiveness and generalization of our method. Compared with three traditional feature descriptors and four unsupervised deep feature descriptors, the features learned in PSDNN appear powerful discrimination and the PSDNN achieves desired classification accuracy and a good visual appearance.","","","10.1109/JSTARS.2018.2851023","National Natural Science Foundation of China; Joint Fund of the Equipment Research of Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409445","Convolutional neural network;dual-sparse autoencoder;high-resolution synthetic aperture radar (SAR);image classification;patch-sorted;unsupervised deep feature learning","Feature extraction;Synthetic aperture radar;Training;Prototypes;Image resolution;Neural networks;Transforms","convolution;feature extraction;feedforward neural nets;image classification;image resolution;radar computing;radar imaging;support vector machines;synthetic aperture radar;unsupervised learning","high resolution SAR image classification;synthetic aperture radar image classification;deep learning;patch-sorted deep neural network;PSDNN;unsupervised discriminative feature learning;randomly selected patches;meticulously designed patch-sorted strategy;instance-based prototypes;sorted patches;convolutional neural network;structural features;unsupervised deep feature descriptors;high-level spatial features;patch-sorted deep feature learning;dual-sparse autoencoder;linear support vector machine","","1","54","","","","","IEEE","IEEE Journals"
"Baidu Meizu Deep Learning Competition: Arithmetic Operation Recognition Using End-to-End Learning OCR Technologies","Y. Jiang; H. Dong; A. El Saddik","Multimedia Computing Research Laboratory, School of Electrical Engineering and Computer Science, University of Ottawa, Ottawa, ON, Canada; Multimedia Computing Research Laboratory, School of Electrical Engineering and Computer Science, University of Ottawa, Ottawa, ON, Canada; Multimedia Computing Research Laboratory, School of Electrical Engineering and Computer Science, University of Ottawa, Ottawa, ON, Canada","IEEE Access","","2018","6","","60128","60136","The end-to-end learning approaches were proposed for an arithmetic expression recognition task in the Baidu Meizu Deep Learning Competition by a deep convolutional neural network (DCNN) with parallel dense layers and component-connection-based detection pipeline with the convolutional recurrent neural network (CRNN) model. Two effective pipelines for DCNN and CRNN to identify long and complex expressions are presented and compared. In the first task, a DCNN connected to parallel dense layers for digital arithmetic operations was developed, which achieves 99.985% accuracy. In the second task, the CRNN with connectionist temporal classification was adopted, combined with the text region detection technique to recognize more complex pictures with both assignment operations and calculation formulas, which achieves 98.087% accuracy.","","","10.1109/ACCESS.2018.2876035","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8491274","Optical character recognition;end-to-end learning;convolutional recurrent neural network","Task analysis;Feature extraction;Optical character recognition software;Character recognition;Image segmentation;Pipelines;Machine learning","convolutional neural nets;face recognition;feature extraction;image classification;learning (artificial intelligence);optical character recognition;recurrent neural nets","Baidu Meizu Deep Learning Competition;arithmetic operation recognition;end-to-end learning approaches;arithmetic expression recognition task;deep convolutional neural network;DCNN;parallel dense layers;component-connection-based detection pipeline;convolutional recurrent neural network model;CRNN;complex expressions;digital arithmetic operations","","1","20","","","","","IEEE","IEEE Journals"
"Label-Sensitive Deep Metric Learning for Facial Age Estimation","H. Liu; J. Lu; J. Feng; J. Zhou","Department of Automation, State Key Lab of Intelligent Technologies and Systems, Tsinghua National Laboratory for Information Science and Technology (TNList), Tsinghua University, Beijing, China; Department of Automation, State Key Lab of Intelligent Technologies and Systems, Tsinghua National Laboratory for Information Science and Technology (TNList), Tsinghua University, Beijing, China; Department of Automation, State Key Lab of Intelligent Technologies and Systems, Tsinghua National Laboratory for Information Science and Technology (TNList), Tsinghua University, Beijing, China; Department of Automation, State Key Lab of Intelligent Technologies and Systems, Tsinghua National Laboratory for Information Science and Technology (TNList), Tsinghua University, Beijing, China","IEEE Transactions on Information Forensics and Security","","2018","13","2","292","305","In this paper, we present a label-sensitive deep metric learning (LSDML) approach for facial age estimation. Motivated by the fact that human age labels are chronologically correlated, our proposed LSDML aims to seek a series of hierarchical nonlinear transformations by deep residual network to project face samples to a latent common space, where the similarity of face pairs is equivalently isotonic to the age difference in a ranking-preserving manner. Since traversal access to total negative samples catastrophically costs and leads to suboptimal, our model learns to mine hard meaningful samples in parallel to learning feature similarity, so that the local manifold of face samples is preserved in the transformed subspace. To better improve the performance on the data set that contains few labeled samples, we further extend our LSDML to a multi-source LSDML method, which aims at maximizing the cross-population correlation of different face aging data sets. Extensive experimental results on four benchmarking data sets show the effectiveness of our proposed approach.","","","10.1109/TIFS.2017.2746062","National Key Research and Development Program of China; National Natural Science Foundation of China; National 1000 Young Talents Plan Program; National Basic Research Program of China; Shenzhen Fundamental Research Fund (Subject Arrangement); Ministry of Education of China; Tsinghua University Initiative Scientific Research Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8017500","Facial age estimation;metric learning;deep learning;residual network;biometrics","Face;Measurement;Estimation;Correlation;Learning systems;Aging;Robustness","face recognition;image representation;learning (artificial intelligence)","face samples;labeled samples;multisource LSDML method;facial age estimation;label-sensitive deep metric learning approach;human age labels;hierarchical nonlinear transformations;deep residual network;latent common space;face pairs;age difference;total negative samples;hard meaningful samples;face aging data sets;feature similarity;cross-population correlation","","5","77","","","","","IEEE","IEEE Journals"
"A Novel Deep Learning Framework for Internal Gross Target Volume Definition From 4D Computed Tomography of Lung Cancer Patients","X. Li; Z. Deng; Q. Deng; L. Zhang; T. Niu; Y. Kuang","Sir Run Run Shaw Hospital, Zhejiang University School of Medicine, Hangzhou, China; School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Radiation Oncology, Affiliated Hangzhou First People’s Hospital, Zhejiang University School of Medicine, Hangzhou, China; Department of Radiation Oncology, Hangzhou Cancer Hospital, Hangzhou, China; Sir Run Run Shaw Hospital, Zhejiang University School of Medicine, Hangzhou, China; Department of Medical Physics, University of Nevada, Las Vegas, NV, USA","IEEE Access","","2018","6","","37775","37783","In this paper, we study the reliability of a novel deep learning framework for internal gross target volume (IGTV) delineation from 4-D computed tomography (4DCT), which is applied to patients with lung cancer treated by stereotactic body radiation therapy (SBRT). Seventy seven patients who underwent SBRT followed by 4DCT scans were incorporated in this retrospective study. The IGTV_DL was delineated using a novel deep machine learning algorithm with a linear exhaustive optimal combination framework. For the purpose of comparison, three other IGTVs based on common methods was also delineated. We compared the relative volume difference (RVI), matching index (MI), and encompassment index (EI) for the above IGTVs. Then, multiple parameter regression analysis was performed to assess the tumor volume and motion range as clinical influencing factors in the MI variation. The results demonstrated that the deep learning algorithm with linear exhaustive optimal combination framework has a higher probability of achieving optimal MI compared with other currently widely used methods. For patients after simple breathing training by keeping the respiratory frequency in 10 breath per minute (BPM), the four phase combinations of 0%, 30%, 50% and 90% can be considered as a potential solution for an optimal combination to synthesize IGTV in all respiration amplitudes.","","","10.1109/ACCESS.2018.2851027","Natural Science Foundation of Zhejiang Province; National High-tech R&D Program for Young Scientists by the Ministry of Science and Technology of China; National Natural Science Foundation of China; National Key Research Plan by the Ministry of Science and Technology of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8408475","Deep learning;computed tomography;algorithm;stereotactic ablative radiotherapy;internal gross target volume;lung cancer","Tumors;Lung;Training;Image segmentation;Computed tomography;Cancer;Machine learning","cancer;computerised tomography;learning (artificial intelligence);lung;medical image processing;pneumodynamics;regression analysis;tumours","deep learning algorithm;linear exhaustive optimal combination framework;optimal MI;internal gross target volume definition;lung cancer patients;internal gross target volume delineation;stereotactic body radiation therapy;SBRT;seventy seven patients;4DCT scans;retrospective study;IGTV_DL;deep machine learning algorithm;relative volume difference;multiple parameter regression analysis;tumor volume;motion range;4D computed tomography;simple breathing training;respiratory frequency;respiration amplitudes;phase combinations","","1","31","","","","","IEEE","IEEE Journals"
"An Uphill Safety Controller With Deep Learning-Based Ramp Detection for Intelligent Wheelchairs","B. Wu; Y. Chen; C. Huang; P. Chang","Institute of Electrical and Control Engineering, National Chiao Tung University, Hsinchu, Taiwan; Institute of Electrical and Control Engineering, National Chiao Tung University, Hsinchu, Taiwan; Institute of Electrical and Control Engineering, National Chiao Tung University, Hsinchu, Taiwan; Institute of Electrical and Control Engineering, National Chiao Tung University, Hsinchu, Taiwan","IEEE Access","","2018","6","","28356","28371","In a society with aging population, the demand for electric wheelchairs is growing with the advancement of automation. However, many accidents have occurred due to the misjudgment of the slope angle and wheelchair speed while the wheelchair is traveling on ramps. This research employs the light electronic assistance pal compact motor package to reduce the weight and size of conventional electric wheelchairs. The modular design of proposed uphill controller and ramp detection functions allows users to easily select and incorporate only the functions they need. This paper proposes a ramp detection model implemented using the deep learning algorithm with CNN-4 structure to analyze depth image data. The model's recognition time of each video frame is 11 times faster than that of the AlexNet and GoogleNet. The uphill safety controller is designed as an adaptive network-based fuzzy inference system with Q-learning. The safe speed is automatically calculated according to the angle obtained from slope classification and revised in real-time during the slope driving to prevent the user from moving towards the dangerous ramp or rolling back due to inadequate speed. The accuracy of ramp detection is further increased by 5% to 97.1% due to assistance from the voting system processing and the gyroscope output data. The 5° ramp experiment of our uphill controller with ramp classification takes 20 s to complete the slope driving which is 23% faster than the controller without ramp detection. The energy consumption is also one half less than the experiment without uphill detection.","","","10.1109/ACCESS.2018.2839729","National Science Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8364538","Command and control systems;learning;intelligent wheelchair;deep learning;adaptive network-based fuzzy inference system (ANFIS);Q-learning;ramp classification","Wheelchairs;Safety;Machine learning;Databases;Gyroscopes;Training;Cameras","control engineering computing;electric vehicles;fuzzy reasoning;handicapped aids;learning (artificial intelligence);object detection;power engineering computing;real-time systems;wheelchairs","CNN-4 structure;depth image data;AlexNet;GoogleNet;adaptive network-based fuzzy inference system;energy consumption;real-time;voting system processing;uphill detection;ramp classification;slope driving;slope classification;Q-learning;deep learning algorithm;ramp detection model;conventional electric wheelchairs;light electronic assistance pal compact motor package;wheelchair speed;slope angle;uphill safety controller;time 20.0 s","","","28","","","","","IEEE","IEEE Journals"
"MfeCNN: Mixture Feature Embedding Convolutional Neural Network for Data Mapping","D. Li; M. Huang; X. Li; Y. Ruan; L. Yao","Big Data Laboratory, Baidu, Sunnyvale, CA, USA; Department of Health Sciences Research, Mayo Clinic, Rochester, MN, USA; Department of Mechatronics Engineering, Donhua University, Shanghai, China; Watson Health Cloud, IBM, Yorktown Heights, NY, USA; Department of Health Sciences Research, Mayo Clinic, Rochester, MN, USA","IEEE Transactions on NanoBioscience","","2018","17","3","165","171","Data mapping plays an important role in data integration and exchanges among institutions and organizations with different data standards. However, traditional rule-based approaches and machine learning methods fail to achieve satisfactory results for the data mapping problem. In this paper, we propose a novel and sophisticated deep learning framework for data mapping called mixture feature embedding convolutional neural network (MfeCNN). The MfeCNN model converts the data mapping task to a multiple classification problem. In the model, we incorporated multimodal learning and multiview embedding into a CNN for mixture feature tensor generation and classification prediction. Multimodal features were extracted from various linguistic spaces with a medical natural language processing package. Then, powerful feature embeddings were learned by using the CNN. As many as 10 classes could be simultaneously classified by a softmax prediction layer based on multiview embedding. MfeCNN achieved the best results on unbalanced data (average F1 score, 82.4%) among the traditional state-of-the-art machine learning models and CNN without mixture feature embedding. Our model also outperformed a very deep CNN with 29 layers, which took free texts as inputs. The combination of mixture feature embedding and a deep neural network can achieve high accuracy for data mapping and multiple classification.","","","10.1109/TNB.2018.2841053","National Center for Advancing Translational Sciences; National Center for Advancing Translational Sciences; U.S. National Library of Medicine; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8368078","Data mapping;convolutional neural network;mixture feature embedding;multimodal;multiview;deep learning","Data models;Feature extraction;Machine learning;Standards;Predictive models;Training;Semantics","convolution;data integration;feature extraction;feedforward neural nets;learning (artificial intelligence);medical computing;natural language processing;pattern classification","mixture feature embedding convolutional neural network;data integration;machine learning methods;data mapping problem;MfeCNN model;mixture feature tensor generation;classification prediction;unbalanced data;deep neural network;deep learning framework;rule-based approaches;multimodal features extraction;medical natural language processing package;softmax prediction layer","Computational Biology;Data Mining;Deep Learning;Humans;Natural Language Processing;Neural Networks (Computer);Workflow","3","30","","","","","IEEE","IEEE Journals"
"Short-Term Residential Load Forecasting Based on Resident Behaviour Learning","W. Kong; Z. Y. Dong; D. J. Hill; F. Luo; Y. Xu","School of Electrical and Information Engineering, The University of Sydney, Sydney, NSW, Australia; School of EE&T, University of NSW, Sydney, NSW, Australia; School of Electrical and Information Engineering, The University of Sydney, Sydney, NSW, Australia; School of Civil Engineering, The University of Sydney, Sydney, NSW, Australia; School of Electrical and Information Engineering, The University of Sydney, Sydney, NSW, Australia","IEEE Transactions on Power Systems","","2018","33","1","1087","1088","Residential load forecasting has been playing an increasingly important role in modern smart grids. Due to the variability of residents' activities, individual residential loads are usually too volatile to forecast accurately. A long short-term memory-based deep-learning forecasting framework with appliance consumption sequences is proposed to address such volatile problem. It is shown that the forecasting accuracy can be notably improved by including appliance measurements in the training data. The effectiveness of the proposed method is validated through extensive comparison studies on a real-world dataset.","","","10.1109/TPWRS.2017.2688178","Faculty Research Cluster Program; China Southern Power Grid; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7887751","Deep learning;meter-level load forecasting;recurrent neural network;short-term load forecasting","Forecasting;Load forecasting;Home appliances;Load modeling;Predictive models;Recurrent neural networks;Machine learning","domestic appliances;learning (artificial intelligence);load forecasting;power engineering computing;smart power grids","modern smart grids;individual residential loads;short-term memory;deep-learning forecasting framework;appliance consumption sequences;appliance measurements;short-term residential load forecasting;resident behaviour learning;residents activity variability","","30","7","Traditional","","","","IEEE","IEEE Journals"
"Using deep learning to detect small targets in infrared oversampling images","L. Liangkui; W. Shaoyou; T. Zhongxing","Shanghai Institute of Satellite Engineering, Shanghai 201109, China; Shanghai Institute of Satellite Engineering, Shanghai 201109, China; Shanghai Institute of Satellite Engineering, Shanghai 201109, China","Journal of Systems Engineering and Electronics","","2018","29","5","947","952","According to the oversampling imaging characteristics, an infrared small target detection method based on deep learning is proposed. A 7-layer deep convolutional neural network (CNN) is designed to automatically extract small target features and suppress clutters in an end-to-end manner. The input of CNN is an original oversampling image while the output is a clutter-suppressed feature map. The CNN contains only convolution and non-linear operations, and the resolution of the output feature map is the same as that of the input image. The L1-norm loss function is used, and a mass of training data is generated to train the network effectively. Results show that compared with several baseline methods, the proposed method improves the signal clutter ratio gain and background suppression factor by 3-4 orders of magnitude, and has more powerful target detection performance.","","","10.21629/JSEE.2018.05.07","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8536779","infrared small target detection;oversampling;deep learning;convolutional neural network (CNN)","Object detection;Clutter;Training;Imaging;Feature extraction;Training data","convolutional neural nets;feature extraction;geophysical image processing;image sampling;infrared imaging;object detection;remote sensing","CNN;original oversampling image;clutter-suppressed feature map;convolution;nonlinear operations;output feature map;input image;L1-norm loss function;baseline methods;signal clutter ratio gain;background suppression factor;deep learning;infrared oversampling images;oversampling imaging characteristics;infrared small target detection method;7-layer deep convolutional neural network;target features;target detection performance","","","","","","","","BIAI","BIAI Journals"
"Exploiting Web Images for Video Highlight Detection With Triplet Deep Ranking","H. Kim; T. Mei; H. Byun; T. Yao","Department of Computer Science, Yonsei University, Seoul, South Korea; Artificial Intelligence Platform and Research, JD.com, Beijing, China; Department of Computer Science, Yonsei University, Seoul, South Korea; Microsoft Research Asia, Beijing, China","IEEE Transactions on Multimedia","","2018","20","9","2415","2426","Highlight detection from videos has been widely studied due to the fast growth of video contents. However, most existing approaches to highlight detection, either handcraft feature based or deep learning based, heavily rely on human-curated training data, which is very expensive to obtain and, thus, hinders the scalability to large datasets and unlabeled video categories. We observe that the largely available Web images can be applied as a weak supervision for highlight detection. For example, the top-ranked images in reference to the query “skiing” returned by a search engine may contain considerable positive samples of “skiing” highlights. Motivated by this observation, we propose a novel triplet deep ranking approach to video highlight detection using Web images as a weak supervision. The approach handles the relative preference of highlight scores between highlighting frames, nonhighlighting frames, and Web images by the triplet ranking constraints. Our approach can iteratively train two interdependent deep models (i.e., a triplet highlight model and a pairwise noise model) to deal with the noisy Web images in a single framework. We train the two models with relative preferences to generalize the capability regardless of the categories of training data. Therefore, our approach is fully category independent and exploits weakly supervised Web images. We evaluate our approach on two challenging datasets and achieve impressive results compared with the state-of-the-art pairwise ranking support vector machines, a robust recurrent autoencoder, and spatial deep convolution neural networks. We also empirically verify through cross-dataset evaluation that our category-independent model is fairly generalizable even if two different datasets do not share exactly the same categories.","","","10.1109/TMM.2018.2806224","National Research Foundation of Korea (NRF); Korea government (MSIT); MSIP (The Ministry of Science, ICT and Future Planning), Korea and Microsoft Research; IITP (Institute for Information & Communications Technology Promotion); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8291744","Video highlight detection;triplet deep ranking;weakly supervised Web images;category-independent learning;deep learning","Noise measurement;Search engines;Training;Machine learning;Feature extraction;Support vector machines;Neural networks","convolution;feature extraction;feedforward neural nets;Internet;learning (artificial intelligence);search engines;support vector machines;video signal processing","spatial deep convolution neural networks;category-independent model;video highlight detection;deep learning;triplet highlight model;triplet deep ranking approach;web images;search engine;pairwise ranking support vector machine;robust recurrent autoencoder","","","51","","","","","IEEE","IEEE Journals"
"Enhanced Network Anomaly Detection Based on Deep Neural Networks","S. Naseer; Y. Saleem; S. Khalid; M. K. Bashir; J. Han; M. M. Iqbal; K. Han","Department of Computer Science & Engineering, University of Engineering and Technology, Lahore, Pakistan; Department of Computer Science & Engineering, University of Engineering and Technology, Lahore, Pakistan; Department of Computer Engineering, Bahria University, Islamabad, Pakistan; Department of Computer Science & Engineering, University of Engineering and Technology, Lahore, Pakistan; School of Computer Science and Engineering, Kyungpook National University, Daegu, South Korea; Department of Computer Science, University of Engineering and Technology, Taxila, Pakistan; School of Computer Science and Engineering, Kyungpook National University, Daegu, South Korea","IEEE Access","","2018","6","","48231","48246","Due to the monumental growth of Internet applications in the last decade, the need for security of information network has increased manifolds. As a primary defense of network infrastructure, an intrusion detection system is expected to adapt to dynamically changing threat landscape. Many supervised and unsupervised techniques have been devised by researchers from the discipline of machine learning and data mining to achieve reliable detection of anomalies. Deep learning is an area of machine learning which applies neuron-like structure for learning tasks. Deep learning has profoundly changed the way we approach learning tasks by delivering monumental progress in different disciplines like speech processing, computer vision, and natural language processing to name a few. It is only relevant that this new technology must be investigated for information security applications. The aim of this paper is to investigate the suitability of deep learning approaches for anomaly-based intrusion detection system. For this research, we developed anomaly detection models based on different deep neural network structures, including convolutional neural networks, autoencoders, and recurrent neural networks. These deep models were trained on NSLKDD training data set and evaluated on both test data sets provided by NSLKDD, namely NSLKDDTest+ and NSLKDDTest21. All experiments in this paper are performed by authors on a GPU-based test bed. Conventional machine learning-based intrusion detection models were implemented using well-known classification techniques, including extreme learning machine, nearest neighbor, decision-tree, random-forest, support vector machine, naive-bays, and quadratic discriminant analysis. Both deep and conventional machine learning models were evaluated using well-known classification metrics, including receiver operating characteristics, area under curve, precision-recall curve, mean average precision and accuracy of classification. Experimental results of deep IDS models showed promising results for real-world application in anomaly detection systems.","","","10.1109/ACCESS.2018.2863036","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8438865","Deep learning;convolutional neural networks;autoencoders;LSTM;k_NN;decision_tree;intrusion detection;convnets;information security","Anomaly detection;Machine learning;Training;Intrusion detection;Measurement;Neural networks","Bayes methods;computer vision;convolution;data mining;decision trees;feedforward neural nets;graphics processing units;Internet;learning (artificial intelligence);natural language processing;pattern classification;recurrent neural nets;security of data;speech processing;support vector machines","deep neural networks;monumental growth;Internet applications;information network;network infrastructure;supervised techniques;unsupervised techniques;data mining;monumental progress;natural language processing;information security applications;anomaly-based intrusion detection system;convolutional neural networks;recurrent neural networks;GPU-based test bed;conventional machine learning-based intrusion detection models;support vector machine;deep machine learning models;deep IDS models;anomaly detection systems;threat landscape;deep neural network structures;network anomaly detection;neuron-like structure;speech processing;computer vision;autoencoders;NSLKDD training dataset;test datasets;classification techniques;nearest neighbor;decision-tree;random-forest;naive-bays;quadratic discriminant analysis;classification metrics;receiver operating characteristics;area under curve;precision-recall curve;mean average precision","","10","47","","","","","IEEE","IEEE Journals"
"Retrieval Oriented Deep Feature Learning With Complementary Supervision Mining","Y. Lv; W. Zhou; Q. Tian; S. Sun; H. Li","EEis Department, CAS Key Laboratory of Technology in Geo-spatial Information Processing and Application System, University of Science and Technology of China, Hefei, China; EEis Department, CAS Key Laboratory of Technology in Geo-spatial Information Processing and Application System, University of Science and Technology of China, Hefei, China; Computer Science Department, The University of Texas at San Antonio, TX, USA; Horizon Robotics, Inc., Beijing, China; EEis Department, CAS Key Laboratory of Technology in Geo-spatial Information Processing and Application System, University of Science and Technology of China, Hefei, China","IEEE Transactions on Image Processing","","2018","27","10","4945","4957","Deep convolutional neural networks (CNNs) have been widely and successfully applied in many computer vision tasks, such as classification, detection, semantic segmentation, and so on. As for image retrieval, while off-the-shelf CNN features from models trained for classification task are demonstrated promising, it remains a challenge to learn specific features oriented for instance retrieval. Witnessing the great success of low-level SIFT feature in image retrieval and its complementary nature to the semantic-aware CNN feature, in this paper, we propose to embed the SIFT feature into the CNN feature with a Siamese structure in a learning-based paradigm. The learning objective consists of two kinds of loss, i.e., similarity loss and fidelity loss. The first loss embeds the image-level nearest neighborhood structure with the SIFT feature into CNN feature learning, while the second loss imposes that the CNN feature with the updated CNN model preserves the fidelity of that from the original CNN model solely trained for classification. After the learning, the generated CNN feature inherits the property of the SIFT feature, which is well oriented for image retrieval. We evaluate our approach on the public data sets, and comprehensive experiments demonstrate the effectiveness of the proposed method.","","","10.1109/TIP.2018.2845120","973 Program; National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; Young Elite Scientists Sponsorship Program by CAST; Army Research Office; Faculty Research Gift Awards by NEC Laboratories of America and Blippar; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8374946","Image retrieval;deep feature learning;feature fusion","Image retrieval;Task analysis;Feature extraction;Training;Semantics;Machine learning","computer vision;feature extraction;feedforward neural nets;image classification;image retrieval;learning (artificial intelligence);transforms","CNN feature learning;image retrieval;complementary supervision mining;computer vision tasks;off-the-shelf CNN features;classification task;instance retrieval;low-level SIFT feature;semantic-aware CNN feature;learning-based paradigm;image-level nearest neighborhood structure;Siamese structure;retrieval oriented deep feature learning;deep convolutional neural networks;CNN model","","","60","","","","","IEEE","IEEE Journals"
"Robust RGB-D Hand Tracking Using Deep Learning Priors","J. Sanchez-Riera; K. Srinivasan; K. Hua; W. Cheng; M. A. Hossain; M. F. Alhamid","Multimedia Computing Laboratory, CITI, Academia Sinica, Taipei, Taiwan; Department of CSIE, National Ilan University, Yilan, Taiwan; Deptartment of CSIE, National Taiwan University of Science and Technology, Taipei, Taiwan; Multimedia Computing Laboratory, CITI, Academia Sinica, Taipei, Taiwan; Department of Software Engineering, King Saud University, Riyadh, Saudi Arabia; Department of Software Engineering, King Saud University, Riyadh, Saudi Arabia","IEEE Transactions on Circuits and Systems for Video Technology","","2018","28","9","2289","2301","With the irruption of inexpensive depth sensor devices, hand gesture tracking has become a topic of great interest. Two main problems to face respect other tracking algorithms are the high complexity of the hand structure, which translate in a very large amount of possible gestures, and the rapidness of the movements we are able to make when moving the hand or just the fingers. Recent approaches try to fit a 3D hand model to the observed RGB-D data by an optimization function that minimizes the error between the model and the data. However, these algorithms are very dependent on the initialization point, which are impractical to run in a natural environment. To solve these kinds of problems, it is common to use an offline data set with prelearned gestures that will serve as a first rough estimate. In concrete, we present an algorithm that uses an articulated ICP minimization function that is initialized by the parameters obtained from a data set of hand gestures trained through a deep learning framework. This setup has two strong points. First, deep learning provides a very fast and accurate estimate of performed hand gestures. Second, the articulated ICP algorithm allows capturing the possible variability of a gesture performed by different persons or slightly different gestures. Our proposed algorithm is evaluated and validated in several ways. Independent evaluations for the deep learning framework and articulated ICP are performed. Moreover, different real sequences are recorded to validate our approach and, finally, quantitative and qualitative comparisons are conducted with state-of-the-art algorithms.","","","10.1109/TCSVT.2017.2718622","King Saud University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7955084","Hand gesture;hand recognition;tracking;deep learning;iterative closest point algorithm","Three-dimensional displays;Tracking;Iterative closest point algorithm;Minimization;Machine learning;Solid modeling;Data models","gesture recognition;image motion analysis;image sensors;learning (artificial intelligence);minimisation;object tracking;pose estimation","robust RGB-D hand tracking;hand structure complexity;3D hand model;observed RGB-D data;error minimization;inexpensive depth sensor devices;deep learning priors;articulated ICP algorithm;deep learning framework;data set;articulated ICP minimization function;prelearned gestures;optimization function;hand gesture tracking","","4","48","","","","","IEEE","IEEE Journals"
"Deep Learning Techniques for Automatic MRI Cardiac Multi-Structures Segmentation and Diagnosis: Is the Problem Solved?","O. Bernard; A. Lalande; C. Zotti; F. Cervenansky; X. Yang; P. Heng; I. Cetin; K. Lekadir; O. Camara; M. A. Gonzalez Ballester; G. Sanroma; S. Napel; S. Petersen; G. Tziritas; E. Grinias; M. Khened; V. A. Kollerathu; G. Krishnamurthi; M. Rohé; X. Pennec; M. Sermesant; F. Isensee; P. Jäger; K. H. Maier-Hein; P. M. Full; I. Wolf; S. Engelhardt; C. F. Baumgartner; L. M. Koch; J. M. Wolterink; I. Išgum; Y. Jang; Y. Hong; J. Patravali; S. Jain; O. Humbert; P. Jodoin","University of Lyon, CREATIS, CNRS UMR5220, Inserm U1044, INSA-Lyon, University of Lyon 1, Lyon, France; Le2i Laboratory, CNRS FRE 2005, University of Burgundy, Dijon, France; Computer Science Department, University of Sherbrooke, Sherbrooke, Canada; University of Lyon, CREATIS, CNRS UMR5220, Inserm U1044, INSA-Lyon, University of Lyon 1, Lyon, France; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong; Barcelona Centre for New Medical Technologies, Universitat Pompeu Fabra, Barcelona, Spain; Barcelona Centre for New Medical Technologies, Universitat Pompeu Fabra, Barcelona, Spain; Barcelona Centre for New Medical Technologies, Universitat Pompeu Fabra, Barcelona, Spain; Barcelona Centre for New Medical Technologies, Universitat Pompeu Fabra, Barcelona, Spain; Barcelona Centre for New Medical Technologies, Universitat Pompeu Fabra, Barcelona, Spain; Department of Radiology, Stanford University School of Medicine, Stanford, CA, USA; William Harvey Research Institute, Queen Mary University of London, London, U.K.; Department of Computer Science, University of Crete, Heraklion, Greece; Department of Computer Science, University of Crete, Heraklion, Greece; Department of Engineering Design, IIT Madras, Chennai, India; Department of Engineering Design, IIT Madras, Chennai, India; Department of Engineering Design, IIT Madras, Chennai, India; Inria-Asclepios Project, Sophia Antipolis, France; Inria-Asclepios Project, Sophia Antipolis, France; Inria-Asclepios Project, Sophia Antipolis, France; Division of Medical Image Computing, German Cancer Research Center, Heidelberg, Germany; Division of Medical Image Computing, German Cancer Research Center, Heidelberg, Germany; Division of Medical Image Computing, German Cancer Research Center, Heidelberg, Germany; Department of Computer Science, Mannheim University of Applied Sciences, Mannheim, Germany; Department of Computer Science, Mannheim University of Applied Sciences, Mannheim, Germany; Department of Computer Science, Mannheim University of Applied Sciences, Mannheim, Germany; Computer Vision Laboratory, ETH Zürich, Zürich, Switzerland; Computer Vision and Geometry Group, ETH Zürich, Zürich, Switzerland; Image Sciences Institute, University Medical Center Utrecht, Utrecht, The Netherlands; Image Sciences Institute, University Medical Center Utrecht, Utrecht, The Netherlands; Integrative Cardiovascular Imaging Research Center, Yonsei University College of Medicine, Seoul, South Korea; Integrative Cardiovascular Imaging Research Center, Yonsei University College of Medicine, Seoul, South Korea; Qure.ai company, Mumbai, India; Qure.ai company, Mumbai, India; TIRO-UMR E 4320 Laboratory, University of Nice, Nice, France; Computer Science Department, University of Sherbrooke, Sherbrooke, Canada","IEEE Transactions on Medical Imaging","","2018","37","11","2514","2525","Delineation of the left ventricular cavity, myocardium, and right ventricle from cardiac magnetic resonance images (multi-slice 2-D cine MRI) is a common clinical task to establish diagnosis. The automation of the corresponding tasks has thus been the subject of intense research over the past decades. In this paper, we introduce the “Automatic Cardiac Diagnosis Challenge” dataset (ACDC), the largest publicly available and fully annotated dataset for the purpose of cardiac MRI (CMR) assessment. The dataset contains data from 150 multi-equipments CMRI recordings with reference measurements and classification from two medical experts. The overarching objective of this paper is to measure how far state-of-the-art deep learning methods can go at assessing CMRI, i.e., segmenting the myocardium and the two ventricles as well as classifying pathologies. In the wake of the 2017 MICCAI-ACDC challenge, we report results from deep learning methods provided by nine research groups for the segmentation task and four groups for the classification task. Results show that the best methods faithfully reproduce the expert analysis, leading to a mean value of 0.97 correlation score for the automatic extraction of clinical indices and an accuracy of 0.96 for automatic diagnosis. These results clearly open the door to highly accurate and fully automatic analysis of cardiac CMRI. We also identify scenarios for which deep learning methods are still failing. Both the dataset and detailed results are publicly available online, while the platform will remain open for new submissions.","","","10.1109/TMI.2018.2837502","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8360453","Cardiac segmentation and diagnosis;deep learning;MRI;left and right ventricles;myocardium","Machine learning;Magnetic resonance imaging;Myocardium;Image segmentation;Task analysis;Biomedical imaging;Heart","biomedical MRI;cardiology;image segmentation;learning (artificial intelligence);medical image processing","fully automatic analysis;cardiac CMRI;highly accurate analysis;automatic diagnosis;automatic extraction;classification task;segmentation task;2017 MICCAI-ACDC challenge;state-of-the-art deep learning methods;medical experts;reference measurements;150 multiequipments;cardiac MRI assessment;fully annotated dataset;largest publicly available annotated dataset;Automatic Cardiac Diagnosis Challenge dataset;intense research;corresponding tasks;common clinical task;multislice 2-D cine MRI;cardiac magnetic resonance images;ventricle;myocardium;left ventricular cavity;automatic MRI cardiac multistructures segmentation;deep learning techniques","","16","58","","","","","IEEE","IEEE Journals"
"Shared Predictive Cross-Modal Deep Quantization","E. Yang; C. Deng; C. Li; W. Liu; J. Li; D. Tao","School of Electronic Engineering, Xidian University, Xi’an, China; School of Electronic Engineering, Xidian University, Xi’an, China; School of Electronic Engineering, Xidian University, Xi’an, China; Tencent AI Lab, Shenzhen, China; School of Electronic Engineering, Xidian University, Xi’an, China; UBTECH Sydney Artificial Intelligence Centre and the School of Information Technologies, Faculty of Engineering and Information Technologies, The University of Sydney, Darlington, NSW, Australia","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","11","5292","5303","With explosive growth of data volume and ever-increasing diversity of data modalities, cross-modal similarity search, which conducts nearest neighbor search across different modalities, has been attracting increasing interest. This paper presents a deep compact code learning solution for efficient cross-modal similarity search. Many recent studies have proven that quantization-based approaches perform generally better than hashing-based approaches on single-modal similarity search. In this paper, we propose a deep quantization approach, which is among the early attempts of leveraging deep neural networks into quantization-based cross-modal similarity search. Our approach, dubbed shared predictive deep quantization (SPDQ), explicitly formulates a shared subspace across different modalities and two private subspaces for individual modalities, and representations in the shared subspace and the private subspaces are learned simultaneously by embedding them to a reproducing kernel Hilbert space, where the mean embedding of different modality distributions can be explicitly compared. In addition, in the shared subspace, a quantizer is learned to produce the semantics preserving compact codes with the help of label alignment. Thanks to this novel network architecture in cooperation with supervised quantization training, SPDQ can preserve intramodal and intermodal similarities as much as possible and greatly reduce quantization error. Experiments on two popular benchmarks corroborate that our approach outperforms state-of-the-art methods.","","","10.1109/TNNLS.2018.2793863","National Natural Science Foundation of China; Key R&D Program—The Key Industry Innovation Chain of Shaanxi; Australian Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8291828","Compact code;deep learning;multimodal;private network;quantization;shared network","Quantization (signal);Semantics;Learning systems;Correlation;Binary codes;Additives;Kernel","Hilbert spaces;learning (artificial intelligence);neural nets;search problems","shared predictive cross-modal deep quantization;nearest neighbor search;deep compact code learning solution;single-modal similarity search;deep neural networks;shared subspace;private subspaces;supervised quantization training;intramodal similarities;intermodal similarities;quantization error;modality distributions;kernel Hilbert space;mean embedding;SPDQ","","6","56","","","","","IEEE","IEEE Journals"
"ActiVis: Visual Exploration of Industry-Scale Deep Neural Network Models","M. Kahng; P. Y. Andrews; A. Kalro; D. H. Chau","Georgia Institute of Technology; Facebook; Facebook; Georgia Institute of Technology","IEEE Transactions on Visualization and Computer Graphics","","2018","24","1","88","97","While deep learning models have achieved state-of-the-art accuracies for many prediction tasks, understanding these models remains a challenge. Despite the recent interest in developing visual tools to help users interpret deep learning models, the complexity and wide variety of models deployed in industry, and the large-scale datasets that they used, pose unique design challenges that are inadequately addressed by existing work. Through participatory design sessions with over 15 researchers and engineers at Facebook, we have developed, deployed, and iteratively improved ActiVis, an interactive visualization system for interpreting large-scale deep learning models and results. By tightly integrating multiple coordinated views, such as a computation graph overview of the model architecture, and a neuron activation view for pattern discovery and comparison, users can explore complex deep neural network models at both the instance-and subset-level. ActiVis has been deployed on Facebook's machine learning platform. We present case studies with Facebook researchers and engineers, and usage scenarios of how ActiVis may work with different models.","","","10.1109/TVCG.2017.2744718","NSF Graduate Research Fellowship Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8022871","Visual analytics;deep learning;machine learning;information visualization","Computational modeling;Tools;Machine learning;Data models;Neurons;Facebook;Data visualization","data visualisation;learning (artificial intelligence);neural nets","visual tools;large-scale datasets;participatory design sessions;interactive visualization system;large-scale deep learning models;model architecture;complex deep neural network models;visual exploration;industry-scale deep neural network models;ActiVis system;machine learning platform","","31","38","Traditional","","","","IEEE","IEEE Journals"
"Deep-learning based fault diagnosis using computer-visualised power flow","S. Wang; S. Fan; J. Chen; X. Liu; B. Hao; J. Yu","School of Electrical Engineering and Automation, Harbin Institute of Technology, People's Republic of China; China Electric Power Research Institute, People's Republic of China; School of Computer Science and Technology, Harbin Institute of Technology, People's Republic of China; China Electric Power Research Institute, People's Republic of China; School of Electrical Engineering and Automation, Harbin Institute of Technology, People's Republic of China; School of Electrical Engineering and Automation, Harbin Institute of Technology, People's Republic of China","IET Generation, Transmission & Distribution","","2018","12","17","3985","3992","Changes in system topology, such as branch breaking and the loss of a generator or load, may profoundly influence the operation security of the power system. This study introduces a novel deep-learning based fault diagnosis method using power flow to diagnose topology changes in the power system. Power flow samples with different system states and topologies are first computed numerically; then, they are transformed into computer-visualised images. Using massive power-flow image samples, a convolutional neural network that aims to identify the system state is trained. A feature-map restriction technique is used to restructure the network. To enhance the robustness of the network, the random noise of branch flow is considered in the sample generation process. The results show that the proposed deep-learning based method may diagnose system faults effectively.","","","10.1049/iet-gtd.2018.5254","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8467586","","","learning (artificial intelligence);fault diagnosis;neural nets;load flow","topologies;computer-visualised images;massive power-flow image samples;convolutional neural network;system state;branch flow;sample generation process;deep-learning based method;system faults;computer-visualised power flow;system topology;branch breaking;generator;operation security;power system;deep-learning based fault diagnosis method;topology changes;power flow samples;different system states","","2","29","","","","","IET","IET Journals"
"Securing Collaborative Deep Learning in Industrial Applications Within Adversarial Scenarios","C. Esposito; X. Su; S. A. Aljawarneh; C. Choi","Department of Computer Science, University of Salerno, Fisciano, Italy; College of IoT Engineering, Hohai University, Changzhou, China; Software Engineering Department, Jordan University of Science and Technology, Irbid, Jordan; IT Institute, Chosun University, Gwangju, South Korea","IEEE Transactions on Industrial Informatics","","2018","14","11","4972","4981","Several industries in many different domains are looking at deep learning as a way to take advantage of the insights in their data, to improve their competitiveness, to open up novel business possibilities, or to resolve the problem that thought to be impossible to tackle. The large scale of the systems where deep learning is applied and the need of preserving the privacy of the used data have imposed a shift from the traditional centralized deployment to a more collaborative one. However, this has opened up several vulnerabilities caused by compromised nodes and inputs, with traditional crypto primitives and access control models exploited to offer protection means. Providing security can be costly in terms of higher energy consumption, calling for a wise use of these protection means. This paper exploits game theory to model interactions among collaborative deep learning nodes and to decide when using actions to support security enhancements.","","","10.1109/TII.2018.2853676","Basic Science Research Program; National Research Foundation of Korea; Ministry of Education; National Research Foundation of Korea; Government of South Korea (Ministry of Science and ICT); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8405583","Adversarial learning;collaborative learning;deep learning (DL);energy efficiency;game theory;privacy","Cryptography;Machine learning;Data privacy;Collaboration;Training data;Informatics","authorisation;cryptography;data privacy;game theory;learning (artificial intelligence)","industrial applications;adversarial scenarios;novel business possibilities;traditional centralized deployment;compromised nodes;traditional crypto primitives;access control models;protection means;collaborative deep learning nodes;security enhancements;game theory","","2","30","","","","","IEEE","IEEE Journals"
"Deep Hybrid Similarity Learning for Person Re-Identification","J. Zhu; H. Zeng; S. Liao; Z. Lei; C. Cai; L. Zheng","College of Engineering, Huaqiao University, Quanzhou, China; College of Information Science and Engineering, Huaqiao University, Xiamen, China; Center for Biometrics and Security Research and National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Center for Biometrics and Security Research and National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; College of Engineering, Huaqiao University, Quanzhou, China; College of Engineering, Huaqiao University, Quanzhou, China","IEEE Transactions on Circuits and Systems for Video Technology","","2018","28","11","3183","3193","Person re-identification (Re-ID) aims to match person images captured from two non-overlapping cameras. In this paper, a deep hybrid similarity learning (DHSL) method for person Re-ID based on a convolution neural network (CNN) is proposed. In our approach, a light CNN learning feature pair for the input image pair is simultaneously extracted. Then, both the elementwise absolute difference and multiplication of the CNN learning feature pair are calculated. Finally, a hybrid similarity function is designed to measure the similarity between the feature pair, which is realized by learning a group of weight coefficients to project the elementwise absolute difference and multiplication into a similarity score. Consequently, the proposed DHSL method is able to reasonably assign complexities of feature learning and metric learning in a CNN, so that the performance of person Re-ID is improved. Experiments on three challenging person Re-ID databases, QMUL GRID, VIPeR, and CUHK03, illustrate that the proposed DHSL method is superior to multiple state-of-the-art person Re-ID methods.","","","10.1109/TCSVT.2017.2734740","National Natural Science Foundation of China; Natural Science Foundation of Fujian Province; Scientific and Technology Founds of Xiamen; Huaqiao University; Scientific Research Funds of Huaqiao University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7999218","Metric learning;convolution neural network;deep hybrid similarity learning;person re-identification (Re-ID)","Euclidean distance;Convolution;Neural networks;Feature extraction;Correlation;DH-HEMTs","cameras;feature extraction;learning (artificial intelligence);neural nets","light CNN learning feature pair;multiple state-of-the-art person Re-ID methods;hybrid similarity function;elementwise absolute difference;input image pair;light CNN learning;convolution neural network;deep hybrid similarity learning method;nonoverlapping cameras;person images;person re-identification;challenging person Re-ID databases;metric learning;feature learning;DHSL method;similarity score","","9","48","","","","","IEEE","IEEE Journals"
"Cross Hardware-Software Boundary Exploration for Scalable and Optimized Deep Learning Platform Design","B. Chen; L. Wang; Q. Wu; Y. Tan; P. Zou","College of Computer Science, National University of Defense Technology, Changsha, China; College of Computer Science, National University of Defense Technology, Changsha, China; College of Computer Science, National University of Defense Technology, Changsha, China; College of Computer Science, National University of Defense Technology, Changsha, China; Science and Technology on Complex Electronic System Simulation Laboratory, Equipment Academy, Beijing, China","IEEE Embedded Systems Letters","","2018","10","4","107","110","Deep learning system composed with multiple levels of layers is increasingly presented in diverse areas nowadays. To achieve good performance, multicore CPUs and accelerators are widely used in real system. Previous study shows that GPU can significantly speed up computation in deep neural networks, while the performance does not scale very well on multicore CPUs. In this letter, we run Caffe on various hardware platforms using different computation setups to train LeNet-5 on MNIST dataset and measure individual time durations of forward and backward passes for each layer. We find that the speedups perform diversely and the scalability of multicore CPU varies when processing different stages of the network. Based on the observation, we show it is worth applying different policies for each layer separately to achieve the overall optimized performance. In addition, our benchmarking results can be used for references to develop dedicated acceleration methods for individual layer of the network.","","","10.1109/LES.2017.2776949","National S&T Major Project of China; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8119544","Artificial neural networks;deep learning;embedded computing;multicore system;multithreading","Graphics processing units;Multicore processing;Machine learning;Artificial neural networks;Embedded computing;Multithreading;Scalability","learning (artificial intelligence);multiprocessing systems;neural nets","cross hardware-software boundary exploration;optimized deep learning platform design;deep learning system;deep neural networks;LeNet-5;multicore CPU;acceleration methods;MNIST dataset","","1","14","","","","","IEEE","IEEE Journals"
"A Study on Deep Belief Net for Branch Prediction","Y. Mao; J. Shen; X. Gui","School of Electronic and Information Engineering, Xi’an Jiaotong University, Xi’an, China; Department of Electrical and Computer Engineering, North Carolina State University, Raleigh, NC, USA; School of Electronic and Information Engineering, Xi’an Jiaotong University, Xi’an, China","IEEE Access","","2018","6","","10779","10786","Since 2006, there have been significant advances in deep learning algorithms, and they have shown superior performance in audio and image processing. In this paper, we explore the feasibility of applying deep learning algorithms to branch prediction. We treat branch prediction as a classification problem and compare the effectiveness of deep learning with existing branch predictors. We make several interesting observations from our study. The first is that for branch prediction, the deep learning algorithm based on deep belief networks outperforms the prior work, but only outperforms state-of-the-art branch predictors, such as the TAgged GEometric length (TAGE) predictors, for several benchmarks. Compared with the much simpler perceptron branch classifier, the deep learning classifier reduces the average misprediction rate by 3%-4% for the benchmarks in this paper. Second, we analyze the impact of the length of hashed program counter, local history register, global history register, and branch global addresses of deep learning classifiers on the misprediction rate. Our results show that an adaptive length of the history information is a better choice than the longest history. Third, compared with TAGE, the hardware budget of our model is less than 1% of the TAGE predictor.","","","10.1109/ACCESS.2017.2772334","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8103746","Branch predictor;perceptron;misprediction rate;DBN;deep learning","Machine learning;History;Training;Benchmark testing;Prediction algorithms;Classification algorithms;Hardware","belief networks;learning (artificial intelligence);parallel architectures;pattern classification;perceptrons","branch predictors;branch global addresses;deep learning classifier;simpler perceptron branch classifier;deep belief networks;deep learning algorithm;branch prediction;deep belief net","","2","38","","","","","IEEE","IEEE Journals"
"Analyzing Tongue Images Using a Conceptual Alignment Deep Autoencoder","Y. Dai; G. Wang","School of Information Science and Engineering, Central South University, Changsha, China; School of Computer Science and Educational Software, Guangzhou University, Guangzhou, China","IEEE Access","","2018","6","","5962","5972","Artificial intelligence can learn some concepts by analyzing sensory data similarly to humans. This paper explores how artificial neural networks (ANNs) can learn abstract concepts by analyzing tongue images based on concepts from traditional Chinese medicine (TCM), which is a discipline that relies heavily on practitioner experience. A computer-aided method will be investigated that analyzes sensory data for TCM practitioners. This paper proposes capitalizing on deep learning techniques. A method called the conceptual alignment deep auto-encoder (CADAE) is proposed to analyze tongue images that represent different body constitution (BC) types, which are the underlying concepts in TCM. In the first step, CADAE encodes the images to a representation space; in the second step, it decodes the patterns. The experiments demonstrate that CADAE can learn effective representations of abstract concepts aligned with BC types by encoding the tongue images. Furthermore, the representation space of the hidden conceptual neurons can be visualized by a decoder network. The experiments also demonstrate that ANNs acquire different data perspectives when different loss functions are used for training. Numerous representation spaces of ANNs remain to be explored. To some extent, our exploration demonstrates that artificial intelligence (AI) has the ability to learn some concepts in a manner similarly to human beings. Based on this ability, AI shows promise in helping humans form new effective concepts that can facilitate medical development and alleviate the burdens of medical practitioners.","","","10.1109/ACCESS.2017.2788849","National Natural Science Foundation of China; Guangdong Provincial Natural Science Foundation; High-Level Talents Program of Higher Education in Guangdong Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8244274","Conceptual alignment deep autoencoder;deep learning;representation learning;tongue image;traditional Chinese medicine","Tongue;Machine learning;Medical diagnostic imaging;IEEE Constitution;Biological system modeling;Neurons","image coding;image representation;learning (artificial intelligence);medical image processing;medicine;neural nets","decoder network;pattern decoding;image encoding;sensory data;computer-aided method;body constitution types;tongue images;data perspectives;deep learning techniques;TCM practitioners;traditional Chinese medicine;artificial neural networks;conceptual alignment deep autoencoder;artificial intelligence;ANNs;hidden conceptual neurons;representation space;CADAE","","6","41","","","","","IEEE","IEEE Journals"
"ComNet: Combination of Deep Learning and Expert Knowledge in OFDM Receivers","X. Gao; S. Jin; C. Wen; G. Y. Li","National Mobile Communications Research Laboratory, Southeast University, Nanjing, China; National Mobile Communications Research Laboratory, Southeast University, Nanjing, China; Institute of Communications Engineering, National Sun Yat-sen University, Kaohsiung, Taiwan; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA","IEEE Communications Letters","","2018","22","12","2627","2630","In this letter, we propose a model-driven deep learning (DL) approach that combines DL with the expert knowledge to replace the existing orthogonal frequency-division multiplexing receiver in wireless communications. Different from the data-driven fully connected deep neural network (FC-DNN) method, we adopt the block-by-block signal processing method that divides the receiver into channel estimation subnet and signal detection subnet. Each subnet is constructed by a DNN and uses the existing simple and traditional solution as initialization. The proposed model-driven DL receiver offers more accurate channel estimation comparing with the linear minimum mean-squared error method and exhibits higher data recovery accuracy comparing with the existing methods and FC-DNN. Simulation results further demonstrate the robustness of the proposed approach in terms of signal-to-noise ratio and its superiority to the FC-DNN approach in the computational complexities or the memory usage.","","","10.1109/LCOMM.2018.2877965","National Science Foundation (NSFC) for Distinguished Young Scholars of China; National Natural Science Foundation of China; Ministry of Science and Technology, Taiwan; ITRI in Hsinchu, Taiwan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8509622","Deep learning;wireless communications;OFDM","Receivers;OFDM;Wireless communication;Machine learning;Learning data;Channel estimation;Signal to noise ratio","channel estimation;learning (artificial intelligence);least mean squares methods;neural nets;OFDM modulation;radio receivers;signal detection;telecommunication computing","linear minimum mean-squared error method;signal-to-noise ratio;FC-DNN approach;ComNet;expert knowledge;OFDM receivers;model-driven deep learning approach;wireless communications;block-by-block signal processing method;channel estimation subnet;signal detection subnet;model-driven DL receiver;data-driven FC-DNN method;data-driven fully connected deep neural network method;orthogonal frequency-division multiplexing receiver;data recovery accuracy","","14","12","","","","","IEEE","IEEE Journals"
"Deep Learning Based Pilot Allocation Scheme (DL-PAS) for 5G Massive MIMO System","K. Kim; J. Lee; J. Choi","Department of Electrical Engineering, KAIST, Daejeon, South Korea; Department of Software, Gachon University, Seongnam, South Korea; Department of Electrical Engineering, KAIST, Daejeon, South Korea","IEEE Communications Letters","","2018","22","4","828","831","This letter proposes a deep learning-based pilot assignment scheme (DL-PAS) for a massive multiple-input multiple-output (massive MIMO) system that utilizes a large number of antennas for multiple users. The proposed DL-PAS improves the performance in cellular networks with severe pilot contamination by learning the relationship between pilot assignment and the users' location pattern. In this letter, we design a novel supervised learning method, where input features and output labels are users' locations in all cells and pilot assignments, respectively. Specifically, pretrained optimal pilot assignments with given users' locations are provided through an exhaustive search method as the training data. Then, the proposed DL-PAS provides a near-optimal pilot assignment from the produced inferred function by analyzing the training data. We implement the proposed scheme using a commercial deep multilayer perceptron system. Simulation-based experiments show that the proposed scheme achieves almost 99.38% theoretical upper-bound performance with low complexity, requiring only 0.92-ms computational time.","","","10.1109/LCOMM.2018.2803054","National Research Council of Science and Technology (NST); Korea government (MSIP); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8283585","Pilot contamination;pilot assignment;massive MIMO;SNR;deep learning","Machine learning;MIMO communication;Base stations;Antennas;Contamination;Interference;Resource management","5G mobile communication;antenna arrays;cellular radio;learning (artificial intelligence);MIMO communication;multilayer perceptrons;resource allocation","DL-PAS;pilot assignment scheme;massive multiple-input multiple-output system;pretrained optimal pilot assignments;near-optimal pilot assignment;commercial deep multilayer perceptron system;deep learning based pilot allocation scheme;5G massive MIMO system;cellular networks;user location pattern;supervised learning method","","14","10","","","","","IEEE","IEEE Journals"
"Automatic Modulation Classification: A Deep Learning Enabled Approach","F. Meng; P. Chen; L. Wu; X. Wang","School of Information Science and Engineering, Southeast University, Nanjing, China; State Key Laboratory of Millimeter Waves, Southeast University, Nanjing, China; School of Information Science and Engineering, Southeast University, Nanjing, China; Department of Electrical and Computer Engineering, Western University, London, ON, Canada","IEEE Transactions on Vehicular Technology","","2018","67","11","10760","10772","Automatic modulation classification (AMC), which plays critical roles in both civilian and military applications, is investigated in this paper through a deep learning approach. Conventional AMCs can be categorized into maximum likelihood (ML) based (ML-AMC) and feature-based AMC. However, the practical deployment of ML-AMCs is difficult due to its high computational complexity, and the manually extracted features require expert knowledge. Therefore, an end-to-end convolution neural network (CNN) based AMC (CNN-AMC) is proposed, which automatically extracts features from the long symbol-rate observation sequence along with the estimated signal-to-noise ratio (SNR). With CNNAMC, a unit classifier is adopted to accommodate the varying input dimensions. The direct training of CNN-AMC is challenging with the complicated model and complex tasks, so a novel two-step training is proposed, and the transfer learning is also introduced to improve the efficiency of retraining. Different digital modulation schemes have been considered in distinct scenarios, and the simulation results show that the CNN-AMC can outperform the feature-based method, and obtain a closer approximation to the optimal ML-AMC. Besides, CNN-AMCs have the certain robustness to estimation error on carrier phase offset and SNR. With parallel computation, the deep-learning-based approach is about 40 to 1700 times faster than the ML-AMC regarding inference speed.","","","10.1109/TVT.2018.2868698","National Natural Science Foundation of China; Natural Science Foundation of Jiangsu Province; State Key Laboratory of Millimeter Waves in Southeast University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8454504","Automatic modulation classification;convolution neural network;deep learning;two-step training","Modulation;Feature extraction;Signal to noise ratio;Training;Machine learning;Receivers;Convolution","computational complexity;feature extraction;learning (artificial intelligence);modulation;neural nets","automatic modulation classification;deep learning approach;end-to-end convolution neural network;CNN-AMC;feature-based method;optimal ML-AMC;deep-learning-based approach;conventional AMC","","9","39","","","","","IEEE","IEEE Journals"
"Learning Deep Off-the-Person Heart Biometrics Representations","E. J. da Silva Luz; G. J. P. Moreira; L. S. Oliveira; W. R. Schwartz; D. Menotti","Computing Department, Federal University of Ouro Preto, Ouro Preto, Brazil; Computing Department, Federal University of Ouro Preto, Ouro Preto, Brazil; Department of Informatics, Federal University of Paraná, Curitiba, Brazil; Department of Computer Science, Federal University of Minas Gerais, Belo Horizonte, Brazil; Department of Informatics, Federal University of Paraná, Curitiba, Brazil","IEEE Transactions on Information Forensics and Security","","2018","13","5","1258","1270","Since the beginning of the new millennium, the electrocardiogram (ECG) has been studied as a biometric trait for security systems and other applications. Recently, with devices such as smartphones and tablets, the acquisition of ECG signal in the off-the-person category has made this biometric signal suitable for real scenarios. In this paper, we introduce the usage of deep learning techniques, specifically convolutional networks, for extracting useful representation for heart biometrics recognition. Particularly, we investigate the learning of feature representations for heart biometrics through two sources: on the raw heartbeat signal and on the heartbeat spectrogram. We also introduce heartbeat data augmentation techniques, which are very important to generalization in the context of deep learning approaches. Using the same experimental setup for six methods in the literature, we show that our proposal achieves state-of-the-art results in the two off-the-person publicly available databases.","","","10.1109/TIFS.2017.2784362","UFOP, UFPR, UFMG, FAPEMIG; CAPES; CNPq; IBM Ph.D. fellowship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8219706","Electrocardiogram;biometric systems;deep learning;off-the-person category","Electrocardiography;Biometrics (access control);Databases;Heart beat;Machine learning;Feature extraction","biometrics (access control);electrocardiography;feature extraction;learning (artificial intelligence);medical signal processing;security of data;signal representation","heartbeat data augmentation techniques;deep learning approaches;off-the-person publicly available databases;off-the-person heart biometrics representations;electrocardiogram;biometric trait;security systems;smartphones;tablets;ECG signal;off-the-person category;biometric signal suitable;deep learning techniques;specifically convolutional networks;heart biometrics recognition;feature representations;raw heartbeat signal;heartbeat spectrogram","","7","37","","","","","IEEE","IEEE Journals"
"Anti-Jamming Underwater Transmission With Mobility and Learning","L. Xiao; Donghua; Jiang; X. Wan; W. Su; Y. Tang","Department of Communication Engineering, Xiamen University, Xiamen, China; Department of Communication Engineering, Xiamen University, Xiamen, China; Department of Communication Engineering, Xiamen University, Xiamen, China; Department of Communication Engineering, Xiamen University, Xiamen, China; Department of Communication Engineering, Xiamen University, Xiamen, China; Department of Communication Engineering, Xiamen University, Xiamen, China","IEEE Communications Letters","","2018","22","3","542","545","In this letter, we present an anti-jamming underwater transmission framework that applies reinforcement learning to control the transmit power and uses the transducer mobility to address jamming in underwater acoustic networks. The deep Q-networks-based transmission scheme can achieve the optimal power and node mobility control without knowing the jamming model and the underwater channel model in the dynamic game. Experiments performed with transducers in a non-anechoic pool show that our proposed scheme can reduce the bit error rate of the underwater transmission against reactive jamming compared with the Q-learning based scheme.","","","10.1109/LCOMM.2018.2792015","National Natural Science Foundation of China; National Mobile Communications Research Laboratory Southeast University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8254362","Jamming;underwater transmission;reinforcement learning;deep Q-networks","Jamming;Signal to noise ratio;Interference;Acoustics;Transducers;Power control;Learning (artificial intelligence)","error statistics;jamming;learning (artificial intelligence);underwater acoustic communication","anti-jamming underwater transmission framework;underwater acoustic networks;deep Q-networks;transmission scheme;optimal power;node mobility control;underwater channel model;reactive jamming;Q-learning based scheme","","6","12","","","","","IEEE","IEEE Journals"
"Runtime Programmable and Memory Bandwidth Optimized FPGA-Based Coprocessor for Deep Convolutional Neural Network","N. Shah; P. Chaudhari; K. Varghese","Department of Electronic Systems Engineering, Indian Institute of Science, Bangalore, India; Department of Electronic Systems Engineering, Indian Institute of Science, Bangalore, India; Department of Electronic Systems Engineering, Indian Institute of Science, Bangalore, India","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","12","5922","5934","The deep convolutional neural network (DCNN) is a class of machine learning algorithms based on feed-forward artificial neural network and is widely used for image processing applications. Implementation of DCNN in real-world problems needs high computational power and high memory bandwidth, in a power-constrained environment. A general purpose CPU cannot exploit different parallelisms offered by these algorithms and hence is slow and energy inefficient for practical use. We propose a field-programmable gate array (FPGA)-based runtime programmable coprocessor to accelerate feed-forward computation of DCNNs. The coprocessor can be programmed for a new network architecture at runtime without resynthesizing the FPGA hardware. Hence, it acts as a plug-and-use peripheral for the host computer. Caching is implemented for input features and filter weights using on-chip memory to reduce the external memory bandwidth requirement. Data are prefetched at several stages to avoid stalling of computational units and different optimization techniques are used to efficiently reuse the fetched data. Dataflow is dynamically adjusted in runtime for each DCNN layer to achieve consistent computational throughput across a wide range of input feature sizes and filter sizes. The coprocessor is prototyped using Xilinx Virtex-7 XC7VX485T FPGA-based VC707 board and operates at 150 MHz. Experimental results show that our implementation is 15× energy efficient than highly optimized CPU implementation and achieves consistent computational throughput of more than 140 G operations/s for a wide range of input feature sizes and filter sizes. Off-chip memory transactions decrease by 111× due to the use of the on-chip cache.","","","10.1109/TNNLS.2018.2815085","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8333773","Accelerator;coprocessor;deep convolutional neural network (DCNN);deep learning;field-programmable gate array (FPGA);runtime programmable","Coprocessors;Convolutional neural networks;Deep learning;Field programmable gate arrays;Bandwidth","coprocessors;field programmable gate arrays;learning (artificial intelligence);recurrent neural nets","memory bandwidth requirement;memory bandwidth;computational power;off-chip memory transactions;Xilinx Virtex-7 XC7VX485T FPGA-based VC707 board;DCNN layer;on-chip memory;FPGA hardware;network architecture;field-programmable gate array-based runtime programmable coprocessor;general purpose CPU;power-constrained environment;image processing applications;feed-forward artificial neural network;deep convolutional neural network;memory bandwidth optimized FPGA-based coprocessor;frequency 150.0 MHz","","5","35","","","","","IEEE","IEEE Journals"
"Deep-PRWIS: Periocular Recognition Without the Iris and Sclera Using Deep Learning Frameworks","H. Proença; J. C. Neves","Department of Computer Science, IT: Instituto de Telecomunicações, University of Beira Interior, Covilhã, Portugal; Department of Computer Science, IT: Instituto de Telecomunicações, University of Beira Interior, Covilhã, Portugal","IEEE Transactions on Information Forensics and Security","","2018","13","4","888","896","This paper is based on a disruptive hypothesis for periocular biometrics-in visible-light data, the recognition performance is optimized when the components inside the ocular globe (the iris and the sclera) are simply discarded, and the recognizer's response is exclusively based on the information from the surroundings of the eye. As a major novelty, we describe a processing chain based on convolution neural networks (CNNs) that defines the regions-of-interest in the input data that should be privileged in an implicit way, i.e., without masking out any areas in the learning/test samples. By using an ocular segmentation algorithm exclusively in the learning data, we separate the ocular from the periocular parts. Then, we produce a large set of “multi-class” artificial samples, by interchanging the periocular and ocular parts from different subjects. These samples are used for data augmentation purposes and feed the learning phase of the CNN, always considering as label the ID of the periocular part. This way, for every periocular region, the CNN receives multiple samples of different ocular classes, forcing it to conclude that such regions should not be considered in its response. During the test phase, samples are provided without any segmentation mask and the network naturally disregards the ocular components, which contributes for improvements in performance. Our experiments were carried out in full versions of two widely known data sets (UBIRIS.v2 and FRGC) and show that the proposed method consistently advances the state-of-the-art performance in the closed-world setting, reducing the EERs in about 82% (UBIRIS.v2) and 85% (FRGC) and improving the Rank-1 over 41% (UBIRIS.v2) and 12% (FRGC).","","","10.1109/TIFS.2017.2771230","FCT Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8101565","Soft biometrics;visual surveillance;homeland security","Iris recognition;Convolution;Eyelids;Feature extraction;Machine learning","biometrics (access control);convolution;eye;face recognition;feedforward neural nets;image classification;image segmentation;iris recognition;learning (artificial intelligence);optimisation","learning phase;periocular part;periocular region;segmentation mask;ocular components;periocular recognition;iris;sclera;deep learning;disruptive hypothesis;periocular biometrics;visible-light data;ocular globe;processing chain;convolution neural networks;learning/test samples;ocular segmentation algorithm;learning data;artificial samples;periocular parts;CNNs;recognition performance optimisation;multi-class artificial samples;Deep-PRWIS;data augmentation;ocular classes","","15","27","","","","","IEEE","IEEE Journals"
"A Fingerprint Method for Indoor Localization Using Autoencoder Based Deep Extreme Learning Machine","Z. E. Khatab; A. Hajihoseini; S. A. Ghorashi","Department of Electrical Engineering, Cognitive Telecommunication Research Group, Shahid Beheshti University, Tehran, Iran; Department of Electrical Engineering, Cognitive Telecommunication Research Group, Shahid Beheshti University, Tehran, Iran; Department of Electrical Engineering, Cognitive Telecommunication Research Group, Shahid Beheshti University, Tehran, Iran","IEEE Sensors Letters","","2018","2","1","1","4","By growing the demand for location based services in indoor environments in recent years, fingerprint based indoor localization has attracted much research interest. The fingerprint localization method works based on received signal strength (RSS) in wireless sensor networks. This method uses RSS measurements from available transmitter sensors, which are collected by a smart phone with internal sensors. In this article, we propose a novel algorithm that takes advantage of deep learning, extreme learning machines, and high level extracted features by autoencoder to improve the localization performance in the feature extraction and the classification. Furthermore, as the fingerprint database needs to be updated (due to the dynamic nature of environment), we also increase the number of training data, in order to improve the localization performance, gradually. Simulation results indicate that the proposed method provides a significant improvement in localization performance by using high level extracted features by autoencoder and increasing the number of training data.","","","10.1109/LSENS.2017.2787651","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8240634","Sensor applications;indoor localization;fingerprint;wireless sensor network;autoencoder;deep extreme learning machine","Feature extraction;Sensors;Training;Wireless sensor networks;Neurons;Decoding;Machine learning","codecs;feature extraction;fingerprint identification;indoor communication;indoor environment;indoor radio;learning (artificial intelligence);radionavigation;RSSI;telecommunication computing;wireless sensor networks","transmitter sensors;internal sensors;RSS measurements;wireless sensor networks;received signal strength;fingerprint localization method;fingerprint based indoor localization;indoor environments;location based services;deep extreme learning machine;fingerprint method;fingerprint database;feature extraction;localization performance;autoencoder;extreme learning machines;deep learning","","14","24","","","","","IEEE","IEEE Journals"
"A Computer Vision-Inspired Deep Learning Architecture for Virtual Metrology Modeling With 2-Dimensional Data","M. Maggipinto; M. Terzi; C. Masiero; A. Beghi; G. A. Susto","Department of Information Engineering, University of Padova, Padua, Italy; Department of Information Engineering and with the Human Inspired Technology Research Center, University of Padova, Padua, Italy; Department of Information Engineering, University of Padova, Padua, Italy; Department of Information Engineering and with the Human Inspired Technology Research Center, University of Padova, Padua, Italy; Department of Information Engineering and with the Human Inspired Technology Research Center, University of Padova, Padua, Italy","IEEE Transactions on Semiconductor Manufacturing","","2018","31","3","376","384","The rise of industry 4.0 and data-intensive manufacturing makes advanced process control (APC) applications more relevant than ever for process/production optimization, related costs reduction, and increased efficiency. One of the most important APC technologies is virtual metrology (VM). VM aims at exploiting information already available in the process/system under exam, to estimate quantities that are costly or impossible to measure. Machine learning (ML) approaches are the foremost choice to design VM solutions. A serious drawback of traditional ML methodologies is that they require a features extraction phase that generally limits the scalability and performance of VM solutions. Particularly, in presence of multi-dimensional data, the feature extraction process is based on heuristic approaches that may capture features with poor predictive power. In this paper, we exploit modern deep learning (DL)-based technologies that are able to automatically extract highly informative features from the data, providing more accurate and scalable VM solutions. In particular, we exploit DL architectures developed in the realm of computer vision to model data that have both spatial and time evolution. The proposed methodology is tested on a real industrial dataset related to etching, one of the most important semiconductor manufacturing processes. The dataset at hand contains optical emission spectroscopy data and it is paradigmatic of the feature extraction problem in VM under examination.","","","10.1109/TSM.2018.2849206","Horizon 2020 Framework Programme; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8390943","Advanced process control;deep learning;etching;industry 4.0;neural networks;optical emission spectroscopy;semiconductor manufacturing;soft sensor;virtual metrology","Feature extraction;Machine learning;Manufacturing;Computer architecture;Data models;Computational modeling;Neurons","computer vision;cost reduction;feature extraction;learning (artificial intelligence);manufacturing processes;process control;process monitoring;production engineering computing;semiconductor device manufacture;semiconductor industry","machine learning approaches;features extraction phase;scalability;multidimensional data;feature extraction process;heuristic approaches;highly informative features;accurate VM solutions;scalable VM solutions;DL architectures;model data;industrial dataset;optical emission spectroscopy data;feature extraction problem;virtual metrology modeling;2-dimensional data;data-intensive manufacturing;process control applications;process/production optimization;related costs reduction;semiconductor manufacturing processes;APC technologies;deep learning-based technologies;computer vision-inspired deep learning architecture;industry 4.0","","2","38","","","","","IEEE","IEEE Journals"
"An Efficient Deep Learning Model to Predict Cloud Workload for Industry Informatics","Q. Zhang; L. T. Yang; Z. Yan; Z. Chen; P. Li","School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; State Key Laboratory on Integrated Services Networks, School of Cyber Engineering, Xidian University, Xian, China; School of Software Technology, Dalian University of Technology, Dalian, China; School of Software Technology, Dalian University of Technology, Dalian, China","IEEE Transactions on Industrial Informatics","","2018","14","7","3170","3178","Deep learning, as the most important architecture of current computational intelligence, achieves super performance to predict the cloud workload for industry informatics. However, it is a nontrivial task to train a deep learning model efficiently since the deep learning model often includes a great number of parameters. In this paper, an efficient deep learning model based on the canonical polyadic decomposition is proposed to predict the cloud workload for industry informatics. In the proposed model, the parameters are compressed significantly by converting the weight matrices to the canonical polyadic format. Furthermore, an efficient learning algorithm is designed to train the parameters. Finally, the proposed efficient deep learning model is applied to the workload prediction of virtual machines on cloud. Experiments are conducted on the datasets collected from PlanetLab to validate the performance of the proposed model by comparing with other machine-learning-based approaches for workload prediction of virtual machines. Results indicate that the proposed model achieves a higher training efficiency and workload prediction accuracy than state-of-the-art machine-learning-based approaches, proving the potential of the proposed model to provide predictive services for industry informatics.","","","10.1109/TII.2018.2808910","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8301555","Canonical polyadic decomposition;cloud workload prediction;deep learning;industry informatics","Tensile stress;Informatics;Cloud computing;Machine learning;Virtual machining;Industries;Computational modeling","cloud computing;learning (artificial intelligence);virtual machines","cloud workload;industry informatics;workload prediction;deep learning model;machine-learning-based approaches;canonical polyadic decomposition;virtual machines;PlanetLab","","13","30","","","","","IEEE","IEEE Journals"
"Deep Learning for Link Prediction in Dynamic Networks Using Weak Estimators","C. Chiu; J. Zhan","Department of Computer Science, University of Nevada at Las Vegas, Las Vegas, NV, USA; Department of Computer Science, University of Nevada at Las Vegas, Las Vegas, NV, USA","IEEE Access","","2018","6","","35937","35945","Link prediction is the task of evaluating the probability that an edge exists in a network, and it has useful applications in many domains. Traditional approaches rely on measuring the similarity between two nodes in a static context. Recent research has focused on extending link prediction to a dynamic setting, predicting the creation and destruction of links in networks that evolve over time. Though a difficult task, the employment of deep learning techniques has shown to make notable improvements to the accuracy of predictions. To this end, we propose the novel application of weak estimators in addition to the utilization of traditional similarity metrics to inexpensively build an effective feature vector for a deep neural network. Weak estimators have been used in a variety of machine learning algorithms to improve model accuracy, owing to their capacity to estimate the changing probabilities in dynamic systems. Experiments indicate that our approach results in increased prediction accuracy on several real-world dynamic networks.","","","10.1109/ACCESS.2018.2845876","U.S. Department of Defense; National Science Foundation; United Healthcare Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8379423","Deep learning;link prediction;dynamic networks;weak estimators;similarity metrics","Measurement;Machine learning;Task analysis;Neural networks;Heuristic algorithms;Social network services;Prediction algorithms","learning (artificial intelligence);neural nets;probability","link prediction;deep learning techniques;weak estimators;deep neural network;real-world dynamic networks;similarity metrics;probability;machine learning","","8","50","","","","","IEEE","IEEE Journals"
"Reconstruction Algorithm for Lost Frame of Multiview Videos in Wireless Multimedia Sensor Network Based on Deep Learning Multilayer Perceptron Regression","T. Lin; H. Tseng; Y. Wen; F. Lai; C. Lin; C. Wang","Department of Electronic Engineering, National Taipei University of Technology, Taipei, Taiwan; Department of Electronic Engineering, Chung Yuan Christian University, Taoyuan, Taiwan; Department of Computer Science, University of California at Davis, Davis, CA, USA; Department of Electronic Engineering, Chung Yuan Christian University, Taoyuan, Taiwan; Department of Electronic Engineering, Chung Yuan Christian University, Taoyuan, Taiwan; Department of Electronic Engineering, Chung Yuan Christian University, Taoyuan, Taiwan","IEEE Sensors Journal","","2018","18","23","9792","9801","Wireless multimedia sensor network (WMSN) is important for environmental monitoring. When the sensors are used as cameras, the network can be regarded as a multiview video system. The Packet loss may occur when the multiview videos are transmitted wirelessly. When the video frames are lost during transmission, a frame reconstruction method is needed in the decoder to estimate the missing pixels. In the proposed work, a reconstruction algorithm for lost frame of multiview videos in the WMSN based on deep learning methods is presented. A novel pixel estimation algorithm is developed using multilayer perceptron regression (MPR) with the deep learning method. Furthermore, a modified inpainting method is proposed with the use of the information from the optical flow algorithm with the neighboring available frames. Compared with the state-of-the-art method, the proposed MPR method with the traditional inpainting method increased the average peak signal-to-noise ratio up to 5.62 dB. The combination of the proposed MPR method with the proposed inpainting method outperformed previous proposed combination up to 8.32 dB on average, showing the significance of the proposed inpainting method.","","","10.1109/JSEN.2018.2865916","Ministry of Science and Technology, Taiwan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8439010","Wireless multimedia sensor network (WMSN);multiview video system;frame loss recovery;error concealment;multilayer perceptron regression (MPR);deep learning;inpainting;optical flow","Machine learning;Videos;Sensors;Wireless sensor networks;Multilayer perceptrons;Wireless communication;Streaming media","image resolution;image restoration;image sequences;learning (artificial intelligence);multilayer perceptrons;multimedia communication;regression analysis;video coding;wireless sensor networks","signal-to-noise ratio;multilayer perceptron regression;pixel estimation algorithm;MPR method;optical flow algorithm;modified inpainting method;deep learning method;frame reconstruction method;video frames;multiview video system;WMSN;deep learning multilayer perceptron regression;wireless multimedia sensor network;lost frame;reconstruction algorithm","","1","30","","","","","IEEE","IEEE Journals"
"A Self-Adaptive Deep Learning-Based System for Anomaly Detection in 5G Networks","L. Fernández Maimó; Á. L. Perales Gómez; F. J. García Clemente; M. Gil Pérez; G. Martínez Pérez","Departamento de Ingeniería y Tecnología de Computadores, University of Murcia, Murcia, Spain; Departamento de Ingeniería y Tecnología de Computadores, University of Murcia, Murcia, Spain; Departamento de Ingeniería y Tecnología de Computadores, University of Murcia, Murcia, Spain; Departamento de Ingeniería de la Información y las Comunicaciones, University of Murcia, Murcia, Spain; Departamento de Ingeniería de la Información y las Comunicaciones, University of Murcia, Murcia, Spain","IEEE Access","","2018","6","","7700","7712","The upcoming fifth-generation (5G) mobile technology, which includes advanced communication features, is posing new challenges on cybersecurity defense systems. Although innovative approaches have evolved in the last few years, 5G will make existing intrusion detection and defense procedures become obsolete, in case they are not adapted accordingly. In this sense, this paper proposes a novel 5G-oriented cyberdefense architecture to identify cyberthreats in 5G mobile networks efficient and quickly enough. For this, our architecture uses deep learning techniques to analyze network traffic by extracting features from network flows. Moreover, our proposal allows adapting, automatically, the configuration of the cyberdefense architecture in order to manage traffic fluctuation, aiming both to optimize the computing resources needed in each particular moment and to fine tune the behavior and the performance of analysis and detection processes. Experiments using a well-known botnet data set depict how a neural network model reaches a sufficient classification accuracy in our anomaly detection system. Extended experiments using diverse deep learning solutions analyze and determine their suitability and performance for different network traffic loads. The experimental results show how our architecture can self-adapt the anomaly detection system based on the volume of network flows gathered from 5G subscribers' user equipments in real-time and optimizing the resource consumption.","","","10.1109/ACCESS.2018.2803446","European Commission Horizon 2020 Programme (Framework for Self-Organized Network Management in Virtualized and Software-Defined Networks); Spanish MICINN (Project DHARMA, Dynamic Heterogeneous Threats Risk Management and Assessment); European Commission (FEDER/ERDF); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8283694","5G;anomaly detection;botnets;deep learning;performance evaluation","Anomaly detection;5G mobile communication;Machine learning;Botnet;Computer architecture;Feature extraction","5G mobile communication;computer network security;invasive software;learning (artificial intelligence);neural nets;security of data;telecommunication traffic","cybersecurity defense systems;intrusion detection;cyberdefense architecture;deep learning techniques;neural network model;self-adaptive deep learning-based system;anomaly detection;5G mobile networks;network traffic analysis;botnet data","","14","35","","","","","IEEE","IEEE Journals"
"Deep Context-Sensitive Facial Landmark Detection With Tree-Structured Modeling","J. Zeng; S. Liu; X. Li; D. A. Mahdi; F. Wu; G. Wang","College of Computer Science and Technology, Zhejiang University, Hangzhou, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China; AI Laboratories, Alibaba Group, Hangzhou, China","IEEE Transactions on Image Processing","","2018","27","5","2096","2107","Facial landmark detection is typically cast as a point-wise regression problem that focuses on how to build an effective image-to-point mapping function. In this paper, we propose an end-to-end deep learning approach for contextually discriminative feature construction together with effective facial structure modeling. The proposed learning approach is able to predict more contextually discriminative facial landmarks by capturing their associated contextual information. Moreover, we present a tree model to characterize human face structure and a structural loss function to measure the deformation cost between the ground-truth and predicted tree model, which are further incorporated into the proposed learning approach and jointly optimized within a unified framework. The presented tree model is able to well characterize the spatial layout patterns of facial landmarks for capturing the facial structure information. Experimental results demonstrate the effectiveness of the proposed approach against the state-of-the-art over the MTFL and AFLW-full data sets.","","","10.1109/TIP.2017.2784571","National Natural Science Foundation of China; Alibaba-Zhejiang University Joint Institute of Frontier Technologies; National Basic Research Program of China; Key Research and Development Program of Zhejiang Province; China Engineering Knowledge Center; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8219746","Facial landmark detection;deep learning;CNN;tree-structured modeling;context constraint","Face;Context modeling;Predictive models;Feature extraction;Shape;Loss measurement","face recognition;feature extraction;learning (artificial intelligence);regression analysis;trees (mathematics)","effective image-to-point mapping function;end-to-end deep learning approach;contextually discriminative feature construction;effective facial structure modeling;associated contextual information;human face structure;structural loss function;facial structure information;deep context-sensitive facial landmark detection;point-wise regression problem;contextually discriminative facial landmarks;predicted tree model;spatial layout patterns","Algorithms;Anatomic Landmarks;Databases, Factual;Deep Learning;Face;Humans;Image Processing, Computer-Assisted","1","52","","","","","IEEE","IEEE Journals"
"Application of quantisation-based deep-learning model compression in JPEG image steganalysis","X. Wu; Z. Shao; P. Ou; S. Tan","College of Information Engineering, People's Republic of China; College of Computer Science and Software Engineering, Shenzhen University, People's Republic of China; College of Computer Science and Software Engineering, Shenzhen University, People's Republic of China; College of Computer Science and Software Engineering, Shenzhen University, People's Republic of China","The Journal of Engineering","","2018","2018","16","1402","1406","Steganography can hide secret information in an innocent cover medium. Its opponent is steganalysis, which is used to discriminate whether a suspicious carrier contains a hidden message or not. With the rapid development of deep-learning frameworks, deep-learning-based steganalytic models have hold the dominant position in the field of steganalysis. In recent years, some scholars have successfully utilised model compression methods in the field of image classification. However, as far as the authors know, no prior works are devoted to the application of model compression methods in the field of deep-learning-based steganalysis. In this study, the authors explore the effect of two quantisation schemes, namely 8-bit calculation and floating-point calculation, on the performance of XuNet, a state-of-the-art deep-learning steganalytic model. The experimental results show that the two deep-learning model quantisation schemes are applicable to steganalysis. It is even possible to compress the network size while retaining satisfactory performance.","","","10.1049/joe.2018.8299","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8543754","","","steganography;learning (artificial intelligence);data compression;image coding;floating point arithmetic;quantisation (signal)","JPEG image steganalysis;hidden message;image classification;cover medium;quantisation based deep learning model compression;deep learning based steganalytic models;floating point calculation;XuNet;suspicious carrier;steganography;secret information hiding;8-bit calculation","","","15","","","","","IET","IET Journals"
"Phase-Sensitive Joint Learning Algorithms for Deep Learning-Based Speech Enhancement","J. Lee; J. Skoglund; T. Shabestary; H. Kang","Department of Electrical and Electronic Engineering, Yonsei University, Seoul, South Korea; Google, Inc., Mountain View, CA, USA; Google, Inc., Mountain View, CA, USA; Department of Electrical and Electronic Engineering, Yonsei University, Seoul, South Korea","IEEE Signal Processing Letters","","2018","25","8","1276","1280","This letter presents a phase-sensitive joint learning algorithm for single-channel speech enhancement. Although a deep learning framework that estimates the time-frequency (T-F) domain ideal ratio masks demonstrates a strong performance, it is limited in the sense that the enhancement process is performed only in the magnitude domain, while the phase spectra remain unchanged. Thus, recent studies have been conducted to involve phase spectra in speech enhancement systems. A phase-sensitive mask (PSM) is a T-F mask that implicitly represents phase-related information. However, since the PSM has an unbounded value, the networks are trained to target its truncated values rather than directly estimating it. To effectively train the PSM, we first approximate it to have a bounded dynamic range under the assumption that speech and noise are uncorrelated. We then propose a joint learning algorithm that trains the approximated value through its parameterized variables in order to minimize the inevitable error caused by the truncation process. Specifically, we design a network that explicitly targets three parameterized variables: 1) speech magnitude spectra; 2) noise magnitude spectra; and 3) phase difference of clean to noisy spectra. To further improve the performance, we also investigate how the dynamic range of magnitude spectra controlled by a warping function affects the final performance in joint learning algorithms. Finally, we examined how the proposed additional constraint that preserves the sum of the estimated speech and noise power spectra affects the overall system performance. The experimental results show that the proposed learning algorithm outperforms the conventional learning algorithm with the truncated phase-sensitive approximation.","","","10.1109/LSP.2018.2849578","Google Inc.; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8392411","Phase-sensitive objective function;joint learning;single-channel speech enhancement","Speech enhancement;Noise measurement;Signal processing algorithms;Approximation algorithms;Linear programming;Dynamic range;Estimation","learning (artificial intelligence);speech enhancement;time-frequency analysis","phase-sensitive joint learning algorithm;deep learning-based speech enhancement;single-channel speech enhancement;deep learning framework;phase spectra;speech enhancement systems;phase-sensitive mask;PSM;estimated speech;noise power spectra;truncated phase-sensitive approximation;time-frequency domain ideal ratio masks;parameterized variables;speech magnitude spectra","","4","22","","","","","IEEE","IEEE Journals"
"Deep Learning for Automated Extraction of Primary Sites From Cancer Pathology Reports","J. X. Qiu; H. Yoon; P. A. Fearn; G. D. Tourassi","University of Tennessee, Knoxville, TN, USA; Biomedical Sciences, Engineering, and Computing Group, Computational Sciences and Engineering Division and the Health Data Sciences Institute, Oak Ridge National Laboratory, Oak Ridge, TN, USA; National Cancer Institute, Surveillance Research Program, Bethesda, MD, USA; Biomedical Sciences, Engineering, and Computing Group, Computational Sciences and Engineering Division and the Health Data Sciences Institute, Oak Ridge National Laboratory, Oak Ridge, TN, USA","IEEE Journal of Biomedical and Health Informatics","","2018","22","1","244","251","Pathology reports are a primary source of information for cancer registries which process high volumes of free-text reports annually. Information extraction and coding is a manual, labor-intensive process. In this study, we investigated deep learning and a convolutional neural network (CNN), for extracting ICD-O-3 topographic codes from a corpus of breast and lung cancer pathology reports. We performed two experiments, using a CNN and a more conventional term frequency vector approach, to assess the effects of class prevalence and inter-class transfer learning. The experiments were based on a set of 942 pathology reports with human expert annotations as the gold standard. CNN performance was compared against a more conventional term frequency vector space approach. We observed that the deep learning models consistently outperformed the conventional approaches in the class prevalence experiment, resulting in micro- and macro-F score increases of up to 0.132 and 0.226, respectively, when class labels were well populated. Specifically, the best performing CNN achieved a micro-F score of 0.722 over 12 ICD-O-3 topography codes. Transfer learning provided a consistent but modest performance boost for the deep learning methods but trends were contingent on the CNN method and cancer site. These encouraging results demonstrate the potential of deep learning for automated abstraction of pathology reports.","","","10.1109/JBHI.2017.2700722","Joint Design of Advanced Computing Solutions; U.S. Department of Energy; National Cancer Institute of the National Institutes of Health; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7918552","Convolutional neural network;deep learning;information extraction;natural language processing;pathology reports;primary cancer site","","cancer;learning (artificial intelligence);lung;medical computing;neural nets","ICD-O-3 topographic codes;convolutional neural network;deep learning methods;micro-F score;macro-F score;deep learning models;frequency vector space approach;CNN performance;interclass transfer learning;frequency vector approach;lung cancer pathology reports;information coding;information extraction;cancer registries;automated extraction","","9","24","","","","","IEEE","IEEE Journals"
"Domestic Violence Crisis Identification From Facebook Posts Based on Deep Learning","S. Subramani; H. Wang; H. Q. Vu; G. Li","Institute for Sustainable Industries and Liveable Cities, Victoria University, Melbourne, VIC, Australia; Institute for Sustainable Industries and Liveable Cities, Victoria University, Melbourne, VIC, Australia; Centre for Tourism and Regional Opportunities, School of Engineering and Technology, Central Queensland University, Australia; School of Information Technology, Deakin University, Geelong, VIC, Australia","IEEE Access","","2018","6","","54075","54085","Domestic violence (DV) is a cause of concern due to the threat it poses toward public health and human rights. There is a need for quick identification of the victims of this condition so that DV crisis service (DVCS) can offer necessary support in a timely manner. The availability of social media has allowed DV victims to share their stories and receive support from the community, which opens an opportunity for DVCS to actively approach and support DV victims. However, it is time consuming and inefficient to manually browse through a massive number of available posts. This paper adopts deep learning as an approach for automatic identification of DV victims in critical need. Empirical evidence on a ground truth data set has achieved an accuracy of up to 94%, which outperforms traditional machine-learning techniques. The analysis of informative features helps to identify important words which might indicate critical posts in the classification process. The experimental results are helpful to researchers and practitioners in developing techniques for identifying and supporting DV victims.","","","10.1109/ACCESS.2018.2871446","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8469150","Domestic violence;deep learning;feature extraction;machine learning;social media","Machine learning;Feature extraction;Data mining;Facebook;Task analysis;Predictive models","learning (artificial intelligence);pattern classification;public administration;social networking (online)","human rights;DV crisis service;DVCS;automatic identification;critical posts;domestic violence crisis identification;deep learning;public health;machine-learning techniques;Facebook posts;social media;DV victims;classification process","","1","68","","","","","IEEE","IEEE Journals"
"Personalized Channel Recommendation Deep Learning From a Switch Sequence","C. Yang; S. Ren; Y. Liu; H. Cao; Q. Yuan; G. Han","College of Computer Science and Engineering, South China University of Technology, Guangzhou, China; College of Computer Science and Engineering, South China University of Technology, Guangzhou, China; Department of Electrical and Computer Engineering, New York University, Brooklyn, NY, USA; Department of Computer Science, New York Institute of Technology, New York, NY, USA; College of Computer Science and Engineering, South China University of Technology, Guangzhou, China; College of Computer Science and Engineering, South China University of Technology, Guangzhou, China","IEEE Access","","2018","6","","50824","50838","Internet protocol TV (IPTV) services could enhance personalized viewing experience in a more interactive way than traditional broadcast TV systems, but it is still difficult for subscribers to quickly find interesting channels to watch from a huge selection. This paper focuses on a framework for personalized live channel recommending via deep learning from a historical switching sequence with a long short-term memory (LSTM) neural network. Using real-world IPTV watching logs, we first obtained insights into user behaviors when watching live channels, and then proposed a learning scheme on how to dynamically generate a recommended channel list for each user with an independent LSTM net trained using the channel watching history during a slide window. For designing a good data architecture and representation scheme for a dynamically learning framework, we then studied the performance of the proposed recommendation method by varying the width of the slide window for training, the length of input sequence for prediction, and the mode to process input and label space. We finally developed a separate learning method to fairly recommend for popular (hot) or unpopular (cold) channels, respectively, based on channel popularity in the training set with an extra price of a possible hit lag after recommendation, in order to alleviate the Matthew effect arising from the conventional recommendation based on historical information. The experimental results show LSTM succeeds in learning from a historical channel switching sequence, outperforms several baseline recommendation methods, especially for hot channels, and the classified recommendation by separate learning brings an overall performance gain.","","","10.1109/ACCESS.2018.2869470","National Natural Science Foundation of China; Guangdong Science and Technology Department; Guangzhou Science and Technology Program key projects; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8458124","Deep learning;IPTV;long-short term memory;recommender systems;recurrent neural networks;separate learning;user behavior analysis","IPTV;Switches;Recommender systems;Neural networks;Training;Schedules","Internet;IPTV;learning (artificial intelligence);neural nets;recommender systems","personalized channel recommendation deep learning;switch sequence;traditional broadcast TV systems;interesting channels;personalized live channel;historical switching sequence;short-term memory neural network;real-world IPTV watching logs;user behaviors;live channels;learning scheme;recommended channel list;independent LSTM net;channel watching history;slide window;representation scheme;dynamically learning framework;recommendation method;input sequence;process input;label space;separate learning method;channel popularity;conventional recommendation;historical channel switching sequence;baseline recommendation methods;hot channels;classified recommendation;data architecture;Internet protocol TV services","","","45","","","","","IEEE","IEEE Journals"
"Voice Pathology Detection Using Deep Learning on Mobile Healthcare Framework","M. Alhussein; G. Muhammad","Department of Computer Engineering, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia; Department of Computer Engineering, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia","IEEE Access","","2018","6","","41034","41041","The feasibility and popularity of mobile healthcare are currently increasing. The advancement of modern technologies, such as wireless communication, data processing, the Internet of Things, cloud, and edge computing, makes mobile healthcare simpler than before. In addition, the deep learning approach brings a revolution in the machine learning domain. In this paper, we investigate a voice pathology detection system using deep learning on the mobile healthcare framework. A mobile multimedia healthcare framework is also designed. In the voice pathology detection system, voices are captured using smart mobile devices. Voice signals are processed before being fed to a convolutional neural network (CNN). We use a transfer learning technique to use the existing robust CNN models. In particular, the VGG-16 and CaffeNet models are investigated in the paper. The Saarbrucken voice disorder database is used in the experiments. Experimental results show that the voice pathology detection accuracy reaches up to 97.5% using the transfer learning of CNN models.","","","10.1109/ACCESS.2018.2856238","King Saud University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8411437","Mobile multimedia healthcare;voice pathology detection;deep learning;Saarbrucken voice database","Pathology;Medical services;Databases;Cloud computing;Machine learning;Feature extraction;Servers","convolution;feedforward neural nets;health care;learning (artificial intelligence);mobile computing;speech processing","voice pathology detection system;smart mobile devices;voice signals;transfer learning technique;Saarbrucken voice disorder database;data processing;deep learning approach;machine learning domain;wireless communication;Internet of Things;cloud;edge computing;mobile multimedia healthcare framework;convolutional neural network;CNN models;VGG models;CaffeNet models","","5","44","","","","","IEEE","IEEE Journals"
"A Survey of Clustering With Deep Learning: From the Perspective of Network Architecture","E. Min; X. Guo; Q. Liu; G. Zhang; J. Cui; J. Long","College of Computer, National University of Defense Technology, Changsha, China; College of Computer, National University of Defense Technology, Changsha, China; College of Computer, National University of Defense Technology, Changsha, China; College of Computer, National University of Defense Technology, Changsha, China; College of Computer, National University of Defense Technology, Changsha, China; College of Computer, National University of Defense Technology, Changsha, China","IEEE Access","","2018","6","","39501","39514","Clustering is a fundamental problem in many data-driven application domains, and clustering performance highly depends on the quality of data representation. Hence, linear or non-linear feature transformations have been extensively used to learn a better data representation for clustering. In recent years, a lot of works focused on using deep neural networks to learn a clustering-friendly representation, resulting in a significant increase of clustering performance. In this paper, we give a systematic survey of clustering with deep learning in views of architecture. Specifically, we first introduce the preliminary knowledge for better understanding of this field. Then, a taxonomy of clustering with deep learning is proposed and some representative methods are introduced. Finally, we propose some interesting future opportunities of clustering with deep learning and give some conclusion remarks.","","","10.1109/ACCESS.2018.2855437","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8412085","Clustering;deep learning;data representation;network architecture","Clustering methods;Machine learning;Clustering algorithms;Network architecture;Neural networks;Neurons;Gallium nitride","feature extraction;learning (artificial intelligence);neural net architecture;pattern clustering","deep neural networks;clustering-friendly representation;deep learning;network architecture;data-driven application domains;nonlinear feature transformations;linear feature transformations","","10","62","","","","","IEEE","IEEE Journals"
"Deep Sparse Coding for Non–Intrusive Load Monitoring","S. Singh; A. Majumdar","Indraprastha Institute of Information Technology, New Delhi, India; Indraprastha Institute of Information Technology, New Delhi, India","IEEE Transactions on Smart Grid","","2018","9","5","4669","4678","Energy disaggregation is the task of segregating the aggregate energy of the entire building (as logged by the smart-meter) into the energy consumed by individual appliances. This is a single channel (the only channel being the smart-meter) blind source (different electrical appliances) separation problem. The traditional way to address this is via stochastic finite state machines (e.g., factorial hidden Markov model). In recent times, dictionary learning-based approaches have shown promise in addressing the disaggregation problem. The usual technique is to learn a dictionary for every device and use the learned dictionaries as basis for blind source separation during disaggregation. Prior studies in this area are shallow learning techniques, i.e., they learn a single layer of dictionary for every device. In this paper, we propose a deep learning approach-instead of learning one level of dictionary, we learn multiple layers of dictionaries for each device. These multi-level dictionaries are used as a basis for source separation during disaggregation. Results on two benchmark datasets and one actual implementation show that our method outperforms state-of-the-art techniques.","","","10.1109/TSG.2017.2666220","Department of Information Technology, Ministry of Communications and Information Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7847445","Energy disaggregation;non-intrusive load monitoring;deep learning;dictionary learning","Dictionaries;Home appliances;Encoding;Hidden Markov models;Machine learning;Loading;Automata","blind source separation;finite state machines;hidden Markov models;learning (artificial intelligence);load forecasting;power engineering computing;signal processing","blind source separation;shallow learning techniques;multilevel dictionaries;non-intrusive load monitoring;energy disaggregation;stochastic finite state machines;factorial hidden Markov model;deep sparse coding;dictionary learning;deep learning","","13","43","","","","","IEEE","IEEE Journals"
"Deep Representation for Finger-Vein Image-Quality Assessment","H. Qin; M. A. El-Yacoubi","SAMOVAR, Telecom SudParis, CNRS, University of Paris-Saclay, Evry Cedex, France; SAMOVAR, Telecom SudParis, CNRS, University of Paris-Saclay, Evry Cedex, France","IEEE Transactions on Circuits and Systems for Video Technology","","2018","28","8","1677","1693","Finger-vein biometrics has been extensively investigated for personal authentication. One of the open issues in finger-vein verification is the lack of robustness against image-quality degradation. Spurious and missing features in poor-quality images may degrade the system's performance. Despite recent advances in finger-vein quality assessment, current solutions depend on domain knowledge. In this paper, we propose a deep neural network (DNN) for representation learning to predict image quality using very limited knowledge. Driven by the primary target of biometric quality assessment, i.e., verification error minimization, we assume that low-quality images are falsely rejected in a verification system. Based on this assumption, the low- and high-quality images are labeled automatically. We then train a DNN on the resulting data set to predict the image quality. To further improve the DNN's robustness, the finger-vein image is divided into various patches, on which a patch-based DNN is trained. The deepest layers associated with the patches form together a complementary and an over-complete representation. Subsequently, the quality of each patch from a testing image is estimated and the quality scores from the image patches are conjointly input to probabilistic support vector machines (P-SVM) to boost quality-assessment performance. To the best of our knowledge, this is the first proposed work of deep learning-based quality assessment, not only for finger-vein biometrics, but also for other biometrics in general. The experimental results on two public finger-vein databases show that the proposed scheme accurately identifies high- and low-quality images and significantly outperforms existing approaches in terms of the impact on equal error-rate decrease.","","","10.1109/TCSVT.2017.2684826","Direction générale des Entreprises of Ministére de l’économie, de l’industrie et du numérique; National Natural Science Foundation of China; Natural Science Foundation of Chongqing; Chongqing Technology and Business University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7882698","Biometrics;finger-vein quality assessment;deep learning;deep neural network;representation learning","Image quality;Quality assessment;Veins;Iris recognition;Error analysis;Machine learning","fingerprint identification;image representation;neural nets;support vector machines;vein recognition","deep representation;finger-vein image-quality assessment;finger-vein biometrics;finger-vein verification;image-quality degradation;deep neural network;image quality;biometric quality assessment;verification error minimization;low-quality images;high-quality images;patch-based DNN;testing image;quality scores;image patches;quality-assessment performance;deep learning-based quality assessment;public finger-vein databases;personal authentication;representation learning;probabilistic support vector machines","","8","48","","","","","IEEE","IEEE Journals"
"Deep Learning Applications in Medical Image Analysis","J. Ker; L. Wang; J. Rao; T. Lim","Department of Neurosurgery, National Neuroscience Institute, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; Department of Neurosurgery, National Neuroscience Institute, Singapore; Department of Neuroradiology, National Neuroscience Institute, Singapore","IEEE Access","","2018","6","","9375","9389","The tremendous success of machine learning algorithms at image recognition tasks in recent years intersects with a time of dramatically increased use of electronic medical records and diagnostic imaging. This review introduces the machine learning algorithms as applied to medical image analysis, focusing on convolutional neural networks, and emphasizing clinical aspects of the field. The advantage of machine learning in an era of medical big data is that significant hierarchal relationships within the data can be discovered algorithmically without laborious hand-crafting of features. We cover key research areas and applications of medical image classification, localization, detection, segmentation, and registration. We conclude by discussing research obstacles, emerging trends, and possible future directions.","","","10.1109/ACCESS.2017.2788044","National Neuroscience Institute–Nanyang Technological University Neurotechnology Fellowship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8241753","Convolutional neural networks;medical image analysis;machine learning;deep learning","Image analysis;Machine learning algorithms;Medical diagnostic imaging;Convolution","Big Data;image classification;image registration;image segmentation;learning (artificial intelligence);medical image processing;neural nets","diagnostic imaging;medical image analysis;convolutional neural networks;medical big data;medical image classification;tremendous success;image recognition tasks;electronic medical records;machine learning algorithms;deep learning applications;image localization;image detection;image segmentation;image registration","","40","127","","","","","IEEE","IEEE Journals"
"Efficient Scheduling in Training Deep Convolutional Networks at Large Scale","C. Que; X. Zhang","School of Computer Science and Technology, University of Science and Technology of China, Hefei, China; School of Computer Science and Technology, University of Science and Technology of China, Hefei, China","IEEE Access","","2018","6","","61452","61456","The deep convolutional network is one of the most successful machine learning models in recent years. However, training large deep networks is a time consuming process. Due to a large number of parameters in these networks, the efficiency of data parallel methods is usually limited by the communication speed of networks. In this paper, we introduce two new algorithms to speedup training large deep networks with multiple machines: (1) propose a new scheduling algorithm to reduce communication delay in gradient transmission and (2) present a new collective algorithm based on reverse-reduce tree to reduce link contentions. We implement our algorithms on a well-known library Caffe and obtain near linearly scaling performance on commodity Ethernet networks.","","","10.1109/ACCESS.2018.2875407","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8490649","All reduce;data parallel;deep learning;scheduling","Training;Delays;Backpropagation;Servers;Broadcasting;Indexes;Neural networks","convolution;learning (artificial intelligence);local area networks;neural nets;scheduling","commodity Ethernet networks;efficient scheduling;training deep convolutional networks;deep convolutional network;successful machine learning models;data parallel methods;speedup training;multiple machines;scheduling algorithm","","","9","","","","","IEEE","IEEE Journals"
"An Automatic Detection System of Lung Nodule Based on Multigroup Patch-Based Deep Learning Network","H. Jiang; H. Ma; W. Qian; M. Gao; Y. Li","Sino-Dutch Biomedical and Information Engineering School, Northeastern University, Shenyang, China; Sino-Dutch Biomedical and Information Engineering School and the Key Laboratory of Medical Image Computing, Ministry of Education, Northeastern University, Shenyang, China; Sino-Dutch Biomedical and Information Engineering School, Northeastern University, Shenyang, China; Sino-Dutch Biomedical and Information Engineering School, Northeastern University, Shenyang, China; College of Engineering, University of Texas at El Paso, El Paso, TX, USA","IEEE Journal of Biomedical and Health Informatics","","2018","22","4","1227","1237","High-efficiency lung nodule detection dramatically contributes to the risk assessment of lung cancer. It is a significant and challenging task to quickly locate the exact positions of lung nodules. Extensive work has been done by researchers around this domain for approximately two decades. However, previous computer-aided detection (CADe) schemes are mostly intricate and time-consuming since they may require more image processing modules, such as the computed tomography image transformation, the lung nodule segmentation, and the feature extraction, to construct a whole CADe system. It is difficult for these schemes to process and analyze enormous data when the medical images continue to increase. Besides, some state of the art deep learning schemes may be strict in the standard of database. This study proposes an effective lung nodule detection scheme based on multigroup patches cut out from the lung images, which are enhanced by the Frangi filter. Through combining two groups of images, a four-channel convolution neural networks model is designed to learn the knowledge of radiologists for detecting nodules of four levels. This CADe scheme can acquire the sensitivity of 80.06% with 4.7 false positives per scan and the sensitivity of 94% with 15.1 false positives per scan. The results demonstrate that the multigroup patch-based learning system is efficient to improve the performance of lung nodule detection and greatly reduce the false positives under a huge amount of image data.","","","10.1109/JBHI.2017.2725903","Recruitment Program of Global Experts; Fundamental Research Funds for the Central Universities; Bureau of Science and Technology of Liaoning Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7981333","Computer aided detection (CADe);computed tomography (CT) images;deep learning network;Frangi filter;lung nodule detection","Lungs;Computed tomography;Feature extraction;Cancer;Image segmentation;Databases;Biomedical imaging","cancer;computerised tomography;feature extraction;image segmentation;learning (artificial intelligence);lung;medical image processing;neural nets","high-efficiency lung nodule detection;lung cancer;image processing modules;computed tomography image transformation;lung nodule segmentation;CADe system;medical images;lung images;four-channel convolution neural networks model;CADe scheme;deep learning network;feature extraction;computer-aided detection;multigroup patch-based deep learning network;deep learning schemes","","8","44","","","","","IEEE","IEEE Journals"
"Unsupervised Transfer Learning via Multi-Scale Convolutional Sparse Coding for Biomedical Applications","H. Chang; J. Han; C. Zhong; A. M. Snijders; J. Mao","Berkeley Biomedical Data Science Center, Biological Systems and Engineering Division, Lawrence Berkeley National Laboratory, Berkeley, CA; Berkeley Biomedical Data Science Center, Biological Systems and Engineering Division, Lawrence Berkeley National Laboratory, Berkeley, CA; Berkeley Biomedical Data Science Center, Biological Systems and Engineering Division, Lawrence Berkeley National Laboratory, Berkeley, CA; Berkeley Biomedical Data Science Center, Biological Systems and Engineering Division, Lawrence Berkeley National Laboratory, Berkeley, CA; Berkeley Biomedical Data Science Center, Biological Systems and Engineering Division, Lawrence Berkeley National Laboratory, Berkeley, CA","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","5","1182","1194","The capabilities of (I) learning transferable knowledge across domains; and (II) fine-tuning the pre-learned base knowledge towards tasks with considerably smaller data scale are extremely important. Many of the existing transfer learning techniques are supervised approaches, among which deep learning has the demonstrated power of learning domain transferrable knowledge with large scale network trained on massive amounts of labeled data. However, in many biomedical tasks, both the data and the corresponding label can be very limited, where the unsupervised transfer learning capability is urgently needed. In this paper, we proposed a novel multi-scale convolutional sparse coding (MSCSC) method, that (I) automatically learns filter banks at different scales in a joint fashion with enforced scale-specificity of learned patterns; and (II) provides an unsupervised solution for learning transferable base knowledge and fine-tuning it towards target tasks. Extensive experimental evaluation of MSCSC demonstrates the effectiveness of the proposed MSCSC in both regular and transfer learning tasks in various biomedical domains.","","","10.1109/TPAMI.2017.2656884","NIH R01; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7829370","Transfer learning;sharable information;convolutional sparse coding;deep learning;biomedical application;brain tumors;low dose ionizing radiation (LDIR);mouse model;breast cancer subtypes","Convolutional codes;Training;Feature extraction;Encoding;Knowledge engineering;Biological neural networks","learning (artificial intelligence);unsupervised learning","supervised approaches;deep learning;demonstrated power;domain transferrable knowledge;corresponding label;unsupervised transfer learning capability;MSCSC;enforced scale-specificity;learned patterns;unsupervised solution;transferable base knowledge;target tasks;regular transfer learning tasks;biomedical domains;biomedical applications;transferable knowledge;transfer learning techniques;large scale network;multiscale convolutional sparse coding method","","9","42","","","","","IEEE","IEEE Journals"
"Deep-Learning-Based Channel Estimation for Wireless Energy Transfer","J. Kang; C. Chun; I. Kim","Department of Electrical and Computer Engineering, Queen’s University, Kingston, ON, Canada; Department of Electrical and Computer Engineering, Queen’s University, Kingston, ON, Canada; Department of Electrical and Computer Engineering, Queen’s University, Kingston, ON, Canada","IEEE Communications Letters","","2018","22","11","2310","2313","We propose a deep-learning-based channel estimation technique for wireless energy transfer. Specifically, we develop a channel learning scheme using the deep autoencoder, which learns the channel state information (CSI) at the energy transmitter based on the harvested energy feedback from the energy receiver, in the sense of minimizing the mean square error (mse) of the channel estimation. Numerical results demonstrate that the proposed scheme learns the CSI very well and significantly outperforms the conventional scheme in terms of the channel estimation mse as well as the harvested energy.","","","10.1109/LCOMM.2018.2871442","Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8469031","Autoencoder;channel estimation;deep learning;wireless energy transfer","Channel estimation;Erbium;Machine learning;Decoding;Energy exchange;Wireless sensor networks;Wireless communication","channel estimation;encoding;energy harvesting;learning (artificial intelligence);mean square error methods;radio receivers;radio transmitters;radiofrequency power transmission;telecommunication power management","wireless energy transfer;deep autoencoder;channel state information;CSI;energy transmitter;harvested energy feedback;energy receiver;mean square error;deep learning;channel estimation;MSE","","10","12","","","","","IEEE","IEEE Journals"
"Unsupervised Spectral–Spatial Feature Learning via Deep Residual Conv–Deconv Network for Hyperspectral Image Classification","L. Mou; P. Ghamisi; X. X. Zhu","German Aerospace Center, Remote Sensing Technology Institute, Wessling, Germany; German Aerospace Center, Remote Sensing Technology Institute, Wessling, Germany; German Aerospace Center, Remote Sensing Technology Institute, Wessling, Germany","IEEE Transactions on Geoscience and Remote Sensing","","2018","56","1","391","406","Supervised approaches classify input data using a set of representative samples for each class, known as training samples. The collection of such samples is expensive and time demanding. Hence, unsupervised feature learning, which has a quick access to arbitrary amounts of unlabeled data, is conceptually of high interest. In this paper, we propose a novel network architecture, fully Conv-Deconv network, for unsupervised spectral-spatial feature learning of hyperspectral images, which is able to be trained in an end-to-end manner. Specifically, our network is based on the so-called encoder-decoder paradigm, i.e., the input 3-D hyperspectral patch is first transformed into a typically lower dimensional space via a convolutional subnetwork (encoder), and then expanded to reproduce the initial data by a deconvolutional subnetwork (decoder). However, during the experiment, we found that such a network is not easy to be optimized. To address this problem, we refine the proposed network architecture by incorporating: 1) residual learning and 2) a new unpooling operation that can use memorized max-pooling indexes. Moreover, to understand the “black box,” we make an in-depth study of the learned feature maps in the experimental analysis. A very interesting discovery is that some specific “neurons” in the first residual block of the proposed network own good description power for semantic visual patterns in the object level, which provide an opportunity to achieve “free” object detection. This paper, for the first time in the remote sensing community, proposes an end-to-end fully Conv-Deconv network for unsupervised spectral-spatial feature learning. Moreover, this paper also introduces an in-depth investigation of learned features. Experimental results on two widely used hyperspectral data, Indian Pines and Pavia University, demonstrate competitive performance obtained by the proposed methodology compared with other studied approaches.","","","10.1109/TGRS.2017.2748160","China Scholarship Council; Alexander von Humboldt Foundation; European Research Council (ERC); European Unions Horizon 2020 research and innovation programme (grant agreement No, Acronym: So2Sat); Helmholtz Association under the framework of the Young Investigators Group “SiPEO” (VH-NG-1018, www.sipeo.bgu.tum.de); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8082108","Convolutional network;deconvolutional network;hyperspectral image classification;residual learning;unsupervised spectral–spatial feature learning","Hyperspectral imaging;Feature extraction;Training;Network architecture;Support vector machines","image classification;learning (artificial intelligence);object detection;unsupervised learning","network architecture;learned feature maps;unsupervised spectral-spatial feature learning;learned features;widely used hyperspectral data;deep residual Conv-Deconv network;hyperspectral image classification;unsupervised feature learning;end-to-end manner;input 3-D hyperspectral patch","","29","57","","","","","IEEE","IEEE Journals"
"Cloud-Based Cyber-Physical Intrusion Detection for Vehicles Using Deep Learning","G. Loukas; T. Vuong; R. Heartfield; G. Sakellari; Y. Yoon; D. Gan","Computing and Information Systems, University of Greenwich, London, U.K.; Computing and Information Systems, University of Greenwich, London, U.K.; Computing and Information Systems, University of Greenwich, London, U.K.; Computing and Information Systems, University of Greenwich, London, U.K.; Computing and Information Systems, University of Greenwich, London, U.K.; Computing and Information Systems, University of Greenwich, London, U.K.","IEEE Access","","2018","6","","3491","3508","Detection of cyber attacks against vehicles is of growing interest. As vehicles typically afford limited processing resources, proposed solutions are rule-based or lightweight machine learning techniques. We argue that this limitation can be lifted with computational offloading commonly used for resource-constrained mobile devices. The increased processing resources available in this manner allow access to more advanced techniques. Using as case study a small four-wheel robotic land vehicle, we demonstrate the practicality and benefits of offloading the continuous task of intrusion detection that is based on deep learning. This approach achieves high accuracy much more consistently than with standard machine learning techniques and is not limited to a single type of attack or the in-vehicle CAN bus as previous work. As input, it uses data captured in real-time that relate to both cyber and physical processes, which it feeds as time series data to a neural network architecture. We use both a deep multilayer perceptron and recurrent neural network architecture, with the latter benefitting from a long-short term memory hidden layer, which proves very useful for learning the temporal context of different attacks. We employ denial of service, command injection and malware as examples of cyber attacks that are meaningful for a robotic vehicle. The practicality of computation offloading depends on the resources afforded onboard and remotely, and the reliability of the communication means between them. Using detection latency as the criterion, we have developed a mathematical model to determine when computation offloading is beneficial given parameters related to the operation of the network and the processing demands of the deep learning model. The more reliable the network and the greater the processing demands, the greater the reduction in detection latency achieved through offloading.","","","10.1109/ACCESS.2017.2782159","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8171725","Intrusion detection;machine learning;autonomous vehicles","Robot sensing systems;Intrusion detection;Monitoring;Aircraft;Machine learning","cloud computing;control engineering computing;invasive software;learning (artificial intelligence);mobile robots;multilayer perceptrons;recurrent neural nets;security of data;time series","mobile devices;four-wheel robotic land vehicle;standard machine learning techniques;physical processes;time series data;deep multilayer perceptron;recurrent neural network architecture;long-short term memory hidden layer;cyber attacks;robotic vehicle;computation offloading;processing demands;deep learning model;cyber-physical intrusion detection;lightweight machine learning techniques;computational offloading;cloud-based cyber-physical intrusion detection","","5","64","","","","","IEEE","IEEE Journals"
"Deep Learning-Based Interval State Estimation of AC Smart Grids Against Sparse Cyber Attacks","H. Wang; J. Ruan; G. Wang; B. Zhou; Y. Liu; X. Fu; J. Peng","College of Mechatronics and Control Engineering, Shenzhen University, Shenzhen, China; College of Mechatronics and Control Engineering, Shenzhen University, Shenzhen, China; College of Mechatronics and Control Engineering, Shenzhen University, Shenzhen, China; College of Electrical and Information Engineering, Hunan University, Changsha, China; College of Mechatronics and Control Engineering, Shenzhen University, Shenzhen, China; College of Information and Electrical Engineering, China Agricultural University, Beijing, China; College of Mechatronics and Control Engineering, Shenzhen University, Shenzhen, China","IEEE Transactions on Industrial Informatics","","2018","14","11","4766","4778","Due to the aging of electric infrastructures, conventional power grid is being modernized toward smart grid that enables two-way communications between consumer and utility, and thus more vulnerable to cyber-attacks. However, due to the attacking cost, the attack strategy may vary a lot from one operation scenario to another from the perspective of adversary, which is not considered in previous studies. Therefore, in this paper, scenario-based two-stage sparse cyber-attack models for smart grid with complete and incomplete network information are proposed. Then, in order to effectively detect the established cyber-attacks, an interval state estimation-based defense mechanism is developed innovatively. In this mechanism, the lower and upper bounds of each state variable are modeled as a dual optimization problem that aims to maximize the variation intervals of the system variable. At last, a typical deep learning, i.e., stacked auto-encoder, is designed to properly extract the nonlinear and nonstationary features in electric load data. These features are then applied to improve the accuracy for electric load forecasting, resulting in a more narrow width of state variables. The uncertainty with respect to forecasting errors is modeled as a parametric Gaussian distribution. The validation of the proposed cyber-attack models and defense mechanism have been demonstrated via comprehensive tests on various IEEE benchmarks.","","","10.1109/TII.2018.2804669","National Natural Science Foundation of China; Natural Science Foundations of Guangdong Province; Foundation of Shenzhen Science and Technology Committee; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8288611","Cyber physical power system;deep learning;false data injection attack;smart grid security;state estimation","Load modeling;Smart grids;Machine learning;Security;State estimation;Feature extraction;Uncertainty","distributed power generation;learning (artificial intelligence);load forecasting;optimisation;power engineering computing;power system security;smart power grids","deep learning-based interval state estimation;AC smart grids;sparse cyber attacks;electric infrastructures;conventional power grid;smart grid;attacking cost;attack strategy;sparse cyber-attack models;interval state estimation-based defense mechanism;lower bounds;upper bounds;dual optimization problem;electric load data;electric load forecasting;deep learning;cyber-attacks","","9","52","","","","","IEEE","IEEE Journals"
"3-D Deep Learning Approach for Remote Sensing Image Classification","A. Ben Hamida; A. Benoit; P. Lambert; C. Ben Amar","Informatics, Systems, Information and Knowledge Processing Laboratory, Université Savoie Mont Blanc, Annecy, France; Informatics, Systems, Information and Knowledge Processing Laboratory, Université Savoie Mont Blanc, Annecy, France; Informatics, Systems, Information and Knowledge Processing Laboratory, Université Savoie Mont Blanc, Annecy, France; Research Groups in Intelligent Machines, Ecole Nationale d’Ingénieurs de Sfax, Sfax, Tunisia","IEEE Transactions on Geoscience and Remote Sensing","","2018","56","8","4420","4434","Recently, a variety of approaches have been enriching the field of remote sensing (RS) image processing and analysis. Unfortunately, existing methods remain limited to the rich spatiospectral content of today's large data sets. It would seem intriguing to resort to deep learning (DL)-based approaches at this stage with regard to their ability to offer accurate semantic interpretation of the data. However, the specificity introduced by the coexistence of spectral and spatial content in the RS data sets widens the scope of the challenges presented to adapt DL methods to these contexts. Therefore, the aim of this paper is first to explore the performance of DL architectures for the RS hyperspectral data set classification and second to introduce a new 3-D DL approach that enables a joint spectral and spatial information process. A set of 3-D schemes is proposed and evaluated. Experimental results based on well-known hyperspectral data sets demonstrate that the proposed method is able to achieve a better classification rate than state-of-the-art methods with lower computational costs.","","","10.1109/TGRS.2018.2818945","Research and Education France Ministry; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8344565","Classification;deep learning (DL);hyperspectral;pixel-based;remote sensing (RS)","Computer architecture;Machine learning;Tools;Neural networks;Remote sensing;Semantics;Task analysis","geophysical image processing;hyperspectral imaging;image classification;learning (artificial intelligence);remote sensing","spectral content;spatial content;RS hyperspectral data set;joint spectral;spatial information process;classification rate;remote sensing image classification;deep learning-based approaches;semantic interpretation;3D deep learning approach;spatiospectral content;RS image processing;RS image analysis;RS hyperspectral data sets","","10","60","","","","","IEEE","IEEE Journals"
"Quality Assessment of Retargeted Images Using Hand-Crafted and Deep-Learned Features","Z. Fu; F. Shao; Q. Jiang; R. Fu; Y. Ho","Faculty of Information Science and Engineering, Ningbo University, Ningbo, China; Faculty of Information Science and Engineering, Ningbo University, Ningbo, China; Faculty of Information Science and Engineering, Ningbo University, Ningbo, China; Faculty of Information Science and Engineering, Ningbo University, Ningbo, China; School of Information and Communications, Gwangju Institute of Science and Technology, Gwangju, South Korea","IEEE Access","","2018","6","","12008","12018","Since the goal of image retargeting is to adapt source images on target displays with different sizes and aspect ratios, how to objectively evaluate the quality of retargeted images is particularly important to optimize the retargeting operations. In this paper, we proposed a new image retargeting quality assessment metric, which constructs the metric using both hand-crafted features and deep-learned features. To enhance the reliability and accuracy of the proposed method: 1) we use similarity transformation as local descriptor to extract hand-craft features, and measure structure distortion and content loss from the hand-craft features and 2) we use deep learning architecture to construct encoders and extract deep-learned features, and measure texture similarity and semantic similarity from the deep-learned features. We conduct experiments on two databases: RetargetMe and CUHK. Experimental results show that our method can achieve superior performance to the state-of-the-art metrics.","","","10.1109/ACCESS.2018.2808322","Natural Science Foundation of China; Zhejiang Natural Science Foundation of China; Natural Science Foundation of Ningbo; K. C. Wong Magna Fund in Ningbo University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8299620","Image retargeting quality assessment;hand-crafted feature;deep-learned feature;structure distortion;content loss","Feature extraction;Distortion;Semantics;Distortion measurement;Loss measurement;Quality assessment","feature extraction;learning (artificial intelligence)","deep learning architecture;retargeted images;source images;image retargeting quality assessment metric;quality assessment;similarity transformation;local descriptor;hand-craft feature extraction;structure distortion;deep-learned feature extraction;semantic similarity;CUHK database;RetargetMe database","","2","48","","","","","IEEE","IEEE Journals"
"Deep Inductive Graph Representation Learning","R. A. Rossi; R. Zhou; N. Ahmed","Machine Learning, Adobe Research, San Jose, California United States (e-mail: ryarossi@gmail.com); Machine Learning, Google, Mountain View, California United States (e-mail: rongzhou@google.com); Machine Learning, Intel Labs, Santa Clara, California United States (e-mail: nesreen.k.ahmed@intel.com)","IEEE Transactions on Knowledge and Data Engineering","","2018","PP","99","1","1","This paper presents a general inductive graph representation learning framework called DeepGL for learning deep node and edge features that generalize across-networks. In particular, DeepGL begins by deriving a set of base features from the graph (e.g., graphlet features) and automatically learns a multi-layered hierarchical graph representation where each successive layer leverages the output from the previous layer to learn features of a higher-order. Contrary to previous work, DeepGL learns relational functions (each representing a feature) that naturally generalize across-networks and are therefore useful for graph-based transfer learning tasks. Moreover, DeepGL naturally supports attributed graphs, learns interpretable inductive graph representations, and is space-efficient (by learning sparse feature vectors). In addition, DeepGL is expressive, flexible with many interchangeable components, efficient with a time complexity of $O(|E|)$, and scalable for large networks via an efficient parallel implementation. Compared with recent methods, DeepGL is (1) effective for across-network transfer learning tasks and large (attributed) graphs, (2) space-efficient requiring up to 6x less memory, (3) fast with up to 106x speedup in runtime performance, and (4) accurate with an average improvement in AUC of 20% or more on many learning tasks and across a wide variety of networks.","","","10.1109/TKDE.2018.2878247","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8519335","Graph representation learning;inductive representation learning;relational function learning;transfer learning;graph-based feature learning;higher-order structures","Orbits;Task analysis;Runtime;Electronic mail;Natural language processing","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Label Distribution-Based Facial Attractiveness Computation by Deep Residual Learning","Y. Fan; S. Liu; B. Li; Z. Guo; A. Samal; J. Wan; S. Z. Li","School of Electronics and Information, Northwestern Polytechnical University, Xi’an, China; School of Electronics and Information, Northwestern Polytechnical University, Xi’an, China; School of Electronics and Information, Northwestern Polytechnical University, Xi’an, China; School of Electronics and Information, Northwestern Polytechnical University, Xi’an, China; Department of Computer Science and Engineering, University of Nebraska–Lincoln, Lincoln, NE, USA; Center for Biometrics and Security Research and National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Center for Biometrics and Security Research and National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Multimedia","","2018","20","8","2196","2208","Two key challenges lie in the facial attractiveness computation research: the lack of discriminative face representations, and the scarcity of sufficient and complete training data. Motivated by recent promising work in face recognition using deep neural networks to learn effective features, the first challenge is expected to be addressed from a deep learning point of view. A very deep residual network is utilized to enable automatic learning of hierarchical aesthetics representation. The inspiration to deal with the second challenge comes from the natural representation of the training data, where each training face can be associated with a label (score) distribution given by human raters rather than a single label (average score). This paper, therefore, recasts facial attractiveness computation as a label distribution learning problem. Integrating these two ideas, an end-to-end attractiveness learning framework is established. We also perform feature-level fusion by incorporating the low-level geometric features to further improve the computational performance. Extensive experiments are conducted on a standard benchmark, the SCUT-FBP dataset, where our approach shows significant advantages over the other state-of-the-art work.","","","10.1109/TMM.2017.2780762","National Natural Science Foundation of China; Science and Technology Innovation Engineering Plan in Shaanxi Province of China; Natural Science Basic Research Plan in Shaanxi Province of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8168380","Facial attractiveness computation;deep residual network;label distribution;feature fusion;SCUT-FBP","Face;Feature extraction;Image color analysis;Computer architecture;Computational modeling;Training data","face recognition;feature extraction;image representation;learning (artificial intelligence);neural nets","label distribution-based facial attractiveness computation;deep residual learning;key challenges;facial attractiveness computation research;discriminative face representations;sufficient training data;complete training data;face recognition;deep neural networks;deep residual network;automatic learning;hierarchical aesthetics representation;natural representation;label distribution learning problem;feature-level fusion;low-level geometric features;computational performance;end-to-end attractiveness learning framework;standard benchmark;SCUT-FBP dataset","","2","44","","","","","IEEE","IEEE Journals"
"Online Real-Time Analysis of Data Streams Based on an Incremental High-Order Deep Learning Model","Y. Li; M. Zhang; W. Wang","College of Electronics and Communication Engineering, Tianjin Normal University, Tianjin, China; College of Electronics and Communication Engineering, Tianjin Normal University, Tianjin, China; College of Electronics and Communication Engineering, Tianjin Normal University, Tianjin, China","IEEE Access","","2018","6","","77615","77623","As the core part of the new generation of information technology, the Internet of Things has accumulated a large number of real-time data streams of various types and structures. The data stream is generated at an extremely fast speed, and its content and distribution characteristics are all in high-speed dynamic changes, which must be processed in real time. Therefore, the feature learning algorithm is required to support incremental updates and learn the characteristics of high-speed dynamic change data in real time. Most of the current machine learning models for processing big data belong to the static learning model. The batch learning method makes it impossible to analyze data streams in real time, and the learning ability of dynamic data streams is poor. Therefore, this paper proposes an incremental high-order deep learning model to extend the data from the vector space to the tensor space and update the parameters and structure of the network model in the high-order tensor space. In the process of parameter updating, the firstorder approximation concept is introduced to avoid incrementing parameters by the iterative method and to improve the parameter update efficiency, so that the updated model can quickly learn the characteristics of dynamically changing big data and satisfy the real-time requirements of big data feature learning while maintaining the original knowledge of the neural network model as much as possible. To evaluate the performance of the proposed model, experiments were performed on real image data sets-MNIST, and the model was evaluated for stability, plasticity, and run time. The experimental results show that the model not only has the ability to incrementally learn the characteristics of new data online but also retains the ability to learn the original data features, improve the model update efficiency, and maximize the online analysis and real-time processing of dynamic data streams.","","","10.1109/ACCESS.2018.2883666","Natural Youth Science Foundation of China; National Natural Science Foundation of China; Natural Science Foundation of China; Tianjin Research Program of Application Foundation and Advanced Technology; Tianjin Science Foundation; Tianjin Higher Education Creative Team Funds Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8550701","Incremental high-order deep learning model;online analysis;parameter update;real-time processing;structure update;tensor space","Data models;Real-time systems;Big Data;Tensile stress;Internet of Things;Analytical models","Big Data;data analysis;iterative methods;learning (artificial intelligence);neural nets","MNIST image data sets;iterative method;first order approximation concept;big data processing;Internet of Things;information technology;machine learning models;content characteristics;data stream analysis;data features;batch learning method;static learning model;high-speed dynamic change data;feature learning algorithm;distribution characteristics;online real-time analysis;neural network model;real-time requirements;parameter updating;high-order tensor space;incremental high-order deep learning model;dynamic data streams","","","30","","","","","IEEE","IEEE Journals"
"Learning Generalized Deep Feature Representation for Face Anti-Spoofing","H. Li; P. He; S. Wang; A. Rocha; X. Jiang; A. C. Kot","Nanyang Technological University, Singapore; Shanghai Jiao Tong University, Shanghai, China; City University of Hong Kong, Hong Kong; University of Campinas, Campinas, Brazil; Shanghai Jiao Tong University, Shanghai, China; Nanyang Technological University, Singapore","IEEE Transactions on Information Forensics and Security","","2018","13","10","2639","2652","In this paper, we propose a novel framework leveraging the advantages of the representational ability of deep learning and domain generalization for face spoofing detection. In particular, the generalized deep feature representation is achieved by taking both spatial and temporal information into consideration, and a 3D convolutional neural network architecture tailored for the spatial-temporal input is proposed. The network is first initialized by training with augmented facial samples based on cross-entropy loss and further enhanced with a specifically designed generalization loss, which coherently serves as the regularization term. The training samples from different domains can seamlessly work together for learning the generalized feature representation by manipulating their feature distribution distances. We evaluate the proposed framework with different experimental setups using various databases. Experimental results indicate that our method can learn more discriminative and generalized information compared with the state-of-the-art methods.","","","10.1109/TIFS.2018.2825949","National Research Foundation, Singapore; Infocomm Media Development Authority, Singapore; Tan Chin Tuan Foundation; São Paulo Research Foundation, Fapesp, DéjàVu; Coordination for the Improvement of Higher Level Education Personnel, CAPES (DeepEyes Grant); China Scholarship Council for the Scholarship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8335313","Face spoofing;deep learning;3D CNN;domain generalization","Face;Three-dimensional displays;Distortion;Feature extraction;Machine learning;Cameras;Data mining","entropy;face recognition;feature extraction;feedforward neural nets;generalisation (artificial intelligence);learning (artificial intelligence)","generalized deep feature representation;face anti-spoofing;representational ability;deep learning;domain generalization;face spoofing detection;spatial information;temporal information;3D convolutional neural network architecture;spatial-temporal input;generalized feature representation;feature distribution distances;discriminative information;generalized information;generalization loss","","10","70","","","","","IEEE","IEEE Journals"
"Vehicle Type Recognition in Surveillance Images From Labeled Web-Nature Data Using Deep Transfer Learning","J. Wang; H. Zheng; Y. Huang; X. Ding","Department of Communication Engineering, Fujian Key Laboratory of Sensing and Computing for Smart City, School of Information Science and Engineering, Xiamen University, Xiamen, China; Department of Communication Engineering, Fujian Key Laboratory of Sensing and Computing for Smart City, School of Information Science and Engineering, Xiamen University, Xiamen, China; Department of Communication Engineering, Fujian Key Laboratory of Sensing and Computing for Smart City, School of Information Science and Engineering, Xiamen University, Xiamen, China; Department of Communication Engineering, Fujian Key Laboratory of Sensing and Computing for Smart City, School of Information Science and Engineering, Xiamen University, Xiamen, China","IEEE Transactions on Intelligent Transportation Systems","","2018","19","9","2913","2922","Vehicle type recognition from surveillance images represents a challenging task in the domain of intelligent monitoring systems. Recently, deep learning methods have been applied to solve this problem. The existing deep learning methods, such as convolutional neural networks (CNN), assume that the training and test data are generated from the same or similar imaging systems. They also require a lot of manual annotations for each task. In this paper, we aim to create an improved deep learning method for vehicle type recognition from surveillance images and propose a system based on CNN and transfer learning. Labeled image data of different types of vehicles are easy to acquire from both vehicle manufacturers and Internet sources. Therefore, our proposed surveillance-based vehicle type recognition system is implemented using only labels from Web data. This allows us to overcome the task of manually labeling the data from surveillance images during the training phase. We need to overcome the gap in the types of vehicles between two different imaging systems. For this, a regularization technique in transfer learning is introduced to the objective function of the traditional convolutional neural network. The proposed method was verified through experiments with the public data set comprehensive cars. The experimental results demonstrate that our proposed recognition method outperforms existing deep learning methods when the training and test data are taken from different imaging systems.","","","10.1109/TITS.2017.2765676","National Natural Science Foundation of China; Natural Science Foundation of Guangdong Province; Fundamental Research Funds for the Central Universities; Natural Science Foundation of Fujian Province; CCF-Tencent open grant; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8120162","Vehicle type recognition;surveillance images;convolutional neural network;transfer learning;unsupervised domain adaptation","Surveillance;Image recognition;Machine learning;Training;Imaging","image recognition;Internet;learning (artificial intelligence);neural nets;object recognition","surveillance images;labeled Web-nature data;deep transfer learning;intelligent monitoring systems;labeled image data;vehicle manufacturers;surveillance-based vehicle type recognition system;Web data;public data set comprehensive cars;recognition method;imaging systems;deep learning method","","5","30","","","","","IEEE","IEEE Journals"
"Reducing Complexity of HEVC: A Deep Learning Approach","M. Xu; T. Li; Z. Wang; X. Deng; R. Yang; Z. Guan","School of Electronic and Information Engineering, Beihang University, Beijing, China; School of Electronic and Information Engineering, Beihang University, Beijing, China; School of Electronic and Information Engineering, Beihang University, Beijing, China; Department of Electrical and Electronic Engineering, Imperial College London, London, U.K.; School of Electronic and Information Engineering, Beihang University, Beijing, China; School of Electronic and Information Engineering, Beihang University, Beijing, China","IEEE Transactions on Image Processing","","2018","27","10","5044","5059","High efficiency video coding (HEVC) significantly reduces bit rates over the preceding H.264 standard but at the expense of extremely high encoding complexity. In HEVC, the quad-tree partition of the coding unit (CU) consumes a large proportion of the HEVC encoding complexity, due to the brute-force search for rate-distortion optimization (RDO). Therefore, this paper proposes a deep learning approach to predict the CU partition for reducing the HEVC complexity at both intra-and inter-modes, which is based on convolutional neural network (CNN) and long- and short-term memory (LSTM) network. First, we establish a large-scale database including substantial CU partition data for the HEVC intra- and inter-modes. This enables deep learning on the CU partition. Second, we represent the CU partition of an entire coding tree unit in the form of a hierarchical CU partition map (HCPM). Then, we propose an early terminated hierarchical CNN (ETH-CNN) for learning to predict the HCPM. Consequently, the encoding complexity of intra-mode HEVC can be drastically reduced by replacing the brute-force search with ETH-CNN to decide the CU partition. Third, an ETH-LSTM is proposed to learn the temporal correlation of the CU partition. Then, we combine the ETH-LSTM and the ETH-CNN to predict the CU partition for reducing the HEVC complexity at inter-mode. Finally, experimental results show that our approach outperforms the other state-of-the-art approaches in reducing the HEVC complexity at both intra- and inter-modes.","","","10.1109/TIP.2018.2847035","National Natural Science Foundation of China; Fok Ying-Tong Education Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8384310","High efficiency video coding;complexity reduction;deep learning;convolutional neural network;long- and short-term memory network","Complexity theory;Machine learning;Image coding;Databases;Encoding;Video coding;Feature extraction","computational complexity;data compression;learning (artificial intelligence);optimisation;rate distortion theory;recurrent neural nets;video coding","ETH-CNN;intra-mode HEVC;brute-force search;deep learning approach;high efficiency video coding;extremely high encoding complexity;quad-tree partition;HEVC encoding complexity;substantial CU partition data;HEVC intra;hierarchical CU partition map;HEVC complexity reduction;coding tree unit;bit rate reduction;H.264 standard;rate-distortion optimization;RDO;convolutional neural network;long-short-term memory network;LSTM network;HEVC inter-modes;CU partition;HCPM;early terminated hierarchical CNN;temporal correlation learning;large-scale database","","17","43","","","","","IEEE","IEEE Journals"
"Sample Efficient Deep Reinforcement Learning for Dialogue Systems With Large Action Spaces","G. Weisz; P. Budzianowski; P. Su; M. Gašić","Department of Engineering, University of Cambridge, Cambridge, U.K.; Department of Engineering, University of Cambridge, Cambridge, U.K.; Department of Engineering, University of Cambridge, Cambridge, U.K.; Department of Engineering, University of Cambridge, Cambridge, U.K.","IEEE/ACM Transactions on Audio, Speech, and Language Processing","","2018","26","11","2083","2097","In spoken dialogue systems, we aim to deploy artificial intelligence to build automated dialogue agents that can converse with humans. A part of this effort is the policy optimization task, which attempts to find a policy describing how to respond to humans, in the form of a function taking the current state of the dialogue and returning the response of the system. In this paper, we investigate deep reinforcement learning approaches to solve this problem. Particular attention is given to actor-critic methods, off-policy reinforcement learning with experience replay, and various methods aimed at reducing the bias and variance of estimators. When combined, these methods result in the previously proposed ACER algorithm that gave competitive results in gaming environments. These environments, however, are fully observable and have a relatively small action set so, in this paper, we examine the application of ACER to dialogue policy optimization. We show that this method beats the current state of the art in deep learning approaches for spoken dialogue systems. This not only leads to a more sample efficient algorithm that can train faster, but also allows us to apply the algorithm in more difficult environments than before. We thus experiment with learning in a very large action space, which has two orders of magnitude more actions than previously considered. We find that ACER trains significantly faster than the current state of the art.","","","10.1109/TASLP.2018.2851664","EPSRC Council; Toshiba Research Europe, Ltd.; Cambridge Research Laboratory; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8402196","Deep reinforcement learning;spoken dialogue systems;Gaussian processes","Optimization;Learning (artificial intelligence);Task analysis;Neural networks;Speech processing;Training;Markov processes","human computer interaction;interactive systems;learning (artificial intelligence);software agents","ACER algorithm;dialogue policy optimization;spoken dialogue systems;artificial intelligence;automated dialogue agents;policy optimization task;deep reinforcement learning;actor-critic methods;off-policy reinforcement learning;human-computer interaction","","6","43","","","","","IEEE","IEEE Journals"
"Deep Learning Based Speech Separation via NMF-Style Reconstructions","S. Nie; S. Liang; W. Liu; X. Zhang; J. Tao","National Laboratory of Pattern Recognition, Institute of Automation Chinese Academy of Sciences, Beijing, China; National Laboratory of Pattern Recognition, Institute of Automation Chinese Academy of Sciences, Beijing, China; National Laboratory of Pattern Recognition, Institute of Automation Chinese Academy of Sciences, Beijing, China; College of Computer Science, Inner Mongolia University, Huhhot, China; National Laboratory of Pattern Recognition, Institute of Automation Chinese Academy of Sciences, Beijing, China","IEEE/ACM Transactions on Audio, Speech, and Language Processing","","2018","26","11","2043","2055","Deep learning based speech separation usually uses a supervised algorithm to learn a mapping function from noisy features to separation targets. These separation targets, either ideal masks or magnitude spectrograms, have prominent spectro-temporal structures. Nonnegative matrix factorization (NMF) is a well-known representation learning technique that is capable of capturing the basic spectral structures. Therefore, the combination of deep learning and NMF as an organic whole is a smart strategy. However, previous methods typically use deep neural networks (DNN) and NMF for speech separation in a separate manner. In this paper, we propose a jointly combinatorial scheme to concentrate the strengths of both DNN and NMF for speech separation. NMF is used to learn the basis spectra that then are integrated into a DNN to directly reconstruct the magnitude spectrograms of speech and noise. Instead of predicting activation coefficients inferred by NMF, which is used as an intermediate target by the previous methods, DNN directly optimizes an actual separation objective in our system, so that the accumulated errors could be alleviated. Moreover, we explore a discriminative training objective with sparsity constraints to suppress noise and preserve more speech components further. Systematic experiments show that the proposed models are competitive with the previous methods.","","","10.1109/TASLP.2018.2851151","National Natural Science Foundation of China; National Science Fund for Distinguished Young Scholars; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8401338","Speech separation;deep neural network (DNN);nonnegative matrix factorization (NMF);spectro-temporal structures","Spectrogram;Noise measurement;Machine learning;Training;Neural networks;Speech enhancement","learning (artificial intelligence);matrix decomposition;neural nets;speech processing","speech separation;NMF-style reconstructions;magnitude spectrograms;representation learning technique;deep learning;deep neural networks;DNN;nonnegative matrix factorization;spectro-temporal structures","","2","62","","","","","IEEE","IEEE Journals"
"Capturing Car-Following Behaviors by Deep Learning","X. Wang; R. Jiang; L. Li; Y. Lin; X. Zheng; F. Wang","Department of Computer Science and Technology, Xi’an Jiaotong University, Xi’an, China; School of Traffic and Transportation, Beijing Jiaotong University, Beijing, China; Department of Automation, Tsinghua University, Beijing, China; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN, USA; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Intelligent Transportation Systems","","2018","19","3","910","920","In this paper, we propose a deep neural network-based car-following model that has two distinctive properties. First, unlike most existing car-following models that take only the instantaneous velocity, velocity difference, and position difference as inputs, this new model takes the velocities, velocity differences, and position differences that were observed in the last few time intervals as inputs. That is, we assume that drivers' actions are temporally dependent in this model and try to embed prediction capability or memory effect of human drivers in a natural and efficient way. Second, this car-following model is built in a data-driven way, in which we reduce human interference to the minimum degree. Specially, we use recently developing deep neural networks rather than conventional neural networks to establish the model, since deep learning technique provides us more flexibility and accuracy to describe complicated human actions. Tests on empirical trajectory records show that this deep neural network-based car-following model yield significantly higher simulation accuracy than existing car-following models. All these findings provide a novel way to study traffic flow theory and traffic simulations.","","","10.1109/TITS.2017.2706963","National Natural Science Foundation of China; National Key R&D Program in China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7970189","Microscopic car-following model;deep learning;recurrent neural network (RNN);gated recurrent unit (GRU) neural networks","Biological neural networks;Neurons;Machine learning;Vehicles;Numerical models;Acceleration","automobiles;feedforward neural nets;learning (artificial intelligence);traffic engineering computing","instantaneous velocity;velocity difference;prediction capability;human drivers;deep neural network;conventional neural networks;deep learning technique;complicated human actions;existing car-following models;capturing car-following behaviors","","13","67","","","","","IEEE","IEEE Journals"
"Integrating Feature Selection and Feature Extraction Methods With Deep Learning to Predict Clinical Outcome of Breast Cancer","D. Zhang; L. Zou; X. Zhou; F. He","College of Information and Engineering, Sichuan Agricultural University, Yaan, China; College of Information and Engineering, Sichuan Agricultural University, Yaan, China; College of Informatics, Huazhong Agricultural University, Wuhan, China; School of Computer, Wuhan University, Wuhan, China","IEEE Access","","2018","6","","28936","28944","In many microarray studies, classifiers have been constructed based on gene signatures to predict clinical outcomes for various cancer sufferers. However, signatures originating from different studies often suffer from poor robustness when used in the classification of data sets independent from which they were generated from. In this paper, we present an unsupervised feature learning framework by integrating a principal component analysis algorithm and autoencoder neural network to identify different characteristics from gene expression profiles. As the foundation for the obtained features, an ensemble classifier based on the AdaBoost algorithm (PCA-AE-Ada) was constructed to predict clinical outcomes in breast cancer. During the experiments, we established an additional classifier with the same classifier learning strategy (PCA-Ada) in order to perform as a baseline to the proposed method, where the only difference is the training inputs. The area under the receiver operating characteristic curve index, Matthews correlation coefficient index, accuracy, and other evaluation parameters of the proposed method were tested on several independent breast cancer data sets and compared with representative gene signature-based algorithms including the baseline method. Experimental results demonstrate that the proposed method using deep learning techniques performs better than others.","","","10.1109/ACCESS.2018.2837654","National Natural Science Foundation of China; Open Project Program of the State Key Laboratory of Digital Manufacturing Equipment and Technology, HUST; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8361862","Cancer prognosis;ensemble classifier;principal component analysis;deep learning","Feature extraction;Principal component analysis;Machine learning;Gene expression;Neural networks;Breast cancer","cancer;feature extraction;feature selection;genetics;neural nets;pattern classification;principal component analysis;unsupervised learning","feature extraction methods;unsupervised feature learning framework;ensemble classifier;gene expression profiles;feature selection;deep learning techniques;baseline method;Matthews correlation coefficient index;classifier learning strategy;PCA-AE-Ada;AdaBoost algorithm;autoencoder neural network;principal component analysis algorithm;operating characteristic curve index;data classification;gene signature-based algorithms;breast cancer data sets;clinical outcome prediction","","4","43","","","","","IEEE","IEEE Journals"
"Energy-Efficient UAV Control for Effective and Fair Communication Coverage: A Deep Reinforcement Learning Approach","C. H. Liu; Z. Chen; J. Tang; J. Xu; C. Piao","School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; Department of Computer Science and Engineering, Syracuse University, Syracuse, NY, USA; School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China","IEEE Journal on Selected Areas in Communications","","2018","36","9","2059","2070","Unmanned aerial vehicles (UAVs) can be used to serve as aerial base stations to enhance both the coverage and performance of communication networks in various scenarios, such as emergency communications and network access for remote areas. Mobile UAVs can establish communication links for ground users to deliver packets. However, UAVs have limited communication ranges and energy resources. Particularly, for a large region, they cannot cover the entire area all the time or keep flying for a long time. It is thus challenging to control a group of UAVs to achieve certain communication coverage in a long run, while preserving their connectivity and minimizing their energy consumption. Toward this end, we propose to leverage emerging deep reinforcement learning (DRL) for UAV control and present a novel and highly energy-efficient DRL-based method, which we call DRL-based energy-efficient control for coverage and connectivity (DRL-EC3). The proposed method 1) maximizes a novel energy efficiency function with joint consideration for communications coverage, fairness, energy consumption and connectivity; 2) learns the environment and its dynamics; and 3) makes decisions under the guidance of two powerful deep neural networks. We conduct extensive simulations for performance evaluation. Simulation results have shown that DRL-EC3significantly and consistently outperform two commonly used baseline methods in terms of coverage, fairness, and energy consumption.","","","10.1109/JSAC.2018.2864373","National Natural Science Foundation of China; National Key Research and Development Program of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8432464","UAV control;deep reinforcement learning;energy efficiency;communication coverage","Energy consumption;Task analysis;Aerospace electronics;Communication networks;Machine learning;Unmanned aerial vehicles;Energy resources","aerospace communication;autonomous aerial vehicles;energy conservation;learning (artificial intelligence);mobile radio;mobile robots;neural nets","mobile UAV;energy efficiency;deep neural networks;DRL-EC;communications coverage;DRL-based energy-efficient control;deep reinforcement learning;energy consumption;energy resources;communication ranges;communication links;remote areas;network access;emergency communications;communication networks;aerial base stations;unmanned aerial vehicles;fair communication coverage;energy-efficient UAV control","","20","41","","","","","IEEE","IEEE Journals"
"Privacy-Preserving Double-Projection Deep Computation Model With Crowdsourcing on Cloud for Big Data Feature Learning","Q. Zhang; L. T. Yang; Z. Chen; P. Li; M. J. Deen","School of Software Technology, Dalian University of Technology, Dalian, China; School of Software Technology, Dalian University of Technology, Dalian, China; School of Software Technology, Dalian University of Technology, Dalian, China; School of Software Technology, Dalian University of Technology, Dalian, China; Department of Electrical and Computer Engineering, McMaster University, Hamilton, ON, Canada","IEEE Internet of Things Journal","","2018","5","4","2896","2903","Recent years have witness a considerable advance of Internet of Things with the tremendous progress of communication theories and sensing technologies. A large number of data, usually referring to big data, have been generated from Internet of Things. In this paper, we present a double-projection deep computation model (DPDCM) for big data feature learning, which projects the raw input into two separate subspaces in the hidden layers to learn interacted features of big data by replacing the hidden layers of the conventional deep computation model (DCM) with double-projection layers. Furthermore, we devise a learning algorithm to train the DPDCM. Cloud computing is used to improve the training efficiency of the learning algorithm by crowdsourcing the data on cloud. To protect the private data, a privacy-preserving DPDCM (PPDPDCM) is proposed based on the BGV encryption scheme. Finally, experiments are carried on Animal-20 and NUS-WIDE-14 to estimate the performance of DPDCM and PPDPDCM by comparing with DCM. Results demonstrate that DPDCM achieves a higher classification accuracy than DCM. More importantly, PPDPDCM can effectively improve the efficiency for training parameters, proving its potential for big data feature learning.","","","10.1109/JIOT.2017.2732735","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7994599","Big data;deep computation model (DCM);feature learning;Internet of Things;privacy-preserving","Computational modeling;Tensile stress;Data models;Internet of Things;Big Data;Training;Cloud computing","Big Data;cloud computing;cryptography;data privacy;feature extraction;learning (artificial intelligence);pattern classification","big data feature learning;conventional deep computation model;double-projection layers;learning algorithm;cloud computing;private data;privacy-preserving DPDCM;privacy-preserving double-projection deep computation model;BGV encryption scheme;crowdsourcing;Animal-20 data;NUS-WIDE-14 data","","26","34","","","","","IEEE","IEEE Journals"
"DAGAN: Deep De-Aliasing Generative Adversarial Networks for Fast Compressed Sensing MRI Reconstruction","G. Yang; S. Yu; H. Dong; G. Slabaugh; P. L. Dragotti; X. Ye; F. Liu; S. Arridge; J. Keegan; Y. Guo; D. Firmin","Imperial College London, National Heart & Lung Institute, London, U.K.; Imperial College London, Data Science Institute, London, U.K.; Imperial College London, Data Science Institute, London, U.K.; Department of Computer Science, City University of London, London, U.K.; EEE Department, Imperial College London, London, U.K.; School of Computer Science, University of Lincoln, Lincoln, U.K.; Imperial College London, Data Science Institute, London, U.K.; CMIC, University College London, London, U.K.; Imperial College London, National Heart & Lung Institute, London, U.K.; Imperial College London, Data Science Institute, London, U.K.; Imperial College London, National Heart & Lung Institute, London, U.K.","IEEE Transactions on Medical Imaging","","2018","37","6","1310","1321","Compressed sensing magnetic resonance imaging (CS-MRI) enables fast acquisition, which is highly desirable for numerous clinical applications. This can not only reduce the scanning cost and ease patient burden, but also potentially reduce motion artefacts and the effect of contrast washout, thus yielding better image quality. Different from parallel imaging-based fast MRI, which utilizes multiple coils to simultaneously receive MR signals, CS-MRI breaks the Nyquist-Shannon sampling barrier to reconstruct MRI images with much less required raw data. This paper provides a deep learning-based strategy for reconstruction of CS-MRI, and bridges a substantial gap between conventional non-learning methods working only on data from a single image, and prior knowledge from large training data sets. In particular, a novel conditional Generative Adversarial Networks-based model (DAGAN)-based model is proposed to reconstruct CS-MRI. In our DAGAN architecture, we have designed a refinement learning method to stabilize our U-Net based generator, which provides an end-to-end network to reduce aliasing artefacts. To better preserve texture and edges in the reconstruction, we have coupled the adversarial loss with an innovative content loss. In addition, we incorporate frequency-domain information to enforce similarity in both the image and frequency domains. We have performed comprehensive comparison studies with both conventional CS-MRI reconstruction methods and newly investigated deep learning approaches. Compared with these methods, our DAGAN method provides superior reconstruction with preserved perceptual image details. Furthermore, each image is reconstructed in about 5 ms, which is suitable for real-time processing.","","","10.1109/TMI.2017.2785879","British Heart Foundation Project Grant; NIHR Cardiovascular Biomedical Research Unit; Royal Brompton Hospital and Harefield NHS Foundation Trust; Jaywing plc; Optimise Portal; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8233175","Compressed sensing;magnetic resonance imaging (MRI);fast MRI;deep learning;generative adversarial networks (GAN);de-aliasing;inverse problems","Image reconstruction;Machine learning;Acceleration;Transforms;Encoding","biomedical MRI;compressed sensing;image reconstruction;image sampling;image texture;learning (artificial intelligence);medical image processing","fast acquisition;image quality;MRI images;nonlearning methods;single image;refinement learning method;U-Net based generator;end-to-end network;conventional CS-MRI reconstruction methods;DAGAN method;superior reconstruction;compressed sensing magnetic resonance imaging;conditional Generative Adversarial Networks;deep de-aliasing generative adversarial networks;fast compressed sensing MRI reconstruction;motion artefacts;contrast washout;deep learning-based strategy;aliasing artefact reduction;frequency-domain information;deep learning approaches;preserved perceptual image;Nyquist-Shannon sampling barrier","","23","72","CCBY","","","","IEEE","IEEE Journals"
"Deep learning-assisted and combined attack: a novel side-channel attack","W. Yu; J. Chen","Old Dominion University, USA; University of Minnesota Twin Cities, USA","Electronics Letters","","2018","54","19","1114","1116","A deep learning (DL)-assisted and combined side-channel attack (SCA) is exploited to disclose the secret key of an advanced encryption standard (AES) cryptographic circuit with a countermeasure. Different physical leakages of the protected AES cryptographic circuit such as power dissipation and electromagnetic (EM) emission are captured together at first. Then the deep neural networks are utilised to model the relationship between the power noise and the EM noise by analysing the captured power dissipation and EM emission profiles. Ultimately, a special power attack is performed on the protected AES cryptographic circuit to leak the secret key efficiently through using the EM noise to filter the power noise. As demonstrated in the results, for the conventional SCAs, the secret key of the protected AES cryptographic circuit is undisclosed to the adversary even if 1 million plaintexts are enabled. By contrast, only analysing 32,500 number of plaintexts are sufficient to leak the secret key if the DL-assisted and combined SCA is executed.","","","10.1049/el.2018.5411","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8464106","","","cryptography;integrated circuits;learning (artificial intelligence);neural nets;power aware computing","deep learning-assisted;combined side-channel attack;secret key;advanced encryption standard cryptographic circuit;protected AES cryptographic circuit;physical leakages;power dissipation;electromagnetic emission;deep neural networks;EM emission profiles;EM noise;power noise","","3","5","","","","","IET","IET Journals"
"Multi-Axial Force/Torque Sensor Calibration Method Based on Deep-Learning","H. S. Oh; U. Kim; G. Kang; J. K. Seo; H. R. Choi","School of Mechanical Engineering, Sungkyunkwan University, Suwon, South Korea; School of Mechanical Engineering, Sungkyunkwan University, Suwon, South Korea; School of Mechanical Engineering, Sungkyunkwan University, Suwon, South Korea; School of Mechanical Engineering, Sungkyunkwan University, Suwon, South Korea; School of Mechanical Engineering, Sungkyunkwan University, Suwon, South Korea","IEEE Sensors Journal","","2018","18","13","5485","5496","The multi-axial force/torque sensor for advanced robotic applications utilizes the internal strain of deformable structure for its measurement. Thus, there exist coupling and errors due to nonlinearity caused from the variation of the electric signal with respect to the strain. This paper presents a method of calibrating six-axis force/torque sensors with high accuracy based on deep learning. The method can solve the aforementioned problems easily by using deep-neural network (DNN). After performing the structural analysis of the sensor, generalized equations of the electric signal is derived, which leads it to the basic DNN structure, and optimization is performed. Training and test data are prepared by using a dummy and a reference sensor. Then, the proposed method is validated by comparing the three results obtained from the linear transformation method based on least-square method, two-step neural-network, and the DNN-based method for each untrained test data set.","","","10.1109/JSEN.2018.2834727","Gyeonggi Technology Development Program funded by Gyeonggi Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8356571","Force/torque sensor calibration;deep-learning;multi-layer neural network;deep neural network;coupling effect;decoupling method","Calibration;Force;Artificial neural networks;Capacitive sensors;Couplings;Torque","calibration;control engineering computing;force sensors;learning (artificial intelligence);least squares approximations;neural nets;robots","multiaxial force/torque sensor calibration method;advanced robotic applications;internal strain;deformable structure;electric signal;deep learning;deep-neural network;structural analysis;linear transformation method;least-square method;DNN structure","","3","24","","","","","IEEE","IEEE Journals"
"Deep Convolution Neural Network and Autoencoders-Based Unsupervised Feature Learning of EEG Signals","T. Wen; Z. Zhang","Software School, Xiamen University, Xiamen, China; Software School, Xiamen University, Xiamen, China","IEEE Access","","2018","6","","25399","25410","Epilepsy is a health problem that seriously affects the quality of humans for many years. Therefore, it is important to accurately analyze and recognize epilepsy based on EEG signals, and for a long time, researchers have attempted to extract new features from the signals for epilepsy recognition. However, it is very difficult to select useful features from a large number of them in this diagnostic application. As the development of artificial intelligence progresses, unsupervised feature learning based on the deep learning model can obtain features that can better describe identified objects from unlabeled data. In this paper, the deep convolution network and autoencoders-based model, named as AE-CDNN, is constructed in order to perform unsupervised feature learning from EEG in epilepsy. We extract features by AE-CDNN model and classify the features based on two public EEG data sets. Experimental results showed that the classification results of features obtained by AE-CDNN are more optimal than features obtained by principal component analysis and sparse random projection. Using several common classifiers to classify features obtained by AE-CDNN model results in high accuracy and not inferior to the research results from most recent studies. The results also showed that the features of AE-CDNN model are clear, effective, and easy to learn. These features can speed up the convergence and reduce the training times of classifiers. Therefore, the AE-CDNN model can be effectively applied to feature extraction of EEG in epilepsy.","","","10.1109/ACCESS.2018.2833746","Science and Technology Guiding Project of Fujian Province, China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8355473","EEG;unsupervised learning;feature extraction;CNN;epileptic seizure","Electroencephalography;Feature extraction;Brain modeling;Convolution;Epilepsy;Training;Deconvolution","convergence;diseases;electroencephalography;feature extraction;feedforward neural nets;learning (artificial intelligence);medical signal processing;principal component analysis;random processes;signal classification;unsupervised learning","AE-CDNN model;artificial intelligence;autoencoders-based model;feature classification;principal component analysis;sparse random projection;convergence;feature extraction;epilepsy recognition;EEG signals;unsupervised feature learning;deep convolution network;deep learning model","","12","36","CCBY","","","","IEEE","IEEE Journals"
"PolSAR Image Classification Using Polarimetric-Feature-Driven Deep Convolutional Neural Network","S. Chen; C. Tao","State Key Laboratory of Complex Electromagnetic Environment Effects on Electronics and Information System, College of Electronic Science, National University of Defense Technology, Changsha, China; State Key Laboratory of Complex Electromagnetic Environment Effects on Electronics and Information System, College of Electronic Science, National University of Defense Technology, Changsha, China","IEEE Geoscience and Remote Sensing Letters","","2018","15","4","627","631","Polarimetric synthetic aperture radar (PolSAR) image classification is an important application. Advanced deep learning techniques represented by deep convolutional neural network (CNN) have been utilized to enhance the classification performance. One current challenge is how to adapt deep CNN classifier for PolSAR classification with limited training samples, while keeping good generalization performance. This letter attempts to contribute to this problem. The core idea is to incorporate expert knowledge of target scattering mechanism interpretation and polarimetric feature mining to assist deep CNN classifier training and improve the final classification performance. A polarimetric-feature-driven deep CNN classification scheme is established. Both classical roll-invariant polarimetric features and hidden polarimetric features in the rotation domain are used to drive the proposed deep CNN model. Comparison studies validate the efficiency and superiority of the proposal. For the benchmark AIRSAR data, the proposed method achieves the state-of-the-art classification accuracy. Meanwhile, the convergence speed from the proposed polarimetric-feature-driven CNN approach is about 2.3 times faster than the normal CNN method. For multitemporal UAVSAR data sets, the proposed scheme achieves comparably high classification accuracy as the normal CNN method for train-used temporal data, while for train-not-used data it obtains an average of 4.86% higher overall accuracy than the normal CNN method. Furthermore, the proposed strategy can also produce very promising classification accuracy even with very limited training samples.","","","10.1109/LGRS.2018.2799877","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8292839","Classification;convolutional neural network (CNN);deep learning;multitemporal;polarimetric feature;polarimetric synthetic aperture radar (PolSAR);rotation domain","Training;Scattering;Benchmark testing;Entropy;Anisotropic magnetoresistance;Machine learning;Feature extraction","feedforward neural nets;geophysical image processing;image classification;learning (artificial intelligence);pattern classification;radar imaging;radar polarimetry;remote sensing by radar;synthetic aperture radar","normal CNN method;PolSAR image classification;deep convolutional neural network;polarimetric synthetic aperture radar image classification;advanced deep learning techniques;target scattering mechanism interpretation;polarimetric feature mining;deep CNN classifier training;final classification performance;deep CNN classification scheme;classical roll-invariant polarimetric features;hidden polarimetric features;polarimetric-feature-driven CNN approach;polarimetric-feature-driven deep CNN classification scheme","","26","20","","","","","IEEE","IEEE Journals"
"Orientation truncated centre learning for deep face recognition","M. M. Y. Zhang; Y. Xu; H. Wu","LPMC, Nankai University, People's Republic of China; LPMC, Nankai University, People's Republic of China; Tianjin University, People's Republic of China","Electronics Letters","","2018","54","19","1110","1112","Recently, centre loss that aiming to assist Softmax loss with the objectives of both inter-class dispension and intra-class compactness simultaneously, has achieved remarkable performance on convolutional neural network-based face recognition. However, its advantages highly rely on the centre feature assumption, which influences the capacity of the final obtained face features. Inspired by the centre loss approach, a novel Orientation Truncated Centre Learning is proposed, which takes advantage of an orientation truncated centre function to make the centre feature learning have more suitable orientation for deep face recognition. Three metrics are proposed to evaluate how discriminative are the distributions of the learned features for MNIST visualisation. Experimental results on several challenging benchmarks, including fine-grained labelled faces in the wild (FGLFW), labelled faces in the wild (LFW), YouTube faces (YTF), and benchmark of large-scale unconstrained face recognition (BLUFR), show that the proposed approach can easily generate more favourable results than several state-of-the-art competitors.","","","10.1049/el.2018.1326","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8464113","","","face recognition;learning (artificial intelligence);feedforward neural nets;feature extraction","orientation truncated centre learning;deep face recognition;centre loss;Softmax loss;interclass dispension;intraclass compactness;convolutional neural network-based face recognition;centre feature assumption;orientation truncated centre function;centre feature learning;MNIST visualisation;FGLFW benchmark;LFW benchmark;YTF benchmark;BLUFR benchmark","","","11","","","","","IET","IET Journals"
"Image ordinal classification with deep multi-view learning","C. Zhang; X. Xu; C. Zhu","University of Electronic Science and Technology of China (UESTC), People's Republic of China; National University of Singapore (NUS), Singapore; University of Electronic Science and Technology of China (UESTC), People's Republic of China","Electronics Letters","","2018","54","22","1280","1282","Image ordinal classification has drawn substantial attention from the research community due to the ordering relation between image categories. Recent advancements towards image ordinal classification lie in applying deep neural networks [convolutional neural network (CNN)]. Nevertheless, the lack of ordinal training data prevents deep models from generalising to testing data. In this work, two multi-view learning approaches are proposed to tackle the insufficient data issue. On one hand, a multi-view ordinal classification with multi-view max pooling (MVMP) approach is proposed, in which each image is randomly blocked with some grids thus creating multiple views of the original data. All views are then used to train multi-view CNN for classification. On the other hand, in order to account for the ordinal relation, the authors propose a double-task learning on MVMP for classification and average pooling for regression. The task of regression benefits that of classification, mainly focusing on improving classification's recognition accuracy. The two proposed approaches are validated on Adience dataset, and show very compelling results. The code and models will be available online.","","","10.1049/el.2018.5101","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8509722","","","convolution;feedforward neural nets;image classification;learning (artificial intelligence);regression analysis","adience dataset;MVMP;deep multiview learning;image ordinal classification;double-task learning;multiview CNN;multiview max pooling approach;insufficient data issue;testing data;ordinal training data;convolutional neural network;deep neural networks;image categories","","","","","","","","IET","IET Journals"
"Motion Blur Kernel Estimation via Deep Learning","X. Xu; J. Pan; Y. Zhang; M. Yang","Department of Electronic Engineering, Tsinghua University, Beijing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; School of Engineering, University of California at Merced, Merced, CA, USA","IEEE Transactions on Image Processing","","2018","27","1","194","205","The success of the state-of-the-art deblurring methods mainly depends on the restoration of sharp edges in a coarse-to-fine kernel estimation process. In this paper, we propose to learn a deep convolutional neural network for extracting sharp edges from blurred images. Motivated by the success of the existing filtering-based deblurring methods, the proposed model consists of two stages: suppressing extraneous details and enhancing sharp edges. We show that the two-stage model simplifies the learning process and effectively restores sharp edges. Facilitated by the learned sharp edges, the proposed deblurring algorithm does not require any coarse-to-fine strategy or edge selection, thereby significantly simplifying kernel estimation and reducing computation load. Extensive experimental results on challenging blurry images demonstrate that the proposed algorithm performs favorably against the state-of-the-art methods on both synthetic and real-world images in terms of visual quality and run-time.","","","10.1109/TIP.2017.2753658","NSF CAREER; NSF of China; 973 Program of China; NSF of Jiangsu Province; National Key Research and Development Program of China; Adobe; Nvidia; China Scholarship Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8039224","Blind image deblurring;kernel estimation;deep convolutional neural network;sharp edges","Image edge detection;Image restoration;Kernel;Estimation;Computational modeling;Training data;Machine learning","image enhancement;image filtering;image restoration;learning (artificial intelligence);neural nets","motion blur kernel estimation;deep learning;state-of-the-art deblurring methods;coarse-to-fine kernel estimation process;deep convolutional neural network;blurred images;learning process;learned sharp edges;deblurring algorithm;coarse-to-fine strategy;simplifying kernel estimation;state-of-the-art methods;filtering-based deblurring methods","","7","42","Traditional","","","","IEEE","IEEE Journals"
"Learning Semantic-Aligned Action Representation","B. Ni; T. Li; X. Yang","Department of Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; College of Electrical Engineering and Automation, Anhui University, Hefei, China; Department of Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","8","3715","3725","A fundamental bottleneck for achieving highly discriminative action representation is that local motion/appearance features are usually not semantic aligned. Namely, a local feature, such as a motion vector or motion trajectory, does not possess any attribute that indicates which moving body part or operated object it is associated with. This mostly leads to global feature pooling/representation learning methods that are often too coarse. Inspired by the recent success of end-to-end (pixel-to-pixel) deep convolutional neural networks (DCNNs), in this paper, we first propose a DCNN architecture, which maps a human centric image region onto human body part response maps. Based on these response maps, we propose a second DCNN, which achieves semantic-aligned feature representation learning. Prior knowledge that only a few parts are responsible for a certain action is also utilized by introducing a group (part) sparseness prior during feature learning. The learned semantic-aligned feature not only boosts the discriminative capability of action representation, but also possesses the good nature of robustness to pose variations and occlusions. Finally, an iterative mining method is employed for learning discriminative action primitive detectors. Extensive experiments on action recognition benchmarks demonstrate a superior recognition performance of the proposed framework.","","","10.1109/TNNLS.2017.2731775","National Key Research and Development Program of China; National Natural Science Foundation of China; 111 Program; Shanghai Key Lab of Digital Media Processing and Transmission; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8023876","Deep convolutional neural network (DCNN);end-to-end model;semantic alignment;sparse","Semantics;Trajectory;Feature extraction;Nickel;Motion segmentation;Learning systems","data mining;feature extraction;feedforward neural nets;image classification;image motion analysis;image representation;iterative methods;learning (artificial intelligence);object recognition","local motion feature;local appearance feature;motion trajectory;global feature pooling;global feature representation;end-to-end deep convolutional neural networks;pixel-to-pixel deep convolutional neural networks;semantic-aligned feature representation learning;iterative mining method;discriminative action primitive detector learning;action recognition benchmarks;discriminative capability;group sparseness;feature representation learning;human body part response maps;human centric image region;DCNN architecture;motion vector;fundamental bottleneck","","1","51","","","","","IEEE","IEEE Journals"
"A Regularized Deep Learning Approach for Clinical Risk Prediction of Acute Coronary Syndrome Using Electronic Health Records","Z. Huang; W. Dong; H. Duan; J. Liu","College of Biomedical Engineering and Instrument Science, Zhejiang University; Department of Cardiology, Chinese PLA General Hospital; College of Biomedical Engineering and Instrument Science, Zhejiang University; College of Biomedical Engineering and Instrument Science, Zhejiang University, Hangzhou, China","IEEE Transactions on Biomedical Engineering","","2018","65","5","956","968","Objective: Acute coronary syndrome (ACS), as a common and severe cardiovascular disease, is a leading cause of death and the principal cause of serious long-term disability globally. Clinical risk prediction of ACS is important for early intervention and treatment. Existing ACS risk scoring models are based mainly on a small set of hand-picked risk factors and often dichotomize predictive variables to simplify the score calculation. Methods: This study develops a regularized stacked denoising auto-encoder (SDAE) model to stratify clinical risks of ACS patients from a large volume of electronic health records (EHR). To capture characteristics of patients at similar risk levels, and preserve the discriminating information across different risk levels, two constraints are added on SDAE to make the reconstructed feature representations contain more risk information of patients, which contribute to a better clinical risk prediction result. Results: We validate our approach on a real clinical dataset consisting of 3464 ACS patient samples. The performance of our approach for predicting ACS risk remains robust and reaches 0.868 and 0.73 in terms of both AUC and accuracy, respectively. Conclusions: The obtained results show that the proposed approach achieves a competitive performance compared to state-of-the-art models in dealing with the clinical risk prediction problem. In addition, our approach can extract informative risk factors of ACS via a reconstructive learning strategy. Some of these extracted risk factors are not only consistent with existing medical domain knowledge, but also contain suggestive hypotheses that could be validated by further investigations in the medical domain.","","","10.1109/TBME.2017.2731158","National Natural Science Foundation of China; National Basic Research Program of China (973 Program); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7990180","Acute coronary syndrome;clinical risk prediction;deep learning;electronic health record;stacked denoising auto-encoder","Cardiovascular diseases;Deep learning;Clinical diagnosis;Encoding;Risk management;Predictive models;Electronic medical records","cardiovascular system;diseases;feature extraction;health care;learning (artificial intelligence);medical information systems;patient diagnosis;risk analysis","clinical risk prediction result;clinical dataset;informative risk factors;extracted risk factors;regularized deep learning approach;Acute coronary syndrome;electronic health records;common disease;severe cardiovascular disease;long-term disability;ACS risk scoring models;predictive variables;regularized stacked denoising auto-encoder model;clinical risks;ACS patients;risk levels","","2","48","","","","","IEEE","IEEE Journals"
"Content Popularity Prediction and Caching for ICN: A Deep Learning Approach With SDN","W. Liu; J. Zhang; Z. Liang; L. Peng; J. Cai","Department of Electronic and Information Engineering, Guangzhou University, Guangzhou, China; Department of Electrical Engineering and Automation, Guangzhou University, Guangzhou, China; Department of Electrical Engineering and Automation, Guangzhou University, Guangzhou, China; Department of Electronic and Information Engineering, Guangzhou University, Guangzhou, China; School of Electronic and Information, Guangdong Polytechnic Normal University, Guangzhou, China","IEEE Access","","2018","6","","5075","5089","In information-centric networking, accurately predicting content popularity can improve the performance of caching. Therefore, based on software defined network (SDN), this paper proposes Deep-Learning-based Content Popularity Prediction (DLCPP) to achieve the popularity prediction. DLCPP adopts the switch's computing resources and links in the SDN to build a distributed and reconfigurable deep learning network. For DLCPP, we initially determine the metrics that can reflect changes in content popularity. Second, each network node collects the spatial-temporal joint distribution data of these metrics. Then, the data are used as input to stacked auto-encoders (SAE) in DLCPP to extract the spatiotemporal features of popularity. Finally, we transform the popularity prediction into a multi-classification problem through discretizing the content popularity into multiple classifications. The Softmax classifier is used to achieve the content popularity prediction. Some challenges for DLCPP are also addressed, such as determining the structure of SAE, realizing the neuron function on an SDN switch, and deploying DLCPP on an OpenFlow-based SDN. At the same time, we propose a lightweight caching scheme that integrates cache placement and cache replacement-caching based on popularity prediction and cache capacity (CPC). Abundant experiments demonstrate good performance of DLCPP, and it achieves close to 2.1%~15% and 5.2%~40% accuracy improvements over neural networks and auto regressive, respectively. Benefitting from DLCPP's better prediction accuracy, CPC can yield a steady improvement of caching performance over other dominant cache management frameworks.","","","10.1109/ACCESS.2017.2781716","National Natural Science Foundation of China; Guangdong Natural Science Foundation; Guangdong provincial key platform and major scientific research projects; China National Spark Program; Science and Technology Project of Guangdong Province; Guangzhou Education Science 12th Five-Year planning; Innovative Academic Team Project of Guangzhou Education System; Science and Technology Project for Universities in Guangzhou (Researching on key technology of achieving multisource transmission for ICN, China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8172025","Information-centric networking;SDN;deep learning;content popularity prediction;caching scheme","Machine learning;Correlation;Switches;Feature extraction;Predictive models;Artificial neural networks;Data mining","cache storage;Internet;learning (artificial intelligence);neural nets","DLCPP;SDN;cache placement;cache replacement-caching;prediction accuracy;content popularity prediction;information-centric networking;software defined network;distributed learning network;reconfigurable deep learning network;stacked auto-encoders;SAE;Softmax classifier;popularity prediction;cache capacity;cache management frameworks","","15","54","","","","","IEEE","IEEE Journals"
"Multi-Organ Plant Classification Based on Convolutional and Recurrent Neural Networks","S. H. Lee; C. S. Chan; P. Remagnino","Center of Image and Signal Processing, Faculty of Computer Science and Information Technology, University of Malaya, Kuala Lumpur, Malaysia; Center of Image and Signal Processing, Faculty of Computer Science and Information Technology, University of Malaya, Kuala Lumpur, Malaysia; Faculty of Science, Engineering and Computing, Kingston University, Kingston Upon Thames, U.K.","IEEE Transactions on Image Processing","","2018","27","9","4287","4301","Classification of plants based on a multi-organ approach is very challenging. Although additional data provide more information that might help to disambiguate between species, the variability in shape and appearance in plant organs also raises the degree of complexity of the problem. Despite promising solutions built using deep learning enable representative features to be learned for plant images, the existing approaches focus mainly on generic features for species classification, disregarding the features representing plant organs. In fact, plants are complex living organisms sustained by a number of organ systems. In our approach, we introduce a hybrid generic-organ convolutional neural network (HGO-CNN), which takes into account both organ and generic information, combining them using a new feature fusion scheme for species classification. Next, instead of using a CNN-based method to operate on one image with a single organ, we extend our approach. We propose a new framework for plant structural learning using the recurrent neural network-based method. This novel approach supports classification based on a varying number of plant views, capturing one or more organs of a plant, by optimizing the contextual dependencies between them. We also present the qualitative results of our proposed models based on feature visualization techniques and show that the outcomes of visualizations depict our hypothesis and expectation. Finally, we show that by leveraging and combining the aforementioned techniques, our best network outperforms the state of the art on the PlantClef2015 benchmark. The source code and models are available at https://github.com/cs-chan/Deep-Plant.","","","10.1109/TIP.2018.2836321","Fundamental Research Grant Scheme through the Ministry of Education Malaysia; Postgraduate Research Fund through the University of Malaya; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8359391","Plant classification;deep learning","Feature extraction;Biological systems;Recurrent neural networks;Task analysis;Shape;Machine learning;Computer vision","biology computing;data visualisation;feature extraction;image classification;learning (artificial intelligence);recurrent neural nets","multiorgan plant classification;convolutional networks;recurrent neural networks;deep learning;plant images;feature fusion scheme;plant structural learning;feature visualization techniques;hybrid generic organ convolutional neural network;HGO-CNN","Algorithms;Databases, Factual;Deep Learning;Image Processing, Computer-Assisted;Plants","3","74","","","","","IEEE","IEEE Journals"
"Deep Learning-Based Classification and Reconstruction of Residential Scenes From Large-Scale Point Clouds","L. Zhang; L. Zhang","State Key Laboratory of Remote Sensing Science, Faculty of Geographical Science, Beijing Normal University, Beijing, China; School of Civil Engineering, Shi Jiazhuang Tiedao University, Shijiazhuang, China","IEEE Transactions on Geoscience and Remote Sensing","","2018","56","4","1887","1897","The reconstruction of urban buildings from large-scale airborne laser scanning point clouds is an important research topic in the geoscience field. Large-scale urban scenes usually contain a large number of object categories and many overlapped or closely neighboring objects, which poses great challenges for classifying and modeling buildings from these data sets. In this paper, we propose a deep reinforcement learning framework that integrates a 3-D convolutional neural network, a deep Q-network, and a residual recurrent neural network for the efficient semantic parsing of large-scale 3-D point clouds. The proposed framework provides an end-to-end automatic processing method that maps the raw point cloud to the classification results of the given categories. After obtaining the building classes, we utilize an edge-aware resampling algorithm to consolidate the point set with noise-free normals and clean preservation of sharp features. Finally, 2.5-D dual contouring, which is a data-driven approach, is introduced to generate urban building models from the consolidated point clouds. Our method can generate lightweight building models with arbitrarily shaped roofs while preserving the verticality of connecting walls.","","","10.1109/TGRS.2017.2769120","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8226988","Classification;deep learning;point cloud;reconstruction","Three-dimensional displays;Buildings;Feature extraction;Image reconstruction;Semantics;Solid modeling;Shape","buildings (structures);convolution;feedforward neural nets;image classification;image reconstruction;learning (artificial intelligence);recurrent neural nets;sampling methods;solid modelling;structural engineering computing","deep learning;residential scenes;large-scale point clouds;urban buildings;large-scale airborne laser scanning point clouds;geoscience field;large-scale urban scenes;overlapped objects;closely neighboring objects;deep reinforcement learning framework;3-D convolutional neural network;deep Q-network;residual recurrent neural network;efficient semantic parsing;end-to-end automatic processing method;edge-aware resampling algorithm;data-driven approach;urban building models;consolidated point clouds;lightweight building models","","6","50","","","","","IEEE","IEEE Journals"
"DeepThings: Distributed Adaptive Deep Learning Inference on Resource-Constrained IoT Edge Clusters","Z. Zhao; K. M. Barijough; A. Gerstlauer","Department of Electrical and Computer Engineering, University of Texas at Austin, Austin, TX, USA; Department of Electrical and Computer Engineering, University of Texas at Austin, Austin, TX, USA; Department of Electrical and Computer Engineering, University of Texas at Austin, Austin, TX, USA","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","","2018","37","11","2348","2359","Edge computing has emerged as a trend to improve scalability, overhead, and privacy by processing large-scale data, e.g., in deep learning applications locally at the source. In IoT networks, edge devices are characterized by tight resource constraints and often dynamic nature of data sources, where existing approaches for deploying Deep/Convolutional Neural Networks (DNNs/CNNs) can only meet IoT constraints when severely reducing accuracy or using a static distribution that cannot adapt to dynamic IoT environments. In this paper, we propose DeepThings, a framework for adaptively distributed execution of CNN-based inference applications on tightly resource-constrained IoT edge clusters. DeepThings employs a scalable Fused Tile Partitioning (FTP) of convolutional layers to minimize memory footprint while exposing parallelism. It further realizes a distributed work stealing approach to enable dynamic workload distribution and balancing at inference runtime. Finally, we employ a novel work scheduling process to improve data reuse and reduce overall execution latency. Results show that our proposed FTP method can reduce memory footprint by more than 68% without sacrificing accuracy. Furthermore, compared to existing work sharing methods, our distributed work stealing and work scheduling improve throughput by 1.7 × -2.2× with multiple dynamic data sources. When combined, DeepThings provides scalable CNN inference speedups of 1.7×-3.5× on 2-6 edge devices with less than 23 MB memory each.","","","10.1109/TCAD.2018.2858384","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8493499","Deep learning;distributed inference;edge computing;Internet of Things","Task analysis;Runtime;Logic gates;Distributed databases;Dynamic scheduling;Parallel processing;Neural networks","convolution;feedforward neural nets;inference mechanisms;Internet of Things;learning (artificial intelligence);pattern clustering;resource allocation;scheduling","DeepThings;deep learning applications;IoT networks;tight resource constraints;dynamic nature;static distribution;dynamic IoT environments;adaptively distributed execution;CNN-based inference applications;tightly resource-constrained IoT edge clusters;convolutional layers;memory footprint;distributed work;dynamic workload distribution;inference runtime;novel work scheduling process;data reuse;multiple dynamic data sources;scalable CNN inference speedups;deep-convolutional neural networks;distributed adaptive deep learning inference;edge computing;scalable fused tile partitioning;DNNs-CNNs;FTP","","2","24","","","","","IEEE","IEEE Journals"
"A Deep Learning Loss Function Based on the Perceptual Evaluation of the Speech Quality","J. M. Martín-Doñas; A. M. Gomez; J. A. Gonzalez; A. M. Peinado","Department of Signal Theory, Telematics and Communications, Universidad de Granada, Granada, Spain; Department of Signal Theory, Telematics and Communications, Universidad de Granada, Granada, Spain; Department of Languages and Computer Sciences, Universidad de Malaga, Malaga, Spain; Department of Signal Theory, Telematics and Communications, Universidad de Granada, Granada, Spain","IEEE Signal Processing Letters","","2018","25","11","1680","1684","This letter proposes a perceptual metric for speech quality evaluation, which is suitable, as a loss function, for training deep learning methods. This metric, derived from the perceptual evaluation of the speech quality algorithm, is computed in a per-frame basis and from the power spectra of the reference and processed speech signal. Thus, two disturbance terms, which account for distortion once auditory masking and threshold effects are factored in, amend the mean square error (MSE) loss function by introducing perceptual criteria based on human psychoacoustics. The proposed loss function is evaluated for noisy speech enhancement with deep neural networks. Experimental results show that our metric achieves significant gains in speech quality (evaluated using an objective metric and a listening test) when compared to using MSE or other perceptual-based loss functions from the literature.","","","10.1109/LSP.2018.2871419","Spanish MINECO/FEDER; Spanish Ministry of Education through the National Program FPU; NVIDIA Corporation with the donation of a Titan X GPU; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8468124","Deep learning;loss function;speech enhancement;PESQ;DNN","Training;Measurement;Spectral analysis;Gain;Speech enhancement;Signal processing algorithms","distortion;learning (artificial intelligence);mean square error methods;neural nets;speech enhancement","human psychoacoustics;MSE loss function;disturbance terms;speech signal processing;deep learning loss function;perceptual-based loss functions;deep neural networks;noisy speech enhancement;perceptual criteria;mean square error loss function;threshold effects;distortion once auditory masking;power spectra;per-frame basis;speech quality algorithm;deep learning methods;speech quality evaluation;perceptual evaluation","","3","31","","","","","IEEE","IEEE Journals"
"Intelligent Bearing Fault Diagnosis Method Combining Compressed Data Acquisition and Deep Learning","J. Sun; C. Yan; J. Wen","School of Information Science and Engineering, Yanshan University, Qinhuangdao, China; Key Laboratory of Measurement Technology and Instrumentation of Hebei Province, Yanshan University, Qinhuangdao, China; Key Laboratory of Measurement Technology and Instrumentation of Hebei Province, Yanshan University, Qinhuangdao, China","IEEE Transactions on Instrumentation and Measurement","","2018","67","1","185","195","Effective intelligent fault diagnosis has long been a research focus on the condition monitoring of rotary machinery systems. Traditionally, time-domain vibration-based fault diagnosis has some deficiencies, such as complex computation of feature vectors, excessive dependence on prior knowledge and diagnostic expertise, and limited capacity for learning complex relationships in fault signals. Furthermore, following the increase in condition data, how to promptly process the massive fault data and automatically provide accurate diagnosis has become an urgent need to solve. Inspired by the idea of compressed sensing and deep learning, a novel intelligent diagnosis method is proposed for fault identification of rotating machines. In this paper, a nonlinear projection is applied to achieve the compressed acquisition, which not only reduces the amount of measured data that contained all the information of faults but also realizes the automatic feature extraction in transform domain. For exploring the discrimination hidden in the acquired data, a stacked sparse autoencoders-based deep neural network is established and performed with an unsupervised learning procedure followed by a supervised fine-tuning process. We studied the significance of compressed acquisition and provided the effects of key factors and comparison with traditional methods. The effectiveness of the proposed method is validated using data sets from rolling element bearings and the analysis shows that it is able to obtain high diagnotic accuracies and is superior to the existing methods. The proposed method reduces the need of human labor and expertise and provides new strategy to handle the massive data more easily.","","","10.1109/TIM.2017.2759418","National Natural Science Foundation of China; Natural Science Foundation of Hebei Province of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8097416","Bearing fault;compressed sensing (CS);deep neural network (DNN);intelligent diagnosis;stacked sparse autoencoder (SSAE)","Fault diagnosis;Feature extraction;Machine learning;Time-domain analysis;Neural networks;Data acquisition;Compressed sensing","compressed sensing;data acquisition;encoding;fault diagnosis;feature extraction;mechanical engineering computing;neural nets;rolling bearings;transforms;unsupervised learning","intelligent bearing fault diagnosis method;compressed data acquisition;deep learning;condition monitoring;rotary machinery system;time-domain vibration-based fault diagnosis;complex feature vector computation;fault signal relationship;compressed sensing;rotating machine fault identification;nonlinear projection application;automatic feature extraction;transform domain;stacked sparse autoencoders-based deep neural network;unsupervised learning procedure;supervised fine-tuning process;rolling element bearings","","27","42","","","","","IEEE","IEEE Journals"
"Deep Learning for Human Affect Recognition: Insights and New Developments","P. V. Rouast; M. Adam; R. Chiong","School of Electrical Engineering and Computing, The University of Newcastle, Australia, Callaghan, New South Wales Australia (e-mail: philipp.rouast@uon.edu.au); Faculty of Engineering and Built Environment, The University of Newcastle, Callaghan, New South Wales Australia (e-mail: marc.adam@newcastle.edu.au); School of Electrical Engineering and Computing, The University of Newcastle, Australi, Callaghan, New South Wales Australia (e-mail: Raymond.Chiong@newcastle.edu.au)","IEEE Transactions on Affective Computing","","2018","PP","99","1","1","Automatic human affect recognition is a key step towards more natural human-computer interaction. Recent trends include recognition in the wild using a fusion of audiovisual and physiological sensors, a challenging setting for conventional machine learning algorithms. Since 2010, novel deep learning algorithms have been applied increasingly in this field. In this paper, we review the literature on human affect recognition between 2010 and 2017, with a special focus on approaches using deep neural networks. By classifying a total of 950 studies according to their usage of shallow or deep architectures, we are able to show a trend towards deep learning. Reviewing a subset of 233 studies that employ deep neural networks, we comprehensively quantify their applications in this field. We find that deep learning is used for learning of (i) spatial feature representations, (ii) temporal feature representations, and (iii) joint feature representations for multimodal sensor data. Exemplary state-of-the-art architectures illustrate the recent progress. Our findings show the role deep architectures will play in human affect recognition, and can serve as a reference point for researchers working on related applications.","","","10.1109/TAFFC.2018.2890471","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8598999","Affect recognition;Deep learning;Emotion recognition;Human-computer interaction","Deep learning;Computer architecture;Biological neural networks;Emotion recognition;Training;Human computer interaction;Machine learning algorithms","","","","2","","","","","","IEEE","IEEE Early Access Articles"
"Joint Segment-Level and Pixel-Wise Losses for Deep Learning Based Retinal Vessel Segmentation","Z. Yan; X. Yang; K. Cheng","Department of Computer Science and EngineeringHong Kong University of Science and Technology; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Department of Computer Science and EngineeringHong Kong University of Science and Technology","IEEE Transactions on Biomedical Engineering","","2018","65","9","1912","1923","Objective: Deep learning based methods for retinal vessel segmentation are usually trained based on pixel-wise losses, which treat all vessel pixels with equal importance in pixel-to-pixel matching between a predicted probability map and the corresponding manually annotated segmentation. However, due to the highly imbalanced pixel ratio between thick and thin vessels in fundus images, a pixel-wise loss would limit deep learning models to learn features for accurate segmentation of thin vessels, which is an important task for clinical diagnosis of eye-related diseases. Methods: In this paper, we propose a new segment-level loss which emphasizes more on the thickness consistency of thin vessels in the training process. By jointly adopting both the segment-level and the pixel-wise losses, the importance between thick and thin vessels in the loss calculation would be more balanced. As a result, more effective features can be learned for vessel segmentation without increasing the overall model complexity. Results: Experimental results on public data sets demonstrate that the model trained by the joint losses outperforms the current state-of-the-art methods in both separate-training and cross-training evaluations. Conclusion: Compared to the pixel-wise loss, utilizing the proposed joint-loss framework is able to learn more distinguishable features for vessel segmentation. In addition, the segment-level loss can bring consistent performance improvement for both deep and shallow network architectures. Significance: The findings from this study of using joint losses can be applied to other deep learning models for performance improvement without significantly changing the network architectures.","","","10.1109/TBME.2018.2828137","National Natural Science Foundation of China; Wuhan Science and Technology Bureau Award; HUST Acadamic Frontier Youth Team; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8341481","Segment-level loss;deep learning;retinal image analysis;vessel segmentation","Image segmentation;Machine learning;Retinal vessels;Manuals;Loss measurement;Skeleton;Training","biomedical optical imaging;blood vessels;diseases;eye;feature extraction;image segmentation;learning (artificial intelligence);medical image processing","pixel-wise loss;retinal vessel segmentation;vessel pixels;pixel-to-pixel matching;deep learning models;segment-level loss;pixel ratio","","10","44","","","","","IEEE","IEEE Journals"
"Deep Neural Networks for Learning Spatio-Temporal Features From Tomography Sensors","O. Costilla-Reyes; P. Scully; K. B. Ozanyan","School of Electrical and Electronic Engineering, The University of Manchester, Manchester, U.K.; School of Chemical Engineering and Analytical Science, Faculty of Engineering and Physical Sciences and the Photon Science Institute, The University of Manchester, Manchester, U.K.; School of Electrical and Electronic Engineering, The University of Manchester, Manchester, U.K.","IEEE Transactions on Industrial Electronics","","2018","65","1","645","653","We demonstrate accurate spatio-temporal gait data classification from raw tomography sensor data without the need to reconstruct images. This is based on a simple yet efficient machine learning methodology based on a convolutional neural network architecture for learning spatio-temporal features, automatically end-to-end from raw sensor data. In a case study on a floor pressure tomography sensor, experimental results show an effective gait pattern classification F-score performance of 97.88 ± 1.70%. It is shown that the automatic extraction of classification features from raw data leads to a substantially better performance, compared to features derived by shallow machine learning models that use the reconstructed images as input, implying that for the purpose of automatic decisionmaking it is possible to eliminate the image reconstruction step. This approach is portable across a range of industrial tasks that involve tomography sensors. The proposed learning architecture is computationally efficient, has a low number of parameters and is able to achieve reliable classification F-score performance from a limited set of experimental samples. We also introduce a floor sensor dataset of 892 samples, encompassing experiments of 10 manners of walking and 3 cognitive-oriented tasks to yield a total of 13 types of gait patterns.","","","10.1109/TIE.2017.2716907","Engineering and Physical Sciences Research Council; Consejo Nacional de Ciencia y Tecnología; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8003415","Convolutional neural networks (CNNs);deep learning;floor sensor system;machine learning;spatio-temporal analysis;tomography","Sensor systems;Tomography;Feature extraction;Sensor phenomena and characterization;Image reconstruction;Image sensors","compressed sensing;feature extraction;gait analysis;learning (artificial intelligence);neural nets;pattern classification;statistical analysis","deep neural networks;tomography sensors;raw tomography sensor data;convolutional neural network architecture;floor pressure tomography sensor;reconstructed images;learning architecture;reliable classification F-score performance;floor sensor dataset;gait patterns;machine learning;spatio-temporal feature learning;spatio-temporal gait data classification;gait pattern classification F-score performance;automatic classification feature extraction;automatic decision making","","15","31","CCBY","","","","IEEE","IEEE Journals"
"Big Data Processing Architecture for Radio Signals Empowered by Deep Learning: Concept, Experiment, Applications and Challenges","S. Zheng; S. Chen; L. Yang; J. Zhu; Z. Luo; J. Hu; X. Yang","Science and Technology on Communication Information Security Control Laboratory, Jiaxing, China; Science and Technology on Communication Information Security Control Laboratory, Jiaxing, China; Science and Technology on Communication Information Security Control Laboratory, Jiaxing, China; Science and Technology on Communication Information Security Control Laboratory, Jiaxing, China; Science and Technology on Communication Information Security Control Laboratory, Jiaxing, China; Science and Technology on Communication Information Security Control Laboratory, Jiaxing, China; Science and Technology on Communication Information Security Control Laboratory, Jiaxing, China","IEEE Access","","2018","6","","55907","55922","In modern society, the demand for radio spectrum resources is increasing. As the information carriers of wireless transmission data, radio signals exhibit the characteristics of big data in terms of volume, variety, value, and velocity. How to uniformly handle these radio signals and obtain value from them is a problem that needs to be studied. In this paper, a big data processing architecture for radio signals is presented and a new approach of end-to-end signal processing based on deep learning is discussed in detail. The radio signal intelligent search engine is used as an example to verify the architecture, and the system components and experimental results are introduced. In addition, the applications of the architecture in cognitive radio, spectrum monitoring, and cyberspace security are introduced. Finally, challenges are discussed, such as unified representation of radio signal features, distortionless compression of wideband sampled data, and deep neural networks for radio signals.","","","10.1109/ACCESS.2018.2872769","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8476607","Radio signals;big data;deep learning;neural networks;search engine;cognitive radio;cyberspace","Big Data;Machine learning;Time-frequency analysis;Data mining;Frequency shift keying;Wireless communication","Big Data;cognitive radio;learning (artificial intelligence);radio spectrum management;search engines;signal representation;signal sampling;telecommunication computing;telecommunication security","deep learning;radio spectrum resources;wireless transmission data;end-to-end signal;radio signal intelligent search engine;cognitive radio;big data processing architecture;radio signal processing;cyberspace security;spectrum monitoring;radio signal feature representation;wideband sampled data distortionless compression;deep neural networks","","4","85","","","","","IEEE","IEEE Journals"
"Exploiting Future Radio Resources With End-to-End Prediction by Deep Learning","J. Guo; C. Yang; I. Chih-Lin","School of Electrical and Information Engineering, Beihang University, Beijing, China; School of Electrical and Information Engineering, Beihang University, Beijing, China; China Mobile Communication Corporation, China Mobile Research Institute, Beijing, China","IEEE Access","","2018","6","","75729","75747","Machine learning is a powerful tool to predict user behavior and harness the vast amount of data measured in cellular networks. Predictive resource allocation is a promising approach to take advantage of the prediction for the mobility and traffic load related user behavior. This paper strives to boost the performance of under-utilized networks by predicting behavior-related information from historical data with deep learning. We first propose a hierarchical and multi-timescale radio resource management scheme for non-realtime service that only needs coarse-grained future knowledge, by taking multi-input-multi-output orthogonal frequency multi-access as an example system and high throughput as an example performance metric. Such a scheme allows the decision of resource management to be made in a central processor and base stations in different timescales and allows the knowledge to be predicted with less training samples. Then, we design a deep neural network to learn the future knowledge required for making decision directly from different types of past data with different resolutions observable in cellular networks. Simulation results show that the proposed scheme with the end-to-end knowledge prediction performs closely to the relevant optimal solution with perfect and fine-grained prediction, and provides dramatic gain over non-predictive counterpart in supporting high request arrival rate for the non-realtime service.","","","10.1109/ACCESS.2018.2882815","National Natural Science Foundation of China; Ministry of Education of China (MOE)-CMCC Science Joint Foundation for Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8543484","User behavior information;radio resource allocation;deep learning;end-to-end prediction","Resource management;Cellular networks;Throughput;Training;Trajectory","cellular radio;frequency division multiple access;learning (artificial intelligence);MIMO communication;neural nets;OFDM modulation;quality of service;resource allocation;telecommunication traffic","deep learning;machine learning;cellular networks;predictive resource allocation;multiinput-multioutput orthogonal frequency multiaccess;resource management;central processor;base stations;deep neural network;end-to-end knowledge prediction;radio resources","","1","34","","","","","IEEE","IEEE Journals"
"Structure Learning for Deep Neural Networks Based on Multiobjective Optimization","J. Liu; M. Gong; Q. Miao; X. Wang; H. Li","Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, International Research Center for Intelligent Perception and Computation, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, International Research Center for Intelligent Perception and Computation, Xidian University, Xi’an, China; School of Computer Science and Technology, Xidian University, Xi’an, China; Department of Electronic Engineering, The Chinese University of Hong Kong, Hong Kong; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, International Research Center for Intelligent Perception and Computation, Xidian University, Xi’an, China","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","6","2450","2463","This paper focuses on the connecting structure of deep neural networks and proposes a layerwise structure learning method based on multiobjective optimization. A model with better generalization can be obtained by reducing the connecting parameters in deep networks. The aim is to find the optimal structure with high representation ability and better generalization for each layer. Then, the visible data are modeled with respect to structure based on the products of experts. In order to mitigate the difficulty of estimating the denominator in PoE, the denominator is simplified and taken as another objective, i.e., the connecting sparsity. Moreover, for the consideration of the contradictory nature between the representation ability and the network connecting sparsity, the multiobjective model is established. An improved multiobjective evolutionary algorithm is used to solve this model. Two tricks are designed to decrease the computational cost according to the properties of input data. The experiments on single-layer level, hierarchical level, and application level demonstrate the effectiveness of the proposed algorithm, and the learned structures can improve the performance of deep neural networks.","","","10.1109/TNNLS.2017.2695223","National Natural Science Foundation of China; National Program for Support of Top-Notch Young Professionals of China; Specialized Research Fund for the Doctoral Program of Higher Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920404","Connecting structure;deep neural networks;evolutionary algorithm (EA);multiobjective optimization","Joining processes;Biological neural networks;Computational modeling;Pareto optimization;Computer architecture","evolutionary computation;learning (artificial intelligence);network theory (graphs);neural nets;optimisation","high representation ability;network connecting sparsity;multiobjective model;improved multiobjective evolutionary algorithm;learned structures;deep neural networks;multiobjective optimization;connecting structure;layerwise structure learning method;connecting parameters;optimal structure;PoE;computational cost","","6","61","","","","","IEEE","IEEE Journals"
"Learning Depth From Single Images With Deep Neural Network Embedding Focal Length","L. He; G. Wang; Z. Hu","University of Chinese Academy of Sciences, Beijing, China; Department of Electrical Engineering and Computer Science, University of Kansas, Lawrence, KS, USA; University of Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Image Processing","","2018","27","9","4676","4689","Learning depth from a single image, as an important issue in scene understanding, has attracted a lot of attention in the past decade. The accuracy of the depth estimation has been improved from conditional Markov random fields, non-parametric methods, to deep convolutional neural networks most recently. However, there exist inherent ambiguities in recovering 3D from a single 2D image. In this paper, we first prove the ambiguity between the focal length and monocular depth learning and verify the result using experiments, showing that the focal length has a great influence on accurate depth recovery. In order to learn monocular depth by embedding the focal length, we propose a method to generate synthetic varying-focal-length data set from fixed-focal-length data sets, and a simple and effective method is implemented to fill the holes in the newly generated images. For the sake of accurate depth recovery, we propose a novel deep neural network to infer depth through effectively fusing the middle-level information on the fixed-focal-length data set, which outperforms the state-of-the-art methods built on pre-trained VGG. Furthermore, the newly generated varying-focal-length data set is taken as input to the proposed network in both learning and inference phases. Extensive experiments on the fixed- and varying-focal-length data sets demonstrate that the learned monocular depth with embedded focal length is significantly improved compared to that without embedding the focal length information.","","","10.1109/TIP.2018.2832296","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8360460","Depth learning;single images;inherent ambiguity;focal length","Estimation;Convolutional neural networks;Biological neural networks;Machine learning;Cameras;Data mining","image processing;learning (artificial intelligence);Markov processes;neural nets","deep neural network embedding focal length;depth estimation;conditional Markov random fields;nonparametric methods;deep convolutional neural networks;single 2D image;monocular depth learning;accurate depth recovery;synthetic varying-focal-length data;fixed-focal-length data set;newly generated varying-focal-length data set;inference phases;fixed- varying-focal-length data sets;learned monocular depth;embedded focal length;focal length information;pretrained VGG","","9","59","","","","","IEEE","IEEE Journals"
"A Novel Technique Based on Deep Learning and a Synthetic Target Database for Classification of Urban Areas in PolSAR Data","S. De; L. Bruzzone; A. Bhattacharya; F. Bovolo; S. Chaudhuri","Centre of Studies in Resources Engineering, Indian Institute of Technology Bombay, Mumbai, India; Department of Information Engineering and Computer Science, University of Trento, Trento, Italy; Centre of Studies in Resources Engineering, Indian Institute of Technology Bombay, Mumbai, India; Center for Information and Communication Technology, Fondazione Bruno Kessler, Trento, Italy; Department of Electrical Engineering, Indian Institute of Technology Bombay, Mumbai, India","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2018","11","1","154","170","The classification of urban areas in polarimetric synthetic aperture radar (PolSAR) data is a challenging task. Moreover, urban structures oriented away from the radar line of sight pose an additional complexity in the classification process. The characterization of such areas is important for disaster relief and urban sprawl monitoring applications. In this paper, a novel technique based on deep learning is proposed, which leverages a synthetic target database for data augmentation. The PolSAR dataset is rotated by uniform steps and collated to form a reference database. A stacked autoencoder network is used to transform the information in the augmented dataset into a compact representation. This significantly improves the generalization capabilities of the network. Finally, the classification is performed by a multilayer perceptron network. The modular architecture allows for easy optimization of the hyperparameters. The synthetic target database is created and the classification performance is evaluated on an Lband airborne UAVSAR dataset and L-band space-borne ALOS-2 dataset acquired over San Francisco, USA. The proposed technique shows an overall accuracy of 91.3%. An improvement over state-of-the-art techniques is achieved, especially in urban areas rotated away from the radar line of sight.","","","10.1109/JSTARS.2017.2752282","Italian Ministries MAECI/MIUR; Advanced Research (ITPAR), Phase III; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8068203","Autoencoder (AE);classification;deep learning;deep neural networks;polarimetric synthetic aperture radar (PolSAR);representation learning;urban remote sensing","Urban areas;Synthetic aperture radar;Feature extraction;Machine learning;Neural networks;Scattering","radar imaging;radar interferometry;radar polarimetry;remote sensing by radar;synthetic aperture radar","synthetic target database;classification performance;urban areas;deep learning;PolSAR data;polarimetric synthetic aperture radar data;urban structures;augmented dataset;stacked autoencoder network;reference database;PolSAR dataset;data augmentation;urban sprawl monitoring applications;classification process","","13","67","","","","","IEEE","IEEE Journals"
"Residual-error prediction based on deep learning for lossless image compression","I. Schiopu; A. Munteanu","Vrije Universiteit Brussel, Belgium; Vrije Universiteit Brussel, Belgium","Electronics Letters","","2018","54","17","1032","1034","A novel residual-error prediction method based on deep learning with application in lossless image compression is introduced. The proposed method employs machine learning tools to minimise the residual error of the employed prediction tools. Experimental results demonstrate average bitrate savings of 32% over the state-of-the-art in lossless image compression. To the best of the authors' knowledge, this Letter is the first to propose a deep-learning based method for residual-error prediction.","","","10.1049/el.2018.0889","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8434545","","","data compression;image coding;learning (artificial intelligence);minimisation","residual-error prediction method;deep-learning based method;lossless image compression;machine learning tools;residual error minimisation;employed prediction tools;bitrate savings","","1","","","","","","IET","IET Journals"
"Hyperspectral Image Classification With Deep Learning Models","X. Yang; Y. Ye; X. Li; R. Y. K. Lau; X. Zhang; X. Huang","Shenzhen Graduate School, Harbin Institute of Technology, Shenzhen, China; Shenzhen Graduate School, Harbin Institute of Technology, Shenzhen, China; Shenzhen Graduate School, Harbin Institute of Technology, Shenzhen, China; City University of Hong Kong, Hong Kong; Shenzhen Graduate School, Harbin Institute of Technology, Shenzhen, China; School of Information Engineering, East China Jiaotong University, Nanchang, China","IEEE Transactions on Geoscience and Remote Sensing","","2018","56","9","5408","5423","Deep learning has achieved great successes in conventional computer vision tasks. In this paper, we exploit deep learning techniques to address the hyperspectral image classification problem. In contrast to conventional computer vision tasks that only examine the spatial context, our proposed method can exploit both spatial context and spectral correlation to enhance hyperspectral image classification. In particular, we advocate four new deep learning models, namely, 2-D convolutional neural network (2-D-CNN), 3-D-CNN, recurrent 2-D CNN (R-2-D-CNN), and recurrent 3-D-CNN (R-3-D-CNN) for hyperspectral image classification. We conducted rigorous experiments based on six publicly available data sets. Through a comparative evaluation with other state-of-the-art methods, our experimental results confirm the superiority of the proposed deep learning models, especially the R-3-D-CNN and the R-2-D-CNN deep learning models.","","","10.1109/TGRS.2018.2815613","Shenzhen Science and Technology Program; RGC of the Hong Kong SAR; National Natural Science Foundation of China; Shenzhen Municipal Science and Technology Innovation Fund; CityU Shenzhen Research Institute; National Natural Science Foundation of China; Education Department of Jiangxi Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8340197","Convolutional neural network (CNN);deep learning;hyperspectral image","Hyperspectral imaging;Machine learning;Kernel;Context modeling;Convolution;Task analysis","computer vision;convolution;feedforward neural nets;image classification;learning (artificial intelligence)","conventional computer vision tasks;spatial context;2-D convolutional neural network;R-3-D-CNN;deep learning techniques;hyperspectral image classification problem;recurrent 2-D CNN;recurrent 3-D-CNN;R-2-D-CNN","","9","43","","","","","IEEE","IEEE Journals"
"Collaborative Random Faces-Guided Encoders for Pose-Invariant Face Representation Learning","M. Shao; Y. Zhang; Y. Fu","Department of Computer and Information Science, University of Massachusetts Dartmouth, Dartmouth, MA, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Electrical and Computer Engineering, College of the Computer and Information Science, Northeastern University, Boston, MA, USA","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","4","1019","1032","Learning discriminant face representation for pose-invariant face recognition has been identified as a critical issue in visual learning systems. The challenge lies in the drastic changes of facial appearances between the test face and the registered face. To that end, we propose a high-level feature learning framework called “collaborative random faces (RFs)-guided encoders” toward this problem. The contributions of this paper are three fold. First, we propose a novel supervised autoencoder that is able to capture the high-level identity feature despite of pose variations. Second, we enrich the identity features by replacing the target values of conventional autoencoders with random signals (RFs in this paper), which are unique for each subject under different poses. Third, we further improve the performance of the framework by incorporating deep convolutional neural network facial descriptors and linking discriminative identity features from different RFs for the augmented identity features. Finally, we conduct face identification experiments on Multi-PIE database, and face verification experiments on labeled faces in the wild and YouTube Face databases, where face recognition rate and verification accuracy with Receiver Operating Characteristic curves are rendered. In addition, discussions of model parameters and connections with the existing methods are provided. These experiments demonstrate that our learning system works fairly well on handling pose variations.","","","10.1109/TNNLS.2017.2648122","NSF IIS; NSF CNS; ONR; ONR Young Investigator; U.S. Army Research Office Young Investigator; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7839179","Collaborative encoders;discriminant feature learning;face representation learning;pose-invariant feature;random faces (RFs)","Face;Learning systems;Radio frequency;Face recognition;Collaboration;Solid modeling;Facial features","face recognition;feature extraction;feedforward neural nets;image coding;image representation;learning (artificial intelligence);pose estimation","verification accuracy;pose variations;discriminant face representation;pose-invariant face recognition;visual learning systems;registered face;high-level feature learning framework;high-level identity feature;random signals;deep convolutional neural network facial descriptors;augmented identity features;face identification experiments;face verification experiments;labeled faces;wild YouTube Face databases;face recognition rate;collaborative random face-guided encoders;pose-invariant face representation learning;facial appearances;discriminative identity features;RF","","1","73","","","","","IEEE","IEEE Journals"
"Improving Periocular Recognition by Explicit Attention to Critical Regions in Deep Neural Network","Z. Zhao; A. Kumar","Department of Computing, The Hong Kong Polytechnic University, Kowloon, Hong Kong; Department of Computing, The Hong Kong Polytechnic University, Kowloon, Hong Kong","IEEE Transactions on Information Forensics and Security","","2018","13","12","2937","2952","Periocular recognition has been emerging as an effective biometric identification approach, especially under less constrained environments where face and/or iris recognition is not applicable. This paper proposes a new deep learning-based architecture for robust and more accurate periocular recognition which incorporates attention model to emphasize important regions in the periocular images. The new architecture adopts multi-glance mechanism, in which part of the intermediate components are configured to incorporate emphasis on important semantical regions, i.e., eyebrow and eye, within a periocular image. By focusing on these regions, the deep convolutional neural network is able to learn additional discriminative features, which in turn improves the recognition capability of the whole model. The superior performance of our method strongly suggests that eyebrow and eye regions are important for periocular recognition, and deserve special attention during the deep feature learning process. This paper also presents a customized verification-oriented loss function, which is shown to provide higher discriminating power than conventional contrastive/triplet loss functions. Extensive experiments on six publicly available databases are performed to evaluate the proposed approach. The reproducible experimental results indicate that our approach significantly outperforms several state-of-the-art methods for the periocular recognition.","","","10.1109/TIFS.2018.2833018","General Research Fund from the Hong Kong Research Grant Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8353874","Periocular recognition;deep learning;attention model;region of interest","Convolution;Iris recognition;Machine learning;Eyebrows;Feature extraction;Visualization;Training","feature extraction;image recognition;learning (artificial intelligence);neural net architecture","robust recognition;periocular image;deep convolutional neural network;recognition capability;eyebrow;eye regions;deep feature learning process;effective biometric identification approach;periocular image recognition;deep learning-based architecture;attention model;multiglance mechanism;discriminative features;customized verification-oriented loss function;contrastive-triplet loss functions","","4","48","","","","","IEEE","IEEE Journals"
"Semi-Supervised Deep Blind Compressed Sensing for Analysis and Reconstruction of Biomedical Signals From Compressive Measurements","V. Singhal; A. Majumdar; R. K. Ward","Department of Computer Science and Engineering, Indraprastha Institute of Information Technology, New Delhi, India; Department of Electronics and Communication Engineering, Indraprastha Institute of Information Technology, New Delhi, India; Department of Electrical and Computer Engineering, The University of British Columbia, Vancouver, BC, Canada","IEEE Access","","2018","6","","545","553","In this paper, the objective is to classify biomedical signals from their compressive measurements. The problem arises when compressed sensing (CS) is used for energy efficient acquisition and transmission of such signals for wireless body area network. After reconstruction, the signal is analyzed via certain machine learning techniques. This paper proposes to carry out joint reconstruction and analysis in a single framework; the reconstruction ability is obtained inherently from our formulation. We put forth a new technique called semi-supervised deep blind CS that combines the analytic power of deep learning with the reconstruction ability of CS. Experimental results on EEG classification show that the proposed technique excels over the state-of-the-art paradigm of CS reconstruction followed by deep learning classification.","","","10.1109/ACCESS.2017.2771536","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8219376","Classification;compressed sensing;deep learning;EEG;reconstruction","Compressed sensing;Machine learning;Dictionaries;Sparse matrices;Biomedical measurement;Energy efficiency;Wireless communication","body area networks;compressed sensing;electroencephalography;learning (artificial intelligence);medical signal processing;signal classification;signal reconstruction;wireless sensor networks","compressive measurements;energy efficient acquisition;wireless body area network;machine learning techniques;joint reconstruction;semisupervised deep blind CS;CS reconstruction;deep learning classification;semisupervised deep blind compressed sensing;signal transmission;biomedical signal analysis;biomedical signal reconstruction;EEG classification","","5","39","","","","","IEEE","IEEE Journals"
"Deep Learning for Fusion of APEX Hyperspectral and Full-Waveform LiDAR Remote Sensing Data for Tree Species Mapping","W. Liao; F. Van Coillie; L. Gao; L. Li; B. Zhang; J. Chanussot","Department of Telecommunications and Information Processing, IMEC–Ghent University, Ghent, Belgium; Department of Forest and Water Management, Ghent University, Ghent, Belgium; Key Laboratory of Digital Earth Science, Institute of Remote Sensing and Digital Earth, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Digital Earth Science, Institute of Remote Sensing and Digital Earth, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Digital Earth Science, Institute of Remote Sensing and Digital Earth, Chinese Academy of Sciences, Beijing, China; CNRS, Grenoble Images Speech Signals and Automatics Laboratory, University of Grenoble Alpes, Grenoble, France","IEEE Access","","2018","6","","68716","68729","Deep learning has been widely used to fuse multi-sensor data for classification. However, current deep learning architecture for multi-sensor data fusion might not always perform better than single data source, especially for the fusion of hyperspectral and light detection and ranging (LiDAR) remote sensing data for tree species mapping in complex, closed forest canopies. In this paper, we propose a new deep fusion framework to integrate the complementary information from hyperspectral and LiDAR data for tree species mapping. We also investigate the fusion of either “single-band"" or multi-band (i.e., fullwaveform) LiDAR with hyperspectral data for tree species mapping. Additionally, we provide a solution to estimate the crown size of tree species by the fusion of multi-sensor data. Experimental results on fusing real APEX hyperspectral and LiDAR data demonstrate the effectiveness of the proposed deep fusion framework. Compared to using only single data source or current deep fusion architecture, our proposed method yields improvements in overall and average classification accuracies ranging from 82.21% to 87.10% and 76.71% to 83.45%, respectively.","","","10.1109/ACCESS.2018.2880083","National Natural Science Foundation of China; Fonds Wetenschappelijk Onderzoek; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8529194","Deep learning;remote sensing;data fusion;hyperspectral;LiDAR","Laser radar;Vegetation;Hyperspectral imaging;Feature extraction;Forestry","forestry;geophysical image processing;hyperspectral imaging;image classification;image fusion;learning (artificial intelligence);optical radar;remote sensing;remote sensing by laser beam;sensor fusion","APEX hyperspectral;full-waveform LiDAR remote sensing data;tree species mapping;multisensor data fusion;single data source;hyperspectral detection;light detection;deep fusion framework;hyperspectral data;LiDAR data;deep fusion architecture;deep learning architecture","","2","58","","","","","IEEE","IEEE Journals"
"Performance Analysis of Google Colaboratory as a Tool for Accelerating Deep Learning Applications","T. Carneiro; R. V. Medeiros Da NóBrega; T. Nepomuceno; G. Bian; V. H. C. De Albuquerque; P. P. R. Filho","Ciência e Tecnologia do Ceará, Instituto Federal de Educação, Fortaleza-CE, Brazil; Ciência e Tecnologia do Ceará, Instituto Federal de Educação, Fortaleza-CE, Brazil; Fraunhofer-Arbeitsgruppe für Supply Chain Services SCS, Nürnberg, Germany; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Programa de Pós-Graduação em Informática Aplicada, Universidade de Fortaleza, Fortaleza-CE, Brazil; Ciência e Tecnologia do Ceará, Instituto Federal de Educação, Fortaleza-CE, Brazil","IEEE Access","","2018","6","","61677","61685","Google Colaboratory (also known as Colab) is a cloud service based on Jupyter Notebooks for disseminating machine learning education and research. It provides a runtime fully configured for deep learning and free-of-charge access to a robust GPU. This paper presents a detailed analysis of Colaboratory regarding hardware resources, performance, and limitations. This analysis is performed through the use of Colaboratory for accelerating deep learning for computer vision and other GPU-centric applications. The chosen test-cases are a parallel tree-based combinatorial search and two computer vision applications: object detection/classification and object localization/segmentation. The hardware under the accelerated runtime is compared with a mainstream workstation and a robust Linux server equipped with 20 physical cores. Results show that the performance reached using this cloud service is equivalent to the performance of the dedicated testbeds, given similar resources. Thus, this service can be effectively exploited to accelerate not only deep learning but also other classes of GPU-centric applications. For instance, it is faster to train a CNN on Colaboratory's accelerated runtime than using 20 physical cores of a Linux server. The performance of the GPU made available by Colaboratory may be enough for several profiles of researchers and students. However, these free-of-charge hardware resources are far from enough to solve demanding real-world problems and are not scalable. The most significant limitation found is the lack of CPU cores. Finally, several strengths and limitations of this cloud service are discussed, which might be useful for helping potential users.","","","10.1109/ACCESS.2018.2874767","Youth Innovation Promotion Association of the Chinese Academy of Sciences; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8485684","Deep learning;Colab;convolutional neural networks;Google colaboratory;GPU computing","Google;Machine learning;Hardware;Graphics processing units;Acceleration;Runtime;Computer vision","cloud computing;computer vision;graphics processing units;grid computing;Internet;learning (artificial intelligence);Linux;security of data;trees (mathematics)","deep learning applications;Google Colaboratory;cloud service;free-of-charge access;robust GPU;GPU-centric applications;parallel tree-based combinatorial search;computer vision applications;detection/classification;robust Linux server;free-of-charge hardware resources;performance analysis;object localization-segmentation","","4","22","CCBY","","","","IEEE","IEEE Journals"
"Dictionary Learning With Low Computational Complexity for Classification of Human Micro-Dopplers Across Multiple Carrier Frequencies","S. Vishwakarma; S. S. Ram","Indraprastha Institute of Information Technology, Delhi, New Delhi, India; Indraprastha Institute of Information Technology, Delhi, New Delhi, India","IEEE Access","","2018","6","","29793","29805","Recently, several machine learning algorithms have been applied for classifying micro-Doppler signatures from different human motions. However, these algorithms must demonstrate versatility in handling diversity in test and training data to be used for real-life scenarios. For example, situations may arise where the propagation channel or the presence of interference sources in the test site will permit only specific frequency bands of radar operation. These bands may differ from those used previously while training. In this paper, we examine the performances of three sparsity driven dictionary learning algorithms-synthesis, deep, and analysis-for learning unique features extracted from training data gathered across multiple carrier frequencies. These features are subsequently used for classifying test data from another distinct carrier frequency. Our experimental results, from measurement data, show that the dictionary learning algorithms are capable of extracting meaningful representations of the micro-Dopplers despite the rich frequency diversity in the data. In particular, the deep dictionary learning algorithm yields a high classification accuracy of 91% with a very low computational time for testing.","","","10.1109/ACCESS.2018.2843391","Department of Science and Technology, Government of India; DST Inspire Fellowship; Air Force Office of Scientific Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8375093","Radar;micro-Dopplers;sparse coding;synthesis dictionary learning;deep learning;analysis dictionary learning;classification","Machine learning;Dictionaries;Radar;Training;Feature extraction;Classification algorithms;Training data","computational complexity;Doppler radar;feature extraction;image classification;learning (artificial intelligence)","different human motions;real-life scenarios;propagation channel;interference sources;specific frequency bands;radar operation;multiple carrier frequencies;distinct carrier frequency;measurement data;dictionary learning algorithms;rich frequency diversity;deep dictionary;human microDopplers;machine learning algorithms;microDoppler signatures;features extraction;computational complexity;computational time","","2","60","","","","","IEEE","IEEE Journals"
"Deep Residual Networks With Dynamically Weighted Wavelet Coefficients for Fault Diagnosis of Planetary Gearboxes","M. Zhao; M. Kang; B. Tang; M. Pecht","State Key Laboratory of Mechanical Transmission, Chongqing University, Chongqing, China; Center for Advanced Life Cycle Engineering, University of Maryland, College Park, MD, USA; State Key Laboratory of Mechanical Transmission, Chongqing University, Chongqing, China; Center for Advanced Life Cycle Engineering, University of Maryland, College Park, MD, USA","IEEE Transactions on Industrial Electronics","","2018","65","5","4290","4300","One of the significant tasks in data-driven fault diagnosis methods is to configure a good feature set involving statistical parameters. However, statistical parameters are often incapable of representing the dynamic behavior of planetary gearboxes under variable operating conditions. Although the use of deep learning algorithms to find a good set of features for fault diagnosis has somewhat improved diagnostic performance, the lack of domain knowledge incorporated into deep learning algorithms has limited further improvement. Accordingly, this paper developed a variant of deep residual networks (DRNs), the so-called deep residual networks with dynamically weighted wavelet coefficients (DRN+DWWC) to improve diagnostic performance, which takes a series of sets of wavelet packet coefficients on various frequency bands as an input. Further, the fact that no general consensus has been reached as to which frequency band contains the most intrinsic information about a planetary gearbox's health status calls for “dynamic weighting layers” in the DRN+DWWC and the role of the layers is to dynamically adjust a weight applied to each set of wavelet packet coefficients to find a discriminative set of features that will be further used for planetary gearbox fault diagnosis.","","","10.1109/TIE.2017.2762639","Technology Innovation Program; Development of Vehicle Self Diagnosis System and Service for Automobile Driving Safety Improvement; Ministry of Trade, Industry and Energy, Korea; National Natural Science Foundation of China; China Scholarship Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8066359","Deep residual learning;fault diagnosis;feature learning;planetary gearbox;wavelet packet transform","Fault diagnosis;Vibrations;Machine learning;Wavelet packets;Gears;Training","fault diagnosis;gears;learning (artificial intelligence);mechanical engineering computing;statistical analysis;wavelet transforms","deep residual networks;dynamically weighted wavelet coefficients;planetary gearboxes;data-driven fault diagnosis methods;statistical parameters;deep learning algorithms;DRN+DWWC;wavelet packet coefficients;dynamic weighting layers;planetary gearbox fault diagnosis","","21","27","","","","","IEEE","IEEE Journals"
"Jointly Learning Deep Features, Deformable Parts, Occlusion and Classification for Pedestrian Detection","W. Ouyang; H. Zhou; H. Li; Q. Li; J. Yan; X. Wang","School of Electrical and Information Engineering, University of Sydney, Camperdown, NSW, Australia; Department of Electronic Engineering, the Chinese University of Hong KongHong Kong; Department of Electronic Engineering, the Chinese University of Hong KongHong Kong; Department of Electronic Engineering, the Chinese University of Hong KongHong Kong; SenseTime Group Limited, Shatin, Hong Kong; Department of Electronic Engineering, the Chinese University of Hong KongHong Kong","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","8","1874","1887","Feature extraction, deformation handling, occlusion handling, and classification are four important components in pedestrian detection. Existing methods learn or design these components either individually or sequentially. The interaction among these components is not yet well explored. This paper proposes that they should be jointly learned in order to maximize their strengths through cooperation. We formulate these four components into a joint deep learning framework and propose a new deep network architecture (Code available on www.ee.cuhk.edu.hk/wlouyang/projects/ouyangWiccv13Joint/index.html). By establishing automatic, mutual interaction among components, the deep model has average miss rate 8.57 percent/11.71 percent on the Caltech benchmark dataset with new/original annotations.","","","10.1109/TPAMI.2017.2738645","General Research Fund; Research Grants Council of Hong Kong; Hong Kong Innovation and Technology Support Programme; National Natural Science Foundation of China; PhD programs foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8008790","CNN;convolutional neural networks;object detection;deep learning;deep model","Feature extraction;Deformable models;Image edge detection;Support vector machines;Image color analysis;Pattern analysis","convolution;data mining;feature extraction;feedforward neural nets;image classification;learning (artificial intelligence);object detection;pedestrians;traffic engineering computing","joint deep learning framework;automatic interaction;mutual interaction;deformable parts;pedestrian detection;feature extraction;deformation handling;occlusion handling;deformable occlusion;deformable classification;average miss rate;Caltech benchmark dataset;convolutional neural net","","12","95","","","","","IEEE","IEEE Journals"
"SAR Image Classification via Deep Recurrent Encoding Neural Networks","J. Geng; H. Wang; J. Fan; X. Ma","School of Information and Communication Engineering, Dalian University of Technology, Dalian, China; School of Information and Communication Engineering, Dalian University of Technology, Dalian, China; Department of Ocean Remote Sensing, National Marine Environmental Monitoring Center, Dalian, China; School of Information and Communication Engineering, Dalian University of Technology, Dalian, China","IEEE Transactions on Geoscience and Remote Sensing","","2018","56","4","2255","2269","Synthetic aperture radar (SAR) image classification is a fundamental process for SAR image understanding and interpretation. With the advancement of imaging techniques, it permits to produce higher resolution SAR data and extend data amount. Therefore, intelligent algorithms for high-resolution SAR image classification are demanded. Inspired by deep learning technology, an end-to-end classification model from the original SAR image to final classification map is developed to automatically extract features and conduct classification, which is named deep recurrent encoding neural networks (DRENNs). In our proposed framework, a spatial feature learning network based on long-short-term memory (LSTM) is developed to extract contextual dependencies of SAR images, where 2-D image patches are transformed into 1-D sequences and imported into LSTM to learn the latent spatial correlations. After LSTM, nonnegative and Fisher constrained autoencoders (NFCAEs) are proposed to improve the discrimination of features and conduct final classification, where nonnegative constraint and Fisher constraint are developed in each autoencoder to restrict the training of the network. The whole DRENN not only combines the spatial feature learning power of LSTM but also utilizes the discriminative representation ability of our NFCAE to improve the classification performance. The experimental results tested on three SAR images demonstrate that the proposed DRENN is able to learn effective feature representations from SAR images and produce competitive classification accuracies to other related approaches.","","","10.1109/TGRS.2017.2777868","National Key Research and Development Program of China; National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; Foundation of High Resolution Special Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8233402","Deep learning;image classification;recurrent neural network (RNN);stacked autoencoders (SAEs);synthetic aperture radar (SAR) image","Feature extraction;Synthetic aperture radar;Logic gates;Artificial neural networks;Machine learning;Radar imaging","feature extraction;image classification;image coding;image representation;image resolution;learning (artificial intelligence);neural nets;radar imaging;synthetic aperture radar","deep recurrent encoding neural networks;synthetic aperture radar image classification;imaging techniques;high-resolution SAR image classification;deep learning technology;end-to-end classification model;spatial feature learning network;LSTM;SAR images;2-D image patches;spatial feature learning power;long-short-term memory;nonnegative and Fisher constrained autoencoders;discriminative representation ability;DRENN","","7","47","","","","","IEEE","IEEE Journals"
"Learning a River Network Extractor Using an Adaptive Loss Function","F. Isikdogan; A. Bovik; P. Passalacqua","University of Texas at Austin, Austin, TX, USA; University of Texas at Austin, Austin, TX, USA; University of Texas at Austin, Austin, TX, USA","IEEE Geoscience and Remote Sensing Letters","","2018","15","6","813","817","We have created a deep-learning-based river network extraction model, called DeepRiver, that learns the characteristics of rivers from synthetic data and generalizes them to natural data. To train this model, we created a very large database of exemplary synthetic local channel segments, including channel intersections. Our model uses a special loss function that automatically shifts the focus to the hardest-to-learn parts of an input image. This adaptive loss function makes it possible to learn to detect river centerlines, including the centerlines at junctions and bifurcations. DeepRiver learns to separate between rivers and oceans, and therefore, it is able to reliably extract rivers in coastal regions. The model produces maps of river centerlines, which have the potential to be quite useful for analyzing the properties of river networks.","","","10.1109/LGRS.2018.2811754","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8319927","Coastal systems;convolutional neural networks;deep learning;river network extraction","Rivers;Adaptation models;Remote sensing;Indexes;Training;Oceans;Computational modeling","feature extraction;geophysical image processing;hydrological techniques;learning (artificial intelligence);neural nets;remote sensing;rivers","adaptive loss function;river centerlines;river network extractor;channel intersections;DeepRiver;deep-learning-based river network extraction model;bifurcations;oceans","","","16","","","","","IEEE","IEEE Journals"
"When Deep Learning Meets Inter-Datacenter Optical Network Management: Advantages and Vulnerabilities","J. Guo; Z. Zhu","School of Information Science and Technology, University of Science and Technology of China, Hefei, China; School of Information Science and Technology, University of Science and Technology of China, Hefei, China","Journal of Lightwave Technology","","2018","36","20","4761","4773","To realize cost-effective and adaptive network control and management (NC&M) on inter-datacenter optical networks (IDCONs), people have considered network virtualization to let the operator of an IDCON work as an infrastructure provider (InP), which can create virtual optical networks (VONs) over the IDCON for tenants. In this paper, we use this network scenario as the background, and try to integrate deep learning (DL) based traffic prediction in the NC&M of the IDCON and the VONs created over it. We first design the service provisioning framework in which each tenant uses a DL module to predict the traffic in its VON and will submit a VON reconfiguration request to the InP, when it sees a significant mismatch between future traffic and the allocated resources in its VON. Then, the InP will invoke the VON reconfiguration to make the VON be better prepared for future traffic. An adaptive and scalable DL-based traffic predictor is proposed together with a cognitive service provisioning algorithm to exploit the temporal and spatial characteristics of interDC traffic and achieve effective service provisioning based on precise and timely traffic prediction. Next, we consider the situation where a tenant leverages “machine-learning-as-a-service” and outsources the training of its DL module to a third-party entity for overcoming its resource limitations, and analyze the induced vulnerabilities due to data poisoning. Our simulation results indicate that with our proposal, the InP can invoke VON reconfigurations timely and improve the service provisioning performance of each VON significantly. Meanwhile, the results also demonstrate that our data poisoning scheme can easily bypass the normal validation of the DL module and generate significant adversarial effects.","","","10.1109/JLT.2018.2864676","National Natural Science Foundation of China; Chinese Academy of Sciences Key Project; NGBWMCN Key Project; China Postdoctoral Science Foundation; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8430520","Datacenters (DCs);data poisoning;deep learning;elastic optical networks (EONs);traffic prediction;virtual optical networks (VONs);virtual network reconfiguration","Indium phosphide;III-V semiconductor materials;Optical fiber networks;Training;Virtualization;Machine learning;Prediction algorithms","computer centres;computer network management;learning (artificial intelligence);optical fibre networks;telecommunication traffic","adaptive network control;inter-datacenter optical networks;network virtualization;virtual optical networks;service provisioning framework;adaptive DL-based traffic predictor;scalable DL-based traffic predictor;cognitive service provisioning algorithm;machine-learning-as-a-service;service provisioning performance;deep learning;inter-datacenter optical network management","","8","46","","","","","IEEE","IEEE Journals"
"Deep Reinforcement Learning for Dynamic Multichannel Access in Wireless Networks","S. Wang; H. Liu; P. H. Gomes; B. Krishnamachari","Ming Hsieh Department of Electrical Engineering, University of Southern California, Los Angeles, CA, USA; Department of Computer Science, University of Southern California, Los Angeles, CA, USA; Ming Hsieh Department of Electrical Engineering, University of Southern California, Los Angeles, CA, USA; Ming Hsieh Department of Electrical Engineering, University of Southern California, Los Angeles, CA, USA","IEEE Transactions on Cognitive Communications and Networking","","2018","4","2","257","265","We consider a dynamic multichannel access problem, where multiple correlated channels follow an unknown joint Markov model and users select the channel to transmit data. The objective is to find a policy that maximizes the expected long-term number of successful transmissions. The problem is formulated as a partially observable Markov decision process with unknown system dynamics. To overcome the challenges of unknown dynamics and prohibitive computation, we apply the concept of reinforcement learning and implement a deep Q-network (DQN). We first study the optimal policy for fixedpattern channel switching with known system dynamics and show through simulations that DQN can achieve the same optimal performance without knowing the system statistics. We then compare the performance of DQN with a Myopic policy and a Whittle Index-based heuristic through both more general simulations as well as real data trace and show that DQN achieves near-optimal performance in more complex situations. Finally, we propose an adaptive DQN approach with the capability to adapt its learning in time-varying scenarios.","","","10.1109/TCCN.2018.2809722","Defense Advanced Research Projects Agency (DARPA); NSF; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8303773","Multichannel access;cognitive sensing;POMDP;DQN;reinforcement learning;online learning","Indexes;Sensors;Markov processes;System dynamics;Adaptation models;Machine learning;Wireless networks","decision theory;learning (artificial intelligence);Markov processes;radio networks;telecommunication computing;wireless channels","deep Q-network;Myopic policy;near-optimal performance;adaptive DQN approach;deep reinforcement learning;wireless networks;dynamic multichannel access problem;multiple correlated channels;partially observable Markov decision process;unknown system dynamics;unknown joint Markov model;DQN;fixedpattern channel switching;Whittle Index-based heuristic","","47","27","","","","","IEEE","IEEE Journals"
"Frankenstein: Learning Deep Face Representations Using Small Data","G. Hu; X. Peng; Y. Yang; T. M. Hospedales; J. Verbeek","CNRS, Grenoble INP, LJK, Université Grenoble Alpes, Inria, Grenoble, France; Hengyang Normal University, Hengyang, China; Electronic Engineering and Computer Science, Queen Mary University of London, London, U.K.; The University of Edinburgh, Edinburgh, U.K.; CNRS, Grenoble INP, LJK, Université Grenoble Alpes, Inria, Grenoble, France","IEEE Transactions on Image Processing","","2018","27","1","293","303","Deep convolutional neural networks have recently proven extremely effective for difficult face recognition problems in uncontrolled settings. To train such networks, very large training sets are needed with millions of labeled images. For some applications, such as near-infrared (NIR) face recognition, such large training data sets are not publicly available and difficult to collect. In this paper, we propose a method to generate very large training data sets of synthetic images by compositing real face images in a given data set. We show that this method enables to learn models from as few as 10 000 training images, which perform on par with models trained from 500 000 images. Using our approach, we also obtain state-of-the-art results on the CASIA NIR-VIS2.0 heterogeneous face recognition data set.","","","10.1109/TIP.2017.2756450","European Unions Horizon 2020 Research and Innovation Program; Science and Technology Plan Project of Hunan Province; Natural Science Foundation of China; French research agency contracts; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8049355","Face recognition;deep learning;small training data","Face;Face recognition;Training;Three-dimensional displays;Machine learning;Nose;Mouth","data analysis;face recognition;image representation;learning (artificial intelligence);neural nets","small data;learning deep face representations;CASIA NIR-VIS2.0 heterogeneous face recognition data set;very large training data sets;real face images;deep convolutional neural networks;training images;synthetic images;near-infrared face recognition;labeled images;uncontrolled settings","","11","68","","","","","IEEE","IEEE Journals"
"Can Deep Networks Learn to Play by the Rules? A Case Study on Nine Men's Morris","F. Chesani; A. Galassi; M. Lippi; P. Mello","Department of Computer Science and Engineering, University of Bologna, Bologna, Italy; Department of Computer Science and Engineering, University of Bologna, Bologna, Italy; Department of Sciences and Methods for Engineering, University of Modena and Reggio Emilia, Modena, Italy; Department of Computer Science and Engineering, University of Bologna, Bologna, Italy","IEEE Transactions on Games","","2018","10","4","344","353","Deep networks have been successfully applied to a wide range of tasks in artificial intelligence, and game playing is certainly not an exception. In this paper, we present an experimental study to assess whether purely subsymbolic systems, such as deep networks, are capable of learning to play by the rules, without any a priori knowledge neither of the game, nor of its rules, but only by observing the matches played by another player. Similar problems arise in many other application domains, where the goal is to learn rules, policies, behaviors, or decisions, simply by the observation of the dynamics of a system. We present a case study conducted with residual networks on the popular board game of Nine Men's Morris, showing that this kind of subsymbolic architecture is capable of correctly discriminating legal from illegal decisions, just from the observation of past matches of a single player.","","","10.1109/TG.2018.2804039","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8286908","Board games;deep learning; ${Nine Men's Morris}$ ;residual networks;rule learning","Games;Law;Neural networks;Machine learning;Cognition","computer games;learning (artificial intelligence);neural nets","Nine Men's Morris;artificial intelligence;game playing;residual networks;board game;deep networks;subsymbolic systems","","1","36","","","","","IEEE","IEEE Journals"
"Deep Convolutional Neural Networks and Learning ECG Features for Screening Paroxysmal Atrial Fibrillation Patients","B. Pourbabaee; M. J. Roshtkhari; K. Khorasani","Department of Electrical and Computer Engineering, Concordia University, Montreal, QC, Canada; SPORTLOGiQ, Montreal, QC, Canada; Department of Electrical and Computer Engineering, Concordia University, Montreal, QC, Canada","IEEE Transactions on Systems, Man, and Cybernetics: Systems","","2018","48","12","2095","2104","In this paper, a novel computationally intelligent-based electrocardiogram (ECG) signal classification methodology using a deep learning (DL) machine is developed. The focus is on patient screening and identifying patients with paroxysmal atrial fibrillation (PAF), which represents a life threatening cardiac arrhythmia. The proposed approach operates with a large volume of raw ECG time-series data as inputs to a deep convolutional neural networks (CNN). It autonomously learns representative and key features of the PAF to be used by a classification module. The features are therefore learned directly from the large time domain ECG signals by using a CNN with one fully connected layer. The learned features can effectively replace the traditional ad hoc and time-consuming user's hand-crafted features. Our experimental results verify and validate the effectiveness and capabilities of the learned features for PAF patient screening. The main advantages of our proposed approach are to simplify the feature extraction process corresponding to different cardiac arrhythmias and to remove the need for using a human expert to define appropriate and critical features working with a large time-series data set. The extensive simulations and case studies conducted indicate that combining the learned features with other classifiers will significantly improve the performance of the patient screening system as compared to an end-to-end CNN classifier. The effectiveness and capabilities of our proposed ECG DL classification machine is demonstrated and quantitative comparisons with several conventional machine learning classifiers are also provided.","","","10.1109/TSMC.2017.2705582","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7937819","Biomedical monitoring;deep convolution neural network;electrocardiogram (ECG);feature extraction;neural network architecture;paroxysmal atrial fibrillation (PAF)","Feature extraction;Electrocardiography;Convolution;Hidden Markov models;Neural networks;Monitoring;Medical services","convolution;electrocardiography;feature extraction;feedforward neural nets;learning (artificial intelligence);medical signal processing;signal classification;time series","deep convolutional neural networks;paroxysmal atrial fibrillation patients;deep learning machine;time domain ECG signals;PAF patient screening;patient screening system;ECG DL classification machine;electrocardiogram signal classification;ECG time-series data;feature extraction;ECG features learning;machine learning classifiers;cardiac arrhythmia","","19","36","","","","","IEEE","IEEE Journals"
"Enhancing the Image Quality via Transferred Deep Residual Learning of Coarse PET Sinograms","X. Hong; Y. Zan; F. Weng; W. Tao; Q. Peng; Q. Huang","School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, China; University of Michigan–Shanghai Jiao Tong University Joint Institute, Shanghai Jiao Tong University, Shanghai, China; School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, China; Lawrence Berkeley National Laboratory, Berkeley, CA, USA; School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, China","IEEE Transactions on Medical Imaging","","2018","37","10","2322","2332","Increasing the image quality of positron emission tomography (PET) is an essential topic in the PET community. For instance, thin-pixelated crystals have been used to provide high spatial resolution images but at the cost of sensitivity and manufacture expense. In this paper, we proposed an approach to enhance the PET image resolution and noise property for PET scanners with large pixelated crystals. To address the problem of coarse blurred sinograms with large parallax errors associated with large crystals, we developed a data-driven, single-image superresolution (SISR) method for sinograms, based on the novel deep residual convolutional neural network (CNN). Unlike the CNN-based SISR on natural images, periodically padded sinogram data and dedicated network architecture were used to make it more efficient for PET imaging. Moreover, we included the transfer learning scheme in the approach to process cases with poor labeling and small training data set. The approach was validated via analytically simulated data (with and without noise), Monte Carlo simulated data, and pre-clinical data. Using the proposed method, we could achieve comparable image resolution and better noise property with large crystals of bin sizes 4 × of thin crystals with a bin size from 1 × 1 mm2 to 1.6 × 1.6 mm2. Our approach uses external PET data as the prior knowledge for training and does not require additional information during inference. Meanwhile, the method can be added into the normal PET imaging framework seamlessly, thus potentially finds its application in designing low-cost high-performance PET systems.","","","10.1109/TMI.2018.2830381","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8349945","Positron emission tomography;super resolution;sinogram;deep residual learning;convolutional neural networks;transfer learning","Crystals;Image quality;Positron emission tomography;Spatial resolution;Image reconstruction","image resolution;learning (artificial intelligence);medical image processing;Monte Carlo methods;neural nets;positron emission tomography","image quality;transferred deep residual learning;coarse PET sinograms;positron emission tomography;PET community;thin-pixelated crystals;high spatial resolution images;PET image resolution;noise property;PET scanners;coarse blurred sinograms;single-image superresolution method;CNN-based SISR;Monte Carlo simulated data;normal PET imaging framework;low-cost high-performance PET systems;image resolution;deep residual convolutional neural network;periodically padded sinogram data","","2","48","","","","","IEEE","IEEE Journals"
"Estimation of Deterioration Levels of Transmission Towers via Deep Learning Maximizing Canonical Correlation Between Heterogeneous Features","K. Maeda; S. Takahashi; T. Ogawa; M. Haseyama","Graduate School of Information Science and Technology, Hokkaido University, Sapporo, Japan; Faculty of Engineering, Hokkaido University, Sapporo, Japan; Graduate School of Information Science and Technology, Hokkaido University, Sapporo, Japan; Graduate School of Information Science and Technology, Hokkaido University, Sapporo, Japan","IEEE Journal of Selected Topics in Signal Processing","","2018","12","4","633","644","This paper presents estimation of deterioration levels of transmission towers via deep learning maximizing the canonical correlation between heterogeneous features. In the proposed method, we newly construct a correlation-maximizing deep extreme learning machine (CMDELM) based on a local receptive field (LRF). For accurate deterioration level estimation, it is necessary to obtain semantic information that effectively represents deterioration levels. However, since the amount of training data for transmission towers is small, it is difficult to perform feature transformation by using many hidden layers such as general deep learning methods. In CMDELM-LRF, one hidden layer, which maximizes the canonical correlation between visual features and text features obtained from inspection text data, is newly inserted. Specifically, by using projections obtained by maximizing the canonical correlation as weight parameters of the hidden layer, feature transformation for extracting semantic information is realized without designing many hidden layers. This is the main contribution of this paper. Consequently, CMDELM-LRF realizes accurate deterioration level estimation from a small amount of training data.","","","10.1109/JSTSP.2018.2849593","JSPS KAKENHI; Global Station for Big Data and Cyber Security; Global Institution for Collaborative Research and Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8391700","Canonical correlation analysis;deep extreme learning machine;deterioration level estimation","Visualization;Correlation;Inspection;Poles and towers;Estimation;Feature extraction;Machine learning","data analysis;feature extraction;learning (artificial intelligence)","transmission towers;feature transformation;CMDELM-LRF;semantic information;training data;correlation-maximizing deep extreme learning machine;local receptive field;canonical correlation;deterioration level estimation;inspection text data","","2","52","","","","","IEEE","IEEE Journals"
"Research on Deep Learning Techniques in Breaking Text-Based Captchas and Designing Image-Based Captcha","M. Tang; H. Gao; Y. Zhang; Y. Liu; P. Zhang; P. Wang","Institute of Software Engineering, Xidian University, Xi’an, China; Institute of Software Engineering, Xidian University, Xi’an, China; Institute of Software Engineering, Xidian University, Xi’an, China; Institute of Software Engineering, Xidian University, Xi’an, China; Institute of Software Engineering, Xidian University, Xi’an, China; Institute of Software Engineering, Xidian University, Xi’an, China","IEEE Transactions on Information Forensics and Security","","2018","13","10","2522","2537","The ability of hackers to infiltrate computer systems using computer attack programs and bots led to the development of Captchas or Completely Automated Public Turing Tests to Tell Computers and Humans Apart. The text Captcha is the most popular Captcha scheme given its ease of construction and user friendliness. However, the next generation of hackers and programmers has decreased the expected security of these mechanisms, leaving websites open to attack. Text Captchas are still widely used, because it is believed that the attack speeds are slow, typically two to five seconds per image, and this is not seen as a critical threat. In this paper, we introduce a simple, generic, and fast attack on text Captchas that effectively challenges that supposition. With deep learning techniques, our attack demonstrates a high success rate in breaking the Roman-character-based text Captchas deployed by the top 50 most popular international websites and three Chinese Captchas that use a larger character set. These targeted schemes cover almost all existing resistance mechanisms, demonstrating that our attack techniques are also applicable to other existing Captchas. Does this work then spell the beginning of the end for text-based Captcha? We believe so. A novel image-based Captcha named Style Area Captcha (SACaptcha) is proposed in this paper, which is based on semantic information understanding, pixel-level segmentation, and deep learning techniques. Having demonstrated that text Captchas are no longer secure, we hope that our proposal shows promise in the development of image-based Captchas using deep learning techniques.","","","10.1109/TIFS.2018.2821096","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8327894","Captcha;text-based;security;deep learning;convolutional neural network;image-based","CAPTCHAs;Machine learning;Resistance;Image segmentation;Character recognition;Computer security","human computer interaction;image segmentation;invasive software;learning (artificial intelligence);text analysis;Web sites","deep learning techniques;computer attack programs;bots;text Captcha;popular Captcha scheme;Text Captchas;Chinese Captchas;existing Captchas;Style Area Captcha;Completely Automated Public Turing Tests;user friendliness;websites;SACaptcha","","4","60","","","","","IEEE","IEEE Journals"
"ELD-Net: An Efficient Deep Learning Architecture for Accurate Saliency Detection","G. Lee; Y. Tai; J. Kim","Daejeon, Korea; ShenZhen, China; Daejeon, Korea","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","7","1599","1610","Recent advances in saliency detection have utilized deep learning to obtain high-level features to detect salient regions in scenes. These advances have yielded results superior to those reported in past work, which involved the use of hand-crafted low-level features for saliency detection. In this paper, we propose ELD-Net, a unified deep learning framework for accurate and efficient saliency detection. We show that hand-crafted features can provide complementary information to enhance saliency detection that uses only high-level features. Our method uses both low-level and high-level features for saliency detection. High-level features are extracted using GoogLeNet, and low-level features evaluate the relative importance of a local region using its differences from other regions in an image. The two feature maps are independently encoded by the convolutional and the ReLU layers. The encoded low-level and high-level features are then combined by concatenation and convolution. Finally, a linear fully connected layer is used to evaluate the saliency of a queried region. A full resolution saliency map is obtained by querying the saliency of each local region of an image. Since the high-level features are encoded at low resolution, and the encoded high-level features can be reused for every query region, our ELD-Net is very fast. Our experiments show that our method outperforms state-of-the-art deep learning-based saliency detection methods.","","","10.1109/TPAMI.2017.2737631","National Research Foundation of Korea; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8006306","Salient region detection;feature extraction;superpixel;deep learning;convolutional neural network (CNN)","Feature extraction;Machine learning;Benchmark testing;Image color analysis;Image segmentation;Neural networks;Visualization","convolution;feature extraction;feedforward neural nets;image resolution;image retrieval;image segmentation;learning (artificial intelligence);object detection","ELD-Net;hand-crafted features;saliency detection methods;deep learning architecture;high-level features extraction;GoogLeNet;feature maps;convolutional layers;ReLU layers;concatenation;saliency query","","7","44","","","","","IEEE","IEEE Journals"
"A Case for Memory-Centric HPC System Architecture for Training Deep Neural Networks","Y. Kwon; M. Rhu","Pohang University of Science and Technology, Pohang, Gyeongsangbuk-do, South Korea; Pohang University of Science and Technology, Pohang, Gyeongsangbuk-do, South Korea","IEEE Computer Architecture Letters","","2018","17","2","134","138","As the models and the datasets to train deep learning (DL) models scale, system architects are faced with new challenges, one of which is the memory capacity bottleneck, where the limited physical memory inside the accelerator device constrains the algorithm that can be studied. We propose a memory-centric deep learning system that can transparently expand the memory capacity accessible to the accelerators while also providing fast inter-device communication for parallel training. Our proposal aggregates a pool of memory modules locally within the device-side interconnect, which are decoupled from the host interface and function as a vehicle for transparent memory capacity expansion. Compared to conventional systems, our proposal achieves an average 2:1× speedup on eight DL applications and increases the system-wide memory capacity to tens of TBs.","","","10.1109/LCA.2018.2823302","Samsung Research Funding Center of Samsung Electronics; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8331846","Computer architecture;system architecture;hardware acceleration;neural network;deep learning","Bandwidth;Machine learning;Performance evaluation;Virtualization;Graphics processing units;Systems architecture;Training","learning (artificial intelligence);memory architecture;neural nets;parallel processing;shared memory systems;storage management","memory modules;device-side interconnect;transparent memory capacity expansion;conventional systems;memory-centric HPC system architecture;training deep neural networks;deep learning models scale;system architects;memory capacity bottleneck;memory-centric deep learning system;fast inter-device communication;parallel training;system-wide memory capacity","","2","18","","","","","IEEE","IEEE Journals"
"DECCO: Deep-Learning Enabled Coverage and Capacity Optimization for Massive MIMO Systems","Y. Yang; Y. Li; K. Li; S. Zhao; R. Chen; J. Wang; S. Ci","Key Laboratory of Wireless Sensor Network and Communication, Shanghai Institute of Microsystem and Information Technology, Chinese Academy of Sciences, Shanghai, China; Key Laboratory of Wireless Sensor Network and Communication, Shanghai Institute of Microsystem and Information Technology, Chinese Academy of Sciences, Shanghai, China; Key Laboratory of Wireless Sensor Network and Communication, Shanghai Institute of Microsystem and Information Technology, Chinese Academy of Sciences, Shanghai, China; Key Laboratory of Wireless Sensor Network and Communication, Shanghai Institute of Microsystem and Information Technology, Chinese Academy of Sciences, Shanghai, China; State Key Laboratory of ISN, Xidian University, Xi’an, China; Department of Computer Science, University College London, London, U.K.; Department of Electrical and Computer Engineering, University of Nebraska–Lincoln, Lincoln, 68588, NE, USA","IEEE Access","","2018","6","","23361","23371","System capacity and service coverage are the most critical performance metrics in cellular wireless communication networks. Usually, system capacity enhancements are at the expense of service coverage degradations, and vice versa. This capacity-coverage tradeoff and the associated joint optimization problem becomes very challenging in massive multiple-input multiple-output (MIMO) wireless systems, due to a large amount of antenna tilt values to be configured and very sophisticated inter-cell interference conditions, under massive antenna scenarios. This paper proposes a novel approach, namely group alignment of user signal strength (GAUSS), to efficiently support the user scheduling for the massive MIMO system, and thus serve as an effective parameter for the coverage and capacity optimization (CCO) problem. Together with a unified threshold of Quality of Service, i.e. the minimum signal-to-interference-plus-noise ratio (SINRmin) for user satisfaction, GAUSS can effectively control the variance of signal strengths of multiple users in the neighborhood. Moreover, an intelligent and efficient deep-learning enabled coverage and capacity optimization (DECCO) algorithm is proposed and evaluated, which adopts a pre-trained deep policy gradient-based neural network to dynamically derive GAUSS and SINRmin during CCO. Furthermore, an inter-cell interference coordination (ICIC) is proposed to enhance the CCO performance. Analytical and simulation results show that the proposed DECCO algorithm can effectively achieve a much better performance balance between system capacity and service coverage than traditional fixed optimization (FO) and proportional fair optimization (PFO) algorithms. Specifically, DECCO significantly increases the overall spectrum efficiency by 24% and 40%, respectively, than FO and PFO in a typical massive MIMO system.","","","10.1109/ACCESS.2018.2828859","National Natural Science Foundation of China; National Science and Technology Major Project; Science and Technology Commission of Shanghai Municipality; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8344405","Coverage and capacity optimization;deep reinforcement learning;massive MIMO;user scheduling;inter-cell interference coordination","MIMO communication;Interference;Optimization;Scheduling;Signal to noise ratio;Precoding;Antennas","antenna arrays;cellular radio;gradient methods;learning (artificial intelligence);MIMO communication;neural nets;optimisation;quality of service;radiofrequency interference;telecommunication computing;telecommunication scheduling;wireless channels","pre-trained deep policy gradient-based neural network;quality of service;massive multiple input multiple output wireless systems;deep-learning enabled coverage and capacity optimization;intercell interference coordination;associated joint optimization problem;capacity-coverage tradeoff;service coverage degradations;system capacity enhancements;cellular wireless communication networks;capacity optimization;proportional fair optimization algorithms;DECCO;intelligent learning;multiple users;minimum signal-to-interference-plus-noise ratio;GAUSS;user signal strength;massive antenna scenarios","","7","20","","","","","IEEE","IEEE Journals"
"Deep Learning for Infrared Thermal Image Based Machine Health Monitoring","O. Janssens; R. Van de Walle; M. Loccufier; S. Van Hoecke","Ghent, Belgium; Ghent, Belgium; Zwijnaarde, Belgium; Ghent, Belgium","IEEE/ASME Transactions on Mechatronics","","2018","23","1","151","159","The condition of a machine can automatically be identified by creating and classifying features that summarize characteristics of measured signals. Currently, experts, in their respective fields, devise these features based on their knowledge. Hence, the performance and usefulness depends on the expert's knowledge of the underlying physics or statistics. Furthermore, if new and additional conditions should be detectable, experts have to implement new feature extraction methods. To mitigate the drawbacks of feature engineering, a method from the subfield of feature learning, i.e., deep learning (DL), more specifically convolutional neural networks (NNs), is researched in this paper. The objective of this paper is to investigate if and how DL can be applied to infrared thermal (IRT) video to automatically determine the condition of the machine. By applying this method on IRT data in two use cases, i.e., machine-fault detection and oil-level prediction, we show that the proposed system is able to detect many conditions in rotating machinery very accurately (i.e., 95 and 91.67% accuracy for the respective use cases), without requiring any detailed knowledge about the underlying physics, and thus having the potential to significantly simplify condition monitoring using complex sensor data. Furthermore, we show that by using the trained NNs, important regions in the IRT images can be identified related to specific conditions, which can potentially lead to new physical insights.","","","10.1109/TMECH.2017.2722479","Vlaamse innovatiesamenwerkingsverband Operations and Maintenance (VIS O&M) Excellence; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7967622","Fault detection;machine learning algorithms;neural networks;preventive maintenance","Feature extraction;Artificial neural networks;Condition monitoring;Machine learning algorithms;Vibrations;Machine learning","condition monitoring;fault diagnosis;feature extraction;infrared imaging;learning (artificial intelligence);machinery;mechanical engineering computing;neural nets","infrared thermal image;measured signals;respective fields;feature extraction methods;feature engineering;feature learning;deep learning;convolutional neural networks;infrared thermal video;IRT data;machine-fault detection;oil-level prediction;respective use cases;condition monitoring;IRT images;trained NN;feature classification;machine health monitoring","","8","25","","","","","IEEE","IEEE Journals"
"Deep Learning of Constrained Autoencoders for Enhanced Understanding of Data","B. O. Ayinde; J. M. Zurada","Department of Electrical and Computer Engineering, University of Louisville, Louisville, KY, USA; Department of Electrical and Computer Engineering, University of Louisville, Louisville, KY, USA","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","9","3969","3979","Unsupervised feature extractors are known to perform an efficient and discriminative representation of data. Insight into the mappings they perform and human ability to understand them, however, remain very limited. This is especially prominent when multilayer deep learning architectures are used. This paper demonstrates how to remove these bottlenecks within the architecture of non-negativity constrained autoencoder. It is shown that using both L1 and L2 regularizations that induce non-negativity of weights, most of the weights in the network become constrained to be non-negative, thereby resulting into a more understandable structure with minute deterioration in classification accuracy. Also, this proposed approach extracts features that are more sparse and produces additional output layer sparsification. The method is analyzed for accuracy and feature interpretation on the MNIST data, the NORB normalized uniform object data, and the Reuters text categorization data set.","","","10.1109/TNNLS.2017.2747861","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8051252","Deep learning (DL);part-based representation;receptive field;sparse autoencoder (SAE);white-box model","Computer architecture;Feature extraction;Encoding;Training;Decoding;Data mining;Data models","feature extraction;neural net architecture;pattern classification;text analysis;unsupervised learning","MNIST data;unsupervised feature extractors;mappings;multilayer deep learning architectures;nonnegativity constrained autoencoder;NORB;normalized uniform object data;Reuters text categorization data set;L2 regularization;L1 regularization;data understanding enhancement","","2","33","","","","","IEEE","IEEE Journals"
"Cost-Sensitive Learning of Deep Feature Representations From Imbalanced Data","S. H. Khan; M. Hayat; M. Bennamoun; F. A. Sohel; R. Togneri","Data61, Commonwealth Scientific and Industrial Research Organization, Canberra, ACT, Australia; Human-Centered Technology Research Centre, University of Canberra, Canberra, ACT, Australia; School of Computer Science and Software Engineering, The University of Western Australia, Crawley, WA, Australia; School of Engineering and Information Technology, Murdoch University, Perth, WA, Australia; School of Electrical, Electronic and Computer Engineering, The University of Western Australia, Crawley, WA, Australia","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","8","3573","3587","Class imbalance is a common problem in the case of real-world object detection and classification tasks. Data of some classes are abundant, making them an overrepresented majority, and data of other classes are scarce, making them an underrepresented minority. This imbalance makes it challenging for a classifier to appropriately learn the discriminating boundaries of the majority and minority classes. In this paper, we propose a cost-sensitive (CoSen) deep neural network, which can automatically learn robust feature representations for both the majority and minority classes. During training, our learning procedure jointly optimizes the class-dependent costs and the neural network parameters. The proposed approach is applicable to both binary and multiclass problems without any modification. Moreover, as opposed to data-level approaches, we do not alter the original data distribution, which results in a lower computational cost during the training process. We report the results of our experiments on six major image classification data sets and show that the proposed approach significantly outperforms the baseline algorithms. Comparisons with popular data sampling techniques and CoSen classifiers demonstrate the superior performance of our proposed method.","","","10.1109/TNNLS.2017.2732482","University of Western Australia; Australian Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8012579","Convolutional neural networks (CNNs);cost-sensitive (CoSen) learning;data imbalance;loss functions","Training;Australia;Neural networks;Computer vision;Tag clouds;Training data;Testing","image classification;image representation;learning (artificial intelligence);neural nets;object detection;optimisation","cost-sensitive learning;deep feature representations;imbalanced data;class imbalance;classification tasks;overrepresented majority;underrepresented minority;minority classes;cost-sensitive deep neural network;robust feature representations;class-dependent costs;neural network parameters;binary problems;multiclass problems;data-level approaches;image classification data sets;object detection","","13","67","","","","","IEEE","IEEE Journals"
"Classification of Hyperspectral Images by Gabor Filtering Based Deep Network","X. Kang; C. Li; S. Li; H. Lin","Electrical and Information Engineering, Hunan University, Changsha, China; Electrical and Information Engineering, Hunan University, Changsha, China; Electrical and Information Engineering, Hunan University, Changsha, China; Electrical and Information Engineering, Hunan University, Changsha, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2018","11","4","1166","1178","In this paper, a novel spectral-spatial classification method based on Gabor filtering and deep network (GFDN) is proposed. First, Gabor features are extracted by performing Gabor filtering on the first three principal components of the hyperspectral image, which can typically characterize the low-level spatial structures of different orientations and scales. Then, the Gabor features and spectral features are simply stacked to form the fused features. Afterwards, deep features are captured by training a stacked sparse autoencoder deep network with the fused features obtained above as inputs. Since the number of training samples of hyperspectral images is often very limited, which negatively affects the classification performance in deep learning, an effective way of constructing virtual samples is designed to generate more training samples, automatically. By jointly utilizing both the real and virtual samples, the parameters of the deep network can be better trained and updated, which can result in classification results of higher accuracies. Experiments performed on four real hyperspectral datasets show that the proposed method outperforms several recently proposed classification methods in terms of classification accuracies.","","","10.1109/JSTARS.2017.2767185","National Natural Science Fund of China for International Cooperation and Exchanges; National Natural Science Foundation of China; National Natural Science Fund of China for Distinguished Young Scholars; Fund of Hunan Province for Science and Technology Plan Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8118120","Deep learning;Gabor filter;hyperspectral image (HSI) classification;stacked sparse autoencoders (SSAE);virtual samples","Feature extraction;Training;Hyperspectral imaging;Machine learning;Image reconstruction","feature extraction;Gabor filters;geophysical image processing;hyperspectral imaging;image classification;image coding;learning (artificial intelligence)","hyperspectral image;novel spectral-spatial classification method;Gabor features;low-level spatial structures;spectral features;fused features;deep features;stacked sparse autoencoder deep network;training samples;classification performance;deep learning;hyperspectral datasets;gabor filtering based deep network;virtual samples","","21","48","","","","","IEEE","IEEE Journals"
"Discriminative Deep Quantization Hashing for Face Image Retrieval","J. Tang; J. Lin; Z. Li; J. Yang","School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","12","6154","6162","This paper proposes a new discriminative deep quantization hashing (DDQH) approach for large-scale face image retrieval by learning discriminative and compact binary codes. It jointly explores the discrete code learning, batch normalization quantization (BNQ) module, and end-to-end learning in one unified framework, which can guarantee the optimal compatibility of hash coding and feature learning. To learn multiscale and robust facial features, a deep network properly stacking several convolution-pooling layers and pooling layers is designed, and the facial features are obtained by fusing the outputs of the last convolutional layer and the last pooling layer. Besides, the prediction errors of the learned binary codes are minimized to learn discriminative binary codes of images. To obtain higher retrieval accuracies, a BNQ module is utilized to control quantization at a moderate level. Experiments are conducted on two widely used data sets, and the proposed DDQH method achieves encouraging improvements over some state-of-the-art hashing approaches.","","","10.1109/TNNLS.2018.2816743","973 Program of China; National Natural Science Foundation of China; Natural Science Foundation of Jiangsu Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8353929","Batch normalization quantization (BNQ);end-to-end learning;hashing;image retrieval","Binary codes;Face;Image retrieval;Quantization (signal);Convolutional codes;Feature extraction;Facial features","binary codes;face recognition;feature extraction;image coding;image retrieval;learning (artificial intelligence)","pooling layer;convolutional layer;BNQ module;discriminative deep quantization hashing approach;large-scale face image retrieval;discriminative codes;compact binary codes;discrete code learning;batch normalization quantization module;end-to-end learning;optimal compatibility;hash coding;feature learning;multiscale facial features;robust facial features;deep network;convolution-pooling layers;DDQH method","","8","48","","","","","IEEE","IEEE Journals"
"Learning deep features to recognise speech emotion using merged deep CNN","J. Zhao; X. Mao; L. Chen",", Beihang University, People's Republic of China; , Beihang University, People's Republic of China; , Beihang University, People's Republic of China","IET Signal Processing","","2018","12","6","713","721","This study aims at learning deep features from different data to recognise speech emotion. The authors designed a merged convolutional neural network (CNN), which had two branches, one being one-dimensional (1D) CNN branch and another 2D CNN branch, to learn the high-level features from raw audio clips and log-mel spectrograms. The building of the merged deep CNN consists of two steps. First, one 1D CNN and one 2D CNN architectures were designed and evaluated; then, after the deletion of the second dense layers, the two CNN architectures were merged together. To speed up the training of the merged CNN, transfer learning was introduced in the training. The 1D CNN and 2D CNN were trained first. Then, the learned features of the 1D CNN and 2D CNN were repurposed and transferred to the merged CNN. Finally, the merged deep CNN initialised with transferred features was fine-tuned. Two hyperparameters of the designed architectures were chosen through Bayesian optimisation in the training. The experiments conducted on two benchmark datasets show that the merged deep CNN can improve emotion classification performance significantly.","","","10.1049/iet-spr.2017.0320","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8434156","","","emotion recognition;learning (artificial intelligence);optimisation;speech recognition","emotion classification;Bayesian optimisation;transfer learning;2D CNN branch;1D CNN branch;merged convolutional neural network;deep features;merged deep CNN;speech emotion recognition","","2","","","","","","IET","IET Journals"
"A Unified Approach for Conventional Zero-Shot, Generalized Zero-Shot, and Few-Shot Learning","S. Rahman; S. Khan; F. Porikli","Research School of Engineering, The Australian National University, Canberra, ACT, Australia; Research School of Engineering, The Australian National University, Canberra, ACT, Australia; Research School of Engineering, The Australian National University, Canberra, ACT, Australia","IEEE Transactions on Image Processing","","2018","27","11","5652","5667","Prevalent techniques in zero-shot learning do not generalize well to other related problem scenarios. Here, we present a unified approach for conventional zero-shot, generalized zero-shot, and few-shot learning problems. Our approach is based on a novel class adapting principal directions' (CAPDs) concept that allows multiple embeddings of image features into a semantic space. Given an image, our method produces one principal direction for each seen class. Then, it learns how to combine these directions to obtain the principal direction for each unseen class such that the CAPD of the test image is aligned with the semantic embedding of the true class and opposite to the other classes. This allows efficient and class-adaptive information transfer from seen to unseen classes. In addition, we propose an automatic process for the selection of the most useful seen classes for each unseen class to achieve robustness in zero-shot learning. Our method can update the unseen CAPD taking the advantages of few unseen images to work in a few-shot learning scenario. Furthermore, our method can generalize the seen CAPDs by estimating seen-unseen diversity that significantly improves the performance of generalized zero-shot learning. Our extensive evaluations demonstrate that the proposed approach consistently achieves superior performance in zero-shot, generalized zero-shot, and few/one-shot learning problems.","","","10.1109/TIP.2018.2861573","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8423721","Zero-shot learning;few-shot learning;generalized zero-shot learning;class adaptive principal direction","Deep learning;Noise reduction","image classification;learning (artificial intelligence)","CAPD;class-adaptive information transfer;unified approach;few-shot learning problems;generalized zero-shot learning;few-shot learning;conventional zero-shot learning;one-shot learning problems;class adapting principal directions;image features;semantic space;test image;automatic process;seen-unseen diversity estimation","","5","59","","","","","IEEE","IEEE Journals"
"An Unsupervised Convolutional Feature Fusion Network for Deep Representation of Remote Sensing Images","Y. Yu; Z. Gong; C. Wang; P. Zhong","College of Electrical Science and Engineering, National University of Defense Technology, Changsha, China; College of Electrical Science and Engineering, National University of Defense Technology, Changsha, China; Fujian Key Laboratory of Sensing and Computing for Smart Cities, School of Information Science and Engineering, Xiamen University, Xiamen, China; College of Electrical Science and Engineering, National University of Defense Technology, Changsha, China","IEEE Geoscience and Remote Sensing Letters","","2018","15","1","23","27","Unsupervised learning of a convolutional neural network (CNN) is a feasible method to represent and classify remote sensing images, where labeling the observed data to prepare training samples is a highly expensive and time-consuming task. In this letter, we propose an unsupervised convolutional feature fusion network to formulate an easy-to-train but effective CNN representation of remote sensing images. The efficiency and effectiveness are derived from the following two aspects. First, the proposed method trains a deep CNN through unsupervised learning of each CNN layer in a greedy layer-wise manner, which makes the training relatively easy and efficient. Second, the feature fusion strategy in the proposed network can effectively use both the information from individual layers and the important interactions between different layers. As a result, the proposed network requires only several layers to obtain comparable or even better results than very deep networks. The experiments on unsupervised deep representations and the classification of remote sensing images demonstrate the efficiency and effectiveness of the proposed method.","","","10.1109/LGRS.2017.2767626","Natural Science Foundation of China; Foundation for the Author of National Excellent Doctoral Dissertation of China; Program for New Century Excellent Talents in University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8194894","Convolutional neural network (CNN);feature fusion network;sparsity;unsupervised deep learning","Training;Remote sensing;Unsupervised learning;Sensors;Convolution;Fuses","feature extraction;feedforward neural nets;geophysical image processing;image classification;image representation;remote sensing;unsupervised learning","unsupervised deep representations;deep networks;feature fusion strategy;greedy layer-wise manner;CNN layer;deep CNN;effective CNN representation;highly expensive time-consuming task;remote sensing images;unsupervised learning;deep representation;unsupervised convolutional feature fusion network","","","18","","","","","IEEE","IEEE Journals"
"Deep Learning for Passive Synthetic Aperture Radar","B. Yonel; E. Mason; B. Yazıcı","Department of Electrical, Computer, and Systems Engineering, Rensselaer Polytechnic Institute, Troy, NY, USA; Department of Electrical, Computer, and Systems Engineering, Rensselaer Polytechnic Institute, Troy, NY, USA; Department of Electrical, Computer, and Systems Engineering, Rensselaer Polytechnic Institute, Troy, NY, USA","IEEE Journal of Selected Topics in Signal Processing","","2018","12","1","90","103","We introduce a deep learning (DL) framework for inverse problems in imaging, and demonstrate the advantages and applicability of this approach in passive synthetic aperture radar (SAR) image reconstruction. We interpret image reconstruction as a machine learning task and utilize deep networks as forward and inverse solvers for imaging. Specifically, we design a recurrent neural network (RNN) architecture as an inverse solver based on the iterations of proximal gradient descent optimization methods. We further adapt the RNN architecture to image reconstruction problems by transforming the network into a recurrent auto-encoder, thereby allowing for unsupervised training. Our DL based inverse solver is particularly suitable for a class of image formation problems in which the forward model is only partially known. The ability to learn forward models and hyper parameters combined with unsupervised training approach establish our recurrent auto-encoder suitable for real world applications. We demonstrate the performance of our method in passive SAR image reconstruction. In this regime a source of opportunity, with unknown location and transmitted waveform, is used to illuminate a scene of interest. We investigate recurrent auto-encoder architecture based on the ℓ1 and ℓ0 constrained least-squares problem. We present a projected stochastic gradient descent based training scheme which incorporates constraints of the unknown model parameters. We demonstrate through extensive numerical simulations that our DL based approach out performs conventional sparse coding methods in terms of computation and reconstructed image quality, specifically, when no information about the transmitter is available.","","","10.1109/JSTSP.2017.2784181","Air Force Office of Scientific Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8214209","Deep learning;image reconstruction;passive imaging;synthetic aperture radar;passive radar","Image reconstruction;Synthetic aperture radar;Machine learning;Imaging;Training;Inverse problems;Computational modeling","encoding;gradient methods;image reconstruction;inverse problems;optimisation;passive radar;radar imaging;recurrent neural nets;synthetic aperture radar;unsupervised learning","least-square problem;recurrent neural network architecture;DL-based approach;reconstructed image quality;projected stochastic gradient descent based training scheme;passive SAR image reconstruction;unsupervised training approach;image formation problems;recurrent auto-encoder;image reconstruction problems;RNN architecture;proximal gradient descent optimization methods;inverse solver;recurrent neural network architecture;passive synthetic aperture radar image reconstruction;deep learning framework","","5","45","","","","","IEEE","IEEE Journals"
"Neurostream: Scalable and Energy Efficient Deep Learning with Smart Memory Cubes","E. Azarkhish; D. Rossi; I. Loi; L. Benini","Department of Electrical, Electronic and Information Engineering, University of Bologna, Bologna, Italy; Department of Electrical, Electronic and Information Engineering, University of Bologna, Bologna, Italy; Department of Electrical, Electronic and Information Engineering, University of Bologna, Bologna, Italy; Department of Information Technology and Electrical Engineering, Swiss Federal Institute of Technology Zurich, Zurich, Switzerland","IEEE Transactions on Parallel and Distributed Systems","","2018","29","2","420","434","High-performance computing systems are moving towards 2.5D and 3D memory hierarchies, based on High Bandwidth Memory (HBM) and Hybrid Memory Cube (HMC) to mitigate the main memory bottlenecks. This trend is also creating new opportunities to revisit near-memory computation. In this paper, we propose a flexible processor-in-memory (PIM) solution for scalable and energy-efficient execution of deep convolutional networks (ConvNets), one of the fastest-growing workloads for servers and high-end embedded systems. Our co-design approach consists of a network of Smart Memory Cubes (modular extensions to the standard HMC) each augmented with a many-core PIM platform called NeuroCluster. NeuroClusters have a modular design based on NeuroStream coprocessors (for Convolution-intensive computations) and general-purpose RISC-V cores. In addition, a DRAM-friendly tiling mechanism and a scalable computation paradigm are presented to efficiently harness this computational capability with a very low programming effort. NeuroCluster occupies only 8 percent of the total logic-base (LoB) die area in a standard HMC and achieves an average performance of 240 GFLOPS for complete execution of full-featured state-of-the-art (SoA) ConvNets within a power budget of 2.5 W. Overall 11 W is consumed in a single SMC device, with 22.5 GFLOPS/W energy-efficiency which is 3.5X better than the best GPU implementations in similar technologies. The minor increase in system-level power and the negligible area increase make our PIM system a cost-effective and energy efficient solution, easily scalable to 955 GFLOPS with a small network of just four SMCs.","","","10.1109/TPDS.2017.2752706","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8038819","Hybrid memory cube;convolutional neural networks;large-scale deep learning;streaming floating-point","Random access memory;Standards;Memory management;Machine learning;Three-dimensional displays;Bandwidth;Indexes","cache storage;coprocessors;data structures;DRAM chips;embedded systems;field programmable gate arrays;graphics processing units;learning (artificial intelligence);microprocessor chips;multiprocessing systems;neural nets;parallel architectures;parallel processing;parallel programming;performance evaluation;power aware computing;program compilers;reduced instruction set computing","energy-efficiency;convolution-intensive computations;flexible processor-in-memory solution;2.5D memory hierarchies;hybrid memory cube;high bandwidth memory;high-performance computing systems;energy efficient solution;system-level power;total logic-base;scalable computation paradigm;modular design;NeuroCluster;many-core PIM platform;standard HMC;high-end embedded systems;deep convolutional networks;energy-efficient execution;processor-in-memory solution;near-memory computation;3D memory hierarchies;smart memory cubes;scalable energy efficient deep learning;computer speed 240.0 GFLOPS;power 2.5 W;power 11.0 W;computer speed 955.0 GFLOPS","","12","61","","","","","IEEE","IEEE Journals"
"Voltage Sag Estimation in Sparsely Monitored Power Systems Based on Deep Learning and System Area Mapping","H. Liao; J. V. Milanović; M. Rodrigues; A. Shenfield","Power, Electrical and Control Engineering Group, Sheffield Hallam University, Sheffield, UK; School of Electrical and Electronic Engineering, The University of Manchester, Manchester, UK; Geometric Modelling and Pattern Recognition Research Group, Sheffield Hallam University, Sheffield, UK; Geometric Modelling and Pattern Recognition Research Group, Sheffield Hallam University, Sheffield, UK","IEEE Transactions on Power Delivery","","2018","33","6","3162","3172","This paper proposes a voltage sag estimation approach based on a deep convolutional neural network. The proposed approach estimates the sag magnitude at unmonitored buses regardless of the system operating conditions and fault location and characteristics. The concept of system area mapping is also introduced via the use of bus matrix, which maps different patches in input matrix to various areas in the power system network. In this way, relevant features are extracted at various local areas in the power system and used in the analysis for higher level feature extraction, before feeding into a fully-connected multiple layer neural network for sag classification. The approach has been tested on the IEEE 68-bus test network and it has been demonstrated that the various sag categories can be identified accurately regardless of the operating condition under which the sags occur.","","","10.1109/TPWRD.2018.2865906","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8439023","Voltage sag estimation;deep learning;convolutional neural networks;bus matrix;pattern classification","Pattern classification;Power quality;Meters;Circuit faults;Machine learning;Voltage sag","convolution;fault location;feature extraction;feedforward neural nets;IEEE standards;learning (artificial intelligence);pattern classification;power engineering computing;power supply quality;power system measurement","sparsely monitored power systems;deep learning;voltage sag estimation;feature extraction;IEEE 68-bus test network;sag classification;fully-connected multiple layer neural network;power system network;bus matrix;fault location;system operating conditions;sag magnitude;deep convolutional neural network;system area mapping","","2","38","","","","","IEEE","IEEE Journals"
"Deep Self-Evolution Clustering","J. Chang; G. Meng; L. Wang; S. Xiang; C. Pan","National Laboratory of Pattern Recognition, Institute of Automation Chinese Academy of Sciences, 74522 Beijing, Beijing China (e-mail: jianlong.chang@nlpr.ia.ac.cn); Chinese Academy of Sciences, Institution of Automation, Beijing, Beijing China (e-mail: gfmeng@nlpr.ia.ac.cn); National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, Beijing China (e-mail: lingfeng.wang@ia.ac.cn); School of Artificial Intelligence, University of the Chinese Academy of Sciences, 74519 Beijing, Beijing China (e-mail: smxiang@nlpr.ia.ac.cn); National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, Beijing China (e-mail: chpan@nlpr.ia.ac.cn)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","PP","99","1","1","Clustering is a crucial but challenging task in pattern analysis and machine learning. Existing methods often ignore the combination between representation learning and clustering. To tackle this problem, we reconsider the clustering task from its definition to develop Deep Self-Evolution Clustering (DSEC) to jointly learn representations and cluster data. For this purpose, the clustering task is recast as a binary pairwise-classification problem to estimate whether pairwise patterns are similar. Specifically, similarities between pairwise patterns are defined by the dot product between indicator features which are generated by a deep neural network (DNN). To learn informative representations for clustering, clustering constraints are imposed on the indicator features to represent specific concepts with specific representations. Since the ground-truth similarities are unavailable in clustering, an alternating iterative algorithm called Self-Evolution Clustering Training (SECT) is presented to select similar and dissimilar pairwise patterns and to train the DNN alternately. Consequently, the indicator features tend to be one-hot vectors and the patterns can be clustered by locating the largest response of the learned indicator features. Extensive experiments strongly evidence that DSEC outperforms current models on twelve popular image, text and audio datasets consistently.","","","10.1109/TPAMI.2018.2889949","National Natural Science Foundation of China; Natural Science Foundation of Beijing Municipality; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8590804","Clustering;deep self-evolution clustering;self-evolution clustering training;deep unsupervised learning","Task analysis;Unsupervised learning;Training;Clustering methods;Pattern analysis","","","","","","","","","","IEEE","IEEE Early Access Articles"
"An Energy-Efficient Online-Learning Stochastic Computational Deep Belief Network","Y. Liu; Y. Wang; F. Lombardi; J. Han","Department of Electrical and Computer Engineering, University of Alberta, Edmonton, AB, Canada; Electrical Engineering and Computer Science Department, Syracuse University, Syracuse, NY, USA; Department of Electrical and Computer Engineering, Northeastern University, Boston, MA, USA; Department of Electrical and Computer Engineering, University of Alberta, Edmonton, AB, Canada","IEEE Journal on Emerging and Selected Topics in Circuits and Systems","","2018","8","3","454","465","Deep neural networks (DNNs) are effective machine learning models to solve a large class of recognition problems, including the classification of nonlinearly separable patterns. The training of DNNs is, however, particularly difficult due to the large size and high energy consumption of the networks. Recently, stochastic computation (SC) has been considered to implement DNNs to reduce the hardware cost. However, it requires a large number of random number generators (RNGs) and long stochastic sequences that lower the energy efficiency of the network. To overcome these limitations, we propose the design of an energy-efficient deep belief network (DBN) with online learning capacity based on stochastic computation. In the SC-DBN, a reconfigurable structure is utilized to implement the fast greedy learning algorithm and an adaptive moment estimation (ADAM) circuit is designed to improve the speed of the training process. An approximate SC activation unit (A-SCAU) is further designed to implement different types of activation functions in the neurons. The A-SCAU is immune to signal correlations, so the RNGs can be shared among all neurons in the same layer with no accuracy loss. The area and energy of the proposed design are less than 5.5% and 3.7% (or 29.3% and 33.3%) of a pipelined 32-bit floating-point (or an 8-bit fixed-point) implementation. The proposed SC-DBN design achieves a higher classification accuracy compared with the fixed-point implementation. The accuracy is in a range of 0.12% to 0.37% lower than the floating-point design with a significantly lower (or slightly higher) energy consumption than the pipelined (or non-pipelined) circuit for both online learning and inference processes.","","","10.1109/JETCAS.2018.2852705","Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8403221","Stochastic computing;deep belief network;rectifier linear unit;cognitive computing","Neurons;Training;Energy consumption;Decoding;Biological neural networks;Hardware;Stochastic processes","belief networks;energy conservation;floating point arithmetic;greedy algorithms;learning (artificial intelligence);neural nets;pattern classification;random number generation;stochastic processes","DNN;machine learning models;RNG;ADAM;signal correlation;SC-DBN design;32-bit floating-point;A-SCAU;approximate SC activation unit;adaptive moment estimation circuit;fast greedy learning algorithm;online learning capacity;energy efficiency;random number generators;high energy consumption;nonlinearly separable patterns;deep neural networks;stochastic computational deep belief network","","3","32","","","","","IEEE","IEEE Journals"
"Deep Nonlinear Metric Learning for 3-D Shape Retrieval","J. Xie; G. Dai; F. Zhu; L. Shao; Y. Fang","Department of Electrical and Computer Engineering, NYU Multimedia and Visual Computing Laboratory, New York University Abu Dhabi, Abu Dhabi, UAE; Department of Electrical and Computer Engineering, NYU Multimedia and Visual Computing Laboratory, New York University Abu Dhabi, Abu Dhabi, UAE; Department of Electrical and Computer Engineering, NYU Multimedia and Visual Computing Laboratory, New York University Abu Dhabi, Abu Dhabi, UAE; Department of Computer Science and Digital Technologies, Northumbria University, Newcastle upon Tyne, U.K.; Department of Electrical and Computer Engineering, NYU Multimedia and Visual Computing Laboratory, New York University Abu Dhabi, Abu Dhabi, UAE","IEEE Transactions on Cybernetics","","2018","48","1","412","422","Effective 3-D shape retrieval is an important problem in 3-D shape analysis. Recently, feature learning-based shape retrieval methods have been widely studied, where the distance metrics between 3-D shape descriptors are usually hand-crafted. In this paper, motivated by the fact that deep neural network has the good ability to model nonlinearity, we propose to learn an effective nonlinear distance metric between 3-D shape descriptors for retrieval. First, the locality-constrained linear coding method is employed to encode each vertex on the shape and the encoding coefficient histogram is formed as the global 3-D shape descriptor to represent the shape. Then, a novel deep metric network is proposed to learn a nonlinear transformation to map the 3-D shape descriptors to a nonlinear feature space. The proposed deep metric network minimizes a discriminative loss function that can enforce the similarity between a pair of samples from the same class to be small and the similarity between a pair of samples from different classes to be large. Finally, the distance between the outputs of the metric network is used as the similarity for shape retrieval. The proposed method is evaluated on the McGill, SHREC'10 ShapeGoogle, and SHREC'14 Human shape datasets. Experimental results on the three datasets validate the effectiveness of the proposed method.","","","10.1109/TCYB.2016.2638924","New York University Abu Dhabi; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7801132","3-D shape descriptor;3-D shape retrieval;deep metric learning;heat kernel signature (HKS);neural network","Shape;Measurement;Feature extraction;Heating;Encoding;Kernel;Solid modeling","feature extraction;image matching;image retrieval;learning (artificial intelligence);linear codes;neural nets;shape recognition","shape retrieval methods;SHREC14 Human shape datasets;deep nonlinear metric learning;3-D shape retrieval;3-D shape analysis;nonlinear distance metric;deep metric network;discriminative loss function;3-D shape descriptors;McGill;SHREC'10 ShapeGoogle","","3","41","","","","","IEEE","IEEE Journals"
"Memristive Fully Convolutional Network: An Accurate Hardware Image-Segmentor in Deep Learning","S. Wen; H. Wei; Z. Zeng; T. Huang","School of Automation and the Key Laboratory of Image Processing and Intelligent Control of Education Ministry of China, Huazhong University of Science and Technology, Wuhan, China; School of Automation and the Key Laboratory of Image Processing and Intelligent Control of Education Ministry of China, Huazhong University of Science and Technology, Wuhan, China; School of Automation and the Key Laboratory of Image Processing and Intelligent Control of Education Ministry of China, Huazhong University of Science and Technology, Wuhan, China; Texas A & M University at Qatar, Doha, Qatar","IEEE Transactions on Emerging Topics in Computational Intelligence","","2018","2","5","324","334","As well known, fully convolutional network (FCN) becomes the state of the art for semantic segmentation in deep learning. Currently, new hardware designs for deep learning have focused on improving the speed and parallelism of processing units. This motivates memristive solutions, in which the memory units (i.e., memristors) have computing capabilities. However, designing a memristive deep learning network is challenging, since memristors work very differently from the traditional CMOS hardware. This paper proposes a complete solution to implement memristive FCN (MFCN). Voltage selectors are firstly utilized to realize max-pooling layers with the detailed MFCN deconvolution hardware circuit by the massively parallel structure, which is effective since the deconvolution kernel and the input feature are similar in size. Then, deconvolution calculation is realized by converting the image into a column matrix and converting the deconvolution kernel into a sparse matrix. Meanwhile, the convolution realization in MFCN is also studied with the traditional sliding window method rather than the large matrix theory to overcome the shortcoming of low efficiency. Moreover, the conductance values of memristors are predetermined in Tensor flow with ex-situ training method. In other words, we train MFCN in software, then download the trained parameters to the simulink system by writing memristor. The effectiveness of the designed MFCN scheme is verified with improved accuracy over some existing machine learning methods. The proposed scheme is also adapt to LFW dataset with three-classification tasks. However, the MFCN training is time consuming as the computational burden is heavy with thousands of weight parameters with just six layers. In future, it is necessary to sparsify the weight parameters and layers of the MFCN network to speed up computing.","","","10.1109/TETCI.2018.2829911","National Natural Science Foundation of China; NPRP; Qatar National Research Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8471011","Memritor crossbar;fully convolutional network;deep learning","Memristors;Convolution;Kernel;Deconvolution;Sparse matrices;Training;Hardware","convolution;deconvolution;feedforward neural nets;image classification;image segmentation;learning (artificial intelligence);memristors","CMOS hardware;sliding window method;machine learning methods;hardware image-segmentor;memristive solutions;MFCN deconvolution hardware circuit;MFCN network;MFCN training;writing memristor;convolution realization;deconvolution calculation;deconvolution kernel;massively parallel structure;memristive deep learning network;memristors;memory units;parallelism;hardware designs;memristive fully convolutional network","","1","45","","","","","IEEE","IEEE Journals"
"Detection of Human Falls on Furniture Using Scene Analysis Based on Deep Learning and Activity Characteristics","W. Min; H. Cui; H. Rao; Z. Li; L. Yao","School of Information Engineering, Nanchang University, Nanchang, China; School of Information Engineering, Nanchang University, Nanchang, China; School of Information Engineering, Nanchang University, Nanchang, China; School of Information Engineering, Nanchang University, Nanchang, China; School of Information Engineering, Nanchang University, Nanchang, China","IEEE Access","","2018","6","","9324","9335","Automatic human fall detection is one important research topic in caring for vulnerable people, such as elders at home and patients in medical places. Over the past decade, numerous methods aiming at solving the problem were proposed. However, the existing methods only focus on detecting human themselves and cannot work effectively in complicated environments, especially for the falls on furniture. To alleviate this problem, a new method for human fall detection on furniture using scene analysis based on deep learning and activity characteristics is presented in this paper. The proposed method first performs scene analysis using a deep learning method faster R-CNN to detect human and furniture. Meanwhile, the space relation between human and furniture is detected. The activity characteristics of the detected people, such as human shape aspect ratio, centroid, motion speed are detected and tracked. Through measuring the changes of these characteristics and judging the relations between the people and furniture nearby, the falls on furniture can be effectively detected. Experiment results demonstrated that our approach not only accurately and effectively detected falls on furniture, such as sofa and chairs but also distinguished them from other fall-like activities, such as sitting or lying down, while the existing methods have difficulties to handle these. In our experiments, our algorithm achieved 94.44% precision, 94.95% recall, and 95.50% accuracy. The proposed method can be potentially used and integrated as a medical assistance in health care and medical places and appliances.","","","10.1109/ACCESS.2018.2795239","National Natural Science Foundation of China; Natural Science Foundation of Jiangxi Province, China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8263164","Activity characteristics;deep learning;faster R-CNN;human fall detection;medical assistance;scene analysis","Image analysis;Sensors;Proposals;Machine learning;Shape;Feature extraction;Hidden Markov models","convolution;feedforward neural nets;geriatrics;health care;learning (artificial intelligence);medical computing;object detection","health care;medical assistance;deep learning method;automatic human fall detection;scene analysis;human falls;fall-like activities;human shape aspect ratio","","8","48","","","","","IEEE","IEEE Journals"
"Spectrum Prediction Based on Taguchi Method in Deep Learning With Long Short-Term Memory","L. Yu; J. Chen; G. Ding; Y. Tu; J. Yang; J. Sun","College of Communications Engineering, Army Engineering University of PLA, Nanjing, China; College of Communications Engineering, Army Engineering University of PLA, Nanjing, China; College of Communications Engineering, Army Engineering University of PLA, Nanjing, China; College of Information and Communication, Harbin Engineering University, Harbin, China; The 63rd Institute, National University of Defense Technology, Nanjing, China; College of Communications Engineering, Army Engineering University of PLA, Nanjing, China","IEEE Access","","2018","6","","45923","45933","Spectrum prediction is a promising technology in cognitive radio networks, since it can reduce considerable time and energy consumed in spectrum sensing process. Many spectrum prediction algorithms have achieved good performance, but majority of them with shallow architecture cannot capture the inherent correlations of spectrum data very well. Long short-term memory (LSTM) neural network in deep learning has been validated to have strong capability of solving time series problems. In this paper, we develop a spectrum prediction framework with a deep learning approach on two real-world spectrum datasets. For the first dataset to predict channel occupancy states, we firstly employ the taguchi method to determine the best optimized configuration of neural network for certain spectrum point and then analyze the effect of each design hyper-parameter. Next, we build LSTM neural networks with two perspectives of regression and classification for spectrum prediction. For the second dataset to predict channel quality, we compare the prediction performance of the LSTM neural network and conventional multilayer perceptron (MLP) neural network. For both of our datasets, results show that the prediction performance varies with frequency bands. From the point of statistics, the LSTM neural network has better prediction performance than the MLP neural network and is more stable as well. Furthermore, we find that the performance of the LSTM neural network with classification perspective is slightly better than that with regression perspective in our first dataset.","","","10.1109/ACCESS.2018.2864222","National Natural Science Foundation of China; Natural Science Foundation of Jiangsu Province; China Postdoctoral Science Foundation; Natural Science Foundation for Distinguished Young Scholars of Jiangsu Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8428623","Deep learning;LSTM neural network;spectrum prediction;taguchi method","Machine learning;Biological neural networks;Sensors;Time series analysis;Neurons;Computer architecture","cognitive radio;learning (artificial intelligence);multilayer perceptrons;radio networks;regression analysis;signal detection;Taguchi methods;time series","short-term memory neural network;spectrum prediction framework;deep learning approach;real-world spectrum datasets;taguchi method;LSTM neural network;conventional multilayer perceptron neural network;MLP neural network;cognitive radio networks;spectrum sensing process;spectrum prediction algorithms","","7","40","","","","","IEEE","IEEE Journals"
"Proactive Resource Management for LTE in Unlicensed Spectrum: A Deep Learning Perspective","U. Challita; L. Dong; W. Saad","School of Informatics, The University of Edinburgh, Edinburgh, U.K.; School of Informatics, The University of Edinburgh, Edinburgh, U.K.; Bradley Department of Electrical and Computer Engineering, Wireless@VT, Virginia Tech, Blacksburg, VA, USA","IEEE Transactions on Wireless Communications","","2018","17","7","4674","4689","Performing cellular long term evolution (LTE) communications in unlicensed spectrum using licensed assisted access LTE (LTE-LAA) is a promising approach to overcome wireless spectrum scarcity. However, to reap the benefits of LTE-LAA, a fair coexistence mechanism with other incumbent WiFi deployments is required. In this paper, a novel deep learning approach is proposed for modeling the resource allocation problem of LTE-LAA small base stations (SBSs). The proposed approach enables multiple SBSs to proactively perform dynamic channel selection, carrier aggregation, and fractional spectrum access while guaranteeing fairness with existing WiFi networks and other LTE-LAA operators. Adopting a proactive coexistence mechanism enables future delay-tolerant LTE-LAA data demands to be served within a given prediction window ahead of their actual arrival time thus avoiding the underutilization of the unlicensed spectrum during off-peak hours while maximizing the total served LTE-LAA traffic load. To this end, a noncooperative game model is formulated in which SBSs are modeled as homo egualis agents that aim at predicting a sequence of future actions and thus achieving long-term equal weighted fairness with wireless local area network and other LTE-LAA operators over a given time horizon. The proposed deep learning algorithm is then shown to reach a mixed-strategy Nash equilibrium, when it converges. Simulation results using real data traces show that the proposed scheme can yield up to 28% and 11% gains over a conventional reactive approach and a proportional fair coexistence mechanism, respectively. The results also show that the proposed framework prevents WiFi performance degradation for a densely deployed LTE-LAA network.","","","10.1109/TWC.2018.2829773","University Of Edinburgh; National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8359094","Licensed assisted access LTE (LTE-LAA);LTE-U;small cell;unlicensed band;long short term memory (LSTM);deep reinforcement learning;game theory;proactive resource allocation","Resource management;Long Term Evolution;Wireless fidelity;Wireless communication;Machine learning;Games","cellular radio;channel allocation;cognitive radio;game theory;learning (artificial intelligence);Long Term Evolution;radio spectrum management;resource allocation;wireless LAN","proactive resource management;unlicensed spectrum;deep learning perspective;licensed assisted access LTE;wireless spectrum scarcity;LTE-LAA operators;proactive coexistence mechanism;total served LTE-LAA traffic load;long-term equal weighted fairness;proportional fair coexistence mechanism;densely deployed LTE-LAA network;cellular long term evolution communications;fractional spectrum access;delay-tolerant LTE-LAA data;mixed-strategy Nash equilibrium;noncooperative game model;homo egualis agents;prediction window;arrival time","","26","48","","","","","IEEE","IEEE Journals"
"Active-Learning-Incorporated Deep Transfer Learning for Hyperspectral Image Classification","J. Lin; L. Zhao; S. Li; R. Ward; Z. J. Wang","Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, BC, Canada; School of Software Technology, Dalian University of Technology, Dalian, China; School of Automation, Xi'an University of Post and Telecommunications, Xi'an, China; Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, BC, Canada; Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, BC, Canada","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2018","11","11","4048","4062","A hyperspectral image (HSI) includes a vast quantity of samples, a large number of bands, and randomly occurring redundancy. Classifying such complex data is challenging, and its classification performance can be affected significantly by the amount of labeled training samples, as well as the quality, position, and others factors of these samples. Collecting such labeled training samples is labor and time consuming, motivating the idea of taking advantage of labeled samples from other pre-existing related images. Therefore, transfer learning, which can mitigate the semantic gap between existing and new HSIs, has drawn increasing research attention. However, existing transfer learning methods for HSIs (which mainly concentrate on how to overcome the divergence among images) may fail to carefully consider the contents to be transferred and thus limit their performances. In this paper, we present two novel ideas: 1) we, for the first time, introduce an active learning process to initialize the salient samples on the HSI data, which would be transferred later; and 2) we propose constructing and connecting higher level features for the source and target HSI data to further overcome the cross-domain disparity. Different from existing methods, the proposed framework requires no a priori knowledge on the target domain, and it works for both homogeneous and heterogeneous HSI data. Experimental results on three real-world HSIs support the effectiveness of the proposed method for HSI classification.","","","10.1109/JSTARS.2018.2874225","Qatar National Research Fund; National Priorities Research Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8531707","Hyperspectral image (HSI);salient samples;supervised classification;transfer learning","Training;Correlation;Semantics;Hyperspectral imaging;Neural networks","feature extraction;geophysical image processing;hyperspectral imaging;image classification;learning (artificial intelligence)","active learning process;homogeneous HSI data;heterogeneous HSI data;HSI classification;active-learning-incorporated deep transfer;hyperspectral image classification;complex data;classification performance;labeled training samples;pre-existing related images;transfer learning","","7","45","","","","","IEEE","IEEE Journals"
"Underwater-Drone With Panoramic Camera for Automatic Fish Recognition Based on Deep Learning","L. Meng; T. Hirayama; S. Oyanagi","College of Science and Engineering, Ritsumeikan University, Kyoto, Japan; OhMy DigiFab Company Ltd., Otsu, Japan; College of Computer Science and Engineering, Ritsumeikan University, Kyoto, Japan","IEEE Access","","2018","6","","17880","17886","Highly developed drone technology enables the use of drones in a wide variety of areas. However, those drones are mainly used in the unmanned aerial vehicles. We believe that underwater drones will become a big research topic and find a market in the near future. We developed an underwater drone with a 360° panoramic camera acting as the “eye”of the drone. The designs are based on the open-source hardware and will be shared as an open-source for contributing to the innovation of manufacturing including drone. The function of the 360° panoramic camera is generated by correcting the images taken by two fisheye lenses. The underwater drone was designed by extending the Raspberry Pi compute module, the frame was designed by OpenSCAD, and the printed circuit board was designed by MakePro. As for the application of the underwater drone, we focused on fish recognition for investigating fish species in a natural lake to help protect the original environment. Fish recognition is based on deep learning, which is the biggest topic in the artificial intelligence research field today. Experimental results show that the function of the underwater drone achieved at diving in the leak automatically. The 360° panoramic images were generated correctly. Fish recognition achieved 87% accuracy by deep learning.","","","10.1109/ACCESS.2018.2820326","JSPS; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8327594","360-degree panoramic image;underwater-drone;fish recognition;deep learning;open source hardware","Unmanned underwater vehicles;Drones;Machine learning;Cameras;Open source software;Image generation;Hardware","aquaculture;autonomous aerial vehicles;autonomous underwater vehicles;cameras;image sensors;learning (artificial intelligence);lenses;logic CAD;microcomputers;mobile robots;object recognition;printed circuits;robot vision","deep learning;drone technology;underwater drone;360° panoramic camera;manufacturing innovation;automatic fish recognition;unmanned aerial vehicles;open-source hardware;fisheye lenses;Raspberry Pi compute module;OpenSCAD;printed circuit board;MakePro;artificial intelligence research field","","4","30","","","","","IEEE","IEEE Journals"
"Scalable and Unsupervised Feature Engineering Using Vibration-Imaging and Deep Learning for Rotor System Diagnosis","H. Oh; J. H. Jung; B. C. Jeon; B. D. Youn","School of Mechanical Engineering, Gwangju Institute of Science and Technology, Gwangju, South Korea; Department of Mechanical and Aerospace Engineering, Seoul National University, Seoul, South Korea; Aero Technology Research Institute, Republic of Korea Air Force, Daegu 41052, South Korea; Department of Mechanical and Aerospace Engineering, Seoul National University, Seoul, South Korea","IEEE Transactions on Industrial Electronics","","2018","65","4","3539","3549","This paper proposes a scalable and unsupervised feature engineering method that uses vibration imaging and deep learning. For scalability, a vibration imaging approach is devised that incorporates data from systems with various scales, such as small testbeds and real field-deployed systems. Moreover, a deep learning approach is proposed for unsupervised feature engineering. The overall procedure includes three key steps: 1) vibration image generation; 2) unsupervised feature extraction; and 3) fault classifier design. To demonstrate the validity of the proposed approach, three case studies are conducted using an RK4 rotor kit and a power plant journal bearing system. By incorporating smaller-system data as well as real-system data, the proposed approach can substantially increase the applicability of the fault diagnosis method while maintaining good accuracy. Moreover, the time and effort needed to develop a diagnostic approach for other rotor systems can be reduced considerably.","","","10.1109/TIE.2017.2752151","Korea Electric Power Corporation; Basic Science Research Program; National Research Foundation of Korea (NRF); Ministry of Education; Institute of Advanced Machinery and Design at Seoul National University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8036215","Deep learning;diagnostics;feature engineering;field data;vibration image","Machine learning;Rotors;Feature extraction;Vibrations;Training;Fault diagnosis;Imaging","fault diagnosis;feature extraction;image classification;learning (artificial intelligence);machine bearings;power plants;rotors;vibrational signal processing","rotor system diagnosis;vibration image generation;unsupervised feature extraction;fault classifier design;deep learning approach;field-deployed systems;vibration imaging approach;scalable feature engineering;unsupervised feature engineering;fault diagnosis method;real-system data;smaller-system data;power plant journal bearing system;RK4 rotor kit","","9","34","Traditional","","","","IEEE","IEEE Journals"
"Detection of Malicious Code Variants Based on Deep Learning","Z. Cui; F. Xue; X. Cai; Y. Cao; G. Wang; J. Chen","Complex System and Computational Intelligence Laboratory, TaiYuan University of Science and Technology, Taiyuan, China; School of Information, Beijing Wuzi University, Beijing, China; Complex System and Computational Intelligence Laboratory, TaiYuan University of Science and Technology, Taiyuan, China; Complex System and Computational Intelligence Laboratory, TaiYuan University of Science and Technology, Taiyuan, China; Department of Computer Science and Technology, Ocean University of China, Qingdao, China; Complex System and Computational Intelligence Laboratory, Taiyuan University of Science and Technology, Taiyuan, China","IEEE Transactions on Industrial Informatics","","2018","14","7","3187","3196","With the development of the Internet, malicious code attacks have increased exponentially, with malicious code variants ranking as a key threat to Internet security. The ability to detect variants of malicious code is critical for protection against security breaches, data theft, and other dangers. Current methods for recognizing malicious code have demonstrated poor detection accuracy and low detection speeds. This paper proposed a novel method that used deep learning to improve the detection of malware variants. In prior research, deep learning demonstrated excellent performance in image recognition. To implement our proposed detection method, we converted the malicious code into grayscale images. Then, the images were identified and classified using a convolutional neural network (CNN) that could extract the features of the malware images automatically. In addition, we utilized a bat algorithm to address the data imbalance among different malware families. To test our approach, we conducted a series of experiments on malware image data from Vision Research Lab. The experimental results demonstrated that our model achieved good accuracy and speed as compared with other malware detection models.","","","10.1109/TII.2018.2822680","National Natural Science Foundation of China; Natural Science Foundation of Shanxi Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8330042","Malware variants;grayscale image;deep learning;convolution neural network;bat algorithm","Malware;Feature extraction;Machine learning;Gray-scale;Informatics;Data visualization;Image recognition","feature extraction;feedforward neural nets;image classification;invasive software;learning (artificial intelligence)","malicious code variants;deep learning;malicious code attacks;Internet security;poor detection accuracy;low detection speeds;malware variants;detection method;malware image data;malware detection models","","11","30","","","","","IEEE","IEEE Journals"
"Modeling Multimodal Clues in a Hybrid Deep Learning Framework for Video Classification","Y. Jiang; Z. Wu; J. Tang; Z. Li; X. Xue; S. Chang","School of Computer Science, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science, Fudan University, Shanghai, China; Department of Electrical Engineering, Columbia University, New York City, NY, USA","IEEE Transactions on Multimedia","","2018","20","11","3137","3147","Videos are inherently multimodal. This paper studies the problem of exploiting the abundant multimodal clues for improved video classification performance. We introduce a novel hybrid deep learning framework that integrates useful clues from multiple modalities, including static spatial appearance information, motion patterns within a short time window, audio information, as well as long-range temporal dynamics. More specifically, we utilize three Convolutional Neural Networks (CNNs) operating on appearance, motion, and audio signals to extract their corresponding features. We then employ a feature fusion network to derive a unified representation with an aim to capture the relationships among features. Furthermore, to exploit the long-range temporal dynamics in videos, we apply two long short-term memory (LSTM) networks with extracted appearance and motion features as inputs. Finally, we also propose refining the prediction scores by leveraging contextual relationships among video semantics. The hybrid deep learning framework is able to exploit a comprehensive set of multimodal features for video classification. Through an extensive set of experiments, we demonstrate that: 1) LSTM networks that model sequences in an explicitly recurrent manner are highly complementary to the CNN models; 2) the feature fusion network that produces a fused representation through modeling feature relationships outperforms a large set of alternative fusion strategies; and 3) the semantic context of video classes can help further refine the predictions for improved performance. Experimental results on two challenging benchmarks-the UCF-101 and the Columbia Consumer Videos (CCV)-provide strong quantitative evidence that our framework can produce promising results: 93.1% on the UCF-101 and 84.5% on the CCV, outperforming several competing methods with clear margins.","","","10.1109/TMM.2018.2823900","NSF China; STCSM, Shanghai; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8336920","Deep learning;framework;fusion;video classification","Semantics;Feature extraction;Hidden Markov models;Machine learning;Optical imaging;Context modeling;Three-dimensional displays","audio signal processing;feature extraction;image classification;image motion analysis;learning (artificial intelligence);neural nets;object detection;video retrieval;video signal processing","hybrid deep learning framework;convolutional neural networks;features extraction;multimodal clues modeling;video classification performance;unified representation;long short-term memory networks;contextual relationships;LSTM networks;model sequences;semantic context;UCF-101;Columbia consumer videos;CCV;video classes;feature relationships;CNN models;multimodal features;video semantics;motion features;short-term memory networks;feature fusion network;audio signals;long-range temporal dynamics;audio information;short time window;motion patterns;static spatial appearance information;abundant multimodal clues","","7","65","","","","","IEEE","IEEE Journals"
"A Novel PAPR Reduction Scheme for OFDM System Based on Deep Learning","M. Kim; W. Lee; D. Cho","School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Department of Information and Communication Engineering, Institute of Marine Industry, Gyeongsang National University, Tongyeong, South Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea","IEEE Communications Letters","","2018","22","3","510","513","High peak-to-average power ratio (PAPR) has been one of the major drawbacks of orthogonal frequency division multiplexing (OFDM) systems. In this letter, we propose a novel PAPR reduction scheme, known as PAPR reducing network (PRNet), based on the autoencoder architecture of deep learning. In the PRNet, the constellation mapping and demapping of symbols on each subcarrier is determined adaptively through a deep learning technique, such that both the bit error rate (BER) and the PAPR of the OFDM system are jointly minimized. We used simulations to show that the proposed scheme outperforms conventional schemes in terms of BER and PAPR.","","","10.1109/LCOMM.2017.2787646","Institute for Information & communications Technology Promotion (IITP); Korea government (MSIT); Development of 5G Mobile Communication Technologies for Hyper-connected smart services; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8240644","Orthogonal frequency division multiplexing;autoencoder;deep learning;peak-to-average power ratio","Peak to average power ratio;Machine learning;Decoding;Bit error rate;Nonlinear distortion","error statistics;learning (artificial intelligence);neural net architecture;OFDM modulation;telecommunication computing","novel PAPR reduction scheme;PRNet;constellation mapping;deep learning technique;peak-to-average power ratio;orthogonal frequency division multiplexing system;OFDM systems;PAPR reducing network;autoencoder architecture;symbol demapping;bit error rate;BER","","25","15","","","","","IEEE","IEEE Journals"
"Iris Recognition With Off-the-Shelf CNN Features: A Deep Learning Perspective","K. Nguyen; C. Fookes; A. Ross; S. Sridharan","Image and Video Lab, Queensland University of Technology, Brisbane, QLD, Australia; Image and Video Lab, Queensland University of Technology, Brisbane, QLD, Australia; Department of Computer Science and Engineering, Michigan State University, East Lansing, MI, USA; Image and Video Lab, Queensland University of Technology, Brisbane, QLD, Australia","IEEE Access","","2018","6","","18848","18855","Iris recognition refers to the automated process of recognizing individuals based on their iris patterns. The seemingly stochastic nature of the iris stroma makes it a distinctive cue for biometric recognition. The textural nuances of an individual's iris pattern can be effectively extracted and encoded by projecting them onto Gabor wavelets and transforming the ensuing phasor response into a binary code - a technique pioneered by Daugman. This textural descriptor has been observed to be a robust feature descriptor with very low false match rates and low computational complexity. However, recent advancements in deep learning and computer vision indicate that generic descriptors extracted using convolutional neural networks (CNNs) are able to represent complex image characteristics. Given the superior performance of CNNs on the ImageNet large scale visual recognition challenge and a large number of other computer vision tasks, in this paper, we explore the performance of state-of-the-art pre-trained CNNs on iris recognition. We show that the off-the-shelf CNN features, while originally trained for classifying generic objects, are also extremely good at representing iris images, effectively extracting discriminative visual features and achieving promising recognition results on two iris datasets: ND-CrossSensor-2013 and CASIA-IrisThousand. We also discuss the challenges and future research directions in leveraging deep learning methods for the problem of iris recognition.","","","10.1109/ACCESS.2017.2784352","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8219390","Iris recognition;biometrics;deep learning;convolutional neural network","Iris recognition;Machine learning;Computer architecture;Visualization;Computer vision;Feature extraction","computational complexity;computer vision;feature extraction;image classification;image matching;image representation;image texture;iris recognition;learning (artificial intelligence);neural nets;wavelet transforms","biometric recognition;robust feature descriptor;low computational complexity;computer vision;iris recognition;off-the-shelf CNN features;iris images;iris datasets;iris patterns;iris stroma;ImageNet large scale visual recognition;textural nuances;Gabor wavelets;binary code;phasor response;textural descriptor;false match rates;generic descriptors;deep learning method;convolutional neural networks;complex image characteristics;generic object classification;discriminative visual feature extraction","","19","55","","","","","IEEE","IEEE Journals"
"Fall Detection Using Deep Learning in Range-Doppler Radars","B. Jokanović; M. Amin","Villanova University, Villanova, PA, USA; Villanova University, Villanova, PA, USA","IEEE Transactions on Aerospace and Electronic Systems","","2018","54","1","180","189","In this paper, we propose an approach that uses deep learning to detect a human fall. The proposed approach automatically captures the intricate properties of the radar returns. In order to minimize false alarms, we fuse information from both the time-frequency and range domains. Experimental data is used to demonstrate the superiority of the deep learning based approach in comparison with the principal component analysis method and those methods incorporating predefined physically interpreted features.","","","10.1109/TAES.2017.2740098","NPRP; Qatar National Research Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8010417","Deep learning;detection;doppler;fall;fusion;human motion;range;sparse autoencoder;time-frequency domain","Doppler radar;Time-frequency analysis;Machine learning;Feature extraction;Radar detection;Spectrogram","Doppler radar;feature extraction;health care;learning (artificial intelligence);principal component analysis;sensor fusion;signal classification;signal representation","range-Doppler radars;deep learning;human fall detection;information fusion;principal component analysis;public health problem;unintentional injury death;feature extraction;motion classification;signal representation;Spectrograms","","31","49","","","","","IEEE","IEEE Journals"
"Learning without Forgetting","Z. Li; D. Hoiem","Department of Computer Science, University of Illinois, Urbana Champaign, IL; Department of Computer Science, University of Illinois, Urbana Champaign, IL","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","12","2935","2947","When building a unified vision system or gradually adding new apabilities to a system, the usual assumption is that training data for all tasks is always available. However, as the number of tasks grows, storing and retraining on such data becomes infeasible. A new problem arises where we add new capabilities to a Convolutional Neural Network (CNN), but the training data for its existing capabilities are unavailable. We propose our Learning without Forgetting method, which uses only new task data to train the network while preserving the original capabilities. Our method performs favorably compared to commonly used feature extraction and fine-tuning adaption techniques and performs similarly to multitask learning that uses original task data we assume unavailable. A more surprising observation is that Learning without Forgetting may be able to replace fine-tuning with similar old and new task datasets for improved new task performance.","","","10.1109/TPAMI.2017.2773081","NSF; ONR MURI; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8107520","Convolutional neural networks;transfer learning;multi-task learning;deep learning;visual recognition","Feature extraction;Deep learning;Training data;Neural networks;Convolutional neural networks;Knowledge engineering;Learning systems;Visual perception","convolution;feature extraction;feedforward neural nets;learning (artificial intelligence)","fine-tuning adaption techniques;CNN;forgetting method;convolutional neural network;vision system;feature extraction","","18","39","","","","","IEEE","IEEE Journals"
"General TCP State Inference Model From Passive Measurements Using Machine Learning Techniques","D. H. Hagos; P. E. Engelstad; A. Yazidi; Ø. Kure","Department of Technology Systems, Autonomous Systems and Sensor Technologies Research Group, University of Oslo, Oslo, Norway; Department of Technology Systems, Autonomous Systems and Sensor Technologies Research Group, University of Oslo, Oslo, Norway; Department of Computer Science, Autonomous Systems and Networks Research Group, Oslo Metropolitan University, Oslo, Norway; Department of Technology Systems, Autonomous Systems and Sensor Technologies Research Group, University of Oslo, Oslo, Norway","IEEE Access","","2018","6","","28372","28387","Many applications in the Internet use the reliable end-to-end Transmission Control Protocol (TCP) as a transport protocol due to practical considerations. There are many different TCP variants widely in use, and each variant uses a specific congestion control algorithm to avoid congestion, while also attempting to share the underlying network capacity equally among the competing users. This paper shows how an intermediate node (e.g., a network operator) can identify the transmission state of the TCP client associated with a TCP flow by passively monitoring the TCP traffic. Here, we present a robust, scalable and generic machine learning-based method which may be of interest for network operators that experimentally infers Congestion Window (cwnd) and the underlying variant of loss-based TCP algorithms within a flow from passive traffic measurements collected at an intermediate node. The method can also be extended to predict other TCP transmission states of the client. We believe that our study also has a potential benefit and opportunity for researchers and scientists in the networking community from both academia and industry who want to assess the characteristics of TCP transmission states related to network congestion. We validate the robustness and scalability approach of our prediction model through a large number of controlled experiments. It turns out, surprisingly enough, that the learned prediction model performs reasonably well by leveraging knowledge from the emulated network when it is applied on a real-life scenario setting. Thus, our prediction model is general bearing similarity to the concept of transfer learning in the machine learning community. The accuracy of our experimental results both in an emulated network, realistic and combined scenario settings and across multiple TCP congestion control variants demonstrate that our model is reasonably effective and has considerable potential.","","","10.1109/ACCESS.2018.2833107","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354788","Network protocols;TCP;congestion control;passive measurement;machine learning;transfer learning;convolutional filtering;deep learning","Monitoring;Predictive models;Machine learning;Internet;Prediction algorithms;Robustness;Loss measurement","Internet;learning (artificial intelligence);telecommunication traffic;transport protocols","transport protocol;specific congestion control algorithm;intermediate node;network operator;transmission state;TCP client;TCP flow;TCP traffic;robust machine learning;scalable machine learning;generic machine learning;Congestion Window;passive traffic measurements;networking community;network congestion;scalability approach;controlled experiments;emulated network;transfer learning;machine learning community;multiple TCP congestion control variants;general TCP state inference model;passive measurements;Internet;reliable end-to-end Transmission Control Protocol;learned prediction model;transmission states;network capacity","","3","43","","","","","IEEE","IEEE Journals"
"HAST-IDS: Learning Hierarchical Spatial-Temporal Features Using Deep Neural Networks to Improve Intrusion Detection","W. Wang; Y. Sheng; J. Wang; X. Zeng; X. Ye; Y. Huang; M. Zhu","Department of Automation, University of Science and Technology of China, Hefei, China; National Network New Media Engineering Research Center, Institute of Acoustics, Chinese Academy of Sciences, Beijing, China; National Network New Media Engineering Research Center, Institute of Acoustics, Chinese Academy of Sciences, Beijing, China; National Network New Media Engineering Research Center, Institute of Acoustics, Chinese Academy of Sciences, Beijing, China; National Network New Media Engineering Research Center, Institute of Acoustics, Chinese Academy of Sciences, Beijing, China; Guilin University of Electronic Technology, Guilin, China; Department of Automation, University of Science and Technology of China, Hefei, China","IEEE Access","","2018","6","","1792","1806","The development of an anomaly-based intrusion detection system (IDS) is a primary research direction in the field of intrusion detection. An IDS learns normal and anomalous behavior by analyzing network traffic and can detect unknown and new attacks. However, the performance of an IDS is highly dependent on feature design, and designing a feature set that can accurately characterize network traffic is still an ongoing research issue. Anomaly-based IDSs also have the problem of a high false alarm rate (FAR), which seriously restricts their practical applications. In this paper, we propose a novel IDS called the hierarchical spatial-temporal features-based intrusion detection system (HAST-IDS), which first learns the low-level spatial features of network traffic using deep convolutional neural networks (CNNs) and then learns high-level temporal features using long short-term memory networks. The entire process of feature learning is completed by the deep neural networks automatically; no feature engineering techniques are required. The automatically learned traffic features effectively reduce the FAR. The standard DARPA1998 and ISCX2012 data sets are used to evaluate the performance of the proposed system. The experimental results show that the HAST-IDS outperforms other published approaches in terms of accuracy, detection rate, and FAR, which successfully demonstrates its effectiveness in both feature learning and FAR reduction.","","","10.1109/ACCESS.2017.2780250","Pioneer Program of Institute of Acoustics, Chinese Academy of Sciences; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8171733","Network intrusion detection;deep neural networks;representation learning","Telecommunication traffic;Feature extraction;Intrusion detection;Recurrent neural networks;Natural language processing","convolution;data analysis;feature extraction;feedforward neural nets;learning (artificial intelligence);security of data;telecommunication traffic","network traffic;deep convolutional neural networks;high-level temporal features;short-term memory networks;feature learning;feature engineering techniques;automatically learned traffic features;HAST-IDS;detection rate;hierarchical spatial-temporal features;intrusion detection system;primary research direction;feature design;feature set;high false alarm rate;low-level spatial features;IDS","","31","48","","","","","IEEE","IEEE Journals"
"NB-CNN: Deep Learning-Based Crack Detection Using Convolutional Neural Network and Naïve Bayes Data Fusion","F. Chen; M. R. Jahanshahi","School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA; Lyles School of Civil Engineering, Purdue University, West Lafayette, IN, USA","IEEE Transactions on Industrial Electronics","","2018","65","5","4392","4400","Regular inspection of nuclear power plant components is important to guarantee safe operations. However, current practice is time consuming, tedious, and subjective, which involves human technicians reviewing the inspection videos and identifying cracks on reactors. A few vision-based crack detection approaches have been developed for metallic surfaces, and they typically perform poorly when used for analyzing nuclear inspection videos. Detecting these cracks is a challenging task since they are tiny, and noisy patterns exist on the components' surfaces. This study proposes a deep learning framework, based on a convolutional neural network (CNN) and a Naïve Bayes data fusion scheme, called NB-CNN, to analyze individual video frames for crack detection while a novel data fusion scheme is proposed to aggregate the information extracted from each video frame to enhance the overall performance and robustness of the system. To this end, a CNN is proposed to detect crack patches in each video frame, while the proposed data fusion scheme maintains the spatiotemporal coherence of cracks in videos, and the Naïve Bayes decision making discards false positives effectively. The proposed framework achieves a 98.3% hit rate against 0.1 false positives per frame that is significantly higher than state-of-the-art approaches as presented in this paper.","","","10.1109/TIE.2017.2764844","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8074762","Crack detection;convolutional neural network (CNN);data fusion;deep learning;nuclear power plant inspection","Videos;Power generation;Surface cracks;Inspection;Data integration;Surface morphology;Cameras","Bayes methods;computer vision;convolution;crack detection;decision making;feature extraction;inspection;learning (artificial intelligence);neural nets;nuclear power stations;power engineering computing;sensor fusion;video signal processing","video frames;NB-CNN;deep learning-based crack detection;naïve Bayes data fusion scheme;cracks identification;vision-based crack detection approaches;crack patches detection;naïve Bayes decision making;video frame;convolutional neural network;deep learning framework;nuclear inspection videos;metallic surfaces;nuclear power plant components;regular inspection","","29","38","","","","","IEEE","IEEE Journals"
"An Improved Deep Computation Model Based on Canonical Polyadic Decomposition","Q. Zhang; L. T. Yang; Z. Chen; P. Li","School of Electronic Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Electronic Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Software Technology, Dalian University of Technology, Dalian, China; School of Software Technology, Dalian University of Technology, Dalian, China","IEEE Transactions on Systems, Man, and Cybernetics: Systems","","2018","48","10","1657","1666","Deep computation models achieve super performance for big data feature learning. However, training a deep computation model poses a significant challenge since a deep computation model typically involves a large number of parameters. Specially, it needs a high-performance computing server with a large-scale memory and a powerful computing unit to train a deep computation model, making it difficult to increase the size of a deep computation model further for big data feature learning on low-end devices such as conventional desktops and portable CPUs. In this paper, we propose an improved deep computation model based on the canonical polyadic decomposition scheme to compress the parameters and to improve the training efficiency. Furthermore, we devise a learning algorithm based on the back-propagation strategy to train the parameters of the proposed model. The learning algorithm can be directly performed on the compressed parameters to improve the training efficiency. Finally, we carry on the experiments on three representative datasets, i.e., CUAVE, SNAE2, and STL-10, to evaluate the performance of the proposed model by comparing with the conventional deep computation model and other two improved deep computation models based on the Tucker decomposition and the tensor-train network. Results demonstrate that the proposed model can compress parameters greatly and improve the training efficiency significantly with a low classification accuracy drop.","","","10.1109/TSMC.2017.2701797","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8015194","Back-propagation strategy;big data feature learning;canonical polyadic decomposition (CP-DCM);deep computation model","Computational modeling;Tensile stress;Data models;Training;Big Data;Machine learning;Neural networks","Big Data;feature extraction;learning (artificial intelligence);parallel processing;pattern classification","training efficiency;conventional deep computation model;improved deep computation model;high-performance computing server;canonical polyadic decomposition;Big Data feature learning","","15","22","","","","","IEEE","IEEE Journals"
"A High-Order Clustering Algorithm Based on Dropout Deep Learning for Heterogeneous Data in Cyber-Physical-Social Systems","F. Bu","Department of Biomedical Informatics, Inner Mongolia University of Finance and Economics, Hohhot, China","IEEE Access","","2018","6","","11687","11693","An explosive growth of cyber-physical-social systems has been witnessed owing to the wide use of various mobile devices recently. A large volume of heterogeneous data has been collected from cyber-physical-social systems in the past few years. Each object in the heterogeneous dataset is typically multi-modal, posing a remarkable challenge on heterogeneous data clustering. In this paper, we propose a high-order k-means algorithm based on the dropout deep learning model for clustering heterogeneous objects in cyber-physical-social systems. We first build three dropout stacked auto-encoders, each with three hidden layers to learn the features for the different modalities of each object. Furthermore, we establish a feature tensor for each object by using the vector outer product to fuse the learned features. At last, we devise a tensor k-means algorithm to cluster the heterogeneous objects based on the tensor distance. We evaluate the proposed high-order k-means algorithm on two representative heterogeneous data sets and results imply that the proposed high-order k-means algorithm can achieve more accurate clustering results than other heterogeneous data clustering methods.","","","10.1109/ACCESS.2017.2759509","National Natural Science Foundation of China; Natural Science Foundation of the Inner Mongolia Autonomous Region; Higher Educational Scientific Research Projects of Inner Mongolia Autonomous Region; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8057763","Cyber-physical-social systems;dropout deep learning model;heterogeneous data;high-order clustering","Clustering algorithms;Tensile stress;Machine learning;Algorithm design and analysis;Feature extraction;Data mining;Computer architecture","learning (artificial intelligence);pattern clustering;social networking (online);tensors","cyber-physical-social systems;heterogeneous data clustering;dropout deep learning model;heterogeneous objects;representative heterogeneous data sets;high-order clustering algorithm;mobile devices;feature tensor;k-means algorithm","","1","27","","","","","IEEE","IEEE Journals"
"Local Deep-Feature Alignment for Unsupervised Dimension Reduction","J. Zhang; J. Yu; D. Tao","School of Science and Technology, Zhejiang International Studies University, Hangzhou, China; School of Computer Science, Hangzhou Dianzi University, Hangzhou, China; UBTECH Sydney Artificial Intelligence Centre and the School of Information Technologies, the Faculty of Engineering and Information Technologies, University of Sydney, Darlington, NSW, Australia","IEEE Transactions on Image Processing","","2018","27","5","2420","2432","This paper presents an unsupervised deep-learning framework named local deep-feature alignment (LDFA) for dimension reduction. We construct neighbourhood for each data sample and learn a local stacked contractive auto-encoder (SCAE) from the neighbourhood to extract the local deep features. Next, we exploit an affine transformation to align the local deep features of each neighbourhood with the global features. Moreover, we derive an approach from LDFA to map explicitly a new data sample into the learned low-dimensional subspace. The advantage of the LDFA method is that it learns both local and global characteristics of the data sample set: the local SCAEs capture local characteristics contained in the data set, while the global alignment procedures encode the interdependencies between neighbourhoods into the final low-dimensional feature representations. Experimental results on data visualization, clustering, and classification show that the LDFA method is competitive with several well-known dimension reduction techniques, and exploiting locality in deep learning is a research topic worth further exploring.","","","10.1109/TIP.2018.2804218","Zhejiang Provincial Natural Science Foundation of China; National Natural Science Foundation of China; Australian Research Council Projects; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8300630","Deep learning;auto-encoder;locality preserving;global alignment;dimension reduction","Manifolds;Feature extraction;Dimensionality reduction;Image reconstruction;Principal component analysis;Learning systems","data visualisation;feature extraction;image representation;pattern classification;unsupervised learning","low-dimensional feature representations;LDFA method;dimension reduction techniques;deep-feature alignment;unsupervised dimension reduction;unsupervised deep-learning framework;local stacked contractive auto-encoder;data sample set;global alignment procedures","","4","38","","","","","IEEE","IEEE Journals"
"Deep Convolutional Framelet Denosing for Low-Dose CT via Wavelet Residual Network","E. Kang; W. Chang; J. Yoo; J. C. Ye","Department of Bio and Brain Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Department of Radiology, Seoul National University Bundang Hospital, Seongnam, South Korea; Department of Bio and Brain Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Department of Bio and Brain Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea","IEEE Transactions on Medical Imaging","","2018","37","6","1358","1369","Model-based iterative reconstruction algorithms for low-dose X-ray computed tomography (CT) are computationally expensive. To address this problem, we recently proposed a deep convolutional neural network (CNN) for low-dose X-ray CT and won the second place in 2016 AAPM Low-Dose CT Grand Challenge. However, some of the textures were not fully recovered. To address this problem, here we propose a novel framelet-based denoising algorithm using wavelet residual network which synergistically combines the expressive power of deep learning and the performance guarantee from the framelet-based denoising algorithms. The new algorithms were inspired by the recent interpretation of the deep CNN as a cascaded convolution framelet signal representation. Extensive experimental results confirm that the proposed networks have significantly improved performance and preserve the detail texture of the original images.","","","10.1109/TMI.2018.2823756","Korea Science and Engineering Foundation; Industrial Strategic Technology Development Program through the Ministry of Trade Industry and Energy (MI), Korea; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8332971","Deep learning;low-dose CT;framelet denoising;convolutional neural network (CNN);convolution framelets","Convolution;Computed tomography;Noise reduction;Image reconstruction;X-ray imaging;Machine learning;Neural networks","computerised tomography;convolution;feedforward neural nets;image denoising;image reconstruction;iterative methods;learning (artificial intelligence);medical image processing;signal representation;wavelet transforms","wavelet residual network;deep learning;deep CNN;cascaded convolution framelet signal representation;deep convolutional neural network;low-dose X-ray CT;deep convolutional framelet denosing;model based iterative reconstruction algorithms;low-dose X-ray computed tomography;framelet based denoising algorithm","","10","49","","","","","IEEE","IEEE Journals"
"Multiobjective Reinforcement Learning for Cognitive Satellite Communications Using Deep Neural Network Ensembles","P. V. R. Ferreira; R. Paffenroth; A. M. Wyglinski; T. M. Hackett; S. G. Bilén; R. C. Reinhart; D. J. Mortensen","Department of Electrical and Computer Engineering, Worcester Polytechnic Institute, Worcester, MA, USA; Department of Mathematical Sciences, Department of Computer Science and Data Science Program, Worcester Polytechnic Institute, Worcester, MA, USA; Department of Electrical and Computer Engineering, Worcester Polytechnic Institute, Worcester, MA, USA; School of Electrical Engineering and Computer Science, The Pennsylvania State University, University Park, PA, USA; School of Electrical Engineering and Computer Science, The Pennsylvania State University, University Park, PA, USA; Space Communications and Navigation, NASA John H. Glenn Research Center, Cleveland, OH, USA; Space Communications and Navigation, NASA John H. Glenn Research Center, Cleveland, OH, USA","IEEE Journal on Selected Areas in Communications","","2018","36","5","1030","1041","Future spacecraft communication subsystems will potentially benefit from software-defined radios controlled by artificial intelligence algorithms. In this paper, we propose a novel radio resource allocation algorithm leveraging multiobjective reinforcement learning and artificial neural network ensembles able to manage available resources and conflicting mission-based goals. The uncertainty in the performance of thousands of possible radio parameter combinations and the dynamic behavior of the radio channel over time producing a continuous multidimensional state-action space requires a fixed-size memory continuous state-action mapping instead of the traditional discrete mapping. In addition, actions need to be decoupled from states in order to allow for online learning, performance monitoring, and resource allocation prediction. The proposed approach leverages the authors' previous research on constraining decisions predicted to have poor performance through ”virtual environment exploration.” The simulation results show the performance for different communication mission profiles, and accuracy benchmarks are provided for the future research reference. The proposed approach constitutes part of the core cognitive engine proof-of-concept delivered to the NASA John H. Glenn Research Center's SCaN Testbed radios on-board the International Space Station.","","","10.1109/JSAC.2018.2832820","Glenn Research Center; National Aeronautics and Space Administration; Coordenação de Aperfeiçoamento de Pessoal de Nível Superior; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8353861","Satellite communication;machine learning;artificial intelligence;reinforcement learning;neural networks;cognitive radio;space communication;SCaN Testbed;NASA GRC","Space vehicles;Artificial neural networks;Learning (artificial intelligence);Communication systems;Resource management;NASA","aerospace computing;cognition;cognitive radio;learning (artificial intelligence);neural nets;resource allocation;satellite communication;software radio;space vehicles","future spacecraft communication subsystems;software-defined radios;artificial intelligence algorithms;novel radio resource allocation algorithm leveraging multiobjective reinforcement learning;artificial neural network;conflicting mission-based goals;possible radio parameter combinations;radio channel;continuous multidimensional state-action space;fixed-size memory continuous state-action mapping;traditional discrete mapping;online learning;performance monitoring;resource allocation prediction;poor performance;future research reference;NASA John H. Glenn Research Center's SCaN Testbed radios;cognitive satellite communications;deep neural network ensembles;communication mission profiles","","4","37","","","","","IEEE","IEEE Journals"
"Active Temporal Action Detection in Untrimmed Videos Via Deep Reinforcement Learning","N. Li; H. Guo; Y. Zhao; T. Li; G. Li","School of Electronic and Computer Engineering, Peking University Shenzhen Graduate School, Shenzhen, China; Chinese Academy of Sciences, Shenzhen Institutes of Advanced Technology, Shenzhen, China; School of Computer and Information, Hefei University of Technology, Hefei, China; Gpower Semiconductor, Inc., Suzhou, China; School of Electronic and Computer Engineering, Peking University Shenzhen Graduate School, Shenzhen, China","IEEE Access","","2018","6","","59126","59140","Existing action detection algorithms usually generate action proposals through an extensive search over the video at multiple temporal scales, which brings about huge computational overhead and deviates from the human perception procedure. We argue that the process of detecting actions in the video should be naturally one of observation and refinement: observe the current temporal window and refine the span of attended window to cover true action regions. In this paper, we propose an active action detection model that learns to search actions through continuously adjusting the bounds of temporal attended window in a self-adaptive way. The whole process can be deemed as an exploring procedure, where an agent is first placed at the beginning of the video and then traverses the whole video by adopting a sequence of transformations on the current attended window to discover actions according to a learned policy. We utilize reinforcement learning, especially the deep Q-learning algorithm to learn the agent’s decision policy. Actually, we construct an end-to-end trainable framework for the action detection task, which includes a proposal generation network based on deep Q-learning, and the classification and regression networks responsible for the action category prediction and the action location adjustment, respectively. In addition, we design a long short-term memory structure upon extracted convolutional neural network features of sparsely sampled frames to generate the effective feature representations for video sequences of various durations. We evaluate the action proposal performance of our approach onTHUMOS’14and assess the generalization ability for unseen action categories onActivityNet. We also compare the action detection performance of ours with other state-of-the-art methods on both data sets. Experiment results validate the effectiveness of the proposed approach, which can achieve comparative or superior performance than other action detection methods via much fewer proposals.","","","10.1109/ACCESS.2018.2872759","National Natural Science Foundation of China; Shenzhen Fundamental Research Program; National Natural Science Foundation of China; Guangdong Province Scientific Research on Big Data; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8476583","Video analysis;temporal action detection;deep reinforcement learning;deep learning;self adaptive","Videos;Proposals;Microsoft Windows;Feature extraction;Machine learning;Task analysis;Video sequences","","","","1","68","","","","","IEEE","IEEE Journals"
"Deep-Structured Machine Learning Model for the Recognition of Mixed-Defect Patterns in Semiconductor Fabrication Processes","G. Tello; O. Y. Al-Jarrah; P. D. Yoo; Y. Al-Hammadi; S. Muhaidat; U. Lee","ATIC-Khalifa Semiconductor Innovation Centre, Abu Dhabi, UAE; Warwick Manufacturing Group, University of Warwick, Coventry, U.K.; Centre for Electronic Warfare, Information and Cyber, Cranfield Defence Security, Defence Academy of the United Kingdom, Shrivenham, U.K.; ATIC-Khalifa Semiconductor Innovation Centre, Abu Dhabi, UAE; ATIC-Khalifa Semiconductor Innovation Centre, Abu Dhabi, UAE; Memory Division, Samsung Electronics, Seoul, South Korea","IEEE Transactions on Semiconductor Manufacturing","","2018","31","2","315","322","Semiconductor manufacturers aim to fabricate defect-free wafers in order to improve product quality, increase yields, and reduce costs. Typically, wafer defects form spatial patterns that provide useful information, helping to identify problems and faults during the fabrication process. Machine learning (ML) methods have been used to classify these defects in order to locate the root causes of failure. This paper proposes a novel deep-structured ML approach as an extension of our previous randomized general regression network (RGRN) model, to identify and classify both single-defect and mixed-defect patterns. The principal motivation for this paper is that a shallow-structured RGRN performs well on single-pattern defects, achieving an accuracy of 99.8%, but performs poorly when a wafer has mixed-defect patterns. The proposed approach improves RGRN performance, particularly on mixed-pattern defects, by incorporating a novel information gain (IG)-based splitter as well as deep-structured ML. A spatial filter is applied to remove random noise and reduce model bias during training. During the first detection stage, the splitter generates unique rules that are built using the IG theory and splits the defects data into single-defect and mixed-defect patterns. Single-defect patterns are then classified by RGRN, whereas mixed-defect patterns are fed into the deep-structured ML model for further classification. This combination improves the ability of the proposed approach to classify diverse defect patterns and achieve a better overall performance. Our experimental results demonstrate that the proposed approach achieves an overall detection accuracy of 86.17% on a dataset that contains real data representing both single-defect and mixed-defect patterns, as commonly found in real manufacturing scenarios, outperforming existing ML-based models.","","","10.1109/TSM.2018.2825482","ICT Fund, UAE; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8335303","Semiconductor wafer defect detection;deep learning;machine learning;pattern recognition;mixed-defect patterns","Feature extraction;Spatial filters;Semiconductor device modeling;Pattern recognition;Data models;Task analysis;Electronic mail","condition monitoring;fault diagnosis;learning (artificial intelligence);manufacturing processes;pattern classification;production engineering computing;random processes;regression analysis;semiconductor industry;semiconductor technology","defect-free wafers;wafer defects;single-pattern defects;mixed-pattern defects;single-defect patterns;mixed-defect patterns recognition;deep-structured machine learning model;semiconductor fabrication processes;information gain-based splitter;IG-based splitter;randomized general regression network model;RGRN model","","9","29","","","","","IEEE","IEEE Journals"
"Semi-Supervised Deep Learning Using Pseudo Labels for Hyperspectral Image Classification","H. Wu; S. Prasad","Department of Electrical and Computer Engineering, Hyperspectral Image Analysis Group, University of Houston, Houston, TX, USA; Department of Electrical and Computer Engineering, Hyperspectral Image Analysis Group, University of Houston, Houston, TX, USA","IEEE Transactions on Image Processing","","2018","27","3","1259","1270","Deep learning has gained popularity in a variety of computer vision tasks. Recently, it has also been successfully applied for hyperspectral image classification tasks. Training deep neural networks, such as a convolutional neural network for classification requires a large number of labeled samples. However, in remote sensing applications, we usually only have a small amount of labeled data for training because they are expensive to collect, although we still have abundant unlabeled data. In this paper, we propose semi-supervised deep learning for hyperspectral image classification-our approach uses limited labeled data and abundant unlabeled data to train a deep neural network. More specifically, we use deep convolutional recurrent neural networks (CRNN) for hyperspectral image classification by treating each hyperspectral pixel as a spectral sequence. In the proposed semi-supervised learning framework, the abundant unlabeled data are utilized with their pseudo labels (cluster labels). We propose to use all the training data together with their pseudo labels to pre-train a deep CRNN, and then fine-tune using the limited available labeled data. Further, to utilize spatial information in the hyperspectral images, we propose a constrained Dirichlet process mixture model (C-DPMM), a non-parametric Bayesian clustering algorithm, for semi-supervised clustering which includes pairwise must-link and cannot-link constraints-this produces high-quality pseudo-labels, resulting in improved initialization of the deep neural network. We also derived a variational inference model for the C-DPMM for efficient inference. Experimental results with real hyperspectral image data sets demonstrate that the proposed semi-supervised method outperforms state-of-the-art supervised and semi-supervised learning methods for hyperspectral classification.","","","10.1109/TIP.2017.2772836","NASA New Investigator (Early Career) Award; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8105856","Convolutional recurrent neural networks;pseudo labels;constrained Dirichlet process mixture model","Hyperspectral imaging;Feature extraction;Neural networks;Machine learning;Training","Bayes methods;computer vision;convolution;hyperspectral imaging;image classification;image sequences;learning (artificial intelligence);mixture models;pattern clustering;recurrent neural nets;spectral analysis","spectral sequence;C-DPMM;Dirichlet process mixture model;nonparametric Bayesian clustering algorithm;hyperspectral image data sets;high-quality pseudolabels;semisupervised clustering;deep CRNN;cluster labels;hyperspectral pixel;deep convolutional recurrent neural networks;hyperspectral image classification tasks;computer vision tasks;semisupervised deep learning","","23","58","","","","","IEEE","IEEE Journals"
"Identification of Maize Leaf Diseases Using Improved Deep Convolutional Neural Networks","X. Zhang; Y. Qiao; F. Meng; C. Fan; M. Zhang","School of Electronic Engineering and Information, Northeast Agricultural University, Harbin, China; School of Electronic Engineering and Information, Northeast Agricultural University, Harbin, China; School of Electronic Engineering and Information, Northeast Agricultural University, Harbin, China; School of Electronic Engineering and Information, Northeast Agricultural University, Harbin, China; School of Electronic Engineering and Information, Northeast Agricultural University, Harbin, China","IEEE Access","","2018","6","","30370","30377","In the field of agricultural information, the automatic identification and diagnosis of maize leaf diseases is highly desired. To improve the identification accuracy of maize leaf diseases and reduce the number of network parameters, the improved GoogLeNet and Cifar10 models based on deep learning are proposed for leaf disease recognition in this paper. Two improved models that are used to train and test nine kinds of maize leaf images are obtained by adjusting the parameters, changing the pooling combinations, adding dropout operations and rectified linear unit functions, and reducing the number of classifiers. In addition, the number of parameters of the improved models is significantly smaller than that of the VGG and AlexNet structures. During the recognition of eight kinds of maize leaf diseases, the GoogLeNet model achieves a top - 1 average identification accuracy of 98.9%, and the Cifar10 model achieves an average accuracy of 98.8%. The improved methods are possibly improved the accuracy of maize leaf disease, and reduced the convergence iterations, which can effectively improve the model training and recognition efficiency.","","","10.1109/ACCESS.2018.2844405","National Natural Science Foundation of China; China Postdoctoral Science Foundation; Heilongjiang Provincial Postdoctoral Science Foundation; Harbin Science and Technology Innovation Youth Talents Special Fund; Northeast Agricultural University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8374024","Deep learning;deep convolutional neural networks;identification;image processing;leaf diseases","Diseases;Training;Machine learning;Support vector machines;Testing;Convolutional neural networks","agriculture;image classification;image recognition;learning (artificial intelligence);neural nets;plant diseases","dropout operations;convergence iterations;rectified linear unit functions;pooling combinations;deep learning;Cifar10 models;GoogLeNet models;improved deep convolutional neural networks;maize leaf images;leaf disease recognition;maize leaf disease","","16","34","","","","","IEEE","IEEE Journals"
"Convolutional Recurrent Deep Learning Model for Sentence Classification","A. Hassan; A. Mahmood","Department of Computer Science and Engineering, University of Bridgeport, Bridgeport, CT, USA; Department of Computer Science and Engineering, University of Bridgeport, Bridgeport, CT, USA","IEEE Access","","2018","6","","13949","13957","As the amount of unstructured text data that humanity produces overall and on the Internet grows, so does the need to intelligently to process it and extract different types of knowledge from it. Convolutional neural networks (CNNs) and recurrent neural networks (RNNs) have been applied to natural language processing systems with comparative, remarkable results. The CNN is a noble approach to extract higher level features that are invariant to local translation. However, it requires stacking multiple convolutional layers in order to capture long-term dependencies, due to the locality of the convolutional and pooling layers. In this paper, we describe a joint CNN and RNN framework to overcome this problem. Briefly, we use an unsupervised neural language model to train initial word embeddings that are further tuned by our deep learning network, then, the pre-trained parameters of the network are used to initialize the model. At a final stage, the proposed framework combines former information with a set of feature maps learned by a convolutional layer with long-term dependencies learned via long-short-term memory. Empirically, we show that our approach, with slight hyperparameter tuning and static vectors, achieves outstanding results on multiple sentiment analysis benchmarks. Our approach outperforms several existing approaches in term of accuracy; our results are also competitive with the state-of-the-art results on the Stanford Large Movie Review data set with 93.3% accuracy, and the Stanford Sentiment Treebank data set with 48.8% fine-grained and 89.2% binary accuracy, respectively. Our approach has a significant role in reducing the number of parameters and constructing the convolutional layer followed by the recurrent layer as a substitute for the pooling layer. Our results show that we were able to reduce the loss of detailed, local information and capture long-term dependencies with an efficient framework that has fewer parameters and a high level of performance.","","","10.1109/ACCESS.2018.2814818","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8314136","Convolutional neural network;recurrent neural network;natural language processing;deep learning;sentiment analysis;long-term dependencies","Feature extraction;Task analysis;Machine learning;Computational modeling;Convolutional neural networks;Sentiment analysis","feedforward neural nets;learning (artificial intelligence);recurrent neural nets;sentiment analysis","binary accuracy;long-term dependencies;static vectors;natural language processing systems;unstructured text data;hyperparameter tuning;initial word embeddings;unsupervised neural language model;RNN framework;joint CNN;pooling layers;locality;multiple convolutional layers;local translation;recurrent neural networks;convolutional neural networks;sentence classification;convolutional recurrent deep learning model;local information;pooling layer;recurrent layer;Stanford Sentiment Treebank data set;Stanford Large Movie Review data set;multiple sentiment analysis benchmarks;long-short-term memory;convolutional layer;feature maps","","16","44","","","","","IEEE","IEEE Journals"
"Learning to Segment Generic Handheld Objects Using Class-Agnostic Deep Comparison and Segmentation Network","K. Chaudhary; K. Wada; X. Chen; K. Kimura; K. Okada; M. Inaba","JSK Lab, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; JSK Lab, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; JSK Lab, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; JSK Lab, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; JSK Lab, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; JSK Lab, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan","IEEE Robotics and Automation Letters","","2018","3","4","3844","3851","Learning unknown objects in the environment is important for detection and manipulation tasks. Prior to learning the unknown objects the ground-truth labels have to be provided. The data annotation or labeling can be achieved in a number of ways but the most widely used method is still manual annotation. Although manual annotation has shown superior performance, it limits robots' capabilities to known object instances and is also a time consuming task. This letter considers the aforementioned limitations and presents a method that allows robots to autonomously annotate objects from observations of human-object interactions. Specifically, we present a novel method that segments handheld objects in real-time using the class-agnostic deep comparison and segmentation network. The inputs to the network are the RGB-D data of known object template and a search space, and it outputs a pixel-wise label of the object and an objectness score. The score indicates the likelihood that the same object is present in both the inputs. The object template is manually initialized in the first frame and thereafter, the object is segmented and the template is updated online. The template is strategically updated using the likelihood score. The segmented object regions are accumulated as pseudo-ground-truth labels, which are used for object learning. The approach efficiently handles both rigid and highly deformable objects.","","","10.1109/LRA.2018.2856917","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8412598","Deep learning in robotics and automation;visual tracking and segmentation","Image segmentation;Robots;Search problems;Labeling;Manuals;Object segmentation;Machine learning","image recognition;image segmentation;learning (artificial intelligence);object detection;robot vision","ground-truth labels;data annotation;manual annotation;robots;human-object interactions;class-agnostic deep comparison;segmentation network;pixel-wise label;objectness score;segmented object regions;pseudoground-truth labels;object learning;segment generic handheld objects","","","22","","","","","IEEE","IEEE Journals"
"Super-High-Purity Seed Sorter Using Low-Latency Image-Recognition Based on Deep Learning","Y. J. Heo; S. J. Kim; D. Kim; K. Lee; W. K. Chung","Department of Mechanical Engineering, Pohang University of Science and Technology, Pohang-si, South Korea; Department of Mechanical Engineering, Pohang University of Science and Technology, Pohang-si, South Korea; Department of Mechanical Engineering, Pohang University of Science and Technology, Pohang-si, South Korea; Department of Mechanical Engineering, Pohang University of Science and Technology, Pohang-si, South Korea; Department of Mechanical Engineering, Pohang University of Science and Technology, Pohang-si, South Korea","IEEE Robotics and Automation Letters","","2018","3","4","3035","3042","Most commercial optical sorting systems are designed to achieve high throughput, so they use a naive low-latency image processing for object identification. These naive low-latency algorithms have difficulty in accurately identifying objects with various shapes, textures, sizes, and colors, so the purity of sorted objects is degraded. Current deep learning technology enables robust image detection and classification, but its inference latency requires several milliseconds; thus, deep learning cannot be directly applied to such real-time high throughput applications. We therefore developed a super-high purity seed sorting system that uses a low-latency image-recognition based on a deep neural network and removes the seeds of noxious weeds from mixed seed product at high throughput with accuracy. The proposed system partitions the detection task into localization and classification, and applies batch inference only once strategy; it achieved 500-fps throughput image-recognition including detection and tracking. Based on the classified and tracked results, air ejectors expel the unwanted seeds. This proposed system eliminates almost the whole weeds with small loss of desired seeds, and is superior to current commercial optical sorting systems.","","","10.1109/LRA.2018.2849513","National Research Foundation of Korea; South Korea government; Industrial Technology Innovation Program; Ministry Of Trade, Industry & Energy; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8391727","Agricultural automation;deep learning in robotics and automation;computer vision for automation","Sorting;Throughput;Optical imaging;Cameras;Machine learning;Image color analysis;Belts","agricultural products;feature extraction;image classification;image colour analysis;image resolution;materials handling;neural nets;production engineering computing","image tracking;image classification;weeds;super-high purity seed sorter;real-time high throughput applications;robust image detection;current deep learning technology;sorted objects;object identification;low-latency image processing;high-purity seed sorter;current commercial optical sorting systems;desired seeds;unwanted seeds;mixed seed product;deep neural network;low-latency image-recognition","","","26","","","","","IEEE","IEEE Journals"
"Deep Convolutional Computation Model for Feature Learning on Big Data in Internet of Things","P. Li; Z. Chen; L. T. Yang; Q. Zhang; M. J. Deen","Key Laboratory for Ubiquitous Network and Service Software of Liaoning Province and the School of Software Technology, Dalian University of Technology, Dalian, China; Key Laboratory for Ubiquitous Network and Service Software of Liaoning Province and the School of Software Technology, Dalian University of Technology, Dalian, China; Department of Computer Science, St. Francis Xavier University, Antigonish, NS, Canada; Department of Computer Science, St. Francis Xavier University, Antigonish, NS, Canada; Department of Electrical and Computer Engineering, McMaster University, Hamilton, ON, Canada","IEEE Transactions on Industrial Informatics","","2018","14","2","790","798","Currently, a large number of industrial data, usually referred to big data, are collected from Internet of Things (IoT). Big data are typically heterogeneous, i.e., each object in big datasets is multimodal, posing a challenging issue on the convolutional neural network (CNN) that is one of the most representative deep learning models. In this paper, a deep convolutional computation model (DCCM) is proposed to learn hierarchical features of big data by using the tensor representation model to extend the CNN from the vector space to the tensor space. To make full use of the local features and topologies contained in the big data, a tensor convolution operation is defined to prevent overfitting and improve the training efficiency. Furthermore, a high-order backpropagation algorithm is proposed to train the parameters of the deep convolutional computational model in the high-order space. Finally, experiments on three datasets, i.e., CUAVE, SNAE2, and STL-10 are carried out to verify the performance of the DCCM. Experimental results show that the deep convolutional computation model can give higher classification accuracy than the deep computation model or the multimodal model for big data in IoT.","","","10.1109/TII.2017.2739340","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; Dalian University of Technology Fundamental Research Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8010374","Big data;convolutional neural network (CNN);deep convolutional computation model (DCCM);high-order backpropagation (HBP) algorithm;Internet of Things (IoT);tensor computation","Data models;Big Data;Computational modeling;Tensile stress;Neural networks;Machine learning;Feature extraction","backpropagation;convolution;feature extraction;feedforward neural nets;image classification;image representation;Internet of Things;tensors","industrial data;big datasets;representative deep learning models;deep convolutional computational model;Internet of Things;IoT;convolutional neural network;CNN;DCCM;hierarchical feature learning;local features;tensor convolution operation;high-order backpropagation algorithm;high-order space;classification accuracy;multimodal model","","27","25","","","","","IEEE","IEEE Journals"
"Multiscaled Fusion of Deep Convolutional Neural Networks for Screening Atrial Fibrillation From Single Lead Short ECG Recordings","X. Fan; Q. Yao; Y. Cai; F. Miao; F. Sun; Y. Li","Joint Engineering Research Center for Health Big Data Intelligent Analysis Technology, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Joint Engineering Research Center for Health Big Data Intelligent Analysis Technology, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Joint Engineering Research Center for Health Big Data Intelligent Analysis Technology, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Joint Engineering Research Center for Health Big Data Intelligent Analysis Technology, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Joint Engineering Research Center for Health Big Data Intelligent Analysis Technology, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Key Laboratory for Health Informatics of the Chinese Academy of Sciences, Shenzhen Institutes of advanced technology, Shenzhen, China","IEEE Journal of Biomedical and Health Informatics","","2018","22","6","1744","1753","Atrial fibrillation (AF) is one of the most common sustained chronic cardiac arrhythmia in elderly population, associated with a high mortality and morbidity in stroke, heart failure, coronary artery disease, systemic thromboembolism, etc. The early detection of AF is necessary for averting the possibility of disability or mortality. However, AF detection remains problematic due to its episodic pattern. In this paper, a multiscaled fusion of deep convolutional neural network (MS-CNN) is proposed to screen out AF recordings from single lead short electrocardiogram (ECG) recordings. The MS-CNN employs the architecture of two-stream convolutional networks with different filter sizes to capture features of different scales. The experimental results show that the proposed MS-CNN achieves 96.99% of classification accuracy on ECG recordings cropped/padded to 5 s. Especially, the best classification accuracy, 98.13%, is obtained on ECG recordings of 20 s. Compared with artificial neural network, shallow single-stream CNN, and VisualGeometry group network, the MS-CNN can achieve the better classification performance. Meanwhile, visualization of the learned features from the MS-CNN demonstrates its superiority in extracting linear separable ECG features without hand-craft feature engineering. The excellent AF screening performance of the MS-CNN can satisfy the most elders for daily monitoring with wearable devices.","","","10.1109/JBHI.2018.2858789","Major Special Project of Guangdong Province; Shenzhen Basic Research Projects; Guangdong Applied Special Project for Research and Development; Special Fund Project for Overseas High-level Talents Innovation and Entrepreneurship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8428414","Deep convolutional neural network;ECG;atrial fibrillation;deep learning;classification;biomedical monitoring","Electrocardiography;Convolutional neural networks;Feature extraction;Biomedical monitoring;Atrial fibrillation;Deep learning","blood vessels;cardiology;convolution;diseases;electrocardiography;feature extraction;feedforward neural nets;learning (artificial intelligence);medical signal processing;signal classification","AF detection;MS-CNN;single lead short electrocardiogram recordings;artificial neural network;linear separable ECG features;multiscaled fusion deep convolutional neural network;chronic cardiac arrhythmia;visualgeometry group network;screening atrial fibrillation","","8","32","","","","","IEEE","IEEE Journals"
"Improving Interpretability and Regularization in Deep Learning","C. Wu; M. J. F. Gales; A. Ragni; P. Karanasou; K. C. Sim","Department of Engineering, University of Cambridge, Cambridge, U.K.; Department of Engineering, University of Cambridge, Cambridge, U.K.; Department of Engineering, University of Cambridge, Cambridge, U.K.; Department of Engineering, University of Cambridge, Cambridge, U.K.; Google Inc., Mountain View, USA","IEEE/ACM Transactions on Audio, Speech, and Language Processing","","2018","26","2","256","265","Deep learning approaches yield state-of-the-art performance in a range of tasks, including automatic speech recognition. However, the highly distributed representation in a deep neural network (DNN) or other network variations is difficult to analyze, making further parameter interpretation and regularization challenging. This paper presents a regularization scheme acting on the activation function output to improve the network interpretability and regularization. The proposed approach, referred to as activation regularization, encourages activation function outputs to satisfy a target pattern. By defining appropriate target patterns, different learning concepts can be imposed on the network. This method can aid network interpretability and also has the potential to reduce overfitting. The scheme is evaluated on several continuous speech recognition tasks: the Wall Street Journal continuous speech recognition task, eight conversational telephone speech tasks from the IARPA Babel program and a U.S. English broadcast news task. On all the tasks, the activation regularization achieved consistent performance gains over the standard DNN baselines.","","","10.1109/TASLP.2017.2774919","Intelligence Advanced Research Projects Activity via Department of Defense U.S. Army Research Laboratory; Singapore Ministry of Education Academic Research Fund Tier 2; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8114209","Activation regularisation;interpretability;visualisation;neural network;deep learning","Training;Neural networks;Speech;Speech processing;Speech recognition;Transforms","learning (artificial intelligence);neural nets;speech recognition","activation regularization;automatic speech recognition;highly distributed representation;deep neural network;activation function output;network interpretability;target pattern;Wall Street Journal continuous speech recognition task;conversational telephone speech tasks;deep learning;English broadcast news task;IARPA Babel program","","2","43","Traditional","","","","IEEE","IEEE Journals"
"Deep Learning for an Effective Nonorthogonal Multiple Access Scheme","G. Gui; H. Huang; Y. Song; H. Sari","Nanjing University of Posts and Telecommunications, Nanjing, China; Nanjing University of Posts and Telecommunications, Nanjing, China; Nanjing University of Posts and Telecommunications, Nanjing, China; Nanjing University of Posts and Telecommunications, Nanjing, China","IEEE Transactions on Vehicular Technology","","2018","67","9","8440","8450","Nonorthogonal multiple access (NOMA) has been considered as an essential multiple access technique for enhancing system capacity and spectral efficiency in future communication scenarios. However, the existing NOMA systems have a fundamental limit: high computational complexity and a sharply changing wireless channel make exploiting the characteristics of the channel and deriving the ideal allocation methods very difficult tasks. To break this fundamental limit, in this paper, we propose a novel and effective deep learning (DL)-aided NOMA system, in which several NOMA users with random deployment are served by one base station. Since DL is advantageous in that it allows training the input signals and detecting sharply changing channel conditions, we exploit it to address wireless NOMA channels in an end-to-end manner. Specifically, it is employed in the proposed NOMA system to learn a completely unknown channel environment. A long short-term memory (LSTM) network based on DL is incorporated into a typical NOMA system, enabling the proposed scheme to detect the channel characteristics automatically. In the proposed strategy, the LSTM is first trained by simulated data under different channel conditions via offline learning, and then the corresponding output data can be obtained based on the current input data used during the online learning process. In general, we build, train and test the proposed cooperative framework to realize automatic encoding, decoding and channel detection in an additive white Gaussian noise channel. Furthermore, we regard one conventional user activity and data detection scheme as an unknown nonlinear mapping operation and use LSTM to approximate it to evaluate the data detection capacity of DL based on NOMA. Simulation results demonstrate that the proposed scheme is robust and efficient compared with conventional approaches. In addition, the accuracy of the LSTM-aided NOMA scheme is studied by introducing the well-known tenfold cross-validation procedure.","","","10.1109/TVT.2018.2848294","National Natural Science Foundation of China; Jiangsu Specially Appointed Professor; Innovation and Entrepreneurship of Jiangsu High-level Talent; 1311 Talent Plan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8387468","Non-orthogonal multiple access (NOMA);long short-term memory (LSTM);deep learning","NOMA;Machine learning;Resource management;Reliability;Wireless communication;Channel estimation;Training","AWGN channels;channel coding;computational complexity;decoding;learning (artificial intelligence);multi-access systems;telecommunication computing;wireless channels","offline learning;current input data;online learning process;additive white Gaussian noise channel;conventional user activity;data detection scheme;data detection capacity;LSTM-aided NOMA scheme;effective nonorthogonal multiple access scheme;essential multiple access technique;system capacity;spectral efficiency;future communication scenarios;high computational complexity;wireless channel;NOMA users;base station;input signals;wireless NOMA channels;end-to-end manner;completely unknown channel environment;short-term memory network;channel characteristics;channel conditions;NOMA systems;ideal allocation methods","","127","33","","","","","IEEE","IEEE Journals"
"Preprocessing-Free Gear Fault Diagnosis Using Small Datasets With Deep Convolutional Neural Network-Based Transfer Learning","P. Cao; S. Zhang; J. Tang","Department of Mechanical Engineering, University of Connecticut, Storrs, CT, USA; Stanley Black & Decker, Towson, MD, USA; Department of Mechanical Engineering, University of Connecticut, Storrs, CT, USA","IEEE Access","","2018","6","","26241","26253","Early diagnosis of gear transmission has been a significant challenge, because gear faults occur primarily at microstructure or even material level but their effects can only be observed indirectly at a system level. The performance of a gear fault diagnosis system depends significantly on the features extracted and the classifier subsequently applied. Traditionally, fault-related features are extracted and identified based on domain expertise through data preprocessing which are system-specific and may not be easily generalized. On the other hand, although recently the deep neural networks based approaches featuring adaptive feature extractions and inherent classifications have attracted attention, they usually require a substantial set of training data. Aiming at tackling these issues, this paper presents a deep convolutional neural network-based transfer learning approach. The proposed transfer learning architecture consists of two parts; the first part is constructed with a pre-trained deep neural network that serves to extract the features automatically from the input, and the second part is a fully connected stage to classify the features that needs to be trained using gear fault experimental data. Case analyses using experimental data from a benchmark gear system indicate that the proposed approach not only entertains preprocessing free adaptive feature extractions, but also requires only a small set of training data.","","","10.1109/ACCESS.2018.2837621","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8360102","Alexnet;deep convolutional neural network;gear fault diagnosis;transfer learning","Gears;Feature extraction;Fault diagnosis;Convolution;Convolutional neural networks;Vibrations","convolution;fault diagnosis;feature extraction;feedforward neural nets;gears;learning (artificial intelligence);mechanical engineering computing;pattern classification;power transmission (mechanical)","deep convolutional neural network;gear transmission;gear faults;material level;system level;gear fault diagnosis system;fault-related features;data preprocessing;transfer learning approach;transfer learning architecture;free adaptive feature extractions;gear system;classifier;classifications","","14","39","","","","","IEEE","IEEE Journals"
"Deep learning based RF fingerprinting for device identification and wireless security","Q. Wu; C. Feres; D. Kuzmenko; D. Zhi; Z. Yu; X. Liu; X. Liu","University of California, USA; University of California, USA; University of California, USA; University of California, USA; University of California, USA; University of California, USA; Univ. of California, Davis, Davis, CA, USA","Electronics Letters","","2018","54","24","1405","1407","RF fingerprinting is an emerging technology for identifying hardware-specific features of wireless transmitters and may find important applications in wireless security. In this study, the authors present a new RF fingerprinting scheme using deep neural networks. In particular, a long short-term memory based recurrent neural network is proposed and used for automatically identifying hardware-specific features and classifying transmitters. Experimental studies using identical RF transmitters showed very high detection accuracy in the presence of strong noise (signal-to-noise ratio as low as -12 dB) and demonstrated the effectiveness of the proposed scheme.","","","10.1049/el.2018.6404","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8556574","","","learning (artificial intelligence);radio transmitters;recurrent neural nets;telecommunication security;wireless channels","deep learning;RF fingerprinting;device identification;wireless security;hardware-specific features;wireless transmitters;deep neural networks;short-term memory;recurrent neural network;identical RF transmitters","","2","","","","","","IET","IET Journals"
"Datanet: Deep Learning Based Encrypted Network Traffic Classification in SDN Home Gateway","P. Wang; F. Ye; X. Chen; Y. Qian","Department of Modern Posts, Nanjing University of Posts and Telecommunications, Nanjing, China; Department of Electrical and Computer Engineering, University of Dayton, Dayton, OH, USA; School of Communication, Nanjing College of Information Technology, Nanjing, China; Department of Electrical and Computer Engineering, University of Nebraska–Lincoln, Omaha, NE, USA","IEEE Access","","2018","6","","55380","55391","A smart home network will support various smart devices and applications, e.g., home automation devices, E-health devices, regular computing devices, and so on. Most devices in a smart home access the Internet through a home gateway (HGW). In this paper, we propose a software-definednetwork (SDN)-HGW framework to better manage distributed smart home networks and support the SDN controller of the core network. The SDN controller enables efficient network quality-of-service management based on real-time traffic monitoring and resource allocation of the core network. However, it cannot provide network management in distributed smart homes. Our proposed SDN-HGW extends the control to the access network, i.e., a smart home network, for better end-to-end network management. Specifically, the proposed SDN-HGW can achieve distributed application awareness by classifying data traffic in a smart home network. Most existing traffic classification solutions, e.g., deep packet inspection, cannot provide real-time application awareness for encrypted data traffic. To tackle those issues, we develop encrypted data classifiers (denoted as DataNets) based on three deep learning schemes, i.e., multilayer perceptron, stacked autoencoder, and convolutional neural networks, using an open data set that has over 200 000 encrypted data samples from 15 applications. A data preprocessing scheme is proposed to process raw data packets and the tested data set so that DataNet can be created. The experimental results show that the developed DataNets can be applied to enable distributed application-aware SDN-HGW in future smart home networks.","","","10.1109/ACCESS.2018.2872430","2016 Jiangsu Provincial Government Scholarship Program, China; 2017 Jiangsu Overseas Visiting Scholar Program for University Prominent Young & Middle-Aged Teachers and Presidents, China; Top-Notch Academic Programs Project of Jiangsu Higher Education Institutions; National Natural Science Foundation of China; Natural Science Foundation of Jiangsu Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8473682","Encrypted traffic classification;home gateway;distributed network management;deep learning;SDN","Smart homes;Cryptography;Machine learning;Quality of service;Logic gates;Smart devices","computer network management;convolution;cryptography;home automation;Internet;internetworking;learning (artificial intelligence);multilayer perceptrons;pattern classification;quality of service;resource allocation;software defined networking;telecommunication traffic","smart devices;home automation devices;smart home access;SDN controller;network quality-of-service management;distributed smart homes;access network;end-to-end network management;convolutional neural networks;distributed application-aware SDN-HGW;SDN home gateway;stacked autoencoder;multilayer perceptron;encrypted data classifiers;resource allocation;real-time traffic monitoring;distributed smart home networks;Internet;home gateway;deep learning based encrypted network traffic classification;Datanet;software-defined network-HGW framework","","9","49","","","","","IEEE","IEEE Journals"
"Deep Feature Alignment Neural Networks for Domain Adaptation of Hyperspectral Data","X. Zhou; S. Prasad","Department of Electrical and Computer Engineering, Hyperspectral Image Analysis Group, University of Houston, Houston, TX, USA; Department of Electrical and Computer Engineering, Hyperspectral Image Analysis Group, University of Houston, Houston, TX, USA","IEEE Transactions on Geoscience and Remote Sensing","","2018","56","10","5863","5872","Deep neural networks have been shown to be useful for the classification of hyperspectral images, particularly when a large amount of labeled data is available. However, we may not have enough reference data to train a deep neural network for many practical geospatial image analysis applications. To address this issue, in this paper, we propose to use a deep feature alignment neural network to carry out the domain adaptation, where the labeled data from a supplementary data source can be utilized to improve the classification performance in a domain where otherwise limited labeled data are available. In the proposed model, discriminative features for the source and target domains are first extracted using deep convolutional recurrent neural networks and then aligned with each other layer-by-layer by mapping features from each layer to transformed common subspaces at each layer. Experimental results are presented with two data sets. One of these data sets represents domain adaptation between images acquired at different times, while the other data set represents a very unique and challenging domain adaptation problem, representing source and target images that are acquired using different hyperspectral imagers that collect data from different viewpoints and platforms (a ground-based forward-looking street view of objects acquired at the close range and an aerial hyperspectral image). We demonstrate that the proposed deep learning framework enables the robust classification of the target domain data by leveraging information from the source domain.","","","10.1109/TGRS.2018.2827308","National Aeronautics and Space Administration; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8356196","Classification;deep neural network;domain adaptation;hyperspectral;transformation learning","Feature extraction;Hyperspectral imaging;Neural networks;Adaptation models;Training data;Machine learning","convolution;feature extraction;feedforward neural nets;geophysical image processing;hyperspectral imaging;image classification;learning (artificial intelligence);recurrent neural nets","deep feature alignment neural networks;domain adaptation;classification performance;target domains extraction;geospatial image analysis applications;hyperspectral images;hyperspectral data;source domain;target domain data;deep learning framework;target images;deep convolutional recurrent neural networks;supplementary data source","","2","42","","","","","IEEE","IEEE Journals"
"Exploring Hierarchical Convolutional Features for Hyperspectral Image Classification","G. Cheng; Z. Li; J. Han; X. Yao; L. Guo","School of Automation, Northwestern Polytechnical University, Xi’an, China; School of Automation, Northwestern Polytechnical University, Xi’an, China; School of Automation, Northwestern Polytechnical University, Xi’an, China; School of Automation, Northwestern Polytechnical University, Xi’an, China; School of Automation, Northwestern Polytechnical University, Xi’an, China","IEEE Transactions on Geoscience and Remote Sensing","","2018","56","11","6712","6722","Hyperspectral image (HSI) classification is an active and important research task driven by many practical applications. To leverage deep learning models especially convolutional neural networks (CNNs) for HSI classification, this paper proposes a simple yet effective method to extract hierarchical deep spatial feature for HSI classification by exploring the power of off-the-shelf CNN models, without any additional retraining or fine-tuning on the target data set. To obtain better classification accuracy, we further propose a unified metric learning-based framework to alternately learn discriminative spectral-spatial features, which have better representation capability and train support vector machine (SVM) classifiers. To this end, we design a new objective function that explicitly embeds a metric learning regularization term into SVM training. The metric learning regularization term is used to learn a powerful spectral-spatial feature representation by fusing spectral feature and deep spatial feature, which has small intraclass scatter but big between class separation. By transforming HSI data into new spectral-spatial feature space through CNN and metric learning, we can pull the pixels from the same class closer, while pushing the different class pixels farther away. In the experiments, we comprehensively evaluate the proposed method on three commonly used HSI benchmark data sets. State-of-the-art results are achieved when compared with the existing HSI classification methods.","","","10.1109/TGRS.2018.2841823","National Natural Science Foundation of China; National Aerospace Science Foundation of China; Fundamental Research Funds for the Central Universities; Science and Technology Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8393448","Convolutional neural networks (CNNs);deep learning;hyperspectral image (HSI) classification;metric learning;spectral–spatial feature","Feature extraction;Measurement;Support vector machines;Training;Machine learning;Semantics;Hyperspectral imaging","feature extraction;geophysical image processing;hyperspectral imaging;image classification;image recognition;learning (artificial intelligence);neural nets;object detection;support vector machines","hierarchical convolutional features;hyperspectral image classification;practical applications;convolutional neural networks;hierarchical deep spatial feature;off-the-shelf CNN models;classification accuracy;unified metric learning-based framework;representation capability;metric learning regularization term;SVM training;spectral feature;HSI data;benchmark data sets;target data set;spectral-spatial feature representation;HSI classification methods;spectral-spatial feature space;discriminative spectral-spatial features;deep learning models","","20","61","","","","","IEEE","IEEE Journals"
"Deep Salient Object Detection With Dense Connections and Distraction Diagnosis","H. Xiao; J. Feng; Y. Wei; M. Zhang; S. Yan","College of Information System and Management, National University of Defense Technology, Changsha, China; Department of Electrical and Computer Engineering, National University of Singapore, Singapore; Beckman Institute, University of Illinois at Urbana-Champaign, Urbana, IL, USA; College of Information System and Management, National University of Defense Technology, Changsha, China; Department of Electrical and Computer Engineering, National University of Singapore, Singapore","IEEE Transactions on Multimedia","","2018","20","12","3239","3251","In this paper, we propose two novel components for improving deep salient object detection models. The first component, called saliency detection network (S-Net), introduces dense short- and long-range connections that effectively integrate multiscale features to better exploit contexts at multiple levels. Benefiting from the direct access to low- and high-level features, the S-Net can not only exploit the object context but also preserve the object boundary sharply, leading to enhanced saliency detection performance. Second, a distraction detection network (D-Net) is developed to learn to diagnose which regions of an input image are distracting and harmful for saliency prediction of the S-Net. With such distraction diagnosis, the regions that are distracting to S-Net are removed in hindsight from the input image and the resulted distraction-free image is fed to S-Net for saliency prediction. To train the D-Net, a distraction mining approach is proposed to localize the model-specific distracting regions through examining the sensitiveness of the S-Net to image regions in a principled manner. Besides, the distraction mining approach also provides a way to interpret decisions made by deep neural network (DNN) saliency detection models, which relieves the black-box issues of DNNs to some extent. Extensive experiments on seven popular benchmark datasets demonstrate the effectiveness of the combined S-Net and D-Net, which provides new state of the arts.","","","10.1109/TMM.2018.2830098","China Scholarship Council; NUS startup; MOE; NUS IDS; ECRA; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8350300","Neural networks;deep learning;salient object detection;model interpretability","Saliency detection;Object detection;Feature extraction;Image segmentation;Computational modeling;Deep learning;Neural networks","learning (artificial intelligence);neural nets;object detection","distraction-free image;combined S-Net;deep neural network saliency detection models;image regions;model-specific distracting regions;distraction mining approach;saliency prediction;input image;distraction detection network;enhanced saliency detection performance;object boundary;object context;high-level features;multiscale features;long-range connections;deep salient object detection models;distraction diagnosis;dense connections","","2","53","","","","","IEEE","IEEE Journals"
"Intelligent Power Control for Spectrum Sharing in Cognitive Radios: A Deep Reinforcement Learning Approach","X. Li; J. Fang; W. Cheng; H. Duan; Z. Chen; H. Li","National Key Laboratory of Science and Technology on Communications, University of Electronic Science and Technology of China, Chengdu, China; National Key Laboratory of Science and Technology on Communications, University of Electronic Science and Technology of China, Chengdu, China; National Key Laboratory of Science and Technology on Communications, University of Electronic Science and Technology of China, Chengdu, China; School of Electronic Engineering, University of Electronic Science and Technology of China, Chengdu, China; National Key Laboratory of Science and Technology on Communications, University of Electronic Science and Technology of China, Chengdu, China; Department of Electrical and Computer Engineering, Stevens Institute of Technology, Hoboken, NJ, USA","IEEE Access","","2018","6","","25463","25473","We consider the problem of spectrum sharing in a cognitive radio system consisting of a primary user and a secondary user. The primary user and the secondary user work in a non-cooperative manner. Specifically, the primary user is assumed to update its transmitted power based on a pre-defined power control policy. The secondary user does not have any knowledge about the primary user's transmit power, or its power control strategy. The objective of this paper is to develop a learning-based power control method for the secondary user in order to share the common spectrum with the primary user. To assist the secondary user, a set of sensor nodes are spatially deployed to collect the received signal strength information at different locations in the wireless environment. We develop a deep reinforcement learning-based method, which the secondary user can use to intelligently adjust its transmit power such that after a few rounds of interaction with the primary user, both users can transmit their own data successfully with required qualities of service. Our experimental results show that the secondary user can interact with the primary user efficiently to reach a goal state (defined as a state in which both users can successfully transmit their data) from any initial states within a few number of steps.","","","10.1109/ACCESS.2018.2831240","National Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8352517","Spectrum sharing;power control;cognitive radio;deep reinforcement learning","Power control;Interference;Receivers;Cognitive radio;Signal to noise ratio;Machine learning;Quality of service","cognitive radio;intelligent control;learning (artificial intelligence);quality of service;radio networks;telecommunication control","received signal strength information;deep reinforcement learning-based method;wireless environment;cognitive radio system;secondary user;power control method;power control strategy;power control policy;transmitted power;primary user;spectrum sharing;intelligent power control","","18","40","","","","","IEEE","IEEE Journals"
"A Highly Accurate Deep Learning Based Approach for Developing Wireless Sensor Network Middleware","R. A. Alshinina; K. M. Elleithy","Department of Computer Science and Engineering, University of Bridgeport, Bridgeport, CT, USA; Department of Computer Science and Engineering, University of Bridgeport, Bridgeport, CT, USA","IEEE Access","","2018","6","","29885","29898","Despite the popularity of wireless sensor networks (WSNs) in a wide range of applications, security problems associated with them have not been completely resolved. Middleware is generally introduced as an intermediate layer between WSNs and the end user to resolve some limitations, but most of the existing middleware is unable to protect data from malicious and unknown attacks during transmission. This paper introduces a secure wireless sensor network middleware (SWSNM) based on an unsupervised learning technique called generative adversarial network algorithm. SWSNM consists of two networks: a generator (G) network and a discriminator (D) network. The G creates fake data that are similar to the real sample and combines it with real data from the sensors to confuse the attacker. The D contains multi-layers that have the ability to differentiate between real and fake data. The output intended for this algorithm shows an actual interpretation of the data that is securely communicated through the WSN. The framework is implemented in Python with experiments performed using Keras. Results illustrate that SWSNM algorithm improves the accuracy of the data and enhances its security by protecting data from adversaries. In addition, the SWSNM algorithm consumes significantly less energy, has higher throughput, and lower end-to-end delay when compared with a similar conventional approach.","","","10.1109/ACCESS.2018.2844255","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8373695","Middleware;unsupervised learning;WSNs;generator;discriminator;visualization;confusion matrix;security;GANs;energy consumption;delay","Wireless sensor networks;Middleware;Security;Sensors;Machine learning algorithms;Machine learning;Support vector machines","data protection;middleware;unsupervised learning;wireless sensor networks","secure wireless sensor network middleware;generative adversarial network algorithm;generator network;discriminator network;fake data;SWSNM algorithm;malicious attacks;unknown attacks;unsupervised learning;data security;data protection;deep learning","","","58","","","","","IEEE","IEEE Journals"
"Deep Domain Generalization With Structured Low-Rank Constraint","Z. Ding; Y. Fu","Department of Electrical and Computer Engineering, Northeastern University, Boston, MA, USA; Department of Electrical and Computer Engineering, College of Computer and Information Science, Northeastern University, Boston, MA, USA","IEEE Transactions on Image Processing","","2018","27","1","304","313","Domain adaptation nowadays attracts increasing interests in pattern recognition and computer vision field, since it is an appealing technique in fighting off weakly labeled or even totally unlabeled target data by leveraging knowledge from external well-learned sources. Conventional domain adaptation assumes that target data are still accessible in the training stage. However, we would always confront such cases in reality that the target data are totally blind in the training stage. This is extremely challenging since we have no prior knowledge of the target. In this paper, we develop a deep domain generalization framework with structured low-rank constraint to facilitate the unseen target domain evaluation by capturing consistent knowledge across multiple related source domains. Specifically, multiple domain-specific deep neural networks are built to capture the rich information within multiple sources. Meanwhile, a domain-invariant deep neural network is jointly designed to uncover most consistent and common knowledge across multiple sources so that we can generalize it to unseen target domains in the test stage. Moreover, structured low-rank constraint is exploited to align multiple domain-specific networks and the domain-invariant one in order to better transfer knowledge from multiple sources to boost the learning problem in unseen target domains. Extensive experiments are conducted on several cross-domain benchmarks and the experimental results show the superiority of our algorithm by comparing it with state-of-the-art domain generalization approaches.","","","10.1109/TIP.2017.2758199","NSF IIS; ONR Young Investigator; U.S. Army Research Office; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8053784","Domain generalization;deep learning;low-rank constraint","Training;Feature extraction;Machine learning;Neural networks;Knowledge engineering;Data models","computer vision;learning (artificial intelligence);neural nets","domain generalization approaches;totally unlabeled target data;knowledge leverage;knowledge transfer;multiple domain-specific network alignment;learning problem;common knowledge;domain-invariant deep neural network;multiple domain-specific deep neural networks;multiple related source domains;consistent knowledge;unseen target domain evaluation;deep domain generalization framework;training stage;conventional domain adaptation;weakly labeled target data;computer vision field;pattern recognition;structured low-rank constraint;cross-domain benchmarks;unseen target domains","","9","50","","","","","IEEE","IEEE Journals"
"Hidden variability subspace learning for adaptation of deep neural networks","S. Fernando; V. Sethu; E. Ambikairajah","UNSW, Australia; UNSW, Australia; UNSW, Australia","Electronics Letters","","2018","54","3","173","175","This Letter proposes a deep neural network (DNN) adaptation method, herein referred to as the hidden variability subspace (HVS) method, to achieve improved robustness under diverse acoustic environments arising due to differences in conditions, e.g. speaker, channel, duration and environmental noise. In the proposed approach, a set of condition-dependent parameters is estimated to adapt the hidden layer weights of the DNN in the HVS to reduce the condition mismatch. These condition-dependent parameters are then connected to various layers through a new set of adaptively trained weights. The authors evaluate the proposed hidden variability learning method on a language identification task and show that significant performance gains can be obtained by discriminatively estimating a set of adaptation parameters to compensate the mismatch in the trained model.","","","10.1049/el.2017.4027","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8282755","","","learning (artificial intelligence);neural nets;speech processing","hidden variability subspace learning;deep neural networks;DNN adaptation method;HVS method;improved robustness;diverse acoustic environment;environmental noise;condition-dependent parameters;hidden layer weights;adaptively-trained weights;language identification task;adaptation parameters;trained model;speech utterance","","2","10","","","","","IET","IET Journals"
"Sparsity-Constrained Deep Nonnegative Matrix Factorization for Hyperspectral Unmixing","H. Fang; A. Li; H. Xu; T. Wang","Xi’an Research Institute of High Technology, Xi’an, China; Xi’an Research Institute of High Technology, Xi’an, China; Department of Electronic Information, Huanggang Normal University, Huanggang, China; Xi’an Research Institute of High Technology, Xi’an, China","IEEE Geoscience and Remote Sensing Letters","","2018","15","7","1105","1109","Nonnegative matrix factorization (NMF) has been widely used in hyperspectral unmixing (HU). However, most NMF-based methods have single-layer structures, which may achieve poor performance for complex data. Deep learning, with its carefully designed hierarchical structure, has shown great advantages in learning data features. In this letter, we design a deep NMF structure by unfolding NMF into multilayers and present a sparsity-constrained deep NMF method for HU. In each layer, the abundance matrix is directly decomposed into the abundance matrix and endmember matrix of the next layer. Due to the nonconvexity of the NMF model, sparsity constraint is added to each layer using a L1 regularizer of the abundance matrix on each layer. To get better initial parameters for the deep NMF network, a layer-wise pretraining strategy based on Nesterov's accelerated gradient algorithm is put forward to initialize the network. An alternative update method is also proposed to further fine-tune the network to get final decomposition results. The experimental results based on synthetic data and real data demonstrate that the proposed method outperforms several other state-of-the-art unmixing approaches.","","","10.1109/LGRS.2018.2823425","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8347076","Deep network;hyperspectral imagery;nonnegative matrix factorization (NMF);sparsity constraint;spectral unmixing","Matrix decomposition;Hyperspectral imaging;Nonhomogeneous media;Sparse matrices;Machine learning;Optimization","geophysical image processing;gradient methods;hyperspectral imaging;learning (artificial intelligence);matrix decomposition","sparsity-constrained deep nonnegative matrix factorization;Nesterov's accelerated gradient algorithm;NMF model;endmember matrix;deep NMF method;deep NMF structure;deep learning;single-layer structures;hyperspectral unmixing;layer-wise pretraining strategy;deep NMF network;abundance matrix;sparsity constraint","","","22","","","","","IEEE","IEEE Journals"
"Supervised Hash Coding With Deep Neural Network for Environment Perception of Intelligent Vehicles","C. Yan; H. Xie; D. Yang; J. Yin; Y. Zhang; Q. Dai","Institute of Information and Control, Hangzhou Dianzi University, Hangzhou, China; School of Information Science and Technology, University of Science and Technology of China, Hefei, China; National Engineering Laboratory for Information Security Technologies, Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; School of Mechanical, Electrical and Information Engineering, Shandong University, Weihai, China; School of Information Science and Technology, University of Science and Technology of China, Hefei, China; Department of Automation, Tsinghua University, Beijing, China","IEEE Transactions on Intelligent Transportation Systems","","2018","19","1","284","295","Image content analysis is an important surround perception modality of intelligent vehicles. In order to efficiently recognize the on-road environment based on image content analysis from the large-scale scene database, relevant images retrieval becomes one of the fundamental problems. To improve the efficiency of calculating similarities between images, hashing techniques have received increasing attentions. For most existing hash methods, the suboptimal binary codes are generated, as the hand-crafted feature representation is not optimally compatible with the binary codes. In this paper, a one-stage supervised deep hashing framework (SDHP) is proposed to learn high-quality binary codes. A deep convolutional neural network is implemented, and we enforce the learned codes to meet the following criterions: 1) similar images should be encoded into similar binary codes, and vice versa; 2) the quantization loss from Euclidean space to Hamming space should be minimized; and 3) the learned codes should be evenly distributed. The method is further extended into SDHP+ to improve the discriminative power of binary codes. Extensive experimental comparisons with state-of-the-art hashing algorithms are conducted on CIFAR-10 and NUS-WIDE, the MAP of SDHP reaches to 87.67% and 77.48% with 48 b, respectively, and the MAP of SDHP+ reaches to 91.16%, 81.08% with 12 b, 48 b on CIFAR-10 and NUS-WIDE, respectively. It illustrates that the proposed method can obviously improve the search accuracy.","","","10.1109/TITS.2017.2749965","National Nature Science Foundation of China; Zhejiang Province Nature Science Foundation of China; Youth Innovation Promotion Association Chinese Academy of Sciences; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8058003","Intelligent vehicles;binary codes;supervised hashing;image retrieval;deep learning","Binary codes;Semantics;Quantization (signal);Neural networks;Machine learning;Intelligent vehicles;Image retrieval","binary codes;feature extraction;file organisation;image classification;image coding;image representation;image retrieval;learning (artificial intelligence)","supervised deep hashing framework;surround perception modality;hash methods;image retrieval;hashing algorithms;binary codes;deep convolutional neural network;high-quality binary codes;suboptimal binary codes;large-scale scene database;on-road environment;image content analysis;intelligent vehicles;deep neural network;hash coding;SDHP;learned codes","","38","48","","","","","IEEE","IEEE Journals"
"Sentiment Classification Based on Information Geometry and Deep Belief Networks","M. Wang; Z. Ning; C. Xiao; T. Li","Faculty of Information Technology, Beijing University of Technology, Beijing, China; Faculty of Information Technology, Beijing University of Technology, Beijing, China; Faculty of Information Technology, Beijing University of Technology, Beijing, China; Faculty of Information Technology, Beijing University of Technology, Beijing, China","IEEE Access","","2018","6","","35206","35213","Sentiment classification for reviews has attracted increasingly more attention from the natural language processing community. By embedding prior knowledge into learning structures, classifiers often achieve a better performance than original methods. In this paper, we propose a sophisticated algorithm based on deep learning and information geometry in which the distribution of all training samples in the space is treated as prior knowledge and is encoded by deep belief networks (DBNs). From the view of information geometry, we construct the geodesic distance between the distributions over the features for classification. The study of the distributions contributes to the training of the DBN, since the distance is correlated to the error rate in the classification. Finally, we evaluate our proposal using empirical data sets that are dedicated for sentiment classification. The results show that our algorithm results in a significant improvement over existing methods.","","","10.1109/ACCESS.2018.2848298","Beijing Council of Science and Technology; Natural Science Foundation of Beijing Municipality; National Natural Science Foundation of China; National Natural Science Foundation of China; Beijing Postdoctoral Research Foundation; Beijing Science CCF-Venustech Open Research Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8387737","Information geometry;neural networks;semi-supervised learning;sentiment classification","Training;Information geometry;Supervised learning;Natural language processing;Classification algorithms;Unsupervised learning;Semantics","belief networks;geometry;learning (artificial intelligence);natural language processing;pattern classification;sentiment analysis","sentiment classification;information geometry;deep belief networks;increasingly more attention;natural language processing community;prior knowledge;learning structures;original methods;deep learning;training samples;DBN","","3","45","","","","","IEEE","IEEE Journals"
"DeepCAS: A Deep Reinforcement Learning Algorithm for Control-Aware Scheduling","B. Demirel; A. Ramaswamy; D. E. Quevedo; H. Karl","Scania CV AB, Autonomous Motion, ATS Pre-Development and Research, Stockholm, Sweden; Faculty of Computer Science, Electrical Engineering and Mathematics, Paderborn University, Paderborn, Germany; Faculty of Computer Science, Electrical Engineering and Mathematics, Paderborn University, Paderborn, Germany; Faculty of Computer Science, Electrical Engineering and Mathematics, Paderborn University, Paderborn, Germany","IEEE Control Systems Letters","","2018","2","4","737","742","We consider networked control systems consisting of multiple independent controlled subsystems, operating over a shared communication network. Such systems are ubiquitous in cyber-physical systems, Internet of Things, and large-scale industrial systems. In many large-scale settings, the size of the communication network is smaller than the size of the system. In consequence, scheduling issues arise. The main contribution of this letter is to develop a deep reinforcement learning-based control-aware scheduling (DEEPCAS) algorithm to tackle these issues. We use the following (optimal) design strategy: first, we synthesize an optimal controller for each subsystem; next, we design a learning algorithm that adapts to the chosen subsystems (plants) and controllers. As a consequence of this adaptation, our algorithm finds a schedule that minimizes the control loss. We present empirical results to show that DEEPCAS finds schedules with better performance than periodic ones.","","","10.1109/LCSYS.2018.2847721","German Research Foundation through Priority Programme 1914 Cyber-Physical Networking; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8386658","Deep learning;reinforcement learning;optimal control;networked control systems;scheduling;communication","Intelligent sensors;Kalman filters;Communication networks;Optimal scheduling;Networked control systems;Schedules","control engineering computing;learning (artificial intelligence);networked control systems;optimal control;scheduling","deep reinforcement learning-based control-aware scheduling algorithm;DEEPCAS;optimal controller;networked control systems;multiple independent controlled subsystems;shared communication network;cyber-physical systems;large-scale industrial systems;Internet of things","","2","16","","","","","IEEE","IEEE Journals"
"Short-Term Wind Speed Forecasting via Stacked Extreme Learning Machine With Generalized Correntropy","X. Luo; J. Sun; L. Wang; W. Wang; W. Zhao; J. Wu; J. Wang; Z. Zhang","School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China; School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China; School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China; School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China; Department of Electrical Engineering and Computer Science, Cleveland State University, Cleveland, OH, USA; Department of Electrical Engineering, Universidad de Chile, Santiago, Chile; Department of Computer Science and Information Engineering, National Taipei University of Technology, Taipei, Taiwan; School of Data Science, City University of Hong Kong, Hong Kong","IEEE Transactions on Industrial Informatics","","2018","14","11","4963","4971","Recently, wind speed forecasting as an effective computing technique plays an important role in advancing industry informatics, while dealing with these issues of control and operation for renewable power systems. However, it is facing some increasing difficulties to handle the large-scale dataset generated in these forecasting applications, with the purpose of ensuring stable computing performance. In response to such limitation, this paper proposes a more practical approach through the combination of extreme-learning machine (ELM) method and deep-learning model. ELM is a novel computing paradigm that enables the neural network (NN) based learning to be achieved with fast training speed and good generalization performance. The stacked ELM (SELM) is an advanced ELM algorithm under deep-learning framework, which works efficiently on memory consumption decrease. In this paper, an enhanced SELM is accordingly developed via replacing the Euclidean norm of the mean square error (MSE) criterion in ELM with the generalized correntropy criterion to further improve the forecasting performance. The advantage of the enhanced SELM with generalized correntropy to achieve better forecasting performance mainly relies on the following aspect. Generalized correntropy is a stable and robust nonlinear similarity measure while employing machine learning method to forecast wind speed, where the outliers may exist in some industrially measured values. Specifically, the experimental results of short-term and ultra-short-term forecasting on real wind speed data show that the proposed approach can achieve better computing performance compared with other traditional and more recent methods.","","","10.1109/TII.2018.2854549","National Key Research and Development Program of China; National Natural Science Foundation of China; University of Science and Technology Beijing—National Taipei University of Technology Joint Research Program; Fundamental Research Funds for the Central Universities; Foundation from the National Taipei University of Technology of Taiwan; Chile CONICYT FONDECYT (Regular) Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8408773","Autoencoder;generalized correntropy;stacked extreme learning machine (SELM);wind speed forecasting","Forecasting;Wind speed;Autoregressive processes;Computational modeling;Informatics;Machine learning;Predictive models","feedforward neural nets;learning (artificial intelligence);mean square error methods;power engineering computing;wind power plants","short-term wind speed forecasting;stacked extreme learning machine;effective computing technique;industry informatics;renewable power systems;large-scale dataset;stable computing performance;deep-learning model;computing paradigm;stacked ELM;advanced ELM algorithm;deep-learning framework;enhanced SELM;mean square error criterion;generalized correntropy criterion;stable similarity measure;robust nonlinear similarity measure;ultra-short-term forecasting;wind speed data;memory consumption;neural network based learning;NN based learning;MSE criterion;machine learning method","","13","24","","","","","IEEE","IEEE Journals"
"Effective Feature Extraction via Stacked Sparse Autoencoder to Improve Intrusion Detection System","B. Yan; G. Han","National Digital Switching System Engineering & Technology Research Center, Zhengzhou, China; National Digital Switching System Engineering & Technology Research Center, Zhengzhou, China","IEEE Access","","2018","6","","41238","41248","Classification features are crucial for an intrusion detection system (IDS), and the detection performance of IDS will change dramatically when providing different input features. Moreover, the large number of network traffic and their high-dimensional features will result in a very lengthy classification process. Recently, there is an increasing interest in the application of deep learning approaches for classification and learn feature representations. So, in this paper, we propose using the stacked sparse autoencoder (SSAE), an instance of a deep learning strategy, to extract high-level feature representations of intrusive behavior information. The original classification features are introduced into SSAE to learn the deep sparse features automatically for the first time. Then, the low-dimensional sparse features are used to build different basic classifiers. We compare SSAE with other feature extraction methods proposed by previous researchers. The experimental results both in binary classification and multiclass classification indicate the following: 1) the high-dimensional sparse features learned by SSAE are more discriminative for intrusion behaviors compared to previous methods and 2) the classification process of basic classifiers is significantly accelerated by using high-dimensional sparse features. In summary, it is shown that the SSAE is a feasible and efficient feature extraction method and provides a new research method for intrusion detection.","","","10.1109/ACCESS.2018.2858277","National Science Technology Major Project of China; National Natural Science Foundation of China; National Natural Science Foundation Innovation Group Project of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8418451","Intrusion detection;deep learning;machine learning;SSAE;feature extraction","Feature extraction;Intrusion detection;Machine learning;Machine learning algorithms;Anomaly detection","feature extraction;learning (artificial intelligence);pattern classification;security of data","SSAE;feature extraction methods;binary classification;multiclass classification;high-dimensional sparse features;stacked sparse autoencoder;intrusion detection system;IDS;lengthy classification process;deep learning approaches;high-level feature representations;intrusive behavior information;deep sparse features;low-dimensional sparse features","","4","31","","","","","IEEE","IEEE Journals"
"Learning Multi-Instance Deep Ranking and Regression Network for Visual House Appraisal","X. Liu; Q. Xu; J. Yang; J. Thalman; S. Yan; J. Luo","Department of Computer Science, San Diego State University (SDSU), San Diego, CA; XreLab Inc., San Diego, CA; Department of Computer Science, San Diego State University (SDSU), San Diego, CA; Department of Computer Science, San Diego State University (SDSU), San Diego, CA; Qihoo/360 Company, Beijing, China; Department of Computer Science, University of Rochester, Rochester, NY","IEEE Transactions on Knowledge and Data Engineering","","2018","30","8","1496","1506","This paper presents a weakly supervised regression model for the visual house appraisal problem, which aims to predict the value of a house from its photos and textual descriptions (e.g., number of bedrooms). The key idea of our approach is a multi-layer neural network, called multi-instance Deep Ranking and Regression (MiDRR) net, which jointly solves two coupled tasks: ranking and regression, in the multiple instance setting. The network is trained using weakly supervised data, which do not require intensive human annotations. We also design a set of human heuristics to promote deep features through imposing constraints over the solution space, e.g., a house with three bedrooms often has a higher value than that with only two bedrooms. While these constraints are specific to the studied problem, the developed formula can be easily generalized to the other regression applications. For test and evaluation purposes, we collect a comprehensive house image benchmark that includes 900,000 photos from 30,000 houses recently traded in the USA, and apply the proposed MiDRR net to predict house values. Extensive evaluations with comparisons demonstrate that additional usage of imagery data as well as human heuristics can significantly boost system performance and that the proposed MiDRR net clearly outperforms the alternative methods.","","","10.1109/TKDE.2018.2791611","NSF; DARPA SIMPLEX; ONR; Goergen Institute for Data Science; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8253468","Deep learning;ranking;regression;social network;multi-instance learning;house photos","Appraisal;Visualization;Neural networks;Convolution;Boosting;Image retrieval","image processing;learning (artificial intelligence);neural nets;property market;regression analysis","weakly supervised regression model;visual house appraisal problem;textual descriptions;bedrooms;multilayer neural network;multiple instance setting;weakly supervised data;intensive human annotations;human heuristics;deep features;higher value;studied problem;regression applications;comprehensive house image benchmark;MiDRR net;house values;USA;multi-instance Deep Ranking and Regression","","1","41","","","","","IEEE","IEEE Journals"
"Deep Learning-Based Intrusion Detection With Adversaries","Z. Wang","National Institute of Standards and Technology, Gaithersburg, MD, USA","IEEE Access","","2018","6","","38367","38384","Deep neural networks have demonstrated their effectiveness in most machine learning tasks, with intrusion detection included. Unfortunately, recent research found that deep neural networks are vulnerable to adversarial examples in the image classification domain, i.e., they leave some opportunities for an attacker to fool the networks into misclassification by introducing imperceptible changes to the original pixels in an image. The vulnerability raises some concerns in applying deep neural networks in security-critical areas, such as intrusion detection. In this paper, we investigate the performances of the state-of-the-art attack algorithms against deep learning-based intrusion detection on the NSL-KDD data set. The vulnerabilities of neural networks employed by the intrusion detection systems are experimentally validated. The roles of individual features in generating adversarial examples are explored. Based on our findings, the feasibility and applicability of the attack methodologies are discussed.","","","10.1109/ACCESS.2018.2854599","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8408779","Intrusion detection;neural networks;classification algorithms;data security","Machine learning;Neural networks;Intrusion detection;Feature extraction;Perturbation methods;Measurement;Task analysis","learning (artificial intelligence);neural nets;pattern classification;security of data","deep neural networks;intrusion detection systems;adversaries;intrusion detection;machine learning;deep learning","","6","15","","","","","IEEE","IEEE Journals"
"Deep Sparse Tensor Filtering Network for Synthetic Aperture Radar Images Classification","S. Yang; M. Wang; Z. Feng; Z. Liu; R. Li","Xidian University, Xi’an, China; Xidian University, Xi’an, China; Xidian University, Xi’an, China; Xidian University, Xi’an, China; University of Electronic Science and Technology of China, Chengdu, China","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","8","3919","3924","Recognizing scenes from synthetic aperture radar (SAR) images has been a challenging task due to the increasing resolution of SAR data. Extracting discriminative features from SAR images is extremely difficult for their sensitivity to target aspect. Considering the intractability of the available deep neural networks in practical implementations, in this brief, we propose a simple and efficient deep sparse tensor filtering network (DSTFN) for SAR image classification. An SAR image is first organized into a data tensor by an overlapped partition. Then, a set of dimension-inseparable geometric filters is developed from a least squares support vector machine, followed by a learned sparse filtering of tensors. Finally, the constructed sparse tensor filters are cascaded to a deep network to automatically extract the discriminative features of the image for accurate classification. Simulations are carried out to verify the effectiveness of the proposed DSTFN.","","","10.1109/TNNLS.2017.2688466","National Natural Science Foundation of China; Equipment Pre-Research Project of the 13th Five-Years Plan; Major Research Plan in Shaanxi Province of China; Foundation of the State Key Laboratory of CEMEE; Natural Science Basic Research Plan in Shaanxi Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8307437","Deep sparse tensor filtering network (DSTFN);sparse tensor filters;synthetic aperture radar (SAR)","Tensile stress;Synthetic aperture radar;Feature extraction;Image coding;Robustness;Learning systems;Task analysis","feature extraction;image classification;learning (artificial intelligence);least squares approximations;neural nets;radar computing;radar imaging;support vector machines;synthetic aperture radar;tensors","scene recognition;deep sparse tensor filtering network;discriminative feature extraction;constructed sparse tensor filters;dimension-inseparable geometric filters;data tensor;SAR image classification;available deep neural networks;SAR data;synthetic aperture radar images classification;deep network","","6","45","","","","","IEEE","IEEE Journals"
"Learned Primal-Dual Reconstruction","J. Adler; O. Öktem","Department of Mathematics, KTH - Royal Institute of Technology, Stockholm, Sweden; Department of Mathematics, KTH - Royal Institute of Technology, Stockholm, Sweden","IEEE Transactions on Medical Imaging","","2018","37","6","1322","1332","We propose the Learned Primal-Dual algorithm for tomographic reconstruction. The algorithm accounts for a (possibly non-linear) forward operator in a deep neural network by unrolling a proximal primal-dual optimization method, but where the proximal operators have been replaced with convolutional neural networks. The algorithm is trained end-to-end, working directly from raw measured data and it does not depend on any initial reconstruction such as filtered back-projection (FBP). We compare performance of the proposed method on low dose computed tomography reconstruction against FBP, total variation (TV), and deep learning based post-processing of FBP. For the Shepp-Logan phantom we obtain >6 dB peak signal to noise ratio improvement against all compared methods. For human phantoms the corresponding improvement is 6.6 dB over TV and 2.2 dB over learned post-processing along with a substantial improvement in the structural similarity index. Finally, our algorithm involves only ten forward-back-projection computations, making the method feasible for time critical clinical applications.","","","10.1109/TMI.2018.2799231","Swedish Foundation of Strategic Research; Industrial Ph.D.; Elekta; National Institute of Biomedical Imaging and Bioengineering; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8271999","Inverse problems;tomography;deep learning;primal-dual;optimization","Image reconstruction;Inverse problems;Computed tomography;TV;Machine learning","computerised tomography;feedforward neural nets;image denoising;image reconstruction;learning (artificial intelligence);medical image processing;optimisation;phantoms","learned post-processing;forward-back-projection computations;primal-dual reconstruction;tomographic reconstruction;deep neural network;primal-dual optimization method;proximal operators;convolutional neural networks;raw measured data;initial reconstruction;filtered back-projection;FBP;low dose computed tomography reconstruction;deep learning;Shepp-Logan phantom;nonlinear forward operator;peak signal to noise ratio improvement;time critical clinical applications","","23","37","","","","","IEEE","IEEE Journals"
"A Deep Learning Approach for Vital Signs Compression and Energy Efficient Delivery in mhealth Systems","A. B. said; M. F. Al-Sa’D; M. Tlili; A. A. Abdellatif; A. Mohamed; T. Elfouly; K. Harras; M. D. O’Connor","Department of Computer Science and Engineering, Qatar University, Doha, Qatar; Department of Computer Science and Engineering, Qatar University, Doha, Qatar; Department of Computer Science and Engineering, Qatar University, Doha, Qatar; Department of Computer Science and Engineering, Qatar University, Doha, Qatar; Department of Computer Science and Engineering, Qatar University, Doha, Qatar; Department of Computer Science and Engineering, Qatar University, Doha, Qatar; School of Computer Science, Carnegie Mellon University in Qatar, Education City, Doha, Qatar; Mobile Healthcare Service, Ambulance Service, Hamad Medical Corporation, Doha, Qatar","IEEE Access","","2018","6","","33727","33739","Due to the increasing number of chronic disease patients, continuous health monitoring has become the top priority for health-care providers and has posed a major stimulus for the development of scalable and energy efficient mobile health systems. Collected data in such systems are highly critical and can be affected by wireless network conditions, which in return, motivates the need for a preprocessing stage that optimizes data delivery in an adaptive manner with respect to network dynamics. We present in this paper adaptive single and multiple modality data compression schemes based on deep learning approach, which consider acquired data characteristics and network dynamics for providing energy efficient data delivery. Results indicate that: 1) the proposed adaptive single modality compression scheme outperforms conventional compression methods by 13.24% and 43.75% reductions in distortion and processing time, respectively; 2) the proposed adaptive multiple modality compression further decreases the distortion by 3.71% and 72.37% when compared with the proposed single modality scheme and conventional methods through leveraging inter-modality correlations; and 3) adaptive multiple modality compression demonstrates its efficiency in terms of energy consumption, computational complexity, and responding to different network states. Hence, our approach is suitable for mobile health applications (mHealth), where the smart preprocessing of vital signs can enhance energy consumption, reduce storage, and cut down transmission delays to the mHealth cloud.","","","10.1109/ACCESS.2018.2844308","Qatar National Research Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8372913","WBASN;multiple modality data;compression;deep learning;cross-layer optimization","Electroencephalography;Image coding;Machine learning;Adaptive systems;Data compression;Correlation;Energy consumption","data compression;diseases;health care;learning (artificial intelligence);mobile computing;patient monitoring","single modality scheme;adaptive multiple modality compression;energy consumption;mobile health applications;deep learning approach;vital signs compression;energy efficient delivery;mhealth systems;chronic disease patients;continuous health monitoring;health-care providers;scalable energy efficient mobile health systems;collected data;wireless network conditions;adaptive manner;network dynamics;multiple modality data compression schemes;data characteristics;energy efficient data delivery;adaptive single modality compression scheme;network states;data delivery;inter-modality correlations;smart preprocessing","","3","54","","","","","IEEE","IEEE Journals"
"Using Deep Learning-Based Approach to Predict Remaining Useful Life of Rotating Components","J. Deutsch; D. He","Department of Mechanical and Industrial Engineering, University of Illinois at Chicago, Chicago, IL, USA; College of Mechanical Engineering and Automation, Northeastern University, Shenyang, China","IEEE Transactions on Systems, Man, and Cybernetics: Systems","","2018","48","1","11","20","In the age of Internet of Things and Industrial 4.0, prognostic and health management (PHM) systems are used to collect massive real-time data from mechanical equipment. PHM big data has the characteristics of large-volume, diversity, and high-velocity. Effectively mining features from such data and accurately predicting the remaining useful life (RUL) of the rotating components with new advanced methods become issues in PHM. Traditional data driven prognostics is based on shallow learning architectures, requires establishing explicit model equations and much prior knowledge about signal processing techniques and prognostic expertise, and therefore is limited in the age of big data. This paper presents a deep learning-based approach for RUL prediction of rotating components with big data. The presented approach is tested and validated using data collected from a gear test rig and bearing run-to-failure tests and compared with existing PHM methods. The test results show the promising RUL prediction performance of the deep learning-based approach.","","","10.1109/TSMC.2017.2697842","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7927458","Bearing;condition monitoring;gearbox;machine learning;prediction methods;prognostics","Big Data;Prognostics and health management;Mathematical model;Feature extraction;Machine learning;Data mining;Data models","condition monitoring;data mining;failure analysis;fault diagnosis;gears;learning (artificial intelligence);machine bearings;maintenance engineering;production engineering computing;remaining life assessment","massive real-time data;mechanical equipment;PHM big data;high-velocity;remaining useful life;rotating components;prognostics;shallow learning architectures;explicit model equations;prognostic expertise;deep learning;bearing run-to-failure tests;PHM methods;RUL prediction performance","","18","42","","","","","IEEE","IEEE Journals"
"DeepX: Deep Learning Accelerator for Restricted Boltzmann Machine Artificial Neural Networks","L. Kim","Department of Computer Science and Engineering, Kyung Hee University, Seoul, South Korea","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","5","1441","1453","Although there have been many decades of research and commercial presence on high performance general purpose processors, there are still many applications that require fully customized hardware architectures for further computational acceleration. Recently, deep learning has been successfully used to learn in a wide variety of applications, but their heavy computation demand has considerably limited their practical applications. This paper proposes a fully pipelined acceleration architecture to alleviate high computational demand of an artificial neural network (ANN) which is restricted Boltzmann machine (RBM) ANNs. The implemented RBM ANN accelerator (integrating 1024 × 1024 network size, using 128 input cases per batch, and running at a 303-MHz clock frequency) integrated in a state-of-the art field-programmable gate array (FPGA) (Xilinx Virtex 7 XC7V-2000T) provides a computational performance of 301-billion connection-updates-per-second and about 193 times higher performance than a software solution running on general purpose processors. Most importantly, the architecture enables over 4 times (12 times in batch learning) higher performance compared with a previous work when both are implemented in an FPGA device (XC2VP70).","","","10.1109/TNNLS.2017.2665555","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7874153","Deep belief networks (DBNs);hardware-based computational acceleration;pipeline and parallel architecture;reconfigurable computing;restricted Boltzmann machine (RBM)","Computer architecture;Hardware;Field programmable gate arrays;Program processors;Acceleration;Training;Neural networks","Boltzmann machines;field programmable gate arrays;learning (artificial intelligence);pipeline arithmetic","deep learning accelerator;hardware architectures;artificial neural network;Boltzmann machine ANNs;RBM ANN accelerator;Xilinx Virtex 7 XC7V-2000T;DeepX;field-programmable gate array;Boltzmann machine artificial neural networks;pipelined acceleration architecture","","11","29","","","","","IEEE","IEEE Journals"
"Generalizing Pooling Functions in CNNs: Mixed, Gated, and Tree","C. Lee; P. Gallagher; Z. Tu","Department of Electrical and Computer Engineering, University of California, San Diego, La Jolla, CA; Department of Cognitive Science, University of California, San Diego, La Jolla, CA; Department of Cognitive Science, University of California, San Diego, La Jolla, CA","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","4","863","875","In this paper, we seek to improve deep neural networks by generalizing the pooling operations that play a central role in the current architectures. We pursue a careful exploration of approaches to allow pooling to learn and to adapt to complex and variable patterns. The two primary directions lie in: (1) learning a pooling function via (two strategies of) combining of max and average pooling, and (2) learning a pooling function in the form of a tree-structured fusion of pooling filters that are themselves learned. In our experiments every generalized pooling operation we explore improves performance when used in place of average or max pooling. We experimentally demonstrate that the proposed pooling operations provide a boost in invariance properties relative to conventional pooling and set the state of the art on several widely adopted benchmark datasets. These benefits come with only a light increase in computational overhead during training (ranging from additional 5 to 15 percent in time complexity) and a very modest increase in the number of model parameters (e.g., additional 1, 9, and 27 parameters for mixed, gated, and 2-level tree pooling operators, respectively). To gain more insights about our proposed pooling methods, we also visualize the learned pooling masks and the embeddings of the internal feature responses for different pooling operations. Our proposed pooling operations are easy to implement and can be applied within various deep neural network architectures.","","","10.1109/TPAMI.2017.2703082","US National Science Foundation; Northrop Grumman Contextual Robotics; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7927440","Convolutional neural networks;deep learning;pooling functions;supervised classification","Logic gates;Computer architecture;Decision trees;Standards;Neural networks;Training;Machine learning","computational complexity;feedforward neural nets;learning (artificial intelligence);neural net architecture;trees (mathematics)","pooling function;max pooling;average pooling;pooling filters;2-level tree pooling operators;pooling methods;learned pooling masks;deep neural network architectures;generalized pooling operation;tree-structured fusion;computational overhead","","8","45","","","","","IEEE","IEEE Journals"
"Learning to Optimize: Training Deep Neural Networks for Interference Management","H. Sun; X. Chen; Q. Shi; M. Hong; X. Fu; N. D. Sidiropoulos","Department of Electrical and Computer Engineering, University of Minnesota, Minneapolis, MN, USA; Department of Electrical and Computer Engineering, University of Minnesota, Minneapolis, MN, USA; School of Software Engineering, Tongji University, Shanghai, China; Department of Electrical and Computer Engineering, University of Minnesota, Minneapolis, MN, USA; School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, OR, USA; Department of Electrical and Computer Engineering, University of Virginia, Charlottesville, VA, USA","IEEE Transactions on Signal Processing","","2018","66","20","5438","5453","Numerical optimization has played a central role in addressing key signal processing (SP) problems. Highly effective methods have been developed for a large variety of SP applications such as communications, radar, filter design, and speech and image analytics, just to name a few. However, optimization algorithms often entail considerable complexity, which creates a serious gap between theoretical design/analysis and real-time processing. In this paper, we aim at providing a new learning-based perspective to address this challenging issue. The key idea is to treat the input and output of an SP algorithm as an unknown nonlinear mapping and use a deep neural network (DNN) to approximate it. If the nonlinear mapping can be learned accurately by a DNN of moderate size, then SP tasks can be performed effectively-since passing the input through a DNN only requires a small number of simple operations. In our paper, we first identify a class of optimization algorithms that can be accurately approximated by a fully connected DNN. Second, to demonstrate the effectiveness of the proposed approach, we apply it to approximate a popular interference management algorithm, namely, the WMMSE algorithm. Extensive experiments using both synthetically generated wireless channel data and real DSL channel data have been conducted. It is shown that, in practice, only a small network is sufficient to obtain high approximation accuracy, and DNNs can achieve orders of magnitude speedup in computational time compared to the state-of-the-art interference management algorithm.","","","10.1109/TSP.2018.2866382","National Science Foundation; Air Force Office of Scientific Research; National Science Foundation; National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; Zhejiang Provincial NSF of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8444648","Optimization algorithms approximation;deep neural networks;interference management;WMMSE algorithm","Signal processing algorithms;Approximation algorithms;Interference;Optimization;Task analysis;Machine learning algorithms;Wireless communication","approximation theory;interference (signal);learning (artificial intelligence);least mean squares methods;neural nets;optimisation;wireless channels","key signal processing problems;optimization algorithms;real-time processing;learning-based perspective;SP algorithm;unknown nonlinear mapping;deep neural network;fully connected DNN;WMMSE algorithm;state-of-the-art interference management algorithm;training deep neural networks;numerical optimization;central role;popular interference management algorithm;synthetically generated wireless channel","","36","35","","","","","IEEE","IEEE Journals"
"Deep Constrained Siamese Hash Coding Network and Load-Balanced Locality-Sensitive Hashing for Near Duplicate Image Detection","W. Hu; Y. Fan; J. Xing; L. Sun; Z. Cai; S. Maybank","CAS Center for Excellence in Brain Science and Intelligence Technology, National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; CAS Center for Excellence in Brain Science and Intelligence Technology, National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; CAS Center for Excellence in Brain Science and Intelligence Technology, National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; School of Information Science and Technology, University of Science and Technology of China, Hefei, China; Department of Information Science and Technology, Huizhou University, Huizhou, China; Department of Computer Science and Information Systems, Birkbeck College, University of London, London, U.K.","IEEE Transactions on Image Processing","","2018","27","9","4452","4464","We construct a new efficient near duplicate image detection method using a hierarchical hash code learning neural network and load-balanced locality-sensitive hashing (LSH) indexing. We propose a deep constrained siamese hash coding neural network combined with deep feature learning. Our neural network is able to extract effective features for near duplicate image detection. The extracted features are used to construct a LSH-based index. We propose a load-balanced LSH method to produce load-balanced buckets in the hashing process. The load-balanced LSH significantly reduces the query time. Based on the proposed load-balanced LSH, we design an effective and feasible algorithm for near duplicate image detection. Extensive experiments on three benchmark data sets demonstrate the effectiveness of our deep siamese hash encoding network and load-balanced LSH.","","","10.1109/TIP.2018.2839886","Beijing Natural Science Foundation; Natural Science Foundation of China; NSFC-General Technology Collaborative Fund for Basic Research; Key Research Program of Frontier Sciences, CAS; CAS External Cooperation Key Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8362942","Near duplicate image detection;load-balanced locality-sensitive hashing;deep constrained siamese neural network;deep feature extraction","Feature extraction;Indexing;Image coding;Neural networks;Matrix decomposition;Encoding","feature extraction;learning (artificial intelligence);neural nets;object detection","near duplicate image detection;duplicate image detection method;load-balanced locality-sensitive hashing indexing;deep constrained siamese hash coding neural network;deep feature learning;load-balanced LSH method;load-balanced buckets;hashing process;deep constrained siamese hash encoding network;hierarchical hash code learning neural network;LSH-based index;feature extraction","","1","45","","","","","IEEE","IEEE Journals"
"Visual Navigation for Biped Humanoid Robots Using Deep Reinforcement Learning","K. Lobos-Tsunekawa; F. Leiva; J. Ruiz-del-Solar","Department of Electrical Engineering and Advanced Mining Technology Center, Universidad de Chile, Santiago, Chile; Department of Electrical Engineering and Advanced Mining Technology Center, Universidad de Chile, Santiago, Chile; Department of Electrical Engineering and Advanced Mining Technology Center, Universidad de Chile, Santiago, Chile","IEEE Robotics and Automation Letters","","2018","3","4","3247","3254","In this letter, we propose a map-less visual navigation system for biped humanoid robots, which extracts information from color images to derive motion commands using deep reinforcement learning (DRL). The map-less visual navigation policy is trained using the Deep Deterministic Policy Gradients (DDPG) algorithm, which corresponds to an actor-critic DRL algorithm. The algorithm is implemented using two separate networks, one for the actor and one for the critic, but with similar structures. In addition to convolutional and fully connected layers, Long Short-Term Memory (LSTM) layers are included to address the limited observability present in the problem. As a proof of concept, we consider the case of robotic soccer using humanoid NAO V5 robots, which have reduced computational capabilities, and low-cost Red - Green - Blue (RGB) cameras as main sensors. The use of DRL allowed to obtain a complex and high performant policy from scratch, without any prior knowledge of the domain, or the dynamics involved. The visual navigation policy is trained in a robotic simulator and then successfully transferred to a physical robot, where it is able to run in 20 ms, allowing its use in real-time applications.","","","10.1109/LRA.2018.2851148","Fondo Nacional de Desarrollo Científico y Tecnológico; Fondo Nacional de Desarrollo Científico y Tecnológico; CONICYT-PFCHA/Magíster Nacional/2018-22182130; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8398461","Visual-based navigation;deep learning in robotics and automation and humanoid robots","Navigation;Visualization;Task analysis;Robot kinematics;Robot sensing systems","humanoid robots;image colour analysis;learning systems;legged locomotion;multi-robot systems;path planning;robot vision","Long Short-Term Memory layers;robotic soccer;humanoid NAO V5 robots;high performant policy;visual navigation policy;robotic simulator;physical robot;biped humanoid robots;deep reinforcement learning;color images;Deep Deterministic Policy Gradients algorithm;actor-critic DRL algorithm;convolutional connected layers;fully connected layers;motion commands;low-cost Red-Green-Blue cameras;real-time applications;time 20.0 ms","","3","28","","","","","IEEE","IEEE Journals"
"P2T: Part-to-Target Tracking via Deep Regression Learning","J. Gao; T. Zhang; X. Yang; C. Xu","National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Image Processing","","2018","27","6","3074","3086","Most existing part-based tracking methods are part-to-part trackers, which usually have two separated steps including the part matching and target localization. Different from existing methods, in this paper, we propose a novel part-to-target (P2T) tracker in a unified fashion by inferring target location from parts directly. To achieve this goal, we propose a novel deep regression model for P2T regression in an end-to-end framework via convolutional neural networks. The proposed model is designed not only to exploit the part context information to preserve object spatial layout structure, but also to learn part reliability to emphasize part importance for the robust P2T regression. We evaluate the proposed tracker on four challenging benchmark sequences, and extensive experimental results demonstrate that our method performs favorably against state-of-the-art trackers because of the powerful capacity of the proposed deep regression model.","","","10.1109/TIP.2018.2813166","National Natural Science Foundation of China; Key Research Program of Frontier Sciences, CAS; Beijing Natural Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8310629","Visual tracking;deep learning;part-based tracker","Target tracking;Visualization;Reliability;Context modeling;Strain;Correlation","convolution;feedforward neural nets;image representation;image sequences;learning (artificial intelligence);object detection;object tracking;regression analysis;target tracking;tracking;video signal processing","state-of-the-art trackers;deep regression model;part-to-target tracking;deep regression learning;tracking methods;part-to-part trackers;target localization;part-to-target tracker;target location;part context information;part reliability;part importance;method performs;P2T regression;convolutional neural networks","","5","74","","","","","IEEE","IEEE Journals"
"Bearing Fault Automatic Classification Based on Deep Learning","Y. Yang; P. Fu; Y. He","Tianjin Key Laboratory of Optoelectronic Detection Technology and Systems, Tianjin Polytechnic University, Tianjin, China; Tianjin Key Laboratory of Optoelectronic Detection Technology and Systems, Tianjin Polytechnic University, Tianjin, China; Tianjin Key Laboratory of Optoelectronic Detection Technology and Systems, Tianjin Polytechnic University, Tianjin, China","IEEE Access","","2018","6","","71540","71554","An automatic classification method based on deep learning for bearing fault diagnosis is proposed. The method is designed with the ability of faulty signal automatic clustering without human knowledge. A dataset in which each sample is given a random label is configured after extracting the features of vibration signals from the frequency domain. The dataset is used to train a deep neural network (DNN) to obtain the initial classification. The classification results are assessed by testing the subsignals extracted from the raw data, and the sample labels are modified according to the evaluation result. The modified dataset is used to train the DNN a second time. Samples with characteristic faults are clustered in various classes after iterating the DNN training and testing. The proposed method is tested with the bearing data provided by the Case Western Reserve University (CWRU) Bearing Data Center, which is a standard reference to test fault detection algorithms. The 12k drive end, 48k drive end, and 12k fan end CWRU bearing data are classified into 7, 6, and 4 groups, respectively. The testing results show that the proposed method can achieve automatic clustering for vibration signals with a variety of faults.","","","10.1109/ACCESS.2018.2880990","National Natural Science Foundation of China; Natural Science Foundation of Tianjin City; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8537893","Rotating machinery;fault diagnosis;deep learning;artificial neural network;bearing;fast Fourier transforms;feature extraction;classification algorithms","Fault diagnosis;Feature extraction;Machinery;Frequency-domain analysis;Neural networks;Testing","condition monitoring;fault diagnosis;learning (artificial intelligence);machine bearings;mechanical engineering computing;neural nets;pattern classification;pattern clustering;vibrations","automatic classification method;deep learning;fault diagnosis;faulty signal automatic clustering;human knowledge;random label;vibration signals;frequency domain;deep neural network;DNN;classification results;raw data;sample labels;evaluation result;modified dataset;characteristic faults;test fault detection algorithms;12k drive end;48k drive end;12k fan end;testing results;fault automatic classification;case western reserve university bearing data center;CWRU","","4","30","","","","","IEEE","IEEE Journals"
"Modeling Task fMRI Data Via Deep Convolutional Autoencoder","H. Huang; X. Hu; Y. Zhao; M. Makkie; Q. Dong; S. Zhao; L. Guo; T. Liu","School of Automation, Northwestern Polytechnical University, Xi’an, China; School of Automation, Northwestern Polytechnical University, Xi’an, China; Department of Computer Science and Bioimaging Research Center, Cortical Architecture Imaging and Discovery Laboratory, The University of Georgia, Athens, GA, USA; Department of Computer Science and Bioimaging Research Center, Cortical Architecture Imaging and Discovery Laboratory, The University of Georgia, Athens, GA, USA; Department of Computer Science and Bioimaging Research Center, Cortical Architecture Imaging and Discovery Laboratory, The University of Georgia, Athens, GA, USA; School of Automation, Northwestern Polytechnical University, Xi’an, China; School of Automation, Northwestern Polytechnical University, Xi’an, China; Department of Computer Science and Bioimaging Research Center, Cortical Architecture Imaging and Discovery Laboratory, The University of Georgia, Athens, GA, USA","IEEE Transactions on Medical Imaging","","2018","37","7","1551","1561","Task-based functional magnetic resonance imaging (tfMRI) has been widely used to study functional brain networks under task performance. Modeling tfMRI data is challenging due to at least two problems: the lack of the ground truth of underlying neural activity and the highly complex intrinsic structure of tfMRI data. To better understand brain networks based on fMRI data, data-driven approaches have been proposed, for instance, independent component analysis (ICA) and sparse dictionary learning (SDL). However, both ICA and SDL only build shallow models, and they are under the strong assumption that original fMRI signal could be linearly decomposed into time series components with their corresponding spatial maps. As growing evidence shows that human brain function is hierarchically organized, new approaches that can infer and model the hierarchical structure of brain networks are widely called for. Recently, deep convolutional neural network (CNN) has drawn much attention, in that deep CNN has proven to be a powerful method for learning high-level and mid-level abstractions from low-level raw data. Inspired by the power of deep CNN, in this paper, we developed a new neural network structure based on CNN, called deep convolutional auto-encoder (DCAE), in order to take the advantages of both data-driven approach and CNN's hierarchical feature abstraction ability for the purpose of learning mid-level and high-level features from complex, large-scale tfMRI time series in an unsupervised manner. The DCAE has been applied and tested on the publicly available human connectome project tfMRI data sets, and promising results are achieved.","","","10.1109/TMI.2017.2715285","National Institutes of Health; National Science Foundation; National Institutes of Health; National Science Foundation; National Science Foundation; National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7949140","Task fMRI;CNN;deep learning;unsupervised","Convolution;Data models;Brain modeling;Hidden Markov models;Decoding;Machine learning;Time series analysis","biomedical MRI;brain;independent component analysis;learning (artificial intelligence);medical image processing;neural nets;neurophysiology;time series","functional brain networks;ground truth;neural activity;data-driven approach;sparse dictionary;time series components;human brain function;deep convolutional neural network;neural network structure;fMRI signal;deep convolutional auto-encoder;hierarchical feature abstraction ability;human connectome project tfMRI data;independent component analysis;sparse dictionary learning;task-based functional magnetic resonance imaging","","4","42","","","","","IEEE","IEEE Journals"
"Weakly-Supervised Deep Embedding for Product Review Sentiment Analysis","W. Zhao; Z. Guan; L. Chen; X. He; D. Cai; B. Wang; Q. Wang","School of Computer Science and Technology, Xidian University, Xi'an, CN, China; School of Computer Science and Technology, Xidian University, Xi'an, CN, China; School of Information and Technology, Northwest University of China, Xi'an, CN, China; State Key Lab of CAD&CG, College of Computer Science, Zhejiang University, Hangzhou, CN, China; State Key Lab of CAD&CG, College of Computer Science, Zhejiang University, Hangzhou, CN, China; School of Computing Science, Simon Fraser University, Burnaby, BC, Canada; School of Computer Science and Technology, Xidian University, Xi'an, CN, China","IEEE Transactions on Knowledge and Data Engineering","","2018","30","1","185","197","Product reviews are valuable for upcoming buyers in helping them make decisions. To this end, different opinion mining techniques have been proposed, where judging a review sentence's orientation (e.g., positive or negative) is one of their key challenges. Recently, deep learning has emerged as an effective means for solving sentiment classification problems. A neural network intrinsically learns a useful representation automatically without human efforts. However, the success of deep learning highly relies on the availability of large-scale training data. We propose a novel deep learning framework for product review sentiment classification which employs prevalently available ratings as weak supervision signals. The framework consists of two steps: (1) learning a high level representation (an embedding space) which captures the general sentiment distribution of sentences through rating information; and (2) adding a classification layer on top of the embedding layer and use labeled sentences for supervised fine-tuning. We explore two kinds of low level network structure for modeling review sentences, namely, convolutional feature extractors and long short-term memory. To evaluate the proposed framework, we construct a dataset containing 1.1M weakly labeled review sentences and 11,754 labeled review sentences from Amazon. Experimental results show the efficacy of the proposed framework and its superiority over baselines.","","","10.1109/TKDE.2017.2756658","National Natural Science Foundation of China; Major Basic Research Project of Shaanxi Province; Science and Technology Plan Program in Shaanxi Province of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8051113","Deep learning;opinion mining;sentiment classification;weak-supervision","Machine learning;Neural networks;Feature extraction;Sentiment analysis;Syntactics;Training","data mining;learning (artificial intelligence);neural nets;pattern classification;sentiment analysis","product review sentiment analysis;sentiment classification problems;neural network;human efforts;large-scale training data;deep learning framework;product review sentiment classification;weak supervision signals;high level representation;embedding space;general sentiment distribution;rating information;classification layer;embedding layer;supervised fine-tuning;low level network structure;opinion mining techniques;weakly-supervised deep embedding;review sentence orientation;labeled review sentences;review sentences modeling","","6","54","Traditional","","","","IEEE","IEEE Journals"
"Kernel Deep Regression Network for Touch-Stroke Dynamics Authentication","I. Chang; C. Low; S. Choi; A. B. Teoh","School of Electrical and Electronic Engineering, College of Engineering, Yonsei University, Seoul, South Korea; School of Electrical and Electronic Engineering, College of Engineering, Yonsei University, Seoul, South Korea; School of Electrical and Electronic Engineering, College of Engineering, Yonsei University, Seoul, South Korea; School of Electrical and Electronic Engineering, College of Engineering, Yonsei University, Seoul, South Korea","IEEE Signal Processing Letters","","2018","25","7","1109","1113","Touch-stroke dynamics is an emerging behavioral biometrics justified feasible for mobile identity management. A touch-stroke dynamics authentication system is composed of a hand-engineered feature extractor and a classifier separately. In this letter, we propose a stacking-based deep learning network that performs feature extraction and classification, collectively dubbed Kernel Deep Regression Network (KDRN). The KDRN is built on multiple kernel ridge regressions (KRR) hierarchically, where each is trained analytically and independently. In principal, KDRN does not mean to learn directly from the raw touch-stroke data like other deep learning models, but it relearns from the pre-extracted features to yield a richer and a relatively more discriminative feature set. Subsequent to that, the authentication is carried out by KRR. Overall, KDRN achieves an equal error rate of 0.013% for intrasession authentication, 0.023% for intersession authentication, and 0.121% for interweek authentication on the Touchlaytics dataset.","","","10.1109/LSP.2018.2846050","National Research Foundation of Korea; Ministry of Science, ICT and Future Planning; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8378259","Authentication;biometrics;stacking-based deep neural network;touch-stroke dynamics","Authentication;Kernel;Training;Feature extraction;Biometrics (access control);Machine learning;Hidden Markov models","biometrics (access control);feature extraction;learning (artificial intelligence);regression analysis","Kernel deep regression network;emerging behavioral biometrics;mobile identity management;feature extractor;deep learning network;KDRN;multiple kernel ridge regressions;raw touch-stroke data;deep learning models;intersession authentication;interweek authentication;touch-stroke dynamic authentication system","","1","19","","","","","IEEE","IEEE Journals"
"Speaker-Independent Speech Separation With Deep Attractor Network","Y. Luo; Z. Chen; N. Mesgarani","Department of Electrical Engineering, Columbia University, New York, NY, USA; Department of Electrical Engineering, Columbia University, New York, NY, USA; Department of Electrical Engineering, Columbia University, New York, NY, USA","IEEE/ACM Transactions on Audio, Speech, and Language Processing","","2018","26","4","787","796","Despite the recent success of deep learning for many speech processing tasks, single-microphone, speaker-independent speech separation remains challenging for two main reasons. The first reason is the arbitrary order of the target and masker speakers in the mixture (permutation problem), and the second is the unknown number of speakers in the mixture (output dimension problem). We propose a novel deep learning framework for speech separation that addresses both of these issues. We use a neural network to project the time-frequency representation of the mixture signal into a high-dimensional embedding space. A reference point (attractor) is created in the embedding space to represent each speaker which is defined as the centroid of the speaker in the embedding space. The time-frequency embeddings of each speaker are then forced to cluster around the corresponding attractor point which is used to determine the time-frequency assignment of the speaker. We propose three methods for finding the attractors for each source in the embedding space and compare their advantages and limitations. The objective function for the network is standard signal reconstruction error which enables end-to-end operation during both training and test phases. We evaluated our system using the Wall Street Journal dataset (WSJ0) on two and three speaker mixtures and report comparable or better performance than other state-of-the-art deep learning methods for speech separation.","","","10.1109/TASLP.2018.2795749","National Institute on Deafness and Other Communication Disorders; National Science Foundation CAREER Award; Pew Charitable Trusts; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8264702","Source separation;multi-talker;deep clustering;attractor network","Speech;Time-frequency analysis;Spectrogram;Machine learning;Speech processing;Neural networks","learning (artificial intelligence);neural nets;signal reconstruction;signal representation;source separation;speech processing;speech recognition","speaker mixtures;deep learning methods;speaker-independent speech separation;deep attractor network;masker speakers;output dimension problem;deep learning framework;time-frequency representation;high-dimensional embedding space;reference point;time-frequency embeddings;corresponding attractor point;time-frequency assignment;standard signal reconstruction","","21","55","","","","","IEEE","IEEE Journals"
"Auto-Sorting System Toward Smart Factory Based on Deep Learning for Image Segmentation","T. Wang; Y. Yao; Y. Chen; M. Zhang; F. Tao; H. Snoussi","School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; College of Electrical Engineering and Control Science, Nanjing Tech University, Nanjing, China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; Institute Charles Delaunay-LM2S-UMR STMR 6279 CNRS, University of Technology of Troyes, Troyes, France","IEEE Sensors Journal","","2018","18","20","8493","8501","Machine part sorting is important and monotonous in smart factory. In this paper, an auto-sorting system is proposed based on the deep learning method. In the proposed system, an industrial objection detection network combined with a robotic arm controlling system is designed to automatically and efficiently complete machine part sorting. Region-based full convolutional network (R-FCN) is applied for locating and recognizing different types of images of industrial object models. After comparison and simulation analysis, it illustrated that the R-FCN model trained with enough labeled data can efficiently and accurately recognize the object from the images captured by visual sensors. Furthermore, with enough data, the network can be robust to view angle rotation both vertically and horizontally, and a small part of overlapping of object will not mislead the judgment of the network in most situations. The case study results illustrate that the position and type of objects can be successfully detected. The code will be available publicly at https://github.com/tianwangbuaa/.","","","10.1109/JSEN.2018.2866943","National Key Research and Development Program of China; National Natural Science Foundation of China; Aeronautical Science Foundation of China; Fundamental Research Funds for the Central Universities; SURECAP CPER Project; Platform CAPSEC; Région Champagne-Ardenne and FEDER; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8444660","Smart factory;deep learning;auto-sorting;convolutional network;object detection","Feature extraction;Proposals;Smart manufacturing;Object detection;Neural networks;Sensors;Machine learning","convolution;image segmentation;learning (artificial intelligence);object detection;production engineering computing","deep learning method;machine part sorting;image segmentation;smart factory;auto-sorting system;R-FCN model;industrial object models;region-based full convolutional network;efficiently complete machine part;automatically machine part;robotic arm controlling system;industrial objection detection network","","","43","","","","","IEEE","IEEE Journals"
"Low-Shot Learning for the Semantic Segmentation of Remote Sensing Imagery","R. Kemker; R. Luu; C. Kanan","Machine and Neuromorphic Perception Laboratory, Carlson Center for Imaging Science, Rochester Institute of Technology, Rochester, NY, USA; Machine and Neuromorphic Perception Laboratory, Carlson Center for Imaging Science, Rochester Institute of Technology, Rochester, NY, USA; Machine and Neuromorphic Perception Laboratory, Carlson Center for Imaging Science, Rochester Institute of Technology, Rochester, NY, USA","IEEE Transactions on Geoscience and Remote Sensing","","2018","56","10","6214","6223","Recent advances in computer vision using deep learning with RGB imagery (e.g., object recognition and detection) have been made possible thanks to the development of large annotated RGB image data sets. In contrast, multispectral image (MSI) and hyperspectral image (HSI) data sets contain far fewer labeled images, in part due to the wide variety of sensors used. These annotations are especially limited for semantic segmentation, or pixelwise classification, of remote sensing imagery because it is labor intensive to generate image annotations. Low-shot learning algorithms can make effective inferences despite smaller amounts of annotated data. In this paper, we study low-shot learning using self-taught feature learning for semantic segmentation. We introduce: 1) an improved self-taught feature learning framework for HSI and MSI data and 2) a semisupervised classification algorithm. When these are combined, they achieve the state-of-the-art performance on remote sensing data sets that have little annotated training data available. These low-shot learning frameworks will reduce the manual image annotation burden and improve semantic segmentation performance for remote sensing imagery.","","","10.1109/TGRS.2018.2833808","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8368069","Deep learning;feature learning;hyperspectral imaging;self-taught learning;semantic segmentation;semisupervised","Feature extraction;Semantics;Image segmentation;Remote sensing;Image reconstruction;Data models;Support vector machines","computer vision;feature extraction;geophysical image processing;geophysical techniques;hyperspectral imaging;image classification;image colour analysis;image segmentation;learning (artificial intelligence);object detection;object recognition;remote sensing","remote sensing imagery;low-shot learning algorithms;annotated data;semisupervised classification algorithm;annotated training data;semantic segmentation performance;computer vision;deep learning;RGB imagery;labeled images;object recognition;object detection;HSI;multispectral image data sets;MSI;hyperspectral image data sets;pixelwise classification;inferences;self-taught feature learning framework;image annotation","","3","33","","","","","IEEE","IEEE Journals"
"Empirical Mode Decomposition Based Deep Learning for Electricity Demand Forecasting","J. Bedi; D. Toshniwal","Department of CSE, IIT Roorkee, Roorkee, India; Department of CSE, IIT Roorkee, Roorkee, India","IEEE Access","","2018","6","","49144","49156","Electricity is of great significance for national economic, social, and technological activities, such as material production, healthcare, and education. The nationwide electricity demand has grown rapidly over the past few decades. Therefore, efficient electricity demand estimation and management are required for better strategies planning, energy utilization, waste management, improving revenue, and maintenance of power systems. In this paper, we propose an empirical mode decomposition (EMD)-based deep learning approach which combines the EMD method with the long short-term memory network model to estimate electricity demand for the given season, day, and time interval of a day. For this purpose, the EMD algorithm decomposes a load time series signal into several intrinsic mode functions (IMFs) and residual. Then, a LSTM model is trained separately for each of the extracted IMFs and residual. Finally, the prediction results of all IMFs are combined by summation to determine an aggregated output for electricity demand. To demonstrate the applicability of the proposed approach, it is applied to electricity consumption data of city Chandigarh. Furthermore, the performance of the proposed approach is evaluated by comparing the prediction results with recurrent neural network (RNN), LSTM, and EMD-based RNN (EMD+RNN) models.","","","10.1109/ACCESS.2018.2867681","Ministry of Human Resource Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8449937","Deep learning;electricity demand prediction;empirical mode decomposition;energy analytic;long short term memory network","Predictive models;Demand forecasting;Time series analysis;Machine learning;Recurrent neural networks;Load modeling;Support vector machines","demand forecasting;Hilbert transforms;learning (artificial intelligence);load forecasting;power consumption;power engineering computing;recurrent neural nets;time series","material production;nationwide electricity demand;waste management;empirical mode decomposition-based deep learning approach;electricity consumption data;EMD-based RNN models;national economic activities;electricity demand forecasting estimation;healthcare;electricity demand estimation;electricity demand management;IMF extraction;recurrent neural network;Chandigarh city;LSTM model;intrinsic mode function;load time series signal decomposition;long short-term memory network model;power system maintenance;strategies planning","","3","40","","","","","IEEE","IEEE Journals"
"3-D Consistent and Robust Segmentation of Cardiac Images by Deep Learning With Spatial Propagation","Q. Zheng; H. Delingette; N. Duchateau; N. Ayache","Université Côte d’Azur, Inria, Nice, France; Université Côte d’Azur, Inria, Nice, France; CNRS UMR 5220, INSERM U1206, CREATIS, Lyon, France; Université Côte d’Azur, Inria, Nice, France","IEEE Transactions on Medical Imaging","","2018","37","9","2137","2148","We propose a method based on deep learning to perform cardiac segmentation on short axis Magnetic resonance imaging stacks iteratively from the top slice (around the base) to the bottom slice (around the apex). At each iteration, a novel variant of the U-net is applied to propagate the segmentation of a slice to the adjacent slice below it. In other words, the prediction of a segmentation of a slice is dependent upon the already existing segmentation of an adjacent slice. The 3-D consistency is hence explicitly enforced. The method is trained on a large database of 3078 cases from the U.K. Biobank. It is then tested on the 756 different cases from the U.K. Biobank and three other state-of-the-art cohorts (ACDC with 100 cases, Sunnybrook with 30 cases, and RVSC with 16 cases). Results comparable or even better than the state of the art in terms of distance measures are achieved. They also emphasize the assets of our method, namely, enhanced spatial consistency (currently neither considered nor achieved by the state of the art), and the generalization ability to unseen cases even from other databases.","","","10.1109/TMI.2018.2820742","European Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8327905","Cardiac segmentation;deep learning;neural network;3D consistency;spatial propagation","Image segmentation;Three-dimensional displays;Training;Machine learning;Two dimensional displays;Magnetic resonance imaging;Neural networks","biomedical MRI;cardiology;image segmentation;learning (artificial intelligence);medical image processing","U.K. Biobank;state-of-the-art cohorts;enhanced spatial consistency;unseen cases;robust segmentation;cardiac images;deep learning;spatial propagation;cardiac segmentation;short axis Magnetic resonance;bottom slice;iteration;adjacent slice;existing segmentation;3D consistent segmentation;U","","6","21","","","","","IEEE","IEEE Journals"
"Model-Based Learning for Accelerated, Limited-View 3-D Photoacoustic Tomography","A. Hauptmann; F. Lucka; M. Betcke; N. Huynh; J. Adler; B. Cox; P. Beard; S. Ourselin; S. Arridge","Department of Computer Science, University College London, London, U.K.; Department of Computer Science, University College London, London, U.K.; Department of Computer Science, University College London, London, U.K.; Department of Medical Physics and Biomedical Engineering, University College London, London, U.K.; Department of Mathematics, KTH Royal Institute of Technology, Stockholm, Sweden; Department of Medical Physics and Biomedical Engineering, University College London, London, U.K.; Department of Medical Physics and Biomedical Engineering, University College London, London, U.K.; Department of Computer Science, University College London, London, U.K.; Department of Computer Science, University College London, London, U.K.","IEEE Transactions on Medical Imaging","","2018","37","6","1382","1393","Recent advances in deep learning for tomographic reconstructions have shown great potential to create accurate and high quality images with a considerable speed up. In this paper, we present a deep neural network that is specifically designed to provide high resolution 3-D images from restricted photoacoustic measurements. The network is designed to represent an iterative scheme and incorporates gradient information of the data fit to compensate for limited view artifacts. Due to the high complexity of the photoacoustic forward operator, we separate training and computation of the gradient information. A suitable prior for the desired image structures is learned as part of the training. The resulting network is trained and tested on a set of segmented vessels from lung computed tomography scans and then applied to in-vivo photoacoustic measurement data.","","","10.1109/TMI.2018.2820382","H2020 LEIT Information and Communication Technologies; Photonics Public Private Partnership; Engineering and Physical Sciences Research Council; Engineering and Physical Sciences Research Council; Nederlandse Organisatie voor Wetenschappelijk Onderzoek; Stiftelsen för Strategisk Forskning; Elekta; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8327873","Deep learning;convolutional neural networks;photoacoustic tomography;iterative reconstruction","Image reconstruction;Tomography;TV;Three-dimensional displays;Machine learning;Propagation;Computational modeling","acoustic tomography;biomedical optical imaging;blood vessels;image reconstruction;image segmentation;iterative methods;learning (artificial intelligence);lung;medical image processing;neural nets;optical tomography;photoacoustic effect;tomography","deep learning;tomographic reconstructions;high quality images;deep neural network;high resolution 3-D images;restricted photoacoustic measurements;iterative scheme;gradient information;photoacoustic forward operator;lung computed tomography scans;image structures;model-based learning;limited-view 3-D photoacoustic tomography;limited view artifacts;segmented vessels;in-vivo photoacoustic measurement data","","5","53","CCBY","","","","IEEE","IEEE Journals"
"Deep Learning for Smart Industry: Efficient Manufacture Inspection System With Fog Computing","L. Li; K. Ota; M. Dong","Department of Information and Electronic Engineering, Muroran Institute of Technology, Muroran, Japan; Department of Information and Electronic Engineering, Muroran Institute of Technology, Muroran, Japan; Department of Information and Electronic Engineering, Muroran Institute of Technology, Muroran, Japan","IEEE Transactions on Industrial Informatics","","2018","14","10","4665","4673","With the rapid development of Internet of things devices and network infrastructure, there have been a lot of sensors adopted in the industrial productions, resulting in a large size of data. One of the most popular examples is the manufacture inspection, which is to detect the defects of the products. In order to implement a robust inspection system with higher accuracy, we propose a deep learning based classification model in this paper, which can find the possible defective products. As there may be many assembly lines in one factory, one huge problem in this scenario is how to process such big data in real time. Therefore, we design our system with the concept of fog computing. By offloading the computation burden from the central server to the fog nodes, the system obtains the ability to deal with extremely large data. There are two obvious advantages in our system. The first one is that we adapt the convolutional neural network model to the fog computing environment, which significantly improves its computing efficiency. The other one is that we work out an inspection model, which can simultaneously indicate the defect type and its degree. The experiments well prove that the proposed method is robust and efficient.","","","10.1109/TII.2018.2842821","JSPS KAKENHI; KDDI Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8370640","Deep learning;fog computing;manufacture inspection;smart industry","Inspection;Edge computing;Industries;Computational modeling;Machine learning;Production;Informatics","cloud computing;feedforward neural nets;inspection;intelligent manufacturing systems;Internet of Things;learning (artificial intelligence);production engineering computing","smart industry;network infrastructure;industrial productions;robust inspection system;deep learning based classification model;assembly lines;big data;fog nodes;extremely large data;convolutional neural network model;fog computing environment;computing efficiency;inspection model;defect type;Internet of Things devices;defective products;manufacture inspection system","","24","33","","","","","IEEE","IEEE Journals"
"A New Deep Learning-Based Food Recognition System for Dietary Assessment on An Edge Computing Service Infrastructure","C. Liu; Y. Cao; Y. Luo; G. Chen; V. Vokkarane; M. Yunsheng; S. Chen; P. Hou","University of Massachusetts, Lowell, MA; University of Massachusetts, Lowell, MA; Department of Electrical and Computer Engineering, University of Massachusetts, Lowell, MA; University of Massachusetts, Lowell, MA; Department of Electrical and Computer Engineering, University of Massachusetts, Lowell, MA; Department of Medicine, University of Massachusetts Medical School, Worcester, MA; Department of Computer Science, George Mason University, Fairfax, VA; University of Massachusetts, Lowell, MA","IEEE Transactions on Services Computing","","2018","11","2","249","261","Literature has indicated that accurate dietary assessment is very important for assessing the effectiveness of weight loss interventions. However, most of the existing dietary assessment methods rely on memory. With the help of pervasive mobile devices and rich cloud services, it is now possible to develop new computer-aided food recognition system for accurate dietary assessment. However, enabling this future Internet of Things-based dietary assessment imposes several fundamental challenges on algorithm development and system design. In this paper, we set to address these issues from the following two aspects: (1) to develop novel deep learning-based visual food recognition algorithms to achieve the best-in-class recognition accuracy; (2) to design a food recognition system employing edge computing-based service computing paradigm to overcome some inherent problems of traditional mobile cloud computing paradigm, such as unacceptable system latency and low battery life of mobile devices. We have conducted extensive experiments with real-world data. Our results have shown that the proposed system achieved three objectives: (1) outperforming existing work in terms of food recognition accuracy; (2) reducing response time that is equivalent to the minimum of the existing approaches; and (3) lowering energy consumption which is close to the minimum of the state-of-the-art.","","","10.1109/TSC.2017.2662008","US National Science Foundation (NSF) of the United States; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7837725","Mobile applications;object recognition;deep learning;edge computing;food recognition","Algorithm design and analysis;Machine learning;Edge computing;Mobile communication;Mobile handsets;Time factors;Image recognition","cloud computing;image recognition;learning (artificial intelligence);mobile computing;mobile radio","food recognition system;edge computing service infrastructure;accurate dietary assessment;existing dietary assessment methods;pervasive mobile devices;rich cloud services;visual food recognition algorithms;best-in-class recognition accuracy;service computing paradigm;traditional mobile cloud computing paradigm;unacceptable system;food recognition accuracy;deep learning","","16","63","","","","","IEEE","IEEE Journals"
"Deep Learning Methods for Improved Decoding of Linear Codes","E. Nachmani; E. Marciano; L. Lugosch; W. J. Gross; D. Burshtein; Y. Be’ery","School of Electrical Engineering, Tel-Aviv University, Tel-Aviv, Israel; School of Electrical Engineering, Tel-Aviv University, Tel-Aviv, Israel; Department of Electrical and Computer Engineering, McGill University, Montréal, QC, Canada; Department of Electrical and Computer Engineering, McGill University, Montréal, QC, Canada; School of Electrical Engineering, Tel-Aviv University, Tel-Aviv, Israel; School of Electrical Engineering, Tel-Aviv University, Tel-Aviv, Israel","IEEE Journal of Selected Topics in Signal Processing","","2018","12","1","119","131","The problem of low complexity, close to optimal, channel decoding of linear codes with short to moderate block length is considered. It is shown that deep learning methods can be used to improve a standard belief propagation decoder, despite the large example space. Similar improvements are obtained for the min-sum algorithm. It is also shown that tying the parameters of the decoders across iterations, so as to form a recurrent neural network architecture, can be implemented with comparable results. The advantage is that significantly less parameters are required. We also introduce a recurrent neural decoder architecture based on the method of successive relaxation. Improvements over standard belief propagation are also observed on sparser Tanner graph representations of the codes. Furthermore, we demonstrate that the neural belief propagation decoder can be used to improve the performance, or alternatively reduce the computational complexity, of a close to optimal decoder of short BCH codes.","","","10.1109/JSTSP.2017.2788405","Israel Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8242643","Deep learning;error correcting codes;belief propagation;min-sum decoding","Decoding;Signal processing algorithms;Neural networks;Belief propagation;Parity check codes;Machine learning;Standards","BCH codes;belief networks;computational complexity;decoding;graph theory;learning (artificial intelligence);linear codes;recurrent neural nets;telecommunication computing","deep learning methods;improved decoding;linear codes;low complexity;channel decoding;moderate block length;standard belief propagation decoder;min-sum algorithm;recurrent neural network architecture;recurrent neural decoder architecture;neural belief propagation decoder;optimal decoder;short BCH codes;successive relaxation method;sparser Tanner graph representations","","60","41","","","","","IEEE","IEEE Journals"
"Over-the-Air Deep Learning Based Radio Signal Classification","T. J. O’Shea; T. Roy; T. C. Clancy","Bradley Department of Electrical and Computer Engineering, Blacksburg, VA, USA; Bradley Department of Electrical and Computer Engineering, Blacksburg, VA, USA; Bradley Department of Electrical and Computer Engineering, Blacksburg, VA, USA","IEEE Journal of Selected Topics in Signal Processing","","2018","12","1","168","179","We conduct an in depth study on the performance of deep learning based radio signal classification for radio communications signals. We consider a rigorous baseline method using higher order moments and strong boosted gradient tree classification, and compare performance between the two approaches across a range of configurations and channel impairments. We consider the effects of carrier frequency offset, symbol rate, and multipath fading in simulation, and conduct over-the-air measurement of radio classification performance in the lab using software radios, and we compare performance and training strategies for both. Finally, we conclude with a discussion of remaining problems, and design considerations for using such techniques.","","","10.1109/JSTSP.2018.2797022","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8267032","Cognitive radio;deep learning;modulation;neural networks;pattern recognition;sensor systems and applications;wireless communication","Modulation;Feature extraction;Wireless communication;Neural networks;Machine learning;Fading channels;Decision trees","fading channels;learning (artificial intelligence);multipath channels;radiocommunication;signal classification;software radio;trees (mathematics)","strong boosted gradient tree classification;over-the-air deep learning based radio signal classification;over-the-air measurement;higher order moments;rigorous baseline method;radio communications signals;software radios","","45","38","","","","","IEEE","IEEE Journals"
"An Evaporation Duct Height Prediction Method Based on Deep Learning","X. Zhu; J. Li; M. Zhu; Z. Jiang; Y. Li","College of Meteorology and Oceanology, National University of Defense Technology, Changsha, China; College of Meteorology and Oceanology, National University of Defense Technology, Changsha, China; College of Meteorology and Oceanology, National University of Defense Technology, Changsha, China; Beijing Institute of Applied Meteorology, Beijing, China; Computer Science and Engineering Department, University of California at Riverside, Riverside, CA, USA","IEEE Geoscience and Remote Sensing Letters","","2018","15","9","1307","1311","An evaporation duct is a particular atmospheric duct that is crucial for marine vessel communication, and one of the most significant indexes to assess it is evaporation duct height (EDH). In this letter, we propose a new method based on a multilayer perceptron (MLP), a classic network in deep learning, to predict the EDH. After so many experiments, the structure of MLP for EDH estimation is chosen as five hidden layer with rectified liner unit activation function. Since this method is essentially some kind of regression, the mean-squared error is chosen as the loss function. To accelerate the training convergence, we choose a self-adaptive optimization scheme called adaptive moment estimation. There are some field observation data sets obtained from some sea areas in northern hemisphere, by which the MLP is trained, to predict the EDH. For single-regional prediction, we use the same input data sets with the Paulus-Jeske (P-J) model, one of the ideal operational models, to predict the EDH. In comparison with the P-J model, the prediction accuracy using our method is significantly escalated in all experimental sea areas, which reveals the efficiency of our method. By cross prediction in distinct sea areas, the consistency between the method and the theory is verified, and this letter yields a new approach of evaporation duct prediction.","","","10.1109/LGRS.2018.2842235","China Postdoctoral Science Foundation; Young Scientists Foundation of the National Natural Science Foundation of China; National Natural Science Foundation of China; Youth Innovation Foundation of the 4th Annual Conference of High Resolution Earth Observation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8392443","Deep learning;evaporation duct;multilayer perceptron (MLP);Paulus–Jeske (P-J) model","Ducts;Atmospheric modeling;Ocean temperature;Machine learning;Mathematical model;Predictive models;Temperature measurement","atmospheric boundary layer;ducts;evaporation;learning (artificial intelligence);mean square error methods;multilayer perceptrons;optimisation;regression analysis","evaporation duct height prediction method;deep learning;marine vessel communication;multilayer perceptron;MLP;EDH estimation;mean-squared error;self-adaptive optimization scheme;adaptive moment estimation;single-regional prediction;atmospheric duct;Paulus-Jeske model;P-J model","","1","28","","","","","IEEE","IEEE Journals"
"Integrated Networking, Caching, and Computing for Connected Vehicles: A Deep Reinforcement Learning Approach","Y. He; N. Zhao; H. Yin","School of Information and Communications Engineering, Dalian University of Technology, Dalian, China; School of Information and Communication Engineering, Dalian University of Technology, Dalian, China; School of Information and Communication Engineering, Dalian University of Technology, Dalian, China","IEEE Transactions on Vehicular Technology","","2018","67","1","44","55","The developments of connected vehicles are heavily influenced by information and communications technologies, which have fueled a plethora of innovations in various areas, including networking, caching, and computing. Nevertheless, these important enabling technologies have traditionally been studied separately in the existing works on vehicular networks. In this paper, we propose an integrated framework that can enable dynamic orchestration of networking, caching, and computing resources to improve the performance of next generation vehicular networks. We formulate the resource allocation strategy in this framework as a joint optimization problem, where the gains of not only networking but also caching and computing are taken into consideration in the proposed framework. The complexity of the system is very high when we jointly consider these three technologies. Therefore, we propose a novel deep reinforcement learning approach in this paper. Simulation results with different system parameters are presented to show the effectiveness of the proposed scheme.","","","10.1109/TVT.2017.2760281","Xinghai Scholars Program; Fundamental Research Funds for the Central Universities; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8061008","Caching;deep reinforcement learning;edge computing;vehicular networks","Learning (artificial intelligence);Videos;Cloud computing;Quality of service;Resource management;Edge computing;Mobile communication","cache storage;learning (artificial intelligence);mobile computing;optimisation;resource allocation;vehicular ad hoc networks","joint optimization problem;caching;deep reinforcement learning approach;integrated networking;connected vehicles;dynamic orchestration;computing resources;resource allocation strategy;information and communications technologies;next generation vehicular networks","","58","41","","","","","IEEE","IEEE Journals"
"Deep Learning for Quantification of Epicardial and Thoracic Adipose Tissue From Non-Contrast CT","F. Commandeur; M. Goeller; J. Betancur; S. Cadet; M. Doris; X. Chen; D. S. Berman; P. J. Slomka; B. K. Tamarappoo; D. Dey","Cedars-Sinai Medical Center, Biomedical Imaging Research Institute, Los Angeles, CA, USA; Cedars-Sinai Medical Center, Biomedical Imaging Research Institute, Los Angeles, CA, USA; Department of Imaging and Medicine, Cedars-Sinai Medical Center, Los Angeles, CA, USA; Department of Imaging and Medicine, Cedars-Sinai Medical Center, Los Angeles, CA, USA; Department of Imaging and Medicine, Cedars-Sinai Medical Center, Los Angeles, CA, USA; Department of Imaging and Medicine, Cedars-Sinai Medical Center, Los Angeles, CA, USA; Department of Imaging and Medicine, Cedars-Sinai Medical Center, Los Angeles, CA, USA; Department of Imaging and Medicine, Cedars-Sinai Medical Center, Los Angeles, CA, USA; Department of Imaging and Medicine, Cedars-Sinai Medical Center, Los Angeles, CA, USA; Cedars-Sinai Medical Center, Biomedical Imaging Research Institute, Los Angeles, CA, USA","IEEE Transactions on Medical Imaging","","2018","37","8","1835","1846","Epicardial adipose tissue (EAT) is a visceral fat deposit related to coronary artery disease. Fully automated quantification of EAT volume in clinical routine could be a timesaving and reliable tool for cardiovascular risk assessment. We propose a new fully automated deep learning framework for EAT and thoracic adipose tissue (TAT) quantification from non-contrast coronary artery calcium computed tomography (CT) scans. The first multi-task convolutional neural network (ConvNet) is used to determine heart limits and perform segmentation of heart and adipose tissues. The second ConvNet, combined with a statistical shape model, allows for pericardium detection. EAT and TAT segmentations are then obtained from outputs of both ConvNets. We evaluate the performance of the method on CT data sets from 250 asymptomatic individuals. Strong agreement between automatic and expert manual quantification is obtained for both EAT and TAT with median Dice score coefficients of 0.823 (inter-quartile range (IQR): 0.779-0.860) and 0.905 (IQR: 0.862-0.928), respectively; with excellent correlations of 0.924 and 0.945 for EAT and TAT volumes. Computations are performed in <;26 s on a standard personal computer for one CT scan. Therefore, the proposed method represents a tool for rapid fully automated quantification of adipose tissue and may improve cardiovascular risk stratification in patients referred for routine CT calcium scans.","","","10.1109/TMI.2018.2804799","National Heart, Lung, and Blood Institute; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8288602","Convolutional neural networks;deep learning;epicardial adipose tissue;non-contrast computed tomography (CT)","Computed tomography;Heart;Calcium;Biomedical imaging;Machine learning;Arteries;Feature extraction","angiocardiography;biological tissues;biomechanics;blood vessels;computerised tomography;diseases;image registration;image segmentation;learning (artificial intelligence);medical image processing","noncontrast CT;epicardial adipose tissue;visceral fat deposit;coronary artery disease;EAT volume;cardiovascular risk assessment;fully automated deep learning framework;thoracic adipose tissue quantification;noncontrast coronary artery calcium;tomography scans;multitask convolutional neural network;adipose tissues;statistical shape model;TAT segmentations;automatic quantification;cardiovascular risk stratification;CT calcium scans","","1","49","","","","","IEEE","IEEE Journals"
"Mobility-Aware Edge Caching and Computing in Vehicle Networks: A Deep Reinforcement Learning","L. T. Tan; R. Q. Hu","Department of Electrical and Computer Engineering, Utah State University, Logan, UT, USA; Department of Electrical and Computer Engineering, Utah State University, Logan, UT, USA","IEEE Transactions on Vehicular Technology","","2018","67","11","10190","10203","This paper studies the joint communication, caching and computing design problem for achieving the operational excellence and the cost efficiency of the vehicular networks. Moreover, the resource allocation policy is designed by considering the vehicle's mobility and the hard service deadline constraint. These critical challenges have often been either neglected or addressed inadequately in the existing work on the vehicular networks because of their high complexity. We develop a deep reinforcement learning with the multi-timescale framework to tackle these grand challenges in this paper. Furthermore, we propose the mobility-aware reward estimation for the large timescale model to mitigate the complexity due to the large action space. Numerical results are presented to illustrate the theoretical findings developed in the paper and to quantify the performance gains attained.","","","10.1109/TVT.2018.2867191","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8447267","Vehicular networks;mobility;edge caching;edge computing;deep reinforcement learning","Computational modeling;Device-to-device communication;Task analysis;Machine learning;Resource management;Edge computing;Quality of service","communication complexity;learning (artificial intelligence);mobile computing;resource allocation;telecommunication computing;vehicular ad hoc networks","mobility-aware edge caching;mobility-aware edge computing;multitimescale framework;hard service deadline constraint;resource allocation policy;vehicular networks;computing design problem;deep reinforcement learning;mobility-aware reward estimation","","20","50","","","","","IEEE","IEEE Journals"
"Deep convolutional autoencoder for radar-based classification of similar aided and unaided human activities","M. S. Seyfioğlu; A. M. Özbayoğlu; S. Z. Gürbüz","TOBB University of Economics and Technology, Ankara, Turkey; TOBB University of Economics and Technology, Ankara, Turkey; University of Alabama, Tuscaloosa, AL, USA","IEEE Transactions on Aerospace and Electronic Systems","","2018","54","4","1709","1723","Radar-based activity recognition is a problem that has been of great interest due to applications such as border control and security, pedestrian identification for automotive safety, and remote health monitoring. This paper seeks to show the efficacy of micro-Doppler analysis to distinguish even those gaits whose micro-Doppler signatures are not visually distinguishable. Moreover, a three-layer, deep convolutional autoencoder (CAE) is proposed, which utilizes unsupervised pretraining to initialize the weights in the subsequent convolutional layers. This architecture is shown to be more effective than other deep learning architectures, such as convolutional neural networks and autoencoders, as well as conventional classifiers employing predefined features, such as support vector machines (SVM), random forest, and extreme gradient boosting. Results show the performance of the proposed deep CAE yields a correct classification rate of 94.2% for micro-Doppler signatures of 12 different human activities measured indoors using a 4 GHz continuous wave radar-17.3% improvement over SVM.","","","10.1109/TAES.2018.2799758","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8283539","Convolutional autoencoder (CAE);deep learning;gait recognition;micro-Doppler;neural networks;radar.","Legged locomotion;Radar;Spectrogram;Support vector machines;Machine learning;Assisted living","convolution;CW radar;Doppler radar;feature extraction;feedforward neural nets;learning (artificial intelligence);radar computing;radar signal processing;support vector machines","human activities;continuous wave radar;deep CAE;support vector machines;random forest;extreme gradient boosting;remote health monitoring;automotive safety;pedestrian identification;radar-based activity recognition;radar-based classification;convolutional neural networks;deep learning architectures;deep convolutional autoencoder;microDoppler signatures","","25","54","","","","","IEEE","IEEE Journals"
"Deep Canonical Time Warping for Simultaneous Alignment and Representation Learning of Sequences","G. Trigeorgis; M. A. Nicolaou; B. W. Schuller; S. Zafeiriou","Department of Computing, Imperial College London, London, United Kingdom; Department of Computing at Goldsmiths, University of London, London, United Kingdom; Department of Computing, Imperial College London, London, United Kingdom; Department of Computing, Imperial College London, London, United Kingdom","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","5","1128","1138","Machine learning algorithms for the analysis of time-series often depend on the assumption that utilised data are temporally aligned. Any temporal discrepancies arising in the data is certain to lead to ill-generalisable models, which in turn fail to correctly capture properties of the task at hand. The temporal alignment of time-series is thus a crucial challenge manifesting in a multitude of applications. Nevertheless, the vast majority of algorithms oriented towards temporal alignment are either applied directly on the observation space or simply utilise linear projections-thus failing to capture complex, hierarchical non-linear representations that may prove beneficial, especially when dealing with multi-modal data (e.g., visual and acoustic information). To this end, we present Deep Canonical Time Warping (DCTW), a method that automatically learns non-linear representations of multiple time-series that are (i) maximally correlated in a shared subspace, and (ii) temporally aligned. Furthermore, we extend DCTW to a supervised setting, where during training, available labels can be utilised towards enhancing the alignment process. By means of experiments on four datasets, we show that the representations learnt significantly outperform state-of-the-art methods in temporal alignment, elegantly handling scenarios with heterogeneous feature sets, such as the temporal alignment of acoustic and visual information.","","","10.1109/TPAMI.2017.2710047","Department of Computing, Imperial College London; EPSRC; FiDiPro program of Tekes; European Community’s Horizon 2020 Framework Programme; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7944692","Time warping;CCA;LDA;DCCA;DDA;deep learning;shared representations;DCTW","Feature extraction;Correlation;Loading;Eigenvalues and eigenfunctions;Acoustics;Speech recognition;Visualization","data structures;learning (artificial intelligence)","temporal alignment;nonlinear representations;multimodal data;multiple time-series;alignment process;representation learning;machine learning algorithms;utilised data;temporal discrepancies;deep canonical time warping;sequences simultaneous alignment;hierarchical non-linear representations;DCTW;heterogeneous feature sets;visual information;acoustic information","","3","45","","","","","IEEE","IEEE Journals"
"Sharable and Individual Multi-View Metric Learning","J. Hu; J. Lu; Y. Tan","School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore, Singapore; Department of Automation, State Key Lab of Intelligent Technologies and Systems and Tsinghua National Laboratory for Information Science and Technology (TNList), Tsinghua University, Beijing, China; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore, Singapore","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","9","2281","2288","This paper presents a sharable and individual multi-view metric learning (MvML) approach for visual recognition. Unlike conventional metric leaning methods which learn a distance metric on either a single type of feature representation or a concatenated representation of multiple types of features, the proposed MvML jointly learns an optimal combination of multiple distance metrics on multi-view representations, where not only it learns an individual distance metric for each view to retain its specific property but also a shared representation for different views in a unified latent subspace to preserve the common properties. The objective function of the MvML is formulated in the large margin learning framework via pairwise constraints, under which the distance of each similar pair is smaller than that of each dissimilar pair by a margin. Moreover, to exploit the nonlinear structure of data points, we extend MvML to a sharable and individual multi-view deep metric learning (MvDML) method by utilizing the neural network architecture to seek multiple nonlinear transformations. Experimental results on face verification, kinship verification, and person re-identification show the effectiveness of the proposed sharable and individual multi-view metric learning methods.","","","10.1109/TPAMI.2017.2749576","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8027090","Metric learning;deep learning;multi-view learning;face verification;kinship verification;person re-identification","Optimization;Learning systems;Linear programming;Neural networks;Indexes;Extraterrestrial measurements","face recognition;image representation;learning (artificial intelligence);neural net architecture","MvML;distance metric;feature representation;concatenated representation;margin learning framework;Multi-View Metric Learning;neural network architecture;face verification;kinship verification;person re-identification;visual recognition","","11","48","","","","","IEEE","IEEE Journals"
"A 0.76 mm2 0.22 nJ/Pixel DL-Assisted 4K Video Encoder LSI for Quality-of-Experience Over Smartphones","T. Liu; C. Tsai; T. Wu; J. Lin; L. Chen; H. Chou; Y. Chang; C. Ju","Mediatek Inc., Hscinchu, Taiwan; Mediatek Inc., Hscinchu, Taiwan; Mediatek Inc., Hscinchu, Taiwan; Mediatek Inc., Hscinchu, Taiwan; Mediatek Inc., Hscinchu, Taiwan; Mediatek Inc., Hscinchu, Taiwan; Mediatek Inc., Hscinchu, Taiwan; Mediatek Inc., Hscinchu, Taiwan","IEEE Solid-State Circuits Letters","","2018","1","12","221","224","This letter proposes the world'sfirst deep learning (DL)assisted video encoder LSI fabricated in a 10-nm process with a core area of 0.76 mm2 to integrate quad-core DL accelerators and 4K×2K H.264/H.265 video encoders. A visual-contact-held network (VCFNet) DL model is newly designed to predict human focus information with extraordinary reduction of encoding complexity, leading to 82.3% power reduction. Moreover, input channel reduction and layer merging approaches reduce VCFNet complexity by 69%. Operated at 0.9 V and 504 MHz, the proposed DL-assisted 4K video encoder LSI consumes 56.54 mW to achieve 0.22 nJ/pixel of energy efficiency, cutting 0.1-14 nJ/pixel compared to conventional designs.","","","10.1109/LSSC.2019.2905958","MediaTek; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8669786","4K;deep learning (DL);HEVC;smartphone;video coding","Streaming media;Visualization;Feature extraction;Engines;Encoding;Deep learning;Tools","large scale integration;video coding","core area;quad-core DL accelerators;H.264/H.265 video encoders;visual-contact-held network DL model;input channel reduction;DL-assisted 4K video encoder LSI;layer merging approaches;deep learning;human focus information;encoding complexity;smartphones;power 56.54 mW;frequency 504.0 MHz;voltage 0.9 V","","","10","","","","","IEEE","IEEE Journals"
"Photoacoustic Source Detection and Reflection Artifact Removal Enabled by Deep Learning","D. Allman; A. Reiter; M. A. L. Bell","Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD, USA; Department of Computer Science, Johns Hopkins University, Baltimore, MD, USA; Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD, USA","IEEE Transactions on Medical Imaging","","2018","37","6","1464","1477","Interventional applications of photoacoustic imaging typically require visualization of point-like targets, such as the small, circular, cross-sectional tips of needles, catheters, or brachytherapy seeds. When these point-like targets are imaged in the presence of highly echogenic structures, the resulting photoacoustic wave creates a reflection artifact that may appear as a true signal. We propose to use deep learning techniques to identify these types of noise artifacts for removal in experimental photoacoustic data. To achieve this goal, a convolutional neural network (CNN) was first trained to locate and classify sources and artifacts in pre-beamformed data simulated with k-Wave. Simulations initially contained one source and one artifact with various medium sound speeds and 2-D target locations. Based on 3,468 test images, we achieved a 100% success rate in classifying both sources and artifacts. After adding noise to assess potential performance in more realistic imaging environments, we achieved at least 98% success rates for channel signal-to-noise ratios (SNRs) of -9dB or greater, with a severe decrease in performance below -21dB channel SNR. We then explored training with multiple sources and two types of acoustic receivers and achieved similar success with detecting point sources. Networks trained with simulated data were then transferred to experimental waterbath and phantom data with 100% and 96.67% source classification accuracy, respectively (particularly when networks were tested at depths that were included during training). The corresponding mean ± one standard deviation of the point source location error was 0.40 ± 0.22 mm and 0.38 ± 0.25 mm for waterbath and phantom experimental data, respectively, which provides some indication of the resolution limits of our new CNN-based imaging system. We finally show that the CNN-based information can be displayed in a novel artifact-free image format, enabling us to effectively remove reflection artifacts from photoacoustic images, which is not possible with traditional geometry-based beamforming.","","","10.1109/TMI.2018.2829662","National Institute of Biomedical Imaging and Bioengineering; Division of Electrical, Communications and Cyber Systems; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8345287","Photoacoustic imaging;neural networks;machine learning;deep learning;artifact reduction;reflection artifacts","Training;Signal to noise ratio;Testing;Photoacoustic imaging;Acoustics;Array signal processing;Neural networks","acoustic imaging;acoustic signal processing;biomedical optical imaging;feedforward neural nets;image classification;image denoising;image reconstruction;learning (artificial intelligence);medical image processing;phantoms;photoacoustic effect","photoacoustic source detection;deep learning techniques;noise artifacts;experimental photoacoustic data;convolutional neural network;CNN;point source location error;phantom experimental data;photoacoustic wave;SNR;source classification accuracy;artifact-free image;reflection artifact removal;photoacoustic imaging interventional applications;point-like target visualization;echogenic structures;channel signal-to-noise ratios;acoustic receivers;standard deviation;waterbath","","5","42","","","","","IEEE","IEEE Journals"
"Deep Reinforcement Learning for Resource Management in Network Slicing","R. Li; Z. Zhao; Q. Sun; C. I; C. Yang; X. Chen; M. Zhao; H. Zhang","College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China; College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China; Green Communication Research Center, China Mobile Research Institute, Beijing, China; Green Communication Research Center, China Mobile Research Institute, Beijing, China; School of Electronics and Information Engineering, Beihang University, Beijing, China; VTT Technical Research Centre of Finland, Oulu, Finland; College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China; College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China","IEEE Access","","2018","6","","74429","74441","Network slicing is born as an emerging business to operators by allowing them to sell the customized slices to various tenants at different prices. In order to provide better-performing and costefficient services, network slicing involves challenging technical issues and urgently looks forward to intelligent innovations to make the resource management consistent with users' activities per slice. In that regard, deep reinforcement learning (DRL), which focuses on how to interact with the environment by trying alternative actions and reinforcing the tendency actions producing more rewarding consequences, is assumed to be a promising solution. In this paper, after briefly reviewing the fundamental concepts of DRL, we investigate the application of DRL in solving some typical resource management for network slicing scenarios, which include radio resource slicing and priority-based core network slicing, and demonstrate the advantage of DRL over several competing schemes through extensive simulations. Finally, we also discuss the possible challenges to apply DRL in network slicing from a general perspective.","","","10.1109/ACCESS.2018.2881964","National Key R&D Program of China; National Natural Science Foundation of China; Zhejiang Key Research and Development Plan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8540003","Deep reinforcement learning;network slicing;neural networks;Q-learning;resource management","Network slicing;Resource management;Neural networks;5G mobile communication;Quality of experience","learning (artificial intelligence);neural nets;quality of service;resource allocation;telecommunication traffic;virtualisation","intelligent innovations;resource management;priority-based core network slicing;radio resource slicing;network slicing scenarios;DRL;customized slices;deep reinforcement learning","","13","24","","","","","IEEE","IEEE Journals"
"DeepNap: Data-Driven Base Station Sleeping Operations Through Deep Reinforcement Learning","J. Liu; B. Krishnamachari; S. Zhou; Z. Niu","Department of Electronic Engineering, Beijing National Research Center for Information Science and Technology, Tsinghua University, Beijing, China; Ming Hsieh Department of Electrical Engineering, University of Southern California, Los Angeles, CA, USA; Department of Electronic Engineering, Beijing National Research Center for Information Science and Technology, Tsinghua University, Beijing, China; Department of Electronic Engineering, Beijing National Research Center for Information Science and Technology, Tsinghua University, Beijing, China","IEEE Internet of Things Journal","","2018","5","6","4273","4282","Base station (BS) sleeping is an effective way to reduce the energy consumption of mobile networks. Previous efforts to design sleeping control algorithms mainly rely on stochastic traffic models and analytical derivation. However, the tractability of models often conflicts with the complexity of real-world traffic, making it difficult to apply in reality. In this paper, we propose a data-driven algorithm for dynamic sleeping control called DeepNap. This algorithm uses a deep Q-network (DQN) to learn effective sleeping policies from high-dimensional raw observations or un-quantized systems state vectors. We propose to enhance the original DQN algorithm with action-wise experience replay and adaptive reward scaling to deal with the challenges in nonstationary traffic. We also provide a model-assisted variant of DeepNap through the Dyna framework for inferring and simulating system dynamics. Periodical traffic modeling makes it possible to capture the nonstationarity in real-world traffic and the incorporation with DQN allows for feature learning and generalization from model outputs. Experiments show that both the end-to-end and the model-assisted version of DeepNap outperform table-based  ${Q}$ -learning algorithm and the nonstationarity enhancements improve the stability of vanilla DQN.","","","10.1109/JIOT.2018.2846694","National Natural Science Foundation of China; Hitachi; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8382258","Base station (BS) sleeping;deep Q-network (DQN);deep reinforcement learning (RL);nonstationary traffic","Hidden Markov models;Heuristic algorithms;Adaptation models;Internet of Things;Machine learning;Analytical models;Energy consumption;Reinforcement learning","","","","8","34","","","","","IEEE","IEEE Journals"
"Investigating Nuisances in DCNN-Based Face Recognition","C. Ferrari; G. Lisanti; S. Berretti; A. Del Bimbo","Department of Information Engineering, University of Florence, Florence, Italy; Department of Electrical, Computer and Biomedical Engineering, University of Pavia, Pavia, Italy; Department of Information Engineering, University of Florence, Florence, Italy; Department of Information Engineering, University of Florence, Florence, Italy","IEEE Transactions on Image Processing","","2018","27","11","5638","5651","Face recognition “in the wild” has been revolutionized by the deployment of deep learning-based approaches. In fact, it has been extensively demonstrated that deep convolutional neural networks (DCNNs) are powerful enough to overcome most of the limits that affected face recognition algorithms based on hand-crafted features. These include variations in illumination, pose, expression, and occlusion, to mention some. The DCNNs discriminative power comes from the fact that low-and high-level representations are learned directly from the raw image data. As a consequence, we expect the performance of a DCNN to be influenced by the characteristics of the image/video data that are fed to the network, and their preprocessing. In this paper, we present a thorough analysis of several aspects that impact on the use of DCNN for face recognition. The evaluation has been carried out from two main perspectives: the network architecture and the similarity measures used to compare deeply learned features; and the data (source and quality) and their preprocessing (bounding box and alignment). The results obtained on the IARPA Janus Benchmark-A, MegaFace, UMDFaces, and YouTube Faces data sets indicate viable hints for designing, training, and testing DCNNs. Considering the outcomes of the experimental evaluation, we show how competitive performance with respect to the state of the art can be reached even with standard DCNN architectures and pipeline.","","","10.1109/TIP.2018.2861359","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8423119","Face recognition;deep learning;CNN architecture;distance measures","Face recognition;Training;Distance measurement;Deep learning;Convolutional neural networks","face recognition;feedforward neural nets;learning (artificial intelligence);visual databases","video data;face recognition algorithms;raw image data;high-level representations;low- level representations;DCNNs discriminative power;hand-crafted features;deep convolutional neural networks;deep learning-based approaches;DCNN-based face recognition;pipeline;YouTube Faces data sets;deeply learned features;network architecture","","2","42","","","","","IEEE","IEEE Journals"
"Transformer Fault Diagnosis Using Self-Powered RFID Sensor and Deep Learning Approach","T. Wang; Y. He; B. Li; T. Shi","School of Electrical Engineering and Automation, Hefei University of Technology, Hefei, China; School of Electrical Engineering and Automation, Hefei University of Technology, Hefei, China; School of Electrical Engineering and Automation, Hefei University of Technology, Hefei, China; School of Electrical Engineering and Automation, Hefei University of Technology, Hefei, China","IEEE Sensors Journal","","2018","18","15","6399","6411","This paper introduces a novel fault diagnosis approach for transformer based on self-powered radio-frequency identification (RFID) sensor and deep learning technique. The exploited RFID sensor tag with functionalities of signal collection, data storage, and wireless transmission employs surrounding electromagnetic field as power source. A customized power management circuit, including ac-dc converter, supercapacitor, and its corresponding charging circuit, is presented to guarantee constant dc power for the sensor tag. The measured vibration signal contains miscellaneous noises and is characterized as nonlinearity and nonstationarity, so it is difficult to extract robust and useful features by using traditional feature extraction approaches. As one of the deep learning techniques, stacked denoising autoencoder (SDA) shows satisfactory performance in learning robust features from complex signal. Hence, in this paper, SDA approach is employed to learn robust and discriminative features from measured signals. The experimental results show that the presented power supply can generate 2.5-V dc voltage, which is the rated operating voltage for the rest of the sensor tag. The developed sensor tag can achieve a reliable communication distance of 17.3 m in the test environment. Furthermore, the SDA approach shows satisfactory performance in learning robust and discriminative features. Experimental results indicate that the presented approach is effective and time-saving in terms of fault diagnosis for transformer winding and core.","","","10.1109/JSEN.2018.2844799","National Natural Science Foundation of China; State Key Program of National Natural Science Foundation of China; National Key Research and Development Plan—Important Scientific Instruments and Equipment Development; Equipment Research Project in Advance; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8374948","Transformer;fault diagnosis;self-powered RFID sensor tag;stacked denoising autoencoder","Radiofrequency identification;Feature extraction;Fault diagnosis;Supercapacitors;Vibrations;Power transformers","AC-DC power convertors;fault diagnosis;feature extraction;learning (artificial intelligence);power engineering computing;radiofrequency identification;signal denoising;supercapacitors;transformer windings;vibrational signal processing","transformer fault diagnosis;self-powered RFID sensor;deep learning approach;fault diagnosis approach;deep learning technique;customized power management circuit;ac-dc converter;constant dc power;deep learning techniques;complex signal;SDA approach;transformer winding;vibration signal;charging circuit;RFID sensor tag","","5","52","","","","","IEEE","IEEE Journals"
"Strengths and weaknesses of deep learning models for face recognition against image degradations","K. Grm; V. Štruc; A. Artiges; M. Caron; H. K. Ekenel","University of Ljubljana, Slovenia; University of Ljubljana, Slovenia; ENSEA, France; ENSEA, France; Istanbul Technical University, Turkey","IET Biometrics","","2018","7","1","81","89","Convolutional neural network (CNN) based approaches are the state of the art in various computer vision tasks including face recognition. Considerable research effort is currently being directed toward further improving CNNs by focusing on model architectures and training techniques. However, studies systematically exploring the strengths and weaknesses of existing deep models for face recognition are still relatively scarce. In this paper, we try to fill this gap and study the effects of different covariates on the verification performance of four recent CNN models using the Labelled Faces in the Wild dataset. Specifically, we investigate the influence of covariates related to image quality and model characteristics, and analyse their impact on the face verification performance of different deep CNN models. Based on comprehensive and rigorous experimentation, we identify the strengths and weaknesses of the deep learning models, and present key areas for potential future research. Our results indicate that high levels of noise, blur, missing pixels, and brightness have a detrimental effect on the verification performance of all models, whereas the impact of contrast changes and compression artefacts is limited. We find that the descriptor-computation strategy and colour information does not have a significant influence on performance.","","","10.1049/iet-bmt.2017.0083","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8244393","","","brightness;computer vision;data compression;face recognition;feedforward neural nets;image coding;image colour analysis;learning (artificial intelligence)","deep learning model strength;deep learning model weakness;face recognition;image degradations;deep convolutional neural network based approach;computer vision tasks;model architectures;learning techniques;deep CNN models;labelled faces in the wild dataset;image quality;blur;Joint Photographic Experts Group compression;occlusion;noise;image brightness;contrast;missing pixels;model characteristics;CNN architecture;colour information;descriptor computation;face verification performance;AlexNet;VGG-Face;GoogLeNet;SqueezeNet;compression artifacts;descriptor-computation strategy","","13","40","","","","","IET","IET Journals"
"Deep Episodic Memory: Encoding, Recalling, and Predicting Episodic Experiences for Robot Action Execution","J. Rothfuss; F. Ferreira; E. E. Aksoy; Y. Zhou; T. Asfour","Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; School of Information Technology, Halmstad University, Halmstad, Sweden; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany","IEEE Robotics and Automation Letters","","2018","3","4","4007","4014","We present a novel deep neural network architecture for representing robot experiences in an episodic-like memory that facilitates encoding, recalling, and predicting action experiences. Our proposed unsupervised deep episodic memory model as follows: First, encodes observed actions in a latent vector space and, based on this latent encoding, second, infers most similar episodes previously experienced, third, reconstructs original episodes, and finally, predicts future frames in an end-to-end fashion. Results show that conceptually similar actions are mapped into the same region of the latent vector space. Based on these results, we introduce an action matching and retrieval mechanism, benchmark its performance on two large-scale action datasets, 20BN-something-something and ActivityNet and evaluate its generalization capability in a real-world scenario on a humanoid robot.","","","10.1109/LRA.2018.2860057","European Union's Horizon 2020 research and innovation programme; German Research Foundation (DFG: Deutsche Forschungsgemeinschaft) under Priority Program on Autonomous Learning; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8421022","Learning and adaptive systems;visual learning;deep learning in robotics and automation","Visualization;Robots;Decoding;Encoding;Neural networks;Predictive models;Image reconstruction","humanoid robots;image coding;image matching;image reconstruction;image retrieval;neural nets;robot vision;unsupervised learning","latent vector space;action matching;large-scale action datasets;humanoid robot;robot action execution;deep neural network architecture;robot experiences;unsupervised deep episodic memory model;latent encoding;episodic experience prediction;episode reconstruction;action experience prediction;retrieval mechanism;ActivityNet","","2","34","","","","","IEEE","IEEE Journals"
"Automatic Colon Polyp Detection Using Region Based Deep CNN and Post Learning Approaches","Y. Shin; H. A. Qadir; L. Aabakken; J. Bergsland; I. Balasingham","Department of Electronic Systems, Norwegian University of Science and Technology, Trondheim, Norway; Intervention Centre, Oslo University Hospital, Oslo, Norway; Intervention Centre, Oslo University Hospital, Oslo, Norway; Intervention Centre, Oslo University Hospital, Oslo, Norway; Department of Electronic Systems, Norwegian University of Science and Technology, Trondheim, Norway","IEEE Access","","2018","6","","40950","40962","Automatic image detection of colonic polyps is still an unsolved problem due to the large variation of polyps in terms of shape, texture, size, and color, and the existence of various polyp-like mimics during colonoscopy. In this paper, we apply a recent region-based convolutional neural network (CNN) approach for the automatic detection of polyps in the images and videos obtained from colonoscopy examinations. We use a deep-CNN model (Inception Resnet) as a transfer learning scheme in the detection system. To overcome the polyp detection obstacles and the small number of polyp images, we examine image augmentation strategies for training deep networks. We further propose two efficient post-learning methods, such as automatic false positive learning and offline learning, both of which can be incorporated with the region-based detection system for reliable polyp detection. Using the large size of colonoscopy databases, experimental results demonstrate that the suggested detection systems show better performance than other systems in the literature. Furthermore, we show improved detection performance using the proposed post-learning schemes for colonoscopy videos.","","","10.1109/ACCESS.2018.2856402","European Research Consortium for Informatics and Mathematics; Norges Forskningsråd; Norges Forskningsråd; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8416731","Colonoscopy;convolutional neural network;image augmentation;polyp detection;region proposal network;transfer learning","Training;Colonoscopy;Videos;Detectors;Image color analysis;Proposals;Feature extraction","cancer;convolution;endoscopes;feedforward neural nets;image classification;image recognition;learning (artificial intelligence);medical image processing","polyp-like mimics;deep-CNN model;transfer learning scheme;polyp images;image augmentation strategies;offline learning;region-based detection system;colonoscopy databases;colonoscopy videos;colon polyp detection;image detection;region-based convolutional neural network;post-learning methods;false positive learning","","8","42","","","","","IEEE","IEEE Journals"
"Magnetic Skyrmion as a Spintronic Deep Learning Spiking Neuron Processor","M. Chen; A. Sengupta; K. Roy","Department of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA; Department of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA; Department of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA","IEEE Transactions on Magnetics","","2018","54","8","1","7","Deep spiking neural networks (SNNs) have emerged as one of the popular architectures in complex pattern recognition and classification tasks that can be enabled by low-power neuromorphic hardware. However, hardware implementation of such algorithms using conventional CMOS devices is area expensive and energy inefficient. This is owing to the fundamental mismatch between the underlying neuromophic computations and the CMOS transistors along with energy consumption involved in synaptic memory-access operations. Hence, there is a need for novel “neuro-mimetic” devices offering a direct mapping to synaptic and neuronal functionalities together with the possibility of providing in situ synaptic storage. Magnetic skyrmions have recently been proposed as a promising alternative for next-generation information carrier due to remarkably high stability, ultra-low depinning current density, and extremely compact size. In this paper, the design of skyrmion-based devices to emulate biological synapses and neurons is explored, and skyrmionic synapse-based crossbar architectures driving skyrmionic neurons are proposed. We perform a systematic device-circuit-architecture co-design for digit recognition with the MNIST handwritten digits dataset to evaluate the feasibility of our proposal. The device-to-system simulations indicate that the proposed skyrmion-based devices in deep SNNs can potentially achieve two orders of magnitude improvement in energy consumption over an optimized CMOS implementation at a 45 nm technology node.","","","10.1109/TMAG.2018.2845890","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8398530","Deep learning architectures;magnetic Skyrmion (MS);magnus force;spiking neural network (SNN);spintronics","Micromagnetics;Neurons;Synapses;Magnetic tunneling;Spintronics;Biological neural networks;Computer architecture","CMOS integrated circuits;current density;learning (artificial intelligence);magnetoelectronics;memristors;neural chips;skyrmions","synaptic functionalities;neuronal functionalities;magnetic skyrmion;next-generation information carrier;ultra-low depinning current density;extremely compact size;skyrmion-based devices;skyrmionic synapse-based;skyrmionic neurons;digit recognition;device-to-system simulations;deep SNNs;energy consumption;optimized CMOS implementation;spintronic deep learning spiking neuron processor;neural networks;complex pattern recognition;classification tasks;low-power neuromorphic hardware;conventional CMOS devices;CMOS transistors;synaptic memory-access operations;neuro-mimetic devices;direct mapping;neuromophic computations;in situ synaptic storage;biological synapses;skyrmionic synapse-based crossbar architectures;systematic device-circuit-architecture codesign;MNIST handwritten digit dataset;size 45.0 nm","","3","36","","","","","IEEE","IEEE Journals"
"Physiological Inspired Deep Neural Networks for Emotion Recognition","P. M. Ferreira; F. Marques; J. S. Cardoso; A. Rebelo","Centre for Telecommunications and Multimedia, INESC TEC, Porto, Portugal; Faculdade de Engenharia da Universidade do Porto, Porto, Portugal; Centre for Telecommunications and Multimedia, INESC TEC, Porto, Portugal; Centre for Telecommunications and Multimedia, INESC TEC, Porto, Portugal","IEEE Access","","2018","6","","53930","53943","Facial expression recognition (FER) is currently one of the most active research topics due to its wide range of applications in the human-computer interaction field. An important part of the recent success of automatic FER was achieved thanks to the emergence of deep learning approaches. However, training deep networks for FER is still a very challenging task, since most of the available FER data sets are relatively small. Although transfer learning can partially alleviate the issue, the performance of deep models is still below of its full potential as deep features may contain redundant information from the pre-trained domain. Instead, we propose a novel end-to-end neural network architecture along with a well-designed loss function based on the strong prior knowledge that facial expressions are the result of the motions of some facial muscles and components. The loss function is defined to regularize the entire learning process so that the proposed neural network is able to explicitly learn expression-specific features. Experimental results demonstrate the effectiveness of the proposed model in both lab-controlled and wild environments. In particular, the proposed neural network provides quite promising results, outperforming in most cases the current state-of-the-art methods.","","","10.1109/ACCESS.2018.2870063","European Regional Development Fund; National Funds through the Portuguese funding agency, Fundação para a Ciência e a Tecnologia (FCT); Fundação para a Ciência e a Tecnologia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8472816","Facial expressions recognition;convolutional neural networks;regularization;domain-knowledge","Neural networks;Feature extraction;Face recognition;Machine learning;Training;Emotion recognition;Task analysis","emotion recognition;face recognition;feature extraction;learning (artificial intelligence);neural nets","emotion recognition;facial expression recognition;active research topics;human-computer interaction field;recent success;automatic FER;deep learning approaches;deep networks;available FER data sets;transfer learning;deep models;deep features;redundant information;pre-trained domain;end-to-end neural network architecture;well-designed loss function;facial expressions;facial muscles;entire learning process;expression-specific features;physiological inspired deep neural networks","","","57","","","","","IEEE","IEEE Journals"
"DeepMEC: Mobile Edge Caching Using Deep Learning","K. Thar; N. H. Tran; T. Z. Oo; C. S. Hong","Department of Computer Science and Engineering, Kyung Hee University, Yongin, South Korea; School of Computer Science, The University of Sydney, Sydney, NSW, Australia; Department of Computer Science and Engineering, Kyung Hee University, Yongin, South Korea; Department of Computer Science and Engineering, Kyung Hee University, Yongin, South Korea","IEEE Access","","2018","6","","78260","78275","Caching popular contents at edge nodes such as base stations is a crucial solution for improving users' quality of services in next-generation networks. However, it is very challenging to correctly predict the future popularity of contents and decide which contents should be stored in the base station cache. Recently, with the advances in big data and high computing power, deep learning models have achieved high prediction accuracy. Hence, in this paper, deep learning is used to learn and predict the future popularity of contents to support cache decision. First, deep learning models are trained and utilized in the cloud data center to make an efficient cache decision. Then, the final cache decision is sent to each base station to store the popular contents proactively. The proposed caching scheme involves three distinct parts: 1) predicting the future class label of each content; 2) predicting the future popularity score of contents based on the predicted class label; and 3) caching the predicted contents with high popularity scores. The prediction models using the Keras and Tensorflow libraries are implemented in this paper. Finally, the performance of the caching schemes is tested with a Python-based simulator. In terms of a cache hit, simulation results show that the proposed scheme outperforms 38%, convolutional recurrent neural network-based scheme outperforms 33%, and convolutional neural network-based scheme outperforms 25% compared to the baseline scheme.","","","10.1109/ACCESS.2018.2884913","National Research Foundation of Korea; Korean Government (MSIT); Institute for Information and communications Technology Promotion; Korean Government (MSIT) through the Development of Access Technology Agnostic Next-Generation Networking Technology for Wired-Wireless Converged Networks; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8576500","Mobile edge computing;deep learning;proactive caching;prediction model searching","Predictive models;Computational modeling;Data models;Videos;Training;Base stations","computer centres;convolutional neural nets;learning (artificial intelligence);mobile computing;prediction theory;recurrent neural nets","Python-based simulator;convolutional recurrent neural network-based scheme;mobile edge caching;next-generation networks;big data;deep learning models;cloud data center;Keras libraries;Tensorflow libraries;quality of service;DeepMEC;base station caching scheme;predicted class label models","","5","42","","","","","IEEE","IEEE Journals"
"Efficient Deep Neural Network Serving: Fast and Furious","F. Yan; Y. He; O. Ruwase; E. Smirni","Department of Computer Science and Engineering, University of Nevada at Reno, Reno, NV, USA; Microsoft Research, Redmond, WA, USA; Microsoft Research, Redmond, WA, USA; Department of Computer Science, College of William and Mary, Williamsburg, VA, USA","IEEE Transactions on Network and Service Management","","2018","15","1","112","126","The emergence of deep neural networks (DNNs) as a state-of-the-art machine learning technique has enabled a variety of artificial intelligence applications for image recognition, speech recognition and translation, drug discovery, and machine vision. These applications are backed by large DNN models running in serving mode on a cloud computing infrastructure to process client inputs such as images, speech segments, and text segments. Given the compute-intensive nature of large DNN models, a key challenge for DNN serving systems is to minimize the request response latencies. This paper characterizes the behavior of different parallelism techniques for supporting scalable and responsive serving systems for large DNNs. We identify and model two important properties of DNN workloads: 1) homogeneous request service demand and 2) interference among requests running concurrently due to cache/memory contention. These properties motivate the design of serving deep learning systems fast (SERF), a dynamic scheduling framework that is powered by an interference-aware queueing-based analytical model. To minimize response latency for DNN serving, SERF quickly identifies and switches to the optimal parallel configuration of the serving system by using both empirical and analytical methods. Our evaluation of SERF using several well-known benchmarks demonstrates its good latency prediction accuracy, its ability to correctly identify optimal parallel configurations for each benchmark, its ability to adapt to changing load conditions, and its efficiency advantage (by at least three orders of magnitude faster) over exhaustive profiling. We also demonstrate that SERF supports other scheduling objectives and can be extended to any general machine learning serving system with the similar parallelism properties as above.","","","10.1109/TNSM.2018.2808352","NSF; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8298516","Deep learning;DNN serving;scheduling;parallelism;performance;analytical model;interference-aware","Parallel processing;Computational modeling;Neurons;Servers;Load modeling;Neural networks;Benchmark testing","cloud computing;image recognition;learning (artificial intelligence);neural nets;scheduling","SERF;good latency prediction accuracy;optimal parallel configuration;general machine learning;efficient deep neural network serving;deep neural networks;artificial intelligence applications;image recognition;drug discovery;machine vision;DNN models;compute-intensive nature;key challenge;DNN serving systems;request response latencies;different parallelism techniques;scalable serving systems;responsive serving systems;DNN workloads;deep learning systems;dynamic scheduling framework;interference-aware queueing;DNN;cache-memory contention","","1","61","","","","","IEEE","IEEE Journals"
"Adaptive Feature Mapping for Customizing Deep Learning Based Facial Expression Recognition Model","B. Wu; C. Lin","Electrical and Control Engineering, National Chiao Tung University, Hsinchu, Taiwan; Electrical and Control Engineering, National Chiao Tung University, Hsinchu, Taiwan","IEEE Access","","2018","6","","12451","12461","Automated facial expression recognition can greatly improve the human-machine interface. The machine can provide better and more personalized services when it knows the human's emotion. This kind of improvement is an important progress in this artificial intelligence era. Many deep learning approaches have been applied in recent years due to their outstanding recognition accuracy after training with large amounts of data. The performance is limited, however, by the specific environmental conditions and variations in different persons involved. Hence, this paper addresses the issue of how to customize the generic model without label information from the testing samples. Weighted Center Regression Adaptive Feature Mapping (W-CR-AFM) is mainly proposed to transform the feature distribution of testing samples into that of trained samples. By means of minimizing the error between each feature of testing sample and the center of the most relevant category, W-CR-AFM can bring the features of testing samples around the decision boundary to the centers of expression categories; therefore, their predicted labels can be corrected. When the model which is tuned by W-CR-AFM is tested on extended Cohn-Kanade (CK+), Radboud Faces database, and Amsterdam dynamic facial expression set, our approach can improve the recognition accuracy by about 3.01%, 0.49%, and 5.33%, respectively. Compared to the competing deep learning architectures with the same training data, our approach shows the better performance.","","","10.1109/ACCESS.2018.2805861","Ministry of Science Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8291717","Cross domain adaption;facial expression recognition;computer vision;pattern recognition;image processing","Testing;Databases;Feature extraction;Training;Face recognition;Training data;Machine learning","emotion recognition;face recognition;feature extraction;learning (artificial intelligence);visual databases","facial expression recognition model;automated facial expression recognition;human-machine interface;personalized services;artificial intelligence era;deep learning approaches;specific environmental conditions;generic model;label information;Weighted Center Regression Adaptive Feature Mapping;W-CR-AFM;feature distribution;expression categories;Amsterdam dynamic facial expression;training data;recognition accuracy;deep learning architectures;decision boundary;Cohn-Kanade database;Radboud faces database;Amsterdam dynamic facial expression set","","5","36","","","","","IEEE","IEEE Journals"
"Photorealistic Monocular Gaze Redirection Using Machine Learning","D. Kononenko; Y. Ganin; D. Sungatullina; V. Lempitsky","Skolkovo Institute of Science and Technology, Moscow, Russia; Université de Montréal, Montréal, Quebec, Canada; Skolkovo Institute of Science and Technology, Moscow, Russia; Skolkovo Institute of Science and Technology, Moscow, Russia","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","11","2696","2710","We propose a general approach to the gaze redirection problem in images that utilizes machine learning. The idea is to learn to re-synthesize images by training on pairs of images with known disparities between gaze directions. We show that such learning-based re-synthesis can achieve convincing gaze redirection based on monocular input, and that the learned systems generalize well to people and imaging conditions unseen during training. We describe and compare three instantiations of our idea. The first system is based on efficient decision forest predictors and redirects the gaze by a fixed angle in real-time (on a single CPU), being particularly suitable for the videoconferencing gaze correction. The second system is based on a deep architecture and allows gaze redirection by a range of angles. The second system achieves higher photorealism, while being several times slower. The third system is based on real-time decision forests at test time, while using the supervision from a “teacher” deep network during training. The third system approaches the quality of a teacher network in our experiments, and thus provides a highly realistic real-time monocular solution to the gaze correction problem. We present in-depth assessment and comparisons of the proposed systems based on quantitative measurements and a user study.","","","10.1109/TPAMI.2017.2737423","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8010348","Gaze redirection;machine learning;deep learning;random forest;weakly-supervised learning;image resynthesis","Real-time systems;Training;Cameras;Teleconferencing;Face;Magnetic heads","image motion analysis;learning (artificial intelligence);video signal processing","fixed angle;gaze correction problem;photorealistic monocular gaze redirection;gaze redirection problem;gaze directions;learning-based re-synthesis;monocular input;imaging conditions;machine learning;video conferencing gaze correction;deep network;monocular solution;decision forest predictors;images resynthesis","","1","50","","","","","IEEE","IEEE Journals"
"Action Recognition in Video Sequences using Deep Bi-Directional LSTM With CNN Features","A. Ullah; J. Ahmad; K. Muhammad; M. Sajjad; S. W. Baik","Intelligent Media Laboratory, Digital Contents Research Institute, Sejong University, Seoul, South Korea; Intelligent Media Laboratory, Digital Contents Research Institute, Sejong University, Seoul, South Korea; Intelligent Media Laboratory, Digital Contents Research Institute, Sejong University, Seoul, South Korea; Department of Computer Science, Digital Image Processing Laboratory, Islamia College Peshawar, Peshawar, Pakistan; Intelligent Media Laboratory, Digital Contents Research Institute, Sejong University, Seoul, South Korea","IEEE Access","","2018","6","","1155","1166","Recurrent neural network (RNN) and long short-term memory (LSTM) have achieved great success in processing sequential multimedia data and yielded the state-of-the-art results in speech recognition, digital signal processing, video processing, and text data analysis. In this paper, we propose a novel action recognition method by processing the video data using convolutional neural network (CNN) and deep bidirectional LSTM (DB-LSTM) network. First, deep features are extracted from every sixth frame of the videos, which helps reduce the redundancy and complexity. Next, the sequential information among frame features is learnt using DB-LSTM network, where multiple layers are stacked together in both forward pass and backward pass of DB-LSTM to increase its depth. The proposed method is capable of learning long term sequences and can process lengthy videos by analyzing features for a certain time interval. Experimental results show significant improvements in action recognition using the proposed method on three benchmark data sets including UCF-101, YouTube 11 Actions, and HMDB51 compared with the state-of-the-art action recognition methods.","","","10.1109/ACCESS.2017.2778011","National Research Foundation of Korea Grant; Korea Government (MSIP); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8121994","Action recognition;deep learning;recurrent neural network;deep bidirectional long short-term memory;convolution neural network","Feature extraction;Computer architecture;Streaming media;Visualization;Microprocessors;Logic gates;Shape","convolution;feature extraction;feedforward neural nets;image sequences;learning (artificial intelligence);recurrent neural nets;video signal processing","video data;convolutional neural network;deep bidirectional LSTM network;DB-LSTM;YouTube 11 Actions;video sequences;long short-term memory;speech recognition;digital signal processing;video processing;text data analysis;action recognition;recurrent neural network;deep feature extraction;video frames;sequence learning;UCF-101;HMDB51","","34","45","","","","","IEEE","IEEE Journals"
"SAR Targets Classification Based on Deep Memory Convolution Neural Networks and Transfer Parameters","R. Shang; J. Wang; L. Jiao; R. Stolkin; B. Hou; Y. Li","Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, International Research Center for Intelligent Perception and Computation, School of Artificial Intelligence, Xidian University, Xi'an, China; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, International Research Center for Intelligent Perception and Computation, School of Artificial Intelligence, Xidian University, Xi'an, China; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, International Research Center for Intelligent Perception and Computation, School of Artificial Intelligence, Xidian University, Xi'an, China; Extreme Robotics Lab, University of Birmingham, Birmingham, U.K.; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, International Research Center for Intelligent Perception and Computation, School of Artificial Intelligence, Xidian University, Xi'an, China; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, International Research Center for Intelligent Perception and Computation, School of Artificial Intelligence, Xidian University, Xi'an, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2018","11","8","2834","2846","Deep learning has obtained state-of-the-art results in a variety of computer vision tasks and has also been used to solve SAR image classification problems. Deep learning algorithms typically require a large amount of training data to achieve high accuracy. In contrast, the size of SAR image datasets is often comparatively limited. Therefore, this paper proposes a novel method, deep memory convolution neural networks (M-Net), to alleviate the problem of overfitting caused by insufficient SAR image samples. Based on the convolutional neural networks (CNN), M-Net adds an information recorder to remember and store samples' spatial features, and then it uses spatial similarity information of the recorded features to predict unknown sample labels. M-Net's use of this information recorder may cause difficulties for convergence if conventional CNN training methods were directly used to train M-Net. To overcome this problem, we propose a transfer parameter technique to train M-Net in two steps. The first step is to train a CNN, which has the same structure as the part of CNN incorporated in M-Net, to obtain initial training parameters. The second step applies the initialized parameters to M-Net and then trains the entire M-Net. This two-step training approach helps us to overcome the nonconvergence issue, and also reduces training time. We evaluate M-Net using the public benchmark MSTAR dataset, and achieve higher accuracy than several other well-known SAR image classification algorithms.","","","10.1109/JSTARS.2018.2836909","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8375097","Deep learning;memory convolutional neural networks (M-Net);parameter transfer;synthetic aperture radar (SAR) targets classification","Training;Feature extraction;Synthetic aperture radar;Convolution;Machine learning;Neural networks;Data mining","computer vision;feature extraction;feedforward neural nets;image classification;learning (artificial intelligence);neural nets;radar imaging;synthetic aperture radar","training time;SAR image classification algorithms;SAR targets classification;computer vision tasks;SAR image classification problems;deep learning algorithms;training data;SAR image datasets;deep memory convolution neural networks;convolutional neural networks;information recorder;spatial similarity information;recorded features;unknown sample labels;conventional CNN training methods;transfer parameter technique;initial training parameters;initialized parameters;two-step training approach;M-Net;public benchmark MSTAR dataset","","4","43","","","","","IEEE","IEEE Journals"
"Framing U-Net via Deep Convolutional Framelets: Application to Sparse-View CT","Y. Han; J. C. Ye","Department of Bio and Brain Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Department of Bio and Brain Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea","IEEE Transactions on Medical Imaging","","2018","37","6","1418","1429","X-ray computed tomography (CT) using sparse projection views is a recent approach to reduce the radiation dose. However, due to the insufficient projection views, an analytic reconstruction approach using the filtered back projection (FBP) produces severe streaking artifacts. Recently, deep learning approaches using large receptive field neural networks such as U-Net have demonstrated impressive performance for sparse-view CT reconstruction. However, theoretical justification is still lacking. Inspired by the recent theory of deep convolutional framelets, the main goal of this paper is, therefore, to reveal the limitation of U-Net and propose new multi-resolution deep learning schemes. In particular, we show that the alternative U-Net variants such as dual frame and tight frame U-Nets satisfy the so-called frame condition which makes them better for effective recovery of high frequency edges in sparse-view CT. Using extensive experiments with real patient data set, we demonstrate that the new network architectures provide better reconstruction performance.","","","10.1109/TMI.2018.2823768","Korea Science and Engineering Foundation; Industrial Strategic Technology Development Program through the Ministry of Trade, Industry and Energy, South Korea; Development of Novel Artificial Intelligence Technologies To Assist Imaging Diagnosis of Pulmonary, Hepatic, and Cardiac Diseases and Their Integration into Commercial Clinical PACS Platforms; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8332969","Deep learning;U-Net;convolutional neural network (CNN);convolution framelets;frame condition","Computed tomography;Convolution;Machine learning;Image reconstruction;Inverse problems;Matrix decomposition;Neural networks","computerised tomography;feedforward neural nets;image reconstruction;learning (artificial intelligence);medical image processing","frame condition;reconstruction performance;deep convolutional framelets;sparse projection views;radiation dose;analytic reconstruction approach;filtered back projection;severe streaking artifacts;receptive field neural networks;sparse-view CT reconstruction;multiresolution deep learning schemes;X-ray computed tomography;dual frame U-Nets;U-Net variants;tight frame U-Nets","","14","46","","","","","IEEE","IEEE Journals"
"Deep Dilation on Multimodality Time Series for Human Activity Recognition","R. Xi; M. Li; M. Hou; M. Fu; H. Qu; D. Liu; C. R. Haruna","School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China","IEEE Access","","2018","6","","53381","53396","Providing accurate information on people's activities and behaviors plays an important role in innumerable applications, such as medical, security, and entertainment. In recent years, deep learning has been applied in human activity recognition, and achieved a better performance. However, if the spatial dependency of inter-sensors is considered, it is possible to enhance the discriminative ability. In this paper, we present a novel deep learning framework for human activity recognition problems. First, on the basis of our previous work, we utilize dilated convolutional neural network to extract features of inter-sensors and intra-sensors. Since the extracted features are local and short-temporal, it is necessary to utilize RNN to model the long-temporal dependencies. However, duo to that LSTM and GRU often rely on the completely previous computations, it will result in slow inference and hard convergence. Hence, inspired by the idea of dilation operation, we present a novel recurrent model to learn the temporal dependencies at different time scales. Then, at the topmost layer, a fully-connected layer with softmax function is utilized to generate a class probability distribution, and the predicted activity is obtained. Eventually, we evaluate the proposed framework in two open human activity datasets, OPPORTUNITY and PAMAP2. Results demonstrate that the proposed framework achieves a higher classification performance than the state-of-the-art methods. Moreover, it takes the least time to recognize an activity. Besides, it also performs faster and easier to converge in the training stage.","","","10.1109/ACCESS.2018.2870841","NSF China Projects; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8467310","Dilation operation;deep learning;feature representation;human activity recognition;multimodality time series","Feature extraction;Machine learning;Convolution;Activity recognition;Training;Time series analysis","convolution;feature extraction;feedforward neural nets;learning (artificial intelligence);pattern classification;probability;recurrent neural nets;time series","class probability distribution;softmax function;recurrent model;GRU;LSTM;feature extraction;spatial dependency;multimodality time series;deep dilation;open human activity datasets;dilation operation;long-temporal dependencies;intra-sensors;inter-sensors;convolutional neural network;human activity recognition problems;deep learning framework","","1","39","","","","","IEEE","IEEE Journals"
"Visual Object Recognition and Pose Estimation Based on a Deep Semantic Segmentation Network","C. Lin; C. Tsai; Y. Lai; S. Li; C. Wong","Department of Electrical and Computer Engineering, Tamkang University, New Taipei City, Taiwan; Department of Electrical and Computer Engineering, Tamkang University, New Taipei City, Taiwan; Department of Electrical and Computer Engineering, Tamkang University, New Taipei City, Taiwan; Department of Electrical and Computer Engineering, Tamkang University, New Taipei City, Taiwan; Department of Electrical and Computer Engineering, Tamkang University, New Taipei City, Taiwan","IEEE Sensors Journal","","2018","18","22","9370","9381","In recent years, deep learning-based object recognition algorithms become emerging in robotic vision applications. This paper addresses the design of a novel deep learning-based visual object recognition and pose estimation system for a robot manipulator to handle random object picking tasks. The proposed visual control system consists of a visual perception module, an object pose estimation module, a data argumentation module, and a robot manipulator controller. The visual perception module combines deep convolution neural networks (CNNs) and a fully connected conditional random field layer to realize an image semantic segmentation function, which can provide stable and accurate object classification results in cluttered environments. The object pose estimation module implements a model-based pose estimation method to estimate the 3D pose of the target for picking control. In addition, the proposed data argumentation module automatically generates training data for training the deep CNN. Experimental results show that the proposed scene segmentation method used in the data argumentation module reaches a high accuracy rate of 97.10% on average, which is higher than other state-of-the-art segment methods. Moreover, with the proposed data argumentation module, the visual perception module reaches an accuracy rate over than 80% and 72% in the case of detecting and recognizing one object and three objects, respectively. In addition, the proposed model-based pose estimation method provides accurate 3D pose estimation results. The average translation and rotation errors in the three axes are all smaller than 0.52 cm and 3.95 degrees, respectively. These advantages make the proposed visual control system suitable for applications of random object picking and manipulation.","","","10.1109/JSEN.2018.2870957","Ministry of Science and Technology, Taiwan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8467328","Deep learning;convolution neural networks;semantic segmentation;pose estimation","Pose estimation;Three-dimensional displays;Robots;Visual perception;Image segmentation;Object recognition;Semantics","feature extraction;image classification;image segmentation;learning (artificial intelligence);manipulators;neural nets;object detection;object recognition;pose estimation;robot vision","deep semantic segmentation network;robotic vision applications;random object picking tasks;visual control system;visual perception module;data argumentation module;robot manipulator controller;deep convolution neural networks;fully connected conditional random field layer;image semantic segmentation function;deep CNN;scene segmentation method;deep learning-based visual object recognition algorithm;model based pose estimation system","","1","30","","","","","IEEE","IEEE Journals"
"Recurrent Variational Autoencoders for Learning Nonlinear Generative Models in the Presence of Outliers","Y. Wang; B. Dai; G. Hua; J. Aston; D. Wipf","Department of Pure Mathematics and Statistic, University of Cambridge, Cambridge, U.K.; Tsinghua University, Beijing, China; Microsoft Research, Redmond, WA, USA; Department of Pure Mathematics and Statistic, University of Cambridge, Cambridge, U.K.; Microsoft Research, Redmond, WA, USA","IEEE Journal of Selected Topics in Signal Processing","","2018","12","6","1615","1627","This paper explores two useful modifications of the recent variational autoencoder (VAE), a popular deep generative modeling framework that dresses traditional autoencoders with probabilistic attire. The first involves a specially-tailored form of conditioning that allows us to simplify the VAE decoder structure while simultaneously introducing robustness to outliers. In a related vein, a second, complementary alteration is proposed to further build invariance to contaminated or dirty samples via a data augmentation process that amounts to recycling. In brief, to the extent that the VAE is legitimately a representative generative model, then each output from the decoder should closely resemble an authentic sample, which can then be resubmitted as a novel input ad infinitum. Moreover, this can be accomplished via special recurrent connections without the need for additional parameters to be trained. We evaluate these proposals on multiple practical outlier-removal and generative modeling tasks involving nonlinear low-dimensional manifolds, demonstrating considerable improvements over existing algorithms.","","","10.1109/JSTSP.2018.2876995","EPSRC Centre for Mathematical Imaging in Healthcare; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8500175","Deep generative models;variational autoencoder;robust PCA;outlier removal;variational Bayesian model;deep learning","Principal component analysis;Computational modeling;Bayes methods;Deep learning;Upper bound;Probabilistic logic","learning (artificial intelligence)","data augmentation process;representative generative model;multiple practical outlier-removal;generative modeling tasks;nonlinear low-dimensional manifolds;recurrent variational autoencoders;nonlinear generative models;probabilistic attire;VAE decoder structure;deep generative modeling framework","","","32","","","","","IEEE","IEEE Journals"
"Machine Learning Approach to RF Transmitter Identification","K. Youssef; L. Bouchard; K. Haigh; J. Silovsky; B. Thapa; C. V. Valk","Department of Chemistry and Biochemistry, Bioengineering, California NanoSystems Institute, University of California at Los Angeles, Los Angeles, CA, USA; Department of Chemistry and Biochemistry, Bioengineering, California NanoSystems Institute, University of California at Los Angeles, Los Angeles, CA, USA; Communications Systems West, L3 Technologies, Salt Lake City, UT, USA; Raytheon BBN Technologies Corporation, Cambridge, MA, USA; Raytheon BBN Technologies Corporation, Cambridge, MA, USA; Raytheon BBN Technologies Corporation, Cambridge, MA, USA","IEEE Journal of Radio Frequency Identification","","2018","2","4","197","205","With the increasing domain and widespread use of wireless devices in recent years (mobile phones, Internet of Things, Wi-Fi), the electromagnetic spectrum has become extremely crowded. To counter security threats posed by rogue or unknown transmitters, we must identify RF transmitters not only by the data content of the transmissions but also based on the intrinsic physical characteristics of the transmitters. RF waveforms represent a particular challenge because of the extremely high data rates involved and the potentially large number of transmitters sharing a channel in a given location. These factors outline the need for rapid fingerprinting and identification methods that go beyond the traditional hand-engineered approaches. In this paper, we investigate the use of machine learning strategies to the classification and identification problem. We evaluate four different strategies: conventional deep neural nets, convolutional neural nets, support vector machines, and deep neural nets with multi-stage training. The latter was by far the most accurate, achieving 100% classification accuracy of 12 transmitters, and showing remarkable potential for scalability to large transmitter populations.","","","10.1109/JRFID.2018.2880457","University of California, Los Angeles; Raytheon BBN Technologies; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8531759","Deep learning;RF identification;fingerprinting;RF security","Deep learning;Radio transmitters;Support vector machines;Radiofrequency identification;Artificial neural networks;Convolutional neural networks","learning (artificial intelligence);neural nets;radio transmitters;support vector machines;telecommunication security","machine learning approach;intrinsic physical characteristics;data content;RF transmitters;security threats;electromagnetic spectrum;Wi-Fi;Internet of Things;mobile phones;wireless devices;RF transmitter identification;transmitter populations;support vector machines;convolutional neural nets;conventional deep neural nets;traditional hand-engineered approaches;identification methods;rapid fingerprinting;extremely high data rates;RF waveforms","","3","54","","","","","IEEE","IEEE Journals"
"Image Style Classification Based on Learnt Deep Correlation Features","W. Chu; Y. Wu","National Chung Cheng University, Min-Hsiung, Taiwan; National Chung Cheng University, Min-Hsiung, Taiwan","IEEE Transactions on Multimedia","","2018","20","9","2491","2502","This paper presents a comprehensive study of deep correlation features on image style classification. Inspired by that, correlation between feature maps can effectively describe image texture, and we design various correlations and transform them into style vectors, and investigate classification performance brought by different variants. In addition to intralayer correlation, interlayer correlation is proposed as well, and its effectiveness is verified. After showing the effectiveness of deep correlation features, we further propose a learning framework to automatically learn correlations between feature maps. Through extensive experiments on image style classification and artist classification, we demonstrate that the proposed learnt deep correlation features outperform several variants of convolutional neural network features by a large margin, and achieve the state-of-the-art performance.","","","10.1109/TMM.2018.2801718","Ministry of Science and Technology, Taiwan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8279468","Painting images;convolutional neural network;Gram matrix;deep correlation features;learnt correlation features","Correlation;Painting;Feature extraction;Image color analysis;Visualization;Semantics;Convolutional neural networks","art;convolution;correlation methods;feature extraction;feedforward neural nets;image classification;image texture;learning (artificial intelligence);self-organising feature maps;vectors","image style classification;learnt deep correlation features;feature maps;image texture;style vectors;intralayer correlation;interlayer correlation;artist classification;convolutional neural network","","4","37","","","","","IEEE","IEEE Journals"
"Intelligent Parameter Tuning in Optimization-Based Iterative CT Reconstruction via Deep Reinforcement Learning","C. Shen; Y. Gonzalez; L. Chen; S. B. Jiang; X. Jia","Department of Radiation Oncology, University of Texas Southwestern Medical Center, Dallas, TX, USA; Department of Radiation Oncology, University of Texas Southwestern Medical Center, Dallas, TX, USA; Department of Radiation Oncology, University of Texas Southwestern Medical Center, Dallas, TX, USA; Department of Radiation Oncology, University of Texas Southwestern Medical Center, Dallas, TX, USA; Department of Radiation Oncology, University of Texas Southwestern Medical Center, Dallas, TX, USA","IEEE Transactions on Medical Imaging","","2018","37","6","1430","1439","A number of image-processing problems can be formulated as optimization problems. The objective function typically contains several terms specifically designed for different purposes. Parameters in front of these terms are used to control the relative importance among them. It is of critical importance to adjust these parameters, as quality of the solution depends on their values. Tuning parameters are a relatively straight forward task for a human, as one can intuitively determine the direction of parameter adjustment based on the solution quality. Yet manual parameter tuning is not only tedious in many cases, but also becomes impractical when a number of parameters exist in a problem. Aiming at solving this problem, this paper proposes an approach that employs deep reinforcement learning to train a system that can automatically adjust parameters in a human-like manner. We demonstrate our idea in an example problem of optimization-based iterative computed tomography (CT) reconstruction with a pixel-wise total-variation regularization term. We set up a parameter-tuning policy network (PTPN), which maps a CT image patch to an output that specifies the direction and amplitude by which the parameter at the patch center is adjusted. We train the PTPN via an end-to-end reinforcement learning procedure. We demonstrate that under the guidance of the trained PTPN, reconstructed CT images attain quality similar or better than those reconstructed with manually tuned parameters.","","","10.1109/TMI.2018.2823679","National Institute of Biomedical Imaging and Bioengineering; National Cancer Institute; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8331966","Image reconstruction - iterative methods;machine learning;inverse methods;x-ray imaging;computed tomography","Image reconstruction;Computed tomography;Tuning;Machine learning;Radio frequency;Optimization;Image quality","computerised tomography;image reconstruction;iterative methods;learning (artificial intelligence);medical image processing;optimisation","relatively straight forward task;parameter adjustment;solution quality;manual parameter tuning;deep reinforcement learning;parameter-tuning policy network;CT image patch;end-to-end reinforcement learning procedure;trained PTPN;reconstructed CT images;intelligent parameter tuning;image-processing problems;optimization problems;objective function;tuning parameters;optimization-based iterative CT reconstruction;optimization-based iterative computed tomography reconstruction;pixel-wise total-variation regularization term;patch center","","1","36","","","","","IEEE","IEEE Journals"
"Learning Temporal Information for Brain-Computer Interface Using Convolutional Neural Networks","S. Sakhavi; C. Guan; S. Yan","Department of Electrical and Computer Engineering, National University of Singapore (NUS), Singapore; Agency for Science, Technology, and Research (A*STAR), Institute for Infocomm Research (I2R), Singapore; Department of Electrical and Computer Engineering, National University of Singapore, Singapore","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","11","5619","5629","Deep learning (DL) methods and architectures have been the state-of-the-art classification algorithms for computer vision and natural language processing problems. However, the successful application of these methods in motor imagery (MI) brain-computer interfaces (BCIs), in order to boost classification performance, is still limited. In this paper, we propose a classification framework for MI data by introducing a new temporal representation of the data and also utilizing a convolutional neural network (CNN) architecture for classification. The new representation is generated from modifying the filter-bank common spatial patterns method, and the CNN is designed and optimized accordingly for the representation. Our framework outperforms the best classification method in the literature on the BCI competition IV-2a 4-class MI data set by 7% increase in average subject accuracy. Furthermore, by studying the convolutional weights of the trained networks, we gain an insight into the temporal characteristics of EEG.","","","10.1109/TNNLS.2018.2789927","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8310961","Brain–computer interface (BCI);convolutional neural network (CNN);deep learning (DL);machine learning;motor imagery (MI);signal processing","Electroencephalography;Feature extraction;Convolution;Heuristic algorithms;Computer architecture;Task analysis;Biological neural networks","brain-computer interfaces;feedforward neural nets;learning (artificial intelligence);natural language processing;pattern classification","temporal information;brain-computer interface;convolutional neural networks;deep learning methods;computer vision;natural language processing problems;motor imagery brain-computer interfaces;classification performance;classification framework;temporal representation;convolutional neural network architecture;CNN;filter-bank common spatial patterns method;classification method;4-class MI data;convolutional weights;trained networks;temporal characteristics","","23","47","","","","","IEEE","IEEE Journals"
"Deep-neural-network-based wavelength selection and switching in ROADM systems","W. Mo; C. L. Gutterman; Y. Li; S. Zhu; G. Zussman; D. C. Kilper","College of Optical Sciences, University of Arizona, Tucson, Arizona 85721, USA; Department of Electrical Engineering, Columbia University, New York, New York 10027, USA; College of Optical Sciences, University of Arizona, Tucson, Arizona 85721, USA; College of Optical Sciences, University of Arizona, Tucson, Arizona 85721, USA; Department of Electrical Engineering, Columbia University, New York, New York 10027, USA; College of Optical Sciences, University of Arizona, Tucson, Arizona 85721, USA","IEEE/OSA Journal of Optical Communications and Networking","","2018","10","10","D1","D11","Recent advances in software and hardware greatly improve the multi-layer control and management of reconfigurable optical add-drop multiplexer (ROADM) systems facilitating wavelength switching. However, ensuring stable performance and reliable quality of transmission (QoT) remain difficult problems for dynamic operation. Optical power dynamics that arise from a variety of physical effects in the amplifiers and transmission fiber complicate the control and performance predictions in these systems.We present a deep-neural-network-based machine learning method to predict the power dynamics of a 90-channel ROADM system from data collection and training. We further show that the trained deep neural network can recommend wavelength assignments for wavelength switching with minimal power excursions.","","","10.1364/JOCN.10.0000D1","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8501523","Machine learning; Power excursions;ROADM systems; Wavelength switching","Optical switches;Optical amplifiers;Biological neural networks;Optical fiber amplifiers;Stimulated emission","learning (artificial intelligence);multiplexing equipment;neural nets;optical communication equipment;optical fibre networks;optical switches;wavelength division multiplexing","quality of transmission;QoT;multilayer control;reconfigurable optical add-drop multiplexer;multilayer management;minimal power excursions;wavelength assignments;trained deep neural network;90-channel ROADM system;deep-neural-network-based machine;physical effects;optical power dynamics;dynamic operation;wavelength switching;add-drop multiplexer systems;hardware;software;deep-neural-network-based wavelength selection","","6","","","","","","IEEE","IEEE Journals"
"Distributed Abnormal Behavior Detection Approach Based on Deep Belief Network and Ensemble SVM Using Spark","N. Marir; H. Wang; G. Feng; B. Li; M. Jia","College of Computer Science and Technology, Harbin Engineering University, Harbin, China; College of Computer Science and Technology, Harbin Engineering University, Harbin, China; College of Computer Science and Technology, Harbin Engineering University, Harbin, China; College of Computer Science and Technology, Harbin Engineering University, Harbin, China; College of Computer Science and Information Technology, Daqing Normal University, Daqing, China","IEEE Access","","2018","6","","59657","59671","The emergence of Internet connectivity has led to a significant increase in the volume and complexity of cyber attacks. Abnormal behavior detection systems are valuable tools for ensuring the security in computer networks. However, due to the huge amount and ever increasing diversity of the intrusions, the existing intrusion detection systems, which use machine learning techniques to learn a classifier based on a handcrafted feature vector, are not robust enough to detect sophisticated attacks which cause a high false alarm rate. Therefore, building a flexible in-depth defense system to detect abnormal behavior requires an ability to automatically learn powerful features and analyze large amounts of network traffic. To address these concerns, this paper proposes a novel distributed approach for the detection of abnormal behavior in largescale networks. The developed model discovers the abnormal behavior from large-scale network traffic data using a combination of a deep feature extraction and multi-layer ensemble support vector machines (SVMs) in a distributed way. First, we perform a non-linear dimensionality reduction, achieved through a distributed deep belief networks on large-scale network traffic data. Then, the obtained features are fed to the multi-layer ensemble SVM. The construction of the ensemble is accomplished through the iterative reduce paradigm based on Spark. Empirical results show a promising gain in performance compared with other existing models.","","","10.1109/ACCESS.2018.2875045","National Natural Science Foundation of China; Natural Science Foundation of Heilongjiang Province; Fundamental Research Fund for the Central Universities in China; National Science and Technology Major Project; Natural Science Foundation of Daqing Normal University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8486946","Abnormal behavior detection;big data;deep belief networks;deep learning;ensemble classifier","Support vector machines;Feature extraction;Intrusion detection;Big Data;Distributed databases;Dimensionality reduction","belief networks;computer network security;feature extraction;Internet;learning (artificial intelligence);parallel processing;pattern classification;support vector machines;telecommunication traffic","handcrafted feature vector;sophisticated attacks;high false alarm rate;in-depth defense system;powerful features;large-scale network traffic data;deep feature extraction;distributed deep belief networks;multilayer ensemble SVM;Spark;abnormal behavior detection approach;deep belief network;cyber attacks;abnormal behavior detection systems;computer networks;SVM;intrusion detection systems;distributed approach","","6","40","","","","","IEEE","IEEE Journals"
"Online Modeling of Esthetic Communities Using Deep Perception Graph Analytics","L. Zhang; M. Liu; L. Chen; L. Qiu; C. Zhang; Y. Hu; R. Zimmermann","Department of CSIE, Hefei University of Technology, Hefei, China; College of Computer Science and Technology, Wuhan University of Science and Technology, Wuhan, China; State Grid Zhejiang Electric Power Company, Hangzhou, China; State Grid Zhejiang Electric Power Company, Information & Telecommunication Branch, Hangzhou, China; Computer Science Department, University of Illinois at Urbana–Champaign, Champaign, USA; School of Aerospace Engineering, Tsinghua University, Beijing, China; School of Computing, National University Singapore, Singapore","IEEE Transactions on Multimedia","","2018","20","6","1462","1474","Accurately detecting esthetic communities from a large number of Internet users (e.g., Flickr11www.flickr.com. or Picasa22picasa.google.com. users) is a useful technique that can facilitate several applications, such as image retargeting, visual esthetic assessment, and fashion recommendation. Conventional approaches cannot appropriately handle this task due to the following challenges: first, it is difficult to online update the detected esthetic communities since these photos may uploaded/removed frequently; second, human visual perception is essential to describe esthetic characteristics, but integrating it into an existing mining algorithm is challenging; and third, flat models cannot encode human visual perception precisely, especially for those sophisticated sceneries. To solve these problems, we propose deep perception graph analytics, an incremental pipeline where the esthetic relations among users are described by utilizing their gaze shifting paths (GSPs). Specifically, we first propose an aggregation-based deep network that formulates GSP representation into a unified framework. Afterward, the deep perception graph is constructed where the esthetic discrepancy between users is measured by their GSP distributions. Accordingly, we adopt a dense subgraph discovery algorithm that efficiently detects the communities belonging to each esthetic style. Finally, an online Gaussian mixture model (GMM) learning model is designed, which dynamically updates the GMM parameters in order to describe esthetic communities given the photos are uploaded/removed on the fly. Experiments on a million-scale image set crawled from Flickr demonstrate the efficiency and effectiveness of our method.","","","10.1109/TMM.2017.2769799","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094950","Aesthetic community;deep perception graph;visual perception;online learning;gaze shifting","Visual perception;Algorithm design and analysis;Flickr;Computational modeling;Adaptation models;Analytical models;Internet","data analysis;Gaussian processes;graph theory;image representation;Internet;learning (artificial intelligence);mixture models","deep perception graph analytics;Internet users;Flickr;visual esthetic assessment;human visual perception;deep network;online Gaussian mixture model learning model;online modeling;esthetic communities detection;gaze shifting paths;aggregation-based deep network;GSP distributions;dense subgraph discovery algorithm;online GMM learning model","","1","60","","","","","IEEE","IEEE Journals"
"Obstacle Detection for Intelligent Transportation Systems Using Deep Stacked Autoencoder and  $k$ -Nearest Neighbor Scheme","A. Dairi; F. Harrou; Y. Sun; M. Senouci","Computer Science Department, University of Oran 1 Ahmed Ben Bella, Oran, Algeria; Computer, Electrical and Mathematical Sciences and Engineering Division, King Abdullah University of Science and Technology, Thuwal, Saudi Arabia; Computer, Electrical and Mathematical Sciences and Engineering Division, King Abdullah University of Science and Technology, Thuwal, Saudi Arabia; Computer Science Department, University of Oran 1 Ahmed Ben Bella, Oran, Algeria","IEEE Sensors Journal","","2018","18","12","5122","5132","Obstacle detection is an essential element for the development of intelligent transportation systems so that accidents can be avoided. In this paper, we propose a stereovision-based method for detecting obstacles in urban environment. The proposed method uses a deep stacked auto-encoders (DSA) model that combines the greedy learning features with the dimensionality reduction capacity and employs an unsupervised k -nearest neighbors (KNN) algorithm to accurately and reliably detect the presence of obstacles. We consider obstacle detection as an anomaly detection problem. We evaluated the proposed method by using practical data from three publicly available data sets, the Malaga stereovision urban data set, the Daimler urban segmentation data set, and the Bahnhof data set. Also, we compared the efficiency of DSA-KNN approach to the deep belief network-based clustering schemes. Results show that the DSA-KNN is suitable to visually monitor urban scenes.","","","10.1109/JSEN.2018.2831082","King Abdullah University of Science and Technology Office of Sponsored Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8352801","Obstacle detection;autonomous vehicles;intelligent transportation systems;deep learning;clustering algorithms","Clustering algorithms;Sensors;Machine learning algorithms;Roads;Partitioning algorithms;Kernel;Machine learning","accident prevention;feature extraction;greedy algorithms;image coding;image segmentation;intelligent transportation systems;nearest neighbour methods;object detection;stereo image processing;unsupervised learning","obstacle detection;intelligent transportation systems;deep stacked autoencoder;anomaly detection problem;greedy learning features;dimensionality reduction capacity;unsupervised k-nearest neighbor algorithm;Malaga stereovision urban data set;Daimler urban segmentation data set;Bahnhof data set","","6","54","","","","","IEEE","IEEE Journals"
"Deep learning methods in transportation domain: a review","H. Nguyen; L. Kieu; T. Wen; C. Cai","Data 61 – CSIRO, Australia; Data 61 – CSIRO, Australia; Data 61 – CSIRO, Australia; Data 61 – CSIRO, Australia","IET Intelligent Transport Systems","","2018","12","9","998","1004","Recent years have seen a significant amount of transportation data collected from multiple sources including road sensors, probe, GPS, CCTV and incident reports. Similar to many other industries, transportation has entered the generation of big data. With a rich volume of traffic data, it is challenging to build reliable prediction models based on traditional shallow machine learning methods. Deep learning is a new state-of-the-art machine learning approach which has been of great interest in both academic research and industrial applications. This study reviews recent studies of deep learning for popular topics in processing traffic data including transportation network representation, traffic flow forecasting, traffic signal control, automatic vehicle detection, traffic incident processing, travel demand prediction, autonomous driving and driver behaviours. In general, the use of deep learning systems in transportation is still limited and there are potential limitations for utilising this advanced approach to improve prediction models.","","","10.1049/iet-its.2018.0064","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8490353","","","Big Data;learning (artificial intelligence);road traffic;traffic engineering computing","deep learning methods;transportation domain;transportation data;road sensors;probe;GPS;CCTV;incident reports;big data generation;traffic data;machine learning methods;transportation network representation;traffic flow forecasting;traffic signal control;automatic vehicle detection;traffic incident processing;travel demand prediction;autonomous driving;driver behaviours;deep learning systems","","7","60","","","","","IET","IET Journals"
"A Deep Cascade of Convolutional Neural Networks for Dynamic MR Image Reconstruction","J. Schlemper; J. Caballero; J. V. Hajnal; A. N. Price; D. Rueckert","Department of Computing, Imperial College London, London, U.K.; Department of Computing, Imperial College London, London, U.K.; Biomedical Engineering Department, Division of Imaging Sciences, King’s College London, London, U.K.; Biomedical Engineering Department, Division of Imaging Sciences, King’s College London, London, U.K.; Department of Computing, Imperial College London, London, U.K.","IEEE Transactions on Medical Imaging","","2018","37","2","491","503","Inspired by recent advances in deep learning, we propose a framework for reconstructing dynamic sequences of 2-D cardiac magnetic resonance (MR) images from undersampled data using a deep cascade of convolutional neural networks (CNNs) to accelerate the data acquisition process. In particular, we address the case where data are acquired using aggressive Cartesian undersampling. First, we show that when each 2-D image frame is reconstructed independently, the proposed method outperforms state-of-the-art 2-D compressed sensing approaches, such as dictionary learning-based MR image reconstruction, in terms of reconstruction error and reconstruction speed. Second, when reconstructing the frames of the sequences jointly, we demonstrate that CNNs can learn spatio-temporal correlations efficiently by combining convolution and data sharing approaches. We show that the proposed method consistently outperforms state-of-the-art methods and is capable of preserving anatomical structure more faithfully up to 11-fold undersampling. Moreover, reconstruction is very fast: each complete dynamic sequence can be reconstructed in less than 10 s and, for the 2-D case, each image frame can be reconstructed in 23 ms, enabling real-time applications.","","","10.1109/TMI.2017.2760978","EPSRC Programme; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8067520","Deep learning;convolutional neural network;dynamic magnetic resonance imaging;compressed sensing;image reconstruction","Image reconstruction;Two dimensional displays;Redundancy;Imaging;Neural networks;Machine learning;Compressed sensing","biomedical MRI;data acquisition;image reconstruction;image sampling;learning (artificial intelligence);medical image processing;neural nets;spatiotemporal phenomena","2D compressed sensing approaches;2D cardiac magnetic resonance images;2D image frame;dynamic MR image reconstruction;reconstruction error;dictionary learning;aggressive Cartesian undersampling;data acquisition process;convolutional neural networks;undersampled data;dynamic sequences;deep learning","Algorithms;Databases, Factual;Heart;Humans;Image Processing, Computer-Assisted;Magnetic Resonance Imaging, Cine;Neural Networks (Computer)","32","37","CCBY","","","","IEEE","IEEE Journals"
"An On-Chip Learning Neuromorphic Autoencoder With Current-Mode Transposable Memory Read and Virtual Lookup Table","H. Cho; H. Son; K. Seong; B. Kim; H. Park; J. Sim","Department of Electronic and Electrical Engineering, Pohang University of Science and Technology 37673, Pohang, South Korea; Department of Electronic and Electrical Engineering, Pohang University of Science and Technology 37673, Pohang, South Korea; Samsung Electronics, Hwaseong-si, South Korea; Department of Electronic and Electrical Engineering, Pohang University of Science and Technology 37673, Pohang, South Korea; Department of Electronic and Electrical Engineering, Pohang University of Science and Technology 37673, Pohang, South Korea; Department of Electronic and Electrical Engineering, Pohang University of Science and Technology 37673, Pohang, South Korea","IEEE Transactions on Biomedical Circuits and Systems","","2018","12","1","161","170","This paper presents an IC implementation of on-chip learning neuromorphic autoencoder unit in a form of rate-based spiking neural network. With a current-mode signaling scheme embedded in a 500 × 500 6b SRAM-based memory, the proposed architecture achieves simultaneous processing of multiplications and accumulations. In addition, a transposable memory read for both forward and backward propagations and a virtual lookup table are also proposed to perform an unsupervised learning of restricted Boltzmann machine. The IC is fabricated using 28-nm CMOS process and is verified in a three-layer network of encoder-decoder pair for training and recovery of images with two-dimensional 16 × 16 pixels. With a dataset of 50 digits, the IC shows a normalized root mean square error of 0.078. Measured energy efficiencies are 4.46 pJ per synaptic operation for inference and 19.26 pJ per synaptic weight update for learning, respectively. The learning performance is also estimated by simulations if the proposed hardware architecture is extended to apply to a batch training of 60 000 MNIST datasets.","","","10.1109/TBCAS.2017.2762002","ICT R&D program of MSIP/IITP; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8255636","Autoencoder;deep belief network (DBN);neuromorphic;on-chip learning;restricted Boltzmann machine (RBM);unsupervised learning","Neurons;Hardware;System-on-chip;Neuromorphics;Computer architecture;Pulse width modulation","biomedical electronics;Boltzmann machines;CMOS memory circuits;decoding;encoding;SRAM chips;table lookup;unsupervised learning","SRAM-based memory;encoder-decoder pair;CMOS process;restricted Boltzmann machine;unsupervised learning;backward propagations;forward propagations;virtual lookup table;transposable memory read;current-mode signaling scheme;rate-based spiking neural network;on-chip learning neuromorphic autoencoder unit;current-mode transposable memory read;size 28 nm","Databases, Factual;Facial Recognition;Humans;Image Processing, Computer-Assisted;Machine Learning;Neural Networks (Computer)","5","29","","","","","IEEE","IEEE Journals"
"Deep Optical Flow Supervised Learning With Prior Assumptions","X. Xiang; M. Zhai; R. Zhang; Y. Qiao; A. El Saddik","School of Information and Communication Engineering, Harbin Engineering University, Harbin, China; School of Information and Communication Engineering, Harbin Engineering University, Harbin, China; School of Information and Communication Engineering, Harbin Engineering University, Harbin, China; School of Information and Communication Engineering, Harbin Engineering University, Harbin, China; School of Electrical Engineering and Computer Science, University of Ottawa, Ottawa, Canada","IEEE Access","","2018","6","","43222","43232","Traditional methods for estimating optical flow use variational model that includes data term and smoothness term, which can build a constraint relationship between two adjacent images and optical flow. However, most of them are too slow to be used in real-time applications. Recently, convolutional neural networks have been used in optical flow area successfully. Many current learning methods use large data sets that contain ground truth for network training, which can make use of prior knowledge to estimate optical flow directly. However, these methods overemphasize the factor of deep learning and ignore advantages of many traditional assumptions used in variational framework for optical flow estimation. In this paper, inspired by classical energy-based optical flow methods, we propose a novel approach for dense motion estimation, which combines traditional prior assumptions with supervised learning network. During training, the variation in image brightness, gradient and spatial smoothness are embedded in network. Our method is tested on both synthetic and real scenes. The experimental results show that employing the prior assumptions during training can obtain more detailed and smoothed flow fields and can improve the accuracy of optical flow estimation.","","","10.1109/ACCESS.2018.2863233","National Natural Science Foundation of China; Natural Science Foundation of Heilongjiang Province; Fundamental Research Funds for the Central Universities of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8425694","Optical flow estimation;convolutional neural networks;supervised learning;prior assumptions","Optical imaging;Adaptive optics;Estimation;Training;Optical computing;Optical fiber networks;Optical losses","image sequences;learning (artificial intelligence);motion estimation","deep learning;optical flow estimation;image brightness;motion estimation;convolutional neural network;variational model;deep optical flow supervised learning network;energy-based optical flow methods","","3","40","","","","","IEEE","IEEE Journals"
"Unsupervised Deep Hashing with Similarity-Adaptive and Discrete Optimization","F. Shen; Y. Xu; L. Liu; Y. Yang; Z. Huang; H. T. Shen","University of Electronic Science and Technology of China, Chengdu, Sichuan, China; Center for Future Media, University of Electronic Science and Technology of China, Chengdu, Sichuan, China; School of Computing Sciences, University of East Anglia, Norwich, United Kingdom; Center for Future Media, University of Electronic Science and Technology of China, Chengdu, Sichuan, China; School of Information Technology & Electrical Engineering, The University of Queensland, St Lucia, Queensland, Australia; Center for Future Media, University of Electronic Science and Technology of China, Chengdu, Sichuan, China","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","12","3034","3044","Recent vision and learning studies show that learning compact hash codes can facilitate massive data processing with significantly reduced storage and computation. Particularly, learning deep hash functions has greatly improved the retrieval performance, typically under the semantic supervision. In contrast, current unsupervised deep hashing algorithms can hardly achieve satisfactory performance due to either the relaxed optimization or absence of similarity-sensitive objective. In this work, we propose a simple yet effective unsupervised hashing framework, named Similarity-Adaptive Deep Hashing (SADH), which alternatingly proceeds over three training modules: deep hash model training, similarity graph updating and binary code optimization. The key difference from the widely-used two-step hashing method is that the output representations of the learned deep model help update the similarity graph matrix, which is then used to improve the subsequent code optimization. In addition, for producing high-quality binary codes, we devise an effective discrete optimization algorithm which can directly handle the binary constraints with a general hashing loss. Extensive experiments validate the efficacy of SADH, which consistently outperforms the state-of-the-arts by large gaps.","","","10.1109/TPAMI.2018.2789887","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; Australian Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8247210","Binary codes;unsupervised deep hashing;image retrieval","Binary codes;Optimization;Image retrieval;Quantization (signal);Adaptation models;Data models;Semantics;Unsupervised learning","binary codes;cryptography;file organisation;graph theory;image representation;image retrieval;matrix algebra;optimisation;unsupervised learning","binary code optimization;similarity graph matrix;subsequent code optimization;retrieval performance;semantic supervision;similarity-sensitive objective;discrete optimization algorithm;hash codes;learning deep hash functions;unsupervised deep hashing algorithms;similarity-adaptive deep hashing;data processing;SADH;representation","","28","59","","","","","IEEE","IEEE Journals"
"Modeling Driver Risk Perception on City Roads Using Deep Learning","P. Ping; Y. Sheng; W. Qin; C. Miyajima; K. Takeda","School of Instrument Science and Engineering, Southeast University, Nanjing, China; School of Informatics, Nagoya University, Nagoya, Japan; School of Instrument Science and Engineering, Southeast University, Nanjing, China; School of Informatics, Daido University, Nagoya, Japan; School of Informatics, Nagoya University, Nagoya, Japan","IEEE Access","","2018","6","","68850","68866","Research on how risk is perceived by drivers is vital to driving behavior research and driving safety. As risk can be divided into subjective and objective risk, in this paper, we focus on modeling subjective risk perception by drivers using a deep learning method. Different drivers often perceive different levels of subjective risk under the same driving conditions. In addition, different driving conditions or driving events will have different effects on drivers. Based on these two risk perception features, in this paper, we first design an experiment on a city road with two lanes to assess the level of subjective risk perceived by drivers belonging to different groups. We then use a deep learning network-based method to abstract features of the driving environment. These environmental features are integrated with driver risk perception data and this information is used as training and testing data for the learning network. Finally, a long-short-term memory-based method is adopted to model the subjective risk perception of individual drivers based on traffic conditions and vehicle operation data from the driver's vehicle. Our results show that the proposed method can effectively model the subjective risk perception behavior of drivers, allowing for end-to-end risk perception prediction in future driving assistance systems.","","","10.1109/ACCESS.2018.2879887","Grant-in-Aid for Scientific Research (C); Japan Society for the Promotion of Science; National Natural Science Foundation of China; Key Research Plan of Jiangsu Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8525270","Driving behavior modeling;deep learning;traffic safety;risk perception","Vehicles;Accidents;Roads;Urban areas;Hazards","driver information systems;learning (artificial intelligence);recurrent neural nets;risk management;road safety;road traffic;road vehicles;traffic engineering computing","traffic conditions;vehicle operation data;end-to-end risk perception prediction;city road;driving safety;driving environment;long short-term memory;driving assistance systems;deep learning network;driver risk perception","","2","43","","","","","IEEE","IEEE Journals"
"Deep Learning-Based Channel Estimation for Beamspace mmWave Massive MIMO Systems","H. He; C. Wen; S. Jin; G. Y. Li","National Mobile Communications Research Laboratory, Southeast University, Nanjing, China; Institute of Communications Engineering, National Sun Yat-sen University, Kaohsiung, Taiwan; National Mobile Communications Research Laboratory, Southeast University, Nanjing, China; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA","IEEE Wireless Communications Letters","","2018","7","5","852","855","Channel estimation is very challenging when the receiver is equipped with a limited number of radio-frequency (RF) chains in beamspace millimeter-wave massive multiple-input and multiple-output systems. To solve this problem, we exploit a learned denoising-based approximate message passing (LDAMP) network. This neural network can learn channel structure and estimate channel from a large number of training data. Furthermore, we provide an analytical framework on the asymptotic performance of the channel estimator. Based on our analysis and simulation results, the LDAMP neural network significantly outperforms state-of-the-art compressed sensing-based algorithms even when the receiver is equipped with a small number of RF chains.","","","10.1109/LWC.2018.2832128","National Science Foundation (NSFC) for Distinguished Young Scholars of China; National Natural Science Foundation of China; Ministry of Science and Technology, Taiwan; ITRI, Hsinchu, Taiwan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8353153","Millimeter wave;beamspace MIMO;channel estimation;deep learning;neural network","Channel estimation;Antenna arrays;Radio frequency;Neural networks;MIMO communication;Lenses;Noise measurement","channel estimation;learning (artificial intelligence);message passing;millimetre wave communication;MIMO communication;neural nets;signal denoising;telecommunication computing;wireless channels","radio-frequency chains;learned denoising-based approximate message passing network;channel structure;channel estimator;LDAMP neural network;deep learning-based channel estimation;beamspace mmWave massive MIMO system;beamspace millimeter-wave massive multiple input multiple output systems","","47","10","","","","","IEEE","IEEE Journals"
"Medical Image Synthesis with Deep Convolutional Adversarial Networks","D. Nie; R. Trullo; J. Lian; L. Wang; C. Petitjean; S. Ruan; Q. Wang; D. Shen","Department of Computer Science, Department of Radiology and BRIC, UNC-Chapel Hill, Chapel Hill, NC, USA; Department of Radiology and BRICUNC-Chapel Hill; Department of Radiation OncologyUNC-Chapel Hill; Department of Radiology and BRICUNC-Chapel Hill; Department of Computer ScienceUniversity of Normandy; Med-X Research Institute, School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, China Radiology and Biomedical; Department of Radiology and Biomedical Research Imaging Center, University of North Carolina at Chapel Hill, Chapel Hill, NC, USA; Department of Radiology and Biomedical Research Imaging Center, University of North Carolina at Chapel Hill, Chapel Hill, NC, USA","IEEE Transactions on Biomedical Engineering","","2018","65","12","2720","2730","Medical imaging plays a critical role in various clinical applications. However, due to multiple considerations such as cost and radiation dose, the acquisition of certain image modalities may be limited. Thus, medical image synthesis can be of great benefit by estimating a desired imaging modality without incurring an actual scan. In this paper, we propose a generative adversarial approach to address this challenging problem. Specifically, we train a fully convolutional network (FCN) to generate a target image given a source image. To better model a nonlinear mapping from source to target and to produce more realistic target images, we propose to use the adversarial learning strategy to better model the FCN. Moreover, the FCN is designed to incorporate an image-gradient-difference-based loss function to avoid generating blurry target images. Long-term residual unit is also explored to help the training of the network. We further apply Auto-Context Model to implement a context-aware deep convolutional adversarial network. Experimental results show that our method is accurate and robust for synthesizing target images from the corresponding source images. In particular, we evaluate our method on three datasets, to address the tasks of generating CT from MRI and generating 7T MRI from 3T MRI images. Our method outperforms the state-of-the-art methods under comparison in all datasets and tasks.","","","10.1109/TBME.2018.2814538","National Institutes of Health; National Key Research and Development Program of China; National Natural Science Foundation of China; Science and Technology Commission of Shanghai Municipality; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8310638","Adversarial learning;auto-context model;deep learning;image synthesis;residual learning","Magnetic resonance imaging;Computed tomography;Generators;Image generation;Biomedical imaging;Task analysis","biomedical MRI;computerised tomography;convolution;learning (artificial intelligence);medical image processing;neural nets","MRI images;auto-context model;nonlinear mapping;cost dose;context-aware deep convolutional adversarial network;blurry target images;image-gradient-difference-based loss function;adversarial learning strategy;source image;FCN;fully convolutional network;generative adversarial approach;image modalities;radiation dose;medical imaging;deep convolutional adversarial networks;medical image synthesis","","19","54","","","","","IEEE","IEEE Journals"
"Learning Automata Based Competition Scheme to Train Deep Neural Networks","H. Guo; S. Li; K. Qi; Y. Guo; Z. Xu","Department of Electronic Engineering, School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai 200240, China (e-mail: haonan2012@sjtu.edu.cn).; School of Cyber Security, School of Electronic Information and Electrical Engineering, Artificial Intelligence Institute, Shanghai Jiao Tong University, Shanghai 200240, China (e-mail: shli@sjtu.edu.cn).; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai 200240, China (e-mail: tommy-qi@sjtu.edu.cn).; Department of Electronic Engineering, School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai 200240, China (e-mail: guoying2014vip@sjtu.edu.cn).; Z. Xu is with School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu 611731, China (e-mail: zwxu@uestc.edu.cn).","IEEE Transactions on Emerging Topics in Computational Intelligence","","2018","PP","99","1","8","Deep neural network has been one of the most powerful models in the field of machine learning, which has acquired state-of-the-art results in many tasks including image classification, object detection, text recognition, and so on. There have been many tricks to improve the training and generalization performance of deep neural network, such as dropout, ReLU, batch normalization, etc. In this paper, we proposed a new basic element to form deep neural networks, called learning automata competition unit (LCU). The LCU includes a group of general neural units and learning automata. The adopted learning automata are reinforcement learning methods, which can learn the optimal action through continuously interacting with a stochastic environment. Since the learning automata has powerful policy-making ability for both stochastic and non-stationary environment, the proposed LCU can facilitate competition in a group of neural units and gradually select the better trained neural units during training. The selected neural units through competition can make the training process more efficient, which can simultaneously get better training and generalization performance. The experiments on MNIST, CIFAR-10, and the Reuters newswire topic classification dataset show the performance of our method for both deep fully connected neural network and convolutional neural network.","","","10.1109/TETCI.2018.2868474","State Grid Corporation of China SGCC Science and Technology Project; Sichuan province and university cooperation Key Program of Science and Technology Department of Sichuan Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8540460","Deep neural network;learning automata;reinforcement learning;convolutional neural network","Learning automata;Training;Convolutional neural networks;Computational modeling;Adaptation models;Stochastic processes","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Rotor-Current-Based Fault Diagnosis for DFIG Wind Turbine Drivetrain Gearboxes Using Frequency Analysis and a Deep Classifier","F. Cheng; J. Wang; L. Qu; W. Qiao","Power and Energy Systems Laboratory, Department of Electrical and Computer Engineering, University of Nebraska–Lincoln, Lincoln, NE, USA; Power and Energy Systems Laboratory, Department of Electrical and Computer Engineering, University of Nebraska–Lincoln, Lincoln, NE, USA; Power and Energy Systems Laboratory, Department of Electrical and Computer Engineering, University of Nebraska–Lincoln, Lincoln, NE, USA; Power and Energy Systems Laboratory, Department of Electrical and Computer Engineering, University of Nebraska–Lincoln, Lincoln, NE, USA","IEEE Transactions on Industry Applications","","2018","54","2","1062","1071","Fault diagnosis of drivetrain gearboxes is a prominent challenge in wind turbine condition monitoring. Many machine learning algorithms have been applied to gearbox fault diagnosis. However, many of the current machine learning algorithms did not provide satisfactory fault diagnosis results due to their shallow architectures. Recently, a class of machine learning models with deep architectures called deep learning has received more attention, because it can learn high-level features of inputs. This paper proposes a new fault diagnosis method for the drivetrain gearboxes of the wind turbines equipped with doubly-fed induction generators (DFIGs) using DFIG rotor current signal analysis. In the proposed method, the instantaneous fundamental frequency of the rotor current signal is first estimated to obtain the instantaneous shaft rotating frequency. Then, the Hilbert transform is used to demodulate the rotor current signal to obtain its envelope, and the resultant envelope signal contains fault characteristic frequencies that are in proportion to the varying DFIG shaft rotating frequency. Next, an angular resampling algorithm is designed to resample the nonstationary envelope signal to be stationary based on the estimated instantaneous shaft rotating frequency. After that, the power spectral density analysis is performed on the resampled envelope signal for the gearbox fault detection. Finally, a classifier with a deep architecture that consists of a stacked autoencoder and a support vector machine is proposed for gearbox fault classification using extracted fault features. Experimental results obtained from a DFIG wind turbine drivetrain test rig are provided to verify the effectiveness of the proposed method.","","","10.1109/TIA.2017.2773426","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8106815","Deep classifier;doubly-fed induction generator (DFIG);fault diagnosis;gearbox;rotor current;stacked autoencoder (SAE);support vector machine (SVM);wind turbine","Wind turbines;Rotors;Fault diagnosis;Shafts;Vibrations;Support vector machines","asynchronous generators;condition monitoring;fault diagnosis;frequency estimation;gears;Hilbert transforms;learning (artificial intelligence);power engineering computing;power generation faults;rotors;shafts;signal classification;signal sampling;support vector machines;wind power plants;wind turbines","deep architecture;support vector machine;gearbox fault classification;extracted fault features;DFIG wind turbine drivetrain test rig;DFIG wind turbine drivetrain gearboxes;frequency analysis;deep classifier;wind turbine condition monitoring;satisfactory fault diagnosis results;machine learning models;deep learning;fault diagnosis method;wind turbines;DFIG rotor current signal analysis;instantaneous fundamental frequency;fault characteristic frequencies;varying DFIG shaft rotating frequency;angular resampling algorithm;nonstationary envelope signal;resampled envelope signal;gearbox fault detection;machine learning algorithms;envelope signal;instantaneous shaft rotating frequency estimation","","14","44","","","","","IEEE","IEEE Journals"
"Parallel reinforcement learning: a framework and case study","T. Liu; B. Tian; Y. Ai; L. Li; D. Cao; F. Wang","Institute of Automation, Chinese Academy of Sciences, China; Institute of Automation, and also with the Cloud Computing Center, Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China; Tsinghua University, China; University of Waterloo, Canada; Institute of Automation, Chinese Academy of Sciences, China","IEEE/CAA Journal of Automatica Sinica","","2018","5","4","827","835","In this paper, a new machine learning framework is developed for complex system control, called parallel reinforcement learning. To overcome data deficiency of current data-driven algorithms, a parallel system is built to improve complex learning system by self-guidance. Based on the Markov chain (MC) theory, we combine the transfer learning, predictive learning, deep learning and reinforcement learning to tackle the data and action processes and to express the knowledge. Parallel reinforcement learning framework is formulated and several case studies for real-world problems are finally introduced.","","","10.1109/JAS.2018.7511144","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8370297","","Learning (artificial intelligence);Complex systems;Power demand;Machine learning;Computational modeling;Control systems;Force","learning (artificial intelligence);Markov processes;parallel processing","transfer learning;predictive learning;deep learning;action processes;parallel reinforcement learning framework;machine learning framework;complex system control;parallel system;complex learning system;Markov chain theory;data-driven algorithms;parallel reinforcement learning;data processes","","7","","","","","","IEEE","IEEE Journals"
"Face Alignment With Deep Regression","B. Shi; X. Bai; W. Liu; J. Wang","School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Microsoft Research Asia, Beijing, China","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","1","183","194","In this paper, we present a deep regression approach for face alignment. The deep regressor is a neural network that consists of a global layer and multistage local layers. The global layer estimates the initial face shape from the whole image, while the following local layers iteratively update the shape with local image observations. Combining standard derivations and numerical approximations, we make all layers able to backpropagate error differentials, so that we can apply the standard backpropagation to jointly learn the parameters from all layers. We show that the resulting deep regressor gradually and evenly approaches the true facial landmarks stage by stage, avoiding the tendency that often occurs in the cascaded regression methods and deteriorates the overall performance: yielding early stage regressors with high alignment accuracy gains but later stage regressors with low alignment accuracy gains. Experimental results on standard benchmarks demonstrate that our approach brings significant improvements over previous cascaded regression algorithms.","","","10.1109/TNNLS.2016.2618340","National Natural Science Foundation of China; Open Project Program of the State Key Laboratory of Digital Publishing Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7728148","Backpropagation;cascaded regression;deep learning;face alignment","Shape;Face;Feature extraction;Estimation;Computational modeling;Learning systems;Deformable models","approximation theory;backpropagation;face recognition;iterative methods;neural nets;regression analysis","deep regressor;facial landmarks stage;standard backpropagation;numerical approximations;standard derivations;local image observations;initial face shape;multistage local layers;global layer;neural network;deep regression approach;face alignment;standard benchmarks;low alignment accuracy gains;high alignment accuracy gains;early stage regressors;cascaded regression methods","","11","50","","","","","IEEE","IEEE Journals"
"Intelligent Map Reader: A Framework for Topographic Map Understanding With Deep Learning and Gazetteer","H. Li; J. Liu; X. Zhou","College of Electrical and Information Engineering, Hunan University, Hunan, China; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Arizona State University, Tempe, AZ, USA","IEEE Access","","2018","6","","25363","25376","Text features in topographic maps are important for helping users to locate the area that a map covers and to understand the map's content. Previous works on the optical detection of map text from topographic maps have used geometric features, the Hough transform, and segmentation. However, these approaches still face challenges when detecting map text in complicated contexts, especially when the map text is touching other map features, such as contours or geographical features. Thus, state-of-the-art techniques for map text and feature recognition and manual interpretation and correction are always required to produce accurate results when optically converting topographic maps into a readable format. This paper proposes a methodological framework called the intelligent map reader that enables the automatic and accurate optical understanding of the content of a topographic map using deep learning techniques in combination with a gazetteer. The intelligent map reader framework includes the detection of map text via deep learning, the separation of text units via graph-based segmentation and clustering, optical character recognition (OCR) via an OCR engine, and digital-gazetteer-based map content understanding. Experimental results validate the efficiency and robustness of our proposed methodology for map text recognition and map content understanding. We expect the proposed intelligent map reader to contribute to various applications in the GeoAI field.","","","10.1109/ACCESS.2018.2823501","National Natural Science Foundation of China; China Postdoctoral Science Special Foundation; National Key Research and Development Program of China; Hunan Provincial Natural Science Foundation of China; Basic Research Program of Shenzhen; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8331828","Optical character recognition;deep convolutional neural network;map feature detection;gazetteer;topographic map understanding","Optical character recognition software;Text recognition;Feature extraction;Proposals;Training;Machine learning;Google","cartography;feature extraction;geographic information systems;Hough transforms;image segmentation;learning (artificial intelligence);optical character recognition;text analysis","geometric features;digital-gazetteer-based map content understanding;OCR engine;optical character recognition;graph-based segmentation;feature recognition;geographical features;Hough transform;optical detection;deep learning techniques;intelligent map reader framework;map features;text features;topographic map understanding;map text recognition","","","61","","","","","IEEE","IEEE Journals"
"Text clustering algorithm based on deep representation learning","B. Wang; W. Liu; Z. Lin; X. Hu; J. Wei; C. Liu","People's Republic of China; Guilin University of Electronic Technology, People's Republic of China; People's Republic of China; People's Republic of China; People's Republic of China; People's Republic of China","The Journal of Engineering","","2018","2018","16","1407","1414","Text clustering is an important method for effectively organising, summarising, and navigating text information. However, in the absence of labels, the text data to be clustered cannot be used to train the text representation model based on deep learning. To address the problem, an algorithm of text clustering based on deep representation learning is proposed using the transfer learning domain adaptation and the parameters update during cluster iteration. First, source domain data is used to perform the pre-training of the deep learning classification model. This procedure acts as an initialisation of the model parameters. Then, the domain discriminator is added to the model, to domain-divide the input sample. If the discriminator cannot distinguish which domain the data belongs to, the common feature space of two domains is obtained, so the domain adaptation problem is solved. Finally, the text feature vectors obtained by the model are clustered with MCSKM++ algorithm. The algorithm not only resolves the model pre-training problem in unsupervised clustering, but also has a good clustering effect on the transfer problem caused by different numbers of domain labels. Experiments suggest that the clustering accuracy of the algorithm is superior to other similar algorithms.","","","10.1049/joe.2018.8282","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8543721","","","text analysis;feature extraction;pattern clustering;learning (artificial intelligence)","text information;text representation model;deep representation learning;transfer learning domain adaptation;parameters update;source domain data;deep learning classification model;domain discriminator;domain-divide;domain adaptation problem;text feature vectors;MCSKM++ algorithm;clustering iteration process;expectation maximisation algorithm;target domain data;text clustering result;model pre-training problem;unsupervised clustering;transfer problem;domain labels;clustering accuracy;text clustering algorithm","","1","18","","","","","IET","IET Journals"
"Green Resource Allocation based on Deep Reinforcement Learning in Content-Centric IoT","X. He; K. Wang; H. Huang; T. Miyazaki; Y. Wang; S. Guo","Computer, Nanjing University of Post and Telecommunications, Nanjing, Jiangsu China (e-mail: isxmhe@gmail.com); Computer, Nanjing University of Post and Telecommunications, Nanjing, Jiangsu China (e-mail: kwang@njupt.edu.cn); School of Computer Science and Engineering, The University of Aizu, Aizu-Wakamatsu, Fukushima Japan (e-mail: cshwhuang@comp.polyu.edu.hk); School of Computer Science and Engineering, The University of Aizu, Aizu-Wakamatsu, Fukushima Japan 965-8580 (e-mail: miyazaki@u-aizu.ac.jp); Computer, Nanjing University of Post and Telecommunications, Nanjing, Jiangsu China (e-mail: wangyixuan.cs@gmail.com); Department of Computing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong China (e-mail: song.guo@polyu.edu.hk)","IEEE Transactions on Emerging Topics in Computing","","2018","PP","99","1","1","In the era of information, the green services of content-centric IoT are expected to offer users the better satisfaction of Quality of Experience (QoE) than that in a conventional IoT. Nevertheless, the network traffic and new demands from IoT users increase along with the promising of the content-centric computing system. Therefore, the satisfaction of QoE will become the major challenge in the content-centric computing system for IoT users. In this article, to enhance the satisfaction of QoE, we propose QoE models to evaluate the qualities of the IoT concerning both network and users. The value of QoE does not only refer to the network cost, but also the Mean Opinion Score (MOS) of users. Therefore, our models could capture the influence factors from network cost and services for IoT users based on IoT conditions. Specially, we mainly focus on the issues of cache allocation and transmission rate. Under this content-centric IoT, aiming to allocate the cache capacity among content-centric computing nodes and handle the transmission rates under a constrained total network cost and MOS for the whole IoT, we devote our efforts to the following two aspects. First, we formulate the QoE as a green resource allocation problem under the different transmission rate to acquire the best QoE. Then, in the basis of the node centrality, we will propose a suboptimal dynamic approach, which is suitable for IoT with content delivery frequently. Furthermore, we present a green resource allocation algorithm based on Deep Reinforcement Learning (DRL) to improve accuracy of QoE adaptively. Simulation results reveal that our proposals could achieve high QoE performance for content-centric IoT.","","","10.1109/TETC.2018.2805718","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8290944","Green Resource Allocation;QoE;Content-Centric Computing;IoT;Deep Reinforcement Learning","Quality of experience;Resource management;Computational modeling;Heuristic algorithms;Quality of service;Wireless networks;Electronic mail","","","","43","","","","","","IEEE","IEEE Early Access Articles"
"Deep Learning Approach for Short-Term Stock Trends Prediction Based on Two-Stream Gated Recurrent Unit Network","D. Lien Minh; A. Sadeghi-Niaraki; H. D. Huy; K. Min; H. Moon","Department of Computer Science and Engineering, Sejong University, Seoul, South Korea; Department of Computer Science and Engineering, Sejong University, Seoul, South Korea; Department of Information System, University of Information Technology, Ho Chi Minh City, Vietnam; Department of Computer Science and Engineering, Sejong University, Seoul, South Korea; Department of Computer Science and Engineering, Sejong University, Seoul, South Korea","IEEE Access","","2018","6","","55392","55404","Financial news has been proven to be a crucial factor which causes fluctuations in stock prices. However, previous studies heavily relied on analyzing shallow features and ignored the structural relation among words in a sentence. Several sentiment analysis studies have tried to point out the relationship between investors' reaction and news events. However, the sentiment dataset was usually constructed from the lingual dataset which is unrelated to the financial sector and led to poor performance. This paper proposes a novel framework to predict the directions of stock prices by using both financial news and sentiment dictionary. The original contributions of this paper include the proposal of a novel two-stream gated recurrent unit network and Stock2Vec-a sentiment word embedding trained on financial news dataset and Harvard IV-4. Two main experiments are conducted: the first experiment predicts S&P 500 index stock price directions using the historical S&P 500 prices and the articles crawled from Reuters and Bloomberg, and the second experiment forecasts the price trends of VN-index using VietStock news and stock prices from cophieu68. Results show that: 1) two-stream GRU outperforms state-of-the-art models; 2) Stock2Vec is more efficient in dealing with financial datasets; and 3) applying the model, a simulation scenario proves that our model is effective for the stock sector.","","","10.1109/ACCESS.2018.2868970","Korea Institute of Planning and Evaluation for Technology in Food, Agriculture, Forestry and Fisheries; Ministry of Agriculture, Food and Rural Affairs; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8456512","Deep learning;natural language processing;stock trends;sentiment analysis","Dictionaries;Sentiment analysis;Market research;Feature extraction;Machine learning;Internet","data mining;financial data processing;learning (artificial intelligence);pricing;recurrent neural nets;sentiment analysis;stock markets","deep learning;sentiment analysis;lingual dataset;sentiment dataset;sentiment analysis studies;structural relation;shallow features;two-stream gated recurrent unit network;short-term Stock trends prediction;stock sector;financial datasets;two-stream GRU;price trends;historical S&P 500 prices;S&P 500 index stock price directions;financial news dataset;Stock2Vec-a sentiment word embedding;sentiment dictionary;stock prices;financial sector","","4","34","","","","","IEEE","IEEE Journals"
"Contrast-Oriented Deep Neural Networks for Salient Object Detection","G. Li; Y. Yu","School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; Department of Computer Science, The University of Hong Kong, Hong Kong","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","12","6038","6051","Deep convolutional neural networks (CNNs) have become a key element in the recent breakthrough of salient object detection. However, existing CNN-based methods are based on either patchwise (regionwise) training and inference or fully convolutional networks. Methods in the former category are generally time-consuming due to severe storage and computational redundancies among overlapping patches. To overcome this deficiency, methods in the second category attempt to directly map a raw input image to a predicted dense saliency map in a single network forward pass. Though being very efficient, it is arduous for these methods to detect salient objects of different scales or salient regions with weak semantic information. In this paper, we develop hybrid contrast-oriented deep neural networks to overcome the aforementioned limitations. Each of our deep networks is composed of two complementary components, including a fully convolutional stream for dense prediction and a segment-level spatial pooling stream for sparse saliency inference. We further propose an attentional module that learns weight maps for fusing the two saliency predictions from these two streams. A tailored alternate scheme is designed to train these deep networks by fine-tuning pretrained baseline models. Finally, a customized fully connected conditional random field model incorporating a salient contour feature embedding can be optionally applied as a postprocessing step to improve spatial coherence and contour positioning in the fused result from these two streams. Extensive experiments on six benchmark data sets demonstrate that our proposed model can significantly outperform the state of the art in terms of all popular evaluation metrics.","","","10.1109/TNNLS.2018.2817540","National Natural Science Foundation of China; CCF-Tencent Open Research Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8337098","Conditional random fields (CRFs);deep contrast network;salient object detection","Object detection;Feature extraction;Neural networks;Visualization;Semantics;Image segmentation;Streaming media","convolution;feedforward neural nets;image segmentation;inference mechanisms;learning (artificial intelligence);object detection","saliency predictions;deep networks;salient contour feature embedding;salient object detection;convolutional neural networks;CNN-based methods;fully convolutional networks;salient objects;salient regions;hybrid contrast-oriented deep neural networks;segment-level spatial pooling stream;sparse saliency inference;dense saliency map;semantic information;weight map learning","","11","69","","","","","IEEE","IEEE Journals"
"Learning to Detect Local Overheating of the High-Power Microwave Heating Process With Deep Learning","K. Wang; L. Ma; Q. Xiong; S. Liang; G. Sun; X. Yu; Z. Yao; T. Liu","Key Laboratory of Dependable Service Computing in Cyber Physical Society, MOE, Chongqing, China; Key Laboratory of Dependable Service Computing in Cyber Physical Society, MOE, Chongqing, China; Key Laboratory of Dependable Service Computing in Cyber Physical Society, MOE, Chongqing, China; Key Laboratory of Dependable Service Computing in Cyber Physical Society, MOE, Chongqing, China; Key Laboratory of Dependable Service Computing in Cyber Physical Society, MOE, Chongqing, China; Key Laboratory of Dependable Service Computing in Cyber Physical Society, MOE, Chongqing, China; Key Laboratory of Dependable Service Computing in Cyber Physical Society, MOE, Chongqing, China; Key Laboratory of Dependable Service Computing in Cyber Physical Society, MOE, Chongqing, China","IEEE Access","","2018","6","","10288","10296","As a new kind of heating technology, microwave heating could replace traditional heating methods, because it has the advantages of high efficiency, no secondary pollution, and rapid heating. But the microwave heating process, which involves complex coupling between time-varying electromagnetic field and thermal field, is extremely complicated. At this point, the heated medium may produce local overheating. Worse, it may cause unexpected safety accidents, such as burning and even explosion. However, the temperature variation during the period of microwave heating could barely be obtained. In order to solve the problem of local overheating, this paper proposes a deep learning algorithm based on multidimensional data to construct an anomaly detection model for detecting local overheating. The algorithm consists of convolutional neural networks (CNNs) and unsupervised learning method named isolation forest algorithm (IFA). First, CNNs is utilized to extract features of the data collected from a WXD15S microwave heating system. Then, IFA detects the local overheating. Compared with the algorithm with common model, experiment results show that the proposed algorithm owns better measurement performance and higher precision.","","","10.1109/ACCESS.2018.2810266","Fundamental Research Funds for the Central Universities; Chongqing Research Program of Basic Research and Frontier Technology; National Natural Science Foundations of China; Science and Technology Major Special Project of Guangxi; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8304573","Microwave heating;local overheating;convolutional neural networks;isolation forest","Electromagnetic heating;Feature extraction;Microwave measurement;Temperature distribution;Microwave technology","electromagnetic fields;heat systems;microwave heating;neural nets;unsupervised learning","high-power microwave heating process;rapid heating;time-varying electromagnetic field;heated medium;deep learning algorithm;local overheating detection;unsupervised learning method;isolation forest algorithm;IFA;convolutional neural networks;CNN","","3","38","","","","","IEEE","IEEE Journals"
"Unified Deep Learning Architecture for Modeling Biology Sequence","H. Wu; C. Cao; X. Xia; Q. Lü","School of Computer Science and Technology, Soochow University, Suzhou, China; School of Computer Science and Technology, Soochow University, Suzhou, China; School of Computer Science and Technology, Soochow University, Suzhou, China; School of Computer Science and Technology, Soochow University, Suzhou, China","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2018","15","5","1445","1452","Prediction of the spatial structure or function of biological macromolecules based on their sequences remains an important challenge in bioinformatics. When modeling biological sequences using traditional sequencing models, long-range interaction, complicated and variable output of labeled structures, and variable length of biological sequences usually lead to different solutions on a case-by-case basis. This study proposed a unified deep learning architecture based on long short-term memory or a gated recurrent unit to capture long-range interactions. The architecture designs the optional reshape operator to adapt to the diversity of the output labels and implements a training algorithm to support the training of sequence models capable of processing variable-length sequences. The merging and pooling operators enhances the ability of capturing short-range interactions between basic units of biological sequences. The proposed deep-learning architecture and its training algorithm might be capable of solving currently variable biological sequence-modeling problems under a unified framework. We validated the model on one of the most difficult biological sequence-modeling problems, protein residue interaction prediction. The results indicate that the accuracy of obtaining the residue interactions of the model exceeded popular approaches by 10 percent on multiple widely-used benchmarks.","","","10.1109/TCBB.2017.2760832","National Natural Science Foundation of China; Special Program for Applied Research; NSFC-Guangdong Joint Fund; Suzhou Science and Technology Development Plan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8062800","Biological sequence;deep learning;bidirectional recurrent neural network","Proteins;Biological system modeling;Training;Predictive models;Computer architecture;RNA","bioinformatics;learning (artificial intelligence);molecular biophysics;proteins;recurrent neural nets","unified deep learning architecture;spatial structure;biological macromolecules;long-range interaction;variable output;labeled structures;case-by-case basis;output labels;training algorithm;variable-length sequences;short-range interactions;protein residue interaction prediction;variable biological sequence-modeling problems;gated recurrent unit","","1","44","","","","","IEEE","IEEE Journals"
"Discriminative Sparse Neighbor Approximation for Imbalanced Learning","C. Huang; C. C. Loy; X. Tang","The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Information Engineering, The Chinese University of Hong Kong, Hong Kong; Department of Information Engineering, The Chinese University of Hong Kong, Hong Kong","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","5","1503","1513","Data imbalance is common in many vision tasks where one or more classes are rare. Without addressing this issue, conventional methods tend to be biased toward the majority class with poor predictive accuracy for the minority class. These methods further deteriorate on small, imbalanced data that have a large degree of class overlap. In this paper, we propose a novel discriminative sparse neighbor approximation (DSNA) method to ameliorate the effect of class-imbalance during prediction. Specifically, given a test sample, we first traverse it through a cost-sensitive decision forest to collect a good subset of training examples in its local neighborhood. Then, we generate from this subset several class-discriminating but overlapping clusters and model each as an affine subspace. From these subspaces, the proposed DSNA iteratively seeks an optimal approximation of the test sample and outputs an unbiased prediction. We show that our method not only effectively mitigates the imbalance issue, but also allows the prediction to extrapolate to unseen data. The latter capability is crucial for achieving accurate prediction on small data set with limited samples. The proposed imbalanced learning method can be applied to both classification and regression tasks at a wide range of imbalance levels. It significantly outperforms the state-of-the-art methods that do not possess an imbalance handling mechanism, and is found to perform comparably or even better than recent deep learning methods by using hand-crafted features only.","","","10.1109/TNNLS.2017.2671845","General Research Fund through the Research Grants Council of the Hong Kong SAR; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7875451","Data extrapolation;decision forest;discriminative sparse neighbor approximation (DSNA);imbalanced learning","Image edge detection;Training;Robustness;Learning systems;Pose estimation;Bagging","approximation theory;image classification;learning (artificial intelligence);sparse matrices","discriminative sparse neighbor approximation;data imbalance;majority class;minority class;imbalanced data;class overlap;neighbor approximation method;DSNA;class-imbalance;cost-sensitive decision forest;local neighborhood;affine subspace;optimal approximation;unbiased prediction;unseen data;data set;imbalanced learning method;regression tasks;imbalance levels;imbalance handling mechanism;compter vision tasks;deep learning methods","","1","55","","","","","IEEE","IEEE Journals"
"An End-to-End Model Based on Improved Adaptive Deep Belief Network and Its Application to Bearing Fault Diagnosis","J. Xie; G. Du; C. Shen; N. Chen; L. Chen; Z. Zhu","School of Rail Transportation, Soochow University, Suzhou, China; School of Rail Transportation, Soochow University, Suzhou, China; School of Rail Transportation, Soochow University, Suzhou, China; Department of Industrial Systems Engineering and Management, National University of Singapore, Singapore; School of Rail Transportation, Soochow University, Suzhou, China; School of Rail Transportation, Soochow University, Suzhou, China","IEEE Access","","2018","6","","63584","63596","Effective machinery prognostics and health management play a crucial role in ensuring the safe and continuous operation of equipment, and satisfactory characteristics' expression of machine health status plays a key role in the ability to diagnose faults with high accuracy. At present, most methods based on signal processing and the shallow learning model rely on artificial feature extraction to identify the machine fault type. In practical applications, however, meaningful health management requires correct recognition of not only the health type but also the fault degree, if any occurs. Such recognition is useful for determining the priority level of mechanical maintenance and minimizing economic losses. Deep learning techniques, such as deep belief network (DBN), have demonstrated great potential in exploring characteristic information from machine status signals. In this paper, an end-to-end fault diagnosis model based on an adaptive DBN optimized by the Nesterov moment (NM) is proposed to extract deep representative features from rotating machinery and recognize bearing fault types and degrees simultaneously. Frequency-domain signals are inputted into the model for feature learning, and NM is introduced to the training process of the DBN model. Individual adaptive learning rate algorithms are then applied to optimize parameter updating. The performance of the proposed method is validated using a self-made bearing fault test platform, and the model is shown to achieve satisfactory convergence and a testing accuracy higher than those obtained from standard DBN and support vector machine.","","","10.1109/ACCESS.2018.2877447","National Natural Science Foundation of China; Suzhou Prospective Research Program; Natural Science Foundation of Jiangsu Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8502755","Bearing;health management;deep belief network;end-to-end model","Neurons;Feature extraction;Fault diagnosis;Adaptation models;Training;Rolling bearings;Modeling","belief networks;condition monitoring;fault diagnosis;feature extraction;learning (artificial intelligence);machine bearings;maintenance engineering;mechanical engineering computing;signal processing","bearing fault diagnosis;machine health status;signal processing;shallow learning model;artificial feature extraction;machine fault type;mechanical maintenance;deep learning techniques;machine status signals;end-to-end fault diagnosis model;bearing fault types;adaptive deep belief network;equipment health management;economic loss minimization;Nesterov moment;deep representative feature extraction;rotating machinery prognostics;adaptive learning rate algorithms","","5","29","","","","","IEEE","IEEE Journals"
"Learning View-Specific Deep Networks for Person Re-Identification","Z. Feng; J. Lai; X. Xie","School of Electronics and Information Technology, Sun Yat-sen University, Guangzhou, China; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China","IEEE Transactions on Image Processing","","2018","27","7","3472","3483","In recent years, a growing body of research has focused on the problem of person re-identification (re-id). The re-id techniques attempt to match the images of pedestrians from disjoint non-overlapping camera views. A major challenge of the re-id is the serious intra-class variations caused by changing viewpoints. To overcome this challenge, we propose a deep neural network-based framework which utilizes the view information in the feature extraction stage. The proposed framework learns a view-specific network for each camera view with a cross-view Euclidean constraint (CV-EC) and a cross-view center loss. We utilize the CV-EC to decrease the margin of the features between diverse views and extend the center loss metric to a view-specific version to better adapt the re-id problem. Moreover, we propose an iterative algorithm to optimize the parameters of the view-specific networks from coarse to fine. The experiments demonstrate that our approach significantly improves the performance of the existing deep networks and outperforms the state-of-the-art methods on the VIPeR, CUHK01, CUHK03, SYSU-mReId, and Market-1501 benchmarks.","","","10.1109/TIP.2018.2818438","NSFC; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8322217","Person re-identification;view-specific deep networks;cross-view Euclidean constraint;cross-view center loss","Feature extraction;Cameras;Measurement;Computational modeling;Benchmark testing;Dictionaries;Machine learning","cameras;feature extraction;image matching;image representation;learning (artificial intelligence);neural nets;object detection","view-specific deep networks;person re-identification;disjoint nonoverlapping camera views;serious intra-class variations;deep neural network;view information;feature extraction stage;camera view;cross-view Euclidean constraint;cross-view center loss;diverse views;view-specific version;re-id problem;re-id techniques;CV-EC;VIPeR;CUHK03;CUHK01;SYSU-mReId;Market-1501 benchmarks","","11","79","","","","","IEEE","IEEE Journals"
"Deep Bimodal Regression of Apparent Personality Traits from Short Video Sequences","X. Wei; C. Zhang; H. Zhang; J. Wu","Nanjing University, Nanjing, Jiangsu, China; Nanjing University, Nanjing, Jiangsu, China; Nanjing University, Nanjing, Jiangsu, China; Nanjing University, Nanjing, Jiangsu, China","IEEE Transactions on Affective Computing","","2018","9","3","303","315","Apparent personality analysis (APA) is an important problem of personality computing, and furthermore, automatic APA becomes a hot and challenging topic in computer vision and multimedia. In this paper, we propose a deep learning solution to APA from short video sequences. In order to capture rich information from both the visual and audio modality of videos, we tackle these tasks with our Deep Bimodal Regression (DBR) framework. In DBR, for the visual modality, we modify the traditional convolutional neural networks for exploiting important visual cues. In addition, taking into account the model efficiency, we extract audio representations and build a linear regressor for the audio modality. For combining the complementary information from the two modalities, we ensemble these predicted regression scores by both early fusion and late fusion. Finally, based on the proposed framework, we come up with a solution for the Apparent Personality Analysis competition track in the ChaLearn Looking at People challenge in association with ECCV 2016. Our DBR is the winner (first place) of this challenge with 86 registered participants. Beyond the competition, we further investigate the performance of different loss functions in our visual models, and prove non-convex loss functions for regression are optimal on the human-labeled video data.","","","10.1109/TAFFC.2017.2762299","National Natural Science Foundation of China; Collaborative Innovation Center of Novel Software Technology and Industrialization; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8066355","Apparent personality analysis;deep learning;bimodal data;convolutional neural networks;regression","Visualization;Distributed Bragg reflectors;Machine learning;Convolution;Video sequences;Computational modeling","image fusion;image representation;image sequences;learning (artificial intelligence);neural nets;regression analysis","human-labeled video data;APA;DBR framework;convolutional neural networks;apparent personality trait analysis;deep bimodal regression framework;audio representation extraction;linear regressor;ChaLearn looking at people challenge;ECCV 2016;nonconvex loss functions;complementary information;audio modality;visual modality;deep learning solution;multimedia;computer vision;personality computing;short video sequences","","1","58","","","","","IEEE","IEEE Journals"
"Transfer-Learning-Based Online Mura Defect Classification","H. Yang; S. Mei; K. Song; B. Tao; Z. Yin","State Key Laboratory of Digital Manufacturing Equipment and Technology, Huazhong University of Science and Technology, Wuhan, China; State Key Laboratory of Digital Manufacturing Equipment and Technology, Huazhong University of Science and Technology, Wuhan, China; State Key Laboratory of Digital Manufacturing Equipment and Technology, Huazhong University of Science and Technology, Wuhan, China; State Key Laboratory of Digital Manufacturing Equipment and Technology, Huazhong University of Science and Technology, Wuhan, China; State Key Laboratory of Digital Manufacturing Equipment and Technology, Huazhong University of Science and Technology, Wuhan, China","IEEE Transactions on Semiconductor Manufacturing","","2018","31","1","116","123","Flat panel displays, such as the thin film transistor liquid crystal display, the organic light-emitting diode, and the polymer light-emitting diode, have been widely applied in many fields in recent decades. To ensure the quality of these displays, defect inspection is crucial. Mura defects, which are phenomena of uneven screen displays, are the most challenging visual defects to detect. This paper presents an online sequential classifier and transfer learning (OSC-TL) method for the online training and classification of Mura defects. OSC-TL is a new method that combines a deep convolutional feature extractor and a sequential extreme learning machine classifier. It makes online sequential training in a production line possible. To demonstrate the performance of the OSC-TL method, several experiments are performed to compare the results of this method with those of other popular classification algorithms. The experimental results show that the computational resources and time consumed by OSC-TL are well below those of other common methods because of the feature transfer and the online sequential classification strategies. Consequently, the OSC-TL method has been implemented in our automated optical inspection equipment to perform online Mura defect classification. It is able to learn and recognize a Mura defect image within 1.5 milliseconds.","","","10.1109/TSM.2017.2777499","National Science Foundation of China; Major Project Foundation of Hubei Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8119927","Mura defect;online classification;deep learning;transfer learning;online sequential extreme learning machine","Training;Feature extraction;Liquid crystal displays;Inspection;Classification algorithms;Organic light emitting diodes","automatic optical inspection;convolution;feature extraction;flat panel displays;image classification;learning (artificial intelligence)","online training;deep convolutional feature extractor;sequential extreme learning machine classifier;online sequential training;OSC-TL method;feature transfer;online sequential classification strategies;Mura defect image;online Mura defect classification flat panel displays;film transistor liquid crystal display;organic light-emitting diode;polymer light-emitting diode;defect inspection;uneven screen displays;online sequential classifier;transfer-learning-based online Mura defect classification;time 1.5 ms","","5","31","","","","","IEEE","IEEE Journals"
"An Intrusion Detection System Using a Deep Neural Network With Gated Recurrent Units","C. Xu; J. Shen; X. Du; F. Zhang","College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China; College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China; College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China; College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China","IEEE Access","","2018","6","","48697","48707","To improve the performance of network intrusion detection systems (IDS), we applied deep learning theory to intrusion detection and developed a deep network model with automatic feature extraction. In this paper, we consider the characteristics of the time-related intrusion and propose a novel IDS that consists of a recurrent neural network with gated recurrent units (GRU), multilayer perceptron (MLP), and softmax module. Experiments on the well-known KDD 99 and NSL-KDD data sets show that the system has leading performance. The overall detection rate was 99.42% using KDD 99 and 99.31% using NSL-KDD with false positive rates as low as 0.05% and 0.84%, respectively. In particular, for detecting the denial of service attacks, the system achieved detection rates of 99.98% and 99.55%, respectively. Comparative experiments showed that the GRU is more suitable as a memory unit for IDS than LSTM, and proved that it is an effective simplification and improvement of LSTM. Moreover, the bidirectional GRU can reach the best performance compared with the recently published methods.","","","10.1109/ACCESS.2018.2867564","National Natural Science Foundation of China; Welfare Technology Research Project of Zhejiang Province; China Scholarship Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8449272","Intrusion detection;deep learning;recurrent neural network;gated recurrent unit","Intrusion detection;Feature extraction;Machine learning;Support vector machines;Recurrent neural networks;Logic gates","computer network security;feature extraction;learning (artificial intelligence);multilayer perceptrons;recurrent neural nets","GRU;multilayer perceptron;deep neural network;gated recurrent units;network intrusion detection systems;deep learning theory;automatic feature extraction;recurrent neural network;IDS;denial of service attacks;LSTM;MLP;softmax module","","6","39","","","","","IEEE","IEEE Journals"
"Scene Text Detection Using Superpixel-Based Stroke Feature Transform and Deep Learning Based Region Classification","Y. Tang; X. Wu","School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China","IEEE Transactions on Multimedia","","2018","20","9","2276","2288","Scene text detection is a crucial step in end-to-end scene text recognition, a greatly challenging problem in computer vision. This paper proposes a novel scene text detection method that involves superpixel-based stroke feature transform (SSFT) and deep learning based region classification (DLRC). The SSFT is developed for candidate character region (CCR) extraction, which consists in partitioning an input image into several regions via superpixel-based clustering, removing most regions based on predefined criteria satisfied by the characters, and refining the remaining regions to obtain CCRs by computing a stroke width map. The character regions are identified from the CCRs using DLRC, in which several hand-crafted low-level features, i.e., color, texture, and geometric features, and some deep convolution neural network (CNN) based high-level features are first extracted from the regions, and then these features are fused by using two fully connected networks (FCNs) for region classification. In the DLRC step, the deep feature extraction CNN and the feature fusion FCNs are jointly trained. Next, the extracted character regions are merged to form candidate text regions, from which the final scene texts are detected. The proposed method is evaluated on three publicly available datasets: ICDAR2011, ICDAR2013, and street view text. It achieves F -measures of 0.876, 0.885, and 0.631, respectively, which demonstrate the effectiveness of the proposed scene text detection method.","","","10.1109/TMM.2018.2802644","National Natural Science Foundation of China; ShanDong Provincial Natural Science Foundation, China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8281640","Scene text detection;superpixel based stroke feature transform;deep learning;convolutional neural network;fully connected network;region classification","Feature extraction;Image color analysis;Transforms;Image edge detection;Microsoft Windows;Proposals;Machine learning","character recognition;computer vision;feature extraction;image classification;image resolution;neural nets;text detection;transforms","superpixel-based stroke feature transform;region classification;end-to-end scene text recognition;greatly challenging problem;scene text detection method;candidate character region extraction;superpixel-based clustering;stroke width map;hand-crafted low-level features;geometric features;deep convolution neural network;high-level features;DLRC step;deep feature extraction CNN;feature fusion FCNs;candidate text regions;street view text;SSFT","","2","68","","","","","IEEE","IEEE Journals"
"Person Re-Identification Using Hybrid Representation Reinforced by Metric Learning","N. Perwaiz; M. M. Fraz; M. Shahzad","School of Electrical Engineering and Computer Science, National University of Sciences and Technology, Islamabad, Pakistan; School of Electrical Engineering and Computer Science, National University of Sciences and Technology, Islamabad, Pakistan; School of Electrical Engineering and Computer Science, National University of Sciences and Technology, Islamabad, Pakistan","IEEE Access","","2018","6","","77334","77349","Person Re-Identification (Re-Id) is among the main constituents of an automated visual surveillance system. It aims at finding out true matches of a given query person from a large repository of non-overlapping camera images/videos. In this paper, we have proposed an efficient Re-Id approach that is based on a highly discriminative hybrid person representation which combines the low-level hand-crafted appearance based features together with the mid-level attributes and semantic based deep features. The lowlevel hand crafted features are extracted by using hierarchical Gaussian and local histogram distributions in different color spaces. These features incorporate discriminative texture, shape and color information which is invariant to distractors, e.g., variations in pose, viewpoint and illumination, and so on. The mid-level attribute based deep features are extracted to incorporate contextual- and semantic-based information. The feature space is optimized and self-learned using cross-view quadratic discriminant analysis and multiple metric learning, with the aim to reduce the intra-class differences and increase the inter-class variations for robust person matching. The proposed framework is evaluated on publicly available small scale (VIPeR, PRID450s, and GRID) and large scale (CUHK01, Market1501, and DukeMTMC-ReID) person Re-Id datasets. The experimental results show that the hybrid hand-crafted and deep features outperformed the existing state-of-the-art in approaches in the unsupervised paradigm.","","","10.1109/ACCESS.2018.2882254","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8567879","Person re-identification;visual surveillance;hand-crafted features;hybrid person representation;metric learning;deep learning","Measurement;Feature extraction;Image color analysis;Visualization;Surveillance;Cameras","cameras;feature extraction;Gaussian distribution;image classification;image colour analysis;image matching;image representation;image texture;unsupervised learning;video surveillance","local histogram distributions;color information;feature space;cross-view quadratic discriminant analysis;multiple metric learning;inter-class variations;robust person matching;Person Re-Identification;automated visual surveillance system;efficient Re-Id approach;low-level hand-crafted appearance;semantic based deep features;low-level hand;color spaces;hybrid representation;nonoverlapping camera image-videos;low-level hand-crafted appearance based features;intra-class difference reduction;person Re-Id datasets;hybrid hand-crafted features;unsupervised paradigm;contextual-based information;semantic-based information;mid-level attribute based deep feature extraction;discriminative texture;hierarchical Gaussian distributions;query person matching;discriminative hybrid person representation","","2","67","","","","","IEEE","IEEE Journals"
"Which Artificial Intelligence Algorithm Better Predicts the Chinese Stock Market?","L. Chen; Z. Qiao; M. Wang; C. Wang; R. Du; H. E. Stanley","School of Management, Northwestern Polytechnical University, Xi’an, China; School of Economics and Finance, Xi’an Jiaotong University, Xi’an, China; School of Mathematical Science, Nanjing Normal University, Nanjing, China; College of Economics and Management, Beijing University of Technology, Beijing, China; Energy Development and Environmental Protection Strategy Research Center, Jiangsu University, Zhenjiang, China; Center for Polymer Studies and Department of Physics, Boston University, Boston, MA, USA","IEEE Access","","2018","6","","48625","48633","Unpredictable stock market factors make it difficult to predict stock index futures. Although efforts to develop an effective prediction method have a long history, recent developments in artificial intelligence and the use of artificial neural networks have increased our success in nonlinear approximation. When we study financial markets, we can now extract features from a big data environment without prior predictive information. We here propose to further improve this predictive performance using a combination of a deep-learning-based stock index futures prediction model, an autoencoder, and a restricted Boltzmann machine. We use high-frequency data to examine the predictive performance of deep learning, and we compare three traditional artificial neural networks: 1) the back propagation neural network; 2) the extreme learning machine; and 3) the radial basis function neural network. We use all of the 1-min high-frequency transaction data of the CSI 300 futures contract (IF1704) in our empirical analysis, and we test three groups of different volume samples to validate our observations. We find that the deep learning method of predicting stock index futures outperforms the back propagation, the extreme learning machine, and the radial basis function neural network in its fitting degree and directional predictive accuracy. We also find that increasing the amount of data increases predictive performance. This indicates that deep learning captures the nonlinear features of transaction data and can serve as a powerful stock index futures prediction tool for financial market investors.","","","10.1109/ACCESS.2018.2859809","National Social Science Fund of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8419702","Prediction methods;artificial neural networks;stock markets;deep learning","Machine learning;Feature extraction;Neural networks;Stock markets;Neurons;Prediction algorithms;Indexes","Big Data;learning (artificial intelligence);neural nets;stock markets","high-frequency transaction data;Chinese stock market;artificial neural networks;deep-learning-based stock index futures prediction model;financial market investors;powerful stock index futures prediction tool;directional predictive accuracy;deep learning method;radial basis function neural network;extreme learning machine;back propagation neural network;high-frequency data;restricted Boltzmann machine;big data environment;nonlinear approximation;effective prediction method;unpredictable stock market factors;artificial intelligence algorithm better predicts","","4","39","","","","","IEEE","IEEE Journals"
"Hyperspectral Unmixing Using Sparsity-Constrained Deep Nonnegative Matrix Factorization With Total Variation","X. Feng; H. Li; J. Li; Q. Du; A. Plaza; W. J. Emery","Sichuan Provincial Key Laboratory of Information Coding and Transmission, Southwest Jiaotong University, Chengdu, China; Sichuan Provincial Key Laboratory of Information Coding and Transmission, Southwest Jiaotong University, Chengdu, China; Guangdong Provincial Key Laboratory of Urbanization and Geo-simulation, Sun Yat-sen University, Guangzhou, China; Department of Electrical and Computer Engineering, Mississippi State University, Starkville, MS, USA; Department of Technology of Computers and Communications, Hyperspectral Computing Laboratory, Escuela Politécnica, University of Extremadura, Cáceres, Spain; Department of Aerospace Engineering Sciences, University of Colorado, Boulder, CO, USA","IEEE Transactions on Geoscience and Remote Sensing","","2018","56","10","6245","6257","Hyperspectral unmixing is an important processing step for many hyperspectral applications, mainly including: 1) estimation of pure spectral signatures (endmembers) and 2) estimation of the abundance of each endmember in each pixel of the image. In recent years, nonnegative matrix factorization (NMF) has been highly attractive for this purpose due to the nonnegativity constraint that is often imposed in the abundance estimation step. However, most of the existing NMF-based methods only consider the information in a single layer while neglecting the hierarchical features with hidden information. To alleviate such limitation, in this paper, we propose a new sparsity-constrained deep NMF with total variation (SDNMF-TV) technique for hyperspectral unmixing. First, by adopting the concept of deep learning, the NMF algorithm is extended to deep NMF model. The proposed model consists of pretraining stage and fine-tuning stage, where the former pretrains all factors layer by layer and the latter is used to reduce the total reconstruction error. Second, in order to exploit adequately the spectral and spatial information included in the original hyperspectral image, we enforce two constraints on the abundance matrix. Specifically, the L1/2 constraint is adopted, since the distribution of each endmember is sparse in the 2-D space. The TV regularizer is further introduced to promote piecewise smoothness in abundance maps. For the optimization of the proposed model, multiplicative update rules are derived using the gradient descent method. The effectiveness and superiority of the SDNMF-TV algorithm are demonstrated by comparing with other unmixing methods on both synthetic and real data sets.","","","10.1109/TGRS.2018.2834567","National Natural Science Foundation of China; Frontier Intersection Basic Research Project for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8372956","Deep learning (DL);hyperspectral unmixing;nonnegative matrix factorization (NMF);sparsity constraint;total variation (TV)","Hyperspectral imaging;Estimation;Sparse matrices;TV;Periodic structures;Artificial neural networks","geophysical image processing;gradient methods;hyperspectral imaging;learning (artificial intelligence);matrix decomposition;optimisation","gradient descent method;multiplicative update rules;optimization;hierarchical features;hyperspectral image;NMF-based methods;hyperspectral applications;sparsity-constrained deep nonnegative matrix factorization;unmixing methods;SDNMF-TV algorithm;abundance maps;abundance matrix;spatial information;spectral information;total reconstruction error;deep NMF model;deep learning;hyperspectral unmixing;total variation technique;sparsity-constrained deep NMF;hidden information;single layer;abundance estimation step;nonnegativity constraint;pure spectral signatures","","5","56","","","","","IEEE","IEEE Journals"
"Deep Learning Meets Wireless Network Optimization: Identify Critical Links","L. Liu; B. Yin; S. Zhang; X. Cao; Y. Cheng","ECE, Illinois Institute of Technology, Chicago, Illinois United States (e-mail: lliu41@hawk.iit.edu); ECE, Illinois Institute of Technology, Chicago, Illinois United States (e-mail: byin@hawk.iit.edu); Illinois Institute of Technology, Chicago, Illinois United States (e-mail: szhang104@hawk.iit.edu); ECE, Illinois Institute of Technology, Chicago, Illinois United States (e-mail: xh.cao@ieee.org); Electrical and Computer Engineering, Illinois Institute of Technology, Chicago, Illinois United States 60616 (e-mail: cheng@iit.edu)","IEEE Transactions on Network Science and Engineering","","2018","PP","99","1","1","With the superior capability of discovering intricate structure of large data sets, deep learning has been widely applied in various areas including wireless networking. While existing deep learning applications mainly focus on data analysis, the role it can play on fundamental research issues in wireless networks is yet to be explored. With the proliferation of wireless networking infrastructure and mobile applications, wireless network optimization has seen a tremendous increase in problem size and complexity, calling for a paradigm for efficient computation. This paper presents a pioneering study on how to exploit deep learning for significant performance gain in wireless network optimization. Analysis on the flow constrained optimization problems suggests the possibility that a smaller-sized problem can be solved while sharing equally optimal solutions with the original problem, by excluding the potentially unused links from the problem formulation. To this end, we design a deep learning framework to find the latent relationship between flow information and link usage by learning from past computation experience. Numerical results demonstrate that the proposed method is capable of identifying critical links and can reduce computation cost by up to 50% without affecting optimality, thus greatly improve the efficiency of solving network optimization problems.","","","10.1109/TNSE.2018.2827997","National Natural Science Foundation of China; National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8340067","Optimization;Machine learning;Deep learning","Optimization;Machine learning;Wireless networks;Task analysis;Feature extraction;Resource management","","","","10","","","","","","IEEE","IEEE Early Access Articles"
"Duplex Metric Learning for Image Set Classification","G. Cheng; P. Zhou; J. Han","School of Automation, Northwestern Polytechnical University, Xi’an, China; School of Automation, Northwestern Polytechnical University, Xi’an, China; School of Automation, Northwestern Polytechnical University, Xi’an, China","IEEE Transactions on Image Processing","","2018","27","1","281","292","Image set classification has attracted much attention because of its broad applications. Despite the success made so far, the problems of intra-class diversity and inter-class similarity still remain two major challenges. To explore a possible solution to these challenges, this paper proposes a novel approach, termed duplex metric learning (DML), for image set classification. The proposed DML consists of two progressive metric learning stages with different objectives used for feature learning and image classification, respectively. The metric learning regularization is not only used to learn powerful feature representations but also well explored to train an effective classifier. At the first stage, we first train a discriminative stacked autoencoder (DSAE) by layer-wisely imposing a metric learning regularization term on the neurons in the hidden layers and meanwhile minimizing the reconstruction error to obtain new feature mappings in which similar samples are mapped closely to each other and dissimilar samples are mapped farther apart. At the second stage, we discriminatively train a classifier and simultaneously fine-tune the DSAE by optimizing a new objective function, which consists of a classification error term and a metric learning regularization term. Finally, two simple voting strategies are devised for image set classification based on the learnt classifier. In the experiments, we extensively evaluate the proposed framework for the tasks of face recognition, object recognition, and face verification on several commonly-used data sets and state-of-the-art results are achieved in comparison with existing methods.","","","10.1109/TIP.2017.2760512","National Science Foundation of China; Natural Science Basic Research Plan in Shaanxi Province of China; Science and Technology Foundation; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8060589","Image set classification;metric learning;feature learning;deep learning","Measurement;Image reconstruction;Training;Linear programming;Neurons;Object recognition","face recognition;image classification;image coding;image reconstruction;image representation;image sampling;learning (artificial intelligence)","classification error term;metric learning regularization term;image set classification;progressive metric learning stages;feature learning;intraclass diversity;interclass similarity;duplex metric learning;DML;feature representations;discriminative stacked autoencoder;DSAE;feature mappings;image sampling;face recognition;object recognition","","17","74","","","","","IEEE","IEEE Journals"
"Deep Shrinkage Convolutional Neural Network for Adaptive Noise Reduction","K. Isogawa; T. Ida; T. Shiodera; T. Takeguchi","Corporate Research and Development Center, Toshiba Corporation, Kawasaki, Japan; Corporate Research and Development Center, Toshiba Corporation, Kawasaki, Japan; Corporate Research and Development Center, Toshiba Corporation, Kawasaki, Japan; Corporate Research and Development Center, Toshiba Corporation, Kawasaki, Japan","IEEE Signal Processing Letters","","2018","25","2","224","228","The noise level of an image depends on settings of an imaging device. The settings can be used to select appropriate parameters for denoising methods. But denoising methods based on deep convolutional neural networks (deep-CNN) do not have such adjustable parameters. Therefore, a deep-CNN whose training data contain limited levels of noise does not effectively restore images whose noise level is different from the training data. If the range of noise levels of training data is extended to solve the problem, the maximum performance of a produced deep-CNN is limited. To solve the tradeoff, we propose a deep-CNN that is adjustable to the noise level of the input image immediately. We use soft shrinkage for activation functions of our deep-CNN. The soft shrinkage has thresholds proportional to the noise level given by the user. We also propose an optimization method for proportionality coefficients for the thresholds of soft shrinkage. Our method optimizes the coefficients for various noise levels simultaneously. In our experiment using a test set whose noise level is from 5 to 50, the proposed method showed higher PSNR than that in the case of the conventional method using only one deep-CNN, and PSNR comparable to that in the case of the conventional method using multiple noise-level-specific CNNs.","","","10.1109/LSP.2017.2782270","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8186226","Convolutional neural networks (CNN);image denoising;soft shrinkage;supervised learning","Noise level;Noise reduction;Convolution;Neural networks;Noise measurement;Training data;Feature extraction","convolution;image denoising;image restoration;image segmentation;learning (artificial intelligence);neural nets;signal denoising","multiple noise-level-specific CNNs;soft shrinkage;deep-CNN;deep convolutional neural networks;denoising methods;noise level;adaptive noise reduction;deep shrinkage convolutional neural network","","10","19","","","","","IEEE","IEEE Journals"
"Computational Deep Intelligence Vision Sensing for Nutrient Content Estimation in Agricultural Automation","S. B. Sulistyo; D. Wu; W. L. Woo; S. S. Dlay; B. Gao","School of Electrical and Electronics Engineering, Newcastle University, Newcastle upon Tyne, U.K.; School of Electrical and Electronics Engineering, Newcastle University, Newcastle upon Tyne, U.K.; School of Electrical and Electronics Engineering, Newcastle University, Newcastle upon Tyne, U.K.; School of Electrical and Electronics Engineering, Newcastle University, Newcastle upon Tyne, U.K.; School of Electrical and Electronics Engineering, Newcastle University, Newcastle upon Tyne, U.K.","IEEE Transactions on Automation Science and Engineering","","2018","15","3","1243","1257","This paper presents a novel computational intelligence vision sensing approach to estimate nutrient content in wheat leaves by analyzing color features of the leaves images captured on field with various lighting conditions. We propose the development of deep sparse extreme learning machines (DSELM) fusion and genetic algorithm (GA) to normalize plant images as well as to reduce color variability due to a variation of sunlight intensities. We also apply the DSELM in image segmentation to differentiate wheat leaves from a complex background. In this paper, four moments of color distribution of the leaves images (mean, variance, skewness, and kurtosis) are extracted and utilized as predictors in the nutrient estimation. We combine a number of DSELMs with committee machine and optimize them using the GA to estimate nitrogen content in wheat leaves. The results have shown the superiority of the proposed method in the term of quality and processing speed in all steps, i.e., color normalization, image segmentation, and nutrient prediction, as compared with other existing methods.","","","10.1109/TASE.2017.2770170","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8233416","Agricultural automation;committee machines;computational intelligence;deep learning;deep neural networks;image processing","Image color analysis;Nitrogen;Estimation;Agriculture;Genetic algorithms;Image segmentation;Feature extraction","agricultural products;agriculture;computer vision;feature extraction;genetic algorithms;image colour analysis;image segmentation;learning (artificial intelligence)","computational deep intelligence vision sensing;nutrient content estimation;agricultural automation;color features;leaves images;lighting conditions;deep sparse extreme learning machines;genetic algorithm;GA;plant images;color variability;sunlight intensities;DSELM;image segmentation;color distribution;skewness;nutrient estimation;nitrogen content;color normalization;nutrient prediction;wheat leaves;computational intelligence vision sensing approach","","","48","","","","","IEEE","IEEE Journals"
"Deep Recurrent Regression for Facial Landmark Detection","H. Lai; S. Xiao; Y. Pan; Z. Cui; J. Feng; C. Xu; J. Yin; S. Yan","National University of Singapore, Singapore; Department of Electronic and Computer Engineering, National University of Singapore, Singapore; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; Key Laboratory of Child Development and Learning Science of Ministry of Education, Research Center for Learning Science, Southeast University, Nanjing, China; Department of Electronic and Computer Engineering, National University of Singapore, Singapore; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; Department of Electronic and Computer Engineering, National University of Singapore, Singapore","IEEE Transactions on Circuits and Systems for Video Technology","","2018","28","5","1144","1157","We propose a novel end-to-end deep architecture for face landmark detection, based on a deep convolutional and deconvolutional network followed by carefully designed recurrent network structures. The pipeline of this architecture consists of three parts. Through the first part, we encode an input face image to resolution-preserved deconvolutional feature maps via a deep network with stacked convolutional and deconvolutional layers. Then, in the second part, we estimate the initial coordinates of the facial key points by an additional convolutional layer on top of these deconvolutional feature maps. In the last part, by using the deconvolutional feature maps and the initial facial key points as input, we refine the coordinates of the facial key points by a recurrent network that consists of multiple long short-term memory components. Extensive evaluations on several benchmark data sets show that the proposed deep architecture has superior performance against the state-of-the-art methods.","","","10.1109/TCSVT.2016.2645723","National Natural Science Foundation of China; Natural Science Foundation of Guangdong Province; CCF-Tencent Open Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7801061","Cascaded regression;facial landmark detection;recurrent regression;shape-indexed features","Feature extraction;Face;Shape;Visualization;Computer architecture;Pipelines;Image resolution","deconvolution;face recognition;learning (artificial intelligence);recurrent neural nets","deep recurrent regression;facial landmark detection;end-to-end deep architecture;face landmark detection;deep convolutional network;deconvolutional network;input face image;deconvolutional feature maps;deep network;stacked convolutional layers;deconvolutional layers","","7","41","","","","","IEEE","IEEE Journals"
"Deep Self-Paced Residual Network for Multispectral Images Classification Based on Feature-Level Fusion","J. Zhang; D. Zhang; W. Ma; L. Jiao","Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, International Research Center of Intelligent Perception and Computation, International Collaboration Joint Laboratory in Intelligent Perception and Computation, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, International Research Center of Intelligent Perception and Computation, International Collaboration Joint Laboratory in Intelligent Perception and Computation, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, International Research Center of Intelligent Perception and Computation, International Collaboration Joint Laboratory in Intelligent Perception and Computation, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, International Research Center of Intelligent Perception and Computation, International Collaboration Joint Laboratory in Intelligent Perception and Computation, Xidian University, Xi’an, China","IEEE Geoscience and Remote Sensing Letters","","2018","15","11","1740","1744","The classification methods based on fusion techniques of multisource multispectral (MS) images have been studied for a long time. However, it may be difficult to classify these data based on a feature level while avoiding the inconsistency of data caused by multisource and multiple regions or cities. In this letter, we propose a deep learning structure called 2-branch SPL-ResNet which combines the self-paced learning with deep residual network to classify multisource MS data based on the feature-level fusion. First, a 2-D discrete wavelet is used to obtain the multiscale features and sparse representation of MS data. Then, a 2-branch SPL-ResNet is established to extract respective characteristics of the two satellites. Finally, we implement the feature-level fusion by cascading the two feature vectors and then classify the integrated feature vector. We conduct the experiments on Landsat_8 and Sentinel_2 MS images. Compared with the commonly used classification methods such as support vector machine and convolutional neural networks, our proposed 2-branch SPL-ResNet framework has higher accuracy and more robustness.","","","10.1109/LGRS.2018.2854847","Major Research Plan of the National Natural Science Foundation of China; National Natural Science Foundation of China; Fund for Foreign Scholars in University Research and Teaching Programs (the 111 Project); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8424470","Deep residual network (ResNet);image classification;image fusion;multisource multispectral (MS) data;self-paced learning (SPL)","Feature extraction;Satellites;Fuses;Data mining;Urban areas;Remote sensing;Support vector machines","convolution;discrete wavelet transforms;feature extraction;feedforward neural nets;geophysical image processing;hyperspectral imaging;image classification;image fusion;image representation;learning (artificial intelligence);support vector machines;vectors","2-branch SPL-ResNet framework;deep self-paced residual network;multispectral images classification;feature-level fusion;fusion techniques;multisource multispectral images;multiple regions;cities;deep learning structure;multisource MS data;2-D discrete wavelet;multiscale features;integrated feature vector;Sentinel_2 MS images;self-paced learning;sparse representation;satellites;Landsat_8;support vector machine;convolutional neural networks","","","15","","","","","IEEE","IEEE Journals"
"DeepPolyA: A Convolutional Neural Network Approach for Polyadenylation Site Prediction","X. Gao; J. Zhang; Z. Wei; H. Hakonarson","Department of Computer Science, New Jersey Institute of Technology, Newark, NJ, USA; Adobe Systems, San Jose, CA, USA; Department of Computer Science, New Jersey Institute of Technology, Newark, NJ, USA; The Center for Applied Genomics, Abramson Research Center, The Children’s Hospital of Philadelphia, Philadelphia, PA, USA","IEEE Access","","2018","6","","24340","24349","Polyadenylation (Poly(A)) plays crucial roles in gene regulation, especially in messenger RNA metabolism, protein diversification, and protein localization. Accurate prediction of polyadenylation sites and identification of motifs that controlling polyadenylation are fundamental for interpreting the patterns of gene expression, improving the accuracy of genome annotation and comprehending the mechanisms that governing gene regulation. Despite considerable advances in using machine learning techniques for this problem, its efficiency is still limited by the lack of experiences and domain knowledge to carefully design and generate useful features, especially for plants. With the increasing availability of extensive genomic data sets and leading computational techniques, deep learning methods, especially convolutional neural networks, have been applied to automatically identify and understand gene regulation directly from gene sequences and predict unknown sequence profiles. Here, we present DeepPolyA, a new deep convolutional neural network-based approach, to predict polyadenylation sites from the plant Arabidopsis thaliana gene sequences. We investigate various deep neural network architectures and evaluate their performance against classical machine learning algorithms and several popular deep learning models. Experimental results demonstrate that DeepPolyA is substantially better than competing methods regarding various performance metrics. We further visualize the learned motifs of DeepPolyA to provide insights of our model and learned polyadenylation signals.","","","10.1109/ACCESS.2018.2825996","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8336859","Polyadenylation prediction;deep learning;multi-layer neural network;motif discovery;genomics and machine learning algorithms","Predictive models;Genomics;Bioinformatics;Feature extraction;DNA;Convolution;Hidden Markov models","biology computing;convolution;feedforward neural nets;genetics;genomics;learning (artificial intelligence);proteins;RNA","Arabidopsis thaliana gene sequences;RNA metabolism;genome annotation;gene expression;protein localization;protein diversification;polyadenylation site prediction;classical machine learning algorithms;deep neural network architectures;deep convolutional neural network;DeepPolyA;gene regulation;deep learning methods;extensive genomic data sets","","1","50","","","","","IEEE","IEEE Journals"
"Penalized PET Reconstruction Using Deep Learning Prior and Local Linear Fitting","K. Kim; D. Wu; K. Gong; J. Dutta; J. H. Kim; Y. D. Son; H. K. Kim; G. El Fakhri; Q. Li","Gordon Center for Medical Imaging, Massachusetts General Hospital, Harvard Medical School, Boston, MA, USA; Gordon Center for Medical Imaging, Massachusetts General Hospital, Harvard Medical School, Boston, MA, USA; Gordon Center for Medical Imaging, Massachusetts General Hospital, Harvard Medical School, Boston, MA, USA; Gordon Center for Medical Imaging, Massachusetts General Hospital, Harvard Medical School, Boston, MA, USA; Neuroscience Research Institute, Gachon University of Medicine and Science, Incheon, South Korea; Neuroscience Research Institute, Gachon University of Medicine and Science, Incheon, South Korea; Neuroscience Research Institute, Gachon University of Medicine and Science, Incheon, South Korea; Gordon Center for Medical Imaging, Massachusetts General Hospital, Harvard Medical School, Boston, MA, USA; Gordon Center for Medical Imaging, Massachusetts General Hospital, Harvard Medical School, Boston, MA, USA","IEEE Transactions on Medical Imaging","","2018","37","6","1478","1487","Motivated by the great potential of deep learning in medical imaging, we propose an iterative positron emission tomography reconstruction framework using a deep learning-based prior. We utilized the denoising convolutional neural network (DnCNN) method and trained the network using full-dose images as the ground truth and low dose images reconstructed from downsampled data by Poisson thinning as input. Since most published deep networks are trained at a predetermined noise level, the noise level disparity of training and testing data is a major problem for their applicability as a generalized prior. In particular, the noise level significantly changes in each iteration, which can potentially degrade the overall performance of iterative reconstruction. Due to insufficient existing studies, we conducted simulations and evaluated the degradation of performance at various noise conditions. Our findings indicated that DnCNN produces additional bias induced by the disparity of noise levels. To address this issue, we propose a local linear fitting function incorporated with the DnCNN prior to improve the image quality by preventing unwanted bias. We demonstrate that the resultant method is robust against noise level disparities despite the network being trained at a predetermined noise level. By means of bias and standard deviation studies via both simulations and clinical experiments, we show that the proposed method outperforms conventional methods based on total variation and non-local means penalties. We thereby confirm that the proposed method improves the reconstruction result both quantitatively and qualitatively.","","","10.1109/TMI.2018.2832613","Korean Health Technology R&D Project, Ministry of Health and Welfare, South Korea; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354909","PET;reconstruction;convolutional neural network;DnCNN;local linear fitting","Noise level;Image reconstruction;Training;Machine learning;Noise reduction;Computed tomography;Image quality","computerised tomography;feedforward neural nets;image denoising;image reconstruction;image representation;iterative methods;learning (artificial intelligence);medical image processing;positron emission tomography","penalized PET reconstruction;deep learning;local linear fitting;medical imaging;iterative positron emission tomography reconstruction framework;denoising convolutional neural network method;full-dose images;downsampled data;published deep networks;predetermined noise level;noise level disparity;testing data;iterative reconstruction;noise conditions;image quality;low-dose images;DnCNN","","6","33","","","","","IEEE","IEEE Journals"
"Classification of Medical Images in the Biomedical Literature by Jointly Using Deep and Handcrafted Visual Features","J. Zhang; Y. Xia; Y. Xie; M. Fulham; D. D. Feng","Shaanxi Key Laboratory of Speech and Image Information Processing and the Centre for Multidisciplinary Convergence Computing, School of Computer Science and Engineering, Northwestern Polytechnical University, Xi’an, China; Shaanxi Key Laboratory of Speech and Image Information Processing and the Centre for Multidisciplinary Convergence Computing, School of Computer Science and Engineering, Northwestern Polytechnical University, Xi’an, China; Shaanxi Key Laboratory of Speech and Image Information Processing and the Centre for Multidisciplinary Convergence Computing, School of Computer Science and Engineering, Northwestern Polytechnical University, Xi’an, China; Department of Molecular Imaging, Royal Prince Alfred Hospital, Sydney, Australia; Biomedical and Multimedia Information Technology Research Group, School of Information Technologies, University of Sydney, Sydney, NSW, Australia","IEEE Journal of Biomedical and Health Informatics","","2018","22","5","1521","1530","The classification of medical images and illustrations from the biomedical literature is important for automated literature review, retrieval, and mining. Although deep learning is effective for large-scale image classification, it may not be the optimal choice for this task as there is only a small training dataset. We propose a combined deep and handcrafted visual feature (CDHVF) based algorithm that uses features learned by three fine-tuned and pretrained deep convolutional neural networks (DCNNs) and two handcrafted descriptors in a joint approach. We evaluated the CDHVF algorithm on the ImageCLEF 2016 Subfigure Classification dataset and it achieved an accuracy of 85.47%, which is higher than the best performance of other purely visual approaches listed in the challenge leaderboard. Our results indicate that handcrafted features complement the image representation learned by DCNNs on small training datasets and improve accuracy in certain medical image classification problems.","","","10.1109/JBHI.2017.2775662","National Natural Science Foundation of China; Seed Foundation of Innovation and Creation for Graduate Students in Northwestern Polytechnical University; Australian Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115141","Medical image classification;deep convolutional neural network (DCNN);back-propagation neural network (BPNN);ensemble learning","Biomedical imaging;Visualization;Feature extraction;Training;Computed tomography;Terminology;Image representation","convolution;feature extraction;feedforward neural nets;image classification;image representation;learning (artificial intelligence);medical image processing","biomedical literature;handcrafted visual features;deep learning;large-scale image classification;fine-tuned networks;DCNNs;joint approach;CDHVF algorithm;handcrafted features;image representation;medical image classification problems;medical images classification;deep convolutional neural networks;deep visual features","","4","44","","","","","IEEE","IEEE Journals"
"Deep Deformable Patch Metric Learning for Person Re-Identification","S. Bąk; P. Carr","Disney Research, Pittsburgh, PA, USA; Disney Research, Pittsburgh, PA, USA","IEEE Transactions on Circuits and Systems for Video Technology","","2018","28","10","2690","2702","The methodology for finding the same individual in a network of cameras must deal with significant changes in appearance caused by variations in illumination, viewing angle, and a person's pose. Re-identification requires solving two fundamental problems: 1) determining a distance measure between features extracted from different cameras that cope with illumination changes (metric learning) and 2) ensuring that matched features refer to the same body part (correspondence). Most metric learning approaches focus on finding a robust distance measure between bounding box images, neglecting the alignment aspects. In this paper, we propose to learn appearance measures for patches that are combined using deformable models. Learning metrics for patches avoids strong dimensionality reduction, thus keeping more information. Additionally, we allow patches to change their locations, directly addressing the correspondence problem. As patches from different locations may share the same metric, our method effectively multiplies the amount of training data and allows patch metrics to be learned on the smaller amounts of labeled images. Different metric learning approaches (KISSME, XQDA, and LSSL) together with different deformable models (spring constraints and one-to-one matching constraints) are investigated and compared. For describing patches, we propose to learn a deep feature representation with convolutional neural networks, thus obtaining highly effective features for re-identification. We demonstrate that our approach significantly outperforms state-of-the-art methods on multiple data sets.","","","10.1109/TCSVT.2017.2765242","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8076890","Metric learning;deformable models","Measurement;Feature extraction;Cameras;Deformable models;Robustness;Training data","feature extraction;image matching;image representation;learning (artificial intelligence)","matched features;robust distance measure;appearance measures;correspondence problem;deep feature representation;deep deformable patch metric learning;person re-identification","","","51","","","","","IEEE","IEEE Journals"
"Analyzing the Training Processes of Deep Generative Models","M. Liu; J. Shi; K. Cao; J. Zhu; S. Liu","Tsinghua UniversityNational Engineering Lab for Big Data Software; Tsinghua University; Tsinghua UniversityNational Engineering Lab for Big Data Software; Tsinghua University; Tsinghua UniversityNational Engineering Lab for Big Data Software","IEEE Transactions on Visualization and Computer Graphics","","2018","24","1","77","87","Among the many types of deep models, deep generative models (DGMs) provide a solution to the important problem of unsupervised and semi-supervised learning. However, training DGMs requires more skill, experience, and know-how because their training is more complex than other types of deep models such as convolutional neural networks (CNNs). We develop a visual analytics approach for better understanding and diagnosing the training process of a DGM. To help experts understand the overall training process, we first extract a large amount of time series data that represents training dynamics (e.g., activation changes over time). A blue-noise polyline sampling scheme is then introduced to select time series samples, which can both preserve outliers and reduce visual clutter. To further investigate the root cause of a failed training process, we propose a credit assignment algorithm that indicates how other neurons contribute to the output of the neuron causing the training failure. Two case studies are conducted with machine learning experts to demonstrate how our approach helps understand and diagnose the training processes of DGMs. We also show how our approach can be directly used to analyze other types of deep models, such as CNNs.","","","10.1109/TVCG.2017.2744938","National NSF of China; NVIDIA; Tsinghua Tiangong Intelligent Technology Institute; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8019879","deep learning;deep generative models;blue noise sampling;credit assignment","Training;Neurons;Time series analysis;Tools;Visual analytics;Analytical models","data analysis;data visualisation;learning (artificial intelligence);time series","machine learning;credit assignment algorithm;visual clutter reduction;blue-noise polyline sampling scheme;visual analytics approach;training DGM;training dynamics;deep generative models;training failure;failed training process;time series samples","","21","55","Traditional","","","","IEEE","IEEE Journals"
"Wide and Deep Model of Multi-Source Information-Aware Recommender System","W. Yuan; H. Wang; B. Hu; L. Wang; Q. Wang","School of Information Science and Engineering, Shandong Normal University, Jinan, China; School of Information Science and Engineering, Shandong Normal University, Jinan, China; School of Information Science and Engineering, Shandong Normal University, Jinan, China; School of Information Science and Engineering, Shandong Normal University, Jinan, China; School of Information Science and Engineering, Shandong Normal University, Jinan, China","IEEE Access","","2018","6","","49385","49398","Collaborative filtering recommendation suffers from the problems of high data sparsity, poor expansibility, cold start, and the difficulty of modeling user preferences, among which data sparsity is the greatest issue. Although our previous work on matrix completion model, named low rank non-negative matrix factorization and completion algorithm (LR-NMFC) and stochastic sub-gradient based low rank matrix completion algorithm, could effectively alleviate the sparsity problem, they customarily model the linear feature interactions instead of the complex nonlinear structures between users and items when making recommendations. To better depict user preferences and item features, we deepen the linear model LR-NMFC to establish a wide and deep model, which we named Wide and Deep model of Multi-source information-Aware recommender system (WDMMA), based on multi-source information composed of user-item interaction matrix, attributes, and context. The wide part mainly handles the linear interactions between users and items, while the deep part portrays the high-order nonlinear interactions. We pre-train both the wide and the deep part using LR-NMFC in the embedding layer. In the pooling layer, we define a pooling operation, AC-pooling, which is used to model the various interactions among users, items, attributes, and context information. Upon the pooling layer, we stack some hidden layers to capture the high-order nonlinear feature interactions. Experiments on two public datasets show that WDMMA can learn complex nonlinear feature patterns successfully and effectively and is beneficial to improve the recommendation performance. Therefore, it is an effective way to consider both linear user-item interactions and multi-source information-aware nonlinear interactions in a deep learning framework when making recommendations.","","","10.1109/ACCESS.2018.2868083","National Science Foundation; Technology Program of Shandong Province; Science and Technology Program Project of Shandong Colleges and Universities; Shandong Jianzhu University; Excellent Course Project of Shandong Province; Educational Science Planning Project of Shandong Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453012","Collaborative filtering recommendation;data sparsity;deep learning;high-order nonlinear interactions;multi-source information","Recommender systems;Feature extraction;Collaboration;Context modeling;Machine learning;Data models;Wavelength division multiplexing","collaborative filtering;learning (artificial intelligence);matrix decomposition;recommender systems","completion algorithm;low rank nonnegative matrix factorization;multisource information-aware recommender system;collaborative filtering recommendation;high-order nonlinear interactions;deep part;linear interactions;wide part;user-item interaction matrix;deep model;wide model;linear model LR-NMFC;linear feature interactions;sparsity problem;stochastic sub-gradient based low rank matrix completion algorithm;matrix completion model;modeling user preferences;high data sparsity;making recommendations;linear user-item interactions;complex nonlinear feature patterns;high-order nonlinear feature interactions;pooling layer","","","40","","","","","IEEE","IEEE Journals"
"Graph Regularized Restricted Boltzmann Machine","D. Chen; J. Lv; Z. Yi","College of Computer Science, Sichuan University, Chengdu, China; College of Computer Science, Sichuan University, Chengdu, China; College of Computer Science, Sichuan University, Chengdu, China","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","6","2651","2659","The restricted Boltzmann machine (RBM) has received an increasing amount of interest in recent years. It determines good mapping weights that capture useful latent features in an unsupervised manner. The RBM and its generalizations have been successfully applied to a variety of image classification and speech recognition tasks. However, most of the existing RBM-based models disregard the preservation of the data manifold structure. In many real applications, the data generally reside on a low-dimensional manifold embedded in high-dimensional ambient space. In this brief, we propose a novel graph regularized RBM to capture features and learning representations, explicitly considering the local manifold structure of the data. By imposing manifold-based locality that preserves constraints on the hidden layer of the RBM, the model ultimately learns sparse and discriminative representations. The representations can reflect data distributions while simultaneously preserving the local manifold structure of data. We test our model using several benchmark image data sets for unsupervised clustering and supervised classification problem. The results demonstrate that the performance of our method exceeds the state-of-the-art alternatives.","","","10.1109/TNNLS.2017.2692773","National Natural Science Foundation of China; State Key Program of National Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7927417","Deep learning;graph regularized RBM (GraphRBM);manifold learning;restricted Boltzmann machine (RBM);structure preservation","Manifolds;Data models;Computational modeling;Mathematical model;Machine learning;Learning systems;Benchmark testing","Boltzmann machines;feature extraction;graph theory;image classification;image representation;pattern clustering;unsupervised learning","graph regularized restricted Boltzmann machine;image classification;speech recognition tasks;data manifold structure;low-dimensional manifold;high-dimensional ambient space;learning representations;local manifold structure;data distributions;image data sets;graph regularized RBM;feature capture;sparse representation;discriminative representation;unsupervised clustering;supervised classification problem","","4","65","","","","","IEEE","IEEE Journals"
"Deformable Image Registration Using a Cue-Aware Deep Regression Network","X. Cao; J. Yang; J. Zhang; Q. Wang; P. Yap; D. Shen","School of AutomationNorthwestern Polytechnical University and also with the Department of Radiology and BRIC University of North Carolina at Chapel Hill; School of AutomationNorthwestern Polytechnical University; Department of Radiology and BRICUniversity of North Carolina at Chapel Hill; School of Biomedical Engineering, Institute for Medical Imaging Technology, Shanghai Jiao Tong University, Shanghai, China; Department of Radiology and BRICUniversity of North Carolina at Chapel Hill; Department of Radiology and BRIC, University of North Carolina at Chapel Hill, Chapel Hill, NC, USA","IEEE Transactions on Biomedical Engineering","","2018","65","9","1900","1911","Significance: Analysis of modern large-scale, multicenter or diseased data requires deformable registration algorithms that can cope with data of diverse nature. Objective: We propose a novel deformable registration method, which is based on a cue-aware deep regression network, to deal with multiple databases with minimal parameter tuning. Methods: Our method learns and predicts the deformation field between a reference image and a subject image. Specifically, given a set of training images, our method learns the displacement vector associated with a pair of reference-subject patches. To achieve this, we first introduce a key-point truncated-balanced sampling strategy to facilitate accurate learning from the image database of limited size. Then, we design a cue-aware deep regression network, where we propose to employ the contextual cue, i.e., the scale-adaptive local similarity, to more apparently guide the learning process. The deep regression network is aware of the contextual cue for accurate prediction of local deformation. Results and Conclusion: Our experiments show that the proposed method can tackle various registration tasks on different databases, giving consistent good performance without the need of manual parameter tuning, which could be applicable to various clinical applications.","","","10.1109/TBME.2018.2822826","NIH; National Key Research and Development Program of China; National Natural Science Foundation of China; Science and Technology Commission of Shanghai Municipality; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8331111","Deformable registration;deep learning;nonlinear regression;key-points sampling","Strain;Task analysis;Databases;Machine learning;Image registration;Tuning;Training","diseases;image registration;image segmentation;learning (artificial intelligence);medical image processing;regression analysis","deformable registration method;scale-adaptive local similarity;learning process;local deformation;contextual cue;image database;deformable registration algorithms;cue-aware deep regression network;deformable image registration","","2","56","","","","","IEEE","IEEE Journals"
"Depth Estimation From a Single Image Using Deep Learned Phase Coded Mask","H. Haim; S. Elmalem; R. Giryes; A. M. Bronstein; E. Marom","Faculty of Electrical Engineering, Tel Aviv University, Tel Aviv, Israel; Faculty of Electrical Engineering, Tel Aviv University, Tel Aviv, Israel; Faculty of Electrical Engineering, Tel Aviv University, Tel Aviv, Israel; Faculty of Electrical Engineering, Tel Aviv University, Tel Aviv, Israel; Faculty of Electrical Engineering, Tel Aviv University, Tel Aviv, Israel","IEEE Transactions on Computational Imaging","","2018","4","3","298","310","Depth estimation from a single image is a well-known challenge in computer vision. With the advent of deep learning, several approaches for monocular depth estimation have been proposed, all of which have inherent limitations due to the scarce depth cues that exist in a single image. Moreover, these methods are very demanding computationally, which makes them inadequate for systems with limited processing power. In this paper, a phase-coded aperture camera for depth estimation is proposed. The camera is equipped with an optical phase mask that provides unambiguous depth-related color characteristics for the captured image. These are used for estimating the scene depth map using a fully convolutional neural network. The phase-coded aperture structure is learned jointly with the network weights using backpropagation. The strong depth cues (encoded in the image by the phase mask, designed together with the network weights) allow a much simpler neural network architecture for faster and more accurate depth estimation. Performance achieved on simulated images as well as on a real optical setup is superior to the state-of-the-art monocular depth estimation methods (both with respect to the depth accuracy and required processing power), and is competitive with more complex and expensive depth estimation methods such as light-field cameras.","","","10.1109/TCI.2018.2849326","NVIDIA's; ERC-StG SPADE; ERC-StG RAPID; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8389203","Coded aperture;phase mask;depth reconstruction;deep learning;computational camera","Estimation;Apertures;Cameras;Optical imaging;Computer architecture;Image color analysis","backpropagation;computer vision;image coding;image colour analysis;image resolution;learning (artificial intelligence);neural nets","optical phase mask;unambiguous depth-related color characteristics;scene depth map;phase-coded aperture structure;more accurate depth estimation;complex depth estimation methods;deep learned phase coded mask;phase-coded aperture camera;monocular depth estimation methods","","2","31","","","","","IEEE","IEEE Journals"
"Deep Learning for Massive MIMO CSI Feedback","C. Wen; W. Shih; S. Jin","Institute of Communications Engineering, National Sun Yat-sen University, Kaohsiung, Taiwan; Institute of Communications Engineering, National Sun Yat-sen University, Kaohsiung, Taiwan; National Mobile Communications Research Laboratory, Southeast University, Nanjing, China","IEEE Wireless Communications Letters","","2018","7","5","748","751","In frequency division duplex mode, the downlink channel state information (CSI) should be sent to the base station through feedback links so that the potential gains of a massive multiple-input multiple-output can be exhibited. However, such a transmission is hindered by excessive feedback overhead. In this letter, we use deep learning technology to develop CsiNet, a novel CSI sensing and recovery mechanism that learns to effectively use channel structure from training samples. CsiNet learns a transformation from CSI to a near-optimal number of representations (or codewords) and an inverse transformation from codewords to CSI. We perform experiments to demonstrate that CsiNet can recover CSI with significantly improved reconstruction quality compared with existing compressive sensing (CS)-based methods. Even at excessively low compression regions where CS-based methods cannot work, CsiNet retains effective beamforming gain.","","","10.1109/LWC.2018.2818160","Ministry of Science and Technology, Taiwan; ITRI, Hsinchu, Taiwan; National Science Foundation for Distinguished Young Scholars of China; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8322184","Massive MIMO;FDD;compressed sensing;deep learning;conventional neural network","MIMO communication;Decoding;Image reconstruction;Training;Wireless communication;Discrete Fourier transforms;Machine learning","array signal processing;channel estimation;compressed sensing;feedback;inverse transforms;MIMO communication;wireless channels","massive MIMO CSI feedback;frequency division duplex mode;downlink channel state information;feedback links;massive multiple-input multiple-output;excessive feedback overhead;deep learning technology;CsiNet;recovery mechanism;CS-based methods;effective beamforming gain","","55","17","","","","","IEEE","IEEE Journals"
"UV-flashover evaluation of porcelain insulators based on deep learning","S. Pei; Y. Liu; X. Ji; J. Geng; G. Zhou; S. Wang","North China Electric Power University, People's Republic of China; North China Electric Power University, People's Republic of China; North China Electric Power University, People's Republic of China; North China Electric Power University, People's Republic of China; North China Electric Power University, People's Republic of China; North China Electric Power University, People's Republic of China","IET Science, Measurement & Technology","","2018","12","6","770","776","Based on the analysis of the principle and structure of the convolutional neural network (CNN) model in a deep learning theory system, an intelligent method for judging the flashover of a porcelain insulator with ultraviolet discharge is proposed. In this method, the porcelain insulator chip was subjected to power frequency flashover testing, and the ultraviolet spectra of different discharge states without discharge, weak coronal discharge, and strong spark discharge were captured by FILIN UV imager. The Alexnet deep convolution neural network model was used to predict the discharge state of the UV spectrum for classification training and identification assessment. The new method doesn't use UV imaging to detect flashover warnings. It is necessary to extract the characteristics of the UV spectra and leakage current parameters manually. The multi-layer combination of UV imaging method with end-to-end autonomous learning with deep learning training and the adopted test method provided classification identification, through a large number of UV images in the deep CNN training. This allowed flashover evaluation of abstract feature parameters of the independent extraction. The results show that this method has the advantages of high accuracy, and provides a new idea for the intelligent detection of UV flashover.","","","10.1049/iet-smt.2017.0465","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8437070","","","charge measurement;computerised instrumentation;corona;electric current measurement;flashover;image classification;leakage currents;learning (artificial intelligence);neural nets;porcelain insulators;power engineering computing;sparks;ultraviolet spectra","intelligent detection;end-to-end autonomous learning;multilayer combination;leakage current parameter;flashover warning detection;identification assessment;classification training;modified Alexnet deep CNN model;FILIN UV imaging method;spark discharge;weak coronal discharge;ultraviolet spectra;power frequency flashover testing;porcelain insulator chip;ultraviolet discharge;intelligent method;deep learning theory system;convolutional neural network model;UV-flashover evaluation","","","19","","","","","IET","IET Journals"
"Deep Blur Mapping: Exploiting High-Level Semantics by Deep Neural Networks","K. Ma; H. Fu; T. Liu; Z. Wang; D. Tao","Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, Canada; UBTECH Sydney Artificial Intelligence Centre, School of Information Technologies, Faculty of Engineering and Information Technologies, The University of Sydney, Sydney, NSW, Australia; UBTECH Sydney Artificial Intelligence Centre, School of Information Technologies, Faculty of Engineering and Information Technologies, The University of Sydney, Sydney, NSW, Australia; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, Canada; UBTECH Sydney Artificial Intelligence Centre, School of Information Technologies, Faculty of Engineering and Information Technologies, The University of Sydney, Sydney, NSW, Australia","IEEE Transactions on Image Processing","","2018","27","10","5155","5166","The human visual system excels at detecting the local blur of visual images, but the underlying mechanism is not well understood. Traditional views of blur such as the reduction in energy at high frequencies and loss of phase coherence at localized features have fundamental limitations. For example, they cannot well discriminate flat regions from blurred ones. Here, we propose that the high-level semantic information is critical in successfully identifying the local blur. Therefore, we resort to deep neural networks that are proficient at learning high-level features and propose the first end-to-end local blur mapping algorithm based on a fully convolutional network. By analyzing various architectures with different depths and design philosophies, we empirically show that the high-level features of deeper layers play a more important role than the low-level features of shallower layers in resolving challenging ambiguities for this task. We test the proposed method on a standard blur detection benchmark and demonstrate that it significantly advances the state-of-the-art (ODS F-score of 0.853). Furthermore, we explore the use of the generated blur maps in three applications, including the blur region segmentation, blur degree estimation, and blur magnification.","","","10.1109/TIP.2018.2847421","Natural Sciences and Engineering Research Council of Canada; Australian Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8386849","Local blur mapping;deep neural networks;blur perception","Semantics;Image segmentation;Task analysis;Benchmark testing;Image restoration;Computer architecture;Training","convolutional neural nets;image restoration;image segmentation;learning (artificial intelligence);object detection","deep neural networks;human visual system;visual images;localized features;high-level semantic information;end-to-end local blur mapping algorithm;fully convolutional network;low-level features;standard blur detection benchmark;blur region segmentation;deep blur mapping;high-level semantics;high-level feature learning;blur magnification;blur degree estimation;energy reduction;phase coherence loss;local blur detection","","3","52","","","","","IEEE","IEEE Journals"
"Ghost Numbers","L. Chen; D. Casperson; L. Gao","Wenzhou University (adjunct), Wenzhou, Zhejiang, China; Department of Computer Science, University of Northern British Columbia, BC, Canada; Wenzhou University, Wenzhou, Zhejiang, China","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","10","2538","2539","We comment on a paper describing an algorithm for image set classification. Following the general practice in computer vision research, the performance of the algorithm was evaluated on benchmarks in order to support the claim of its advantage over other algorithms in the literature. We have examined the reported data of experiences on two datasets, and found that many numbers are not a possible answer regardless how the random partitions were selected and regardless how the algorithms performed in each partition. Our finding suggests that the experimental results in the paper (“Deep Reconstruction Models for Image Set Classification”, IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 37, no. 4, pp. 713-727, April 2015) has serious flaws to the extent that all the experimental results should be re-examined.","","","10.1109/TPAMI.2017.2757489","Wenzhou University in China; National Natural Science Foundation of China; Zhejiang Provincial Natural Science Foundation of China; NSERC in Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8052561","Image set classification;deep learning;experiment;ghost number","Machine learning;Machine intelligence;Pattern recognition;Image reconstruction;Training;Algorithm design and analysis;Partitioning algorithms","computer vision;image classification;image reconstruction;learning (artificial intelligence)","image set classification;ghost numbers;computer vision research;random partitions;deep learning","","1","2","","","","","IEEE","IEEE Journals"
"Reformulating Level Sets as Deep Recurrent Neural Network Approach to Semantic Segmentation","T. H. N. Le; K. G. Quach; K. Luu; C. N. Duong; M. Savvides","Department of Electrical and Computer Engineering, CyLab Biometrics Center, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Electrical and Computer Engineering, CyLab Biometrics Center, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Electrical and Computer Engineering, CyLab Biometrics Center, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Electrical and Computer Engineering, CyLab Biometrics Center, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Electrical and Computer Engineering, CyLab Biometrics Center, Carnegie Mellon University, Pittsburgh, PA, USA","IEEE Transactions on Image Processing","","2018","27","5","2393","2407","Variational Level Set (LS) has been a widely used method in medical segmentation. However, it is limited when dealing with multi-instance objects in the real world. In addition, its segmentation results are quite sensitive to initial settings and highly depend on the number of iterations. To address these issues and boost the classic variational LS methods to a new level of the learnable deep learning approaches, we propose a novel definition of contour evolution named Recurrent Level Set (RLS)1 to employ Gated Recurrent Unit under the energy minimization of a variational LS functional. The curve deformation process in RLS is formed as a hidden state evolution procedure and updated by minimizing an energy functional composed of fitting forces and contour length. By sharing the convolutional features in a fully end-to-end trainable framework, we extend RLS to Contextual RLS (CRLS) to address semantic segmentation in the wild. The experimental results have shown that our proposed RLS improves both computational time and segmentation accuracy against the classic variational LS-based method whereas the fully end-to-end system CRLS achieves competitive performance compared to the state-of-the-art semantic segmentation approaches.","","","10.1109/TIP.2018.2794205","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8259369","Level set;deep learning;recurrent neuron network;semantic segmentation","Image segmentation;Semantics;Logic gates;Level set;Machine learning;Active contours;Recurrent neural networks","image segmentation;learning (artificial intelligence);least squares approximations;medical image processing;recurrent neural nets","segmentation accuracy;end-to-end system CRLS;semantic segmentation approaches;Level sets;deep Recurrent neural network approach;Variational Level Set;medical segmentation;multiinstance objects;classic variational LS methods;learnable deep learning approaches;contour evolution;Recurrent Level Set;Gated Recurrent Unit;energy minimization;variational LS functional;curve deformation process;hidden state evolution procedure;energy functional;end-to-end trainable framework;Contextual RLS","","3","79","","","","","IEEE","IEEE Journals"
"Visual Saliency Prediction Using a Mixture of Deep Neural Networks","S. F. Dodge; L. J. Karam","Image, Video and Usability Laboratory, School of Electrical, Computer and Energy Engineering, Arizona State University, Tempe, AZ, USA; Image, Video and Usability Laboratory, School of Electrical, Computer and Energy Engineering, Arizona State University, Tempe, AZ, USA","IEEE Transactions on Image Processing","","2018","27","8","4080","4090","Visual saliency models have recently begun to incorporate deep learning to achieve predictive capacity much greater than previous unsupervised methods. However, most existing models predict saliency without explicit knowledge of global scene semantic information. We propose a model (MxSalNet) that incorporates global scene semantic information in addition to local information gathered by a convolutional neural network. Our model is formulated as a mixture of experts. Each expert network is trained to predict saliency for a set of closely related images. The final saliency map is computed as a weighted mixture of the expert networks' output, with weights determined by a separate gating network. This gating network is guided by global scene information to predict weights. The expert networks and the gating network are trained simultaneously in an end-to-end manner. We show that our mixture formulation leads to improvement in performance over an otherwise identical non-mixture model that does not incorporate global scene information. Additionally, we show that our model achieves better performance than several other visual saliency models.","","","10.1109/TIP.2018.2834826","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8356626","Visual attention;human visual system;saliency map;deep learning","Computational modeling;Biological system modeling;Adaptation models;Visualization;Predictive models;Context modeling;Machine learning","computer vision;convolution;feedforward neural nets;learning (artificial intelligence)","unsupervised methods;semantic information;saliency map;separate gating network;weighted mixture;convolutional neural network;deep learning;visual saliency models;deep neural networks","","4","54","","","","","IEEE","IEEE Journals"
"Semi-supervised Deep Domain Adaptation via Coupled Neural Networks","Z. Ding; N. M. Nasrabadi; Y. Fu","Department of Electrical and Computer Engineering, Northeastern University, Boston, MA, USA; Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, WV, USA; Department of Electrical and Computer Engineering, College of Computer and Information Science, Northeastern University, Boston, MA, USA","IEEE Transactions on Image Processing","","2018","27","11","5214","5224","Domain adaptation is a promising technique when addressing limited or no labeled target data by borrowing well-labeled knowledge from the auxiliary source data. Recently, researchers have exploited multi-layer structures for discriminative feature learning to reduce the domain discrepancy. However, there are limited research efforts on simultaneously building a deep structure and a discriminative classifier over both labeled source and unlabeled target. In this paper, we propose a semi-supervised deep domain adaptation framework, in which the multi-layer feature extractor and a multi-class classifier are jointly learned to benefit from each other. Specifically, we develop a novel semi-supervised class-wise adaptation manner to fight off the conditional distribution mismatch between two domains by assigning a probabilistic label to each target sample, i.e., multiple class labels with different probabilities. Furthermore, a multi-class classifier is simultaneously trained on labeled source and unlabeled target samples in a semi-supervised fashion. In this way, the deep structure can formally alleviate the domain divergence and enhance the feature transferability. Experimental evaluations on several standard cross-domain benchmarks verify the superiority of our proposed approach.","","","10.1109/TIP.2018.2851067","National Science Foundation; Office of Naval Research; Army Research Office; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8398464","Domain adaptation;semi-supervised learning;deep neural networks","Adaptation models;Neural networks;Feature extraction;Computer architecture;Training;Task analysis;Machine learning","feature extraction;learning (artificial intelligence);neural nets;pattern classification;probability","feature transferability;standard cross-domain benchmarks;coupled neural networks;labeled target data;auxiliary source data;multilayer structures;discriminative feature;domain discrepancy;deep structure;discriminative classifier;semisupervised deep domain adaptation framework;multilayer feature extractor;multiclass classifier;novel semisupervised class-wise adaptation manner;probabilistic label;multiple class labels;unlabeled target samples;domain divergence","","10","51","","","","","IEEE","IEEE Journals"
"Multiscale Deep Alternative Neural Network for Large-Scale Video Classification","J. Wang; W. Wang; W. Gao","Department of Electrical and Computer Engineering, Peking University, Beijing, China; Department of Electrical and Computer Engineering, Peking University, Beijing, China; Department of Electrical and Computer Engineering, Peking University, Beijing, China","IEEE Transactions on Multimedia","","2018","20","10","2578","2592","With the rapid increase in the amount of multimedia data, video classification has become a demanding and challenging research topic. Compared with image classification, video classification requires mapping a video that contains hundreds of frames to semantic tags, which poses many challenges to the direct use of advanced models originally designed for image-oriented tasks. On the other hand, continuous frames in a video also give us more visual clues that we can leverage to achieve better classification. One of the most important clues is the context in the spatiotemporal domain. In this paper, we introduce the multiscale deep alternative neural network (DANN), a novel architecture combining the strengths of both convolutional neural network and recurrent neural networks to achieve a deep network that can collect rich context hierarchies for video classification. In particular, the DANN is stacked with alternative layers, each of which consists of a volumetric convolutional layer followed by a recurrent layer. The former acts as a local feature learner, whereas the latter is used to collect contexts. Compared with popular deep feed-forward neural networks, the DANN learns local features and their contexts from the very beginning. This setting enables preserving context evolutions, which we show to be essential for improving the accuracy of video classification. To release the full potential of the DANN, we develop a deeper version with stochastic-layer skip-connections and construct a multiscale DANN to incorporate contexts at different scales. We show how to apply the multiscale DANN for video classification with carefully designed configurations in terms of both input-output settings and training-testing methods. The DANN is shown to be robust to not only human-centric videos, but also natural videos. As there are few large-scale natural disaster video datasets, we construct a new large-scale one and make it publicly available. Experiments on four datasets show the effectiveness of our method for both human actions and natural events.","","","10.1109/TMM.2018.2855081","Shenzhen Peacock Plan; Shenzhen Key Laboratory for Intelligent Multimedia and Virtual Reality; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409973","Video classification;deep alternative neural network;multi-scale deep network;human activity;natural disaster;new dataset","Neural networks;Feature extraction;Three-dimensional displays;Task analysis;Training;Machine learning;Semantics","disasters;feedforward neural nets;image classification;learning (artificial intelligence);recurrent neural nets;video signal processing","image-oriented tasks;stochastic-layer skip-connections;deep network;recurrent neural networks;convolutional neural network;image classification;large-scale video classification;multiscale deep alternative neural network;large-scale natural disaster video datasets;natural videos;human-centric videos;multiscale DANN","","4","92","","","","","IEEE","IEEE Journals"
"Autoencoder With Invertible Functions for Dimension Reduction and Image Reconstruction","Y. Yang; Q. M. J. Wu; Y. Wang","Department of Electrical and Computer Engineering, University of Windsor, Windsor, ON, Canada; Department of Electrical and Computer Engineering, University of Windsor, Windsor, ON, Canada; College of Electrical and Information Engineering, Hunan University, Changsha, China","IEEE Transactions on Systems, Man, and Cybernetics: Systems","","2018","48","7","1065","1079","The extreme learning machine (ELM), which was originally proposed for “generalized” single-hidden layer feedforward neural networks, provides efficient unified learning solutions for the applications of regression and classification. Although, it provides promising performance and robustness and has been used for various applications, the single-layer architecture possibly lacks the effectiveness when applied for natural signals. In order to over come this shortcoming, the following work indicates a new architecture based on multilayer network framework. The significant contribution of this paper are as follows: 1) unlike existing multilayer ELM, in which hidden nodes are obtained randomly, in this paper all hidden layers with invertible functions are calculated by pulling the network output back and putting it into hidden layers. Thus, the feature learning is enriched by additional information, which results in better performance; 2) in contrast to the existing multilayer network methods, which are usually efficient for classification applications, the proposed architecture is implemented for dimension reduction and image reconstruction; and 3) unlike other iterative learning-based deep networks (DL), the hidden layers of the proposed method are obtained via four steps. Therefore, it has much better learning efficiency than DL. Experimental results on 33 datasets indicate that, in comparison to the other existing dimension reduction techniques, the proposed method performs competitively better with fast training speeds.","","","10.1109/TSMC.2016.2637279","Natural Sciences and Engineering Research Council of Canada; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7797236","Autoencoder;deep learning (DL);dimension reduction;extreme learning machine (ELM);feature selection;generalization performance","Nonhomogeneous media;Encoding;Image reconstruction;Artificial neural networks;Decoding;Training;Learning systems","feature extraction;feedforward neural nets;image reconstruction;iterative methods;learning (artificial intelligence)","hidden layers;feature learning;classification applications;image reconstruction;iterative learning;deep networks;invertible functions;extreme learning machine;regression;multilayer network framework;multilayer ELM;hidden nodes;single-hidden layer feedforward neural networks;dimension reduction techniques;unified learning solutions","","6","90","","","","","IEEE","IEEE Journals"
"Compnet: A New Scheme for Single Image Super Resolution Based on Deep Convolutional Neural Network","A. Esmaeilzehi; M. O. Ahmad; M. N. S. Swamy","Department of Electrical and Computer Engineering, Concordia University, Montreal, Canada; Department of Electrical and Computer Engineering, Concordia University, Montreal, Canada; Department of Electrical and Computer Engineering, Concordia University, Montreal, Canada","IEEE Access","","2018","6","","59963","59974","The features produced by the layers of a neural network become increasingly more sparse as the network gets deeper and consequently, the learning capability of the network is not further enhanced as the number of layers is increased. In this paper, a novel residual deep network, called CompNet, is proposed for the single image super resolution problem without an excessive increase in the network complexity. The idea behind the proposed network is to compose the residual signal that is more representative of the features produced by the different layers of the network and it is not as sparse. The proposed network is experimented on different benchmark datasets and is shown to outperform the state-of-the-art schemes designed to solve the super resolution problem.","","","10.1109/ACCESS.2018.2874442","Natural Sciences and Engineering Research Council of Canada; Regroupment Strategique en Microelectronique du Quebec; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8485283","Image super resolution;residual learning;deep learning","Image resolution;Feature extraction;Image reconstruction;Complexity theory;Convolutional neural networks;Signal resolution","convolutional neural nets;image resolution;learning (artificial intelligence)","single image super resolution problem;network complexity;residual signal;deep convolutional neural network;learning capability;novel residual deep network;CompNet;benchmark datasets","","4","46","","","","","IEEE","IEEE Journals"
"SNR-Invariant Multitask Deep Neural Networks for Robust Speaker Verification","Q. Yao; M. Mak","Department of Electronic and Information Engineering, The Hong Kong Polytechnic University, Hong Kong; Department of Electronic and Information Engineering, The Hong Kong Polytechnic University, Hong Kong","IEEE Signal Processing Letters","","2018","25","11","1670","1674","A major challenge in speaker verification is to achieve low error rates under noisy environments. We observed that background noise in utterances will not only enlarge the speaker-dependent i-vector clusters but also shift the clusters, with the amount of shift depending on the signal-to-noise ratio (SNR) of the utterances. To overcome this SNR-dependent clustering phenomenon, we propose two deep neural network (DNN) architectures: hierarchical regression DNN (H-RDNN) and multitask DNN (MT-DNN). The H-RDNN is formed by stacking two regression DNNs in which the lower DNN is trained to map noisy i-vectors to their respective speaker-dependent cluster means of clean i-vectors and the upper DNN aims to regularize the outliers that cannot be denoised properly by the lower DNN. The MT-DNN is trained to denoise i-vectors (main task) and classify speakers (auxiliary task). The network leverages the auxiliary task to retain speaker information in the denoised i-vectors. Experimental results suggest that these two DNN architectures together with the PLDA backend significantly outperform the multicondition PLDA model and mixtures of PLDA, and that multitask learning helps to boost verification performance.","","","10.1109/LSP.2018.2870726","RGC of Hong Kong; HKPolyU; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8466600","Deep learning;${i}$-vectors;multitask learning;noise robustness;speaker verification","Task analysis;Signal to noise ratio;Noise measurement;Training;Noise reduction;Neural networks;Production facilities","learning (artificial intelligence);neural net architecture;pattern clustering;regression analysis;signal classification;signal denoising;speaker recognition","multitask learning;verification performance;SNR-invariant multitask deep neural networks;robust speaker verification;low error rates;noisy environments;background noise;speaker-dependent i-vector clusters;signal-to-noise ratio;SNR-dependent clustering phenomenon;deep neural network architectures;H-RDNN;MT-DNN;map noisy i-vectors;speaker information;DNN architectures;speaker-dependent cluster;speakers classification;hierarchical regression DNN;denoised i-vectors","","1","28","","","","","IEEE","IEEE Journals"
"DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs","L. Chen; G. Papandreou; I. Kokkinos; K. Murphy; A. L. Yuille","Google Inc., Mountain View, CA; Google Inc., Mountain View, CA; University College London, London, UK; Google Inc., Mountain View, CA; Departments of Cognitive Science and Computer Science, Johns Hopkins University, Baltimore, MD","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","4","834","848","In this work we address the task of semantic image segmentation with Deep Learning and make three main contributions that are experimentally shown to have substantial practical merit. First, we highlight convolution with upsampled filters, or `atrous convolution', as a powerful tool in dense prediction tasks. Atrous convolution allows us to explicitly control the resolution at which feature responses are computed within Deep Convolutional Neural Networks. It also allows us to effectively enlarge the field of view of filters to incorporate larger context without increasing the number of parameters or the amount of computation. Second, we propose atrous spatial pyramid pooling (ASPP) to robustly segment objects at multiple scales. ASPP probes an incoming convolutional feature layer with filters at multiple sampling rates and effective fields-of-views, thus capturing objects as well as image context at multiple scales. Third, we improve the localization of object boundaries by combining methods from DCNNs and probabilistic graphical models. The commonly deployed combination of max-pooling and downsampling in DCNNs achieves invariance but has a toll on localization accuracy. We overcome this by combining the responses at the final DCNN layer with a fully connected Conditional Random Field (CRF), which is shown both qualitatively and quantitatively to improve localization performance. Our proposed “DeepLab” system sets the new state-of-art at the PASCAL VOC-2012 semantic image segmentation task, reaching 79.7 percent mIOU in the test set, and advances the results on three other datasets: PASCAL-Context, PASCAL-Person-Part, and Cityscapes. All of our code is made publicly available online.","","","10.1109/TPAMI.2017.2699184","ARO 62250-CS; FP7-RECONFIG; FP7-MOBOT; H2020-ISUPPORT EU; NVIDIA Corporation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7913730","Convolutional neural networks;semantic segmentation;atrous convolution;conditional random fields","Convolution;Image segmentation;Semantics;Image resolution;Computational modeling;Neural networks;Context","convolution;feature extraction;feedforward neural nets;image segmentation;learning (artificial intelligence);random processes","highlight convolution;atrous convolution;Deep Convolutional Neural Networks;atrous spatial pyramid pooling;image context;fully connected Conditional Random Field;PASCAL VOC-2012 semantic image segmentation task;deep convolutional nets;Deep Learning;DeepLab;semantic image segmentation;probabilistic graphical models","","530","102","","","","","IEEE","IEEE Journals"
"Detecting Abnormal Ozone Measurements With a Deep Learning-Based Strategy","F. Harrou; A. Dairi; Y. Sun; F. Kadri","Computer, Electrical and Mathematical Sciences and Engineering Division, King Abdullah University of Science and Technology, Thuwal, Saudi Arabia; Computer Science Department, University of Oran 1 Ahmed Ben Bella, Oran, Algeria; Computer, Electrical and Mathematical Sciences and Engineering Division, King Abdullah University of Science and Technology, Thuwal, Saudi Arabia; Big Data and Data Analytics Team, Sopra Steria Group, Colomiers, France","IEEE Sensors Journal","","2018","18","17","7222","7232","Air quality management and monitoring are vital to maintaining clean air, which is necessary for the health of human, vegetation, and ecosystems. Ozone pollution is one of the main pollutants that negatively affect human health and ecosystems. This paper reports the development of an unsupervised and efficient scheme to detecting anomalies in unlabeled ozone measurements. This scheme combines a deep belief networks (DBNs) model and a one-class support vector machine (OCSVM). The DBN model accounts for nonlinear variations in the ground-level ozone concentrations, while OCSVM detects the abnormal ozone measurements. The performance of this approach is evaluated using real data from Isère in France. We also compare the detection quality of DBN-based detection schemes to that of deep stacked auto-encoders, restricted Boltzmann machines-based OCSVM, and DBN-based clustering procedures (i.e., K-means, Birch, and expectation-maximization). The results show that the developed strategy is able to identify anomalies in ozone measurements.","","","10.1109/JSEN.2018.2852001","King Abdullah University of Science and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8401490","Air quality;learning;OCSVM;ozone;DBNs;statistical monitoring;anomaly detection","Gases;Pollution measurement;Data models;Monitoring;Feature extraction;Sensors;Air quality","air pollution;atmospheric composition;belief networks;Boltzmann machines;environmental science computing;expectation-maximisation algorithm;learning (artificial intelligence);ozone;pattern clustering;support vector machines","deep learning-based strategy;clean air;ozone pollution;unsupervised scheme;unlabeled ozone measurements;one-class support vector machine;ground-level ozone concentrations;detection quality;DBN-based detection schemes;deep stacked auto-encoders;restricted Boltzmann machines-based OCSVM;DBN-based clustering procedures;air quality monitoring;deep belief network model;abnormal ozone measurement detection;air quality management;Isère;France;K-means clustering;Birch clustering;expectation-maximization clustering","","","40","","","","","IEEE","IEEE Journals"
"Regional Detection of Traffic Congestion Using in a Large-Scale Surveillance System via Deep Residual TrafficNet","P. Wang; W. Hao; Z. Sun; S. Wang; E. Tan; L. Li; Y. Jin","Institute for Transportation Systems Engineering Research, Chang’an University, Xi’an, China; Institute for Transportation Systems Engineering Research, Chang’an University, Xi’an, China; Institute for Transportation Systems Engineering Research, Chang’an University, Xi’an, China; Institute for Transportation Systems Engineering Research, Chang’an University, Xi’an, China; Institute for Transportation Systems Engineering Research, Chang’an University, Xi’an, China; Institute for Transportation Systems Engineering Research, Chang’an University, Xi’an, China; Institute for Transportation Systems Engineering Research, Chang’an University, Xi’an, China","IEEE Access","","2018","6","","68910","68919","Despite the huge amount of traffic surveillance videos and images have been accumulated in the daily monitoring, deep learning approaches have been underutilized in the application of traffic intelligent management and control. In this paper, traffic images, including various illumination, weather conditions, and vast scenarios, are extracted from the current surveillance system using in Shaanxi Province and preprocessed to set up a proper training dataset. In order to detect traffic congestion, a network structure is proposed based on residual learning to be pre-trained and fine-tuned. The network is then transferred to the traffic application and re-trained with self-established training dataset to generate the TrafficNet. The accuracy of TrafficNet to classify congested and uncongested road states reaches 99% for the validation dataset and 95% for the testing dataset. The proposed TrafficNet are verified by a regional detection of traffic congestion on a large-scale surveillance system currently using in China. The effectiveness and efficiencies are magnificently demonstrated with quick detection in the high accuracy in the case study. The experimental trial could extend its successful application to traffic surveillance system and has potential enhancement for intelligent transport system in future.","","","10.1109/ACCESS.2018.2879809","National Natural Science Foundation of China; Xi’an Intelligent Freeway Information Fusion and Control Key Laboratory; China Postdoctoral Science Foundation; Key Research and Development Program of Shaanxi Province; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8532117","Congestion;deep learning;freeway;residual network;traffic surveillance system","Traffic control;Surveillance;Traffic congestion;Videos;Training;Cameras","feature extraction;image classification;learning (artificial intelligence);neural nets;road traffic;traffic engineering computing;video surveillance","traffic surveillance system;intelligent transport system;deep residual TrafficNet;traffic surveillance videos;traffic intelligent management;residual learning;deep learning;traffic surveillance images;regional traffic congestion detection;Shaanxi Province;congested road state classification;China","","4","33","","","","","IEEE","IEEE Journals"
"Learning in Memristor Crossbar-Based Spiking Neural Networks Through Modulation of Weight-Dependent Spike-Timing-Dependent Plasticity","N. Zheng; P. Mazumder","University of Michigan, Ann Arbor, MI, USA; University of Michigan, Ann Arbor, MI, USA","IEEE Transactions on Nanotechnology","","2018","17","3","520","532","In this paper, we propose a methodology to design learning systems based on a memristor crossbar structure. Learning is carried out with the help of a hardware-friendly spike-timing-dependent plasticity learning rule. Several simplifications and adaptations are made in order to apply the learning algorithm to memristor-based neural networks. The difficulties in conducting division and representing signed weights are circumvented using the proposed techniques. In addition, different conductance-changing behaviors are considered to demonstrate the effectiveness of the proposed algorithm and architecture when applied to practical memristor devices. Furthermore, various nonidealities existing in the neural network, including variations in CMOS neurons and memristor synapses and noises associated with updating the synaptic weights, are considered. We demonstrate that the proposed learning algorithm and hardware architecture are robust against most variations and noises. This robustness of learning is promising, as variations and stochastic behaviors of memristor devices are usually substantial. Memristor-based neural networks with the proposed learning algorithm are benchmarked with the MNIST handwritten digits recognition task. A recognition accuracy as high as 97.10% is demonstrated.","","","10.1109/TNANO.2018.2821131","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8328902","Memristor;crossbar;supervised learning;machine learning;neuromorphic computing;spiking neural network;deep learning;hardware neural network;spike-timing-dependent plasticity;MNIST benchmark","Memristors;Biological neural networks;Neurons;Synapses;Heuristic algorithms;Hardware;Artificial neural networks","handwritten character recognition;learning (artificial intelligence);memristors;neural nets","learning systems;memristor crossbar structure;learning algorithm;memristor synapses;synaptic weights;spiking neural network;signed weights;conductance-changing behaviors;weight-dependent spike-timing-dependent plasticity learning rule;MNIST handwritten digit recognition task","","5","33","","","","","IEEE","IEEE Journals"
"Value-based deep reinforcement learning for adaptive isolated intersection signal control","C. Wan; M. Hwang","China Engineering Consultants, Inc., Taiwan; China Engineering Consultants, Inc., Taiwan","IET Intelligent Transport Systems","","2018","12","9","1005","1010","Under efficiency improvement of road networks by utilizing advanced traffic signal control methods, intelligent transportation systems intend to characterize a smart city. Recently, due to significant progress in artificial intelligence, machine learning-based framework of adaptive traffic signal control has been highly concentrated. In particular, deep Q-learning neural network is a model-free technique and can be applied to optimal action selection problems. However, setting variable green time is a key mechanism to reflect traffic fluctuations such that time steps need not be fixed intervals in reinforcement learning framework. In this study, the authors proposed a dynamic discount factor embedded in the iterative Bellman equation to prevent from a biased estimation of action-value function due to the effects of inconstant time step interval. Moreover, action is added to the input layer of the neural network in the training process, and the output layer is the estimated action-value for the denoted action. Then, the trained neural network can be used to generate action that leads to an optimal estimated value within a finite set as the agents' policy. The preliminary results show that the trained agent outperforms a fixed timing plan in all testing cases with reducing system total delay by 20%..","","","10.1049/iet-its.2018.5170","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8490349","","","dynamic programming;iterative methods;learning (artificial intelligence);neural nets;road traffic;traffic engineering computing","value-based deep reinforcement learning;adaptive isolated intersection signal control;road network efficiency improvement;advanced traffic signal control methods;intelligent transportation systems;smart city;modern city;artificial intelligence;machine learning-based framework;deep Q-learning neural network;model-free technique;optimal discrete-time action selection problems;variable green time;traffic fluctuations;dynamic discount factor;iterative Bellman equation;biased action-value function estimation;VISSIM software;traffic arrival rates;traffic arrival patterns","","2","22","","","","","IET","IET Journals"
"Use of Deep Learning for Characterization of Microfluidic Soft Sensors","S. Han; T. Kim; D. Kim; Y. Park; S. Jo","School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Department of Mechanical and Aerospace Engineering and the Institute of Advanced Machines and Design, Seoul National University, Seoul, South Korea; School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Department of Mechanical and Aerospace Engineering and the Institute of Advanced Machines and Design, Seoul National University, Seoul, South Korea; School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, South Korea","IEEE Robotics and Automation Letters","","2018","3","2","873","880","Soft sensors made of highly deformable materials are one of the enabling technologies to various soft robotic systems, such as soft mobile robots, soft wearable robots, and soft grippers. However, major drawbacks of soft sensors compared with traditional sensors are their nonlinearity and hysteresis in response, which are common especially in microfluidic soft sensors. In this research, we propose to address the above issues of soft sensors by taking advantage of deep learning. We implemented a hierarchical recurrent sensing network, a type of recurrent neural network model, to the calibration of soft sensors for estimating the magnitude and the location of a contact pressure simultaneously. The proposed approach in this letter is not only able to model the nonlinear characteristic with hysteresis of the pressure response, but also find the location of the pressure.","","","10.1109/LRA.2018.2792684","National Research Foundation of Korea; Korean Government (MSIT); Institute for Information and Communications Technology Promotion; MSIT; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8255560","Soft material robotics;deep learning in robotics and automation;force and tactile sensing","Sensor phenomena and characterization;Robot sensing systems;Microchannels;Hysteresis;Liquids","grippers;learning (artificial intelligence);microfluidics;microsensors;mobile robots;motion control;pneumatic actuators;pressure sensors;recurrent neural nets","soft grippers;microfluidic soft sensors;deep learning;soft mobile robots;soft wearable robots;hierarchical recurrent sensing network;recurrent neural network model;contact pressure;nonlinear characteristic;pressure response","","8","25","","","","","IEEE","IEEE Journals"
"DROM: Optimizing the Routing in Software-Defined Networks With Deep Reinforcement Learning","C. Yu; J. Lan; Z. Guo; Y. Hu","National Digital Switching System Engineering and Technological R&D Center, Zhengzhou, China; National Digital Switching System Engineering and Technological R&D Center, Zhengzhou, China; University of Minnesota Twin Cities, Minneapolis, MN, USA; National Digital Switching System Engineering and Technological R&D Center, Zhengzhou, China","IEEE Access","","2018","6","","64533","64539","This paper proposes DROM, a deep reinforcement learning mechanism for Software-Defined Networks (SDN) to achieve a universal and customizable routing optimization. DROM simplifies the network operation and maintenance by improving the network performance, such as delay and throughput, with a black-box optimization in continuous time. We evaluate the DROM with experiments. The experimental results show that DROM has the good convergence and effectiveness and provides better routing configurations than existing solutions to improve the network performance, such as reducing the delay and improving the throughput.","","","10.1109/ACCESS.2018.2877686","National Natural Science Foundation of China for Innovative Research Groups; National Natural Science Foundation of China; National High Technology Research and Development Program (863 Program) of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8502806","Deep reinforcement learning;routing optimization;software-defined networking","Routing;Neural networks;Optimization;Heuristic algorithms;Decision making","learning (artificial intelligence);optimisation;software defined networking;telecommunication network routing","DROM;deep reinforcement learning mechanism;universal routing optimization;customizable routing optimization;black-box optimization;routing configurations;software-defined networks;SDN","","5","18","","","","","IEEE","IEEE Journals"
"$M^3\text{Fusion}$: A Deep Learning Architecture for Multiscale Multimodal Multitemporal Satellite Data Fusion","P. Benedetti; D. Ienco; R. Gaetano; K. Ose; R. G. Pensa; S. Dupuy","UMR-TETIS Laboratory, IRSTEA, University of Montpellier, Montpellier, France; LIRMM Laboratory, Montpellier, France; UMR TETIS, CIRAD, Montpellier, France; UMR-TETIS Laboratory, IRSTEA, University of Montpellier, Montpellier, France; Department of Computer Science, University of Turin, Turin, Italy; CIRAD, UMR TETIS, Saint-Pierre, Runion, France","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2018","11","12","4939","4949","Modern Earth Observation systems provide remote sensing data at different temporal and spatial resolutions. Among all the available spatial mission, today the Sentinel-2 program supplies high temporal (every five days) and high spatial resolution (HSR) (10 m) images that can be useful to monitor land cover dynamics. On the other hand, very HSR (VHSR) imagery is still essential to figure out land cover mapping characterized by fine spatial patterns. Understanding how to jointly leverage these complementary sources in an efficient way when dealing with land cover mapping is a current challenge in remote sensing. With the aim of providing land cover mapping through the fusion of multitemporal HSR and VHSR satellite images, we propose a suitable end-to-end deep learning framework, namely M3Fusion, which is able to simultaneously leverage the temporal knowledge contained in time series data as well as the fine spatial information available in VHSR images. Experiments carried out on the Reunion Island study area confirm the quality of our proposal considering both quantitative and qualitative aspects.","","","10.1109/JSTARS.2018.2876357","Agence Nationale de la Recherche; Investments for the Future Program; GEOSUD project; Programme National de Télédétection Spatiale; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8516352","Data fusion;deep learning;land cover mapping;satellite image time series;sentinel-2;very high spatial resolution (VHSR)","Time series analysis;Spatial resolution;Remote sensing;Feature extraction;Satellites","geophysical image processing;image classification;image fusion;learning (artificial intelligence);remote sensing;terrain mapping;time series","Sentinel-2 program supplies high temporal;high spatial resolution images;land cover dynamics;HSR imagery;land cover mapping;fine spatial patterns;suitable end-to-end deep learning framework;temporal knowledge;time series data;fine spatial information;VHSR images;multiscale multimodal multitemporal satellite data Fusion;Modern Earth Observation systems;remote sensing data;different temporal resolutions;spatial resolutions;available spatial mission","","","33","","","","","IEEE","IEEE Journals"
"A Deep Reinforcement Learning-Based Framework for Dynamic Resource Allocation in Multibeam Satellite Systems","X. Hu; S. Liu; R. Chen; W. Wang; C. Wang","School of Electronic Engineering, Beijing University of Posts and Telecommunications, Beijing, China; School of Electronic Engineering, Beijing University of Posts and Telecommunications, Beijing, China; School of Electronic Engineering, Beijing University of Posts and Telecommunications, Beijing, China; School of Electronic Engineering, Beijing University of Posts and Telecommunications, Beijing, China; Beijing R&D Center, 54th Research Institute, China Electronics Technology Group Corporation, Beijing, China","IEEE Communications Letters","","2018","22","8","1612","1615","Dynamic resource allocation (DRA) is the key technology to improve the network performance in resource-limited multibeam satellite (MBS) systems. The aim is to find a policy that maximizes the expected long-term resource utilization. Existing iterative metaheuristics DRA optimization algorithms are not practical due to the high computational complexity. To solve the problem of unknown dynamics and prohibitive computation, a deep reinforcement learning-based framework (DRLF) is proposed for DRA problems in MBS systems. A novel image-like tensor reformulation on the system environments is adopted to extract traffic spatial and temporal features. A use case of dynamic channel allocation in DRLF is simulated and shows the effectiveness of the proposed DRLF in time-varying scenarios.","","","10.1109/LCOMM.2018.2844243","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8372935","Dynamic resource allocation (DRA);deep reinforcement learning (DRL);state reformulation;multibeam satellite (MBS)","Resource management;Satellites;Optimization;Heuristic algorithms;Dynamic scheduling;Tensile stress;Quality of service","channel allocation;computational complexity;iterative methods;learning (artificial intelligence);optimisation;resource allocation;satellite communication;telecommunication computing;tensors","deep reinforcement learning-based framework;dynamic resource allocation;network performance;resource-limited multibeam satellite systems;long-term resource utilization;iterative metaheuristics DRA optimization algorithms;high computational complexity;DRA problems;MBS systems;system environments;dynamic channel allocation;image-like tensor reformulation;time-varying scenarios","","2","10","","","","","IEEE","IEEE Journals"
"A Generic Deep-Learning-Based Approach for Automated Surface Inspection","R. Ren; T. Hung; K. C. Tan","Applied Technology Group, Rolls-Royce Singapore, Singapore; Applied Technology Group, Rolls-Royce Singapore, Singapore; Department of Computer Science, City University of Hong Kong, Hong Kong","IEEE Transactions on Cybernetics","","2018","48","3","929","940","Automated surface inspection (ASI) is a challenging task in industry, as collecting training dataset is usually costly and related methods are highly dataset-dependent. In this paper, a generic approach that requires small training data for ASI is proposed. First, this approach builds classifier on the features of image patches, where the features are transferred from a pretrained deep learning network. Next, pixel-wise prediction is obtained by convolving the trained classifier over input image. An experiment on three public and one industrial data set is carried out. The experiment involves two tasks: 1) image classification and 2) defect segmentation. The results of proposed algorithm are compared against several best benchmarks in literature. In the classification tasks, the proposed method improves accuracy by 0.66%-25.50%. In the segmentation tasks, the proposed method reduces error escape rates by 6.00%-19.00% in three defect types and improves accuracies by 2.29%-9.86% in all seven defect types. In addition, the proposed method achieves 0.0% error escape rate in the segmentation task of industrial data.","","","10.1109/TCYB.2017.2668395","Economic Development Board Industrial Postgraduate Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7864335","Automated surface inspection (ASI);deep learning (DL);feature transferring;segmentation","Feature extraction;Training;Heating;Inspection;Surface morphology;Computer vision;Object recognition","feature extraction;image classification;image segmentation;inspection;learning (artificial intelligence);production engineering computing","generic deep-learning;automated surface inspection;image patches;trained classifier;segmentation task;image classification;defect segmentation","","18","41","","","","","IEEE","IEEE Journals"
"SingleCaffe: An Efficient Framework for Deep Learning on a Single Node","C. Wang; Y. Shen; J. Jia; Y. Lu; Z. Chen; B. Wang","School of Computer Science, National University of Defense Technology, Changsha, China; National Supercomputer Center in Guangzhou, Guangzhou, China; Beijing Special Engineering and Design Institute, Beijing, China; National Supercomputer Center in Guangzhou, Guangzhou, China; National Supercomputer Center in Guangzhou, Guangzhou, China; State Key Laboratory of Mathematical Engineering and Advanced Computing, Zhengzhou, China","IEEE Access","","2018","6","","69660","69671","Deep learning (DL) is currently the most promising approach in complicated applications such as computer vision and natural language processing. It thrives with large neural networks and large datasets. However, larger models and larger datasets result in longer training times that impede research and development progress. The modern high-performance and data-parallel nature of hardware equipped with high computing power, such as GPUs, has triggered the widespread adoption of such hardware in DL frameworks, such as Caffe, Torch, and TensorFlow. However, most DL frameworks cannot make full use of this high-performance hardware, and computational efficiency is low. In this paper, we present SingleCaffe1, a DL framework that can make full use of such hardware and improve the computational efficiency of the training process. SingleCaffe opens up multiple threads to speed up the training process within a single node and adopts data parallelism on multiple threads. During the training process, SingleCaffe selects a thread as a parameter server thread and the other threads as worker threads. Both data and workloads are distributed across worker threads, while the server thread maintains the globally shared parameters. The framework also manages memory allocation carefully to reduce the memory overhead. The experimental results show that SingleCaffe can improve training efficiency well, and the performance on a single node can even achieve the distributed training of a dozen nodes.","","","10.1109/ACCESS.2018.2879877","National Key R&D Program of China; National Natural Science Foundation of China; National Science Foundation of China; Program for Guangdong Introducing Innovative and Entrepreneurial Teams; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8528440","Deep learning;framework;single node;multiple threads;speed up;data parallelism;parameter server","Training;Servers;Message systems;Hardware;Parallel processing;Instruction sets;Computational modeling","learning (artificial intelligence);multi-threading;neural nets;parallel processing;power aware computing;storage management","neural networks;data-parallel nature;high computing power;SingleCaffe1;multiple threads;single node;data parallelism;parameter server thread;distributed training;deep learning","","","45","","","","","IEEE","IEEE Journals"
"Action Detection and Recognition in Continuous Action Streams by Deep Learning-Based Sensing Fusion","N. Dawar; N. Kehtarnavaz","Department of Electrical and Computer Engineering, University of Texas at Dallas, Richardson, TX, USA; Department of Electrical and Computer Engineering, University of Texas at Dallas, Richardson, TX, USA","IEEE Sensors Journal","","2018","18","23","9660","9668","This paper presents a deep learning-based sensing fusion system to detect and recognize actions of interest from continuous action streams, which contain actions of interest occurring continuously and randomly among arbitrary actions of non-interest. The sensors used in the fusion system consist of a depth camera and a wearable inertial sensor. A convolutional neural network is utilized for depth images obtained from the depth sensor, and a combination of convolutional neural network and long short-term memory network is utilized for inertial signals obtained from the inertial sensor. Each sensing modality first performs segmentation of all actions and then detection of actions of interest for a particular application. A decision-level fusion of the two sensing modalities is carried out to achieve the recognition of the detected actions of interest. The developed fusion system is examined for two applications: one involving transition movements for home healthcare monitoring and the other involving smart TV hand gestures. The results obtained show the effectiveness of the developed fusion system in dealing with realistic continuous action streams.","","","10.1109/JSEN.2018.2872862","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8476581","Deep learning-based continuous action detection and recognition;fusion of depth and inertial sensing;action detection and recognition in continuous action streams","Cameras;Gesture recognition;Sensor fusion;Skeleton;Sensor systems;Wearable sensors","cameras;convolution;feedforward neural nets;gesture recognition;image segmentation;image sensors;learning (artificial intelligence);sensor fusion","convolutional neural network;depth sensor;sensing modality;decision-level fusion;realistic continuous action streams;action detection;deep learning-based sensing fusion system;arbitrary actions;depth camera;wearable inertial sensor;long short-term memory network;fusion system;action recognition;home healthcare monitoring;smart TV hand gestures;inertial signals","","3","33","","","","","IEEE","IEEE Journals"
"Phonocardiographic Sensing Using Deep Learning for Abnormal Heartbeat Detection","S. Latif; M. Usman; R. Rana; J. Qadir","Department of Electrical Engineering, Information Technology University (ITU)-Punjab, Lahore, Pakistan; Department of Electrical Engineering, COMSATS Institute of Information Technology, Islamabad, Pakistan; Institute of Resilient Regions, University of Southern Queensland, Springfield, QLD, Australia; Department of Electrical Engineering, Information Technology University (ITU)-Punjab, Lahore, Pakistan","IEEE Sensors Journal","","2018","18","22","9393","9400","Deep learning-based cardiac auscultation is of significant interest to the healthcare community as it can help reducing the burden of manual auscultation with automated detection of abnormal heartbeats. However, the problem of automatic cardiac auscultation is complicated due to the requirement of reliable and highly accurate systems, which are robust to the background noise in the heartbeat sound. In this paper, we propose a Recurrent Neural Networks (RNNs)-based automated cardiac auscultation solution. Our choice of RNNs is motivated by their great success of modeling sequential or temporal data even in the presence of noise. We explore the use of various RNN models, and demonstrate that these models significantly outperform the best reported results in the literature. We also present the run-time complexity of various RNNs, which provides insight about their complexity versus performance trade-offs.","","","10.1109/JSEN.2018.2870759","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8466894","Abnormal heartbeat detection;phonocardiography (PCG) signals;deep learning;recurrent neural networks (RNNs)","Logic gates;Heart beat;Phonocardiography;Recurrent neural networks;Computer architecture;Logistics","cardiology;electrocardiography;health care;learning (artificial intelligence);medical signal detection;medical signal processing;recurrent neural nets","healthcare community;automated detection;automatic cardiac auscultation;heartbeat sound;RNN models;phonocardiographic sensing;abnormal heartbeat detection;deep learning-based cardiac auscultation;recurrent neural networks","","4","45","","","","","IEEE","IEEE Journals"
"Image-Based Learning to Measure Traffic Density Using a Deep Convolutional Neural Network","J. Chung; K. Sohn","Laboratory of Big-data Applications in Public Sectors, Chung-Ang University, Seoul, South Korea; Laboratory of Big-data Applications in Public Sectors, Chung-Ang University, Seoul, South Korea","IEEE Transactions on Intelligent Transportation Systems","","2018","19","5","1670","1675","Existing methodologies to count vehicles from a road image have depended upon both hand-crafted feature engineering and rule-based algorithms. These require many predefined thresholds to detect and track vehicles. This paper provides a supervised learning methodology that requires no such feature engineering. A deep convolutional neural network was devised to count the number of vehicles on a road segment based solely on video images. The present methodology does not regard an individual vehicle as an object to be detected separately; rather, it collectively counts the number of vehicles as a human would. The test results show that the proposed methodology outperforms existing schemes.","","","10.1109/TITS.2017.2732029","Chung-Ang University Research Scholarship; National Research Council of Science and Technology Grant by the Korea Government (MSIP); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8011496","Deep convolutional neural network (CNN);machine learning;traffic density;vehicle counting","Training;Feature extraction;Neural networks;Density measurement;Computational modeling;Roads;Detectors","feedforward neural nets;learning (artificial intelligence);object detection;object tracking;road traffic;road vehicles;traffic engineering computing","deep convolutional neural network;road image;supervised learning methodology;road segment;video images;traffic density measurement;vehicle counting;road vehicles;vehicle detection;vehicle tracking","","4","27","","","","","IEEE","IEEE Journals"
"Deep Learning Based Improved Classification System for Designing Tomato Harvesting Robot","L. Zhang; J. Jia; G. Gui; X. Hao; W. Gao; M. Wang","College of Information and Electrical Engineering, China Agricultural University, Beijing, China; National Rural Technology Development Center, Ministry of Science and Technology, Beijing, China; Nanjing University of Posts and Telecommunications, Nanjing, China; College of Information and Electrical Engineering, China Agricultural University, Beijing, China; College of Information and Electrical Engineering, China Agricultural University, Beijing, China; College of Information and Electrical Engineering, China Agricultural University, Beijing, China","IEEE Access","","2018","6","","67940","67950","Maturity level-based classification system plays an essential role in the design of tomato harvesting robot. Traditional knowledge-based systems are unable to meet the current production management requirements of precision picking, because they are time-consuming and have low accuracy. Our research proposes an improved deep learning-based classification method that improves the accuracy and scalability of tomato ripeness with a small amount of training data. This study was on the relationship between different dataset augmentation methods and prediction results of final classification task. We implemented classification systems based on convolutional neural network (CNN), by training and validating the model on different augmented datasets and tried to choose an optimal augmentation method for datasets. The experimental results showed an average accuracy of 91.9% with a less than 0.01-s prediction time. Compared to the existing methods, our solution achieved better prediction results both in terms of accuracy and time consumption. Moreover, this is a versatile method and can be extended to other related fields.","","","10.1109/ACCESS.2018.2879324","Ministry of Education of the People's Republic of China; China Postdoctoral Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8520836","Convolutional neural network;classification;data augmentation;tomato harvesting robot;deep learning","Robots;Task analysis;Image color analysis;Training;Convolutional neural networks;Machine vision","agricultural machinery;convolutional neural nets;crops;industrial robots;learning (artificial intelligence);neurocontrollers;pattern classification;production management","tomato harvesting robot;maturity level-based classification system;precision picking;tomato ripeness;classification systems;optimal augmentation method;augmented datasets;dataset augmentation methods;deep learning-based classification method;production management requirements;convolutional neural network","","4","39","","","","","IEEE","IEEE Journals"
"Deep Neural Networks for No-Reference and Full-Reference Image Quality Assessment","S. Bosse; D. Maniry; K. Müller; T. Wiegand; W. Samek","Department of Video Coding and Analytics, Fraunhofer Heinrich Hertz Institute, Berlin, Germany; Department of Video Coding and Analytics, Fraunhofer Heinrich Hertz Institute, Berlin, Germany; Machine Learning Laboratory, Berlin Institute of Technology, Berlin, Germany; Fraunhofer Heinrich Hertz Institute, Berlin, Germany; Department of Video Coding and Analytics, Fraunhofer Heinrich Hertz Institute, Berlin, Germany","IEEE Transactions on Image Processing","","2018","27","1","206","219","We present a deep neural network-based approach to image quality assessment (IQA). The network is trained end-to-end and comprises ten convolutional layers and five pooling layers for feature extraction, and two fully connected layers for regression, which makes it significantly deeper than related IQA models. Unique features of the proposed architecture are that: 1) with slight adaptations it can be used in a no-reference (NR) as well as in a full-reference (FR) IQA setting and 2) it allows for joint learning of local quality and local weights, i.e., relative importance of local quality to the global quality estimate, in an unified framework. Our approach is purely data-driven and does not rely on hand-crafted features or other types of prior domain knowledge about the human visual system or image statistics. We evaluate the proposed approach on the LIVE, CISQ, and TID2013 databases as well as the LIVE In the wild image quality challenge database and show superior performance to state-of-the-art NR and FR IQA methods. Finally, cross-database evaluation shows a high ability to generalize between different databases, indicating a high robustness of the learned features.","","","10.1109/TIP.2017.2760518","German Ministry for Education and Research as Berlin Big Data Center; Institute for Information and Communications Technology Promotion through the Korea Government; DFG; National Research Foundation of Korea through the Ministry of Education, Science, and Technology in the BK21 Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8063957","Full-reference image quality assessment;no-reference image quality assessment;neural networks;quality pooling;deep learning;feature extraction;regression","Feature extraction;Image quality;Distortion;Databases;Optimization;Computational modeling","feature extraction;image colour analysis;learning (artificial intelligence);neural nets;regression analysis;visual databases","deep neural network;full-reference image quality assessment;convolutional layers;pooling layers;feature extraction;fully connected layers;related IQA models;unique features;full-reference IQA setting;local quality;local weights;global quality estimate;hand-crafted features;human visual system;wild image quality challenge database;FR IQA methods;learned features;no-reference image quality assessment;NR IQA setting;image statistics;cross-database evaluation","","55","52","CCBY","","","","IEEE","IEEE Journals"
"Improving Transfer Learning and Squeeze- and-Excitation Networks for Small-Scale Fine-Grained Fish Image Classification","C. Qiu; S. Zhang; C. Wang; Z. Yu; H. Zheng; B. Zheng","Department of Electronic Engineering, College of Information Science and Engineering, Ocean University of China, Qingdao, China; Department of Electronic Engineering, College of Information Science and Engineering, Ocean University of China, Qingdao, China; Department of Electronic Engineering, College of Information Science and Engineering, Ocean University of China, Qingdao, China; Department of Electronic Engineering, College of Information Science and Engineering, Ocean University of China, Qingdao, China; Department of Electronic Engineering, College of Information Science and Engineering, Ocean University of China, Qingdao, China; Department of Electronic Engineering, College of Information Science and Engineering, Ocean University of China, Qingdao, China","IEEE Access","","2018","6","","78503","78512","Scientific studies on species composition and abundance distribution of fishes have considerable importance to the fishery industry, biodiversity protection, and marine ecosystem. In these studies, fish images are typically collected with the help of scuba divers or autonomous underwater vehicles. These images are then annotated manually by marine biologists. Such a process is certainly a tremendous waste of manpower and material resources. In recent years, the introduction of deep learning has helped making remarkable progress in this area. However, fish image classification can be considered as fine-grained problem, which is more challenging than common image classification, especially with low-quality and small-scale data. Meanwhile, well-known effective convolutional neural networks (CNNs) consistently require a large quantity of high-quality data. This paper presents a new method by improving transfer learning and squeeze-and-excitation networks for fine-grained fish image classification on low-quality and small-scale datasets. Our method enhances data augmentation through super-resolution reconstruction to enlarge the dataset with high-quality images, pre-pretrains, and pretrains to learn common and domain knowledge simultaneously while fine-tuning with professional skill. In addition, refined squeeze-and-excitation blocks are designed to improve bilinear CNNs for a fine-grained classification. Unlike well-known CNNs for image classification, our method can classify images with insufficient low-quality training data. Moreover, we compare the performance of our method with commonly used CNNs on small-scale fine-grained datasets, namely, Croatian and QUT fish datasets. The experimental results show that our method outperforms popular CNNs with higher fish classification accuracy, which indicates its potential applications in combination with other newly updated CNNs.","","","10.1109/ACCESS.2018.2885055","National Natural Science Foundation of China; Qingdao Municipal Science and Technology Program; China Scholarship Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8561295","Deep learning;image classification;image recognition;transfer learning;underwater technology","Feature extraction;Oceans;Visualization;Task analysis;Network architecture;Streaming media","aquaculture;convolutional neural nets;image classification;image reconstruction;image resolution;learning (artificial intelligence)","transfer learning;small-scale fine-grained fish image classification;species composition;marine ecosystem;fish images;autonomous underwater vehicles;marine biologists;material resources;deep learning;fine-grained problem;common image classification;small-scale data;well-known effective convolutional neural networks;high-quality data;small-scale datasets;data augmentation;high-quality images;refined squeeze;fine-grained classification;low-quality training data;small-scale fine-grained datasets;higher fish classification accuracy;squeeze-and-excitation networks;squeeze-and-excitation blocks;well-known CNN","","2","58","CCBY","","","","IEEE","IEEE Journals"
"A Deep Learning Approach for Oriented Electrical Equipment Detection in Thermal Images","X. Gong; Q. Yao; M. Wang; Y. Lin","College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China; College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China; College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China; State Grid Shandong Electric Power Research Institute, Jinan, China","IEEE Access","","2018","6","","41590","41597","Due to the high precision and non-contact characteristics, infrared thermography has been widely used in equipment inspection to ensure the safety of electric power systems. A fundamental step toward automatic inspection and diagnosis is the detection of equipment in thermal images. Therefore, this paper presents a deep learning approach to detect equipment parts in real-time. Specifically, we propose a deep convolutional neural network that predicts the coordinates, orientation angle, and class type of each equipment part. A prior concerning orientation consistency between parts is also incorporated into our model to improve the prediction results. For evaluation, we construct a large image set containing various kinds of scenarios. Experiments on the data set show that our method is robust to noise, achieving 93.7% mean average precision when the intersection over union threshold is 0.5, and running at 20 fps on GPU. We believe that our high accurate detection results can benefit the subsequent diagnosis.","","","10.1109/ACCESS.2018.2859048","Natural Science Foundation of Zhejiang Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8418366","Electrical equipment detection;oriented object detection;automatic diagnosis","Feature extraction;Machine learning;Object detection;Inspection;Convolutional neural networks;Cameras;Task analysis","infrared imaging;inspection;learning (artificial intelligence);neural nets;object detection;power apparatus;power engineering computing;safety","GPU;electric power system safety;orientation consistency;image set;orientation angle;deep convolutional neural network;automatic inspection;equipment inspection;infrared thermography;noncontact characteristics;thermal images;oriented electrical equipment detection;deep learning approach","","","25","","","","","IEEE","IEEE Journals"
"Multiscale Multitask Deep NetVLAD for Crowd Counting","Z. Shi; L. Zhang; Y. Sun; Y. Ye","School of Information Engineering, Zhengzhou University, Zhengzhou, China; Advanced Digital Sciences Center, University of Illinois at Urbana-Champaign, Singapore; School of Information Engineering, Zhengzhou University, Zhengzhou, China; School of Information Engineering, Zhengzhou University, Zhengzhou, China","IEEE Transactions on Industrial Informatics","","2018","14","11","4953","4962","Deep convolutional networks (CNNs) reign undisputed as the new de-facto method for computer vision tasks owning to their success in visual recognition task on still images. However, their adaptations to crowd counting have not clearly established their superiority over shallow models. Existing CNNs turn out to be self-limiting in challenging scenarios such as camera illumination changing, partial occlusions, diverse crowd distributions, and perspective distortions for crowd counting because of their shallow structure. In this paper, we introduce a dynamic augmentation technique to train a much deeper CNN for crowd counting. In order to decrease overfitting caused by limited number of training samples, multitask learning is further employed to learn generalizable representations across similar domains. We also propose to aggregate multiscale convolutional features extracted from the entire image into a compact single vector representation amenable to efficient and accurate counting by way of “Vector of Locally Aggregated Descriptors” (VLAD). The “deeply supervised” strategy is employed to provide additional supervision signal for bottom layers for further performance improvement. Experimental results on three benchmark crowd datasets show that our method achieves better performance than the existing methods. Our implementation will be released at https://github.com/shizenglin/Multitask-Multiscale-Deep-NetVLAD.","","","10.1109/TII.2018.2852481","National Natural Science Foundation of China; National Key R&D Plan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8401914","Crowd counting;deep learning;multitask learning;vector of locally aggregated descriptors (VLAD)","Feature extraction;Task analysis;Visualization;Computer vision;Training;Robustness;Convolution","cameras;computer vision;convolution;feature extraction;image classification;image representation;learning (artificial intelligence);object detection;recurrent neural nets","benchmark crowd datasets;crowd counting;CNNs;computer vision tasks;visual recognition task;diverse crowd distributions;multiscale convolutional features;vector of locally aggregated descriptors;multiscale multitask deep NetVLAD;deep convolutional networks","","2","45","","","","","IEEE","IEEE Journals"
"Heterogeneous Face Attribute Estimation: A Deep Multi-Task Learning Approach","H. Han; A. K. Jain; F. Wang; S. Shan; X. Chen","Key Laboratory of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS, Beijing, China; Department of Computer Science and Engineering, Michigan State University, East Lansing, MI; Key Laboratory of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS, Beijing, China; Key Laboratory of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS and CAS Center for Excellence in Brain Science and Intelligence Technology, Beijing, China; Key Laboratory of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS, Beijing, China","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","11","2597","2609","Face attribute estimation has many potential applications in video surveillance, face retrieval, and social media. While a number of methods have been proposed for face attribute estimation, most of them did not explicitly consider the attribute correlation and heterogeneity (e.g., ordinal versus nominal and holistic versus local) during feature representation learning. In this paper, we present a Deep Multi-Task Learning (DMTL) approach to jointly estimate multiple heterogeneous attributes from a single face image. In DMTL, we tackle attribute correlation and heterogeneity with convolutional neural networks (CNNs) consisting of shared feature learning for all the attributes, and category-specific feature learning for heterogeneous attributes. We also introduce an unconstrained face database (LFW+), an extension of public-domain LFW, with heterogeneous demographic attributes (age, gender, and race) obtained via crowdsourcing. Experimental results on benchmarks with multiple face attributes (MORPH II, LFW+, CelebA, LFWA, and FotW) show that the proposed approach has superior performance compared to state of the art. Finally, evaluations on a public-domain face database (LAP) with a single attribute show that the proposed approach has excellent generalization ability.","","","10.1109/TPAMI.2017.2738004","National Natural Science Foundation of China; External Cooperation Program of CAS; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8007264","Face recognition;heterogeneous attribute estimation;attribute correlation;attribute heterogeneity;multi-task learning","Face;Estimation;Correlation;Databases;Support vector machines;Hair;Predictive models","face recognition;feature extraction;image representation;learning (artificial intelligence);neural nets","heterogeneous face attribute estimation;face retrieval;attribute correlation;feature representation learning;single face image;category-specific feature;unconstrained face database;heterogeneous demographic attributes;public-domain face database;deep multitask learning approach;convolutional neural networks","","17","60","","","","","IEEE","IEEE Journals"
"iTCM: Toward Learning-Based Thermal Comfort Modeling via Pervasive Sensing for Smart Buildings","W. Hu; Y. Wen; K. Guan; G. Jin; K. J. Tseng","School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore; Bell Labs, Nokia, Holmdel, NJ, USA; Green Building Technology | Built Environment Research & Innovation Institute, Building and Construction Authority, Singapore; Electrical Power Engineering, Singapore Institute of Technology, Singapore","IEEE Internet of Things Journal","","2018","5","5","4164","4177","For decades, ASHRAE Standard 55 has been using the Fanger's predicted mean vote (PMV) model to evaluate the indoor thermal comfort satisfaction. However, this canonical model has drawbacks in both data inadequacy and lack of inputs from test subjects. In this paper, we propose a learning-based solution for thermal comfort modeling via the emerging machine learning techniques and Internet of Things-based pervasive sensing technologies. First, we build an intelligent thermal comfort management (iTCM) system. It adopts the wireless sensor network to collect environmental data and utilizes the wearable device for vital sign monitoring. In addition, a cloud-based back-end system, with cost efficient deployment fees, is developed for data management and analysis. Second, we implement a black-box neural network (NN), namely the intelligent thermal comfort NN (ITCNN). To evaluate the performance of ITCNN, we compare it with the PMV model, three traditional white-box machine learning approaches and three classical black-box machine learning methods. Our preliminary results show that four black-box methods achieve better performance than the PMV model and the three white-box approaches. The ITCNN achieves the best performance and outperforms the PMV model by on average 13.1% and up to 17.8%. Third, with the iTCM system, we demonstrate a novel deep reinforcement learning-based application by encouraging human behavioral changes to form energy-saving habits for greener, smarter, and healthier building. Finally, we discuss the limitations of this paper and present the plan for our future research.","","","10.1109/JIOT.2018.2861831","National Research Foundation; Building and Construction Authority (BCA); Singapore–Berkeley Building Efficiency and Sustainability in the Tropics (SinBerBEST) Program; University of California Berkeley; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8423630","Internet of Things (IoT);machine learning;neural network (NN);pervasive sensing;reinforcement learning (RL);smart building;thermal comfort modeling;wearables","Wireless sensor networks;Sensors;Machine learning;Predictive models;Buildings;Adaptation models;Thermal management","Internet of Things;learning (artificial intelligence);neural nets;wireless sensor networks","smart buildings;ASHRAE Standard 55;Fanger's predicted mean vote model;indoor thermal comfort satisfaction;canonical model;data inadequacy;intelligent thermal comfort management system;wireless sensor network;environmental data;cloud-based back-end system;cost efficient deployment fees;data management;black-box neural network;intelligent thermal comfort NN;ITCNN;PMV model;traditional white-box machine learning approaches;classical black-box machine;iTCM system;Internet of Things-based pervasive sensing technologies;deep reinforcement learning-based application","","1","55","","","","","IEEE","IEEE Journals"
"Naturalization Module in Neural Networks for Screen Content Image Quality Assessment","J. Chen; L. Shen; L. Zheng; X. Jiang","Shanghai Institute for Advanced Communication and Data Science, Shanghai University, Shanghai, China; Key laboratory of Specialty Fiber Optics and Optical Access Networks, Joint International Research Laboratory of Specialty Fiber Optics and Advanced Communication, Shanghai Institute for Advanced Communication and Data Science, Shanghai University, Shanghai, China; Shanghai Institute for Advanced Communication and Data Science, Shanghai University, Shanghai, China; Shanghai Institute for Advanced Communication and Data Science, Shanghai University, Shanghai, China","IEEE Signal Processing Letters","","2018","25","11","1685","1689","Deep learning approaches have demonstrated success in no-reference image quality assessment tasks. However, due to the specific properties of screen content images (SCIs), deep neural networks for SCI quality assessment are not as optimal as those designed for images depicting natural scenes. In order to tackle this discrepancy, a “naturalization” module composed of an upsampling layer and a convolutional layer is proposed to transform SCIs to have characteristics more similar to that of natural images. In addition, a new deep learning model architecture along with data augmentation techniques tailored to SCIs are implemented. The performance of the proposed approach is evaluated on the Screen Image Quality Assessment Database and Screen Content Image Database and has shown to have superior performance to state-of-the-art methods in predicting the perceptual quality of SCIs.","","","10.1109/LSP.2018.2871250","National Natural Science Foundation of China; Shanghai Pujiang Program; Shanghai Science and Technology Innovation Plan; Shanghai Shuguang Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8468110","Deep learning;image quality assessment;image processing;naturalization;screen content images","Image quality;Machine learning;Neural networks;Distortion;Interpolation;Convolution;Measurement","image processing;learning (artificial intelligence);natural scenes;neural nets;visual databases","no-reference image quality assessment tasks;SCIs;deep neural networks;SCI quality assessment;natural scenes;upsampling layer;convolutional layer;natural images;deep learning model architecture;perceptual quality;naturalization module;screen content image quality assessment database;deep learning approaches;data augmentation techniques","","","26","","","","","IEEE","IEEE Journals"
"Urban Land Cover Classification With Missing Data Modalities Using Deep Convolutional Neural Networks","M. Kampffmeyer; A. Salberg; R. Jenssen","Machine Learning Group, UiT The Arctic University of Norway, Tromsø, Norway; Norwegian Computing Center, Oslo, Norway; Machine Learning Group, UiT The Arctic University of Norway, Tromsø, Norway","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2018","11","6","1758","1768","Automatic urban land cover classification is a fundamental problem in remote sensing, e.g., for environmental monitoring. The problem is highly challenging, as classes generally have high interclass and low intraclass variances. Techniques to improve urban land cover classification performance in remote sensing include fusion of data from different sensors with different data modalities. However, such techniques require all modalities to be available to the classifier in the decision-making process, i.e., at test time, as well as in training. If a data modality is missing at test time, current state-of-the-art approaches have in general no procedure available for exploiting information from these modalities. This represents a waste of potentially useful information. We propose as a remedy a convolutional neural network (CNN) architecture for urban land cover classification which is able to embed all available training modalities in the so-called hallucination network. The network will in effect replace missing data modalities in the test phase, enabling fusion capabilities even when data modalities are missing in testing. We demonstrate the method using two datasets consisting of optical and digital surface model (DSM) images. We simulate missing modalities by assuming that DSM images are missing during testing. Our method outperforms both standard CNNs trained only on optical images as well as an ensemble of two standard CNNs. We further evaluate the potential of our method to handle situations where only some DSM images are missing during testing. Overall, we show that we can clearly exploit training time information of the missing modality during testing.","","","10.1109/JSTARS.2018.2834961","Norwegian Research Council FRIPRO; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8386424","Convolutional neural networks (CNN);deep learning;land cover classification;missing data modalities;remote sensing","Remote sensing;Testing;Training;Optical sensors;Machine learning;Optical imaging","convolution;decision making;feedforward neural nets;geophysical image processing;image classification;land cover;optical images;sensor fusion;terrain mapping","missing data modalities;deep convolutional neural networks;remote sensing;hallucination network;training time information;training modalities;intraclass variances;interclass variances;data fusion;sensors;decision-making process;classifier;CNN architecture;optical images;digital surface model images;DSM images;Urban land cover classification","","2","36","","","","","IEEE","IEEE Journals"
"Compressing Chinese Dark Chess Endgame Databases by Deep Learning","J. Chen; G. Fan; H. Chang; T. Hsu","Department of Computer Science and Information Engineering, National Taipei University, Taipei, Taiwan; Institute of Information Science, Academia Sinica, Taipei, Taiwan; Department of Computer Science and Information Engineering, Nation Taiwan University, Taipei, Taiwan; Institute of Information Science, Academia Sinica, Taipei, Taiwan","IEEE Transactions on Games","","2018","10","4","413","422","Endgame databases can be difficult to use in tree search when database sizes remain large even after compression. Given the same endgame, we discover that the compression ratios vary significantly when using different encoding schemes. The intuition is that when a set of positions mapped into a continuous chunk of segments have similar values, block-based compression libraries such as zlib can yield a better compression ratio than cases where segments contain diversified values. However, finding the optimal encoding scheme by exhaustive enumeration is time-infeasible for endgame databases with a large number of pieces. We propose a novel approach using deep learning to obtain an encoding scheme so that the compression ratio is suitable for practical purposes. Our approach can be applied to chess-like games.","","","10.1109/TG.2018.2802484","Ministry of Science of Technology of Taiwan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8281641","Board game;Chinese dark chess (CDC);deep learning (DL);endgame database","Encoding;Games;Indexing;Machine learning;Law","computer games;data compression;encoding;search problems;tree searching","optimal encoding scheme;deep learning;tree search;block-based compression libraries;Chinese dark chess endgame databases","","1","30","","","","","IEEE","IEEE Journals"
"Automatic Localization of the Needle Target for Ultrasound-Guided Epidural Injections","M. Pesteie; V. Lessoway; P. Abolmaesumi; R. N. Rohling","Department of Electrical and Computer Engineering, The University of British Columbia, Vancouver, BC, Canada; Department of Ultrasound, Women’s Hospital, Vancouver, BC, Canada; Department of Electrical and Computer Engineering, The University of British Columbia, Vancouver, BC, Canada; Department of Electrical and Computer Engineering, The University of British Columbia, Vancouver, BC, Canada","IEEE Transactions on Medical Imaging","","2018","37","1","81","92","Accurate identification of the needle target is crucial for effective epidural anesthesia. Currently, epidural needle placement is administered by a manual technique, relying on the sense of feel, which has a significant failure rate. Moreover, misleading the needle may lead to inadequate anesthesia, post dural puncture headaches, and other potential complications. Ultrasound offers guidance to the physician for identification of the needle target, but accurate interpretation and localization remain challenges. A hybrid machine learning system is proposed to automatically localize the needle target for epidural needle placement in ultrasound images of the spine. In particular, a deep network architecture along with a feature augmentation technique is proposed for automatic identification of the anatomical landmarks of the epidural space in ultrasound images. Experimental results of the target localization on planes of 3-D as well as 2-D images have been compared against an expert sonographer. When compared with the expert annotations, the average lateral and vertical errors on the planes of 3-D test data were 1 and 0.4 mm, respectively. On 2-D test data set, an average lateral error of 1.7 mm and vertical error of 0.8 mm were acquired.","","","10.1109/TMI.2017.2739110","Natural Science and Engineering Research Council of Canada; Canadian Institutes of Health Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8008783","Epidural injection;deep learning;3D ultrasound;prepuncture scan;target localization","Needles;Three-dimensional displays;Ultrasonic imaging;Anesthesia;Real-time systems;Spine","biomedical ultrasonics;learning (artificial intelligence);medical image processing","automatic localization;needle target;ultrasound-guided epidural injections;hybrid machine learning system;epidural needle placement;ultrasound images;deep network architecture;feature augmentation technique;epidural space;automatic identification;anatomical landmarks;2D images;3D images;lateral errors;vertical errors;target localization;epidural anesthesia;spine","Adult;Algorithms;Anesthesia, Epidural;Deep Learning;Epidural Space;Humans;Image Processing, Computer-Assisted;Lumbosacral Region;Needles;Ultrasonography, Interventional;Young Adult","2","66","","","","","IEEE","IEEE Journals"
"Extreme Trust Region Policy Optimization for Active Object Recognition","H. Liu; Y. Wu; F. Sun","Department of Computer Science and Technology, State Key Laboratory of Intelligent Technology and Systems, Tsinghua University, Beijing, China; Department of Computer Science and Technology, State Key Laboratory of Intelligent Technology and Systems, Tsinghua University, Beijing, China; Department of Computer Science and Technology, State Key Laboratory of Intelligent Technology and Systems, Tsinghua University, Beijing, China","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","6","2253","2258","In this brief, we develop a deep reinforcement learning method to actively recognize objects by choosing a sequence of actions for an active camera that helps to discriminate between the objects. The method is realized using trust region policy optimization, in which the policy is realized by an extreme learning machine and, therefore, leads to efficient optimization algorithm. The experimental results on the publicly available data set show the advantages of the developed extreme trust region optimization method.","","","10.1109/TNNLS.2017.2785233","National Natural Science Foundation of China; National High-Tech Research and Development Plan; Beijing Municipal Science and Technology Commission; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8259343","Active object recognition;extreme learning machines (ELMs);trust region policy optimization (TRPO)","Optimization;Object recognition;Learning (artificial intelligence);Visualization;Learning systems;Cameras","feedforward neural nets;learning (artificial intelligence);object recognition;optimisation","deep reinforcement learning method;extreme learning machine;efficient optimization algorithm;extreme trust region policy optimization;active object recognition;camera","","6","31","","","","","IEEE","IEEE Journals"
"Utilising Deep Learning and Genome Wide Association Studies for Epistatic-Driven Preterm Birth Classification in African-American Women","P. Fergus; A. Montanez; B. Abdulaimma; P. Lisboa; C. Chalmers; B. Pineles","School of Computing and Mathematical Sciences, Liverpool John Moores University, Liverpool, Merseyside United Kingdom of Great Britain and Northern Ireland (e-mail: P.Fergus@ljmu.ac.uk); Computer Science, Liverpool John Moores University, 4589 Liverpool, Merseyside United Kingdom of Great Britain and Northern Ireland (e-mail: C.A.CurbeloMontanez@2015.ljmu.ac.uk); Liverpool John Moores University, 4589 Liverpool, Merseyside United Kingdom of Great Britain and Northern Ireland (e-mail: B.T.Abdulaimma@2015.ljmu.ac.uk); School of Computing and Mathematical Sciences, Liverpool John Moores University, Liverpool, Merseyside United Kingdom of Great Britain and Northern Ireland (e-mail: P.J.Lisboa@ljmu.ac.uk); Department of Computer Science, Liverpool John Moores University, Liverpool, Merseyside United Kingdom of Great Britain and Northern Ireland (e-mail: C.Chalmers@ljmu.ac.uk); University of Maryland Medical Center, 21668 Baltimore, Maryland United States (e-mail: bpineles@gmail.com)","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2018","PP","99","1","1","Genome-Wide Association Studies (GWAS) are used to identify statistically significant genetic variants in case-control studies. The main objective is to find single nucleotide polymorphisms (SNPs) that influence a particular phenotype. GWAS use a p-value threshold of $5\star 10^{-8}$ to identify highly ranked SNPs. While this approach has proven useful for detecting disease-susceptible SNPs, evidence has shown that many of these are, in fact, false positives. Consequently, there is some ambiguity about the most suitable threshold for claiming genome-wide significance. Many believe that using lower p-values will allow us to investigate the joint epistatic interactions between SNPs and provide better insights into phenotype expression. In this paper, we propose a novel framework, based on nonlinear transformations of combinatorically large SNP data, using stacked autoencoders, to identify higher-order SNP interactions. We focus on the challenging problem of classifying preterm births. Latent representations from original SNP sequences are used to initialize a deep learning classifier before it is fine-tuned for classification tasks. The findings show that important information pertaining to epistasis can be extracted from 4666 raw SNPs generated using logistic regression (p-value=$5\star 10^{-8}$) and used to fit a deep learning model and obtain results (Sen=0.9289, Spec=0.9591, Gini=0.9651, Logloss=0.3080, AUC=0.9825, MSE=0.0942) using 500 hidden nodes.","","","10.1109/TCBB.2018.2868667","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8454302","Preterm Birth;GWAS;Epistasis;Classification;Stacked Autoencoders;Deep Learning;Machine Learning","Machine learning;Diseases;Pregnancy;Genomics;Bioinformatics;Pediatrics","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Human Action Monitoring for Healthcare Based on Deep Learning","Y. Gao; X. Xiang; N. Xiong; B. Huang; H. J. Lee; R. Alrifai; X. Jiang; Z. Fang","School of Electronic and Electrical Engineering, Shanghai University of Engineering Science, Shanghai, China; School of Electronic and Electrical Engineering, Shanghai University of Engineering Science, Shanghai, China; Department of Mathematics and Computer Science, Northestern State University, Tahlequah, OK, USA; School of Electronic and Electrical Engineering, Shanghai University of Engineering Science, Shanghai, China; Division of Computer Science and Engineering, Center of Advanced Image and Information Technology, Chonbuk National University, Jeonju, South Korea; Department of Mathematics and Computer Science, Northestern State University, Tahlequah, OK, USA; School of Electronic and Electrical Engineering, Shanghai University of Engineering Science, Shanghai, China; School of Electronic and Electrical Engineering, Shanghai University of Engineering Science, Shanghai, China","IEEE Access","","2018","6","","52277","52285","Human action monitoring can be advantageous to remotely monitor the status of patients or elderly person for intelligent healthcare. Human action recognition enables efficient and accurate monitoring of human behaviors, which can exhibit multifaceted complexity attributed to disparities in viewpoints, personality, resolution and motion speed of individuals, etc. The spatial-temporal information plays an important role in the human action recognition. In this paper, we proposed a novel deep learning architecture named as recurrent 3D convolutional neural network (R3D) to extract effective and discriminative spatial-temporal features to be used for action recognition, which enables the capturing of long-range temporal information by aggregating the 3D convolutional network entries to serve as an input to the LSTM (Long Short-Term Memory) architecture. The 3D convolutional network and LSTM are two effective methods for extracting the temporal information. The proposed R3D network integrated these two methods by sharing a shared 3D convolutional network in sliding windows on video streaming to capturing short-term spatial-temporal features into the LSTM. The output features of LSTM encapsulate the longrange spatial-temporal information representing high-level abstraction of the human actions. The proposed algorithm is compared to traditional and the-state-of-the-art and deep learning algorithms. The experimental results demonstrated the effectiveness of the proposed system, which can be used as smart monitoring for remote healthcare.","","","10.1109/ACCESS.2018.2869790","Project of Local Colleges’ and Universities’ Capacity Construction of Science and Technology Commission in Shanghai; National Natural Science Foundation of China; Collaborative Innovation Center for Economic Crime Investigation and Prevention Technology of Jiangxi Province; Shanghai Chenguang Talented Program; Ministry of Science and ICT (MSIT), South Korea, under the ITRC Support Program supervised by the IITP; National Science Foundation; Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8463470","Action recognition;3D convolutional network;LSTM","Three-dimensional displays;Feature extraction;Convolution;Data mining;Monitoring;Medical services;Kernel","convolution;feedforward neural nets;geriatrics;health care;image motion analysis;image recognition;image representation;learning (artificial intelligence);medical computing;patient monitoring;recurrent neural nets;stereo image processing;video signal processing","human action recognition;spatial-temporal information;deep learning architecture;recurrent 3D convolutional neural network;long-range temporal information;Long Short-Term Memory;shared 3D convolutional network;deep learning algorithms;smart monitoring;remote healthcare;human action monitoring;elderly person;intelligent healthcare;3D convolutional network;LSTM;video streaming;short-term spatial-temporal features;R3D network","","3","51","","","","","IEEE","IEEE Journals"
"Deep Learning Models for Wireless Signal Classification With Distributed Low-Cost Spectrum Sensors","S. Rajendran; W. Meert; D. Giustiniano; V. Lenders; S. Pollin","Department of Electrical Engineering, KU Leuven, Leuven, Belgium; Department of Computer Science, KU Leuven, Leuven, Belgium; IMDEA Networks Institute, Madrid, Spain; Cyberspace and Information, armasuisse, Thun, Switzerland; Department of Electrical Engineering, KU Leuven, Leuven, Belgium","IEEE Transactions on Cognitive Communications and Networking","","2018","4","3","433","445","This paper looks into the modulation classification problem for a distributed wireless spectrum sensing network. First, a new data-driven model for automatic modulation classification based on long short term memory (LSTM) is proposed. The model learns from the time domain amplitude and phase information of the modulation schemes present in the training data without requiring expert features like higher order cyclic moments. Analyses show that the proposed model yields an average classification accuracy of close to 90% at varying signal-to-noise ratio conditions ranging from 0 dB to 20 dB. Further, we explore the utility of this LSTM model for a variable symbol rate scenario. We show that a LSTM based model can learn good representations of variable length time domain sequences, which is useful in classifying modulation signals with different symbol rates. The achieved accuracy of 75% on an input sample length of 64 for which it was not trained, substantiates the representation power of the model. To reduce the data communication overhead from distributed sensors, the feasibility of classification using averaged magnitude spectrum data and on-line classification on the low-cost spectrum sensors are studied. Furthermore, quantized realizations of the proposed models are analyzed for deployment on sensors with low processing power.","","","10.1109/TCCN.2018.2835460","FWO SBO Project SAMURAI; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8357902","Deep learning;modulation classification;LSTM;CNN;spectrum sensing","Sensors;Modulation;Wireless sensor networks;Wireless communication;Machine learning;Data models;Communication system security","cognitive radio;distributed sensors;higher order statistics;modulation;signal classification","deep learning models;wireless signal classification;distributed low-cost spectrum sensors;modulation classification problem;distributed wireless spectrum sensing network;data-driven model;automatic modulation classification;long short term memory;time domain amplitude;phase information;training data;expert features;higher order cyclic moments;average classification accuracy;varying signal-to-noise ratio conditions;LSTM model;variable symbol rate scenario;variable length time domain sequences;modulation signals;input sample length;representation power;data communication overhead;distributed sensors;magnitude spectrum data;on-line classification;low processing power;symbol rates","","38","25","","","","","IEEE","IEEE Journals"
"Learning Source-Invariant Deep Hashing Convolutional Neural Networks for Cross-Source Remote Sensing Image Retrieval","Y. Li; Y. Zhang; X. Huang; J. Ma","School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; Electronic Information School, Wuhan University, Wuhan, China","IEEE Transactions on Geoscience and Remote Sensing","","2018","56","11","6521","6536","Due to the urgent demand for remote sensing big data analysis, large-scale remote sensing image retrieval (LSRSIR) attracts increasing attention from researchers. Generally, LSRSIR can be divided into two categories as follows: uni-source LSRSIR (US-LSRSIR) and cross-source LSRSIR (CS-LSRSIR). More specifically, US-LSRSIR means the inquiry remote sensing image and images in the searching data set come from the same remote sensing data source, whereas CS-LSRSIR is designed to retrieve remote sensing images with a similar content to the inquiry remote sensing image that are from a different remote sensing data source. In the literature, US-LSRSIR has been widely exploited, but CS-LSRSIR is rarely discussed. In practical situations, remote sensing images from different kinds of remote sensing data sources are continually increasing, so there is a great motivation to exploit CS-LSRSIR. Therefore, this paper focuses on CS-LSRSIR. To cope with CS-LSRSIR, this paper proposes source-invariant deep hashing convolutional neural networks (SIDHCNNs), which can be optimized in an end-to-end manner using a series of well-designed optimization constraints. To quantitatively evaluate the proposed SIDHCNNs, we construct a dual-source remote sensing image data set that contains eight typical land-cover categories and 10 000 dual samples in each category. Extensive experiments show that the proposed SIDHCNNs can yield substantial improvements over several baselines involving the most recent techniques.","","","10.1109/TGRS.2018.2839705","National Key Research and Development Program of China; National Natural Science Foundation of China; China Postdoctoral Science Foundation; China Scholarship Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8385104","Cross-source large-scale remote sensing image retrieval (CS-LSRSIR);dual-source remote sensing image data set (DSRSID);remote sensing big data (RSBD) management and mining;source-invariant deep hashing convolutional neural networks (SIDHCNNs)","Remote sensing;Optimization;Image retrieval;Convolutional neural networks;Big Data;Learning systems;Complexity theory","Big Data;convolution;cryptography;data analysis;feedforward neural nets;geophysical image processing;image retrieval;learning (artificial intelligence);remote sensing","learning;large-scale remote sensing image retrieval;uni-source LSRSIR;remote sensing big data analysis;cross-source remote sensing image retrieval;dual-source remote sensing image data;source-invariant deep hashing convolutional neural networks;remote sensing images;US-LSRSIR;CS-LSRSIR;cross-source LSRSIR","","4","44","","","","","IEEE","IEEE Journals"
"A Tensor-Train Deep Computation Model for Industry Informatics Big Data Feature Learning","Q. Zhang; L. T. Yang; Z. Chen; P. Li","School of Electronic Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Electronic Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Software Technology, Dalian University of Technology, Dalian, China; School of Software Technology, Dalian University of Technology, Dalian, China","IEEE Transactions on Industrial Informatics","","2018","14","7","3197","3204","The deep computation model has been proved to be effective for big data hierarchical feature and representation learning in the tensor space. However, it requires expensively computational resources including high-performance computing units and large memory to train a deep computation model with a large number of parameters, limiting its effectiveness and efficiency for industry informatics big data feature learning. In this paper, a tensor-train deep computation model is presented for industry informatics big data feature learning. Specially, the tensor-train network is used to compress the parameters significantly by converting the dense weight tensors into the tensor-train format. Furthermore, a learning algorithm is implemented based on gradient descent and back-propagation to train the parameters of the presented tensor-train deep computation model. Extensive experiments are carried on STL-10, CUAVE, and SNAE2 to evaluate the presented model in terms of the approximation error, classification accuracy drop, parameters reduction, and speedup. Results demonstrate that the presented model can improve the training efficiency and save the memory space greatly for the deep computation model with small accuracy drops, proving its potential for industry informatics big data feature learning.","","","10.1109/TII.2018.2791423","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8252775","Big data;deep computation;industry informatics;tensor-train network","Tensile stress;Computational modeling;Data models;Big Data;Informatics;Industries;Training","backpropagation;Big Data;tensors","big data hierarchical feature;representation learning;tensor space;tensor-train network;dense weight tensors;tensor-train format;industry informatics big data feature learning;tensor-train deep computation model;gradient descent;back-propagation","","7","24","","","","","IEEE","IEEE Journals"
"Deep Network Embedding for Graph Representation Learning in Signed Networks","X. Shen; F. Chung","Department of Computing, Hong Kong Polytechnic University, Hong Kong.; Department of Computing, Hong Kong Polytechnic University, Hong Kong (e-mail: cskchung@comp.polyu.edu.hk).","IEEE Transactions on Cybernetics","","2018","PP","99","1","8","Network embedding has attracted an increasing attention over the past few years. As an effective approach to solve graph mining problems, network embedding aims to learn a low-dimensional feature vector representation for each node of a given network. The vast majority of existing network embedding algorithms, however, are only designed for unsigned networks, and the signed networks containing both positive and negative links, have pretty distinct properties from the unsigned counterpart. In this paper, we propose a deep network embedding model to learn the low-dimensional node vector representations with structural balance preservation for the signed networks. The model employs a semisupervised stacked auto-encoder to reconstruct the adjacency connections of a given signed network. As the adjacency connections are overwhelmingly positive in the real-world signed networks, we impose a larger penalty to make the auto-encoder focus more on reconstructing the scarce negative links than the abundant positive links. In addition, to preserve the structural balance property of signed networks, we design the pairwise constraints to make the positively connected nodes much closer than the negatively connected nodes in the embedding space. Based on the network representations learned by the proposed model, we conduct link sign prediction and community detection in signed networks. Extensive experimental results in real-world datasets demonstrate the superiority of the proposed model over the state-of-the-art network embedding algorithms for graph representation learning in signed networks.","","","10.1109/TCYB.2018.2871503","Hong Kong PhD Fellowship Scheme; PolyU CRF Projects; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8486671","Deep learning;graph representation learning;network embedding;signed network analysis;structural balance","Laplace equations;Prediction algorithms;Clustering algorithms;Eigenvalues and eigenfunctions;Cybernetics;Machine learning;Natural language processing","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"DPC-Net: Deep Pose Correction for Visual Localization","V. Peretroukhin; J. Kelly","Space and Terrestrial Autonomous Robotic Systems Laboratory, Institute for Aerospace Studies, University of Toronto, Toronto, ON, Canada; Space and Terrestrial Autonomous Robotic Systems Laboratory, Institute for Aerospace Studies, University of Toronto, Toronto, ON, Canada","IEEE Robotics and Automation Letters","","2018","3","3","2424","2431","We present a novel method to fuse the power of deep networks with the computational efficiency of geometric and probabilistic localization algorithms. In contrast to other methods that completely replace a classical visual estimator with a deep network, we propose an approach that uses a convolutional neural network to learn difficult-to-model corrections to the estimator from ground-truth training data. To this end, we derive a novel loss function for learning SE(3) corrections based on a matrix Lie groups approach, with a natural formulation for balancing translation and rotation errors. We use this loss to train a deep pose correction network (DPC-Net) that predicts corrections for a particular estimator, sensor and environment. Using the KITTI odometry dataset, we demonstrate significant improvements to the accuracy of a computationally-efficient sparse stereo visual odometry pipeline, that render it as accurate as a modern computationally-intensive dense estimator. Further, we show how DPC-Net can be used to mitigate the effect of poorly calibrated lens distortion parameters.","","","10.1109/LRA.2017.2778765","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8125095","Deep Learning in Robotics and Automation;localization","Visualization;Pipelines;Convolution;Cameras;Jacobian matrices;Robot sensing systems","calibration;control engineering computing;convolution;distance measurement;feedforward neural nets;learning (artificial intelligence);Lie groups;mobile robots;motion estimation;pose estimation;robot vision;SLAM (robots);stereo image processing","KITTI odometry;SE(3) corrections learning;visual estimator;stereo visual odometry pipeline;matrix Lie groups;deep pose correction network;difficult-to-model corrections;convolutional neural network;probabilistic localization algorithms;geometric localization algorithms;deep network;visual localization;DPC-Net","","2","27","","","","","IEEE","IEEE Journals"
"A Scalable Multi-TeraOPS Core for AI Training and Inference","S. Shukla; B. Fleischer; M. Ziegler; J. Silberman; J. Oh; V. Srinivasan; J. Choi; S. Mueller; A. Agrawal; T. Babinsky; N. Cao; C. Chen; P. Chuang; T. Fox; G. Gristede; M. Guillorn; H. Haynie; M. Klaiber; D. Lee; S. Lo; G. Maier; M. Scheuermann; S. Venkataramani; C. Vezyrtzis; N. Wang; F. Yee; C. Zhou; P. Lu; B. Curran; L. Chang; K. Gopalakrishnan","IBM T. J. Watson Research Center, Yorktown Heights, NY, USA; IBM T. J. Watson Research Center, Yorktown Heights, NY, USA; IBM T. J. Watson Research Center, Yorktown Heights, NY, USA; IBM T. J. Watson Research Center, Yorktown Heights, NY, USA; IBM T. J. Watson Research Center, Yorktown Heights, NY, USA; IBM T. J. Watson Research Center, Yorktown Heights, NY, USA; IBM T. J. Watson Research Center, Yorktown Heights, NY, USA; IBM Systems Group, Boeblingen, Germany; IBM T. J. Watson Research Center, Yorktown Heights, NY, USA; IBM Systems Group, Boeblingen, Germany; IBM T. J. Watson Research Center, Yorktown Heights, NY, USA; IBM T. J. Watson Research Center, Yorktown Heights, NY, USA; IBM T. J. Watson Research Center, Yorktown Heights, NY, USA; IBM T. J. Watson Research Center, Yorktown Heights, NY, USA; IBM T. J. Watson Research Center, Yorktown Heights, NY, USA; IBM T. J. Watson Research Center, Yorktown Heights, NY, USA; IBM Systems Group, Poughkeepsie, NY, USA; IBM Systems Group, Boeblingen, Germany; IBM T. J. Watson Research Center, Yorktown Heights, NY, USA; IBM T. J. Watson Research Center, Yorktown Heights, NY, USA; IBM Systems Group, East Fishkill, NY, USA; IBM T. J. Watson Research Center, Yorktown Heights, NY, USA; IBM T. J. Watson Research Center, Yorktown Heights, NY, USA; IBM T. J. Watson Research Center, Yorktown Heights, NY, USA; IBM T. J. Watson Research Center, Yorktown Heights, NY, USA; IBM T. J. Watson Research Center, Yorktown Heights, NY, USA; IBM T. J. Watson Research Center, Yorktown Heights, NY, USA; IBM T. J. Watson Research Center, Yorktown Heights, NY, USA; IBM Systems Group, Poughkeepsie, NY, USA; IBM T. J. Watson Research Center, Yorktown Heights, NY, USA; IBM T. J. Watson Research Center, Yorktown Heights, NY, USA","IEEE Solid-State Circuits Letters","","2018","1","12","217","220","This letter presents a multi-TOPS AI accelerator core for deep learning training and inference. With a programmable architecture and custom ISA, this engine achieves >90% sustained utilization across the range of neural network topologies by employing a dataflow architecture to provide high throughput and an on-chip scratchpad hierarchy to meet the bandwidth demands of the compute units. A custom 16b floating point (fp16) representation with 1 sign bit, 6 exponent bits, and 9 mantissa bits has also been developed for high model accuracy in training and inference as well as 1b/2b (binary/ternary) integer for aggressive inference performance. At 1.5 GHz, the AI core prototype achieves 1.5 TFLOPS fp16, 12 TOPS ternary, or 24 TOPS binary peak performance in 14-nm CMOS.","","","10.1109/LSSC.2019.2902738","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8657745","Accelerators;artificial intelligence;dataflow;deep learning (DL);machine learning","Training;Deep learning;Computer architecture;Solid state circuits;Bandwidth;Hardware","floating point arithmetic;learning (artificial intelligence);multiprocessing systems","scalable multiTeraOPS core;AI training;multiTOPS AI accelerator core;deep learning training;programmable architecture;custom ISA;neural network topologies;dataflow architecture;high throughput;on-chip scratchpad hierarchy;bandwidth demands;compute units;high model accuracy;1b/2b integer;aggressive inference performance;AI core prototype;floating point representation;exponent bits;mantissa bits;TOPS binary peak performance;frequency 1.5 GHz;computer speed 1.5 TFLOPS","","2","8","","","","","IEEE","IEEE Journals"
"Latent Topic Text Representation Learning on Statistical Manifolds","B. Jiang; Z. Li; H. Chen; A. G. Cohn","School of Computer Science and Technology, University of Science and Technology of China, Hefei, China; Advertisement Research for Sponsored Search Group, Sogou Inc., Beijing, China; School of Computer Science and Technology, University of Science and Technology of China, Hefei, China; School of Computing, University of Leeds, Leeds, U.K.","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","11","5643","5654","The explosive growth of text data requires effective methods to represent and classify these texts. Many text learning methods have been proposed, like statistics-based methods, semantic similarity methods, and deep learning methods. The statistics-based methods focus on comparing the substructure of text, which ignores the semantic similarity between different words. Semantic similarity methods learn a text representation by training word embedding and representing text as the average vector of all words. However, these methods cannot capture the topic diversity of words and texts clearly. Recently, deep learning methods such as CNNs and RNNs have been studied. However, the vanishing gradient problem and time complexity for parameter selection limit their applications. In this paper, we propose a novel and efficient text learning framework, named Latent Topic Text Representation Learning. Our method aims to provide an effective text representation and text measurement with latent topics. With the assumption that words on the same topic follow a Gaussian distribution, texts are represented as a mixture of topics, i.e., a Gaussian mixture model. Our framework is able to effectively measure text distance to perform text categorization tasks by leveraging statistical manifolds. Experimental results on text representation and classification, and topic coherence demonstrate the effectiveness of the proposed method.","","","10.1109/TNNLS.2018.2808332","National Key Research and Development Program of China; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8318929","Distance metric;Gaussian mixture model;statistical manifold;text classification;text representation","Manifolds;Semantics;Measurement;Probability distribution;Gaussian mixture model;Gaussian distribution","Gaussian distribution;Gaussian processes;learning (artificial intelligence);pattern classification;text analysis;word processing","text distance;text categorization tasks;statistic-based methods;latent topic text representation learning;text measurement;efficient text learning framework;novel text learning framework;topic diversity;word embedding;deep learning methods;semantic similarity methods;text learning methods;text data;statistical manifolds","","2","43","","","","","IEEE","IEEE Journals"
"Road Extraction by Deep Residual U-Net","Z. Zhang; Q. Liu; Y. Wang","State Key Laboratory of Virtual Reality Technology and Systems, School of Computer Science and Engineering, Beihang University, Beijing, China; State Key Laboratory of Virtual Reality Technology and Systems, School of Computer Science and Engineering, Beihang University, Beijing, China; State Key Laboratory of Virtual Reality Technology and Systems, School of Computer Science and Engineering, Beihang University, Beijing, China","IEEE Geoscience and Remote Sensing Letters","","2018","15","5","749","753","Road extraction from aerial images has been a hot research topic in the field of remote sensing image analysis. In this letter, a semantic segmentation neural network, which combines the strengths of residual learning and U-Net, is proposed for road area extraction. The network is built with residual units and has similar architecture to that of U-Net. The benefits of this model are twofold: first, residual units ease training of deep networks. Second, the rich skip connections within the network could facilitate information propagation, allowing us to design networks with fewer parameters, however, better performance. We test our network on a public road data set and compare it with U-Net and other two state-of-the-art deep-learning-based road extraction methods. The proposed approach outperforms all the comparing methods, which demonstrates its superiority over recently developed state of the arts.","","","10.1109/LGRS.2018.2802944","Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8309343","Convolutional neural network;deep residual U-Net;road extraction","Roads;Training;Neural networks;Remote sensing;Semantics;Image segmentation;Feature extraction","feature extraction;geophysical image processing;image segmentation;learning (artificial intelligence);neural nets;remote sensing;roads","deep networks;rich skip connections;public road data;deep-learning;deep residual U-Net;aerial images;remote sensing image analysis;semantic segmentation neural network;residual learning;road area extraction;residual units","","44","26","","","","","IEEE","IEEE Journals"
"General and Species-Specific Lysine Acetylation Site Prediction Using a Bi-Modal Deep Architecture","X. Zhao; J. Li; R. Wang; F. He; L. Yue; M. Yin","School of Information Science and Technology, Northeast Normal University, Changchun, China; School of Information Science and Technology, Northeast Normal University, Changchun, China; School of Information Science and Technology, Northeast Normal University, Changchun, China; School of Information Science and Technology, Northeast Normal University, Changchun, China; School of Information Science and Technology, Northeast Normal University, Changchun, China; Key Laboratory of Intelligent Information Processing of Jilin Universities, Northeast Normal University, Changchun, China","IEEE Access","","2018","6","","63560","63569","Acetylation, as one of the most important post-translation modifications, plays a key role in a variety of biological functions, such as transcriptional regulation, cytokine signaling, and apoptosis. To understand the mechanism of acetylation profoundly, it is necessary to identify acetylation sites in proteins accurately. The existing methods for identifying protein acetylation sites can be divided into two major categories, i.e., mass spectrometry and computational methods. Mass spectrometry-based experimental methods are capable of discovering acetylation sites from eukaryotes, but can be time-consuming and expensive. Therefore, it is necessary to develop computational approaches that can effectively and accurately identify protein acetylation sites. The existing computational methods usually involve feature engineering, which may lead to redundancy and biased representations. While deep learning is capable of excavating the underlying characteristics from large-scale training data set via multiple-layer networks and non-linear mapping operations. In this paper, we propose a new method (named DeepAce) for predicting general and species-specific lysine acetylation sites based on deep neural network. We critically evaluate the performance of DeepAce and compare it with other existing predictors. The comparative results show the effectiveness of our Bi-modal deep architecture and also indicate that our method is very promising for predicting acetylation sites. The source code of DeepAce can be freely accessed at https://github.com/jiagenlee/DeepAce.","","","10.1109/ACCESS.2018.2874882","National Natural Science Foundation of China; China Postdoctoral Science Foundation; Fundamental Research Funds for the Central Universities; Scientific and Technological Development Program of Jilin Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8487006","Protein acetylation sites prediction;deep learning;convolution neural network;transfer learning","Proteins;Feature extraction;Training;Amino acids;Machine learning;Testing;Convolution","biology computing;mass spectroscopy;neural nets;proteins","protein acetylation sites;mass spectrometry-based experimental methods;species-specific lysine acetylation site prediction;deep neural network;DeepAce;biological functions;post-translation modifications;bi-modal deep architecture","","","33","","","","","IEEE","IEEE Journals"
"Point-to-Set Distance Metric Learning on Deep Representations for Visual Tracking","S. Zhang; Y. Qi; F. Jiang; X. Lan; P. C. Yuen; H. Zhou","School of Computer Science and Technology, Harbin Institute of Technology, Weihai, China; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; Department of Computer Science, Hong Kong Baptist University, Hong Kong; Department of Computer Science, Hong Kong Baptist University, Hong Kong; School of Electronics, Electrical Engineering and Computer Science, Queen’s University of Belfast, Belfast, U.K.","IEEE Transactions on Intelligent Transportation Systems","","2018","19","1","187","198","For autonomous driving application, a car shall be able to track objects in the scene in order to estimate where and how they will move such that the tracker embedded in the car can efficiently alert the car for effective collision-avoidance. Traditional discriminative object tracking methods usually train a binary classifier via a support vector machine (SVM) scheme to distinguish the target from its background. Despite demonstrated success, the performance of the SVM-based trackers is limited because the classification is carried out only depending on support vectors (SVs) but the target's dynamic appearance may look similar to the training samples that have not been selected as SVs, especially when the training samples are not linearly classifiable. In such cases, the tracker may drift to the background and fail to track the target eventually. To address this problem, in this paper, we propose to integrate the point-to-set/image-to-imageSet distance metric learning (DML) into visual tracking tasks and take full advantage of all the training samples when determining the best target candidate. The point-to-set DML is conducted on convolutional neural network features of the training data extracted from the starting frames. When a new frame comes, target candidates are first projected to the common subspace using the learned mapping functions, and then the candidate having the minimal distance to the target template sets is selected as the tracking result. Extensive experimental results show that even without model update the proposed method is able to achieve favorable performance on challenging image sequences compared with several state-of-the-art trackers.","","","10.1109/TITS.2017.2766093","National Natural Science Foundation of China; RGC research grant; U.K. EPSRC; Royal Society-Newton Advanced Fellowship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115211","Metric learning;point to set;visual tracking","Target tracking;Visualization;Feature extraction;Manifolds;Training","feature extraction;image classification;image representation;image sequences;learning (artificial intelligence);neural nets;object detection;object tracking;support vector machines","image sequences;starting frames;convolutional neural network features;point-to-set/image-to-imageSet distance metric learning;traditional discriminative object tracking methods;point-to-set distance metric learning;target template sets;learned mapping functions;training data;visual tracking tasks;DML;training samples;dynamic appearance;SVM;support vector machine scheme;binary classifier;effective collision-avoidance;car;autonomous driving application;deep representations","","11","65","","","","","IEEE","IEEE Journals"
"SEMA: Deeply Learning Semantic Meanings and Temporal Dynamics for Recommendations","J. Zhang; C. Chow","Department of Computer Science, City University of Hong Kong, Hong Kong; Department of Computer Science, City University of Hong Kong, Hong Kong","IEEE Access","","2018","6","","54106","54116","Personalization plays an essential role in recommender systems, in which the key task is to predict the personalized rating of users on new items. Recommender systems usually apply collaborative filtering techniques to make rating prediction. In recent years, some studies pay attention on learning semantic meanings from textual content of items or temporal dynamics from historical information of users in order to improve rating prediction. However, these studies often apply shallow or flat modeling methods and model users and items in an asymmetrical manner; the improvement is considerably limited. In this paper, we propose a new recommendation framework called SEMA to deeply learn Semantic mEanings and teMporal dynAmics by developing hierarchical and symmetrical recurrent neural networks (RNNs). Our SEMA has three important characteristics: 1) deep learning-based: SEMA leverages deep learningbased models to capture semantic meanings from textual content and temporal dynamics from historical information rather than applying shallow methods, e.g., the bag-of-words method for textual content and the decay method for temporal dynamics; 2) hierarchical: SEMA learns both semantic meanings and temporal dynamics in a unified hierarchical RNN to mutually reinforce each other, instead of combining them flatly; and 3) symmetrical: SEMA symmetrically builds two hierarchical RNNs for users and items to model their own semantic meanings and temporal dynamics, because users and items are essentially dual in recommender systems. We conduct a comprehensive performance evaluation for SEMA using two large-scale real-world review data sets collected from Amazon and Yelp. Experimental results show that SEMA achieves significantly superior recommendation quality compared with other state-of-the-art recommendation techniques.","","","10.1109/ACCESS.2018.2871970","National Natural Science Foundation of China; Innovation and Technology Commission; City University of Hong Kong; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8471113","Collaborative filtering;rating prediction;semantic meanings;temporal dynamics;deep learning","Semantics;Recommender systems;Machine learning;Recurrent neural networks;Collaboration;Social network services;Predictive models","collaborative filtering;learning (artificial intelligence);recommender systems;recurrent neural nets","rating prediction;SEMA;semantic meanings;temporal dynamics;textual content;recommender systems;personalized rating;historical information;hierarchical recurrent neural networks;symmetrical recurrent neural networks;deep learning-based characteristics","","4","36","","","","","IEEE","IEEE Journals"
"Deep Learning Based Robot for Automatically Picking Up Garbage on the Grass","J. Bai; S. Lian; Z. Liu; K. Wang; D. Liu","School of Electronic Information Engineering, Beihang University, Beijing, China; AI Department, CloudMinds Technologies Inc., Beijing, China; AI Department, CloudMinds Technologies Inc., Beijing, China; AI Department, CloudMinds Technologies Inc., Beijing, China; National Key Laboratory of Wireless Mobile Communication, China Academy of Telecommunication Technology, Beijing, China","IEEE Transactions on Consumer Electronics","","2018","64","3","382","389","This paper presents a novel garbage pickup robot which operates on the grass. The robot is able to detect the garbage accurately and autonomously by using a deep neural network for garbage recognition. In addition, with the ground segmentation using a deep neural network, a novel navigation strategy is proposed to guide the robot to move around. With the garbage recognition and automatic navigation functions, the robot can clean garbage on the ground in places like parks or schools efficiently and autonomously. Experimental results show that the garbage recognition accuracy can reach as high as 95%, and even without path planning, the navigation strategy can reach almost the same cleaning efficiency with traditional methods. Thus, the proposed robot can serve as a good assistance to relieve dustman's physical labor on garbage cleaning tasks.","","","10.1109/TCE.2018.2859629","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8419288","Deep learning;garbage cleaning;robot navigation;ground segmentation","Robot kinematics;Navigation;Robot sensing systems;Image segmentation;Cleaning","image segmentation;intelligent robots;mobile robots;navigation;neurocontrollers;object detection;object recognition;path planning;robot vision;service robots","deep neural network;automatic navigation functions;garbage recognition accuracy;garbage cleaning tasks;ground segmentation;navigation strategy;garbage pickup robot;deep learning based robot;garbage detection;cleaning efficiency","","","22","","","","","IEEE","IEEE Journals"
"FunkR-pDAE: Personalized Project Recommendation Using Deep Learning","P. Zhang; F. Xiong; H. K. N. Leung; W. Song","College of Computer and Engieering, Hohai University, Nanjing, Jiangsu China (e-mail: pchzhang@hhu.edu.cn); College of Computer and Information, Hohai University, 12462 Nanjing, Jiangsu China (e-mail: 850338792@qq.com); Department of Computing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong Hong Kong (e-mail: hareton.leung@polyu.edu.hk); School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, Jiangsu China 210094 (e-mail: wsong@njust.edu.cn)","IEEE Transactions on Emerging Topics in Computing","","2018","PP","99","1","1","In open source communities, developers always need to spend plenty of time and energy on discovering specific projects from massive open source projects. Consequently, the study of personalized project recommendation for developers has important theoretical and practical significance. However, existing recommendation approaches have clear limitations, such as ignoring developers' operating behavior, social relationships and practical skills, and are very inefficient for large amounts of data. To address these limitations, this paper proposes FunkR-pDAE (Funk singular value decomposition Recommendation using pearson correlation coefficient and Deep Auto-Encoders), a novel personalized project recommendation approach using a deep learning model. FunkR-pDAE first extracts data related to developers and open source projects from open source communities, which build a developer-open source project relevance matrix and a developer-developer relevance matrix. Meanwhile, Pearson Correlation Coefficient is utilized to calculate developer similarity using the developer-developer relevance matrix. Second, deep auto-encoders are used to learn the factor vectors that represent developers and open source projects. Finally, a sorting method is defined to provide personalized project recommendations. Experimental results on real-world GitHub data sets show that FunkR-pDAE has a precision rate of 75.46% and a recall rate of 40.32%, which provides more effective recommendation compared with state-of-the-art approaches.","","","10.1109/TETC.2018.2870734","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8466656","Open Source;project recommendation;deep auto-encoder;GitHub","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Two-Stream Deep Architecture for Hyperspectral Image Classification","S. Hao; W. Wang; Y. Ye; T. Nie; L. Bruzzone","College of Communication and Electronic Engineering, Qingdao University of Technology, Qingdao, China; Department of Information Engineering and Computer Science, University of Trento, Trento, Italy; Faculty of Geosciences and Environmental Engineering, Southwest Jiaotong University, Chengdu, China; College of Communication and Electronic Engineering, Qingdao University of Technology, Qingdao, China; Department of Information Engineering and Computer Science, University of Trento, Trento, Italy","IEEE Transactions on Geoscience and Remote Sensing","","2018","56","4","2349","2361","Most traditional approaches classify hyperspectral image (HSI) pixels relying only on the spectral values of the input channels. However, the spatial context around a pixel is also very important and can enhance the classification performance. In order to effectively exploit and fuse both the spatial context and spectral structure, we propose a novel two-stream deep architecture for HSI classification. The proposed method consists of a two-stream architecture and a novel fusion scheme. In the two-stream architecture, one stream employs the stacked denoising autoencoder to encode the spectral values of each input pixel, and the other stream takes as input the corresponding image patch and deep convolutional neural networks are employed to process the image patch. In the fusion scheme, the prediction probabilities from two streams are fused by adaptive class-specific weights, which can be obtained by a fully connected layer. Finally, a weight regularizer is added to the loss function to alleviate the overfitting of the class-specific fusion weights. Experimental results on real HSIs demonstrate that the proposed two-stream deep architecture can achieve competitive performance compared with the state-of-the-art methods.","","","10.1109/TGRS.2017.2778343","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; Natural Science Foundation of Shandong Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8240968","Class-specific fusion;convolutional neural networks (CNNs);deep learning;hyperspectral image (HSI) classification;remote sensing;stacked denoising autoencoder (SdAE);two-stream architecture","Feature extraction;Machine learning;Hyperspectral imaging;Training","hyperspectral imaging;image classification;image denoising;image fusion;learning (artificial intelligence);neural net architecture;probability","spectral structure;two-stream deep architecture;HSI classification;two-stream architecture;fusion scheme;deep convolutional neural networks;hyperspectral image classification;classification performance enhancement;HSI pixels;stacked denoising autoencoder;spectral value encoding;image patch processing;prediction probabilities;adaptive class-specific weights;fully connected layer;weight regularizer;class-specific fusion weight overfitting","","10","58","","","","","IEEE","IEEE Journals"
"Language/Dialect Recognition Based on Unsupervised Deep Learning","Q. Zhang; J. H. L. Hansen","Center for Robust Speech Systems, Erik Jonsson School of Engineering University of Texas at Dallas, Richardson, TX, USA; Center for Robust Speech Systems, Erik Jonsson School of Engineering University of Texas at Dallas, Richardson, TX, USA","IEEE/ACM Transactions on Audio, Speech, and Language Processing","","2018","26","5","873","882","Over the past decade, bottleneck features within an i-Vector framework have been used for state-of-the-art language/dialect identification (LID/DID). However, traditional bottleneck feature extraction requires additional transcribed speech information. Alternatively, two types of unsupervised deep learning methods are introduced in this study. To address this limitation, an unsupervised bottleneck feature extraction approach is proposed, which is derived from the traditional bottleneck structure but trained with estimated phonetic labels. In addition, based on a generative modeling autoencoder, two types of latent variable learning algorithms are introduced for speech feature processing, which have been previous considered for image processing/reconstruction. Specifically, a variational autoencoder and adversarial autoencoder are utilized on alternative phase of speech processing. To demonstrate the effectiveness of the proposed methods, three corpora are evaluated: 1) a four Chinese dialect dataset, 2) a five Arabic dialect corpus, and 3) multigenre broadcast challenge corpus (MGB-3) for arabic DID. The proposed features are shown to outperform traditional acoustic feature MFCCs consistently across three corpora. Taken collectively, the proposed features achieve up to a relative +58% improvement in Cavg for LID/DID without the need of any secondary speech corpora.","","","10.1109/TASLP.2018.2797420","Air Force Research Laboratory; University of Texas at Dallas from the Distinguished University Chair in Telecommunications Engineering held by J. H. L. Hansen; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8268099","Language/Dialect recognition;unsupervised learning;variational autoencoder;adversarial autoencoder;bottleneck feature;phonetic label estimation","Feature extraction;Acoustics;Speech;Training;Hidden Markov models;Speech processing;Speech recognition","feature extraction;natural language processing;speech coding;speech recognition;unsupervised learning","additional transcribed speech information;unsupervised deep learning methods;unsupervised bottleneck feature extraction approach;estimated phonetic labels;generative modeling autoencoder;latent variable learning algorithms;speech feature processing;variational autoencoder;adversarial autoencoder;speech processing;Arabic dialect corpus;i-Vector framework;state-of-the-art language/dialect;feature extraction;dialect recognition","","3","36","","","","","IEEE","IEEE Journals"
"Classification of Hyperspectral Imagery Using a New Fully Convolutional Neural Network","J. Li; X. Zhao; Y. Li; Q. Du; B. Xi; J. Hu","State Key Laboratory of Integrated Service Networks, School of Telecommunications Engineering, Xidian University, Xi’an, China; State Key Laboratory of Integrated Service Networks, School of Telecommunications Engineering, Xidian University, Xi’an, China; State Key Laboratory of Integrated Service Networks, School of Telecommunications Engineering, Xidian University, Xi’an, China; Department of Electronic and Computer Engineering, Mississippi State University, Starkville, MS, USA; State Key Laboratory of Integrated Service Networks, School of Telecommunications Engineering, Xidian University, Xi’an, China; State Key Laboratory of Integrated Service Networks, School of Telecommunications Engineering, Xidian University, Xi’an, China","IEEE Geoscience and Remote Sensing Letters","","2018","15","2","292","296","With success of convolutional neural networks (CNNs) in computer vision, the CNN has attracted great attention in hyperspectral classification. Many deep learning-based algorithms have been focused on deep feature extraction for classification improvement. In this letter, a novel deep learning framework for hyperspectral classification based on a fully CNN is proposed. Through convolution, deconvolution, and pooling layers, the deep features of hyperspectral data are enhanced. After feature enhancement, the optimized extreme learning machine (ELM) is utilized for classification. The proposed framework outperforms the existing CNN and other traditional classification algorithms by including deconvolution layers and an optimized ELM. Experimental results demonstrate that it can achieve outstanding hyperspectral classification performance.","","","10.1109/LGRS.2017.2786272","National Nature Science Foundation of China; 111 Project; Fundamental Research Funds for the Central Universities; Natural Science Basic Research Plan in Shaanxi Province of China; China Postdoctoral Science Foundation under General Financial; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8249752","Convolution;deconvolution;deep learning;extreme learning machine (ELM);feature enhancement;hyperspectral classification","Hyperspectral imaging;Feature extraction;Deconvolution;Convolution;Training;Principal component analysis","computer vision;convolution;feature extraction;feedforward neural nets;image classification;learning (artificial intelligence)","hyperspectral imagery classification;fully convolutional neural network;hyperspectral data enhancement;deconvolution layers;optimized extreme learning machine;feature enhancement;deep learning framework;deep feature extraction;computer vision","","17","16","","","","","IEEE","IEEE Journals"
"Simple learning method to guarantee operational range of optical monitors","T. Tanimura; T. Hoshida; T. Kato; S. Watanabe; H. Morikawa","Fujitsu Laboratories Ltd., 4-1-1 Kamikodanaka, Nakahara-ku, Kawasaki 211-8588, Japan; Fujitsu Laboratories Ltd., 4-1-1 Kamikodanaka, Nakahara-ku, Kawasaki 211-8588, Japan; Fujitsu Labs. Ltd., Kawasaki, Japan; Fujitsu Laboratories Ltd., 4-1-1 Kamikodanaka, Nakahara-ku, Kawasaki 211-8588, Japan; School of Engineering, the University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo 113-8656, Japan","IEEE/OSA Journal of Optical Communications and Networking","","2018","10","10","D63","D71","It is necessary to guarantee the operational range of machine learning (ML)-based optical physicallayer monitors (OPMs). To declare high-level monitoring objectives and obtain their values from OPMs, finding a methodology to accurately estimate the value of a target quantity and ensure their operational range is necessary. We introduce a deep neural network (DNN) with a digital coherent receiver to ML-based OPMs to deal with the abundance of training data needed for convergence and the preprocessing of input data by human engineers needed for feature (representation) extraction. However, guaranteeing the operational range of trained models on DNN-based OPMs was left for another investigation. To address this issue with DNN-based OPMs, we propose an ""operational range expander,"" a simple treatment of the link between pre-processing training datasets and their specified operational range. We assess the operational range expander by performing simulation and experimentation using a DNNbased optical signal-to-noise ratio (OSNR) estimator. We select a laser frequency offset between a signal and a local oscillator in digital coherent receivers as an example quantity for a practical operational range expander in this study. This is because the OPMs need to work before digitally compensating frequency offset despite the difficulty in fully controlling frequency offset in practical situations. We evaluate bias errors and standard deviations of OSNR estimation from different frequency offsets ranging from -3.5 to 3.5 GHz and confirm that the provided operational range expander specified the operational range of DNNbased OSNR estimators through their training phase.","","","10.1364/JOCN.10.000D63","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8501528","Digital coherent reception; Machine learning;Optical fiber communication; Optical performancemonitoring.","Monitoring;Optical receivers;Signal to noise ratio;Training;Optical noise;Optical polarization","learning (artificial intelligence);neural nets;optical receivers;telecommunication computing","digital coherent receiver;ML-based OPMs;DNN-based OPMs;practical operational range expander;machine learning-based optical physicallayer monitors;operational range expander;optical monitors;deep neural network;optical signal-to-noise ratio estimator;laser frequency offset;local oscillator;frequency -3.5 GHz to 3.5 GHz","","1","","","","","","IEEE","IEEE Journals"
"Cross-Project Transfer Representation Learning for Vulnerable Function Discovery","G. Lin; J. Zhang; W. Luo; L. Pan; Y. Xiang; O. De Vel; P. Montague","School of Information Technology, Deakin University, Geelong, VIC, Australia; School of Software and Electrical Engineering, Swinburne University of Technology, Melbourne, VIC, Australia; School of Information Technology, Deakin University, Geelong, VIC, Australia; School of Information Technology, Deakin University, Geelong, VIC, Australia; Digital Research & Innovation Capability Platform, Swinburne University of Technology, Melbourne, VIC, Australia; Department of Defence, Defence Science & Technology Group, Maribyrnong, VIC, Australia; Department of Defence, Defence Science & Technology Group, Maribyrnong, VIC, Australia","IEEE Transactions on Industrial Informatics","","2018","14","7","3289","3297","Machine learning is now widely used to detect security vulnerabilities in the software, even before the software is released. But its potential is often severely compromised at the early stage of a software project when we face a shortage of high-quality training data and have to rely on overly generic hand-crafted features. This paper addresses this cold-start problem of machine learning, by learning rich features that generalize across similar projects. To reach an optimal balance between feature-richness and generalizability, we devise a data-driven method including the following innovative ideas. First, the code semantics are revealed through serialized abstract syntax trees (ASTs), with tokens encoded by Continuous Bag-of-Words neural embeddings. Next, the serialized ASTs are fed to a sequential deep learning classifier (Bi-LSTM) to obtain a representation indicative of software vulnerability. Finally, the neural representation obtained from existing software projects is then transferred to the new project to enable early vulnerability detection even with a small set of training labels. To validate this vulnerability detection approach, we manually labeled 457 vulnerable functions and collected 30 000+ nonvulnerable functions from six open-source projects. The empirical results confirmed that the trained model is capable of generating representations that are indicative of program vulnerability and is adaptable across multiple projects. Compared with the traditional code metrics, our transfer-learned representations are more effective for predicting vulnerable functions, both within a project and across multiple projects.","","","10.1109/TII.2018.2821768","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8329207","Abstract syntax tree;cross-project;representation learning;transfer learning;vulnerability discovery","Software;Feature extraction;Syntactics;Semantics;Australia;Programming;Informatics","learning (artificial intelligence);neural nets;security of data;software engineering","cross-project transfer representation learning;vulnerable function discovery;machine learning;software project;high-quality training data;cold-start problem;data-driven method;serialized abstract syntax trees;Continuous Bag-of-Words neural embeddings;serialized ASTs;sequential deep learning classifier;representation indicative;software vulnerability;neural representation;early vulnerability detection;training labels;vulnerability detection approach;open-source projects;program vulnerability;multiple projects;transfer-learned representations;software security vulnerabilities;generic hand-crafted features","","6","26","","","","","IEEE","IEEE Journals"
"MIDAS: Model-Independent Training Data Selection Under Cost Constraints","G. Joo; C. Kim","National Association of Cognitive Science Industries, Institute of Cognitive Intelligence, Seoul, South Korea; Sookmyung Women’s University, Seoul, South Korea","IEEE Access","","2018","6","","74462","74474","In general, as the amount of training data is increased, a deep learning model gains a higher training accuracy. To assign labels to training data for use in supervised learning, human resources are required, which incur temporal and economic costs. Therefore, if a sufficient amount of training data cannot be constructed owing to existing cost constraints, it becomes necessary to select the training data that can maximize the accuracy of the deep learning model with only a limited amount of training data. However, although conventional studies on such training data selections take into consideration the training data labeling cost, the selection cost required in the training data selection process is not taken into consideration, which is a problem. Therefore, with the consideration of the selection cost constraint in addition to the data labeling cost constraint, we introduce a training data selection problem and propose novel algorithms to solve it. The advantage of the proposed algorithms is that they can be applied to any network model or data model of deep learning. The performance was verified through experiments using various network models and data.","","","10.1109/ACCESS.2018.2882269","Ministry of Culture, Sports and Tourism; National Research Foundation of Korea; Sookmyung Women’s University Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8540354","Training data selection;cost constraints;model-independent;deep learning;active learning;machine learning;artificial intelligence","Data models;Training data;Labeling;Training;Computational modeling;Supervised learning","learning (artificial intelligence)","training data labeling cost;selection cost constraint;data labeling cost constraint;network models;model-independent training data selection;cost constraints;deep learning model;MIDAS","","","28","","","","","IEEE","IEEE Journals"
"A Mathematical Theory of Deep Convolutional Neural Networks for Feature Extraction","T. Wiatowski; H. Bölcskei","Department of Information Technology and Electrical Engineering, ETH Zürich, Zürich, Switzerland; Department of Information Technology and Electrical Engineering, ETH Zürich, Zürich, Switzerland","IEEE Transactions on Information Theory","","2018","64","3","1845","1866","Deep convolutional neural networks (DCNNs) have led to breakthrough results in numerous practical machine learning tasks, such as classification of images in the ImageNet data set, control-policy-learning to play Atari games or the board game Go, and image captioning. Many of these applications first perform feature extraction and then feed the results thereof into a classifier. The mathematical analysis of DCNNs for feature extraction was initiated by Mallat, 2012. Specifically, Mallat considered so-called scattering networks based on a wavelet transform followed by the modulus non-linearity in each network layer, and proved translation invariance (asymptotically in the wavelet scale parameter) and deformation stability of the corresponding feature extractor. This paper complements Mallat's results by developing a theory that encompasses general convolutional transforms, or in more technical parlance, general semi-discrete frames (including Weyl-Heisenberg filters, curvelets, shearlets, ridgelets, wavelets, and learned filters), general Lipschitz-continuous non-linearities (e.g., rectified linear units, shifted logistic sigmoids, hyperbolic tangents, and modulus functions), and general Lipschitz-continuous pooling operators emulating, e.g., sub-sampling and averaging. In addition, all of these elements can be different in different network layers. For the resulting feature extractor, we prove a translation invariance result of vertical nature in the sense of the features becoming progressively more translation-invariant with increasing network depth, and we establish deformation sensitivity bounds that apply to signal classes such as, e.g., band-limited functions, cartoon functions, and Lipschitz functions.","","","10.1109/TIT.2017.2776228","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8116648","Machine learning;deep convolutional neural networks;scattering networks;feature extraction;frame theory","Feature extraction;Strain;Wavelet transforms;Convolution;Sensitivity;Scattering","feature extraction;image classification;learning (artificial intelligence);mathematical analysis;neural nets;wavelet transforms","image captioning;feature extraction;mathematical analysis;DCNNs;scattering networks;modulus nonlinearity;network layer;wavelet scale parameter;general convolutional transforms;learned filters;rectified linear units;general Lipschitz-continuous pooling operators;network depth;mathematical theory;deep convolutional neural networks;ImageNet data set;control-policy-learning;Atari games;board game;deformation sensitivity bounds;general Lipschitz-continuous nonlinearities;semidiscrete frames;deformation stability;wavelet transform;image classification;translation-invariant;machine learning tasks;feature extractor","","13","84","","","","","IEEE","IEEE Journals"
"Inverse Tone Mapping Operator Using Sequential Deep Neural Networks Based on the Human Visual System","H. Jang; K. Bang; J. Jang; D. Hwang","School of Electrical and Electronic Engineering, Yonsei University College of Engineering, Seoul, South Korea; School of Electrical and Electronic Engineering, Yonsei University College of Engineering, Seoul, South Korea; School of Electrical and Electronic Engineering, Yonsei University College of Engineering, Seoul, South Korea; School of Electrical and Electronic Engineering, Yonsei University College of Engineering, Seoul, South Korea","IEEE Access","","2018","6","","52058","52072","Conventional digital displays show images with much less dynamic range than that of human visual perception. High-dynamic range (HDR) displays are being developed for viewing images with higher dynamic range than that of conventional low-dynamic range (LDR) images. However, to view existing LDR images on HDR displays, an inverse tone mapping operator (ITMO), which is a process to extend the dynamic range of LDR images, is required. In this paper, we propose an adaptive ITMO by effectively learning the differences between LDR and HDR images using a sequential learning process: dynamic range learning followed by color difference learning. Our proposed method enables visualization of colors similar to real-world colors better than conventional ITMOs by learning color differences based on the human visual system properties. For the objective comparison, seven different evaluation metrics optimized for HDR image evaluation were used. Our method resulted in 10%-25% improved HDR-visual difference predictor-2.2 values over those of other ITMOs. Other metrics also demonstrated the superior performance of our method. For the subjective comparison, eight human observers evaluated the estimated HDR images in terms of color appearance and overall preferences. Our method received an average 4.7 out of 5 score, whereas other ITMOs received below 3.5 scores in the evaluation of color appearance. The objective and subjective evaluations' results showed that our proposed method outperformed the conventional ITMOs in estimating the dynamic range and color appearance of ground-truth HDR images.","","","10.1109/ACCESS.2018.2870295","Samsung; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8466589","Color difference;deep neural network;high dynamic range;inverse tone mapping operator;human visual system","Image color analysis;Dynamic range;Cameras;Visual systems;Neural networks;Image resolution;Machine learning","computer vision;image colour analysis;learning (artificial intelligence);neural nets;visual perception","sequential deep neural networks;human visual perception;high-dynamic range displays;low-dynamic range images;HDR displays;adaptive ITMO;sequential learning process;dynamic range learning;color difference learning;human visual system properties;HDR image evaluation;color appearance;digital displays;LDR images;evaluation metrics;adaptive inverse tone mapping operator;HDR-visual difference predictor","","1","57","","","","","IEEE","IEEE Journals"
"Superpixel Guided Deep-Sparse-Representation Learning for Hyperspectral Image Classification","J. Fan; T. Chen; S. Lu","Institute for Infocomm Research, Singapore; Institute for Infocomm Research, Singapore; Nanyang Technological University, Singapore","IEEE Transactions on Circuits and Systems for Video Technology","","2018","28","11","3163","3173","This paper presents a new technique for hyperspectral image (HSI) classification by using superpixel guided deep-sparse-representation learning. The proposed technique constructs a hierarchical architecture by exploiting the sparse coding to learn the HSI representation. Specifically, a multiple-layer architecture using different superpixel maps is designed, where each superpixel map is generated by downsampling the superpixels gradually along with enlarged spatial regions for labeled samples. In each layer, sparse representation of pixels within every spatial region is computed to construct a histogram via the sum-pooling with l1normalization. Finally, the representations (features) learned from the multiple-layer network are aggregated and trained by a support vector machine classifier. The proposed technique has been evaluated over three public HSI data sets, including the Indian Pines image set, the Salinas image set, and the University of Pavia image set. Experiments show superior performance compared with the state-of-the-art methods.","","","10.1109/TCSVT.2017.2746684","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8022877","Hyperspectral;classification;superpixel;sparse representation","Feature extraction;Encoding;Image segmentation;Principal component analysis;Support vector machines;Image edge detection;Correlation","feature extraction;hyperspectral imaging;image classification;image coding;image representation;learning (artificial intelligence);neural nets;support vector machines","enlarged spatial regions;multiple-layer network;public HSI data sets;Indian Pines image set;Salinas image set;deep-sparse-representation learning;hyperspectral image classification;sparse coding;HSI representation;multiple-layer architecture;superpixel maps;superpixel guided deep-sparse-representation learning;hierarchical architecture;superpixel downsampling;l1normalization;sum-pooling;support vector machine classifier;University of Pavia image set;HSI","","1","47","","","","","IEEE","IEEE Journals"
"(DE)$^2$CO: Deep Depth Colorization","F. M. Carlucci; P. Russo; B. Caputo","Department of Computer, Control, and Management Engineering Antonio Ruberti, Sapienza Rome University, Rome, Italy; Department of Computer, Control, and Management Engineering Antonio Ruberti, Sapienza Rome University, Rome, Italy; Department of Computer, Control, and Management Engineering Antonio Ruberti, Sapienza Rome University, Rome, Italy","IEEE Robotics and Automation Letters","","2018","3","3","2386","2393","The ability to classify objects is fundamental for robots. Besides knowledge about their visual appearance, captured by the RGB channel, robots heavily need also depth information to make sense of the world. While the use of deep networks on RGB robot images has benefited from the plethora of results obtained on databases like ImageNet, using convnets on depth images requires mapping them into three-dimensional channels. This transfer learning procedure makes them processable by pretrained deep architectures. Current mappings are based on heuristic assumptions over preprocessing steps and on what depth properties should be most preserved, resulting often in cumbersome data visualizations, and in suboptimal performance in terms of generality and recognition results. Here, we take an alternative route and we attempt instead to learn an optimal colorization mapping for any given pretrained architecture, using as training data a reference RGB-D database. We propose a deep network architecture, exploiting the residual paradigm, that learns how to map depth data to three channel images. A qualitative analysis of the images obtained with this approach clearly indicates that learning the optimal mapping preserves the richness of depth information better than current hand-crafted approaches. Experiments on the Washington, JHUIT-50 and BigBIRD public benchmark databases, using CaffeNet, VGG-16, GoogleNet, and ResNet50 clearly showcase the power of our approach, with gains in performance of up to 16% compared to state of the art competitors on the depth channel only, leading to top performances when dealing with RGB-D data.","","","10.1109/LRA.2018.2812225","CHIST-ERA Project ALOOF; ERC; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8306886","RGB-D perception;recognition;visual learning","Databases;Computer architecture;Feature extraction;Visualization;Training;Robot sensing systems","data visualisation;image classification;image colour analysis;learning (artificial intelligence);neural nets;pattern classification","cumbersome data visualizations;suboptimal performance;recognition results;optimal colorization mapping;deep network architecture;map depth data;channel images;optimal mapping;depth information;depth channel;RGB-D data;deep depth colorization;robots;visual appearance;RGB channel;deep networks;RGB robot images;depth images;three-dimensional channels;transfer learning procedure;pretrained deep architectures;current mappings;heuristic assumptions;preprocessing steps;depth properties;hand-crafted approaches;pretrained architecture;JHUIT-50;BigBIRD public benchmark databases","","4","36","","","","","IEEE","IEEE Journals"
"MIO-TCD: A New Benchmark Dataset for Vehicle Classification and Localization","Z. Luo; F. Branchaud-Charron; C. Lemaire; J. Konrad; S. Li; A. Mishra; A. Achkar; J. Eichel; P. Jodoin","Postdoc Center of Information and Communication Engineering, Xiamen University, Xiamen, China; Computer Science Department, University of Sherbrooke, Sherbrooke, Canada; Computer Science Department, University of Sherbrooke, Sherbrooke, Canada; Department of Electrical and Computer Engineering, Boston University, Boston, MA, USA; Cognitive Science Department, Xiamen University, Xiamen, China; Systems Design Engineering Department, University of Waterloo, Waterloo, Canada; Miovision Technologies Inc., Kitchener, Canada; Miovision Technologies Inc., Kitchener, Canada; Computer Science Department, University of Sherbrooke, Sherbrooke, Canada","IEEE Transactions on Image Processing","","2018","27","10","5129","5141","The ability to train on a large dataset of labeled samples is critical to the success of deep learning in many domains. In this paper, we focus on motor vehicle classification and localization from a single video frame and introduce the “Miovision traffic camera dataset” (MIO-TCD) in this context. MIO-TCD is the largest dataset for motorized traffic analysis to date. It includes 11 traffic object classes such as cars, trucks, buses, motorcycles, bicycles, and pedestrians. It contains 786 702 annotated images acquired at different times of the day and different periods of the year by hundreds of traffic surveillance cameras deployed across Canada and the United States. The dataset consists of two parts: a “localization dataset,” containing 137 743 full video frames with bounding boxes around traffic objects and a “classification dataset,” containing 648 959 crops of traffic objects from the 11 classes. We also report the results from the 2017 CVPR MIO-TCD Challenge that leveraged this dataset and compare them with the results of the state-of-the-art deep learning architectures. These results demonstrate the viability of deep learning methods for vehicle localization and classification from a single video frame in real-life traffic scenarios. The top-performing methods achieve both accuracy and Kappa score above 96% on the classification dataset and mean-average precision of 77% on the localization dataset. We also identify the scenarios in which the state-of-the-art methods still fail, and we suggest avenues to address these challenges. Both the dataset and detailed results are publicly available online.","","","10.1109/TIP.2018.2848705","National Natural Science Foundation of China; Fujian Province 2011 Collaborative Innovation Center of TCM Health Management and the Collaborative Innovation Center of Chinese Oolong Tea Industry-Collaborative Innovation Center (2011) of Fujian Province; Fund for Integration of Cloud Computing and Big Data, Innovation of Science and Education; Fonds Québécois de la Recherche sur la Nature et les Technologies; Mitacs; Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8387876","Traffic analysis;deep learning;vehicle localization;vehicle classification","Cameras;Automobiles;Surveillance;Machine learning;Object recognition;Feature extraction;Benchmark testing","cameras;image classification;learning (artificial intelligence);object detection;traffic engineering computing;video surveillance","real-life traffic scenarios;vehicle localization;deep learning methods;state-of-the-art deep learning architectures;classification dataset;traffic objects;localization dataset;traffic surveillance cameras;motorized traffic analysis;traffic camera dataset;single video frame;motor vehicle classification;benchmark dataset;mean-average precision;Kappa score;CVPR MIO-TCD Challenge;full video frames;traffic object classes","","4","48","","","","","IEEE","IEEE Journals"
"Deep Takagi–Sugeno–Kang Fuzzy Classifier With Shared Linguistic Fuzzy Rules","Y. Zhang; H. Ishibuchi; S. Wang","School of Digital Media, Jiangnan University, Wuxi, China; Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, Guangdong, China; School of Digital Media, Jiangnan University, Wuxi, China","IEEE Transactions on Fuzzy Systems","","2018","26","3","1535","1549","In many practical applications of classifiers, not only high accuracy but also high interpretability is required. Among a wide variety of existing classifiers, Takagi-Sugeno-Kang (TSK) fuzzy classifiers may be one of the best choices for achieving a good balance between interpretability and accuracy. In order to further improve their accuracy without losing their interpretability, we propose a highly interpretable deep TSK fuzzy classifier HID-TSK-FC (deep shared-linguistic-rule-based TSK fuzzy classifier) based on the concept of shared linguistic fuzzy rules. The proposed classifier has two characteristics: One is a stacked hierarchical structure of component TSK fuzzy classifiers for high accuracy, and the other is the use of interpretable linguistic rules with the same set of linguistic labels for all inputs. High interpretability is achieved at each layer by using the same set of linguistic values for all inputs, including the outputs from the previous layers in the stacked hierarchical structure. We show that a linguistic rule with the outputs from the previous layers as its inputs is equivalent to a fuzzy rule with a nonlinear consequent or a linear consequent with a certainty factor. We also show that HID-TSK-FC is mathematically equivalent to a novel TSK fuzzy classifier with shared interpretable linguistic fuzzy rules. Promising performance of HID-TSK-FC is demonstrated through extensive computational experiments on benchmark datasets and a real-world application case.","","","10.1109/TFUZZ.2017.2729507","Japan Society for the Promotion of Science (JSPS); National Natural Science Foundation of China; NSFC-JSPS; Natural Science Foundation of Jiangsu Province; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7984865","Deep learning;linguistically interpretable fuzzy rules;shared membership functions;stacked generalization;Takagi–Sugeno–Kang (TSK) fuzzy classifiers","Pragmatics;Fuzzy sets;Takagi-Sugeno model;Machine learning;Optimization;Complexity theory;Pattern classification","computational linguistics;fuzzy neural nets;fuzzy reasoning;fuzzy set theory;knowledge based systems;learning (artificial intelligence);pattern classification","stacked hierarchical structure;component TSK fuzzy classifiers;interpretable linguistic rules;linguistic labels;linguistic values;fuzzy rule;shared interpretable linguistic fuzzy rules;deep-Takagi-Sugeno-Kang fuzzy classifier;highly interpretable deep TSK fuzzy classifier;HID-TSK-FC","","1","58","","","","","IEEE","IEEE Journals"
"Co-Salient Object Detection Based on Deep Saliency Networks and Seed Propagation Over an Integrated Graph","D. Jeong; I. Hwang; N. I. Cho","Department of Electrical and Computer Engineering, Seoul National University, Seoul, South Korea; Department of Electrical and Computer Engineering, Seoul National University, Seoul, South Korea; Department of Electrical and Computer Engineering, Seoul National University, Seoul, South Korea","IEEE Transactions on Image Processing","","2018","27","12","5866","5879","This paper presents a co-salient object detection method to find common salient regions in a set of images. We utilize deep saliency networks to transfer co-saliency prior knowledge and better capture high-level semantic information. The resulting initial co-saliency maps are enhanced by seed propagation steps over an integrated graph. The deep saliency networks are trained in a supervised manner to avoid weakly supervised online learning and exploit them not only to extract high-level features but also to produce both intra- and inter-image saliency maps. Through a refinement step, the initial co-saliency maps can uniformly highlight co-salient regions and locate accurate object boundaries. To handle input image groups inconsistent in size, we propose to pool multi-regional descriptors including both within-segment and within-group information. In addition, the integrated multilayer graph is constructed to find the regions that the previous steps may not detect by seed propagation with low-level descriptors. In this paper, we utilize the useful complementary components of high- and low-level information and several learning-based steps. Our experiments have demonstrated that the proposed approach outperforms comparable co-saliency detection methods on widely used public databases and can also be directly applied to co-segmentation tasks.","","","10.1109/TIP.2018.2859752","Korean National Police Agency; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8419754","Co-saliency;saliency;deep saliency networks;seed propagation model;foreground probability","Image segmentation;Feature extraction;Saliency detection;Object detection;Supervised learning;Semantics","feature extraction;graph theory;image segmentation;learning (artificial intelligence);object detection","inter-image saliency maps;co-salient regions;accurate object boundaries;multiregional descriptors;high-level semantic information;initial co-saliency maps;input image groups;high-level features;weakly supervised online learning;seed propagation steps;co-saliency prior knowledge;common salient regions;co-salient object detection method;integrated graph;deep saliency networks;comparable co-saliency detection methods;learning-based steps;low-level information;integrated multilayer graph","","1","59","","","","","IEEE","IEEE Journals"
"Convolutional Neural Networks for Automatic State-Time Feature Extraction in Reinforcement Learning Applied to Residential Load Control","B. J. Claessens; P. Vrancx; F. Ruelens","Restore, Antwerp, Belgium; AI-Laboratory, Vrije Universiteit Brussel, Brussels, Belgium; Department of Electrical Engineering, KU Leuven/EnergyVille, Leuven, Belgium","IEEE Transactions on Smart Grid","","2018","9","4","3259","3269","Direct load control of a heterogeneous cluster of residential demand flexibility sources is a high-dimensional control problem with partial observability. This paper proposes a novel approach that uses a convolutional neural network (CNN) to extract hidden state-time features to mitigate the curse of partial observability. More specific, a CNN is used as a function approximator to estimate the state-action value function or Q-function in the supervised learning step of fitted Q-iteration. The approach is evaluated in a qualitative simulation, comprising a cluster of thermostatically controlled loads that only share their air temperature, while their envelope temperature remains hidden. The simulation results show that the presented approach is able to capture the underlying hidden features and able to successfully reduce the electricity cost the cluster.","","","10.1109/TSG.2016.2629450","IWT-SBO-SMILE-IT/140047, funded by the Flemish Agency for Innovation through Science IWT through Science and Technology, promoting Strategic Basic Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7745941","Convolutional neural network;deep learning;demand response;reinforcement learning","Feature extraction;Optimization;Neural networks;Learning (artificial intelligence);Load flow control;Observability;Vehicle dynamics","demand side management;feature extraction;function approximation;learning (artificial intelligence);load regulation;neural nets;thermostats","reinforcement learning;fitted Q-iteration;qualitative simulation;electricity cost;air temperature;thermostatically controlled loads;supervised learning step;state-action value function;function approximator;hidden state-time features;CNN;partial observability;high-dimensional control problem;residential demand flexibility sources;heterogeneous cluster;direct load control;residential load control;automatic state-time feature extraction;convolutional neural network","","8","50","","","","","IEEE","IEEE Journals"
"Unconstrained Face Recognition Using a Set-to-Set Distance Measure on Deep Learned Features","J. Zhao; J. Han; L. Shao","Department of Computer and Information Sciences, Northumbria University, Newcastle upon Tyne, U.K.; School of Computing and Communications, Lancaster University, Lancaster, U.K.; School of Computing Sciences, University of East Anglia, Norwich, U.K.","IEEE Transactions on Circuits and Systems for Video Technology","","2018","28","10","2679","2689","Recently considerable efforts have been dedicated to unconstrained face recognition, which requires to identify faces “in the wild” for a set of images and/or video frames captured without human intervention. Unlike traditional face recognition that compares one-to-one media (either a single image or a video frame) only, we encounter a problem of matching sets with heterogeneous contents containing both images and videos. In this paper, we propose a novel set-to-set (S2S) distance measure to calculate the similarity between two sets with the aim to improve the recognition accuracy for faces with real-world challenges, such as extreme poses or severe illumination conditions. Our S2S distance adopts the kNN-average pooling for the similarity scores computed on all the media in two sets, making the identification far less susceptible to the poor representations (outliers) than traditional feature-average pooling and score-average pooling. Furthermore, we show that various metrics can be embedded into our S2S distance framework, including both predefined and learned ones. This allows to choose the appropriate metric depending on the recognition task in order to achieve the best results. To evaluate the proposed S2S distance, we conduct extensive experiments on the challenging set-based IJB-A face data set, which demonstrate that our algorithm achieves the state-of-the-art results and is clearly superior to the baselines, including several deep learning-based face recognition algorithms.","","","10.1109/TCSVT.2017.2710120","Royal Society; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7936556","Face recognition;IJB-A;S2S distance;kNN-average pooling","Face;Face recognition;Media;Measurement;Feature extraction;Probes;Lighting","face recognition;feature extraction;learning (artificial intelligence)","deep learning-based face recognition algorithms;set-based IJB-A face data set;recognition task;S2S distance framework;score-average pooling;traditional feature-average pooling;kNN-average pooling;recognition accuracy;novel set-to-set distance measure;video frame;single image;traditional face recognition;deep learned features;unconstrained face recognition","","3","50","","","","","IEEE","IEEE Journals"
"Learning Time-Frequency Analysis in Wireless Sensor Networks","Z. Sun; L. Zhou; W. Wang","Key Laboratory of Universal Wireless Communications, Ministry of Education, Beijing University of Posts and Telecommunications, Beijing, China; Key Laboratory of Universal Wireless Communications, Ministry of Education, Beijing University of Posts and Telecommunications, Beijing, China; Key Laboratory of Universal Wireless Communications, Ministry of Education, Beijing University of Posts and Telecommunications, Beijing, China","IEEE Internet of Things Journal","","2018","5","5","3388","3396","Time-frequency analysis is one of essential signal processing tool for wireless sensor signal in Internet of Things (IoT), but its traditional processing approaches, such as short time-frequency transformation (STFT) and discrete wavelet transformation (DWT), are challenged by the limitation of capability to self-learn from unknown environments and adjust parameters adaptively. To address this problem, we propose to build up the deep learning network to learn time-frequency analysis to instead of traditional STFT and DWT approaches. With using typical neural network layers to remodel STFT and DWT operations, the proposed models consider the efficiency on both training and processing procedures and show their parameter adaptability and capability of deep feature extraction from sensor signals. Moreover, we demonstrate how to integrate learning time-frequency analysis networks into practical IoT applications, signal detection in noisy environment, and classifying of various modulated wireless sensor signal, by which their performance are further evaluated in terms of computation complexity and efficiency.","","","10.1109/JIOT.2017.2771514","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8100870","Deep learning;time-frequency analysis;wireless sensor network (WSN)","Time-frequency analysis;Discrete wavelet transforms;Signal resolution;Feature extraction;Wireless sensor networks;Convolution","discrete wavelet transforms;feature extraction;Internet of Things;learning (artificial intelligence);neural nets;signal detection;time-frequency analysis;wireless sensor networks","wireless sensor networks;discrete wavelet transformation;deep learning network;typical neural network layers;modulated wireless sensor signal;signal processing tool;time-frequency analysis networks;deep feature extraction;STFT operations;DWT operations","","2","19","","","","","IEEE","IEEE Journals"
"Deep Multi-Task Network for Learning Person Identity and Attributes","P. Chikontwe; H. J. Lee","Department of Computer Science and Engineering, Chonbuk National University, Jeonju, South Korea; Department of Computer Science and Engineering, Chonbuk National University, Jeonju, South Korea","IEEE Access","","2018","6","","60801","60811","Person re-identification (re-ID) has been gaining in popularity in the research community owing to its numerous applications and growing importance in the surveillance industry. Recent methods often employ partial features for person re-ID and offer fine-grained information beneficial for person retrieval. In this paper, we focus on learning improved partial discriminative features using a deep convolutional neural architecture, which includes a pyramid spatial pooling module for efficient person feature representation. Furthermore, we propose a multi-task convolutional network that learns both personal attributes and identities in an end-to-end framework. Our approach incorporates partial features and global features for identity and attribute prediction, respectively. Experiments on several large-scale person re-ID benchmark data sets demonstrate the accuracy of our approach. For example, we report rank-1 accuracies of 85.37% (+3.47 %) and 92.81% (+0.51 %) on the DukeMTMC re-ID and Market-1501 data sets, respectively. The proposed method shows encouraging improvements compared with the state-of-the-art methods.","","","10.1109/ACCESS.2018.2875783","National Research Foundation of Korea; Ministry of Science and ICT (MSIT), South Korea, through the Information Technology Research Centre (ITRC) Support Program supervised by the Institute for Information and communication Technology Promotion (IITP); Technological Innovation R&D Program through the Small and Medium Business Administration (SMBA), South Korea; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8490820","Attribute recognition;convolutional neural networks (CNNs);deep learning;person re-identification","Feature extraction;Task analysis;Cameras;Image color analysis;Measurement;Surveillance;Benchmark testing","biometrics (access control);convolutional neural nets;feature extraction;learning (artificial intelligence)","attribute prediction;large-scale person re-ID benchmark data sets;DukeMTMC re-ID;Market-1501 data sets;multitask network;person identity;person re-identification;research community owing;surveillance industry;recent methods;partial features;fine-grained information;person retrieval;improved partial discriminative features;deep convolutional neural architecture;pyramid spatial pooling module;efficient person;multitask convolutional network;personal attributes;end-to-end framework;global features","","","60","","","","","IEEE","IEEE Journals"
"Human Action Recognition Algorithm Based on Adaptive Initialization of Deep Learning Model Parameters and Support Vector Machine","F. An","School of Information and Electronics, Beijing Institute of Technology, Beijing, China","IEEE Access","","2018","6","","59405","59421","Action recognition is a trending topic and key research direction in computer vision, machine learning, artificial intelligence, and other fields. This research seeks to identify human action in image and video data. Its research results have been widely used in the fields of safety monitoring, disability monitoring, understanding multimedia content, human–computer interaction, virtual reality, and so on. However, the existing traditional human action recognition technology has many limitations in practical application, such as low accuracy and weak adaptive ability. Although the action recognition based on deep learning can self-learn and improve the action recognition accuracy, there are many difficulties in training the deep neural network model, such as gradient disappearance, gradient explosion, and overfitting. Therefore, this paper will reduce the abovementioned difficulties in deep neural network model training from the perspective of deep neural network model parameter initialization and then propose a model parameter initialization method based on the multilayer maxout network activation function to solve the difficulties in deep neural network model training. Then, on this basis, a method of learning the temporal and spatial characteristics of human action based on the deep neural network model is proposed. First, the method detects and tracks the human action and uses the restricted Boltzmann machine (RBM) to encode the temporal and spatial features of various parts of the human body. Second, the temporal and spatial feature codes of various parts of the human body are integrated into a global temporal and spatial feature representation method of the action video through a RBM neural network. Finally, the trained SVM classifiers are used to recognize human action. Experiments show that the human action recognition method proposed in this paper not only has high recognition accuracy but also has great adaptability. Thus, this method extracts temporal and spatial features from the shape feature sequences of various parts of the human body, thus opening up a new way to extract human action features and solving the problem of human action recognition in complex scenes. Its proposal provides an exploratory technical method and approach for self-adaptive recognition of human action. It also gives directional enlightenment to the development and improvement of self-adaptive human action methods.","","","10.1109/ACCESS.2018.2874022","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8482265","Human action recognition;pose estimation;initialization method;spatial-temporal features;deep learning","Feature extraction;Machine learning;Neural networks;Shape;Training;Adaptation models;Solid modeling","","","","","65","","","","","IEEE","IEEE Journals"
"Deep Learning and Superpixel Feature Extraction Based on Contractive Autoencoder for Change Detection in SAR Images","N. Lv; C. Chen; T. Qiu; A. K. Sangaiah","School of Electronic Engineering, Xidian University, Xi'an, China; State Key Laboratory of Integrated Service Networks, Xidian University, Xi'an, China; School of Computer Science and Technology, Tianjin University, Tianjin, China; School of Computing Science and Engineering, Vellore Institute of Technology, Vellore, India","IEEE Transactions on Industrial Informatics","","2018","14","12","5530","5538","Image segmentation based on superpixel is used in urban and land cover change detection for fast locating region of interest. However, the segmentation algorithms often degrade due to speckle noise in synthetic aperture radar images. In this paper, a feature learning method using a stacked contractive autoencoder (sCAE) is presented to extract the temporal change feature from superpixel with noise suppression. First, an affiliated temporal change image, which obtains temporal difference in the pixel level, are built by three different metrics. Second, the simple linear iterative clustering algorithm is used to generate superpixels, which tightly adhere to the change image boundaries for the purpose of acquiring homogeneous change samples. Third, a sCAE network is trained with the superpixel samples as input to learn the change features in semantic. Then, the encoded features by this sCAE model are binary classified to create the change result map. Finally, the proposed method is compared with methods based on principal components analysis and Markov random fields. Experiment results show that our deep learning model can separate nonlinear noise efficiently from change features and obtain better performance in change detection for synthetic aperture radar images than conventional change detection algorithms.","","","10.1109/TII.2018.2873492","National Natural Science Foundation of China; Key Research and Development Plan of Shaanxi province; National Key Research and Development Program of China; Xi'an Key Laboratory of Mobile Edge Computing and Security; 111 Project of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8478396","Change detection;deep learning;simple linear iterative clustering (SLIC);stacked contractive autoencoder (sCAE);synthetic aperture radar (SAR) image","Feature extraction;Image segmentation;Change detection algorithms;Synthetic aperture radar;Clustering algorithms","feature extraction;geophysical image processing;image sampling;image segmentation;interference suppression;iterative methods;land cover;learning (artificial intelligence);Markov processes;principal component analysis;radar detection;radar imaging;synthetic aperture radar","synthetic aperture radar images;superpixel feature extraction;image segmentation;urban land cover change detection;segmentation algorithms;stacked contractive autoencoder;temporal change feature;noise suppression;homogeneous change samples;change detection algorithms;image boundaries;temporal change image;feature learning method;linear iterative clustering algorithm;principal component analysis;Markov random fields","","4","27","","","","","IEEE","IEEE Journals"
"Perception, Guidance, and Navigation for Indoor Autonomous Drone Racing Using Deep Learning","S. Jung; S. Hwang; H. Shin; D. H. Shim","Unmanned Systems Research Group, KAIST, Daejeon, South Korea; Unmanned Systems Research Group, KAIST, Daejeon, South Korea; Aeronautics Research and Development Head Office, Korea Aerospace Research Institute, Daejeon, South Korea; Unmanned Systems Research Group, KAIST, Daejeon, South Korea","IEEE Robotics and Automation Letters","","2018","3","3","2539","2544","In autonomous drone racing, a drone is required to fly through the gates quickly without any collision. Therefore, it is important to detect the gates reliably using computer vision. However, due to the complications such as varying lighting conditions and gates seen overlapped, traditional image processing algorithms based on color and geometry of the gates tend to fail during the actual racing. In this letter, we introduce a convolutional neural network to estimate the center of a gate robustly. Using the detection results, we apply a line-of-sight guidance algorithm. The proposed algorithm is implemented using low cost, off-the-shelf hardware for validation. All vision processing is performed in real time on the onboard NVIDIA Jetson TX2 embedded computer. In a number of tests our proposed framework successfully exhibited fast and reliable detection and navigation performance in indoor environment.","","","10.1109/LRA.2018.2808368","Ministry of Trade, Industry, and Energy, South Korea; Industrial Technology Innovation Program; Development of robot system for indoor reconnaissance mission in complex disaster situations; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8299437","Autonomous drone racing;search and rescue;deep learning based object detection","Logic gates;Drones;Object detection;FCC;Real-time systems;Indoor navigation","autonomous aerial vehicles;control engineering computing;convolution;feedforward neural nets;learning (artificial intelligence);mobile robots;object detection;path planning;robot vision","gates;convolutional neural network;line-of-sight guidance algorithm;vision processing;onboard NVIDIA Jetson TX2 embedded computer;navigation;deep learning;autonomous drone racing;computer vision;indoor autonomous drone racing;perception;guidance","","6","24","","","","","IEEE","IEEE Journals"
"A Recommendation Model Based on Deep Neural Network","L. Zhang; T. Luo; F. Zhang; Y. Wu","Chinese Academy of Sciences, Institute of Software, Beijing, China; University of Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, Beijing, China; Chinese Academy of Sciences, Institute of Software, Beijing, China","IEEE Access","","2018","6","","9454","9463","In recent years, recommendation systems have been widely used in various commercial platforms to provide recommendations for users. Collaborative filtering algorithms are one of the main algorithms used in recommendation systems. Such algorithms are simple and efficient; however, the sparsity of the data and the scalability of the method limit the performance of these algorithms, and it is difficult to further improve the quality of the recommendation results. Therefore, a model combining a collaborative filtering recommendation algorithm with deep learning technology is proposed, therein consisting of two parts. First, the model uses a feature representation method based on a quadric polynomial regression model, which obtains the latent features more accurately by improving upon the traditional matrix factorization algorithm. Then, these latent features are regarded as the input data of the deep neural network model, which is the second part of the proposed model and is used to predict the rating scores. Finally, by comparing with other recommendation algorithms on three public datasets, it is verified that the recommendation performance can be effectively improved by our model.","","","10.1109/ACCESS.2018.2789866","National Education Information Technology Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8247172","Recommendation system;collaborative filtering;quadric polynomial regression;deep neural network (DNN)","Matrix decomposition;Machine learning;Collaboration;Algorithm design and analysis;Data models;Artificial neural networks","collaborative filtering;learning (artificial intelligence);matrix decomposition;neural nets;recommender systems;regression analysis","feature representation method;quadric polynomial regression model;latent features;traditional matrix factorization algorithm;deep neural network model;recommendation performance;recommendation model;recommendation systems;commercial platforms;recommendation results;collaborative filtering recommendation algorithm;deep learning technology","","10","31","","","","","IEEE","IEEE Journals"
"Automatic Segmentation of Cervical Nuclei Based on Deep Learning and a Conditional Random Field","Y. Liu; P. Zhang; Q. Song; A. Li; P. Zhang; Z. Gui","Shanxi Provincial Key Laboratory for Biomedical Imaging and Big Data, North University of China, Taiyuan, China; Shanxi Provincial Key Laboratory for Biomedical Imaging and Big Data, North University of China, Taiyuan, China; Shanxi Provincial Key Laboratory for Biomedical Imaging and Big Data, North University of China, Taiyuan, China; Shanxi Provincial Key Laboratory for Biomedical Imaging and Big Data, North University of China, Taiyuan, China; Shanxi Provincial Key Laboratory for Biomedical Imaging and Big Data, North University of China, Taiyuan, China; Shanxi Provincial Key Laboratory for Biomedical Imaging and Big Data, North University of China, Taiyuan, China","IEEE Access","","2018","6","","53709","53721","Automatic and accurate cervical nucleus segmentation is important because nuclei carry substantial diagnostic information for automatic computer-assisted cervical cancer screening and diagnosis systems. In this paper, we propose a cervical nucleus segmentation method in which pixel-level prior information is utilized to provide the supervisory information for the training of a mask regional convolutional neural network (Mask-RCNN), which is then employed to extract the multi-scale features of the nuclei, and the coarse segmentation and bounding box of the nuclei are obtained by forward propagation of the Mask-RCNN. To refine the segmentation, a local fully connected conditional random field (LFCCRF) that contains unary and pairwise energy terms is employed. The nuclear region of interest is determined by extending the bounding box, the coarse segmentation in the nuclear region is used to construct the unary energy, and the pairwise energy is contributed by the position and intensity information of all of the pixels in the nuclear region. By minimizing the energy of the LFCCRF, the final segmentation is realized. We evaluated our method by using cervical nuclei from the Herlev Pap smear data set in this paper, and the precision, recall, and Zijdenbos similarity index were all found to be greater than 0.95 with low standard deviations, demonstrating that our method enables more accurate and stable cervical nucleus segmentation than the current state-of-the-art methods.","","","10.1109/ACCESS.2018.2871153","National Natural Science Foundation of China; Shanxi Scholarship Council of China; Fund for Shanxi 1331 Project Key Innovative Research Team; National Key Scientific Instrument and Equipment Development Project of China; National Natural Science Foundation of China; National Key Research and Development Program of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8468154","Conditional random field;deep learning;Mask-RCNN;Pap smear screening","Feature extraction;Image segmentation;Shape;Cervical cancer;Training;Filtering","cancer;convolution;feedforward neural nets;gynaecology;image segmentation;learning (artificial intelligence);medical image processing","Herlev Pap smear data;local fully connected conditional random field;mask-RCNN;intensity information;unary energy;nuclear region;pairwise energy terms;LFCCRF;bounding box;coarse segmentation;multiscale features;mask regional convolutional neural network;supervisory information;pixel-level prior information;diagnosis systems;automatic computer-assisted cervical cancer screening;substantial diagnostic information;accurate cervical nucleus segmentation;deep learning;automatic segmentation","","4","46","","","","","IEEE","IEEE Journals"
"Delay Compensation for a Telepresence System With 3D 360 Degree Vision Based on Deep Head Motion Prediction and Dynamic FoV Adaptation","T. Aykut; M. Karimi; C. Burgmair; A. Finkenzeller; C. Bachhuber; E. Steinbach","Department of Electrical and Computer Engineering, Technical University of Munich, Munich, Germany; Department of Electrical and Computer Engineering, Technical University of Munich, Munich, Germany; Department of Electrical and Computer Engineering, Technical University of Munich, Munich, Germany; Department of Electrical and Computer Engineering, Technical University of Munich, Munich, Germany; Department of Electrical and Computer Engineering, Technical University of Munich, Munich, Germany; Department of Electrical and Computer Engineering, Technical University of Munich, Munich, Germany","IEEE Robotics and Automation Letters","","2018","3","4","4343","4350","The usability of telepresence applications is strongly affected by the communication delay between the user and the remote system. Special attention needs to be paid in case the distant scene is experienced by means of a Head Mounted Display. A high motion-to-photon latency, which describes the time needed to fully reflect the user's motion on the display, results in a poor feeling of presence. Further consequences involve unbearable motion sickness, indisposition, and termination of the telepresence session in the worst case. In this letter, we present our low-cost MAVI telepresence system, which is equipped with a stereoscopic 360° vision system and high-payload manipulation capabilities. Special emphasis is placed on the stereoscopic vision system and its delay compensation. More specifically, we propose velocity-based dynamic field-of-view adaptation techniques to decrease the emergence of simulator sickness and to improve the achievable level of delay compensation. The proposed delay compensation approach relies on deep learning to predict the prospective head motion. We use our previously described head motion dataset for training, validation, and testing. To prove the general validity of our approach, we perform cross validation with another independent dataset. We use both qualitative measures and subjective experiments for evaluation. Our results show that the proposed approach is able to achieve mean compensation rates of around 99.9% for latencies between 0.1 and 0.5 s.","","","10.1109/LRA.2018.2864359","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8429079","3D vision;telepresence;virtual reality;remote reality;omnidirectional vision","Deep learning;Visualization;Delays;Telepresence;Virtual reality;Stereo image processing","compensation;delays;haptic interfaces;helmet mounted displays;learning (artificial intelligence);optical tracking;stereo image processing;three-dimensional displays;virtual reality;visual perception","field-of-view adaptation techniques;delay compensation approach;prospective head motion;mean compensation rates;dynamic FoV adaptation;telepresence applications;communication delay;remote system;Head Mounted Display;unbearable motion sickness;telepresence session;low-cost MAVI telepresence system;stereoscopic 360° vision system;high-payload manipulation capabilities;head motion dataset;3D 360 degree vision;velocity-based dynamic field-of-view adaptation techniques;high motion-to-photon latency;deep head motion prediction;simulator sickness;deep learning","","1","29","","","","","IEEE","IEEE Journals"
"Deep imitation reinforcement learning with expert demonstration data","M. Yi; X. Xu; Y. Zeng; S. Jung","College of Intelligence Science and Technology, National University of Defense Technology, People's Republic of China; College of Intelligence Science and Technology, National University of Defense Technology, People's Republic of China; College of Intelligence Science and Technology, National University of Defense Technology, People's Republic of China; Chungnam National University, Republic of Korea","The Journal of Engineering","","2018","2018","16","1567","1573","In recent years, deep reinforcement learning (DRL) has made impressive achievements in many fields. However, existing DRL algorithms usually require a large amount of exploration to obtain a good action policy. In addition, in many complex situations, the reward function cannot be well designed to meet task requirements. These two problems will make it difficult for DRL to learn a good action policy within a relatively short period. The use of expert data can provide effective guidance and avoid unnecessary exploration. This study proposes a deep imitation reinforcement learning (DIRL) algorithm that uses a certain amount of expert demonstration data to speed up the training of DRL. In the proposed method, the learning agent imitates the expert's action policy by learning from demonstration data. After imitation learning, DRL is used to optimise the action policy in a self-learning way. By experimental comparison on a video game called the Mario racing game, it is shown that the proposed DIRL algorithm with expert demonstration data can obtain much better performance than previous DRL algorithms without expert guidance.","","","10.1049/joe.2018.8314","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8543756","","","learning (artificial intelligence);computer games","expert demonstration data;existing DRL algorithms;good action policy;task requirements;expert data;deep imitation reinforcement learning algorithm;learning agent;DIRL algorithm;expert guidance;Mario racing game","","","27","","","","","IET","IET Journals"
"BundleNet: Learning with Noisy Label via Sample Correlations","C. Li; C. Zhang; K. Ding; G. Li; J. Cheng; H. Lu","Chinese Academy of Sciences, Institute of Automation, Beijing, China; Chinese Academy of Sciences, Institute of Automation, Beijing, China; Chinese Academy of Sciences, Institute of Automation, Beijing, China; Chinese Academy of Sciences, Institute of Automation, Beijing, China; Chinese Academy of Sciences, Institute of Automation, Beijing, China; Chinese Academy of Sciences, Institute of Automation, Beijing, China","IEEE Access","","2018","6","","2367","2377","Sequential patterns are important, because they can be exploited to improve the prediction accuracy of our classifiers. Sequential data, such as time series/video frames, and event data are becoming more and more ubiquitous in a wide spectrum of application scenarios especially in the background of large data and deep learning. However, large data sets used in training modern machine-learning models, such as deep neural networks, are often affected by label noise. Existing noisy learning approaches mainly focus on building an additional network to clean the noise or find a robust loss function. Few works tackle this problem by exploiting sample correlations. In this paper, we propose BundleNet, a framework of sequential structure (named bundle-module, see Fig. 1) for deep neural networks to handle the label noise. The bundle module naturally takes into account sample correlations by constructing bundles of samples class-by-class, and treats them as independent inputs. Moreover, we prove that the bundle-module performs a form of regularization, which is similar to dropout as regularization during training. The regularization effect endows the BundleNet with strong robustness to the label noise. Extensive experiments on public data sets prove that the proposed approach is effective and promising.","","","10.1109/ACCESS.2017.2782844","National Natural Science Foundation of China; Jiangsu Key Laboratory of Big Data Analysis Technology; 863 Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8194827","BundleNet;sequential data;classification;noisy label;regularization","Noise measurement;Neural networks;Training;Robustness;Correlation;Kernel;Machine learning","data handling;data mining;learning (artificial intelligence);neural nets","sequential patterns;prediction accuracy;sequential data;event data;deep learning;deep neural networks;noisy learning approaches;robust loss function;BundleNet;sequential structure;bundle module;public data sets;noisy label;machine-learning models;sample correlations;regularization effect","","","73","","","","","IEEE","IEEE Journals"
"Deep Temporal Multimodal Fusion for Medical Procedure Monitoring Using Wearable Sensors","E. A. Bernal; X. Yang; Q. Li; J. Kumar; S. Madhvanath; P. Ramesh; R. Bala","PARC, Palo Alto, CA, USA; PARC, Palo Alto, CA, USA; PARC, Palo Alto, CA, USA; PARC, Palo Alto, CA, USA; PARC, Palo Alto, CA, USA; Data Analytics and Computer Vision Department, PARC, a Xerox Company, Webster, NY, USA; Data Analytics and Computer Vision Department, PARC, a Xerox Company, Webster, NY, USA","IEEE Transactions on Multimedia","","2018","20","1","107","118","Process monitoring and verification have a wide range of uses in the medical and healthcare fields. Currently, such tasks are often carried out by a trained specialist, which makes them expensive, inefficient, and time-consuming. Recent advances in automated video- and multimodal-data-based action and activity recognition have made it possible to reduce the extent of manual intervention required to effectively carry out process supervision tasks. In this paper, we propose algorithms for automated egocentric human action and activity recognition from multimodal data, with a target application of monitoring and assisting a user perform a multistep medical procedure. We propose a supervised deep multimodal fusion framework that relies on concurrent processing of motion data acquired with wearable sensors and video data acquired with an egocentric or body-mounted camera. We demonstrate the effectiveness of the algorithm on a public multimodal dataset and conclude that automated process monitoring via the use of multiple heterogeneous sensors is a viable alternative to its manual counterpart. Furthermore, we demonstrate that the application of previously proposed adaptive sampling schemes to the video processing branch of the multimodal framework results in significant performance improvements.","","","10.1109/TMM.2017.2726187","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7976382","Action and activity recognition;deep learning;deep temporal fusion;egocentric vision;hand localization;medical procedures;multimodal fusion;wearable sensors","Monitoring;Medical services;Biomedical monitoring;Activity recognition;Data integration;Wearable sensors","cameras;health care;image fusion;learning (artificial intelligence);process monitoring;video signal processing","recent advances;activity recognition;manual intervention;process supervision tasks;automated egocentric human action;multimodal data;target application;multistep medical procedure;supervised deep multimodal fusion framework;concurrent processing;motion data;wearable sensors;video data;public multimodal dataset;automated process monitoring;multiple heterogeneous sensors;video processing branch;multimodal framework results;deep temporal multimodal fusion;medical procedure monitoring;verification;medical fields;healthcare fields;trained specialist;automated video-based action;multimodal-data-based action;egocentric cameras;body-mounted camera","","3","79","Traditional","","","","IEEE","IEEE Journals"
"Deep Neural Networks for Acoustic Modeling in the Presence of Noise","L. M. Q. d. Santana; R. M. Santos; L. N. Matos; H. T. Macedo","Univ. Fed. de Sergipe, Sao Cristovao, Brazil; Univ. Fed. de Sergipe, Sao Cristovao, Brazil; Univ. Fed. de Sergipe, Sao Cristovao, Brazil; Univ. Fed. de Sergipe, Sao Cristovao, Brazil","IEEE Latin America Transactions","","2018","16","3","918","925","Systems using deep neural network (DNN) have shown promising results in automatic speech recognition (ASR), where one of the biggest challenges is the recognition in noisy speech signals. We have combined two famous architectures of deep learning, the convolutional neural networks (CNN) for acoustic approach and a recurrent architecture with connectionist temporal classification (CTC) for sequential modeling, in order to decode the frames in a sequence forming a word. Experimental results show that the proposed architecture achieves improved performance over classical models, such as hidden model Markov (HMM) for labeling in variable time sequences in BioChaves database.","","","10.1109/TLA.2018.8358674","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8358674","Convolutional Neural Network;Deep Learning;Noisy environment;Recurrent Neural Network;Speech recognition","Hidden Markov models;Acoustics;Biological system modeling;Speech recognition;Computer architecture;Convolutional neural networks","feedforward neural nets;hidden Markov models;learning (artificial intelligence);recurrent neural nets;speech recognition","deep neural network;acoustic modeling;automatic speech recognition;noisy speech signals;famous architectures;deep learning;convolutional neural networks;acoustic approach;recurrent architecture;sequential modeling;classical models;hidden model Markov;DNN;ASR;CNN;CTC;connectionist temporal classification;HMM;BioChaves database;variable time sequences","","","","","","","","IEEE","IEEE Journals"
"Prediction for High Risk Clinical Symptoms of Epilepsy Based on Deep Learning Algorithm","M. Sun; F. Wang; T. Min; T. Zang; Y. Wang","School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China","IEEE Access","","2018","6","","77596","77605","Accurate forecasting of high-risk clinical symptoms, like epileptic seizures, has the potential to transform clinical epilepsy care and to create new therapeutic strategies for individuals in clinical decision support systems. With the development of pervasive sensor technologies, physiological signals can be captured continuously to prevent the serious outcomes caused by epilepsy. However, the progress on seizure prediction has been hindered by the lack of automatic early warning system. The existing research is classifying electroencephalograph (EEG) clips and is distinguishing the clips of onset epileptic seizures. Deep learning is a promising method to analyze the large-scale unlabeled data and to widely spread the clinical treatment and risk prediction. In this paper, we outline a patient-specific method for extracting the frequency domain and time-series data features based on the two-layer convolutional neural networks (CNNs). A data preprocessing method based on the discrete Fourier transform is proposed to convert the time-domain signal of the EEG data to the frequency-domain signal. Long short-term memory networks are introduced in seizure prediction using pre-seizure clips of the EEG dataset, expanding the use of deep learning algorithms with recurrent neural networks (RNNs). Furthermore, the proposed CNN and RNN are compared with the traditional machine learning algorithms, such as linear discriminant analysis and logistic regression, and the evaluation criteria are on the area under the curve. The extensive experimental results demonstrate that our method can effectively extract the latent features with meaningful interpretation and exhibits excellent performance for predicting epileptic preictal state changes, and hence is an effective method in detecting the epileptic seizure.","","","10.1109/ACCESS.2018.2883562","National Key Research and Development Programs of China; National High-Tech Research and Development Program of China (863 Program); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8548556","Epilepsy;prediction algorithms;machine learning;neural networks;clinical diagnosis","Electroencephalography;Epilepsy;Feature extraction;Frequency-domain analysis;Discrete Fourier transforms","convolutional neural nets;decision support systems;discrete Fourier transforms;electroencephalography;feature extraction;learning (artificial intelligence);medical disorders;medical signal processing;neurophysiology;recurrent neural nets;regression analysis;seizure;signal classification","high risk clinical symptoms;deep learning algorithm;high-risk clinical symptoms;epileptic seizure;clinical epilepsy care;clinical decision support systems;pervasive sensor technologies;physiological signals;seizure prediction;automatic early warning system;promising method;large-scale unlabeled data;clinical treatment;risk prediction;patient-specific method;time-series data features;two-layer convolutional neural networks;discrete Fourier transform;time-domain signal;frequency-domain signal;short-term memory networks;pre-seizure clips;recurrent neural networks;electroencephalograph clips","","1","32","","","","","IEEE","IEEE Journals"
"Microaneurysm Detection Using Principal Component Analysis and Machine Learning Methods","W. Cao; N. Czarnek; J. Shan; L. Li","Seidenberg School of Computer Science and Information Systems, Pace University, New York City, NY, USA; Pratt School of Electrical and Computer Engineering, Duke University, Durham, NC, USA; Seidenberg School of Computer Science and Information Systems, Pace University, New York City, NY, USA; Department of Computer Science and Software Engineering, Seattle University, Seattle, WA, USA","IEEE Transactions on NanoBioscience","","2018","17","3","191","198","Diabetic retinopathy (DR) is an eye abnormality caused by long-term diabetes and it is the most common cause of blindness before the age of 50. Microaneurysms (MAs), resulting from leakage from retinal blood vessels, are early indicators of DR. In this paper, we analyzed MA detectability using small 25 by 25 pixel patches extracted from fundus images in the DIAbetic RETinopathy DataBase - Calibration Level 1 (DIARETDB1). Raw pixel intensities of extracted patches served directly as inputs into the following classifiers: random forest (RF), neural network, and support vector machine. We also explored the use of two techniques (principal component analysis and RF feature importance) for reducing input dimensionality. With traditional machine learning methods and leave-10-patients-out cross validation, our method outperformed a deep learning-based MA detection method, with AUC performance improved from 0.962 to 0.985 and F-measure improved from 0.913 to 0.926, using the same DIARETDB1 database. Furthermore, we validated our method on a different dataset-retinopathy online challenge (ROC) data set. The performance of the three classifiers and the pattern with different percentage of principal components are consistent on the two data sets. Especially, we trained the RF on DIARETDB1 and applied it to ROC; the performance is very similar to that of the RF trained and tested using cross validation on ROC data set. This result indicates that our method has the potential to generalize to different datasets.","","","10.1109/TNB.2018.2840084","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8364584","Feature representation;automated microaneurysm detection;diabetic retinopathy;random forest;support vector machine;neural network","Aneurysm;Retina;Principal component analysis;Machine learning;Diabetes;Retinopathy;Blindness;Feature extraction","biomedical optical imaging;blood vessels;feature extraction;image classification;learning (artificial intelligence);medical image processing;neural nets;principal component analysis;support vector machines","microaneurysm detection;principal component analysis;eye abnormality;long-term diabetes;retinal blood vessels;fundus images;raw pixel intensities;classifiers;random forest;neural network;support vector machine;input dimensionality;leave-10-patients-out cross validation;deep learning-based MA detection method;AUC performance;DIARETDB1 database;machine learning methods;diabetic retinopathy database - calibration level;DR indicators;F-measure;RF feature importance;dataset-retinopathy online challenge data;ROC data set;patche extraction","Diabetic Retinopathy;Humans;Image Interpretation, Computer-Assisted;Machine Learning;Microaneurysm;Neural Networks (Computer);Principal Component Analysis;Support Vector Machine","","23","","","","","IEEE","IEEE Journals"
"Light Gated Recurrent Units for Speech Recognition","M. Ravanelli; P. Brakel; M. Omologo; Y. Bengio","Information and Communication Technology, Trento, Italy; Montreal Institute for Learning Algorithms, Universite de Montreal, Montreal, QC, Canada; Information and Communication Technology, Trento, Italy; Montreal Institute for Learning Algorithms, Universite de Montreal, Montreal, QC, Canada","IEEE Transactions on Emerging Topics in Computational Intelligence","","2018","2","2","92","102","A field that has directly benefited from the recent advances in deep learning is automatic speech recognition (ASR). Despite the great achievements of the past decades, however, a natural and robust human-machine speech interaction still appears to be out of reach, especially in challenging environments characterized by significant noise and reverberation. To improve robustness, modern speech recognizers often employ acoustic models based on recurrent neural networks (RNNs) that are naturally able to exploit large time contexts and long-term speech modulations. It is thus of great interest to continue the study of proper techniques for improving the effectiveness of RNNs in processing speech signals. In this paper, we revise one of the most popular RNN models, namely, gated recurrent units (GRUs), and propose a simplified architecture that turned out to be very effective for ASR. The contribution of this work is twofold: First, we analyze the role played by the reset gate, showing that a significant redundancy with the update gate occurs. As a result, we propose to remove the former from the GRU design, leading to a more efficient and compact single-gate model. Second, we propose to replace hyperbolic tangent with rectified linear unit activations. This variation couples well with batch normalization and could help the model learn long-term dependencies without numerical issues. Results show that the proposed architecture, called light GRU, not only reduces the per-epoch training time by more than 30% over a standard GRU, but also consistently improves the recognition accuracy across different tasks, input features, noisy conditions, as well as across different ASR paradigms, ranging from standard DNN-HMM speech recognizers to end-to-end connectionist temporal classification models.","","","10.1109/TETCI.2017.2762739","NVIDIA Corporation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8323308","Speech recognition;deep learning;recurrent neural networks;LSTM;GRU","Logic gates;Speech recognition;Speech;Computer architecture;Standards;Hidden Markov models;Robustness","hidden Markov models;learning (artificial intelligence);recurrent neural nets;speech recognition","RNN;ASR paradigms;reset gate;speech signals;long-term speech modulations;recurrent neural networks;acoustic models;reverberation;robust human-machine speech interaction;automatic speech recognition;deep learning;light gated recurrent units;end-to-end connectionist temporal classification models;standard DNN-HMM speech recognizers;rectified linear unit activations;compact single-gate model;GRU design","","5","75","","","","","IEEE","IEEE Journals"
"Improved bare PCB defect detection approach based on deep feature learning","C. Zhang; W. Shi; X. Li; H. Zhang; H. Liu","Electronic Information School, Wuhan University, People's Republic of China; Key Laboratory of Machine Perception, Peking University, People's Republic of China; INRIA Grenoble Rhône-Alpes, France; Electronic Information School, Wuhan University, People's Republic of China; Key Laboratory of Machine Perception, Peking University, People's Republic of China","The Journal of Engineering","","2018","2018","16","1415","1420","Robust and precise defect detection is of great significance in the production of the high-quality printed circuit board (PCB). However, due to the complexity of PCB production environments, most previous works still utilise traditional image processing and matching algorithms to detect PCB defects. In this work, an improved bare PCB defect detection approach is proposed by learning deep discriminative features, which also greatly reduced the high requirement of a large dataset for the deep learning method. First, the authors extend an existing PCB defect dataset with some artificial defect data and affine transformations to increase the quantity and diversity of defect data. Then, a deep pre-trained convolutional neural network is employed to learn high-level discriminative features of defects. They fine-tune the base model on the extended dataset by freezing all the convolutional layers and training the top layers. Finally, the sliding window approach is adopted to further localise the defects. Extensive comparisons with three traditional shallow feature-based methods demonstrate that the proposed approach is more feasible and effective in PCB defect detection area.","","","10.1049/joe.2018.8275","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8543740","","","automatic optical inspection;learning (artificial intelligence);printed circuit manufacture;feature extraction;image representation;printed circuits;feedforward neural nets;convolution;image matching;affine transforms","deep feature learning;high-quality printed circuit board;PCB production environments;matching algorithms;deep discriminative features;artificial defect data;high-level discriminative features;image processing;convolutional neural network;PCB defect detection approach;affine transformations;shallow feature-based methods;convolutional layers;sliding window approach","","1","31","","","","","IET","IET Journals"
"Detecting and Locating Gastrointestinal Anomalies Using Deep Learning and Iterative Cluster Unification","D. K. Iakovidis; S. V. Georgakopoulos; M. Vasilakakis; A. Koulaouzidis; V. P. Plagianakos","Department of Computer Science and Biomedical Informatics, University of Thessaly, Lamia, Greece; Department of Computer Science and Biomedical Informatics, University of Thessaly, Lamia, Greece; Department of Computer Science and Biomedical Informatics, University of Thessaly, Lamia, Greece; Endoscopy Unit, Royal Infirmary of Edinburgh, Edinburgh, U.K.; Department of Computer Science and Biomedical Informatics, University of Thessaly, Lamia, Greece","IEEE Transactions on Medical Imaging","","2018","37","10","2196","2210","This paper proposes a novel methodology for automatic detection and localization of gastrointestinal (GI) anomalies in endoscopic video frame sequences. Training is performed with weakly annotated images, using only image-level, semantic labels instead of detailed, and pixel-level annotations. This makes it a cost-effective approach for the analysis of large videoendoscopy repositories. Other advantages of the proposed methodology include its capability to suggest possible locations of GI anomalies within the video frames, and its generality, in the sense that abnormal frame detection is based on automatically derived image features. It is implemented in three phases: 1) it classifies the video frames into abnormal or normal using a weakly supervised convolutional neural network (WCNN) architecture; 2) detects salient points from deeper WCNN layers, using a deep saliency detection algorithm; and 3) localizes GI anomalies using an iterative cluster unification (ICU) algorithm. ICU is based on a pointwise cross-feature-map (PCFM) descriptor extracted locally from the detected salient points using information derived from the WCNN. Results, from extensive experimentation using publicly available collections of gastrointestinal endoscopy video frames, are presented. The data sets used include a variety of GI anomalies. Both anomaly detection and localization performance achieved, in terms of the area under receiver operating characteristic (AUC), were >80%. The highest AUC for anomaly detection was obtained on conventional gastroscopy images, reaching 96%, and the highest AUC for anomaly localization was obtained on wireless capsule endoscopy images, reaching 88%.","","","10.1109/TMI.2018.2837002","Project Klearchos Koulaouzidis; Special Account of Research Grants of the University of Thessaly, Greece; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8359121","Endoscopy;gastrointestinal tract;computer-aided detection and diagnosis;machine learning","Feature extraction;Training;Lesions;Image segmentation;Image color analysis;Endoscopes;Gastrointestinal tract","biological organs;biomedical optical imaging;endoscopes;feature extraction;image classification;image sequences;iterative methods;learning (artificial intelligence);medical image processing;neural nets;object detection;object recognition;video signal processing","abnormal frame detection;automatically derived image features;weakly supervised convolutional neural network;deep saliency detection algorithm;GI anomalies;iterative cluster unification algorithm;pointwise cross-feature-map descriptor;gastrointestinal endoscopy video frames;anomaly detection;localization performance;anomaly localization;gastrointestinal anomalies;deep learning;automatic detection;endoscopic video frame sequences;weakly annotated images;image-level;pixel-level annotations;cost-effective approach;salient points;WCNN layers;gastroscopy images;wireless capsule endoscopy images","","5","66","","","","","IEEE","IEEE Journals"
"Towards Emotionally Aware AI Smart Classroom: Current Issues and Directions for Engineering and Education","Y. Kim; T. Soyata; R. F. Behnagh","Department of Electrical and Computer Engineering, State University of New York at Albany, Albany, NY, USA; Department of Electrical and Computer Engineering, State University of New York at Albany, Albany, NY, USA; Department of Educational Theory and Practice, State University of New York at Albany, Albany, NY, USA","IEEE Access","","2018","6","","5308","5331","Future smart classrooms that we envision will significantly enhance learning experience and seamless communication among students and teachers using real-time sensing and machine intelligence. Existing developments in engineering have brought the state-of-the-art to an inflection point, where they can be utilized as components of a smart classroom. In this paper, we propose a smart classroom system that consists of these components. Our proposed system is capable of making real-time suggestions to an in-class presenter to improve the quality and memorability of their presentation by allowing the presenter to make real-time adjustments/corrections to their non-verbal behavior, such as hand gestures, facial expressions, and body language. We base our suggested system components on existing research in affect sensing, deep learning-based emotion recognition, and real-time mobile-cloud computing. We provide a comprehensive study of these technologies and determine the computational requirements of a system that incorporates these technologies. Based on these requirements, we provide a feasibility study of the system. Although the state-of-the-art research in most of the components we propose in our system are advanced enough to realize the system, the main challenge lies in: 1) the integration of these technologies into a holistic system design; 2) their algorithmic adaptation to allow real-time execution; and 3) quantification of valid educational variables for use in algorithms. In this paper, we discuss current issues and provide future directions in engineering and education disciplines to deploy the proposed system.","","","10.1109/ACCESS.2018.2791861","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8253436","Educational technology;emotion recognition;smart classroom;deep learning;real-time computing;mobile-cloud computing;meta-cognition","Real-time systems;Education;Engines;Machine learning;System analysis and design;Haptic interfaces;Visualization","cloud computing;computer aided instruction;distance learning;emotion recognition;engineering education;face recognition;gesture recognition;human computer interaction;learning (artificial intelligence);mobile computing","learning experience;real-time sensing;real-time suggestions;in-class presenter;real-time adjustments/corrections;real-time execution;system components;emotionally aware AI smart classroom;seamless communication;machine intelligence;affect sensing;deep learning-based emotion recognition;real-time mobile-cloud computing;computational requirements;engineering discipline;education discipline","","10","185","","","","","IEEE","IEEE Journals"
"An Intelligent Traffic Load Prediction-Based Adaptive Channel Assignment Algorithm in SDN-IoT: A Deep Learning Approach","F. Tang; Z. M. Fadlullah; B. Mao; N. Kato","Graduate School of Information Sciences, Tohoku University, Sendai, Japan; Graduate School of Information Sciences, Tohoku University, Sendai, Japan; Graduate School of Information Sciences, Tohoku University, Sendai, Japan; Graduate School of Information Sciences, Tohoku University, Sendai, Japan","IEEE Internet of Things Journal","","2018","5","6","5141","5154","Due to the fast increase of sensing data and quick response requirement in the Internet of Things (IoT) delivery network, the high speed transmission has emerged as an important issue. Assigning suitable channels in the wireless IoT delivery network is a basic guarantee of high speed transmission. However, the high dynamics of traffic load (TL) make the conventional fixed channel assignment algorithm ineffective. Recently, the software defined networking-based IoT (SDN-IoT) is proposed to improve the transmission quality. Besides this, the intelligent technique of deep learning is widely researched in high computational SDN. Hence, we first propose a novel deep learning-based TL prediction algorithm to forecast future TL and congestion in network. Then, a deep learning-based partially channel assignment algorithm is proposed to intelligently allocate channels to each link in the SDN-IoT network. Finally, we consider a deep learning-based prediction and partially overlapping channel assignment to propose a novel intelligent channel assignment algorithm, which can intelligently avoid potential congestion and quickly assign suitable channels in SDN-IoT. The simulation result demonstrates that our proposal significantly outperforms conventional channel assignment algorithms.","","","10.1109/JIOT.2018.2838574","Japan Society for the Promotion of Science; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8361420","Deep learning;Internet of Things (IoT);partially overlapping channel assignment (POCA);software defined network (SDN);traffic load (TL) prediction","Channel allocation;Machine learning;Sensors;Internet of Things;Prediction algorithms;Control systems;Routing","","","","32","32","","","","","IEEE","IEEE Journals"
"Removing Stripe Noise From Infrared Cloud Images via Deep Convolutional Networks","P. Xiao; Y. Guo; P. Zhuang","Nanjing University of Information Science and Technology, Nanjing, China; Nanjing University of Information Science and Technology, Nanjing, China; Nanjing University of Information Science and Technology, Nanjing, China","IEEE Photonics Journal","","2018","10","4","1","14","We propose a new deep network architecture for removing a stripe noise from a single meteorological satellite infrared cloud image. In the proposed framework, a residual learning is utilized to directly reduce the mapping range from input to output, which speeds up the training process as well as boosts the destriping performance. Inspired by the wide inference networks, we use wider CNNs with more convolutions in the first part of the proposed network, which is helpful for learning the similar pixel-distribution features from noisy images. To further improve the performance, we propose a local-global combination structure model, which combines the representations of different layers for recovering the rich details of infrared cloud images. Moreover, we extend our method to remove rain streaks from single images, which provides a new idea for rain-removal task. In addition, we provide a new meteorological satellite infrared cloud image dataset for training and validating the proposed network. Final extensive experiments demonstrate that the proposed method can achieve both comparable restoration quality and computational efficiency with several state-of-the-art approaches.","","","10.1109/JPHOT.2018.2854303","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8419235","Stripe noise removal;infrared cloud image;deep convolutional neural network;local-global combination;residual learning.","Clouds;Noise measurement;Task analysis;Satellites;Training;Detectors;Network architecture","clouds;feedforward neural nets;image denoising;infrared imaging;learning (artificial intelligence);meteorological instruments;object detection","stripe noise removal;pixel-distribution features;destriping performance;residual learning;single meteorological satellite;deep network architecture;deep convolutional networks;cloud image dataset;rain-removal task;infrared cloud images;local-global combination structure model;noisy images;wide inference networks","","3","51","","","","","IEEE","IEEE Journals"
"Deep-Structured Event Modeling for User-Generated Photos","X. Yang; T. Zhang; C. Xu","National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Multimedia","","2018","20","8","2100","2113","Vision-based event analysis is difficult because of the following challenges. The first challenge is intraclass variation. Photos uploaded by users are sparsely sampled visual appearances of an event over time. Thus, each photo may only capture a single object or scene of a specific complex event. The second challenge is interclass confusion. Photos related to different events may contain similar objects or scenes. Third, unusual events are characterized by scarcity, and only a few samples are available for use in learning event patterns. In this paper, by considering the photo timestamp, we propose a structured event modeling (SEM) framework for event analysis that exploits the temporal information of visual features and event classes in a photo sequence. Specifically, the temporal event patterns of the photo sequence and the relationships of different photos are jointly learned using deep neural networks (convolutional neural networks and recurrent neural networks) and a conditional random field. We evaluate the proposed SEM framework in two applications: multiclass event recognition and unusual event detection in photo sequences. The results of extensive experiments performed on a public event recognition dataset and a collected unusual event dataset demonstrate the effectiveness of the proposed method.","","","10.1109/TMM.2017.2788210","National Natural Science Foundation of China; Natural Science Foundation of Beijing Municipality; Key Research Program of Frontier Sciences, Chinese Academy of Sciences; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8241843","Event analysis;unusual event detection;deep learning","Visualization;Analytical models;Hidden Markov models;Event detection;Recurrent neural networks","computer vision;convolution;feature extraction;feedforward neural nets;image recognition;learning (artificial intelligence);object detection;recurrent neural nets","photo timestamp;structured event modeling framework;temporal event patterns;deep neural networks;convolutional neural networks;recurrent neural networks;deep-structured event modeling;vision-based event analysis;visual appearances;object detection;learning event patterns;SEM framework","","","86","","","","","IEEE","IEEE Journals"
"Using Deep Convolutional Neural Network Architectures for Object Classification and Detection Within X-Ray Baggage Security Imagery","S. Akcay; M. E. Kundegorski; C. G. Willcocks; T. P. Breckon","Department of Computer Science, Durham University, Durham, U.K.; Department of Computer Science, Durham University, Durham, U.K.; Department of Computer Science, Durham University, Durham, U.K.; Department of Computer Science, Durham University, Durham, U.K.","IEEE Transactions on Information Forensics and Security","","2018","13","9","2203","2215","We consider the use of deep convolutional neural networks (CNNs) with transfer learning for the image classification and detection problems posed within the context of X-ray baggage security imagery. The use of the CNN approach requires large amounts of data to facilitate a complex end-to-end feature extraction and classification process. Within the context of X-ray security screening, limited availability of object of interest data examples can thus pose a problem. To overcome this issue, we employ a transfer learning paradigm such that a pre-trained CNN, primarily trained for generalized image classification tasks where sufficient training data exists, can be optimized explicitly as a later secondary process towards this application domain. To provide a consistent feature-space comparison between this approach and traditional feature space representations, we also train support vector machine (SVM) classifier on CNN features. We empirically show that fine-tuned CNN features yield superior performance to conventional hand-crafted features on object classification tasks within this context. Overall we achieve 0.994 accuracy based on AlexNet features trained with SVM classifier. In addition to classification, we also explore the applicability of multiple CNN driven detection paradigms, such as sliding window-based CNN (SW-CNN), Faster region-based CNNs (F-RCNNs), region-based fully convolutional networks (R-FCN), and YOLOv2. We train numerous networks tackling both single and multiple detections over SW-CNN/ F-RCNN/R-FCN/YOLOv2 variants. YOLOv2, Faster-RCNN, and R-FCN provide superior results to the more traditional SW-CNN approaches. With the use of YOLOv2, using input images of size 544×544, we achieve 0.885 mean average precision (mAP) for a six-class object detection problem. The same approach with an input of size 416×416 yields 0.974 mAP for the two-class firearm detection problem and requires approximately 100 ms per image. Overall we illustrate the comparative performance of these techniques and show that object localization strategies cope well with cluttered X-ray security imagery, where classification techniques fail.","","","10.1109/TIFS.2018.2812196","Home Office Centre for Applied Science and Technology (CAST), Department for Transport, Centre for Protection of National Infrastructure (CNPI), Metropolitan Police Service, Defense Science and Technology Laboratory (U.K. MOD) and Innovate U.K. under various U.K. government programs; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8306909","Deep convolutional neural networks;transfer learning;image classification;detection;X-ray baggage security","X-ray imaging;Support vector machines;Security;Task analysis;Feature extraction;Convolutional neural networks;Object detection","convolution;feature extraction;feedforward neural nets;image classification;image representation;image segmentation;learning (artificial intelligence);object detection;pattern classification;security;support vector machines","deep convolutional neural network architectures;X-ray baggage security imagery;deep convolutional neural networks;detection problems;CNN approach;complex end-to-end feature extraction;X-ray security screening;transfer learning paradigm;generalized image classification tasks;sufficient training data;support vector machine classifier;fine-tuned CNN features;object classification tasks;AlexNet features;SVM classifier;multiple CNN driven detection paradigms;fully convolutional networks;YOLOv2;single detections;multiple detections;SW-CNN approaches;six-class object detection problem;two-class firearm detection problem;object localization strategies;cluttered X-ray security imagery;classification techniques;feature-space comparison;feature space representations","","9","50","","","","","IEEE","IEEE Journals"
"Discriminative Deep Feature Learning for Semantic-Based Image Retrieval","K. Song; F. Li; F. Long; J. Wang; Q. Ling","Department of Automation, University of Science and Technology of China, Hefei, China; Department of Automation, University of Science and Technology of China, Hefei, China; Chinaso Inc., Beijing, China; Laboratory of Precision Sensing and Control Center, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Department of Automation, University of Science and Technology of China, Hefei, China","IEEE Access","","2018","6","","44268","44280","Semantic-based image retrieval plays an important role in many practical applications, which aims to look for images with similar contents. Extracting discriminative representations of images is the real crux of this task. Directly utilizing the results of fully connected layers of convolutional neural networks (CNNs) is one of the best feature extraction methods. However, the fully connected layer is only supervised by the softmax loss, which only aims to maximize the accuracy of object classification and hardly pays attention to the spatial distribution of features, especially the intra-class and inter-class feature distances which are of great importance in semantic-based image retrieval. To compensate the performance degradation due to this reason, we try to address the spatial distribution of the features by two different loss functions. The first loss function jointly combines the softmax loss and the center loss in the training of the CNNs, which simultaneously ensures that the features of images with different contents are separable and the features of images in the same class are close. The second loss function is defined as an improved center loss which not only penalizes the distance between the obtained deep feature and the feature center of its own class, but also encourages a far distance between the feature and the feature centers of any other classes. We have conducted experiments on both ILSVRC data set and Caltech256 data set, demonstrated that the deep features got by our approaches can achieve better performance than other methods in semantic-based image retrieval, and the improved center loss can further outperform the joint supervision of the softmax loss and the center loss.","","","10.1109/ACCESS.2018.2862464","National Basic Research Program of China (973 Program); Internet Plus major project for the Internet Plus Coordinated Manufacturing Cloud Service Support Platform; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8424337","Convolutional neural networks;discriminative deep feature learning;improved center loss;semantic-based image retrieval","Image retrieval;Feature extraction;Semantics;Graphical models;Distribution functions;Task analysis;Convolutional neural networks","content-based retrieval;feature extraction;feedforward neural nets;image classification;image representation;image retrieval;learning (artificial intelligence);object recognition","loss function;softmax loss;improved center loss;semantic-based image retrieval;discriminative deep feature;fully connected layer;feature extraction methods;inter-class feature distances;convolutional neural networks;CNN;ILSVRC data set;Caltech256 data set","","1","51","","","","","IEEE","IEEE Journals"
"Deep Abstraction and Weighted Feature Selection for Wi-Fi Impersonation Detection","M. E. Aminanto; R. Choi; H. C. Tanuwidjaja; P. D. Yoo; K. Kim","School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Centre for Electronic Warfare, Information and Cyber, Cranfield Defence and Security, Defence Academy of the United Kingdom, Shrivenham, U.K.; School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, South Korea","IEEE Transactions on Information Forensics and Security","","2018","13","3","621","636","The recent advances in mobile technologies have resulted in Internet of Things (IoT)-enabled devices becoming more pervasive and integrated into our daily lives. The security challenges that need to be overcome mainly stem from the open nature of a wireless medium, such as a Wi-Fi network. An impersonation attack is an attack in which an adversary is disguised as a legitimate party in a system or communications protocol. The connected devices are pervasive, generating high-dimensional data on a large scale, which complicates simultaneous detections. Feature learning, however, can circumvent the potential problems that could be caused by the large-volume nature of network data. This paper thus proposes a novel deep-feature extraction and selection (D-FES), which combines stacked feature extraction and weighted feature selection. The stacked autoencoding is capable of providing representations that are more meaningful by reconstructing the relevant information from its raw inputs. We then combine this with modified weighted feature selection inspired by an existing shallow-structured machine learner. We finally demonstrate the ability of the condensed set of features to reduce the bias of a machine learner model as well as the computational complexity. Our experimental results on a well-referenced Wi-Fi network benchmark data set, namely, the Aegean Wi-Fi Intrusion data set, prove the usefulness and the utility of the proposed D-FES by achieving a detection accuracy of 99.918% and a false alarm rate of 0.012%, which is the most accurate detection of impersonation attacks reported in the literature.","","","10.1109/TIFS.2017.2762828","Institute for Information & communications Technology Promotion through the Korea Government (MSIT) (Research on Communication Technology using Bio-Inspired Algorithm and 2017-0-00555, Towards Provable-secure Multi-party Authenticated Key Exchange Protocol based on Lattices in a Quantum World); National Research Foundation of Korea through the Korea Government (MSIT); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8067440","Intrusion detection system;impersonation attack;deep learning;feature extraction;stacked autoencoder;large-scale Wi-Fi networks","Feature extraction;Wireless fidelity;Support vector machines;Wireless networks;Computational modeling;Security;Machine learning","computer network security;feature extraction;Internet of Things;learning (artificial intelligence);security of data;telecommunication security;wireless LAN","simultaneous detections;feature learning;large-volume nature;deep-feature extraction;modified weighted feature selection;Wi-Fi network benchmark data;Aegean Wi-Fi Intrusion data;detection accuracy;accurate detection;impersonation attack;Wi-Fi impersonation detection;mobile technologies;security challenges;wireless medium;high-dimensional data;shallow-structured machine learner","","14","71","","","","","IEEE","IEEE Journals"
"Layouts From Panoramic Images With Geometry and Deep Learning","C. Fernandez-Labrador; A. Perez-Yus; G. Lopez-Nicolas; J. J. Guerrero","Instituto de Investigación en Ingeniería de Aragón, Universidad de Zaragoza, Zaragoza, Spain; Instituto de Investigación en Ingeniería de Aragón, Universidad de Zaragoza, Zaragoza, Spain; Instituto de Investigación en Ingeniería de Aragón, Universidad de Zaragoza, Zaragoza, Spain; Instituto de Investigación en Ingeniería de Aragón, Universidad de Zaragoza, Zaragoza, Spain","IEEE Robotics and Automation Letters","","2018","3","4","3153","3160","In this letter, we propose a novel procedure for three-dimensional layout recovery of indoor scenes from single 360° panoramic images. With such images, all scene is seen at once, allowing us to recover closed geometries. Our method combines strategically the accuracy provided by geometric reasoning (lines and vanishing points) with the higher level of data abstraction and pattern recognition achieved by deep learning techniques (edge and normal maps). Thus, we extract structural corners from which we generate layout hypotheses of the room assuming Manhattan world. The best layout model is selected, achieving good performance on both simple rooms (box-type), and complex shaped rooms (with more than four walls). Experiments of the proposed approach are conducted within two public datasets, SUN360 and Stanford (2D-3D-S) demonstrating the advantages of estimating layouts by combining geometry and deep learning and the effectiveness of our proposal with respect to the state of the art.","","","10.1109/LRA.2018.2850532","Projects DPI2014-61792-EXP and DPI2015-65962-R (MINECO/FEDER UE); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8395352","Omnidirectional vision;semantic scene understanding","Layout;Geometry;Machine learning;Image edge detection;Three-dimensional displays;Proposals;Estimation","computer vision;geometry;learning (artificial intelligence);stereo image processing","three-dimensional layout recovery;closed geometries;geometric reasoning;vanishing points;data abstraction;pattern recognition;deep learning techniques;normal maps;structural corners;layout hypotheses;Manhattan world;layout model;box-type;complex shaped rooms;SUN360;time 2.0 d","","","24","","","","","IEEE","IEEE Journals"
"Direction-of-Arrival Estimation Based on Deep Neural Networks With Robustness to Array Imperfections","Z. Liu; C. Zhang; P. S. Yu","State Key Laboratory of Complex Electromagnetic Environment Effects on Electronics and Information System, National University of Defense Technology, Changsha, China; Department of Computer Science, The University of Illinois at Chicago, Chicago, IL, USA; Department of Computer Science, The University of Illinois at Chicago, Chicago, IL, USA","IEEE Transactions on Antennas and Propagation","","2018","66","12","7315","7327","Lacking of adaptation to various array imperfections is an open problem for most high-precision direction-of-arrival (DOA) estimation methods. Machine learning-based methods are data-driven, they do not rely on prior assumptions about array geometries, and are expected to adapt better to array imperfections when compared with model-based counterparts. This paper introduces a framework of the deep neural network to address the DOA estimation problem, so as to obtain good adaptation to array imperfections and enhanced generalization to unseen scenarios. The framework consists of a multitask autoencoder and a series of parallel multilayer classifiers. The autoencoder acts like a group of spatial filters, it decomposes the input into multiple components in different spatial subregions. These components thus have more concentrated distributions than the original input, which helps to reduce the burden of generalization for subsequent DOA estimation classifiers. The classifiers follow a one-versus-all classification guideline to determine if there are signal components near preseted directional grids, and the classification results are concatenated to reconstruct a spatial spectrum and estimate signal directions. Simulations are carried out to show that the proposed method performs satisfyingly in both generalization and imperfection adaptation.","","","10.1109/TAP.2018.2874430","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8485631","Array imperfection;deep neural network (DNN);direction-of-arrival (DOA) estimation;multitask autoencoder;one-versus-all classification;supervised learning","Direction-of-arrival estimation;Estimation;Arrays;Adaptive arrays;Neural networks;Machine learning;Array signal processing","array signal processing;direction-of-arrival estimation;learning (artificial intelligence);neural nets;signal classification;signal reconstruction","array geometries;array imperfections;deep neural network;DOA estimation problem;machine learning;direction-of-arrival estimation;DOA estimation classifiers;multitask autoencoder;parallel multilayer classifiers;spatial filters;one-versus-all classification guideline;signal components","","14","60","","","","","IEEE","IEEE Journals"
"Deep Learning Modeling for Top-N Recommendation With Interests Exploring","W. Zhou; J. Li; M. Zhang; Y. Wang; F. Shah","School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Optoelectronic Information, University of Electronic Science and Technology of China, Chengdu, China; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China","IEEE Access","","2018","6","","51440","51455","Recommender systems (RS) currently play a crucial role in information filtering and retrieval, and have been ubiquitously applied in many domains, although suffering from such data sparsity and cold start problems. There are plenty of studies that try to make efforts to improve the performance of RS through different aspects, such as traditional matrix factorization technique and deep learning methods in recent years, however, it's still a challenging issue under research. In this paper, motivated by this, a two-stage deep learning-based model for top-N recommendation with interests exploring (DLMR) is proposed: 1) DLMR explores latent interests for each user, captures factors from reviews and contextual information via convolutional neural network, and performs convolutional matrix factorization to generate the candidates list; 2) In order to enhance the recommendation performance, DLMR further conducts candidates ranking through a three-layer denoising autoencoder, with taking account of heterogeneous side information. The DLMR provides a flexible scheme to leverage the available resources for recommendation, which is able to explore user's latent interests, capture the intricate interactions between users and items, and provide accurate and personalized recommendations. Experimental analysis over real world data sets demonstrates that DLMR could provide high performance top-N recommendation in sparse settings and outperform state-of-the-art recommender approaches significantly.","","","10.1109/ACCESS.2018.2869924","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8463482","Sparse latent Dirichlet allocation;interest exploring;convolutional neural network;denoising autoencoder;top-N recommendation","Machine learning;Recommender systems;Convolutional neural networks;Noise reduction;Probabilistic logic;Resource management;Tools","convolution;feedforward neural nets;information filtering;learning (artificial intelligence);matrix decomposition;recommender systems","recommender systems;information filtering;DLMR;contextual information;convolutional neural network;heterogeneous side information;personalized recommendations;deep learning-based model for top-N recommendation;convolutional matrix factorization;user latent interests;information retrieval","","1","47","","","","","IEEE","IEEE Journals"
"Multi-Targeted Adversarial Example in Evasion Attack on Deep Neural Network","H. Kwon; Y. Kim; K. Park; H. Yoon; D. Choi","School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Department of Electrical Engineering, Korea Military Academy, Seoul, South Korea; Department of Computer and Information Security, Sejong University, Seoul, South Korea; School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Department of Medical Information, Kongju National University, Gongju, South Korea","IEEE Access","","2018","6","","46084","46096","Deep neural networks (DNNs) are widely used for image recognition, speech recognition, pattern analysis, and intrusion detection. Recently, the adversarial example attack, in which the input data are only slightly modified, although not an issue for human interpretation, is a serious threat to a DNN as an attack as it causes the machine to misinterpret the data. The adversarial example attack has been receiving considerable attention owing to its potential threat to machine learning. It is divided into two categories: targeted adversarial example and untargeted adversarial example. The untargeted adversarial example happens when machines misclassify an object into an incorrect class. In contrast, the targeted adversarial example attack causes machines to misinterpret the image as the attacker's desired class. Thus, the latter is a more elaborate and powerful attack than the former. The existing targeted adversarial example is a single targeted attack that allows only one class to be recognized. However, in some cases, a multitargeted adversarial example can be useful for an attacker to make multiple models recognize a single original image as different classes. For example, an attacker can use a single road sign generated by a multi-targeted adversarial example scheme to make model A recognize it as a stop sign and model B recognize it as a left turn, whereas a human might recognize it as a right turn. Therefore, in this paper, we propose a multi-targeted adversarial example that attacks multiple models within each target class with a single modified image. To produce such examples, we carried out a transformation to maximize the probability of different target classes by multiple models. We used the MNIST datasets and TensorFlow library for our experiment. The experimental results showed that the proposed scheme for generating a multi-targeted adversarial example achieved a 100% attack success rate.","","","10.1109/ACCESS.2018.2866197","National Research Foundation of Korea; Korea Government (MSIT); Institute for Information and Communications Technology Promotion; Korea Government (MSIT) (Security Technologies for Financial Fraud Prevention on Fintech); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8439941","Deep neural network (DNN);evasion attack;adversarial example;machine learning","Target recognition;Distortion;Machine learning;Training;Neural networks;Image recognition;Perturbation methods","image recognition;learning (artificial intelligence);neural nets;pattern classification;probability;security of data","evasion attack;deep neural network;untargeted adversarial example;targeted adversarial example attack;multitargeted adversarial example scheme;image recognition;speech recognition;pattern analysis;intrusion detection;human interpretation;machine learning;probability;tensorflow library","","7","44","","","","","IEEE","IEEE Journals"
"Real-World Multiobject, Multigrasp Detection","F. Chu; R. Xu; P. A. Vela","Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA; Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA; Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA","IEEE Robotics and Automation Letters","","2018","3","4","3355","3362","A deep learning architecture is proposed to predict graspable locations for robotic manipulation. It considers situations where no, one, or multiple object(s) are seen. By defining the learning problem to be classified with null hypothesis competition instead of regression, the deep neural network with red, green, blue and depth (RGB-D) image input predicts multiple grasp candidates for a single object or multiple objects, in a single shot. The method outperforms state-of-the-art approaches on the Cornell dataset with 96.0% and 96.1% accuracy on imagewise and object-wise splits, respectively. Evaluation on a multiobject dataset illustrates the generalization capability of the architecture. Grasping experiments achieve 96.0% grasp localization and 89.0% grasping success rates on a test set of household objects. The real-time process takes less than 0.25 s from image to plan.","","","10.1109/LRA.2018.2852777","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8403246","Perception for grasping;grasping;deep learning in robotic automation","Grasping;Proposals;Robots;Machine learning;Planning;Training;Feature extraction","dexterous manipulators;learning (artificial intelligence);neural net architecture;object detection;object recognition;regression analysis;robot vision","multigrasp detection;deep learning architecture;graspable locations;robotic manipulation;learning problem;null hypothesis competition;deep neural network;Cornell dataset;object-wise splits;multiobject dataset;grasping experiments;household objects;red, green, blue and depth image input;RGB-D image input","","4","32","","","","","IEEE","IEEE Journals"
"A Deep Convolutional Coupling Network for Change Detection Based on Heterogeneous Optical and Radar Images","J. Liu; M. Gong; K. Qin; P. Zhang","Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, Xidian University, Xi’an, China; School of Computer Science and Information Technology, RMIT University, Melbourne, VIC, Australia; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, Xidian University, Xi’an, China","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","3","545","559","We propose an unsupervised deep convolutional coupling network for change detection based on two heterogeneous images acquired by optical sensors and radars on different dates. Most existing change detection methods are based on homogeneous images. Due to the complementary properties of optical and radar sensors, there is an increasing interest in change detection based on heterogeneous images. The proposed network is symmetric with each side consisting of one convolutional layer and several coupling layers. The two input images connected with the two sides of the network, respectively, are transformed into a feature space where their feature representations become more consistent. In this feature space, the different map is calculated, which then leads to the ultimate detection map by applying a thresholding algorithm. The network parameters are learned by optimizing a coupling function. The learning process is unsupervised, which is different from most existing change detection methods based on heterogeneous images. Experimental results on both homogenous and heterogeneous images demonstrate the promising performance of the proposed network compared with several existing approaches.","","","10.1109/TNNLS.2016.2636227","National Natural Science Foundation of China; National Program for Support of Top-Notch Young Professionals of China; Specialized Research Fund for the Doctoral Program of Higher Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7795259","Change detection;deep neural network;denoising autoencoder optical images;synthetic aperture radar images","Optical sensors;Optical imaging;Feature extraction;Neural networks;Couplings;Laser radar","feature extraction;image representation;object detection;optical images;radar imaging;unsupervised learning","unsupervised deep convolutional coupling network;optical sensors;homogeneous images;convolutional layer;coupling layers;feature space;ultimate detection map;network parameters;coupling function;change detection methods;heterogeneous optical and radar images;thresholding algorithm;learning process","","33","57","","","","","IEEE","IEEE Journals"
"Good Features to Correlate for Visual Tracking","E. Gundogdu; A. A. Alatan","Department of Intelligent Data Analytics Research Program, ASELSAN Research Center, Ankara, Turkey; Department of Electrical and Electronics Engineering, Center for Image Analysis (OGAM), Middle East Technical University, Ankara, Turkey","IEEE Transactions on Image Processing","","2018","27","5","2526","2540","During the recent years, correlation filters have shown dominant and spectacular results for visual object tracking. The types of the features that are employed in this family of trackers significantly affect the performance of visual tracking. The ultimate goal is to utilize the robust features invariant to any kind of appearance change of the object, while predicting the object location as properly as in the case of no appearance change. As the deep learning based methods have emerged, the study of learning features for specific tasks has accelerated. For instance, discriminative visual tracking methods based on deep architectures have been studied with promising performance. Nevertheless, correlation filter based (CFB) trackers confine themselves to use the pre-trained networks, which are trained for object classification problem. To this end, in this manuscript the problem of learning deep fully convolutional features for the CFB visual tracking is formulated. In order to learn the proposed model, a novel and efficient backpropagation algorithm is presented based on the loss function of the network. The proposed learning framework enables the network model to be flexible for a custom design. Moreover, it alleviates the dependency on the network trained for classification. Extensive performance analysis shows the efficacy of the proposed custom design in the CFB tracking framework. By fine-tuning the convolutional parts of a state-of-the-art network and integrating this model to a CFB tracker, which is the top performing one of VOT2016, 18% increase is achieved in terms of expected average overlap, and tracking failures are decreased by 25%, while maintaining the superiority over the state-of-the-art methods in OTB-2013 and OTB-2015 tracking datasets.","","","10.1109/TIP.2018.2806280","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8291524","Visual tracking;correlation filters;deep feature learning","Correlation;Visualization;Target tracking;Training;Convolution;Computational modeling;Machine learning","backpropagation;image filtering;neural nets;object tracking","visual object tracking;deep learning based methods;pre-trained networks;object classification problem;deep fully convolutional features;CFB visual tracking;learning framework;CFB tracking framework;OTB-2015 tracking datasets;correlation filter based trackers;deep fully convolutional features learning;backpropagation algorithm;network loss function;OTB-2013 tracking datasets","","9","70","","","","","IEEE","IEEE Journals"
"Learning Based Image Transformation Using Convolutional Neural Networks","X. Hou; Y. Gong; B. Liu; K. Sun; J. Liu; B. Xu; J. Duan; G. Qiu","College of Information Engineering, Shenzhen University, Shenzhen, China; College of Information Engineering, Shenzhen University, Shenzhen, China; College of Information Engineering, Shenzhen University, Shenzhen, China; Key Laboratory of Spatial Information Smarting Sensing and Services, Shenzhen University, Shenzhen, China; College of Information Engineering, Shenzhen University, Shenzhen, China; College of Information Engineering, Shenzhen University, Shenzhen, China; School of Economic Information Engineering, Southwestern University of Finance and Economics, Chengdu, China; College of Information Engineering, Shenzhen University, Shenzhen, China","IEEE Access","","2018","6","","49779","49792","We have developed a learning-based image transformation framework and successfully applied it to three common image transformation operations: downscaling, decolorization, and high dynamic range image tone mapping. We use a convolutional neural network (CNN) as a non-linear mapping function to transform an input image to a desired output. A separate CNN network trained for a very large image classification task is used as a feature extractor to construct the training loss function of the image transformation CNN. Unlike similar applications in the related literature such as image super-resolution, none of the problems addressed in this paper have a known ground truth or target. For each problem, we reason about a suitable learning objective function and develop an effective solution. This is the first work that uses deep learning to solve and unify these three common image processing tasks. We present experimental results to demonstrate the effectiveness of the new technique and its state-of-the-art performances.","","","10.1109/ACCESS.2018.2868733","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8456517","Deep learning;image downscaling;image decolorization;HDR image tone mapping","Task analysis;Dynamic range;Convolutional neural networks;Image resolution;Indexes;Visualization","convolution;feature extraction;feedforward neural nets;image classification;image colour analysis;image resolution;inference mechanisms;learning (artificial intelligence)","nonlinear mapping function;input image;image classification task;training loss function;image transformation CNN;deep learning;convolutional neural network;learning-based image transformation framework;decolorization;high dynamic range image tone mapping;CNN network;learning objective function;image processing tasks;feature extractor;image transformation operations;downscaling","","1","52","","","","","IEEE","IEEE Journals"
"Cognitive Privacy Middleware for Deep Learning Mashup in Environmental IoT","A. M. Elmisery; M. Sertovic; B. B. Gupta","Department of Electronics Engineering, Universidad Tecnica Federico Santa Maria, Valparaiso, Chile; Faculty of Humanities and Social Sciences, University of Zagreb, Zagreb, Croatia; National Institute of Technology Kurukshetra, Kurukshetra, India","IEEE Access","","2018","6","","8029","8041","Data mashup is a Web technology that combines information from multiple sources into a single Web application. Mashup applications support new services, such as environmental monitoring. The different organizations utilize data mashup services to merge data sets from the different Internet of Multimedia Things (IoMT) context-based services in order to leverage the performance of their data analytics. However, mashup, different data sets from multiple sources, is a privacy hazard as it might reveal citizens specific behaviors in different regions. In this paper, we present our efforts to build a cognitive-based middleware for private data mashup (CMPM) to serve a centralized environmental monitoring service. The proposed middleware is equipped with concealment mechanisms to preserve the privacy of the merged data sets from multiple IoMT networks involved in the mashup application. In addition, we presented an IoT-enabled data mashup service, where the multimedia data are collected from the various IoMT platforms, and then fed into an environmental deep learning service in order to detect interesting patterns in hazardous areas. The viable features within each region were extracted using a multiresolution wavelet transform, and then fed into a discriminative classifier to extract various patterns. We also provide a scenario for IoMT-enabled data mashup service and experimentation results.","","","10.1109/ACCESS.2017.2787422","Dirección General de Investigación, Innovación y Postgrado through the Security in Cyber-Physical Systems for Power Grids Project, Federico Santa María Technical University, Chile; Advanced Center for Electrical and Electronic Engineering CONICYT-Basal Project; Microsoft Azure for Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8240886","IoT networks;cloud computing;environmental monitoring;smart cities;big data mashup;multimedia data","Mashups;Fires;Privacy;Environmental monitoring;Data privacy;Multimedia communication;Sensors","cloud computing;data analysis;data mining;data privacy;environmental monitoring (geophysics);environmental science computing;Internet;Internet of Things;learning (artificial intelligence);middleware;mobile computing;wavelet transforms;Web services","cognitive privacy middleware;deep learning mashup;single Web application;mashup application;data mashup service;data analytics;cognitive-based middleware;private data mashup;centralized environmental monitoring service;multimedia data;environmental deep learning service;environmental IoT","","1","53","","","","","IEEE","IEEE Journals"
"Deep Learning Global Glomerulosclerosis in Transplant Kidney Frozen Sections","J. N. Marsh; M. K. Matlock; S. Kudose; T. Liu; T. S. Stappenbeck; J. P. Gaut; S. J. Swamidass","Department of Pathology and Immunology, Washington University School of Medicine, St. Louis, MO, USA; Department of Pathology and Immunology, Washington University in St. Louis, St. Louis, MO, USA; Department of Pathology and Immunology, Washington University in St. Louis, St. Louis, MO, USA; Department of Pathology and Immunology, Washington University in St. Louis, St. Louis, MO, USA; Department of Pathology and Immunology, Washington University in St. Louis, St. Louis, MO, USA; Department of Pathology and Immunology, Washington University in St. Louis, St. Louis, MO, USA; Department of Pathology and Immunology, Washington University School of Medicine, St. Louis, MO, USA","IEEE Transactions on Medical Imaging","","2018","37","12","2718","2728","Transplantable kidneys are in very limited supply. Accurate viability assessment prior to transplantation could minimize organ discard. Rapid and accurate evaluation of intra-operative donor kidney biopsies is essential for determining which kidneys are eligible for transplantation. The criterion for accepting or rejecting donor kidneys relies heavily on pathologist determination of the percent of glomeruli (determined from a frozen section) that are normal and sclerotic. This percentage is a critical measurement that correlates with transplant outcome. Inter- and intra-observer variability in donor biopsy evaluation is, however, significant. An automated method for determination of percent global glomerulosclerosis could prove useful in decreasing evaluation variability, increasing throughput, and easing the burden on pathologists. Here, we describe the development of a deep learning model that identifies and classifies non-sclerosed and sclerosed glomeruli in whole-slide images of donor kidney frozen section biopsies. This model extends a convolutional neural network (CNN) pre-trained on a large database of digital images. The extended model, when trained on just 48 whole slide images, exhibits slide-level evaluation performance on par with expert renal pathologists. Encouragingly, the model's performance is robust to slide preparation artifacts associated with frozen section preparation. The model substantially outperforms a model trained on image patches of isolated glomeruli, in terms of both accuracy and speed. The methodology overcomes the technical challenge of applying a pretrained CNN bottleneck model to whole-slide image classification. The traditional patch-based approach, while exhibiting deceptively good performance classifying isolated patches, does not translate successfully to whole-slide image segmentation in this setting. As the first model reported that identifies and classifies normal and sclerotic glomeruli in frozen kidney sections, and thus the first model reported in the literature relevant to kidney transplantation, it may become an essential part of donor kidney biopsy evaluation in the clinical setting.","","","10.1109/TMI.2018.2851150","Mid-America Transplant Foundation; National Institutes of Health; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8398488","Kidney;glomerulosclerosis;digital pathology;fully convolutional network;donor organ evaluation","Kidney;Image segmentation;Training;Biological system modeling;Rats;Immune system","cancer;diseases;feature extraction;feedforward neural nets;image classification;image segmentation;kidney;learning (artificial intelligence);medical image processing;neural nets","deep learning global glomerulosclerosis;transplant kidney frozen sections;transplantable kidneys;accurate viability assessment;organ discard;intra-operative donor kidney biopsies;accepting rejecting donor kidneys;pathologist determination;transplant outcome;intra-observer variability;donor biopsy evaluation;percent global glomerulosclerosis;evaluation variability;deep learning model;sclerosed glomeruli;whole-slide images;donor kidney frozen section biopsies;convolutional neural network pre-trained;digital images;expert renal pathologists;frozen section preparation;image patches;isolated glomeruli;pretrained CNN bottleneck model;whole-slide image classification;deceptively good performance classifying isolated patches;whole-slide image segmentation;normal glomeruli;sclerotic glomeruli;frozen kidney sections;kidney transplantation;donor kidney biopsy evaluation;slide-level evaluation performance","","1","52","","","","","IEEE","IEEE Journals"
"Embedding Visual Hierarchy With Deep Networks for Large-Scale Visual Recognition","T. Zhao; B. Zhang; M. He; W. Zhang; N. Zhou; J. Yu; J. Fan","Department of Computer Science, University of North Carolina at Charlotte, Charlotte, NC, USA; University of North Carolina at Charlotte, Charlotte, NC, USA; Quantum Laboratory, Research Institute of OPPO, Shanghai, China; University of North Carolina at Charlotte, Charlotte, NC, USA; Amazon, Inc., Seattle, WA, USA; University of North Carolina at Charlotte, Charlotte, NC, USA; Department of Computer Science, University of North Carolina at Charlotte, Charlotte, NC, USA","IEEE Transactions on Image Processing","","2018","27","10","4740","4755","In this paper, a layer-wise mixture model (LMM) is developed to support hierarchical visual recognition, where a Bayesian approach is used to automatically adapt the visual hierarchy to the progressive improvements of the deep network along the time. Our LMM algorithm can provide an end-to-end approach for jointly learning: 1) the deep network for achieving more discriminative deep representations for object classes and their inter-class visual similarities; 2) the tree classifier for recognizing large numbers of object classes hierarchically; and 3) the visual hierarchy adaptation for achieving more accurate assignment and organization of large numbers of object classes. By learning the tree classifier, the deep network and the visual hierarchy adaptation jointly in an end-to-end manner, our LMM algorithm can achieve higher accuracy rates on hierarchical visual recognition. Our experiments are carried on ImageNet1K and ImageNet10K image sets, which have demonstrated that our LMM algorithm can achieve very competitive results on the accuracy rates as compared with the baseline methods.","","","10.1109/TIP.2018.2845118","National Science Foundation; Program of Shaanxi Province Innovative Research Team; Program for Changjiang Scholars and Innovative Research Team in University; National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8374885","Hierarchical visual recognition;layer-wise mixture model (LMM);visual hierarchy adaptation;deep network;tree classifier;Bayesian approach","Visualization;Task analysis;Machine learning;Training;Image recognition;Electronic mail;Mixture models","Bayes methods;image classification;learning (artificial intelligence);mixture models;object recognition;trees (mathematics)","tree classifier;object classes;visual hierarchy adaptation;LMM algorithm;hierarchical visual recognition;large-scale visual recognition;layer-wise mixture model;end-to-end approach;discriminative deep representations;deep networks;Bayesian approach;interclass visual similarities;ImageNet1K image set;ImageNet10K image set","","","70","","","","","IEEE","IEEE Journals"
"Combining weather condition data to predict traffic flow: a GRU-based deep learning approach","D. Zhang; M. R. Kabuka","University of Miami, USA; University of Miami, USA","IET Intelligent Transport Systems","","2018","12","7","578","585","Traffic flow prediction is an essential component of the intelligent transportation management system. This study applies gated recurrent neural network to predict urban traffic flow considering weather conditions. Running results show that, under the review of weather influences, their method improves predictive accuracy and also decreases the prediction error rate. To their best knowledge, this is the first time that traffic flow is predicted in urban freeways in this particular way. This study examines it with respect to extensive weather influence under gated recurrent unit-based deep learning framework.","","","10.1049/iet-its.2017.0313","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8436515","","","environmental factors;intelligent transportation systems;learning (artificial intelligence);recurrent neural nets;traffic engineering computing","gated recurrent unit-based deep learning framework;urban freeways;prediction error rate;predictive accuracy;recurrent neural network;intelligent transportation management system;GRU-based deep learning approach;urban traffic flow prediction;weather condition data","","7","42","","","","","IET","IET Journals"
"Learning a Deep Model for Human Action Recognition from Novel Viewpoints","H. Rahmani; A. Mian; M. Shah","School of Computer Science and Software Engineering, University of Western Australia, 35 Stirling Highway, Crawley, WA, Australia; School of Computer Science and Software Engineering, University of Western Australia, 35 Stirling Highway, Crawley, WA, Australia; School of Electric Engineering and Computer Science, University of Central Florida, Orlando, FL","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","3","667","681","Recognizing human actions from unknown and unseen (novel) views is a challenging problem. We propose a Robust Non-Linear Knowledge Transfer Model (R-NKTM) for human action recognition from novel views. The proposed R-NKTM is a deep fully-connected neural network that transfers knowledge of human actions from any unknown view to a shared high-level virtual view by finding a set of non-linear transformations that connects the views. The R-NKTM is learned from 2D projections of dense trajectories of synthetic 3D human models fitted to real motion capture data and generalizes to real videos of human actions. The strength of our technique is that we learn a single R-NKTM for all actions and all viewpoints for knowledge transfer of any real human action video without the need for re-training or fine-tuning the model. Thus, R-NKTM can efficiently scale to incorporate new action classes. R-NKTM is learned with dummy labels and does not require knowledge of the camera viewpoint at any stage. Experiments on three benchmark cross-view human action datasets show that our method outperforms existing state-of-the-art.","","","10.1109/TPAMI.2017.2691768","ARC Discovery; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7893732","Cross-view;dense trajectories;view knowledge transfer","Videos;Trajectory;Three-dimensional displays;Training;Knowledge transfer;Solid modeling;Two dimensional displays","image recognition;learning (artificial intelligence);neural nets;video signal processing","nonlinear transformations;synthetic 3D human models;single R-NKTM;human action video;benchmark cross-view human action datasets;human action recognition;Robust NonLinear Knowledge Transfer Model;fully-connected neural network;high-level virtual view","","24","69","","","","","IEEE","IEEE Journals"
"Two-Dimensional Antijamming Mobile Communication Based on Reinforcement Learning","L. Xiao; D. Jiang; D. Xu; H. Zhu; Y. Zhang; H. V. Poor","Department of Communication Engineering, Xiamen University, Xiamen, China; Department of Communication Engineering, Xiamen University, Xiamen, China; Department of Communication Engineering, Xiamen University, Xiamen, China; Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China; Wireless Information Networks Laboratory, Rutgers University, North Brunswick, NJ, USA; Department of Electrical Engineering, Princeton University, Princeton, NJ, USA","IEEE Transactions on Vehicular Technology","","2018","67","10","9499","9512","By using smart radio devices, a jammer can dynamically change its jamming policy based on opposing security mechanisms; it can even induce the mobile device to enter a specific communication mode and then launch the jamming policy accordingly. On the other hand, mobile devices can exploit spread spectrum and user mobility to address both jamming and interference. In this paper, a two-dimensional (2-D) antijamming mobile communication scheme is proposed in which a mobile device leaves a heavily jammed/interfered-with frequency or area. It is shown that, by applying reinforcement learning techniques, a mobile device can achieve an optimal communication policy without the need to know the jamming and interference model and the radio channel model in a dynamic game framework. More specifically, a hotbooting deep Q-network based 2-D mobile communication scheme is proposed that exploits experiences in similar scenarios to reduce the exploration time at the beginning of the game, and applies deep convolutional neural network and macro-action techniques to accelerate learning in dynamic situations. Several real-world scenarios are simulated to evaluate the proposed method. These simulation results show that our proposed scheme can improve both the signal-to-interference-plus-noise ratio of the signals and the utility of the mobile devices against cooperative jamming compared with benchmark schemes.","","","10.1109/TVT.2018.2856854","National Natural Science Foundation of China; National Science Foundation; National Mobile Communications Research Laboratory, Southeast University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8412128","Mobile devices;jamming;reinforcement learning;game theory;deep Q-network","Jamming;Mobile handsets;Interference;Mobile communication;Robot sensing systems;Games","game theory;jamming;learning (artificial intelligence);mobile communication;mobile radio;neural nets;telecommunication security;wireless channels","smart radio devices;jamming policy;mobile device;user mobility;optimal communication policy;2D antijamming mobile communication scheme;reinforcement learning techniques;hotbooting deep Q-network based 2-D mobile communication scheme;deep convolutional neural network","","16","31","","","","","IEEE","IEEE Journals"
"LS-VO: Learning Dense Optical Subspace for Robust Visual Odometry Estimation","G. Costante; T. A. Ciarfuglia","Department of Engineering, University of Perugia, Perugia, Italy; Department of Engineering, University of Perugia, Perugia, Italy","IEEE Robotics and Automation Letters","","2018","3","3","1735","1742","This work proposes a novel deep network architecture to solve the camera ego-motion estimation problem. A motion estimation network generally learns features similar to optical flow (OF) fields starting from sequences of images. This OF can be described by a lower dimensional latent space. Previous research has shown how to find linear approximations of this space. We propose to use an autoencoder network to find a nonlinear representation of the OF manifold. In addition, we propose to learn the latent space jointly with the estimation task, so that the learned OF features become a more robust description of the OF input. We call this novel architecture latent space visual odometry (LS-VO). The experiments show that LS-VO achieves a considerable increase in performances with respect to baselines, while the number of parameters of the estimation network only slightly increases.","","","10.1109/LRA.2018.2803211","NVIDIA Corporation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8283696","Computer vision for transportation;deep learning in robotics and automation;visual learning;visual-based navigation","Estimation;Cameras;Computer architecture;Robustness;Visual odometry;Optical flow","approximation theory;cameras;distance measurement;feature extraction;image coding;image representation;image sequences;learning (artificial intelligence);motion estimation","motion estimation network;optical flow;lower dimensional latent space;linear approximations;autoencoder network;nonlinear representation;estimation task;robust description;LS-VO;robust visual odometry estimation;deep network architecture;camera ego-motion estimation problem;latent space visual odometry;learning dense optical subspace;image sequence","","1","36","","","","","IEEE","IEEE Journals"
"On-Chip Communication Network for Efficient Training of Deep Convolutional Networks on Heterogeneous Manycore Systems","W. Choi; K. Duraisamy; R. G. Kim; J. R. Doppa; P. P. Pande; D. Marculescu; R. Marculescu","Electrical Engineering and Computer Science, Washington State University, Pullman, WA; Electrical Engineering and Computer Science, Washington State University, Pullman, WA; ECE, Carnegie Mellon University, Pittsburgh, PA; Electrical Engineering and Computer Science, Washington State University, Pullman, WA; Electrical Engineering and Computer Science, Washington State University, Pullman, WA; ECE, Carnegie Mellon University, Pittsburgh, PA; ECE, Carnegie Mellon University, Pittsburgh, PA","IEEE Transactions on Computers","","2018","67","5","672","686","Convolutional Neural Networks (CNNs) have shown a great deal of success in diverse application domains including computer vision, speech recognition, and natural language processing. However, as the size of datasets and the depth of neural network architectures continue to grow, it is imperative to design high-performance and energy-efficient computing hardware for training CNNs. In this paper, we consider the problem of designing specialized CPU-GPU based heterogeneous manycore systems for energy-efficient training of CNNs. It has already been shown that the typical on-chip communication infrastructures employed in conventional CPU-GPU based heterogeneous manycore platforms are unable to handle both CPU and GPU communication requirements efficiently. To address this issue, we first analyze the on-chip traffic patterns that arise from the computational processes associated with training two deep CNN architectures, namely, LeNet and CDBNet, to perform image classification. By leveraging this knowledge, we design a hybrid Network-on-Chip (NoC) architecture, which consists of both wireline and wireless links, to improve the performance of CPU-GPU based heterogeneous manycore platforms running the above-mentioned CNN training workloads. The proposed NoC achieves 1.8× reduction in network latency and improves the network throughput by a factor of 2.2 for training CNNs, when compared to a highly-optimized wireline mesh NoC. For the considered CNN workloads, these network-level improvements translate into 25 percent savings in full-system energy-delay-product (EDP). This demonstrates that the proposed hybrid NoC for heterogeneous manycore architectures is capable of significantly accelerating training of CNNs while remaining energy-efficient.","","","10.1109/TC.2017.2777863","NSF; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8119941","System-on-chip;Deep learning;Manycore systems;Wireless communication;Energy-efficient computing;Heterogeneous Architectures;Network-on-Chip","Computer architecture;Graphics processing units;Training;Wireless communication;System-on-chip;Machine learning;Wireless sensor networks","coprocessors;feedforward neural nets;graphics processing units;learning (artificial intelligence);multiprocessing systems;network-on-chip","deep convolutional Networks;Convolutional Neural Networks;diverse application;computer vision;speech recognition;natural language processing;neural network architectures;energy-efficient computing hardware;specialized CPU-GPU based heterogeneous manycore systems;energy-efficient training;on-chip communication;conventional CPU-GPU based heterogeneous manycore platforms;on-chip traffic patterns;computational processes;Network-on-Chip architecture;network throughput;highly-optimized wireline mesh NoC;network-level improvements;full-system energy-delay-product;heterogeneous manycore architectures;accelerating training;deep CNN architectures;On-Chip Communication Network;On-Chip Communication Network;high-performance computing hardware;training workloads;EDP;wireless links;wireline links","","11","50","","","","","IEEE","IEEE Journals"
"Joint Optic Disc and Cup Segmentation Based on Multi-Label Deep Network and Polar Transformation","H. Fu; J. Cheng; Y. Xu; D. W. K. Wong; J. Liu; X. Cao","Institute for Infocomm Research, Agency for Science, Technology and Research, Singapore; Institute for Infocomm Research, Agency for Science, Technology and Research, Singapore; Guangzhou Shiyuan Electronics Co., Ltd. (CVTE), Guangzhou, China; Institute for Infocomm Research, Agency for Science, Technology and Research, Singapore; Chinese Academy of Sciences, Cixi Institute of Biomedical Engineering, Zhejiang, China; State Key Laboratory of Information Security, Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Medical Imaging","","2018","37","7","1597","1605","Glaucoma is a chronic eye disease that leads to irreversible vision loss. The cup to disc ratio (CDR) plays an important role in the screening and diagnosis of glaucoma. Thus, the accurate and automatic segmentation of optic disc (OD) and optic cup (OC) from fundus images is a fundamental task. Most existing methods segment them separately, and rely on hand-crafted visual feature from fundus images. In this paper, we propose a deep learning architecture, named M-Net, which solves the OD and OC segmentation jointly in a one-stage multi-label system. The proposed M-Net mainly consists of multi-scale input layer, U-shape convolutional network, side-output layer, and multi-label loss function. The multi-scale input layer constructs an image pyramid to achieve multiple level receptive field sizes. The U-shape convolutional network is employed as the main body network structure to learn the rich hierarchical representation, while the side-output layer acts as an early classifier that produces a companion local prediction map for different scale layers. Finally, a multi-label loss function is proposed to generate the final segmentation map. For improving the segmentation performance further, we also introduce the polar transformation, which provides the representation of the original image in the polar coordinate system. The experiments show that our M-Net system achieves state-of-the-art OD and OC segmentation result on ORIGA data set. Simultaneously, the proposed method also obtains the satisfactory glaucoma screening performances with calculated CDR value on both ORIGA and SCES datasets.","","","10.1109/TMI.2018.2791488","National Key Research and Development Plan; BEP; Ningbo 3315 Innovation Team; National Natural Science Foundation of China; Natural Science Foundation of Beijing Municipality; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8252743","Deep learning;optic disc segmentation;optic cup segmentation;glaucoma screening;cup to disc ratio","Image segmentation;Optical imaging;Biomedical optical imaging;Optical losses;Machine learning;Visualization","biomedical optical imaging;convolution;diseases;eye;feedforward neural nets;image classification;image reconstruction;image segmentation;medical image processing;vision defects","joint optic disc;cup segmentation;multilabel deep network;polar transformation;chronic eye disease;disc ratio;optic cup;deep learning architecture;U-shape convolutional network;side-output layer;multilabel loss function;image pyramid;M-Net system;OC segmentation;glaucoma screening;glaucoma diagnosis","","25","45","","","","","IEEE","IEEE Journals"
"Visualizing Dataflow Graphs of Deep Learning Models in TensorFlow","K. Wongsuphasawat; D. Smilkov; J. Wexler; J. Wilson; D. Mané; D. Fritz; D. Krishnan; F. B. Viégas; M. Wattenberg","Paul G. Allen School of Computer Science & EngineeringUniversity of Washington; Google Research; Google Research; Google Research; Google Research; Google Research; Google Research; Google Research; Google Research","IEEE Transactions on Visualization and Computer Graphics","","2018","24","1","1","12","We present a design study of the TensorFlow Graph Visualizer, part of the TensorFlow machine intelligence platform. This tool helps users understand complex machine learning architectures by visualizing their underlying dataflow graphs. The tool works by applying a series of graph transformations that enable standard layout techniques to produce a legible interactive diagram. To declutter the graph, we decouple non-critical nodes from the layout. To provide an overview, we build a clustered graph using the hierarchical structure annotated in the source code. To support exploration of nested structure on demand, we perform edge bundling to enable stable and responsive cluster expansion. Finally, we detect and highlight repeated structures to emphasize a model's modular composition. To demonstrate the utility of the visualizer, we describe example usage scenarios and report user feedback. Overall, users find the visualizer useful for understanding, debugging, and sharing the structures of their models.","","","10.1109/TVCG.2017.2744878","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8019861","Neural Network;Graph Visualization;Dataflow Graph;Clustered Graph","Visualization;Layout;Machine learning;Computational modeling;Tools;Neural networks;Standards","data flow graphs;data visualisation;graph theory;learning (artificial intelligence)","deep learning models;TensorFlow Graph Visualizer;TensorFlow machine intelligence platform;complex machine learning architectures;graph transformations;standard layout techniques;legible interactive diagram;decouple noncritical nodes;clustered graph;hierarchical structure;nested structure;stable cluster expansion;responsive cluster expansion;dataflow graphs;user feedback","","32","57","Traditional","","","","IEEE","IEEE Journals"
"Noise-Resistant Deep Learning for Object Classification in Three-Dimensional Point Clouds Using a Point Pair Descriptor","D. Bobkov; S. Chen; R. Jian; M. Z. Iqbal; E. Steinbach","Chair of Media Technology, Technical University of Munich, Munich, Germany; Augmented Reality Lab, Baidu Inc., Beijing, China; Chair of Media Technology, Technical University of Munich, Munich, Germany; Chair of Media Technology, Technical University of Munich, Munich, Germany; Chair of Media Technology, Technical University of Munich, Munich, Germany","IEEE Robotics and Automation Letters","","2018","3","2","865","872","Object retrieval and classification in point cloud data are challenged by noise, irregular sampling density, and occlusion. To address this issue, we propose a point pair descriptor that is robust to noise and occlusion and achieves high retrieval accuracy. We further show how the proposed descriptor can be used in a four-dimensional (4-D) convolutional neural network for the task of object classification. We propose a novel 4-D convolutional layer that is able to learn class-specific clusters in the descriptor histograms. Finally, we provide experimental validation on three benchmark datasets, which confirms the superiority of the proposed approach.","","","10.1109/LRA.2018.2792681","Higher Education Commission, Pakistan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8255586","Recognition;object detection;segmentation and categorization;RGB-D perception","Three-dimensional displays;Histograms;Robustness;Neural networks;Euclidean distance;Machine learning;Geometry","cloud computing;feature extraction;image classification;image matching;image representation;learning (artificial intelligence);neural nets;object recognition;pattern clustering;solid modelling;statistical analysis","three-dimensional point cloud data;object retrievel;4-D convolutional neural network;benchmark dataset;class-specific cluster learning;point pair descriptor histogram;irregular sampling density;noise-resistant deep learning;object classification;occlusion","","2","28","","","","","IEEE","IEEE Journals"
"Learning to Detect Aircraft for Long-Range Vision-Based Sense-and-Avoid Systems","J. James; J. J. Ford; T. L. Molloy","School of Electrical Engineering and Computer Science, Queensland University of Technology, Brisbane, QLD, Australia; School of Electrical Engineering and Computer Science, Queensland University of Technology, Brisbane, QLD, Australia; School of Electrical Engineering and Computer Science, Queensland University of Technology, Brisbane, QLD, Australia","IEEE Robotics and Automation Letters","","2018","3","4","4383","4390","The commercial use of unmanned aerial vehicles (UAVs) would be enhanced by an ability to sense and avoid potential mid-air collision threats. In this letter, we propose a new approach to aircraft detection for long-range vision-based sense and avoid. We first train a deep convolutional neural network to learn aircraft visual features using flight data of mid-air head-on near-collision course encounters between two fixed-wing aircraft. We then propose an approach that fuses these learnt aircraft features with hand-crafted features that are used by the current state of the art. Finally, we evaluate the performance of our proposed approach on real flight data captured from a UAV, where it achieves a mean detection range of 2527 m and a mean detection range improvement of 299 m (or 13.4%) compared to the current state of the art with no additional false alarms.","","","10.1109/LRA.2018.2867237","Australian Research Council Centre of Excellence; Australian Research Council's Linkage Projects funding scheme through Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8447264","Aerial systems: perception and autonomy, computer vision for automation;deep learning in robotics and automation","Aircraft;Computer vision;Machine learning;Feature extraction;Collision avoidance;Object detection;Unmanned aerial vehicles","aircraft control;autonomous aerial vehicles;collision avoidance;image fusion;learning (artificial intelligence);neural nets;robot vision","unmanned aerial vehicles;UAV;aircraft detection;long-range vision-based sense;deep convolutional neural network;aircraft visual features;flight data;mid-air head-on near-collision course;fixed-wing aircraft;learnt aircraft features;hand-crafted features;mean detection range improvement;mid-air collision threats","","4","30","","","","","IEEE","IEEE Journals"
"NeuroSim: A Circuit-Level Macro Model for Benchmarking Neuro-Inspired Architectures in Online Learning","P. Chen; X. Peng; S. Yu","School of Electrical, Computer and Energy Engineering, Arizona State University, Tempe, AZ, USA; School of Electrical, Computer and Energy Engineering, Arizona State University, Tempe, AZ, USA; School of Electrical, Computer and Energy Engineering, Arizona State University, Tempe, AZ, USA","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","","2018","37","12","3067","3080","Neuro-inspired architectures based on synaptic memory arrays have been proposed for on-chip acceleration of weighted sum and weight update in machine/deep learning algorithms. In this paper, we developed NeuroSim, a circuit-level macro model that estimates the area, latency, dynamic energy, and leakage power to facilitate the design space exploration of neuro-inspired architectures with mainstream and emerging device technologies. NeuroSim provides flexible interface and a wide variety of design options at the circuit and device level. Therefore, NeuroSim can be used by neural networks (NNs) as a supporting tool to provide circuit-level performance evaluation. With NeuroSim, an integrated framework can be built with hierarchical organization from the device level (synaptic device properties) to the circuit level (array architectures) and then to the algorithm level (NN topology), enabling instruction-accurate evaluation on the learning accuracy as well as the circuit-level performance metrics at the run-time of online learning. Using multilayer perceptron as a case-study algorithm, we investigated the impact of the “analog” emerging nonvolatile memory (eNVM)'s “nonideal” device properties and benchmarked the tradeoffs between SRAM, digital, and analog eNVM-based architectures for online learning and offline classification.","","","10.1109/TCAD.2018.2789723","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8246561","Emerging nonvolatile memory (eNVM);machine learning;neural network (NN);neuromorphic computing;offline classification;online learning;synaptic devices","Computer architecture;Microprocessors;Integrated circuit modeling;Artificial neural networks;Algorithm design and analysis;Neuromorphics","learning (artificial intelligence);multilayer perceptrons;random-access storage;SRAM chips","online learning;circuit-level macro model;benchmarking neuro-inspired architectures;synaptic memory arrays;machine/deep learning algorithms;design space exploration;emerging device technologies;circuit-level performance evaluation;synaptic device properties;circuit level;array architectures;learning accuracy;circuit-level performance metrics;nonvolatile memory;device level performance evaluation;NeuroSim model;multilayer perceptron;eNVM","","19","44","","","","","IEEE","IEEE Journals"
"Hand Gesture Recognition Using Input Impedance Variation of Two Antennas with Transfer Learning","I. Alnujaim; H. Alali; F. Khan; Y. Kim","Department of Electrical and Computer Engineering, California State University, Fresno, Fresno, CA, USA; Department of Electrical and Computer Engineering, California State University, Fresno, Fresno, CA, USA; Department of Electrical and Computer Engineering, California State University, Fresno, Fresno, CA, USA; Department of Electrical and Computer Engineering, California State University, Fresno, Fresno, CA, USA","IEEE Sensors Journal","","2018","18","10","4129","4135","This paper investigates the possibility of classifying hand gestures using the impedance variation of two antennas through transfer learning. When a hand gesture is made near an antenna, the impedance of the antenna varies over time due to the near-field perturbation. By recognizing the pattern of impedance variation, the gesture can be identified. We proposed to use two monopole antennas to measure signatures at different locations. A network analyzer measured the input impedance of the two antennas for ten hand gestures. The impedances were collected at 2.4 GHz and then were transformed to spectrograms to capture the time-varying signatures as imagery. The spectrogram images were classified using deep convolutional neural networks. In particular, we employed transfer learning to overcome the issue of the small data set available. Pre-trained networks, such as AlexNet and VGG-16 that were trained for general optical images were able to maximize the classification accuracy of our hand gesture recognition problem.","","","10.1109/JSEN.2018.2820000","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8326479","Human activity classification;hand gestures;antenna impedance variation;deep learning;convolutional neural network;transfer learning;AlexNet;VGG-16","Antennas;Impedance;Antenna measurements;Spectrogram;Impedance measurement;Optical sensors","feedforward neural nets;gesture recognition;image classification;learning (artificial intelligence);monopole antennas","input impedance variation;transfer learning;monopole antennas;impedances;time-varying signatures;hand gesture recognition problem;network analyzer;deep convolutional neural networks;general optical images;classification accuracy;frequency 2.4 GHz","","4","19","","","","","IEEE","IEEE Journals"
"Face Recognition Based on CSGF(2D)2PCANet","J. Kong; M. Chen; M. Jiang; J. Sun; J. Hou","Jiangsu Provincial Engineering Laboratory of Pattern Recognition and Computational Intelligence, Jiangnan University, Wuxi, China; Jiangsu Provincial Engineering Laboratory of Pattern Recognition and Computational Intelligence, Jiangnan University, Wuxi, China; Jiangsu Provincial Engineering Laboratory of Pattern Recognition and Computational Intelligence, Jiangnan University, Wuxi, China; Jiangsu Provincial Engineering Laboratory of Pattern Recognition and Computational Intelligence, Jiangnan University, Wuxi, China; Jiangsu Provincial Engineering Laboratory of Pattern Recognition and Computational Intelligence, Jiangnan University, Wuxi, China","IEEE Access","","2018","6","","45153","45165","Face recognition has a great potential to play an important role in computer vision field. However, the majority of face recognition methods are based on the low-level features, which may not yield good results. Inspired by a simple deep learning model principal component analysis network (PCANet), we propose a novel deep learning network called circular symmetrical Gabor filter (2D)2PCA neural networks [CSGF(2D)2PCANet]. Previous models used in face recognition have three major issues of data redundancy, computation time, and no rotation invariance. We introduce the CSGF to address these issues. Two-directional 2-D PCA [(2D)2PCA] is used in feature extraction stage. Binary hashing, blockwise histograms, and linear SVM are used for the output stage. The proposed CSGF (2D)2PCANet learns highlevel features and provides more recognition information during the training phase, which may result in a higher recognition rate when testing the sample. We tested the proposed method on XM2VTS, ORL, AR, Extend Yale B, and LFW databases. Test results show that the CSGF (2D)2PCANet is more robust to the variation of occlusion, illumination, pose, noise, and expression, which is a promising method in face recognition.","","","10.1109/ACCESS.2018.2865425","National Natural Science Foundation of China; China Postdoctoral Science Foundation; Postdoctoral Science Foundation of Jiangsu Province; Scientific and Technological Aid Program of Xinjiang; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8435907","Face recognition;deep learning;ConvNets;circular symmetric Gabor filter (CSGF);rotation invariance;CSGF(2D)²PCANet","Face recognition;Feature extraction;Face;Principal component analysis;Convolution;Computational modeling;Databases","computer vision;face recognition;feature extraction;Gabor filters;image classification;learning (artificial intelligence);neural nets;principal component analysis","face recognition methods;simple deep learning model principal component analysis network;deep learning network;recognition information;higher recognition rate;XM2VTS database;CSGF;PCA neural networks;deep learning model principal component analysis network;circular symmetrical Gabor filter;PCANet;feature extraction stage;binary hashing;blockwise histograms;linear SVM;training phase;ORL database;AR database;Extend Yale B database;LFW database;occlusion;illumination;time 2.0 d","","3","61","","","","","IEEE","IEEE Journals"
"DNN-Based Score Calibration With Multitask Learning for Noise Robust Speaker Verification","Z. Tan; M. Mak; B. K. Mak","Department of Electronic and Information Engineering, The Hong Kong Polytechnic University, Hong Kong; Department of Electronic and Information Engineering, The Hong Kong Polytechnic University, Hong Kong; Department of Computer Science, The Hong Kong University of Science and Technology, Hong Kong","IEEE/ACM Transactions on Audio, Speech, and Language Processing","","2018","26","4","700","712","This paper proposes and investigates several deep neural network (DNN) based score compensation, transformation, and calibration algorithms for enhancing the noise robustness of i-vector speaker verification systems. Unlike conventional calibration methods where the required score shift is a linear function of SNR or log-duration, the DNN approach learns the complex relationship between the score shifts and the combination of i-vector pairs and uncalibrated scores. Furthermore, with the flexibility of DNNs, it is possible to explicitly train a DNN to recover the clean scores without having to estimate the score shifts. To alleviate the overfitting problem, multitask learning is applied to incorporate auxiliary information such as SNRs and speaker ID of training utterances into the DNN. Experiments on NIST 2012 SRE show that score calibration derived from multitask DNNs can improve the performance of the conventional score-shift approch significantly, especially under noisy conditions.","","","10.1109/TASLP.2018.2791105","RGC of Hong Kong SAR; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8249870","Deep learning;speaker verification;score calibration;multi-task learning;noise robustness","Signal to noise ratio;Calibration;Noise measurement;Speech;Noise robustness;Training","calibration;learning (artificial intelligence);neural nets;speaker recognition","multitask learning;speaker ID;score calibration;multitask DNNs;conventional score-shift approch;noise robust speaker verification;deep neural network;calibration algorithms;noise robustness;i-vector speaker verification systems;conventional calibration methods;DNN approach;i-vector pairs;uncalibrated scores;DNN-based score calibration","","","50","","","","","IEEE","IEEE Journals"
"Multi-Scale Attentive Interaction Networks for Chinese Medical Question Answer Selection","S. Zhang; X. Zhang; H. Wang; L. Guo; S. Liu","Science and Technology on Information Systems Engineering Laboratory, College of Systems Engineering, National University of Defense Technology, Changsha, China; Science and Technology on Information Systems Engineering Laboratory, College of Systems Engineering, National University of Defense Technology, Changsha, China; Science and Technology on Information Systems Engineering Laboratory, College of Systems Engineering, National University of Defense Technology, Changsha, China; Science and Technology on Information Systems Engineering Laboratory, College of Systems Engineering, National University of Defense Technology, Changsha, China; Science and Technology on Information Systems Engineering Laboratory, College of Systems Engineering, National University of Defense Technology, Changsha, China","IEEE Access","","2018","6","","74061","74071","The past few years have witnessed a trend that the deep learning techniques have been increasingly applied in healthcare due to the explosive growth of big data. The online medical community, where users can ask qualified doctors about medical questions with just a few keystrokes and mouse clicks anytime and anywhere, has become quite popular recently. In this paper, we investigate the problem of Chinese medical question answer selection, which is a crucial subtask of automatic question answering and fairly challenging because of its language and domain characteristics. We introduce an end-to-end multiscale interactive networks framework to address the issue. The framework consists of several multi-scale deep neural layers which extract the deep semantic information of medical text from different levels of granularity, shortcut connections which prevent network degradation problem, and attentive interaction which mines the correlation between questions and answers. To evaluate our framework, we update and expand a dataset called cMedQA v2.0. Experimental results demonstrate that our model outperforms the existing state-ofthe-art models with noticeable margins.","","","10.1109/ACCESS.2018.2883637","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8548603","Medical question answering;interactive attention;deep learning;deep neural networks","Biomedical imaging;Data mining;Semantics;Medical services;Feature extraction;Knowledge discovery","Big Data;data mining;learning (artificial intelligence);medical information systems;natural language processing;question answering (information retrieval);text analysis","multiscale attentive interaction networks;Chinese medical question answer selection;deep learning techniques;online medical community;medical questions;automatic question answering;end-to-end multiscale interactive networks framework;multiscale deep neural layers;medical text;network degradation problem;healthcare;Big Data;deep neural layers","","","36","","","","","IEEE","IEEE Journals"
"F-DES: Fast and Deep Event Summarization","K. Kumar; D. D. Shrimankar","Department of Computer Science and Engineering, Visvesvaraya National Institute of Technology, Nagpur, India; Department of Computer Science and Engineering, Visvesvaraya National Institute of Technology, Nagpur, India","IEEE Transactions on Multimedia","","2018","20","2","323","334","In the multimedia era a large volume of video data can be recorded during a certain period of time by multiple cameras. Such a rapid growth of video data requires both effective and efficient multiview video summarization techniques. The users can quickly browse and comprehend a large amount of audiovisual data. It is very difficult in real-time to manage and access the huge amount of video-content-handling issues of interview dependencies significant variations in illumination and presence of many unimportant frames with low activity. In this paper we propose a local-alignment-based FASTA approach to summarize the events in multiview videos as a solution of the aforementioned problems. A deep learning framework is used to extract the features to resolve the problem of variations in illumination and to remove fine texture details and detect the objects in a frame. Interview dependencies among multiple views of video are then captured via the FASTA algorithm through local alignment. Finally object tracking is applied to extract the frames with low activity. Subjective as well as objective evaluations clearly indicate the effectiveness of the proposed approach. Experiments show that the proposed summarization method successfully reduces the video content while keeping momentous information in the form of events. A computing analysis of the system also shows that it meets the requirement of real-time applications.","","","10.1109/TMM.2017.2741423","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8012546","Deep learning;event summarization;FASTA;local alignment;multi-view video;nucleotide sequence","Streaming media;DNA;Feature extraction;Visualization;Multimedia communication;Cameras;Correlation","feature extraction;learning (artificial intelligence);object tracking;video signal processing","video data;audiovisual data;illumination;deep learning framework;video content;real-time applications;Fast and Deep Event Summarization;multiview video summarization techniques;video-content-handling;F-DES;local-alignment-based FASTA approach;feature extraction;object tracking;frame extraction","","17","48","","","","","IEEE","IEEE Journals"
"Deep Person Detection in Two-Dimensional Range Data","L. Beyer; A. Hermans; T. Linder; K. O. Arras; B. Leibe","Visual Computing Institute, RWTH Aachen University, Aachen, Germany; Visual Computing Institute, RWTH Aachen University, Aachen, Germany; Robert Bosch GmbH, Corporate Research, Stuttgart, Germany; Robert Bosch GmbH, Corporate Research, Stuttgart, Germany; Visual Computing Institute, RWTH Aachen University, Aachen, Germany","IEEE Robotics and Automation Letters","","2018","3","3","2726","2733","Detecting humans is a key skill for mobile robots and intelligent vehicles in a large variety of applications. Although the problem is well studied for certain sensory modalities such as image data, few works exist that address this detection task using two-dimensional (2-D) range data. However, a widespread sensory setup for many mobile robots in service and domestic applications contains a horizontally mounted 2-D laser scanner. Detecting people from 2-D range data is challenging due to the speed and dynamics of human leg motion and the high levels of occlusion and self-occlusion particularly in crowds of people. While previous approaches mostly relied on handcrafted features, we recently developed the deep learning based wheelchair and walker detector distance robust wheelchair/walker (DROW). In this letter, we show the generalization to people, including small modifications that significantly boost DROW's performance. Additionally, by providing a small, fully online temporal window in our network, we further boost our score. We extend the DROW dataset with person annotations, making this the largest dataset of person annotations in 2-D range data, recorded during several days in a real-world environment with high diversity. Extensive experiments with three current baseline methods indicate it is a challenging dataset, on which our improved DROW detector beats the current state-of-the-art.","","","10.1109/LRA.2018.2835510","EU Horizon 2020 projects ILIAD; CROWDBOT; BMBF project FRAME; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8357813","Deep learning in robotics and automation human detection and tracking recognition","Legged locomotion;Two dimensional displays;Detectors;Wheelchairs;Robot sensing systems;Lasers","feature extraction;handicapped aids;laser ranging;learning (artificial intelligence);mobile robots;object detection;wheelchairs","two-dimensional range data;mobile robots;intelligent vehicles;sensory modalities;image data;domestic applications;human leg motion;self-occlusion;deep learning based wheelchair;detector distance robust wheelchair/walker;person annotations;deep person detection;2D laser scanner;2D range data","","","31","","","","","IEEE","IEEE Journals"
"Road Segmentation in SAR Satellite Images With Deep Fully Convolutional Neural Networks","C. Henry; S. M. Azimi; N. Merkle","German Aerospace Center (DLR), Remote Sensing Technology Institute, Weßling, Germany; German Aerospace Center (DLR), Remote Sensing Technology Institute, Weßling, Germany; German Aerospace Center (DLR), Remote Sensing Technology Institute, Weßling, Germany","IEEE Geoscience and Remote Sensing Letters","","2018","15","12","1867","1871","Remote sensing is extensively used in cartography. As transportation networks grow and change, extracting roads automatically from satellite images is crucial to keep maps up-to-date. Synthetic aperture radar (SAR) satellites can provide high-resolution topographical maps. However, roads are difficult to identify in these data as they look visually similar to targets, such as rivers and railways. Most road extraction methods on SAR images still rely on a prior segmentation performed by the classical computer vision algorithms. Few works study the potential of deep learning techniques, despite their successful applications to optical imagery. This letter presents an evaluation of fully convolutional neural networks (FCNNs) for road segmentation in SAR images. We study the relative performance of early and state-of-the-art networks after carefully enhancing their sensitivity toward thin objects by adding the spatial tolerance rules. Our models show promising results, successfully extracting most of the roads in our test data set. This shows that although FCNNs natively lack efficiency for road segmentation, they are capable of good results if properly tuned. As the segmentation quality does not scale well with the increasing depth of the networks, the design of specialized architectures for roads extraction should yield better performances.","","","10.1109/LGRS.2018.2864342","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8447237","Deep learning;high-resolution synthetic aperture radar (SAR) data;road extraction;SAR;semantic segmentation;TerraSAR-X","Roads;Image segmentation;Synthetic aperture radar;Satellites;Task analysis;Computer vision;Urban areas","cartography;computer vision;geophysical image processing;image segmentation;learning (artificial intelligence);neural nets;radar imaging;remote sensing by radar;roads;synthetic aperture radar;topography (Earth)","transportation networks;remote sensing;cartography;deep fully convolutional neural networks;SAR satellite images;roads extraction;segmentation quality;state-of-the-art networks;road segmentation;deep learning techniques;classical computer vision algorithms;SAR images;road extraction methods;high-resolution topographical maps;synthetic aperture radar satellites","","8","19","","","","","IEEE","IEEE Journals"
"Procedural Content Generation via Machine Learning (PCGML)","A. Summerville; S. Snodgrass; M. Guzdial; C. Holmgård; A. K. Hoover; A. Isaksen; A. Nealen; J. Togelius","Department of Computational Media, University of California, Santa Cruz, CA, USA; College of Computing and Informatics, Drexel University, Philadelpia, PA, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; Duck and Cover Games ApS, Copenhagen, Denmark; College of Arts, Media and Design, Northeastern University, Boston, MA, USA; Department of Computer Science and Engineering, New York University, Brooklyn, NY, USA; Department of Computer Science and Engineering, New York University, Brooklyn, NY, USA; Department of Computer Science and Engineering, New York University, Brooklyn, NY, USA","IEEE Transactions on Games","","2018","10","3","257","270","This survey explores procedural content generation via machine learning (PCGML), defined as the generation of game content using machine learning models trained on existing content. As the importance of PCG for game development increases, researchers explore new avenues for generating high-quality content with or without human involvement; this paper addresses the relatively new paradigm of using machine learning (in contrast with search-based, solver-based, and constructive methods). We focus on what is most often considered functional game content, such as platformer levels, game maps, interactive fiction stories, and cards in collectible card games, as opposed to cosmetic content, such as sprites and sound effects. In addition to using PCG for autonomous generation, cocreativity, mixed-initiative design, and compression, PCGML is suited for repair, critique, and content analysis because of its focus on modeling existing content. We discuss various data sources and representations that affect the generated content. Multiple PCGML methods are covered, including neural networks: long short-term memory networks, autoencoders, and deep convolutional networks; Markov models: $n$-grams and multi-dimensional Markov chains; clustering; and matrix factorization. Finally, we discuss open problems in PCGML, including learning from small data sets, lack of training data, multilayered learning, style-transfer, parameter tuning, and PCG as a game mechanic.","","","10.1109/TG.2018.2846639","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8382283","Computational and artificial intelligence;design tools;electronic design methodology;knowledge representation;machine learning;pattern analysis;procedural content generation (PCG)","Games;Machine learning;Training;Machine learning algorithms;Neural networks;Maintenance engineering;Media","computer games;learning (artificial intelligence);Markov processes;neural nets","multilayered learning;PCG;game mechanic;procedural content generation;machine learning models;game development increases;high-quality content;considered functional game content;game maps;collectible card games;cosmetic content;autonomous generation;content analysis;generated content;multiple PCGML methods","","10","103","","","","","IEEE","IEEE Journals"
"Single Infrared Image Optical Noise Removal Using a Deep Convolutional Neural Network","X. Kuang; X. Sui; Y. Liu; Q. Chen; G. GU","Jiangsu Key Laboratory of Spectral Imaging and Intelligence Sense, Nanjing University of Science and Technology, Jiangsu, China; Jiangsu Key Laboratory of Spectral Imaging and Intelligence Sense, Nanjing University of Science and Technology, Jiangsu, China; Jiangsu Key Laboratory of Spectral Imaging and Intelligence Sense, Nanjing University of Science and Technology, Jiangsu, China; Jiangsu Key Laboratory of Spectral Imaging and Intelligence Sense, Nanjing University of Science and Technology, Jiangsu, China; Jiangsu Key Laboratory of Spectral Imaging and Intelligence Sense, Nanjing University of Science and Technology, Jiangsu, China","IEEE Photonics Journal","","2018","10","2","1","15","In this paper, we propose a deep learning method for single infrared image optical noise removal. With a fully convolutional neural network, it is able to eliminate the optical noise in single infrared image. Our architecture consists of two networks: a denoising network and a conditional discriminator. The denoising network takes a noise image as input and outputs a denoising result, while the discriminator tries to make the output look more like the target. Actually, only in the testing phase, this method is feed-forward. Significant image quality in experiments is achieved compared with the existing method.","","","10.1109/JPHOT.2017.2779149","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; Qing Lan Project and Open Research Fund of Jiangsu Key Laboratory of Spectral Imaging and Intelligence Sense; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8125746","Deep learning;infrared imaging;optical noise.","Optical noise;Noise reduction;Computer architecture;Gallium nitride;Training;Detectors","convolution;feedforward neural nets;image denoising;image enhancement;infrared imaging;learning (artificial intelligence);optical information processing","conditional discriminator;image qualit;fully convolutional neural network;deep learning method;deep convolutional neural network;single infrared image optical noise removal;noise image;denoising network","","1","47","","","","","IEEE","IEEE Journals"
"Intelligent Transportation System in Macao Based on Deep Self-Coding Learning","D. Li; L. Deng; Z. Cai; B. Franks; X. Yao","Postdoctoral Research Center of Zhuhai Da Hengqin Science and Technology Development, Co., Ltd., Zhuhai, China; Huazhong University of Science and Technology, Wuhan, China; Macau Big Data Research Centre for Urban Governance, City University of Macao, Macau; Computer Science Laboratory of Massachusetts Institute of Technology, Cambridge, MA, USA; Zhuhai Da Hengqin Science and Technology Development, Co., Ltd., Zhuhai, China","IEEE Transactions on Industrial Informatics","","2018","14","7","3253","3260","As the basic content of the construction of the intelligent city, the application of intelligent transportation system plays an important role in improving the quality and safety of modern urban traffic operation. Intelligent transportation system combines information technology, data communication technology, electronic sensing technology, global positioning technology, geographic information system technology, computer processing technology, and system engineering technology together reasonably. The intelligent transportation system is a kind of real-time, accurate, efficient, and intelligent transportation management system. In this paper, we introduce the deep code learning technique and apply it to the Macao intelligent system. At the same time, we combine the deep belief network model and support vector regression classifier as the prediction model, and use the deep belief network model to learn traffic flow characteristics.","","","10.1109/TII.2018.2810291","The Project of Macau Foundation; The First-phase Construction of Big-Data on Smart Macao; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8304635","Deep learning;Macao;self-coding;smart city;smart transportation system","","belief networks;geographic information systems;Global Positioning System;intelligent transportation systems;learning (artificial intelligence);regression analysis;road traffic;support vector machines;traffic information systems;transportation","geographic information system technology;computer processing technology;system engineering technology;intelligent transportation system;intelligent transportation management system;Macao intelligent system;intelligent city;information technology;data communication technology;electronic sensing technology;global positioning technology;transportation management system","","2","12","","","","","IEEE","IEEE Journals"
"Deep Multiscale Spectral-Spatial Feature Fusion for Hyperspectral Images Classification","M. Liang; L. Jiao; S. Yang; F. Liu; B. Hou; H. Chen","Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, International Research Center for Intelligent Perception and Computation, Joint International Research Laboratory of Intelligent Perception and Computation, School of Artificial Intelligence, Xidian University, Xian, China; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, International Research Center for Intelligent Perception and Computation, Joint International Research Laboratory of Intelligent Perception and Computation, School of Artificial Intelligence, Xidian University, Xian, China; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, International Research Center for Intelligent Perception and Computation, Joint International Research Laboratory of Intelligent Perception and Computation, School of Artificial Intelligence, Xidian University, Xian, China; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, International Research Center for Intelligent Perception and Computation, Joint International Research Laboratory of Intelligent Perception and Computation, School of Artificial Intelligence, Xidian University, Xian, China; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, International Research Center for Intelligent Perception and Computation, Joint International Research Laboratory of Intelligent Perception and Computation, School of Artificial Intelligence, Xidian University, Xian, China; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, International Research Center for Intelligent Perception and Computation, Joint International Research Laboratory of Intelligent Perception and Computation, School of Artificial Intelligence, Xidian University, Xian, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2018","11","8","2911","2924","Learning representative and discriminative feature that make full use of spectral-spatial information is of cardinal significance for hyperspectral imagery (HSI) interpretation. In this paper, we present a novel unsupervised feature extraction method, deep multiscale spectral-spatial feature fusion (DMS3 F2), for hyperspectral images classification (HSIC). First, pretrained filter banks in VGG16 are transferred to extract deep multiscale spatial structural information about HSI. Second, we propose a new unsupervised cooperative sparse autoencoder method to fuse together the deep spatial feature and the raw spectral information. It achieves both dimensionality reduction and feature fusion, and cooperates on different features to fulfil self-supervised projective learning, which is beneficial in detecting important structure and retaining significant amount of information about the input. In the end, fused spectral-spatial features from multiple scales in VGG16 are further weighted fused and upsampled to obtain the final discriminative feature. Qualitative classification experiments by support vector machines are reported to show the effectiveness of the proposed algorithm. Compared with existing feature extraction techniques, the proposed method is much more effective for HSIC, especially for datasets with less training samples and scenes with complex semantic information and great heterogeneity in terms of geometrical shape.","","","10.1109/JSTARS.2018.2836671","National Natural Science Foundation of China; Joint Fund of the Equipment Research of Ministry of Education; China Postdoctoral Science Foundation; Xidian University New Teacher Innovation Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8376019","Convolutional neural network (CNN);cooperative sparse autoencoder (CSAE);deep multiscale feature;feature fusion;hyperspectral images classification (HSIC);transfer learning","Feature extraction;Hyperspectral imaging;Convolution;Kernel;Training","feature extraction;geophysical image processing;hyperspectral imaging;image classification;learning (artificial intelligence);support vector machines","hyperspectral images classification;deep multiscale spatial structural information;unsupervised cooperative sparse autoencoder method;raw spectral information;fused spectral-spatial features;spectral-spatial information;hyperspectral imagery interpretation;feature extraction techniques;unsupervised feature extraction method;deep multiscale spectral-spatial feature fusion","","2","55","","","","","IEEE","IEEE Journals"
"Biomedical compound figure detection using deep learning and fusion techniques","S. L. Lee; M. R. Zare","Monash University Malaysia, Malaysia; Monash University Malaysia, Malaysia","IET Image Processing","","2018","12","6","1031","1037","Images contain significant amounts of information but present different challenges relative to textual information. One such challenge is compound figures or images made up of two or more subfigures. A deep learning model is proposed for compound figure detection (CFD) in the biomedical article domain. First, pre-trained convolutional neural networks (CNNs) are selected for transfer learning to take advantage of the image classification performance of CNNs and to overcome the limited dataset of the CFD problem. Next, the pre-trained CNNs are fine-tuned on the training data with early-stopping to avoid overfitting. Alternatively, layer activations of the pre-trained CNNs are extracted and used as input features to a support vector machine classifier. Finally, individual model outputs are combined with score-based fusion. The proposed combined model obtained a best test accuracy of 90.03 and 96.93% outperforming traditional hand-crafted and other deep learning representations on the ImageCLEF 2015 and 2016 CFD subtask datasets, respectively, by using AlexNet, VGG-16, VGG-19 pre-trained CNNs fine-tuned until best validation accuracy stops increasing combined with the combPROD score-based fusion operator.","","","10.1049/iet-ipr.2017.0800","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8362594","","","feature extraction;image classification;image fusion;learning (artificial intelligence);medical image processing;neural nets;support vector machines","score-based fusion;support vector machine classifier;image classification;transfer learning;CNN;pre-trained convolutional neural networks;CFD;compound figure detection;deep learning model;biomedical compound figure detection","","1","34","","","","","IET","IET Journals"
"A Multiobjective Learning and Ensembling Approach to High-Performance Speech Enhancement With Compact Neural Network Architectures","Q. Wang; J. Du; L. Dai; C. Lee","National Engineering Laboratory for Speech and Language Information Processing, University of Science and Technology of China, Hefei, China; National Engineering Laboratory for Speech and Language Information Processing, University of Science and Technology of China, Hefei, China; National Engineering Laboratory for Speech and Language Information Processing, University of Science and Technology of China, Hefei, China; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA","IEEE/ACM Transactions on Audio, Speech, and Language Processing","","2018","26","7","1185","1197","In this study, we propose a novel deep neural network (DNN) architecture for speech enhancement (SE) via a multiobjective learning and ensembling (MOLE) framework to achieve a compact and lowlatency design, while maintaining good performance in quality evaluations. MOLE follows the boosting concept when combining weak models into a strong classifier and consists of two compact DNNs. The first, called the multiobjective learning DNN (MOL-DNN), takes multiple features, such as log-power spectra (LPS), mel-frequency cepstral coefficients (MFCCs) and Gammatone frequency cepstral coefficients (GFCCs) to predict a multiobjective set that includes clean speech feature, dynamic noise feature, and ideal ratio mask (IRM). The second, called the multiobjective ensembling DNN (MOE-DNN), takes the learned features from MOL-DNN as inputs and separately predicts clean LPS and IRM, clean MFCC and IRM, and clean GFCC and IRM using three sets of weak regression functions. Finally, a postprocessing operation can be applied to the estimated clean features by leveraging the multiple targets learned from both the MOL-DNN and the MOE-DNN. On speech corrupted by 15 noise types not seen in model training the SE results show that the MOLE approach, which features a small model size and low run-time latency, can achieve consistent improvements over both DNN- and long short-term memory (LSTM)-based techniques in terms of all the objective metrics evaluated in this study for all three cases (the input contexts contain 1-frame, 4-frame and 7-frame instances). The 1-frame MOLE-based SE system outperforms the DNN-based SE system with a 7-frame input expansion at a 3-frame delay and also achieves better performance than the LSTM-based SE system with 4-frame, no delay expansion by including only 3 previous frames, and with 170 times less processing latency.","","","10.1109/TASLP.2018.2817798","National Key R&D Program of China; National Natural Science Foundation of China; Key Science and Technology Project of Anhui Province; OE-Microsoft Key Laboratory of University of Science and Technology of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8323182","Speech enhancement (SE);deep neural network (DNN);multiobjective learning;multiobjective ensembling;compact and low-latency design","Speech;Speech enhancement;Mel frequency cepstral coefficient;Noise measurement;Neural networks","cepstral analysis;feature extraction;Gaussian processes;hidden Markov models;learning (artificial intelligence);neural net architecture;regression analysis;speech enhancement","ensembling approach;high-performance speech enhancement;compact neural network architectures;deep neural network architecture;lowlatency design;weak models;compact DNNs;multiobjective learning DNN;MOL-DNN;multiple features;log-power spectra;multiobjective set;clean speech feature;dynamic noise feature;IRM;multiobjective ensembling DNN;MOE-DNN;learned features;clean LPS;clean MFCC;clean GFCC;weak regression functions;estimated clean features;MOLE approach;SE system;7-frame input expansion","","4","61","","","","","IEEE","IEEE Journals"
"PDLM: Privacy-Preserving Deep Learning Model on Cloud with Multiple Keys","X. Ma; J. Ma; H. Li; Q. Jiang; S. Gao","School of Cyber Engineering, Xidian University, 47905 Xi'an, Shaanxi China (e-mail: xdma1989@gmail.com); Key Laboratory of Computer Networks and Information Security of Ministry of Education, Xidian University, Xi'an, Shaanxi China (e-mail: jfma@mail.xidian.edu.cn); School of Cyber Engineering, Xidian University, Xi'an, Shaanxi China (e-mail: hli@xidian.edu.cn); School of Cyber Engineering, Xidian University, 47905 Xian, Shaanxi China (e-mail: jiangqixdu@gmail.com); School of Information, Central University of Finance and Economics, 12647 Beijing, Beijing China (e-mail: sgao@cufe.edu.cn)","IEEE Transactions on Services Computing","","2018","PP","99","1","1","Deep learning has aroused a lot of attention and has been used successfully in many domains. Generally, the training of models requires large, representative datasets, which may be collected from a large number of users and contain sensitive information. The collected data would be stored and computed by service providers (SPs) or delegated to an untrusted cloud. Users can neither control how it will be used, nor realize what will be learned, which make the privacy issues prominent and severe. To solve the privacy issues, one of the most popular approaches is to encrypt their data. However, this technique inevitably leads to another challenge that how to train the model based on multi-key encrypted data. In this paper, we propose a novel privacy-preserving learning model, namely PDLM, to apply deep learning over the multi-key encrypted data. In PDLM, users contribute their encrypted data to SP to learn a specific model. We adopt an effective privacy-preserving calculation toolkit to achieve the training in a privacy-preserving manner. Finally, we conduct the analysis of PDLM in both theory and practice and the experimental results over two real-world datasets demonstrate that our PDLM can effectively and efficiently train the model in a privacy-preserving way.","","","10.1109/TSC.2018.2868750","China Postdoctoral Science Foundation Funded Project; China 111 Project; National Natural Science Foundation of China; Shaanxi Science and Technology Coordination Innovation Project; Central University of Finance and Economics program of the Youth Talent Support Plan; CCF-VenustechRP; Natural Science Basic Research Plan in Shaanxi Province of China; Fundamental Research Funds for the Central Universities; Beijing Municipal Social Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8454831","Privacy preservation;deep learning;cryptography;multiple keys","Cryptography;Machine learning;Training;Privacy;Data models;Data privacy;Computational modeling","","","","2","","","","","","IEEE","IEEE Early Access Articles"
"Video Salient Object Detection via Fully Convolutional Networks","W. Wang; J. Shen; L. Shao","Beijing Laboratory of Intelligent Information Technology, School of Computer Science, Beijing Institute of Technology, Beijing, China; Beijing Laboratory of Intelligent Information Technology, School of Computer Science, Beijing Institute of Technology, Beijing, China; School of Computing Sciences, University of East Anglia, Norwich, U.K.","IEEE Transactions on Image Processing","","2018","27","1","38","49","This paper proposes a deep learning model to efficiently detect salient regions in videos. It addresses two important issues: 1) deep video saliency model training with the absence of sufficiently large and pixel-wise annotated video data and 2) fast video saliency training and detection. The proposed deep video saliency network consists of two modules, for capturing the spatial and temporal saliency information, respectively. The dynamic saliency model, explicitly incorporating saliency estimates from the static saliency model, directly produces spatiotemporal saliency inference without time-consuming optical flow computation. We further propose a novel data augmentation technique that simulates video training data from existing annotated image data sets, which enables our network to learn diverse saliency information and prevents overfitting with the limited number of training videos. Leveraging our synthetic video data (150K video sequences) and real videos, our deep video saliency model successfully learns both spatial and temporal saliency cues, thus producing accurate spatiotemporal saliency estimate. We advance the state-of-the-art on the densely annotated video segmentation data set (MAE of .06) and the Freiburg-Berkeley Motion Segmentation data set (MAE of .07), and do so with much improved speed (2 fps with all steps).","","","10.1109/TIP.2017.2754941","National Basic Research Program of China 973 Program; National Natural Science Foundation of China; Fok Ying-Tong Education Foundation for Young Teachers; Joint Building Program of Beijing Municipal Education Commission; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8047320","Video saliency;deep learning;synthetic video data;salient object detection;fully convolutional network","Computational modeling;Object detection;Training;Machine learning;Optical imaging;Computer vision;Spatiotemporal phenomena","convolution;image annotation;image segmentation;image sequences;inference mechanisms;learning (artificial intelligence);neural nets;object detection;video signal processing","temporal saliency information;dynamic saliency model;static saliency model;spatiotemporal saliency inference;annotated image data sets;deep video saliency model;spatial saliency cues;temporal saliency cues;densely annotated video segmentation data set;Freiburg-Berkeley Motion Segmentation data set;video salient object detection;fully convolutional networks;deep learning model;spatial saliency information;data augmentation technique;video sequences","","77","71","Traditional","","","","IEEE","IEEE Journals"
"Query-Adaptive Image Retrieval by Deep-Weighted Hashing","J. Zhang; Y. Peng","Institute of Computer Science and Technology, Peking University, Beijing, China; Institute of Computer Science and Technology, Peking University, Beijing, China","IEEE Transactions on Multimedia","","2018","20","9","2400","2414","Hashing methods have attracted much attention for large-scale image retrieval. Some deep hashing methods have achieved promising results by taking advantage of the strong representation power of deep networks recently. However, existing deep hashing methods treat all hash bits equally. On one hand, a large number of images share the same distance to a query image due to the discrete Hamming distance, which raises a critical issue of image retrieval where fine-grained rankings are very important. On the other hand, different hash bits actually contribute to the image retrieval differently, and treating them equally greatly affects the retrieval accuracy. To address the above two problems, we propose the query-adaptive deep weighted hashing approach, which can perform fine-grained ranking for different queries by weighted Hamming distance. First, a novel deep hashing network is proposed to learn the hash codes and corresponding classwise weights jointly, so that the learned weights can reflect the importance of different hash bits for different image classes. Second, a query-adaptive image retrieval method is proposed, which rapidly generates hash bit weights for different query images by fusing its semantic probability and the learned classwise weights. Fine-grained image ranking is then performed by the weighted Hamming distance, which can provide more accurate ranking than the traditional Hamming distance. Experiments on four widely used datasets show that the proposed approach outperforms eight state-of-the-art hashing methods.","","","10.1109/TMM.2018.2804763","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8288679","Deep weighted hashing;query-adaptive;image retrieval","Hamming distance;Image retrieval;Semantics;Multimedia communication;Training;Multimedia databases;Streaming media","file organisation;image retrieval;learning (artificial intelligence);probability","weighted Hamming distance;deep hashing network;hash codes;query-adaptive image retrieval method;learned classwise weights;fine-grained image ranking;query image;discrete Hamming distance;retrieval accuracy;query-adaptive deep weighted hashing approach;image classes;hash bit weights;semantic probability","","4","51","","","","","IEEE","IEEE Journals"
"A Deep End-to-End Model for Transient Stability Assessment With PMU Data","Q. Zhu; J. Chen; L. Zhu; D. Shi; X. Bai; X. Duan; Y. Liu","State Key Laboratory of Advanced Electromagnetic Engineering and Technology, Electric Power Security and High Efficiency Key Laboratory, School of Electrical and Electronic Engineering, Huazhong University of Science and Technology, Wuhan, China; State Key Laboratory of Advanced Electromagnetic Engineering and Technology, Electric Power Security and High Efficiency Key Laboratory, School of Electrical and Electronic Engineering, Huazhong University of Science and Technology, Wuhan, China; Department of Electrical Engineering and Computer Science, The University of Tennessee, Knoxville, TN, USA; State Key Laboratory of Advanced Electromagnetic Engineering and Technology, Electric Power Security and High Efficiency Key Laboratory, School of Electrical and Electronic Engineering, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; State Key Laboratory of Advanced Electromagnetic Engineering and Technology, Electric Power Security and High Efficiency Key Laboratory, School of Electrical and Electronic Engineering, Huazhong University of Science and Technology, Wuhan, China; Department of Electrical Engineering and Computer Science, The University of Tennessee, Knoxville, TN, USA","IEEE Access","","2018","6","","65474","65487","Accurate transient stability assessment (TSA) is a fundamental requirement for ensuring secure and stable operation of power systems. Tremendous efforts have been made to apply artificial intelligence approaches for TSA with phasor measurement unit data. However, many previous approaches may be failed to provide favorable accuracy due to the shallow architectures and error-prone hand-crafting features. This paper proposed a model for TSA, which is termed multi-branch stacked denoising autoencoder (MSDAE). This model is a unified framework integrating multiple stacked denoising autoencoders (SDAEs), one fusion layer, and one logistic regression (LR) layer. Initially, the SDAEs at the bottom of MSDAE extract features from multiple kinds of measurements respectively. Then, the extracted features are encoded into unified fusion features by the fusion layer. Finally, the LR layer performs TSA by using the fusion features. The depth of the architecture contributes to the remarkable ability for feature learning, while the width of the architecture (i.e., the multiple branches) enables MSDAE to deal with different kinds of measurements by a reasonable mechanism. In this way, MSDAE achieves feature extraction and classification intrinsically and simultaneously, namely, achieves TSA in an end-to-end manner. The results of experiments on IEEE 50-machine system demonstrate the superiority of the proposed model over the prior methods.","","","10.1109/ACCESS.2018.2872796","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8492415","Deep learning;feature extraction;PMU data;stacked denoising autoencoder;transient stability assessment","Feature extraction;Power system stability;Stability analysis;Machine learning;Phasor measurement units;Voltage measurement","feature extraction;learning (artificial intelligence);pattern classification;phasor measurement;power engineering computing;power system transient stability","feature classification;power system secure operation;power system stable operation;unified fusion features;logistic regression layer;fusion layer;multiple stacked denoising autoencoders;unified framework;multibranch stacked denoising autoencoder;error-prone hand-crafting;shallow architectures;favorable accuracy;phasor measurement unit data;artificial intelligence approaches;accurate transient stability assessment;PMU data;deep end-to-end model;feature extraction;MSDAE;multiple branches;feature learning;TSA;LR layer","","2","55","","","","","IEEE","IEEE Journals"
"Multimodal First Impression Analysis with Deep Residual Networks","Y. Güçlütürk; U. Güçlü; X. Baró; H. J. Escalante; I. Guyon; S. Escalera; M. A. J. van Gerven; R. van Lier","Radboud University, Nijmegen, HR, The Netherlands; Radboud University, Nijmegen, HR, The Netherlands; Open University of Catalonia, Barcelona, Spain; Instituto Nacional de Astrofísica, Puebla, Mexico; UPSud/INRIA Université Paris-Saclay, Saint-Aubin, France; University of Barcelona, Barcelona, Spain; Radboud University, Nijmegen, HR, The Netherlands; Radboud University, Nijmegen, HR, The Netherlands","IEEE Transactions on Affective Computing","","2018","9","3","316","329","People form first impressions about the personalities of unfamiliar individuals even after very brief interactions with them. In this study we present and evaluate several models that mimic this automatic social behavior. Specifically, we present several models trained on a large dataset of short YouTube video blog posts for predicting apparent Big Five personality traits of people and whether they seem suitable to be recommended to a job interview. Along with presenting our audiovisual approach and results that won the third place in the ChaLearn First Impressions Challenge, we investigate modeling in different modalities including audio only, visual only, language only, audiovisual, and combination of audiovisual and language. Our results demonstrate that the best performance could be obtained using a fusion of all data modalities. Finally, in order to promote explainability in machine learning and to provide an example for the upcoming ChaLearn challenges, we present a simple approach for explaining the predictions for job interview recommendations.","","","10.1109/TAFFC.2017.2751469","Netherlands Organization for Scientific Research; Nvidia Corporation; Spanish Ministry; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8031881","Big Five personality traits;deep learning;explainability;first impression;multimodal","Interviews;Feature extraction;Predictive models;Machine learning;Face recognition;YouTube","behavioural sciences computing;learning (artificial intelligence);recommender systems;social networking (online);video signal processing","data modalities;job interview recommendations;multimodal first impression analysis;deep residual networks;short YouTube video blog posts;audiovisual approach;automatic social behavior;big five personality traits;ChaLearn challenges;data fusion;machine learning","","1","63","","","","","IEEE","IEEE Journals"
"A Survey on Security Threats and Defensive Techniques of Machine Learning: A Data Driven View","Q. Liu; P. Li; W. Zhao; W. Cai; S. Yu; V. C. M. Leung","College of Computer, National University of Defense Technology, Changsha, China; College of Computer, National University of Defense Technology, Changsha, China; College of Computer, National University of Defense Technology, Changsha, China; Department of Electrical and Computer Engineering, The University of British Columbia, Vancouver, BC, Canada; School of Information Technology, Deakin University Melbourne Burwood Campus, Burwood, VIC, Australia; Department of Electrical and Computer Engineering, The University of British Columbia, Vancouver, BC, Canada","IEEE Access","","2018","6","","12103","12117","Machine learning is one of the most prevailing techniques in computer science, and it has been widely applied in image processing, natural language processing, pattern recognition, cybersecurity, and other fields. Regardless of successful applications of machine learning algorithms in many scenarios, e.g., facial recognition, malware detection, automatic driving, and intrusion detection, these algorithms and corresponding training data are vulnerable to a variety of security threats, inducing a significant performance decrease. Hence, it is vital to call for further attention regarding security threats and corresponding defensive techniques of machine learning, which motivates a comprehensive survey in this paper. Until now, researchers from academia and industry have found out many security threats against a variety of learning algorithms, including naive Bayes, logistic regression, decision tree, support vector machine (SVM), principle component analysis, clustering, and prevailing deep neural networks. Thus, we revisit existing security threats and give a systematic survey on them from two aspects, the training phase and the testing/inferring phase. After that, we categorize current defensive techniques of machine learning into four groups: security assessment mechanisms, countermeasures in the training phase, those in the testing or inferring phase, data security, and privacy. Finally, we provide five notable trends in the research on security threats and defensive techniques of machine learning, which are worth doing in-depth studies in future.","","","10.1109/ACCESS.2018.2805680","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8290925","Machine learning;adversarial samples;security threats;defensive techniques","Security;Training;Machine learning algorithms;Training data;Support vector machines;Testing;Taxonomy","Bayes methods;decision trees;invasive software;learning (artificial intelligence);neural nets;pattern classification;pattern recognition;principal component analysis;regression analysis;security of data;support vector machines","security threats;machine learning;data driven view learning;principle component analysis;data security;defensive techniques;computer science;image processing;natural language processing;pattern recognition;cybersecurity;facial recognition;malware detection;automatic driving;intrusion detection;naive Bayes;logistic regression;decision tree;support vector machine;SVM;deep neural networks;clustering","","18","111","","","","","IEEE","IEEE Journals"
"Deep multiple instance learning for automatic detection of diabetic retinopathy in retinal images","L. Zhou; Y. Zhao; J. Yang; Q. Yu; X. Xu","Shanghai Jiao Tong University, People's Republic of China; Shanghai Jiao Tong University, People's Republic of China; Shanghai Jiao Tong University, People's Republic of China; Shanghai Jiao Tong University, People's Republic of China; Shanghai Jiao Tong University, People's Republic of China","IET Image Processing","","2018","12","4","563","571","As a weakly supervised learning technique, multiple instance learning (MIL) has shown an advantage over supervised learning methods for automatic detection of diabetic retinopathy (DR): only the image-level annotation is needed to achieve both detection of DR images and DR lesions, making more graded and de-identified retinal images available for learning. However, the performance of existing studies on this technique is limited by the use of handcrafted features. The authors propose a deep MIL method for DR detection, which jointly learns features and classifiers from data and achieves a significant improvement on detecting DR images and their inside lesions. Specifically, a pre-trained convolutional neural network is adapted to achieve the patch-level DR estimation, and then global aggregation is used to make the classification of DR images. Further, the authors propose an end-to-end multi-scale scheme to better deal with the irregular DR lesions. For detection of DR images, they achieve an area under the ROC curve of 0.925 on a subset of a Kaggle dataset, and 0.960 on Messidor. For detection of DR lesions, they achieve an F1-score of 0.924 with sensitivity 0.995 and precision 0.863 on DIARETDB1 using the connected component-level validation.","","","10.1049/iet-ipr.2017.0636","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8320067","","","image classification;learning (artificial intelligence);medical image processing;neural nets","deep multiple instance learning;automatic detection;diabetic retinopathy;retinal images;weakly supervised learning technique;DR lesions;DR image classification;image-level annotation;pre-trained convolutional neural network;patch-level DR estimation;global aggregation;end-to-end multi-scale scheme;Kaggle dataset","","","","","","","","IET","IET Journals"
"Engineering Deep Representations for Modeling Aesthetic Perception","Y. Chen; Y. Hu; L. Zhang; P. Li; C. Zhang","Department of CSIE, Hefei University of Technology, Hefei, China; School of Aerospace Engineering, Tsinghua University, Beijing, China; Department of CSIE, Hefei University of Technology, Hefei, China; School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China; Department of Computer Science, University of Illinois at Urbana–Champaign, Champaign, IL, USA","IEEE Transactions on Cybernetics","","2018","48","11","3092","3104","Many aesthetic models in multimedia and computer vision suffer from two shortcomings: 1) the low descriptiveness and interpretability1 of the hand-crafted aesthetic criteria (i.e., fail to indicate region-level aesthetics) and 2) the difficulty of engineering aesthetic features adaptively and automatically toward different image sets. To remedy these problems, we develop a deep architecture to learn aesthetically relevant visual attributes from Flickr,2 which are localized by multiple textual attributes in a weakly supervised setting. More specifically, using a bag-of-words representation of the frequent Flickr image tags, a sparsity-constrained subspace algorithm discovers a compact set of textual attributes (i.e., each textual attribute is a sparse and linear representation of those frequent image tags) for each Flickr image. Then, a weakly supervised learning algorithm projects the textual attributes at image-level to the highly-responsive image patches. These patches indicate where humans look at appealing regions with respect to each textual attribute, which are employed to learn the visual attributes. Psychological and anatomical studies have demonstrated that humans perceive visual concepts in a hierarchical way. Therefore, we normalize these patches and further feed them into a five-layer convolutional neural network to mimic the hierarchy of human perceiving the visual attributes. We apply the learned deep features onto applications like image retargeting, aesthetics ranking, and retrieval. Both subjective and objective experimental results thoroughly demonstrate the superiority of our approach.1In this paper, “describing” and “interpretability” means the ability of seeking region-level representation of each mined textual attribute, i.e., a sparse and linear representation of those frequent image tags.2https://www.flickr.com/.","","","10.1109/TCYB.2017.2758350","National Basic Research Program; National High-Tech Development Program; Fundamental Research Funds for the Central Universities; Program for New Century Excellent Talents in University; National Natural Science Foundation of China; Anhui Fund for Distinguished Young Scholars; National University of Singapore; National Natural Science Foundation of China; Natural Science Foundation of Zhejiang Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8183427","Attributes;convolutional neural network (CNN);deep architecture;Flickr;machine learning","Visualization;Flickr;Image color analysis;Analytical models;Computational modeling;Multimedia communication;Training","computer vision;convolution;feature extraction;feedforward neural nets;image representation;image retrieval;learning (artificial intelligence);text analysis","aesthetic models;engineering aesthetic features;bag-of-words representation;sparse representation;linear representation;image retargeting;visual attributes;supervised learning algorithm;Flickr image;textual attribute;computer vision;multimedia;psychological studies;convolutional neural network;image retrieval;deep architecture","","1","60","","","","","IEEE","IEEE Journals"
"Joint Vertebrae Identification and Localization in Spinal CT Images by Combining Short- and Long-Range Contextual Information","H. Liao; A. Mesfin; J. Luo","Department of Computer Science, University of Rochester, Rochester, NY, USA; Department of Orthopaedics, University of Rochester Medical Center, Rochester, NY, USA; Department of Computer Science, University of Rochester, Rochester, NY, USA","IEEE Transactions on Medical Imaging","","2018","37","5","1266","1275","Automatic vertebrae identification and localization from arbitrary computed tomography (CT) images is challenging. Vertebrae usually share similar morphological appearance. Because of pathology and the arbitrary field-of-view of CT scans, one can hardly rely on the existence of some anchor vertebrae or parametric methods to model the appearance and shape. To solve the problem, we argue that: 1) one should make use of the short-range contextual information, such as the presence of some nearby organs (if any), to roughly estimate the target vertebrae; and 2) due to the unique anatomic structure of the spine column, vertebrae have fixed sequential order, which provides the important long-range contextual information to further calibrate the results. We propose a robust and efficient vertebrae identification and localization system that can inherently learn to incorporate both the short- and long-range contextual information in a supervised manner. To this end, we develop a multi-task 3-D fully convolutional neural network to effectively extract the short-range contextual information around the target vertebrae. For the long-range contextual information, we propose a multi-task bidirectional recurrent neural network to encode the spatial and contextual information among the vertebrae of the visible spine column. We demonstrate the effectiveness of the proposed approach on a challenging data set, and the experimental results show that our approach outperforms the state-of-the-art methods by a significant margin.","","","10.1109/TMI.2018.2798293","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8269371","Automatic vertebrae identification and localization;CT image;deep learning;convolutional neural network;recurrent neural network;multi-task learning","Three-dimensional displays;Computed tomography;Feature extraction;Task analysis;Biomedical imaging;Two dimensional displays;Pathology","bone;computerised tomography;learning (artificial intelligence);medical image processing;neural nets;neurophysiology;recurrent neural nets","joint vertebrae identification;spinal CT images;arbitrary computed tomography images;CT scans;anchor vertebrae;target vertebrae;robust vertebrae identification;efficient vertebrae identification;multitask bidirectional recurrent neural network;spatial information;automatic vertebrae identification;multitask 3D fully convolutional neural network;anatomic structure","Algorithms;Deep Learning;Humans;Image Processing, Computer-Assisted;Spine;Tomography, X-Ray Computed","1","38","","","","","IEEE","IEEE Journals"
"Deep ART Neural Model for Biologically Inspired Episodic Memory and Its Application to Task Performance of Robots","G. Park; Y. Yoo; D. Kim; J. Kim","School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea","IEEE Transactions on Cybernetics","","2018","48","6","1786","1799","Robots are expected to perform smart services and to undertake various troublesome or difficult tasks in the place of humans. Since these human-scale tasks consist of a temporal sequence of events, robots need episodic memory to store and retrieve the sequences to perform the tasks autonomously in similar situations. As episodic memory, in this paper we propose a novel Deep adaptive resonance theory (ART) neural model and apply it to the task performance of the humanoid robot, Mybot, developed in the Robot Intelligence Technology Laboratory at KAIST. Deep ART has a deep structure to learn events, episodes, and even more like daily episodes. Moreover, it can retrieve the correct episode from partial input cues robustly. To demonstrate the effectiveness and applicability of the proposed Deep ART, experiments are conducted with the humanoid robot, Mybot, for performing the three tasks of arranging toys, making cereal, and disposing of garbage.","","","10.1109/TCYB.2017.2715338","National Research Foundation of Korea Grant funded by the Korea Government; Technology Innovation Program funded by the Ministry of Trade, Industry and Energy, South Korea; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7959110","Deep adaptive resonance theory (ART);episode learning;episode retrieval;wheel-based humanoid robot","Subspace constraints;Encoding;Biological system modeling;Robustness;Humanoid robots;Biological information theory","ART neural nets;humanoid robots;learning (artificial intelligence);mobile robots","biologically inspired episodic memory;smart services;humanoid robot;Robot Intelligence Technology Laboratory;deep ART neural model;robot task performance;deep adaptive resonance theory neural model;Mybot;KAIST","","4","37","","","","","IEEE","IEEE Journals"
"Capturing Edge Attributes via Network Embedding","P. Goyal; H. Hosseinmardi; E. Ferrara; A. Galstyan","Department of Computer Science, University of Southern California, Los Angeles, CA, USA; Department of Computer Science, University of Southern California, Los Angeles, CA, USA; Department of Computer Science, University of Southern California, Los Angeles, CA, USA; Department of Computer Science, University of Southern California, Los Angeles, CA, USA","IEEE Transactions on Computational Social Systems","","2018","5","4","907","917","Network embedding, which aims to learn low-dimensional representations of nodes, has been used for various graph related tasks including visualization, link prediction, and node classification. Most existing embedding methods rely solely on network structure. However, in practice, we often have auxiliary information about the nodes and/or their interactions, e.g., the content of scientific papers in coauthorship networks, or topics of communication in Twitter mention networks. Here, we propose a novel embedding method that uses both network structure and edge attributes to learn better network representations. Our method jointly minimizes the reconstruction error for higher order node neighborhood, social roles, and edge attributes using a deep architecture that can adequately capture highly nonlinear interactions. We demonstrate the efficacy of our model over existing state-of-the-art methods on a variety of real-world networks including collaboration networks and social networks. We also observe that using edge attributes to inform network embedding yields better performance in downstream tasks such as link prediction and node classification.","","","10.1109/TCSS.2018.2877083","Office of the Director of National Intelligence; Intelligence Advanced Research Projects Activity; Defense Advanced Research Projects Agency; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8536422","Deep learning;graph embedding;network representation","Information representation;Visualization;Deep learning;Social network services","data visualisation;graph theory;learning (artificial intelligence);network theory (graphs);pattern classification;social networking (online)","network structure;edge attributes;network representations;higher order node neighborhood;social networks;link prediction;node classification;coauthorship networks;Twitter mention networks;network embedding;low-dimensional representation learning;visualization;collaboration networks;deep architecture","","1","66","","","","","IEEE","IEEE Journals"
"Audio-Visual Speech Enhancement Using Multimodal Deep Convolutional Neural Networks","J. Hou; S. Wang; Y. Lai; Y. Tsao; H. Chang; H. Wang","Research Center for Information Technology Innovation, Taipei, Taiwan; Graduate Institute of Communication Engineering, National Taiwan University, Taipei, Taiwan; Department of Biomedical Engineering, National Yang-Ming University, Taipei, Taiwan; Research Center for Information Technology Innovation, Taipei, Taiwan; Department of Audiology and Speech language pathology, Mackay Medical College, New Taipei City, Taiwan; Institute of Information Science, Academia Sinica, Taipei, Taiwan","IEEE Transactions on Emerging Topics in Computational Intelligence","","2018","2","2","117","128","Speech enhancement (SE) aims to reduce noise in speech signals. Most SE techniques focus only on addressing audio information. In this paper, inspired by multimodal learning, which utilizes data from different modalities, and the recent success of convolutional neural networks (CNNs) in SE, we propose an audio-visual deep CNNs (AVDCNN) SE model, which incorporates audio and visual streams into a unified network model. We also propose a multitask learning framework for reconstructing audio and visual signals at the output layer. Precisely speaking, the proposed AVDCNN model is structured as an audio-visual encoder-decoder network, in which audio and visual data are first processed using individual CNNs, and then fused into a joint network to generate enhanced speech (the primary task) and reconstructed images (the secondary task) at the output layer. The model is trained in an endto-end manner, and parameters are jointly learned through back propagation. We evaluate enhanced speech using five instrumental criteria. Results show that the AVDCNN model yields a notably superior performance compared with an audio-only CNN-based SE model and two conventional SE approaches, confirming the effectiveness of integrating visual information into the SE process. In addition, the AVDCNN model also outperforms an existing audio- visual SE model, confirming its capability of effectively combining audio and visual information in SE.","","","10.1109/TETCI.2017.2784878","Academia Sinica Thematic Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8323326","Audio-visual systems;deep convolutional neural networks;multimodal learning;speech enhancement","Visualization;Speech;Speech enhancement;Noise measurement;Mouth;Training;Convolutional neural networks","audio coding;audio signal processing;backpropagation;feedforward neural nets;image coding;speech enhancement;speech recognition","audio-visual speech enhancement;multimodal deep convolutional neural networks;speech signals;audio information;multimodal learning;visual streams;unified network model;multitask learning framework;visual signals;output layer;audio-visual encoder-decoder network;visual data;enhanced speech;SE process;audio-visual deep CNN-SE model;AVDCNN model","","10","87","","","","","IEEE","IEEE Journals"
"Deep CNN With Multi-Scale Rotation Invariance Features for Ship Classification","Q. Shi; W. Li; F. Zhang; W. Hu; X. Sun; L. Gao","College of Information Science and Technology, Beijing University of Chemical Technology, Beijing, China; College of Information Science and Technology, Beijing University of Chemical Technology, Beijing, China; College of Information Science and Technology, Beijing University of Chemical Technology, Beijing, China; College of Information Science and Technology, Beijing University of Chemical Technology, Beijing, China; Chinese Academy of Sciences, Institute of Remote Sensing and Digital Earth, Beijing, China; Chinese Academy of Sciences, Institute of Remote Sensing and Digital Earth, Beijing, China","IEEE Access","","2018","6","","38656","38668","With the rapid development of target tracking technology, how to efficiently take advantage of useful information from optical images for ship classification becomes a challenging problem. In this paper, a novel deep learning framework fused with low-level features is proposed. Deep convolutional neural network (CNN) has been popularly used to capture structural information and semantic context because of the ability of learning high-level features; however, lacking of capability to deal with global rotation in large-scale image and losing some important information in bottom layers of the CNN limit its performance in extracting multi-scales rotation invariance features. Comparatively, some classic algorithms, such as Gabor filter or multiple scales completed local binary patterns, can effectively capture low-level texture information. In the proposed framework, low-level features are combined with high-level features obtained by deep CNN. The fused features are further fed into a typical support vector machine classifier. The proposed strategy achieves average accuracy of 98.33% on the BCCT200-RESIZE data and 88.00% on the challenging VAIS data, which demonstrates its superior classification performance when compared with some state-of-the-art methods.","","","10.1109/ACCESS.2018.2853620","National Key Research and Development Program of China; Higher Education and High-Quality and World-Class Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8405523","Ship classification;convolutional neural network;feature learning;feature-level fusion","Marine vehicles;Feature extraction;Convolution;Training;Support vector machines;Face recognition;Task analysis","feature extraction;feedforward neural nets;image classification;image texture;learning (artificial intelligence);support vector machines","high-level features;BCCT200-RESIZE data;support vector machine;Gabor filter;deep convolutional neural network;convolutional neural network;deep learning framework;optical images;target tracking technology;ship classification;multiscale rotation invariance features;deep CNN;low-level texture information;multiscales rotation invariance features;large-scale image;global rotation","","2","54","","","","","IEEE","IEEE Journals"
"High-Speed Channel Modeling With Machine Learning Methods for Signal Integrity Analysis","T. Lu; J. Sun; K. Wu; Z. Yang","Google Inc., Mountain View, CA, USA; Mathematics Department, Stanford University, Stanford, CA, USA; Google Inc., Mountain View, CA, USA; Google Inc., Mountain View, CA, USA","IEEE Transactions on Electromagnetic Compatibility","","2018","60","6","1957","1964","In this work, machine learning methods are applied to high-speed channel modeling for signal integrity analysis. Linear, support vector, and deep neural network (DNN) regressions are adopted to predict the eye-diagram metrics, taking advantage of the massive amounts of simulation data gathered from prior designs. The regression models, once successfully trained, can be used to predict the performance of high-speed channels based on various design parameters. The proposed learning-based approach saves complex circuit simulations and substantial domain knowledge altogether, in contrast to alternatives that exploit novel numerical techniques or advanced hardware to speed up traditional simulations for signal integrity analysis. Our numerical examples suggest that both support vector and DNN regressions are able to capture the nonlinearities imposed by transmitter and receiver models in high-speed channels. Overall, DNN regression is superior to support vector regression in predicting the eye-diagram metrics. Moreover, we also investigate the impact of various tunable parameters, optimization methods, and data preprocessing on both the learning speed and the prediction accuracy for the support vector and DNN regressions.","","","10.1109/TEMC.2017.2784833","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8245823","Deep neural networks (DNNs);eye diagram;high-speed channel;machine learning;signal integrity;support vector regression (SVR)","Integrated circuit modeling;Predictive models;Computational modeling;Support vector machines;Training","circuit simulation;learning (artificial intelligence);neural nets;optimisation;regression analysis;signal processing;support vector machines","high-speed channel modeling;machine learning methods;signal integrity analysis;deep neural network regressions;eye-diagram metrics;regression models;learning-based approach;complex circuit simulations;DNN regression;receiver models;support vector regressions;transmitter models","","11","23","","","","","IEEE","IEEE Journals"
"Hyperspectral Image Classification Based on Deep Deconvolution Network With Skip Architecture","X. Ma; A. Fu; J. Wang; H. Wang; B. Yin","School of Information and Communication Engineering, Dalian University of Technology, Dalian, China; School of Information and Communication Engineering, Dalian University of Technology, Dalian, China; School of Information Science and Technology, Dalian Maritime University, Dalian, China; School of Information and Communication Engineering, Dalian University of Technology, Dalian, China; School of Information and Communication Engineering, Dalian University of Technology, Dalian, China","IEEE Transactions on Geoscience and Remote Sensing","","2018","56","8","4781","4791","Convolution neural network (CNN) utilizes alternating convolutional and pooling layers to learn representative spatial information when the training samples are sufficient. However, for pixelwise classification of hyperspectral image, some important information is neglected by CNN, such as the erased information by the pooling operation and the appearance information from lower layers. Moreover, the lack of training samples is a common situation in remote sensing area, which afflicts CNN with overfitting problem. To address the aforementioned issues, this paper designs an end-to-end deconvolution network with skip architecture to learn the spectral-spatial features. The proposed network starts with two branches, i.e., the spatial branch and spectral branch. In the spatial branch, a band selection layer is designed to reduce parameters and remit the overfitting problem, unpooling and deconvolution operations are utilized to recover the erased information of the pooling layers and learn pixelwise spatial representation hierarchically, and the skip architecture is constructed for merging the deep semantic information with the shallow appearance information. In the spectral branch, a contextual deep network is employed for learning deep spectral features. Experimental results on three benchmark data sets reveal the competitive performance of the proposed approach over several related methods.","","","10.1109/TGRS.2018.2837142","National Natural Science Foundation of China; China Postdoctoral Science Foundation; Fundamental Research Funds for the Central Universities; Zhejiang University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8372975","Convolution neural network (CNN);deconvolution network;feature learning;hyperspectral image classification","Hyperspectral imaging;Feature extraction;Deconvolution;Training;Semantics","feedforward neural nets;geophysical image processing;image classification;image representation;learning (artificial intelligence);remote sensing","overfitting problem;unpooling deconvolution operations;erased information;pooling layers;pixelwise spatial representation;skip architecture;deep semantic information;shallow appearance information;spectral branch;contextual deep network;deep spectral features;hyperspectral image classification;deep deconvolution network;convolution neural network;CNN;representative spatial information;training samples;pixelwise classification;pooling operation;lower layers;remote sensing area;aforementioned issues;end-to-end deconvolution network;spectral-spatial features","","5","44","","","","","IEEE","IEEE Journals"
"AENet: Learning Deep Audio Features for Video Analysis","N. Takahashi; M. Gygli; L. Van Gool","ETH Zurich, Zurich, Switzerland; Computer Vision Laboratory, ETH Zurich, Zurich, Switzerland; Computer Vision Laboratory, ETH Zurich, Zurich, Switzerland","IEEE Transactions on Multimedia","","2018","20","3","513","524","We propose a new deep network for audio event recognition, called AENet. In contrast to speech, sounds coming from audio events may be produced by a wide variety of sources. Furthermore, distinguishing them often requires analyzing an extended time period due to the lack of clear subword units that are present in speech. In order to incorporate this long-time frequency structure of audio events, we introduce a convolutional neural network (CNN) operating on a large temporal input. In contrast to previous works, this allows us to train an audio event detection system end to end. The combination of our network architecture and a novel data augmentation outperforms previous methods for audio event detection by 16%. Furthermore, we perform transfer learning and show that our model learned generic audio features, similar to the way CNNs learn generic features on vision tasks. In video analysis, combining visual features and traditional audio features, such as mel frequency cepstral coefficients, typically only leads to marginal improvements. Instead, combining visual features with our AENet features, which can be computed efficiently on a GPU, leads to significant performance improvements on action recognition and video highlight detection. In video highlight detection, our audio features improve the performance by more than 8% over visual features alone.","","","10.1109/TMM.2017.2751969","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8036251","Convolutional neural network;audio feature;large audio event dataset;large input field;highlight detection","Feature extraction;Hidden Markov models;Mel frequency cepstral coefficient;Visualization;Speech;Network architecture","audio signal processing;computer vision;feature extraction;feedforward neural nets;learning (artificial intelligence);video signal processing","deep audio features;video analysis;deep network;audio event recognition;extended time period;long-time frequency structure;convolutional neural network;network architecture;transfer learning;generic audio features;visual features;traditional audio features;mel frequency cepstral coefficients;AENet features;video highlight detection;audio event detection system;novel data augmentation;action recognition","","13","66","","","","","IEEE","IEEE Journals"
"Residual Networks for Computer Go","T. Cazenave","Université Paris-Dauphine, PSL Research University, CNRS, LAMSADE, Paris, France","IEEE Transactions on Games","","2018","10","1","107","110","Deep learning for the game of Go recently had a tremendous success with the victory of AlphaGo against Lee Sedol in March 2016. We propose to use residual networks so as to improve the training of a policy network for computer Go. Training is faster than with usual convolutional networks and residual networks achieve high accuracy on our test set and a four dan level.","","","10.1109/TCIAIG.2017.2681042","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7875402","Computer Go;deep learning;residual networks","Training;Games;Computers;Bagging;Convolution;Neural networks;Color","computer games;learning (artificial intelligence)","residual networks;policy network;deep learning;AlphaGo;computer Go","","1","8","","","","","IEEE","IEEE Journals"
"Learning to Segment Object Candidates via Recursive Neural Networks","T. Chen; L. Lin; X. Wu; N. Xiao; X. Luo","School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; School of Computer Science and Information Security, Guilin University of Electronic Technology, Guilin, China","IEEE Transactions on Image Processing","","2018","27","12","5827","5839","To avoid the exhaustive search over locations and scales, current state-of-the-art object detection systems usually involve a crucial component generating a batch of candidate object proposals from images. In this paper, we present a simple yet effective approach for segmenting object proposals via a deep architecture of recursive neural networks (ReNNs), which hierarchically groups regions for detecting object candidates over scales. Unlike traditional methods that mainly adopt fixed similarity measures for merging regions or finding object proposals, our approach adaptively learns the region merging similarity and the objectness measure during the process of hierarchical region grouping. Specifically, guided by a structured loss, the ReNN model jointly optimizes the cross-region similarity metric with the region merging process as well as the objectness prediction. During inference of the object proposal generation, we introduce randomness into the greedy search to cope with the ambiguity of grouping regions. Extensive experiments on standard benchmarks, e.g., PASCAL VOC and ImageNet, suggest that our approach is capable of producing object proposals with high recall while well preserving the object boundaries and outperforms other existing methods in both accuracy and efficiency.","","","10.1109/TIP.2018.2859025","National Natural Science Foundation of China; Program for Guangdong Introducing Innovative and Entrepreneurial Teams; National Natural Science Foundation of China; Science and Technology Planning Project of Guangdong Province; Natural Science Foundation of Guangdong Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8418394","Object proposal generation;object segmentation;region grouping;recursive neural networks;deep learning","Proposals;Deep learning;Feature extraction;Neural networks;Object detection;Object segmentation;Object recognition","image segmentation;learning (artificial intelligence);neural nets;object detection","grouping regions;object boundaries;segment object candidates;recursive neural networks;exhaustive search;candidate object proposals;groups regions;fixed similarity measures;objectness measure;hierarchical region grouping;cross-region similarity;objectness prediction;object proposal generation;state-of-the-art object detection systems;PASCAL VOC;ImageNet;ReNN model","Algorithms;Animals;Humans;Image Processing, Computer-Assisted;Neural Networks (Computer)","1","44","","","","","IEEE","IEEE Journals"
"Deep Metric Learning with BIER: Boosting Independent Embeddings Robustly","M. Opitz; G. Waltner; H. Possegger; H. Bischof","Institute for Computer Graphics and Vision, Graz University of Technology, Graz, Styria Austria (e-mail: michael.opitz@icg.tugraz.at); Institute for Computer Graphics and Vision, Technische Universitat Graz, 27253 Graz, Steiermark Austria (e-mail: waltner@icg.tugraz.at); Institute for Computer Graphics and Vision, Graz University of Technology, Graz, Styria Austria 8010 (e-mail: possegger@icg.tugraz.at); Institut for Computer Graphics and Vision, Graz University of Technology, Graz, Styria Austria A-8010 (e-mail: bischof@icg.tugraz.at)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","PP","99","1","1","Learning similarity functions between image pairs with deep neural networks yields highly correlated activations of embeddings. In this work, we show how to improve the robustness of such embeddings by exploiting the independence within ensembles. To this end, we divide the last embedding layer of a deep network into an embedding ensemble and formulate the task of training this ensemble as an online gradient boosting problem. Each learner receives a reweighted training sample from the previous learners. Further, we propose two loss functions which increase the diversity in our ensemble. These loss functions can be applied either for weight initialization or during training. Together, our contributions leverage large embedding sizes more effectively by significantly reducing correlation of the embedding and consequently increase retrieval accuracy of the embedding. Our method works with any differentiable loss function and does not introduce any additional parameters during test time. We evaluate our metric learning method on image retrieval tasks and show that it improves over state-of-the-art methods on the CUB-200-2011, Cars-196, Stanford Online Products, In-Shop Clothes Retrieval and VehicleID datasets. Therefore, our findings suggest that by dividing deep networks at the end into several smaller and diverse networks, we can significantly reduce overfitting.","","","10.1109/TPAMI.2018.2848925","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8395046","Metric Learning;Deep Learning;Convolutional Neural Network","Measurement;Training;Boosting;Correlation;Feature extraction;Robustness;Task analysis","","","","6","","","","","","IEEE","IEEE Early Access Articles"
"How to Train a CAT: Learning Canonical Appearance Transformations for Direct Visual Localization Under Illumination Change","L. Clement; J. Kelly","Toronto, ON, Canada; Toronto, ON, Canada","IEEE Robotics and Automation Letters","","2018","3","3","2447","2454","Direct visual localization has recently enjoyed a resurgence in popularity with the increasing availability of cheap mobile computing power. The competitive accuracy and robustness of these algorithms compared to state-of-the-art feature-based methods, as well as their natural ability to yield dense maps, makes them an appealing choice for a variety of mobile robotics applications. However, direct methods remain brittle in the face of appearance change due to their underlying assumption of photometric consistency, which is commonly violated in practice. In this letter, we propose to mitigate this problem by training deep convolutional encoder-decoder models to transform images of a scene such that they correspond to a previously seen canonical appearance. We validate our method in multiple environments and illumination conditions using high-fidelity synthetic RGB-D datasets, and integrate the trained models into a direct visual localization pipeline, yielding improvements in visual odometry accuracy through time-varying illumination conditions, as well as improved metric relocalization performance under illumination change, where conventional methods normally fail. We further provide a preliminary investigation of transfer learning from synthetic to real environments in a localization context.","","","10.1109/LRA.2018.2799741","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8272363","Deep learning in robotics and automation;visual learning;visual-based navigation;localization","Lighting;Visualization;Cameras;Robustness;Brightness;Pipelines;Mathematical model","convolution;distance measurement;feature extraction;feedforward neural nets;image colour analysis;learning (artificial intelligence);lighting;mobile robots;robot vision;SLAM (robots)","illumination change;mobile robotics applications;deep convolutional encoder-decoder models;high-fidelity synthetic RGB-D datasets;direct visual localization pipeline;visual odometry accuracy;time-varying illumination conditions;canonical appearance transformations learning;mobile computing power;metric relocalization performance;CAT","","2","35","","","","","IEEE","IEEE Journals"
"Webly-Supervised Fine-Grained Visual Categorization via Deep Domain Adaptation","Z. Xu; S. Huang; Y. Zhang; D. Tao","Cooperative Medianet Innovation Center and the Shanghai Key Laboratory of Multimedia Processing and Transmissions, Shanghai Jiao Tong University, Shanghai, China; Centre for Artificial Intelligence and the Faculty of Engineering and Information Technology, University of Technology Sydney, Ultimo, NSW, Australia; Cooperative Medianet Innovation Center and the Shanghai Key Laboratory of Multimedia Processing and Transmissions, Shanghai Jiao Tong University, Shanghai, China; School of Information Technologies and the Faculty of Engineering and Information Technologies, University of Sydney, Darlington, NSW, Australia","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","5","1100","1113","Learning visual representations from web data has recently attracted attention for object recognition. Previous studies have mainly focused on overcoming label noise and data bias and have shown promising results by learning directly from web data. However, we argue that it might be better to transfer knowledge from existing human labeling resources to improve performance at nearly no additional cost. In this paper, we propose a new semi-supervised method for learning via web data. Our method has the unique design of exploiting strong supervision, i.e., in addition to standard image-level labels, our method also utilizes detailed annotations including object bounding boxes and part landmarks. By transferring as much knowledge as possible from existing strongly supervised datasets to weakly supervised web images, our method can benefit from sophisticated object recognition algorithms and overcome several typical problems found in webly-supervised learning. We consider the problem of fine-grained visual categorization, in which existing training resources are scarce, as our main research objective. Comprehensive experimentation and extensive analysis demonstrate encouraging performance of the proposed approach, which, at the same time, delivers a new pipeline for finegrained visual categorization that is likely to be highly effective for real-world applications.","","","10.1109/TPAMI.2016.2637331","High Technology Research and Development Program of China; NSFC; STCSM; 111 Project B07022; Australian Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7778168","Fine-grained visual categorization;part-based model;domain adaptation;webly-supervised learning;semi-supervised learning","Visualization;Object recognition;Training;Knowledge engineering;Algorithm design and analysis;Training data;Flickr","computer vision;image representation;Internet;learning (artificial intelligence);object recognition","semisupervised method;web data;strong supervision;standard image-level labels;object bounding boxes;strongly supervised datasets;supervised web images;webly-supervised learning;deep domain adaptation;human labeling resources;object recognition algorithms;training resources;visual representation learning;webly-supervised fine-grained visual categorization;part landmarks","","11","64","","","","","IEEE","IEEE Journals"
"Handover Control in Wireless Systems via Asynchronous Multiuser Deep Reinforcement Learning","Z. Wang; L. Li; Y. Xu; H. Tian; S. Cui","State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; Department of Electrical and Computer Engineer, University of California at Davis, Davis, CA, USA; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; Department of Electrical and Computer Engineer, University of California at Davis, Davis, CA, USA","IEEE Internet of Things Journal","","2018","5","6","4296","4307","In this paper, we propose a two-layer framework to learn the optimal handover (HO) controllers in possibly large-scale wireless systems supporting mobile Internet-of-Things users or traditional cellular users, where the user mobility patterns could be heterogeneous. In particular, our proposed framework first partitions the user equipments (UEs) with different mobility patterns into clusters, where the mobility patterns are similar in the same cluster. Then, within each cluster, an asynchronous multiuser deep reinforcement learning (RL) scheme is developed to control the HO processes across the UEs in each cluster, in the goal of lowering the HO rate while ensuring certain system throughput. In this scheme, we use a deep neural network (DNN) as an HO controller learned by each UE via RL in a collaborative fashion. Moreover, we use supervised learning in initializing the DNN controller before the execution of RL to exploit what we already know with traditional HO schemes and to mitigate the negative effects of random exploration at the initial stage. Furthermore, we show that the adopted global-parameter-based asynchronous framework enables us to train faster with more UEs, which could nicely address the scalability issue to support large systems. Finally, simulation results demonstrate that the proposed framework can achieve better performance than the state-of-art online schemes, in terms of HO rates.","","","10.1109/JIOT.2018.2848295","National Natural Science Foundation of China; National Science Foundation; China Scholarships Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8387430","Cooperative communication;mobility optimization;recurrent neural networks (RNNs);reinforcement learning (RL);ultra-dense networks (UDNs)","Internet of Things;Handover;Wireless communication;Throughput;Learning (artificial intelligence);Supervised learning","","","","9","32","","","","","IEEE","IEEE Journals"
"Local Deep Field for Electrocardiogram Beat Classification","W. Li; J. Li","School of Instrument Science and Engineering, Southeast University, Nanjing, China; School of Basic Medical Sciences, Nanjing Medical University, Nanjing, China","IEEE Sensors Journal","","2018","18","4","1656","1664","To reduce the high mortality rate among heart patients, electrocardiogram (ECG) beat classification plays an important role in computer aided diagnosis system, but this issue is challenging because of the complex variations of data. Since ECG beat data lie on high-dimension manifold, we propose a novel method, named “local deep field”, in purpose of capturing the devil in the details of such data manifold. This method learns different deep models within the local manifold charts. Local regionalization can help models focus on the particularity of local variations, while deep architecture can disentangle the hidden class information within local distributions. The advantage of the proposed method has been experimentally demonstrated in terms of MIT-BIH Arrhythmia database.","","","10.1109/JSEN.2017.2772031","Natural Science Foundation of Jiangsu Province; Southeast University–Nanjing Medical University Collaborative Research Project; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8103019","ECG beat classification;local deep field;data manifold","Electrocardiography;Machine learning;Manifolds;Databases;Feature extraction;Heart beat;Sensors","electrocardiography;learning (artificial intelligence);medical signal processing;signal classification","deep architecture;local manifold charts;data manifold;high-dimension manifold;computer aided diagnosis system;ECG;heart patients;electrocardiogram beat classification;local deep field","","5","46","","","","","IEEE","IEEE Journals"
"Deep Learning-Based Unmanned Surveillance Systems for Observing Water Levels","J. Pan; Y. Yin; J. Xiong; W. Luo; G. Gui; H. Sari","Key Laboratory of Broadband Wireless Communication and Sensor Network Technology, Nanjing University of Posts and Telecommunications, Ministry of Education, Nanjing, China; Key Laboratory of Broadband Wireless Communication and Sensor Network Technology, Nanjing University of Posts and Telecommunications, Ministry of Education, Nanjing, China; Key Laboratory of Broadband Wireless Communication and Sensor Network Technology, Nanjing University of Posts and Telecommunications, Ministry of Education, Nanjing, China; NARI Group Corporations/State Grid Electric Power Research Institute, Nanjing, China; Key Laboratory of Broadband Wireless Communication and Sensor Network Technology, Nanjing University of Posts and Telecommunications, Ministry of Education, Nanjing, China; Key Laboratory of Broadband Wireless Communication and Sensor Network Technology, Nanjing University of Posts and Telecommunications, Ministry of Education, Nanjing, China","IEEE Access","","2018","6","","73561","73571","Traditional surveillance systems for observing water levels are often complex, costly, and time-consuming. In this paper, we developed a low-cost unmanned surveillance system consisting of remote measuring stations and a monitoring center. The system uses a map-based Web service, as well as video cameras, water level analyzers, and wireless communication routers necessary to display real-time water level measurements of rivers and reservoirs on a Web platform. With the aid of a wireless communication router, the water level information is transmitted to a server connected to the Internet via a cellular network. By combining complex water level information of different river basins, the proposed system can be used to forecast and prevent flood disasters. In order to evaluate the proposed system, we conduct experiments using three feasible methods, including the difference method, dictionary learning, and deep learning. The experimental results show that the deep learning-based method performs best in terms of accuracy and stability.","","","10.1109/ACCESS.2018.2883702","National Natural Science Foundation of China; Jiangsu Specially Appointed Professor Program; Program for Jiangsu Six Top Talent; Program for High-Level Entrepreneurial and Innovative Talents Introduction; Natural Science Foundation of Jiangsu Province; Natural Science Foundation of Jiangsu Higher Education Institutions; NUPTSF; Chongqing Municipal Education Commission; Nanjing University of Posts and Telecommunications; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8550626","Water level surveillance;internet of things (IoT);dictionary learning;deep learning;convolutional neural network (CNN)","Water resources;Surveillance;Streaming media;Cameras;Floods;Water conservation","","","","26","33","","","","","IEEE","IEEE Journals"
"DRL-Scheduling: An Intelligent QoS-Aware Job Scheduling Framework for Applications in Clouds","Y. Wei; L. Pan; S. Liu; L. Wu; X. Meng","School of Software, Shandong University, Jinan, China; School of Software, Shandong University, Jinan, China; School of Software, Shandong University, Jinan, China; School of Software, Shandong University, Jinan, China; School of Software, Shandong University, Jinan, China","IEEE Access","","2018","6","","55112","55125","As an increasing number of traditional applications migrated to the cloud, achieving resource management and performance optimization in such a dynamic and uncertain environment becomes a big challenge for cloud-based application providers. In particular, job scheduling is a non-trivial task, which is responsible for allocating massive job requests submitted by users to the most suitable resources and satisfying user QoS requirements as much as possible. Inspired by recent success of using deep reinforcement learning techniques to solve AI control problems, in this paper, we propose an intelligent QoS-aware job scheduling framework for application providers. A deep reinforcement learning-based job scheduler is the key component of the framework. It is able to learn to make appropriate online job-to-VM decisions for continuous job requests directly from its experiences without any prior knowledge. Experimental results using synthetic workloads and real-world NASA workload traces show that compared with other baseline solutions, our proposed job scheduling approach can efficiently reduce average job response time (e.g., reduced by 40.4% compared with the best baseline for NASA traces), guarantee the QoS at a high level (e.g., job success rate is higher than 93% for all simulated changing workload scenarios), and adapt to different workload conditions.","","","10.1109/ACCESS.2018.2872674","National Natural Science Foundation of China; National Key Research and Development Program of China; Key Research and Development Program of Shandong Province; Shandong University; Special Funds of Taishan Scholar Construction Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8476582","Cloud computing;deep Q-Learning;job scheduling;QoS;reinforcement learning","Cloud computing;Quality of service;Job shop scheduling;Machine learning;Processor scheduling;Task analysis","cloud computing;learning (artificial intelligence);quality of service;resource allocation;scheduling;virtual machines","DRL-scheduling;intelligent QoS-aware job scheduling framework;resource management;cloud-based application providers;deep reinforcement learning-based job scheduler;average job response time;user QoS requirements;online job-to-VM decisions","","3","39","","","","","IEEE","IEEE Journals"
"Zero-Shot Image Classification Based on Deep Feature Extraction","X. Wang; C. Chen; Y. Cheng; Z. J. Wang","School of Information and Electrical Engineering, China University of Mining and Technology, Xuzhou, China; School of Information and Electrical Engineering, China University of Mining and Technology, Xuzhou, China; School of Information and Electrical Engineering, China University of Mining and Technology, Xuzhou, China; Electrical and Computer Engineering Department, University of British Columbia, Vancouver, BC, Canada","IEEE Transactions on Cognitive and Developmental Systems","","2018","10","2","432","444","The attribute-based zero-shot learning methods generally use low-level features of images to train attribute classifiers, and the corresponding classification accuracy heavily depends on specific low-level features. Because deep networks can automatically extract features from original unlabeled images and the extracted features can better represent the nature of original images, we proposed a zero-shot image classification method based on deep feature extraction. In the image preprocessing step, in order to reduce the computational complexity and the correlations between pixels, image patches extraction and zero-phase component analysis whitening are performed. The compressed feature representations of unlabeled image patches are learned through a stacked sparse autoencoder and a feature mapping matrix can be obtained. Further, we use the feature mapping matrix as a convolution kernel to convolve with image patches. Since the convolution operation results in the feature vector with huge dimensionality, the convolution features will be pooled to reduce the number of network parameters and to reduce the spatial resolution of the network to prevent over-fitting. Finally, the exacted image features are used to train the conventional indirect attribute prediction model to predict image attributes and classify images under the zero-shot setting. Experimental results on the shoes, outdoor scene recognition, and a-Yahoo datasets show that, compared with several popular zero-shot learning methods, the proposed method can yield more accurate attribute prediction and better zero-shot image classification.","","","10.1109/TCDS.2016.2632178","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7755734","Attribute;convolutional neural network (CNN);feature;stacked sparse autoencoder (SSAE);zero-shot learning","Feature extraction;Image classification;Training;Machine learning;Semantics;Predictive models;Neural networks","feature extraction;image classification;image representation;image resolution;learning (artificial intelligence);matrix algebra","zero-shot image classification;deep feature extraction;specific low-level features;deep networks;image preprocessing step;image patches extraction;zero-phase component analysis whitening;compressed feature representations;unlabeled image patches;feature mapping matrix;feature vector;convolution features","","2","35","","","","","IEEE","IEEE Journals"
"A Machine Learning-Based Algorithm for Joint Scheduling and Power Control in Wireless Networks","X. Cao; R. Ma; L. Liu; H. Shi; Y. Cheng; C. Sun","School of Automation, Southeast University, Nanjing, China; School of Automation, Southeast University, Nanjing, China; Department of Electrical and Computer Engineering, Illinois Institute of Technology, Chicago, IL, USA; School of Automation, Southeast University, Nanjing, China; Department of Electrical and Computer Engineering, Illinois Institute of Technology, Chicago, IL, USA; School of Automation, Southeast University, Nanjing, China","IEEE Internet of Things Journal","","2018","5","6","4308","4318","Wireless network resource allocation is an important issue for designing Internet of Things systems. In this paper, we consider the problem of wireless network capacity optimization that involves issues such as flow allocation, link scheduling, and power control. We show that it can be decomposed into a linear program and a nonlinear weighted sum-rate maximization problem for power allocation. Unlike most traditional methods that iteratively search the optimal solutions of the nonlinear subproblem, we propose to directly compute approximated solutions based on machine learning techniques. Specifically, the learning systems consist of both support vector machines (SVMs) and deep belief networks (DBNs) that are trained based on offline computed optimal solutions. In the running phase, the SVMs perform classification for each link to decide whether to use maximal transmit power or be turned off. At the same time, the DBNs compute an approximation of the optimal power allocation. The two results are combined to obtain an approximated solution of the nonlinear program. Simulation results demonstrate the effectiveness of the proposed machine learning-based algorithm.","","","10.1109/JIOT.2018.2853661","National Natural Science Foundation of China; Division of Electrical, Communications and Cyber Systems; State Key Laboratory of Synthetical Automation for Process Industries; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8405562","Deep belief network (DBN);deep learning;joint optimization;power control;scheduling;support vector machine (SVM);wireless network","Machine learning;Resource management;Optimization;Power control;Wireless networks;Machine learning algorithms;Routing","","","","5","34","","","","","IEEE","IEEE Journals"
"DeltaFrame-BP: An Algorithm Using Frame Difference for Deep Convolutional Neural Networks Training and Inference on Video Data","B. Han; K. Roy","Department of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA; Department of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA","IEEE Transactions on Multi-Scale Computing Systems","","2018","4","4","624","634","Inspired by the success of deep convolutional neural networks (CNNs) with back-propagation (BP) training on large-scale image recognition tasks, recent research efforts concentrated on expending deep CNNs toward more challenging automatized video analysis, such as video classification, object tracking, action recognition and optical flow detection. Video comprises a sequence of images (frames) captured over time in which image data is a function of space and time. Extracting three-dimensional spatial-temporal features from multiple frames becomes a key ingredient for capturing and incorporating appearance and dynamic representations using deep CNNs. Hence, training deep CNNs on video involves significant computational resources and energy consumption due to extended number of frames across the time line of video length. We propose DeltaFrame-BP, a deep learning algorithm, which significantly reduces computational cost and energy consumption without accuracy degradation by streaming frame differences for deep CNNs training and inference. The inherent similarity between video frames due to high fps (frames per second) in video recording helps achieving high-sparsity and low-dynamic range data streaming using frame differences in comparison with raw video frames. According to our simulation, nearly 25 percent energy reduction was achieved in training using the proposed accuracy-lossless DeltaFrame-BP algorithm in comparison with the standard Back-propagation algorithm.","","","10.1109/TMSCS.2018.2865303","Center for Spintronic Materials, Interfaces, and Novel Architectures (C-SPIN); Semiconductor Research Corporation; National Science Foundation; Intel Corporation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8434331","Computer vision;deep neural network;back-propagation algorithm;convolutional neural network;energy efficiency","Convolutional neural networks;Training data;Deep learning;Streaming media;Computer vision;Machine learning;Neural networks;Energy efficiency","","","","","69","","","","","IEEE","IEEE Journals"
"Deep Fusion Feature Learning Network for MI-EEG Classification","J. Yang; S. Yao; J. Wang","School of Information Science and Engineering, Yunnan University, Kunming, China; School of Information Science and Engineering, Yunnan University, Kunming, China; School of Information Science and Engineering, Yunnan University, Kunming, China","IEEE Access","","2018","6","","79050","79059","Brain-computer interfaces (BCIs) are used to provide a direct communication between the human brain and the external devices, such as wheelchairs and intelligent apparatus, by interpreting the electroencephalograph (EEG) signals. Recently, motor imagery EEG (MI-EEG) has become an active research field where a subject's active intent can be detected. The accurate decoding of MI-EEG signals is essential for effective BCI systems but also very challenging due to the lack of informative correlation between the signals and the brain activities. To improve the precision performance of a BCI system, accurate feature discrimination from input signals and proper classification are necessary. However, the traditional deep learning scheme is failed to generate spatio-temporal representation simultaneously and capture the dynamic correlation for an MI-EEG sequence. To address this problem, we propose a long short-term memory network combined with a spatial convolutional network that concurrently learns spatial information and temporal correlations from raw MI-EEG signals. In addition, spectral representations of EEG signals are obtained via a discrete wavelet transformation decomposition. In order to achieve even higher learning rates and less demanding initialization, we employ a batch normalization method before training and recognition. Various experiments have been performed to evaluate the performance of the proposed deep learning architectures. Results indicate a high level of accuracy over both the public data set and the local data set. Our method can also serve as a useful and robust model for multi-task classification and subject-independent movement class decoder across many different methods.","","","10.1109/ACCESS.2018.2877452","National Natural Science Foundation of China; Yunnan University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8532289","Motor imagery electroencephalograph (MI-EEG) brain computer interfaces (BCI);long short-term memory (LSTM);convolutional neural networks (CNN)","Electroencephalography;Feature extraction;Discrete wavelet transforms;Electrodes;Convolution;Training;Biological neural networks","brain;brain-computer interfaces;discrete wavelet transforms;electroencephalography;feature extraction;medical signal processing;neural nets;neurophysiology;signal classification","short-term memory network;spatial convolutional network;feature discrimination;MI-EEG sequence;spatio-temporal representation;BCI system;brain activities;motor imagery EEG;electroencephalograph signals;intelligent apparatus;wheelchairs;human brain;BCIs;brain-computer interfaces;MI-EEG classification;deep fusion feature learning network;subject-independent movement class decoder;multitask classification;deep learning architectures;discrete wavelet transformation decomposition;EEG signals;spectral representations","","","40","","","","","IEEE","IEEE Journals"
"Channel Selective Activity Recognition with WiFi: A Deep Learning Approach Exploring Wideband Information","F. Wang; W. Gong; J. Liu; K. Wu","Simon Fraser University Faculty of Applied Sciences, 120447 Burnaby, British Columbia Canada V5A 1S6 (e-mail: fangxinw@sfu.ca); Simon Fraser University, Vancouver, British Columbia Canada (e-mail: gongweig@sfu.ca); Simon Fraser University, Vancouver, British Columbia Canada (e-mail: jcliu@cs.sfu.ca); Computer Science, University of Victoria, Victoria, British Columbia Canada V8W 3P6 (e-mail: wkui@uvic.ca)","IEEE Transactions on Network Science and Engineering","","2018","PP","99","1","1","WiFi-based human activity recognition explores the correlations between body movement and the reflected WiFi signals to classify different activities. State-of-the-art solutions mostly work on a single WiFi channel and hence are quite sensitive to the quality of a particular channel. Co-channel interference in an indoor environment can seriously undermine the recognition accuracy. In this paper, we for the first time explore wideband WiFi information with advanced deep learning towards more accurate and robust activity recognition. We present a practical Channel Selective Activity Recognition system (CSAR) with Commercial Off-The-Shelf (COTS) WiFi devices. The key innovation is to actively select available WiFi channels with good quality and seamlessly hop among adjacent channels to form an extended channel. The wider bandwidth with more subcarriers offers stable information with a higher resolution for feature extraction. Conventional classification tools, e.g., hidden Markov model and k-nearest neighbours, however, are not only sensitive to feature distortion but also not smart enough to explore the time scale correlations from the extracted spectrogram. We accordingly explore advanced deep learning tools for this application context. We demonstrate an integration of channel selection and long short term memory network (LSTM), which seamlessly combine the richer time and frequency features for activity recognition. We have implemented a CSAR prototype using Intel 5300 WiFi cards. Our realworld experiments show that CSAR achieves a stable recognition accuracy around 95% even in crowded wireless environments (compared to 80% with state-of-the-art solutions that highly depend on the quality of the working channel). We have also examined the impact of environments and persons, and the results reaffirm its robustness.","","","10.1109/TNSE.2018.2825144","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8334568","Human activity recognition;Deep learning;LSTM;Channel hopping","Wireless fidelity;Activity recognition;Feature extraction;Hidden Markov models;Machine learning;Tools;Robustness","","","","2","","","","","","IEEE","IEEE Early Access Articles"
"Optimum Selection of DNN Model and Framework for Edge Inference","D. Velasco-Montero; J. Fernández-Berni; R. Carmona-Galán; Á. Rodríguez-Vázquez","Institute of Microelectronics of Seville, Universidad de Sevilla-CSIC, Seville, Spain; Institute of Microelectronics of Seville, Universidad de Sevilla-CSIC, Seville, Spain; Institute of Microelectronics of Seville, Universidad de Sevilla-CSIC, Seville, Spain; Institute of Microelectronics of Seville, Universidad de Sevilla-CSIC, Seville, Spain","IEEE Access","","2018","6","","51680","51692","This paper describes a methodology to select the optimum combination of deep neural network and software framework for visual inference on embedded systems. As a first step, benchmarking is required. In particular, we have benchmarked six popular network models running on four deep learning frameworks implemented on a low-cost embedded platform. Three key performance metrics have been measured and compared with the resulting 24 combinations: accuracy, throughput, and power consumption. Then, application-level specifications come into play. We propose a figure of merit enabling the evaluation of each network/framework pair in terms of relative importance of the aforementioned metrics for a targeted application. We prove through numerical analysis and meaningful graphical representations that only a reduced subset of the combinations must actually be considered for real deployment. Our approach can be extended to other networks, frameworks, and performance parameters, thus supporting system-level design decisions in the ever-changing ecosystem of embedded deep learning technology.","","","10.1109/ACCESS.2018.2869929","Secretaría de Estado de Investigación, Desarrollo e Innovación; Agencia de Innovación y Desarrollo de Andalucía; H2020 Marie Skłodowska-Curie Actions; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8463447","Benchmarking;deep learning;convolutional neural networks;edge inference;embedded vision;high-level specifications","Benchmark testing;Measurement;Economic indicators;Computational modeling;Image recognition;Software;Numerical models","embedded systems;learning (artificial intelligence);neural nets","key performance metrics;throughput;power consumption;application-level specifications;network/framework pair;targeted application;performance parameters;system-level design decisions;embedded deep learning technology;optimum selection;DNN model;edge inference;optimum combination;deep neural network;software framework;visual inference;embedded systems;benchmarking;popular network models;deep learning frameworks;low-cost embedded platform;meaningful graphical representations","","2","51","","","","","IEEE","IEEE Journals"
"Hyperspectral Image Classification With Deep Feature Fusion Network","W. Song; S. Li; L. Fang; T. Lu","College of Electrical and Information Engineering, Hunan University, Changsha, China; College of Electrical and Information Engineering, Hunan University, Changsha, China; College of Electrical and Information Engineering, Hunan University, Changsha, China; College of Electrical and Information Engineering, Hunan University, Changsha, China","IEEE Transactions on Geoscience and Remote Sensing","","2018","56","6","3173","3184","Recently, deep learning has been introduced to classify hyperspectral images (HSIs) and achieved good performance. In general, deep models adopt a large number of hierarchical layers to extract features. However, excessively increasing network depth will result in some negative effects (e.g., overfitting, gradient vanishing, and accuracy degrading) for conventional convolutional neural networks. In addition, the previous networks used in HSI classification do not consider the strong complementary yet correlated information among different hierarchical layers. To address the above two issues, a deep feature fusion network (DFFN) is proposed for HSI classification. On the one hand, the residual learning is introduced to optimize several convolutional layers as the identity mapping, which can ease the training of deep network and benefit from increasing depth. As a result, we can build a very deep network to extract more discriminative features of HSIs. On the other hand, the proposed DFFN model fuses the outputs of different hierarchical layers, which can further improve the classification accuracy. Experimental results on three real HSIs demonstrate that the proposed method outperforms other competitive classifiers.","","","10.1109/TGRS.2018.2794326","National Natural Science Fund of China for International Cooperation and Exchanges; Fund of Hunan Province for the Science and Technology Plan Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8283837","Convolutional neural networks (CNNs);feature fusion;hyperspectal image classification;residual learning","Feature extraction;Hyperspectral imaging;Training;Convolutional neural networks;Support vector machines;Logistics","feature extraction;geophysical image processing;hyperspectral imaging;image classification;learning (artificial intelligence);neural nets","HSIs;hyperspectral image classification;deep feature fusion network;deep learning;hyperspectral images;conventional convolutional neural networks;convolutional layers","","29","57","","","","","IEEE","IEEE Journals"
"Sparse Markov Decision Processes With Causal Sparse Tsallis Entropy Regularization for Reinforcement Learning","K. Lee; S. Choi; S. Oh","Department of Electrical and Computer Engineering and Automation and Systems Research Institute (ASRI), Seoul National University, Seoul, South Korea; Department of Electrical and Computer Engineering and Automation and Systems Research Institute (ASRI), Seoul National University, Seoul, South Korea; Department of Electrical and Computer Engineering and Automation and Systems Research Institute (ASRI), Seoul National University, Seoul, South Korea","IEEE Robotics and Automation Letters","","2018","3","3","1466","1473","In this letter, a sparse Markov decision process (MDP) with novel causal sparse Tsallis entropy regularization is proposed. The proposed policy regularization induces a sparse and multimodal optimal policy distribution of a sparse MDP. The full mathematical analysis of the proposed sparse MDP is provided. We first analyze the optimality condition of a sparse MDP. Then, we propose a sparse value iteration method that solves a sparse MDP and then prove the convergence and optimality of sparse value iteration using the Banach fixed-point theorem. The proposed sparse MDP is compared to soft MDPs that utilize causal entropy regularization. We show that the performance error of a sparse MDP has a constant bound, while the error of a soft MDP increases logarithmically with respect to the number of actions, where this performance error is caused by the introduced regularization term. In experiments, we apply sparse MDPs to reinforcement learning problems. The proposed method outperforms existing methods in terms of the convergence speed and performance.","","","10.1109/LRA.2018.2800085","Basic Science Research Program; National Research Foundation of Korea (NRF); Ministry of Science and ICT; Next-Generation Information Computing Development Program; NRF; Ministry of Science and ICT; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8276246","Autonomous agents;deep learning in robotics and automation;learning and adaptive systems","Entropy;Markov processes;Learning (artificial intelligence);Convergence;Mathematical analysis;Autonomous vehicles","Banach spaces;entropy;learning (artificial intelligence);Markov processes;mathematical analysis","sparse Markov decision process;sparse policy distribution;multimodal optimal policy distribution;sparse MDP;causal sparse Tsallis entropy regularization;Banach fixed-point theorem;Reinforcement Learning","","1","23","","","","","IEEE","IEEE Journals"
"Robust Place Categorization With Deep Domain Generalization","M. Mancini; S. R. Bulò; B. Caputo; E. Ricci","Sapienza University of Rome, Rome, Italy; Mapillary Research, Graz, Austria; Sapienza University of Rome, Rome, Italy; Fondazione Bruno Kessler, Trento, Italy","IEEE Robotics and Automation Letters","","2018","3","3","2093","2100","Traditional place categorization approaches in robot vision assume that training and test images have similar visual appearance. Therefore, any seasonal, illumination, and environmental changes typically lead to severe degradation in performance. To cope with this problem, recent works have been proposed to adopt domain adaptation techniques. While effective, these methods assume that some prior information about the scenario where the robot will operate is available at training time. Unfortunately, in many cases, this assumption does not hold, as we often do not know where a robot will be deployed. To overcome this issue, in this paper, we present an approach that aims at learning classification models able to generalize to unseen scenarios. Specifically, we propose a novel deep learning framework for domain generalization. Our method develops from the intuition that, given a set of different classification models associated to known domains (e.g., corresponding to multiple environments, robots), the best model for a new sample in the novel domain can be computed directly at test time by optimally combining the known models. To implement our idea, we exploit recent advances in deep domain adaptation and design a convolutional neural network architecture with novel layers performing a weighted version of batch normalization. Our experiments, conducted on three common datasets for robot place categorization, confirm the validity of our contribution.","","","10.1109/LRA.2018.2809700","ERC; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8302933","Recognition;visual learning;semantic scene understanding","Robots;Training;Data models;Computational modeling;Adaptation models;Visualization;Semantics","convolution;feedforward neural nets;generalisation (artificial intelligence);image classification;learning (artificial intelligence);robot vision","deep learning framework;robots;deep domain adaptation;robot place categorization;robust place categorization;deep domain generalization;robot vision;test images;seasonal illumination;classification models;visual appearance;domain adaptation;convolutional neural network architecture;place categorization","","4","45","","","","","IEEE","IEEE Journals"
"Trust-based Social Networks with Computing, Caching and Communications: A Deep Reinforcement Learning Approach","Y. He; C. Liang; R. Yu; Z. Han","Systems and Computer Engineering, Carleton University, Ottawa, Ontario Canada (e-mail: heying@sce.carleton.ca); System and Computer Engineering, Carleton University, Ottawa, Ontario Canada K1S5B6 (e-mail: chengchaoliang@sce.carleton.ca); Systems and Computer Engineering, Carleton University, Ottawa, Ontario Canada K1S5B6 (e-mail: Richard.Yu@Carleton.ca); Electrical and Computer Engineering, University of Houston, Houston, Texas United States 77004 (e-mail: hanzhu22@gmail.com)","IEEE Transactions on Network Science and Engineering","","2018","PP","99","1","1","Social networks have continuously been expanding and trying to be innovative. The recent advances of computing, caching, and communication (3C) can have significant impacts on mobile social networks (MSNs). MSNs can leverage these new paradigms to provide a new mechanism for users to share resources (e.g., information, computation-based services). In this paper, we exploit the intrinsic nature of social networks, i.e., the trust formed through social relationships among users, to enable users to share resources under the framework of 3C. Specifically, we consider the mobile edge computing (MEC), in-network caching and device to-device (D2D) communications. When considering the trust-based MSNs with MEC, caching and D2D, we apply a novel deep reinforcement learning approach to automatically make a decision for optimally allocating the network resources. The decision is made purely through observing the network's states, rather than any handcrafted or explicit control rules, which makes it adaptive to variable network conditions. Google TensorFlow is used to implement the proposed deep reinforcement learning approach. Simulation results with different network parameters are presented to show the effectiveness of the proposed scheme.","","","10.1109/TNSE.2018.2865183","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8434316","Mobile social networks;mobile edge computing;caching;deep reinforcement learning","Device-to-device communication;Resource management;Computational modeling;Wireless communication;Optimization;Social network services;Machine learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Regression Segmentation for Cardiac Bi-Ventricle MR Images","X. Du; W. Zhang; H. Zhang; J. Chen; Y. Zhang; J. Claude Warrington; G. Brahm; S. Li","School of Computer Science and Technology, Anhui University, Hefei, China; School of Computer Science and Technology, Anhui University, Hefei, China; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; School of Computer Science and Technology, Anhui University, Hefei, China; School of Computer Science and Technology, Anhui University, Hefei, China; Department of Medical Imaging, Western University, London, ON, Canada; Department of Medical Imaging, Western University, London, ON, Canada; Department of Medical Imaging, Western University, London, ON, Canada","IEEE Access","","2018","6","","3828","3838","Cardiac bi-ventricle segmentation can help physicians to obtain clinical indices, such as mass and volume of left ventricle (LV) and right ventricle (RV). In this paper, we propose a regression segmentation framework to delineate boundaries of bi-ventricle from cardiac magnetic resonance (MR) images by building a regression model automatically and accurately. First, we extract DAISY feature from images. Then, a point based representation method is employed to depict the boundaries. Finally, we use DAISY as input and boundary points as labels to train the regression model based on deep belief network. Regression combined deep learning and DAISY feature can capture high level image information and accurately segment biventricle with fewer assumptions and lower computational cost. In our experiment, the performance of the proposed framework is compared with manual segmentation on 145 clinical subjects (2900 images in total), which are collected from three hospitals affiliated with two health care centers (London Healthcare Center and St. Josephs HealthCare). The results of our method and manually segmented method are highly consistent. High Pearson's correlation coefficient between automated boundaries and manual annotation is up to 0.995 (endocardium of LV), 0.997 (epicardium of LV), and 0.985 (RV). Average Dice metric is up to 0.916 (endocardium of LV), 0.941 (epicardium of LV), and 0.844 (RV). Altogether, experimental results are capable of demonstrating the efficacy of our regression segmentation framework for cardiac MR images.","","","10.1109/ACCESS.2017.2789179","National Science Foundation of China; Provincial Natural Science Research Program of Higher Education Institutions of Anhui province; Anhui Provincial Natural Science Foundation; National High Technology Research and Development Program (863 Program); Shenzhen Innovation funding; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8245780","Bi-ventricle segmentation;regression;DAISY;deep belief network","Image segmentation;Shape;Feature extraction;Computational modeling;Training;Medical services;Manuals","belief networks;biomedical MRI;cardiology;feature extraction;health care;image segmentation;learning (artificial intelligence);medical image processing;regression analysis","deep regression segmentation;cardiac bi-ventricle segmentation;clinical indices;right ventricle;RV;regression segmentation framework;cardiac magnetic resonance images;point based representation method;boundary points;deep belief network;regression combined deep learning;high level image information;manually segmented method;automated boundaries;cardiac bi-ventricle MR images;left ventricle;DAISY feature extraction;health care centers;Pearson correlation coefficient;average dice metric","","7","32","","","","","IEEE","IEEE Journals"
"Gait-Based Human Identification by Combining Shallow Convolutional Neural Network-Stacked Long Short-Term Memory and Deep Convolutional Neural Network","G. Batchuluun; H. S. Yoon; J. K. Kang; K. R. Park","Division of Electronics and Electrical Engineering, Dongguk University, Seoul, South Korea; Division of Electronics and Electrical Engineering, Dongguk University, Seoul, South Korea; Division of Electronics and Electrical Engineering, Dongguk University, Seoul, South Korea; Division of Electronics and Electrical Engineering, Dongguk University, Seoul, South Korea","IEEE Access","","2018","6","","63164","63186","Human identification using camera-based surveillance systems is a challenging research topic, especially in cases where the human face is not visible to cameras and/or when humans captured on cameras have no clear visual identity owing to environments with low-illumination. With the development of deep learning algorithms, studies that are based on the human gait using convolutional neural networks (CNNs) and long short-term memory (LSTM) have achieved promising performance for human identification. However, CNN and LSTM-based methods have the limitation of having higher loss of temporal and spatial information, respectively. In our approach, we use shallow CNN stacked with LSTM and deep CNN followed by score fusion to capture more spatial and temporal features. In addition, there have been a few studies regarding gait-based human identification based on the front and back view images of humans captured in low-illumination environments. This makes it difficult to extract conventional features, such as skeleton joints, cycle, cadence, and the lengths of walking strides. To overcome these problems, we designed our method considering the front and back view images captured in both highand lowillumination environments. The experimental results obtained using a self-collected database and the open database of the institute of automation Chinese academy of sciences gait dataset C show that the proposed method outperforms previous methods.","","","10.1109/ACCESS.2018.2876890","National Research Foundation of Korea; National Research Foundation of Korea; National Research Foundation of Korea; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8502031","Human identification;shallow CNN stacked LSTM;deep CNN;thermal image","Cameras;Feature extraction;Gait recognition;Wearable sensors;Lighting;Training;Object recognition","cameras;convolutional neural nets;feature extraction;gait analysis;image classification;learning (artificial intelligence);object detection;recurrent neural nets","deep learning algorithms;LSTM-based methods;shallow CNN;deep CNN;gait-based human identification;low-illumination environments;deep convolutional neural network;camera-based surveillance systems;human face;visual identity;shallow convolutional neural network-stacked long short-term memory;Chinese academy of sciences gait dataset","","3","62","","","","","IEEE","IEEE Journals"
"Deep Learning for RF Device Fingerprinting in Cognitive Communication Networks","K. Merchant; S. Revay; G. Stantchev; B. Nousain","US Naval Research Laboratory, Washington, DC, USA; US Naval Research Laboratory, Washington, DC, USA; US Naval Research Laboratory, Washington, DC, USA; US Naval Research Laboratory, Washington, DC, USA","IEEE Journal of Selected Topics in Signal Processing","","2018","12","1","160","167","With the increasing presence of cognitive radio networks as a means to address limited spectral resources, improved wireless security has become a necessity. In particular, the potential of a node to impersonate a licensed user demonstrates the need for techniques to authenticate a radio's true identity. In this paper, we use deep learning to detect physical-layer attributes for the identification of cognitive radio devices, and demonstrate the performance of our method on a set of IEEE 802.15.4 devices. Our method is based on the empirical principle that manufacturing variability among wireless transmitters that conform to the same standard creates unique, repeatable signatures in each transmission, which can then be used as a fingerprint for device identification and verification. We develop a framework for training a convolutional neural network using the time-domain complex baseband error signal and demonstrate 92.29% identification accuracy on a set of seven 2.4 GHz commercial ZigBee devices. We also demonstrate the robustness of our method over a wide range of signal-to-noise ratios.","","","10.1109/JSTSP.2018.2796446","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8265093","Communication system security;neural networks;ZigBee;cognitive radio;personal area networks;radio communication;pattern recognition;classification algorithms","ZigBee;Radio frequency;IEEE 802.15 Standard;Performance evaluation;Wireless communication;Machine learning","cognitive radio;feedforward neural nets;learning (artificial intelligence);radio networks;radio transmitters;telecommunication computing;telecommunication security;Zigbee","licensed user;deep learning;physical-layer attributes;cognitive radio devices;empirical principle;manufacturing variability;wireless transmitters;repeatable signatures;fingerprint;device identification;convolutional neural network;time-domain complex baseband error signal;RF device fingerprinting;cognitive communication networks;cognitive radio networks;improved wireless security;limited spectral resources;IEEE 802.15.4 devices;device verification;commercial ZigBee devices;frequency 2.4 GHz","","28","35","","","","","IEEE","IEEE Journals"
"Feature Regularization and Deep Learning for Human Resource Recommendation","H. Wang; G. Liang; X. Zhang","School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; School of Computer Science and Engineering, South China University of Technology, Guangzhou, China","IEEE Access","","2018","6","","39415","39421","A novel recommender system is proposed in this paper. It has been implemented for human resource recommendation and achieved improvement on different evaluation metrics. The algorithm leverages both gradient boosting tree model and a convolutional network-based deep learning model for feature regularization and recommendation. The optimizations of activation function and pooling strategy in the proposed network model have been investigated for mitigating the problems of the gradient disappearance and the feature loss in pooling and for the improvement of recommendation quality. Human resource datasets are fetched by using a cloud-based distributed data collecting framework. Using the datasets, experiments on the proposed recommender system have been done and analyzed. Our proposed algorithm shows better recall rate and F1-score than some other recommender algorithms.","","","10.1109/ACCESS.2018.2854887","Guangdong Science and Technology Department; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409932","Recommender systems;decision trees;artificial neural networks;cloud computing","Convolution;Recommender systems;Feature extraction;Data models;Optimization;Kernel;Machine learning","cloud computing;convolution;feature extraction;feedforward neural nets;human resource management;learning (artificial intelligence);recommender systems;trees (mathematics)","human resource recommendation;gradient boosting tree model;convolutional network-based deep learning model;feature regularization;cloud-based distributed data collecting framework;recommender system;human resource datasets;activation function;pooling strategy","","","18","","","","","IEEE","IEEE Journals"
"Deep D-Bar: Real-Time Electrical Impedance Tomography Imaging With Deep Neural Networks","S. J. Hamilton; A. Hauptmann","Department of Mathematics, Statistics, and Computer Science, Marquette University, Milwaukee, WI, USA; Department of Computer Science, University College London, London, U.K.","IEEE Transactions on Medical Imaging","","2018","37","10","2367","2377","The mathematical problem for electrical impedance tomography (EIT) is a highly nonlinear ill-posed inverse problem requiring carefully designed reconstruction procedures to ensure reliable image generation. D-bar methods are based on a rigorous mathematical analysis and provide robust direct reconstructions by using a low-pass filtering of the associated nonlinear Fourier data. Similarly to low-pass filtering of linear Fourier data, only using low frequencies in the image recovery process results in blurred images lacking sharp features, such as clear organ boundaries. Convolutional neural networks provide a powerful framework for post-processing such convolved direct reconstructions. In this paper, we demonstrate that these CNN techniques lead to sharp and reliable reconstructions even for the highly nonlinear inverse problem of EIT. The network is trained on data sets of simulated examples and then applied to experimental data without the need to perform an additional transfer training. Results for absolute EIT images are presented using experimental EIT data from the ACT4 and KIT4 EIT systems.","","","10.1109/TMI.2018.2828303","Engineering and Physical Sciences Research Council; Engineering and Physical Sciences Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8352045","Electrical impedance tomography;D-bar methods;deep learning;conductivity imaging","Tomography;Image reconstruction;Conductivity;Real-time systems;Impedance;Robustness;Current measurement","electric impedance imaging;feedforward neural nets;image reconstruction;inverse problems;low-pass filters;mathematical analysis;medical image processing","associated nonlinear Fourier data;linear Fourier data;low frequencies;image recovery process results;blurred images;sharp features;clear organ boundaries;convolutional neural networks;post-processing such convolved direct reconstructions;sharp reconstructions;reliable reconstructions;highly nonlinear inverse problem;absolute EIT images;experimental EIT data;KIT4 EIT systems;deep d-bar;CNN techniques;low-pass filtering;robust direct reconstructions;rigorous mathematical analysis;d-bar methods;reliable image generation;carefully designed reconstruction procedures;mathematical problem;deep neural networks;real-time electrical impedance tomography","","8","41","CCBY","","","","IEEE","IEEE Journals"
"A Deep Learning-Based Data Minimization Algorithm for Fast and Secure Transfer of Big Genomic Datasets","M. Aledhari; M. Di Pierro; M. Hefeida; F. Saeed","Computer Science, Western Michigan University, 4175 Kalamazoo, Michigan United States (e-mail: mohammed.a.aledhari@gmail.com); Graduate Research and Retention, Western Michigan University, 4175 Kalamazoo, Michigan United States (e-mail: marianne.dipierro@wmich.edu); Electrical and Computer Engineering, University of Idaho, Moscow, Idaho United States (e-mail: hefeida@uidaho.edu); Western Michigan University, Kalamazoo, Michigan United States (e-mail: fahad.saeed@wmich.edu)","IEEE Transactions on Big Data","","2018","PP","99","1","1","In the age of Big Genomics Data, institutions such as the National Human Genome Research Institute (NHGRI) are challenged in their efforts to share volumes of data between researchers, a process that has been plagued by unreliable transfers and slow speeds. These occur due to throughput bottlenecks of traditional transfer technologies. Two factors that affect the effciency of data transmission are the channel bandwidth and the amount of data. Increasing the bandwidth is one way to transmit data effciently, but might not always be possible due to resource limitations. Another way to maximize channel utilization is by decreasing the bits needed for transmission of a dataset. Traditionally, transmission of big genomic data between two geographical locations is done using general-purpose protocols, such as hypertext transfer protocol (HTTP) and file transfer protocol (FTP) secure. In this paper, we present a novel deep learning-based data minimization algorithm that 1) minimizes the datasets during transfer over the carrier channels; 2) protects the data from the man-in-the-middle (MITM) and other attacks by changing the binary representation (content-encoding) several times for the same dataset: we assign different codewords to the same character in different parts of the dataset. Our data minimization strategy exploits the alphabet limitation of DNA sequences and modifies the binary representation (codeword) of dataset characters using deep learning-based convolutional neural network (CNN) to ensure a minimum of code word uses to the high frequency characters at different time slots during the transfer time. This algorithm ensures transmission of big genomic DNA datasets with minimal bits and latency and yields an effcient and expedient process. Our tested heuristic model, simulation, and real implementation results indicate that the proposed data minimization algorithm is up to 99 times faster and more secure than the currently used content-encoding scheme used in HTTP of the HTTP content-encoding scheme and 96 times faster than FTP on tested datasets. The developed protocol in C# will be available to the wider genomics community and domain scientists.","","","10.1109/TBDATA.2018.2805687","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8290833","Machine Learning;Deep Learning;Convolutional Neural Networks;DNA;Big Genomic Data;Big Data;Content-Encoding;Transfer Protocols;HTTP;Wireless Communication;Variable-Length Binary Encoding","Genomics;Bioinformatics;Big Data;Protocols;Minimization;Sequential analysis;DNA","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Urban Traffic Density Estimation Based on Ultrahigh-Resolution UAV Video and Deep Neural Network","J. Zhu; K. Sun; S. Jia; Q. Li; X. Hou; W. Lin; B. Liu; G. Qiu","Shenzhen Key Laboratory of Spatial Information Smarting Sensing and Services, Shenzhen University, Shenzhen, China; Shenzhen Key Laboratory of Spatial Information Smarting Sensing and Services, Shenzhen University, Shenzhen, China; Computer Vision Research Institute, College of Computer Science and Software Engineering, Shenzhen Key Laboratory of Spatial Information Smarting Sensing and Services, Shenzhen University, Shenzhen, China; Shenzhen Key Laboratory of Spatial Information Smarting Sensing and Services, Shenzhen University, Shenzhen, China; Guangdong Key Laboratory of Intelligent Information Processing, College of Information Engineering, Shenzhen University, Shenzhen, China; Shenzhen Key Laboratory of Spatial Information Smarting Sensing and Services, Shenzhen University, Shenzhen, China; Guangdong Key Laboratory of Intelligent Information Processing, College of Information Engineering, Shenzhen University, Shenzhen, China; Guangdong Key Laboratory of Intelligent Information Processing, College of Information Engineering, Shenzhen University, Shenzhen, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2018","11","12","4968","4981","This paper presents an advanced urban traffic density estimation solution using the latest deep learning techniques to intelligently process ultrahigh-resolution traffic videos taken from an unmanned aerial vehicle (UAV). We first capture nearly an hour-long ultrahigh-resolution traffic video at five busy road intersections of a modern megacity by flying a UAV during the rush hours. We then randomly sampled over 17 K 512×512 pixel image patches from the video frames and manually annotated over 64 K vehicles to form a dataset for this paper, which will also be made available to the research community for research purposes. Our innovative urban traffics analysis solution consists of an advanced deep neural network (DNN) based vehicle detection and localization, type (car, bus, and truck) recognition, tracking, and vehicle counting over time. We will present extensive experimental results to demonstrate the effectiveness of our solution. We will show that our enhanced single shot multibox detector (Enhanced-SSD) outperforms other DNN-based techniques and that deep learning techniques are more effective than traditional computer vision techniques in traffic video analysis. We will also show that ultrahigh-resolution video provides more information that enables more accurate vehicle detection and recognition than lower resolution contents. This paper not only demonstrates the advantages of using the latest technological advancements (ultrahigh-resolution video and UAV), but also provides an advanced DNN-based solution for exploiting these technological advancements for urban traffic density estimation.","","","10.1109/JSTARS.2018.2879368","National Natural Science Foundation of China; Shenzhen Future Industry Development Funding; Shenzhen Scientific Research and Development Funding; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8536405","Deep neural networks (DNNs);road traffic monitoring;traffic density estimation;unmanned aerial vehicle (UAV);vehicle counting;vehicle detection;vehicle tracking","Neural networks;Traffic control;Unmanned aerial vehicles;Vehicle detection;Urban areas;Road traffic","autonomous aerial vehicles;estimation theory;image resolution;learning (artificial intelligence);mobile robots;neural nets;object detection;road traffic;road vehicles;robot vision;traffic engineering computing;video signal processing","enhanced single shot multibox detector;traffic video analysis;ultrahigh-resolution UAV video;deep neural network;unmanned aerial vehicle;vehicle detection;deep learning techniques;DNN-based solution;urban traffic density estimation;ultrahigh-resolution traffic videos","","1","63","","","","","IEEE","IEEE Journals"
"CCL: Cross-modal Correlation Learning With Multigrained Fusion by Hierarchical Network","Y. Peng; J. Qi; X. Huang; Y. Yuan","Institute of Computer Science and Technology, Peking University, Beijing, China; Institute of Computer Science and Technology, Peking University, Beijing, China; Institute of Computer Science and Technology, Peking University, Beijing, China; Institute of Computer Science and Technology, Peking University, Beijing, China","IEEE Transactions on Multimedia","","2018","20","2","405","420","Cross-modal retrieval has become a highlighted research topic for retrieval across multimedia data such as image and text. A two-stage learning framework is widely adopted by most existing methods based on deep neural network (DNN): The first learning stage is to generate separate representation for each modality and the second learning stage is to get the cross-modal common representation. However the existing methods have three limitations: 1) In the first learning stage they only model intramodality correlation but ignore intermodality correlation with rich complementary context. 2) In the second learning stage they only adopt shallow networks with single-loss regularization but ignore the intrinsic relevance of intramodality and intermodality correlation. 3) Only original instances are considered while the complementary fine-grained clues provided by their patches are ignored. For addressing the above problems this paper proposes a cross-modal correlation learning (CCL) approach with multigrained fusion by hierarchical network and the contributions are as follows: 1) In the first learning stage CCL exploits multilevel association with joint optimization to preserve the complementary context from intramodality and intermodality correlation simultaneously. 2) In the second learning stage a multitask learning strategy is designed to adaptively balance the intramodality semantic category constraints and intermodality pairwise similarity constraints. 3) CCL adopts multigrained modeling which fuses the coarse-grained instances and fine-grained patches to make cross-modal correlation more precise. Comparing with 13 state-of-the-art methods on 6 widely-used cross-modal datasets the experimental results show our CCL approach achieves the best performance.","","","10.1109/TMM.2017.2742704","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8013822","Cross-modal retrieval;fine-grained correlation;joint optimization;multi-task learning","Correlation;Multimedia communication;Semantics;Streaming media;Optimization;Boats;Birds","information retrieval;learning (artificial intelligence);multimedia computing;neural nets","multigrained fusion;hierarchical network;cross-modal retrieval;two-stage learning framework;cross-modal common representation;intermodality correlation;learning stage CCL;multitask learning strategy;cross-modal correlation learning;multimedia data;deep neural network;intramodality correlation;intramodality semantic category constraints;intermodality pairwise similarity constraints","","13","48","","","","","IEEE","IEEE Journals"
"OCEAN: An On-Chip Incremental-Learning Enhanced Artificial Neural Network Processor With Multiple Gated-Recurrent-Unit Accelerators","C. Chen; H. Ding; H. Peng; H. Zhu; Y. Wang; C. -. R. Shi","Institute of Brain-Inspired Circuits and Systems, Fudan University, Shanghai, china; Institute of Brain-Inspired Circuits and Systems, Fudan University, Shanghai, china; Institute of Brain-Inspired Circuits and Systems, Fudan University, Shanghai, china; Institute of Brain-Inspired Circuits and Systems, Fudan University, Shanghai, china; Institute of Brain-Inspired Circuits and Systems, Fudan University, Shanghai, china; Institute of Brain-Inspired Circuits and Systems, Fudan University, Shanghai, china","IEEE Journal on Emerging and Selected Topics in Circuits and Systems","","2018","8","3","519","530","This paper presents OCEAN: an artificial neural network processor designed for accelerating gated-recurrent-unit (GRU) inference and on-chip incremental learning for sequential modeling. Implemented in 65-nm CMOS with silicon area of 2.9 × 3.5 mm2, the OCEAN processor features a 32-bit reduced instruction set computing core, 64-KB on-chip SRAM, and eight 16-bit four-cell GRU accelerators for inference and gradient computation. Each GRU accelerator is optimized and enhanced for efficient gradient computation. The processor is measured to consume 155 mW at the peak clock rate of 400 MHz and the supply of 1.2 V or 6.6 mW at 20 MHz/0.8 V. Both inference and on-chip incremental learning are accomplished on well-known AI tasks such as handwritten digit recognition, semantic natural language processing, and biomedical waveform-based seizure detection.","","","10.1109/JETCAS.2018.2852780","Shanghai Science and Technology Innovative Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8403217","Recurrent neural network (RNN);gated recurrent unit (GRU);inference;on-chip training;deep learning processor;energy-efficient accelerator;gradient computing","Training;System-on-chip;Oceans;Logic gates;Recurrent neural networks;Machine learning","circuit optimisation;CMOS memory circuits;gradient methods;integrated circuit design;learning (artificial intelligence);neural chips;reduced instruction set computing;SRAM chips","sequential modeling;silicon area;OCEAN processor features;on-chip SRAM;efficient gradient computation;on-chip incremental learning;gated-recurrent-unit inference;CMOS;on-chip incremental-learning enhanced artificial neural network processor;multiple gated-recurrent-unit accelerators;reduced instruction set computing core;four-cell GRU accelerators;enhanced artificial neural network processor design;peak clock rate;accelerating gated-recurrent-unit inference;power 155.0 mW;frequency 400.0 MHz;voltage 1.2 V;power 6.6 mW;frequency 20.0 MHz;voltage 0.8 V;word length 32 bit;word length 16 bit;storage capacity 64 Kbit;size 65 nm;Si","","1","32","","","","","IEEE","IEEE Journals"
"MicronNet: A Highly Compact Deep Convolutional Neural Network Architecture for Real-Time Embedded Traffic Sign Classification","A. Wong; M. J. Shafiee; M. St. Jules","Department of Systems Design Engineering, University of Waterloo, Waterloo, ON, Canada; Department of Systems Design Engineering, University of Waterloo, Waterloo, ON, Canada; DarwinAI Corp., Waterloo, ON, Canada","IEEE Access","","2018","6","","59803","59810","Traffic sign recognition is a very important computer vision task for a number of real-world applications such as intelligent transportation surveillance and analysis. While deep neural networks have been demonstrated in recent years to provide the state-of-the-art performance traffic sign recognition, a key challenge for enabling the widespread deployment of deep neural networks for embedded traffic sign recognition is the high computational and memory requirements of such networks. As a consequence, there are significant benefits in investigating compact deep neural network architectures for traffic sign recognition that are better suited for embedded devices. In this paper, we introduce MicronNet, a highly compact deep convolutional neural network for real-time embedded traffic sign recognition designed based on macroarchitecture design principles (e.g., spectral macroarchitecture augmentation, parameter precision optimization, etc.) as well as numerical microarchitecture optimization strategies. The resulting overall architecture of MicronNet is thus designed with as few parameters and computations as possible while maintaining recognition performance, leading to optimized information density of the proposed network. The resulting MicronNet possesses a model size of just 1 MB and 5 10000 parameters ( 27× fewer parameters than state-of-the-art) while still achieving a human performance level top-1 accuracy of 98.9% on the German traffic sign recognition benchmark. Furthermore, the MicronNet requires just 10 million multiply-accumulate operations to perform inference, and has a time-to-compute of just 32.19 ms on a Cortex-A53 high efficiency processor. These experimental results show that the highly compact, optimized deep neural network architectures can be designed for real-time traffic sign recognition that are well-suited for embedded scenarios.","","","10.1109/ACCESS.2018.2873948","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8481688","Deep neural network;traffic sign classification;real-time;embedded","Microarchitecture;Optimization;Real-time systems;Network architecture;Computer architecture;Convolutional neural networks","computer vision;driver information systems;feature extraction;image classification;image colour analysis;image recognition;learning (artificial intelligence);neural nets;object detection;object recognition;traffic engineering computing","MicronNet possesses;embedded scenarios;real-time traffic sign recognition;optimized deep neural network architectures;highly compact network architectures;Cortex-A53 high efficiency processor;time-to-compute;German traffic sign recognition benchmark;human performance level top-1 accuracy;recognition performance;resulting overall architecture;highly compact deep convolutional neural network architecture;traffic sign classification;important computer vision task;intelligent transportation surveillance;deep neural networks;state-of-the-art performance traffic sign recognition;high computational memory requirements;compact deep neural network architectures;embedded devices;real-time embedded traffic sign recognition;macroarchitecture design principles;parameter precision optimization","","3","26","","","","","IEEE","IEEE Journals"
"Inference Over Distribution of Posterior Class Probabilities for Reliable Bayesian Classification and Object-Level Perception","V. Tchuiev; V. Indelman","Department of Aerospace Engineering, Technion - Israel Institute of Technology, Haifa, Israel; Department of Aerospace Engineering, Technion - Israel Institute of Technology, Haifa, Israel","IEEE Robotics and Automation Letters","","2018","3","4","4329","4336","State of the art Bayesian classification approaches typically maintain a posterior distribution over possible classes given available sensor observations (images). Yet, while these approaches fuse all classifier outputs thus far, they do not provide any indication regarding how reliable the posterior classification is, thus limiting its functionality in terms of autonomous systems and robotics. On the other hand, current deep learning based classifiers provide an uncertainty measure, thereby quantifying model uncertainty. However, they do so on a single frame basis and do not consider a sequential framework. In this letter, we develop a novel approach that infers a distribution over posterior class probabilities, while accounting for model uncertainty. This distribution enables reasoning about uncertainty in the posterior classification and, therefore, is of prime importance for robust classification, object-level perception in uncertain and ambiguous scenarios, and for safe autonomy in general. The distribution of the posterior class probability has no known analytical solution; thus, we propose to approximate this distribution via sampling. We evaluate our approach in simulation and using real images fed into a convolutional neural network classifier.","","","10.1109/LRA.2018.2852844","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8403264","Deep learning in robotics and automation;recognition","Uncertainty;Algorithm design and analysis;Deep learning;Reliability;Bayes methods;Random variables;Inference mechanisms","Bayes methods;belief networks;feedforward neural nets;image classification;inference mechanisms;learning (artificial intelligence);neural nets;statistical distributions","Bayesian classification;deep learning based classifiers;convolutional neural network classifier;robust classification;uncertainty measure;posterior classification;posterior distribution;posterior class probability;object-level perception","","","17","","","","","IEEE","IEEE Journals"
"Learning to Play Othello With Deep Neural Networks","P. Liskowski; W. Jaśkowski; K. Krawiec","Institute of Computing Science, Poznań University of Technology, Poznań, Poland; IDSIA Dalle Molle Institute for Artificial Intelligence Research, Manno, CH, Switzerland; Institute of Computing Science, Poznań University of Technology, Poznań, Poland","IEEE Transactions on Games","","2018","10","4","354","364","Achieving a superhuman playing level by AlphaGo corroborated the capabilities of convolutional neural network (CNN) architectures for capturing complex spatial patterns. This result was, to a great extent, due to several analogies between Go board states and 2-D images that CNNs have been designed for, in particular, translational invariance and a relatively large board. In this paper, we verify whether CNN-based move predictors prove effective for Othello, a game with significantly different characteristics, including a much smaller board size and complete lack of translational invariance. We compare several CNN architectures and board encodings, augment them with state-of-the-art extensions, train on an extensive database of experts' moves, and examine them with respect to move prediction accuracy and playing strength. The empirical evaluation confirms high capabilities of neural move predictors and suggests a strong correlation between prediction accuracy and playing strength. The best CNNs not only surpass all other 1-ply Othello players proposed to date but defeat (2 ply) Edax, the best open-source Othello player.","","","10.1109/TG.2018.2799997","Narodowym Centrum Nauki; Ministry of Science and Higher Education; National Science Centre; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8276588","Convolutional neural networks (CNNs);deep learning; ${Othello}$ ","Games;Neural networks;Training;Law;Task analysis;Encoding","computer games;convolution;feedforward neural nets;learning (artificial intelligence);neural net architecture","Go board states;translational invariance;CNN-based move predictors;CNN architectures;board encodings;neural move predictors;open-source Othello player;deep neural networks;superhuman playing level;AlphaGo;convolutional neural network architectures;2-D images;spatial patterns","","1","43","","","","","IEEE","IEEE Journals"
"Learning Deep Spatio-Temporal Dependence for Semantic Video Segmentation","Z. Qiu; T. Yao; T. Mei","University of Science and Technology of China, Hefei, China; Microsoft Research Asia, Beijing, China; University of Science and Technology of China, Hefei, China","IEEE Transactions on Multimedia","","2018","20","4","939","949","Semantically labeling every pixel in a video is a very challenging task as video is an information-intensive media with complex spatio-temporal dependence. We present in this paper a novel deep convolutional network architecture, called deep spatio-temporal fully convolutional networks (DST-FCN), which leverages both spatial and temporal dependencies among pixels and voxels by training them in an end-to-end manner. Specifically, we introduce a two-stream network by learning the deep spatio-temporal dependence, in which a 2D FCN followed by the convolutional long short-term memory (ConvLSTM) is employed on the pixel level and a 3-D FCN is exploited on the voxel level. Our model differs from conventional FCN in that it not only extends FCN by adding ConvLSTM on the pixel level for exploring long-term dependence, but also proposes 3-D FCN to enable voxel level prediction. On two benchmarks of A2D and CamVid, our DST-FCN achieves superior results to state-of-the-art techniques. More remarkably, we obtain to-date the best reported results: 45.0% per-label accuracy on A2D and 68.8% mean IoU on CamVid.","","","10.1109/TMM.2017.2759504","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8059880","Semantic segmentation;fully convolutional networks;long-short term memory;video segmentation","Semantics;Two dimensional displays;Image segmentation;Three-dimensional displays;Streaming media;Computer architecture","convolution;feature extraction;feedforward neural nets;image classification;image segmentation;learning (artificial intelligence);video signal processing","deep convolutional network architecture;deep spatio-temporal fully convolutional networks;convolutional long short-term memory;ConvLSTM;complex spatio-temporal dependence;semantic video segmentation;voxel level prediction;long-term dependence;conventional FCN;3-D FCN;pixel level;deep spatio-temporal dependence;voxels;pixels;temporal dependencies;spatial dependencies;DST-FCN","","12","42","","","","","IEEE","IEEE Journals"
"Channel Charting: Locating Users Within the Radio Environment Using Channel State Information","C. Studer; S. Medjkouh; E. Gönültaş; T. Goldstein; O. Tirkkonen","School of Electrical and Computer Engineering, Cornell University, Ithaca, NY, USA; School of Electrical and Computer Engineering, Cornell University, Ithaca, NY, USA; School of Electrical and Computer Engineering, Cornell University, Ithaca, NY, USA; Department of Computer Science, University of Maryland at College Park, College Park, MD, USA; School of Electrical Engineering, Aalto University, Espoo, Finland","IEEE Access","","2018","6","","47682","47698","We propose channel charting (CC), a novel framework in which a multi-antenna network element learns a chart of the radio geometry in its surrounding area. The channel chart captures the local spatial geometry of the area so that points that are close in space will also be close in the channel chart and vice versa. CC works in a fully unsupervised manner, i.e., learning is only based on channel state information (CSI) that is passively collected at a single point in space, but from multiple transmit locations in the area over time. The method then extracts channel features that characterize large-scale fading properties of the wireless channel. Finally, the channel charts are generated with tools from dimensionality reduction, manifold learning, and deep neural networks. The network element performing CC may be, for example, a multi-antenna base-station in a cellular system and the charted area in the served cell. Logical relationships related to the position and movement of a transmitter, e.g., a user equipment (UE), in the cell, can then be directly deduced from comparing measured radio channel characteristics to the channel chart. The unsupervised nature of CC enables a range of new applications in UE localization, network planning, user scheduling, multipoint connectivity, hand-over, cell search, user grouping, and other cognitive tasks that rely on CSI and UE movement relative to the base station, without the need of information from global navigation satellite systems.","","","10.1109/ACCESS.2018.2866979","Xilinx Inc.; National Science Foundation; Xilinx Inc.; U.S. NSF; Ministry of National Education of the Republic of Turkey; Defense Advanced Research Projects Agency; Sloan Foundation; Kaute Foundation; Nokia Foundation; Academy of Finland; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8444621","Autoencoders;deep learning;dimensionality reduction;localization;machine learning;manifold learning massive multiple-input multiple-output (MIMO);Sammon’s mapping","Geometry;Manifolds;Transmitters;Feature extraction;Wireless communication;Dimensionality reduction;Global navigation satellite system","antenna arrays;cellular radio;fading channels;feature extraction;neural nets;radionavigation;unsupervised learning","channel charting;channel state information;wireless channel;unsupervised learning;cell search;hand-over;multipoint connectivity;user scheduling;network planning;user equipment localization;cellular system;multiantenna base-station;deep neural networks;manifold learning;dimensionality reduction;large-scale fading properties;feature extraction;radio geometry;multiantenna network element;user location;radio channel characteristics","","8","59","CCBY","","","","IEEE","IEEE Journals"
"Fast Deep Neural Networks With Knowledge Guided Training and Predicted Regions of Interests for Real-Time Video Object Detection","W. Cao; J. Yuan; Z. He; Z. Zhang; Z. He","Shenzhen Key Laboratory of Media Security, Shenzhen University, Shenzhen, China; Shenzhen Key Laboratory of Media Security, Shenzhen University, Shenzhen, China; Department of Electrical and Computer Engineering, Video Processing and Communication Lab, University of Missouri, Columbia, MO, USA; Department of Electrical and Computer Engineering, Video Processing and Communication Lab, University of Missouri, Columbia, MO, USA; Shenzhen Key Laboratory of Media Security, Shenzhen University, Shenzhen, China","IEEE Access","","2018","6","","8990","8999","It has been recognized that deeper and wider neural networks are continuously advancing the state-of-the-art performance of various computer vision and machine learning tasks. However, they often require large sets of labeled data for effective training and suffer from extremely high computational complexity, preventing them from being deployed in real-time systems, for example vehicle object detection from vehicle cameras for assisted driving. In this paper, we aim to develop a fast deep neural network for real-time video object detection by exploring the ideas of knowledge-guided training and predicted regions of interest. Specifically, we will develop a new framework for training deep neural networks on datasets with limited labeled samples using cross-network knowledge projection which is able to improve the network performance while reducing the overall computational complexity significantly. A large pre-trained teacher network is used to observe samples from the training data. A projection matrix is learned to project this teacher-level knowledge and its visual representations from an intermediate layer of the teacher network to an intermediate layer of a thinner and faster student network to guide and regulate the training process. To further speed up the network, we propose to train a low-complexity object detection using traditional machine learning methods, such as support vector machine. Using this low-complexity object detector, we identify the regions of interest that contain the target objects with high confidence. We obtain a mathematical formula to estimate the regions of interest to save the computation for each convolution layer. Our experimental results on vehicle detection from videos demonstrated that the proposed method is able to speed up the network by up to 16 times while maintaining the object detection performance.","","","10.1109/ACCESS.2018.2795798","National Natural Science Foundation of China; National Science Foundation through US Ignite and through CyberSEES; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8268087","Assisted driving;deep neural networks;knowledge projection;speed optimization;vehicle detection","Training;Neural networks;Object detection;Knowledge engineering;Real-time systems;Computational complexity;Vehicle detection","computational complexity;computer vision;convolution;learning (artificial intelligence);neural nets;object detection;prediction theory;support vector machines;video signal processing","fast deep neural network;knowledge guided training;real-time video object detection;deeper networks;computer vision;machine learning tasks;real-time systems;cross-network knowledge projection;network performance;teacher-level knowledge;training process;low-complexity object detection;low-complexity object detector;mathematical formula;support vector machine;convolution layer;projection matrix;vehicle object detection;neural networks;student network;deep neural network training;computational complexity;object detection performance;vehicle detection","","13","65","","","","","IEEE","IEEE Journals"
"Articulated Multi-Instrument 2-D Pose Estimation Using Fully Convolutional Networks","X. Du; T. Kurmann; P. Chang; M. Allan; S. Ourselin; R. Sznitman; J. D. Kelly; D. Stoyanov","Centre for Medical Image Computing, University College London, London, U.K.; ARTORG Center for Biomedical Engineering Research, University of Bern, Bern, Switzerland; Umbo Computer Vision Inc., San Francisco, CA, USA; Centre for Medical Image Computing, University College London, London, U.K.; Centre for Medical Image Computing, University College London, London, U.K.; ARTORG Center for Biomedical Engineering Research, University of Bern, Bern, Switzerland; Division of Surgery and Interventional Science, University College London, London, U.K.; Centre for Medical Image Computing, University College London, London, U.K.","IEEE Transactions on Medical Imaging","","2018","37","5","1276","1287","Instrument detection, pose estimation, and tracking in surgical videos are an important vision component for computer-assisted interventions. While significant advances have been made in recent years, articulation detection is still a major challenge. In this paper, we propose a deep neural network for articulated multi-instrument 2-D pose estimation, which is trained on detailed annotations of endoscopic and microscopic data sets. Our model is formed by a fully convolutional detection-regression network. Joints and associations between joint pairs in our instrument model are located by the detection subnetwork and are subsequently refined through a regression subnetwork. Based on the output from the model, the poses of the instruments are inferred using maximum bipartite graph matching. Our estimation framework is powered by deep learning techniques without any direct kinematic information from a robot. Our framework is tested on single-instrument RMIT data, and also on multi-instrument EndoVis and in vivo data with promising results. In addition, the data set annotations are publicly released along with our code and model.","","","10.1109/TMI.2017.2787672","EPSRC; Wellcome Trust; EU-Horizon2020 Project EndoVESPA; China Scholarship Council Scholarship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8259318","Surgical instrument detection;articulated pose estimation;fully convolutional networks;surgical vision","Joints;Instruments;Pose estimation;Surgery;Robot kinematics;Semantics","computer vision;convolution;endoscopes;estimation theory;feature extraction;feedforward neural nets;graph theory;inference mechanisms;learning (artificial intelligence);medical image processing;pose estimation;regression analysis;surgery","estimation framework;single-instrument RMIT data;multiinstrument EndoVis;fully convolutional networks;instrument detection;surgical videos;articulation detection;deep neural network;endoscopic data sets;microscopic data sets;fully convolutional detection-regression network;instrument model;detection subnetwork;regression subnetwork;vision component;articulated multiinstrument 2D pose estimation;maximum bipartite graph matching;deep learning techniques","Algorithms;Databases, Factual;Deep Learning;Humans;Image Processing, Computer-Assisted;Robotic Surgical Procedures;Surgical Instruments","7","31","CCBY","","","","IEEE","IEEE Journals"
"Multiple Features With Extreme Learning Machines For Clothing Image Recognition","R. Li; W. Lu; H. Liang; Y. Mao; X. Wang","School of Computer Science, Beijing University of Posts and Telecommunications, Beijing, China; School of Computer Science, Beijing University of Posts and Telecommunications, Beijing, China; School of Computer Science, Beijing University of Posts and Telecommunications, Beijing, China; School of Computer Science, Beijing University of Posts and Telecommunications, Beijing, China; School of Computer Science, Beijing University of Posts and Telecommunications, Beijing, China","IEEE Access","","2018","6","","36283","36294","Clothing image recognition has recently received considerable attention from many communities, such as multimedia information processing and computer vision, due to its commercial and social applications. However, the large variations in clothing images' appearances and styles and their complicated formation conditions make the problem challenging. In addition, a generic treatment with convolutional neural networks (CNNs) cannot provide a satisfactory solution considering the training time and recognition performance. Therefore, how to balance those two factors for clothing image recognition is an interesting problem. Motivated by the fast training and straightforward solutions exhibited by extreme learning machines (ELMs), in this paper, we propose a recognition framework that is based on multiple sources of features and ELM neural networks. In this framework, three types of features are first extracted, including CNN features with pre-trained networks, histograms of oriented gradients and color histograms. Second, those low-level features are concatenated and taken as the inputs to an autoencoder version of the ELM for deep feature-level fusion. Third, we propose an ensemble of adaptive ELMs for decision-level fusion using the previously obtained feature-level fusion representations. Extensive experiments are conducted on an up-to-date large-scale clothing image data set. Those experimental results show that the proposed framework is competitive and efficient.","","","10.1109/ACCESS.2018.2848966","National Natural Science Foundation of China; National Social Science Fund of China; Discipline Building Plan in 111 Base; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8388198","Clothing image recognition;extreme learning machines;feature fusion;autoencoder ELM;ensemble learning","Clothing;Image recognition;Task analysis;Feature extraction;Neural networks;Machine learning;Histograms","clothing;computer vision;convolution;feature extraction;feedforward neural nets;image colour analysis;image recognition;learning (artificial intelligence)","multimedia information processing;computer vision;convolutional neural networks;clothing image recognition;extreme learning machines;recognition framework;ELM neural networks;CNN features;pre-trained networks;deep feature-level fusion;feature-level fusion representations;multiple features;large-scale clothing image data;color histograms","","2","47","","","","","IEEE","IEEE Journals"
"Wide and Deep Convolutional Neural Networks for Electricity-Theft Detection to Secure Smart Grids","Z. Zheng; Y. Yang; X. Niu; H. Dai; Y. Zhou","School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; Faculty of Information Technology, Macau University of Science and Technology, Taipa, Macau; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China","IEEE Transactions on Industrial Informatics","","2018","14","4","1606","1615","Electricity theft is harmful to power grids. Integrating information flows with energy flows, smart grids can help to solve the problem of electricity theft owning to the availability of massive data generated from smart grids. The data analysis on the data of smart grids is helpful in detecting electricity theft because of the abnormal electricity consumption pattern of energy thieves. However, the existing methods have poor detection accuracy of electricity theft since most of them were conducted on one-dimensional (1-D) electricity consumption data and failed to capture the periodicity of electricity consumption. In this paper, we originally propose a novel electricity-theft detection method based on wide and deep convolutional neural networks (CNN) model to address the above concerns. In particular, wide and deep CNN model consists of two components: the wide component and the deep CNN component. The deep CNN component can accurately identify the nonperiodicity of electricity theft and the periodicity of normal electricity usage based on 2-D electricity consumption data. Meanwhile, the wide component can capture the global features of 1-D electricity consumption data. As a result, wide and deep CNN model can achieve the excellent performance in electricity-theft detection. Extensive experiments based on realistic dataset show that wide and deep CNN model outperforms other existing methods.","","","10.1109/TII.2017.2785963","National Key Research and Development Program; National Natural Science Foundation of China; Guangdong Introducing Innovative and Enterpreneurial Teams; Pearl River S & T Nova Program of Guangzhou; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8233155","Convolutional neural networks (CNNs);deep learning;electricity-theft detection;machine learning;smart grids","Smart grids;Anomaly detection;Correlation;Support vector machines;Meters;Sensors;Neural networks","data analysis;load flow;neural nets;power consumption;power engineering computing;power system security;smart power grids","wide CNN model;deep CNN model;smart grids;abnormal electricity consumption pattern;novel electricity-theft detection method;deep CNN component;normal electricity usage;power grids;information flows;energy flows;massive data availability;data analysis;1D electricity consumption data;electricity theft nonperiodicity identification;normal electricity usage periodicity identification","","19","43","","","","","IEEE","IEEE Journals"
"Reflectance and Natural Illumination from Single-Material Specular Objects Using Deep Learning","S. Georgoulis; K. Rematas; T. Ritschel; E. Gavves; M. Fritz; L. Van Gool; T. Tuytelaars","KU Leuven, ESAT-PSI, iMinds, Gent, Belgium; University of Washington, Seattle, WA, USA; University College London, London, United Kingdom; University of Amsterdam, Amsterdam, Netherlands; Max Planck Institute for Informatics, Saarbrcken, Germany; KU Leuven, ESAT-PSI, iMinds, Gent, Belgium; KU Leuven, ESAT-PSI, iMinds, Gent, Belgium","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","8","1932","1947","In this paper, we present a method that estimates reflectance and illumination information from a single image depicting a single-material specular object from a given class under natural illumination. We follow a data-driven, learning-based approach trained on a very large dataset, but in contrast to earlier work we do not assume one or more components (shape, reflectance, or illumination) to be known. We propose a two-step approach, where we first estimate the object's reflectance map, and then further decompose it into reflectance and illumination. For the first step, we introduce a Convolutional Neural Network (CNN) that directly predicts a reflectance map from the input image itself, as well as an indirect scheme that uses additional supervision, first estimating surface orientation and afterwards inferring the reflectance map using a learning-based sparse data interpolation technique. For the second step, we suggest a CNN architecture to reconstruct both Phong reflectance parameters and high-resolution spherical illumination maps from the reflectance map. We also propose new datasets to train these CNNs. We demonstrate the effectiveness of our approach for both steps by extensive quantitative and qualitative evaluation in both synthetic and real data as well as through numerous applications, that show improvements over the state-of-the-art.","","","10.1109/TPAMI.2017.2742999","Toyota Research Institute; FWO project; Structure from Semantics; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8014479","Reflectance maps;intrinsic images;reflectance;natural illumination;specular shading;convolutional neural networks","Lighting;Shape;Three-dimensional displays;Training;Two dimensional displays","computer vision;feedforward neural nets;image reconstruction;image representation;interpolation;learning (artificial intelligence);lighting;realistic images","reflectance map;learning-based sparse data interpolation technique;Phong reflectance parameters;high-resolution spherical illumination maps;natural illumination;single-material specular object;deep learning;illumination information;single image;learning-based approach;two-step approach;CNN architecture","","1","57","","","","","IEEE","IEEE Journals"
"Deep Visual Discomfort Predictor for Stereoscopic 3D Images","H. Oh; S. Ahn; S. Lee; A. C. Bovik","Department of Electrical and Electronics Engineering, Yonsei University, Seoul, South Korea; Department of Electrical and Electronics Engineering, Yonsei University, Seoul, South Korea; Department of Electrical and Electronics Engineering, Yonsei University, Seoul, South Korea; Department of Electrical and Computer Engineering, Laboratory for Image and Video Engineering, The University of Texas at Austin, Austin, TX, USA","IEEE Transactions on Image Processing","","2018","27","11","5420","5432","Most prior approaches to the problem of stereoscopic 3D (S3D) visual discomfort prediction (VDP) have focused on the extraction of perceptually meaningful handcrafted features based on models of visual perception and of natural depth statistics. Toward advancing performance on this problem, we have developed a deep learning-based VDP model named deep visual discomfort predictor (DeepVDP). The DeepVDP uses a convolutional neural network (CNN) to learn features that are highly predictive of experienced visual discomfort. Since a large amount of reference data is needed to train a CNN, we develop a systematic way of dividing the S3D image into local regions defined as patches and model a patch-based CNN using two sequential training steps. Since it is very difficult to obtain human opinions on each patch, instead a proxy ground-truth label that is generated by an existing S3D visual discomfort prediction algorithm called 3D-VDP is assigned to each patch. These proxy ground-truth labels are used to conduct the first stage of training the CNN. In the second stage, the automatically learned local abstractions are aggregated into global features via a feature aggregation layer. The learned features are iteratively updated via supervised learning on subjective 3D discomfort scores, which serve as ground-truth labels on each S3D image. The patch-based CNN model that has been pretrained on proxy ground-truth labels is subsequently retrained on true global subjective scores. The global S3D visual discomfort scores predicted by the trained DeepVDP model achieve the state-of-the-art performance as compared with previous VDP algorithms.","","","10.1109/TIP.2018.2851670","National Research Foundation of Korea; National Research Foundation of Korea; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8400532","Stereoscopic 3D;visual discomfort prediction;convolutional neural network;proxy ground-truth label","Visualization;Feature extraction;Training;Three-dimensional displays;Computational modeling;Predictive models;Tuning","feature extraction;feedforward neural nets;learning (artificial intelligence);statistical analysis;stereo image processing;visual perception","proxy ground-truth label;automatically learned local abstractions;global features;feature aggregation layer;learned features;subjective 3D discomfort scores;ground-truth labels;patch-based CNN model;global S3D visual discomfort scores;trained DeepVDP model;deep visual discomfort predictor;stereoscopic 3D visual discomfort prediction;perceptually meaningful handcrafted features;visual perception;deep learning-based VDP model;3D-VDP;sequential training;S3D visual discomfort prediction algorithm","","1","66","","","","","IEEE","IEEE Journals"
"Exploiting the Spatio-Temporal Patterns in IoT Data to Establish a Dynamic Ensemble of Distributed Learners","M. Mohammadi; A. Al-Fuqaha","Department of Computer Science, Western Michigan University, Kalamazoo, MI, USA; Information and Computing Division, College of Science and Engineering, Hamad Bin Khalifa University, Doha, Qatar","IEEE Access","","2018","6","","63316","63328","Internet of Things applications can greatly benefit from accurate prediction models. The performance of prediction models is highly dependent on the quantity and quality of their training data. In this paper, we investigate the creation of a dynamic ensemble from distributed deep learning models by considering the spatiotemporal patterns embedded in the training data. Our dynamic ensemble does not depend on offline configurations. Instead, it exploits the spatiotemporal patterns embedded in the training data to generate dynamic weights for the underlying weak distributed deep learners to create a stronger learner. Our evaluation experiments using three real-world datasets in the context of the smart city show that our proposed dynamic ensemble strategy leads to an improved error rate of up to 33% compared to the baseline strategy even when using31of the training data. Moreover, using only 20% of the training data, the error rate of the model slightly increased by up to 2 in terms of mean square error. This increase is 82% less than the 11.3 increase seen in the baseline model. Therefore, our approach contributes to the reduced network traffic while not hindering the accuracy significantly.","","","10.1109/ACCESS.2018.2877153","Qatar National Library; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8501920","Distributed deep neural networks;spatio-temporal analysis;ensemble deep learning;bloom filter;Internet of Things;smart city","Data models;Predictive models;Training data;Load modeling;Computational modeling;Sensors","Internet of Things;learning (artificial intelligence);mean square error methods;pattern classification;spatiotemporal phenomena","spatiotemporal patterns;training data;dynamic weights;underlying weak distributed deep learners;dynamic ensemble strategy;baseline model;spatio-temporal patterns;IoT data;accurate prediction models;distributed deep learning models","","","39","","","","","IEEE","IEEE Journals"
"Scalable Discrete Supervised Multimedia Hash Learning With Clustering","S. Zhang; J. Li; M. Jiang; P. Yuan; B. Zhang","State Key Laboratory of Intelligent Technology and Systems, TNList, Department of Computer Science and Technology, Tsinghua University, Beijing, China; State Key Laboratory of Intelligent Technology and Systems, TNList, Department of Computer Science and Technology, Tsinghua University, Beijing, China; School of Software, Tsinghua University, Beijing, China; Intelligent Technology and Robotics Research Center, Beihang University, Beijing, China; State Key Laboratory of Intelligent Technology and Systems, TNList, Department of Computer Science and Technology, Tsinghua University, Beijing, China","IEEE Transactions on Circuits and Systems for Video Technology","","2018","28","10","2716","2729","The hashing method maps similar data of various types to binary hashcodes with smaller hamming distance, and it has received broad attention due to its low-storage cost and fast retrieval speed. However, the existing limitations make the present algorithms difficult to deal with for large-scale data sets: 1) discrete constraints are involved in the learning of the hash function and 2) pairwise or triplet similarity is adopted to generate efficient hashcodes, resulting in both time and space complexity greater than O(n2). To address these issues, we propose a novel discrete supervised hash learning framework that can be scalable to large-scale data sets of various types. First, the discrete learning procedure is decomposed into a binary classifier learning scheme and binary codes learning scheme, which makes the learning procedure more efficient. Second, by adopting the asymmetric low-rank matrix factorization, we propose the fast clustering-based batch coordinate descent method, such that the time and space complexity are reduced to O(n). The proposed framework also provides a flexible paradigm to incorporate with arbitrary hash function, including deep neural networks and kernel methods, as well as any types of data to hash, including images and videos. Experiments on large-scale data sets demonstrate that the proposed method is superior or comparable with the state-of-the-art hashing algorithms.","","","10.1109/TCSVT.2017.2710345","National Basic Research Program (973 Program) of China; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7937842","Hash learning;discrete method;information retrieval;video hashing;asymmetric matrix factorization","Videos;Binary codes;Training data;Semantics;Neural networks;Training;Complexity theory","binary codes;computational complexity;cryptography;file organisation;information retrieval;learning (artificial intelligence);matrix decomposition;neural nets;pattern classification;pattern clustering;video signal processing","low-storage cost;fast retrieval speed;large-scale data sets;space complexity;discrete learning procedure;binary classifier learning scheme;low-rank matrix factorization;arbitrary hash function;deep neural networks;kernel methods;hamming distance;time complexity;hashing algorithms;scalable discrete supervised multimedia hash learning;binary codes learning scheme;clustering-based batch coordinate descent method","","3","62","","","","","IEEE","IEEE Journals"
"Vehicle Instance Segmentation From Aerial Image and Video Using a Multitask Learning Residual Fully Convolutional Network","L. Mou; X. X. Zhu","German Aerospace Center, Remote Sensing Technology Institute, Wessling, Germany; German Aerospace Center, Remote Sensing Technology Institute, Wessling, Germany","IEEE Transactions on Geoscience and Remote Sensing","","2018","56","11","6699","6711","Object detection and semantic segmentation are two main themes in object retrieval from high-resolution remote sensing images, which have recently achieved remarkable performance by surfing the wave of deep learning and, more notably, convolutional neural networks. In this paper, we are interested in a novel, more challenging problem of vehicle instance segmentation, which entails identifying, at a pixel level, where the vehicles appear as well as associating each pixel with a physical instance of a vehicle. In contrast, vehicle detection and semantic segmentation each only concern one of the two. We propose to tackle this problem with a semantic boundary-aware multitask learning network. More specifically, we utilize the philosophy of residual learning to construct a fully convolutional network that is capable of harnessing multilevel contextual feature representations learned from different residual blocks. We theoretically analyze and discuss why residual networks can produce better probability maps for pixelwise segmentation tasks. Then, based on this network architecture, we propose a unified multitask learning network that can simultaneously learn two complementary tasks, namely, segmenting vehicle regions and detecting semantic boundaries. The latter subproblem is helpful for differentiating “touching” vehicles that are usually not correctly separated into instances. Currently, data sets with a pixelwise annotation for vehicle extraction are the ISPRS data set and the IEEE GRSS DFC2015 data set over Zeebrugge, which specializes in a semantic segmentation. Therefore, we built a new, more challenging data set for vehicle instance segmentation, called the Busy Parking Lot Unmanned Aerial Vehicle Video data set, and we make our data set available at http://www.sipeo.bgu.tum.de/downloads so that it can be used to benchmark future vehicle instance segmentation algorithms.","","","10.1109/TGRS.2018.2841808","China Scholarship Council; European Research Council through the European Union’s Horizon 2020 Research and Innovation Programme; Helmholtz-Gemeinschaft; Bayerische Akademie der Wissenschaften; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8408520","Boundary-aware multitask learning network;fully convolutional network (FCN);high-resolution remote sensing image/video;instance semantic segmentation;residual neural network (ResNet);vehicle detection","Image segmentation;Semantics;Feature extraction;Vehicle detection;Remote sensing;Task analysis;Object detection","convolution;feature extraction;feedforward neural nets;geophysical image processing;image resolution;image segmentation;learning (artificial intelligence);object detection;probability;remote sensing;traffic engineering computing;video signal processing","multitask learning residual fully convolutional network;object detection;semantic segmentation;high-resolution remote sensing images;deep learning;convolutional neural networks;vehicle detection;semantic boundary-aware multitask;residual networks;pixelwise segmentation tasks;unified multitask learning network;vehicle extraction;vehicle instance segmentation algorithms;semantic boundary-aware multitask learning network;Busy Parking Lot Unmanned Aerial Vehicle Video data set","","7","49","","","","","IEEE","IEEE Journals"
"Restricted Boltzmann Machine-Based Approaches for Link Prediction in Dynamic Networks","T. Li; B. Wang; Y. Jiang; Y. Zhang; Y. Yan","Key Laboratory of Speech Acoustics and Content Understanding, Institute of Acoustics, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Speech Acoustics and Content Understanding, Institute of Acoustics, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Speech Acoustics and Content Understanding, Institute of Acoustics, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Speech Acoustics and Content Understanding, Institute of Acoustics, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Speech Acoustics and Content Understanding, Institute of Acoustics, Chinese Academy of Sciences, Beijing, China","IEEE Access","","2018","6","","29940","29951","Link prediction in dynamic networks aims to predict edges according to historical linkage status. It is inherently difficult because of the linear/non-linear transformation of underlying structures. The problem of efficiently performing dynamic link inference is extremely challenging due to the scale of networks and different evolving patterns. Most previous approaches for link prediction are based on members' similarity and supervised learning methods. However, research work on investigating hidden patterns of dynamic social networks is rarely conducted. In this paper, we propose a novel framework that incorporates a deep learning method, i.e., temporal restricted Boltzmann machine, and a machine learning approach, i.e., gradient boosting decision tree. The proposed model is capable of modeling each link's evolving patterns. We also propose a novel transformation for input matrix, which significantly reduces the computational complexity and makes our algorithm scalable to large networks. Extensive experiments demonstrate that the proposed method outperforms the existing state-of-the-art algorithms on real-world dynamic networks.","","","10.1109/ACCESS.2018.2840054","National Natural Science Foundation of China; National Key Research and Development Program; Key Science and Technology Project of the Xinjiang Uygur Autonomous Region; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8370030","Link prediction;social network analysis;deep learning","Computational modeling;Heuristic algorithms;Prediction algorithms;Social network services;Machine learning;Computational complexity;Feature extraction","Boltzmann machines;decision trees;gradient methods;learning (artificial intelligence);social networking (online)","deep learning;restricted Boltzmann machine;machine learning;dynamic networks;supervised learning;gradient boosting decision tree;dynamic social networks;dynamic link inference;historical linkage status;link prediction","","1","38","","","","","IEEE","IEEE Journals"
"Learning Consensus Representation for Weak Style Classification","S. Jiang; M. Shao; C. Jia; Y. Fu","Department of Electrical and Computer Engineering, Northeastern University, Boston, MA; Department of Computer Information Science, University of Massachusetts Dartmouth, Dartmouth, MA; Department of Electrical and Computer Engineering, Northeastern University, Boston, MA; Department of Electrical and Computer Engineering, Northeastern University, Boston, MA","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","12","2906","2919","Style classification (e.g., Baroque and Gothic architecture style) is grabbing increasing attention in many fields such as fashion, architecture, and manga. Most existing methods focus on extracting discriminative features from local patches or patterns. However, the spread out phenomenon in style classification has not been recognized yet. It means that visually less representative images in a style class are usually very diverse and easily getting misclassified. We name them weak style images. Another issue when employing multiple visual features towards effective weak style classification is lack of consensus among different features. That is, weights for different visual features in the local patch should have been allocated similar values. To address these issues, we propose a Consensus Style Centralizing Auto-Encoder (CSCAE) for learning robust style features representation, especially for weak style classification. First, we propose a Style Centralizing Auto-Encoder (SCAE) which centralizes weak style features in a progressive way. Then, based on SCAE, we propose both the non-linear and linear version CSCAE which adaptively allocate weights for different features during the progressive centralization process. Consensus constraints are added based on the assumption that the weights of different features of the same patch should be similar. Specifically, the proposed linear counterpart of CSCAE motivated by the “shared weights” idea as well as group sparsity improves both efficacy and efficiency. For evaluations, we experiment extensively on fashion, manga and architecture style classification problems. In addition, we collect a new dataset-Online Shopping, for fashion style classification, which will be publicly available for vision based fashion style research. Experiments demonstrate the effectiveness of the SCAE and CSCAE on both public and newly collected datasets when compared with the most recent state-of-the-art works.","","","10.1109/TPAMI.2017.2771766","NSF IIS; ONR Young Investigator Award; U.S. Army Research Office Award; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8103058","Style classification;deep learning;auto-encoder","Visualization;Feature extraction;Data visualization;Principal component analysis;Encoding;Deep learning;Computer architecture","feature extraction;image classification;image coding;image representation;learning (artificial intelligence)","visual features;local patches;discriminative features;Consensus representation;vision based fashion style research;fashion style classification;architecture style classification problems;weak style features;robust style features representation;CSCAE;Consensus Style Centralizing Auto-Encoder;effective weak style classification;multiple visual features;weak style images","","1","38","","","","","IEEE","IEEE Journals"
"Application of deep autoencoder model for structural condition monitoring","C. S. N. Pathirage; J. Li; L. Li; H. Hao; W. Liu","Department of Computing, Curtin University, Perth WA 6102, Australia; Centre for Infrastructural Monitoring and Protection, Curtin University, Perth WA 6102, Australia; Department of Computing, Curtin University, Perth WA 6102, Australia; Centre for Infrastructural Monitoring and Protection, Curtin University, Perth WA 6102, Australia; Department of Computing, Curtin University, Perth WA 6102, Australia","Journal of Systems Engineering and Electronics","","2018","29","4","873","880","Damage detection in structures is performed via vibration based structural identification. Modal information, such as frequencies and mode shapes, are widely used for structural damage detection to indicate the health conditions of civil structures. The deep learning algorithm that works on a multiple layer neural network model termed as deep autoencoder is proposed to learn the relationship between the modal information and structural stiffness parameters. This is achieved via dimension reduction of the modal information feature and a non-linear regression against the structural stiffness parameters. Numerical tests on a symmetrical steel frame model are conducted to generate the data for the training and validation, and to demonstrate the efficiency of the proposed approach for vibration based structural damage detection.","","","10.21629/JSEE.2018.04.22","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8456671","auto encoder;non-linear regression;deep auto encoder model;damage identification;vibration;structural health monitoring","Modeling;Shape;Neural networks;Frequency measurement;Finite element analysis;Steel;Training","condition monitoring;learning (artificial intelligence);neural nets;regression analysis;steel;structural engineering;vibrations","deep autoencoder model;structural condition monitoring;health conditions;civil structures;deep learning algorithm;multiple layer neural network model;structural stiffness parameters;modal information feature;symmetrical steel frame model;vibration based structural damage detection;vibration-based structural identification","","","","","","","","BIAI","BIAI Journals"
"A Deep Network Architecture for Super-Resolution-Aided Hyperspectral Image Classification With Classwise Loss","S. Hao; W. Wang; Y. Ye; E. Li; L. Bruzzone","College of Information and Control Engineering, Qingdao University of Technology, Qingdao; Department of Information Engineering and Computer Science, University of Trento, Trento, Italy; Faculty of Geosciences and Environmental Engineering, Southwest Jiaotong University, Chengdu, China; College of Information and Control Engineering, Qingdao University of Technology, Qingdao; Department of Information Engineering and Computer Science, University of Trento, Trento, Italy","IEEE Transactions on Geoscience and Remote Sensing","","2018","56","8","4650","4663","The supervised deep networks have shown great potential in improving the classification performance. However, training these supervised deep networks is very challenging for hyperspectral image given the fact that usually only a small amount of labeled samples are available. In order to overcome this problem and enhance the discriminative ability of the network, in this paper, we propose a deep network architecture for a super-resolution (SR)-aided hyperspectral image classification with classwise loss (SRCL). First, a three-layer SR convolutional neural network (SRCNN) is employed to reconstruct a high-resolution image from a low-resolution image. Second, an unsupervised triplet-pipeline CNN (TCNN) with an improved classwise loss is built to encourage intraclass similarity and interclass dissimilarity. Finally, SRCNN, TCNN, and a classification module are integrated to define the SRCL, which can be fine-tuned in an end-to-end manner with a small amount of training data. Experimental results on real hyperspectral images demonstrate that the proposed SRCL approach outperforms other state-of-the-art classification methods, especially for the task in which only a small amount of training data are available.","","","10.1109/TGRS.2018.2832228","Natural Science Foundation of Shandong Province; National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8390939","Classwise loss;convolutional neural networks (CNNs);deep learning;hyperspectral image classification;remote sensing;super-resolution (SR)","Hyperspectral imaging;Training;Feature extraction;Image reconstruction;Task analysis;Image resolution","feature extraction;geophysical image processing;hyperspectral imaging;image classification;image resolution;neural nets;unsupervised learning","deep network architecture;super-resolution-aided hyperspectral image classification;supervised deep networks;three-layer SR convolutional neural network;high-resolution image;low-resolution image;improved classwise loss;classification module;unsupervised triplet-pipeline CNN;intraclass similarity;interclass dissimilarity","","5","49","","","","","IEEE","IEEE Journals"
"Semi-Supervised Deep Fuzzy C-Mean Clustering for Software Fault Prediction","A. Arshad; S. Riaz; L. Jiao; A. Murthy","School of Computer Science and Technology, Xidian University, Xi’an, China; School of Computer Science and Technology, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding, Ministry of Education of China, International Joint Collaboration Laboratory of Intelligent Perception and Computation, International Research Center of Intelligent Perception and Computation, Xidian University, Xi’an, China; Professional Engineers Ontario, Toronto, ON, Canada","IEEE Access","","2018","6","","25675","25685","Software fault prediction is a consequential research area in software quality promise. In this paper, we propose a semi-supervised deep fuzzy C-mean (DFCM) clustering for software fault prediction, which is the cumulation of semi-supervised DFCM clustering and feature compression techniques. Deep is utilized for the feature-based multi clusters of unlabeled and labeled data sets along with their labeled classes. In our approach, for the training model, we simultaneously deal with the unsupervised data and supervised data to exploit the obnubilated information from unlabeled data to labeled data to support the construction of the precise model. We utilize DFCM clustering to handle the class imbalance problem and withal fuzzy theory logic is very akin to human logic and it is facile to comprehend. We further ameliorate the prediction performance with the coalescence of feature learning techniques-feature extraction and feature selection (using random-under sampling) to generate good features and remove irrelevant and redundant features to reduce the noisy data for classification. However, by the performance of the model results, the amalgamation of deep multi clusters and feature techniques work better due to their ability to identify and amalgamation essential information in data feature. The classification model is predicted on the maximum homogeneous between the features of labeled and unlabeled data, the model is trained on the un-noisy data set obtained by the deep coalescence of multi clusters and feature techniques. To check the efficacy of our approach, we chose data sets from real-world software project (NASA & Eclipse), and then we compared our approach with a number of latest classical base-line methods, and investigate the performance by using performance measures such as probability of detection, F-measure, and area under the curve.","","","10.1109/ACCESS.2018.2835304","National Basic Research Program (973 Program) of China; National Natural Science Foundation of China; Fund for Foreign Scholars in University Research and Teaching Programs (111 Project); National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8357535","Semi-supervised learning;fuzzy C-Mean clustering;feature learning;software fault prediction","Software;Feature extraction;Prediction algorithms;Data models;Clustering algorithms;Software algorithms;Predictive models","feature extraction;feature selection;fuzzy set theory;pattern classification;pattern clustering;software fault tolerance;software quality;unsupervised learning","semisupervised deep fuzzy C-mean clustering;software fault prediction;semisupervised DFCM clustering;training model;unsupervised data;fuzzy theory logic;data feature;real-world software project;software quality;feature extraction;feature learning;feature selection;classification model","","5","58","","","","","IEEE","IEEE Journals"
"Speech Emotion Recognition Using Deep Convolutional Neural Network and Discriminant Temporal Pyramid Matching","S. Zhang; S. Zhang; T. Huang; W. Gao","Institute of Digital Media, School of Electronic Engineering and Computer Science, Peking University, China; Institute of Digital Media, School of Electronic Engineering and Computer Science, Peking University, Beijing, China; Institute of Digital Media, School of Electronic Engineering and Computer Science, Peking University, Beijing, China; Institute of Digital Media, School of Electronic Engineering and Computer Science, Peking University, Beijing, China","IEEE Transactions on Multimedia","","2018","20","6","1576","1590","Speech emotion recognition is challenging because of the affective gap between the subjective emotions and low-level features. Integrating multilevel feature learning and model training, deep convolutional neural networks (DCNN) has exhibited remarkable success in bridging the semantic gap in visual tasks like image classification, object detection. This paper explores how to utilize a DCNN to bridge the affective gap in speech signals. To this end, we first extract three channels of log Mel-spectrograms (static, delta, and delta delta) similar to the red, green, blue (RGB) image representation as the DCNN input. Then, the AlexNet DCNN model pretrained on the large ImageNet dataset is employed to learn high-level feature representations on each segment divided from an utterance. The learned segment-level features are aggregated by a discriminant temporal pyramid matching (DTPM) strategy. DTPM combines temporal pyramid matching and optimal Lp-norm pooling to form a global utterance-level feature representation, followed by the linear support vector machines for emotion classification. Experimental results on four public datasets, that is, EMO-DB, RML, eNTERFACE05, and BAUM-1s, show the promising performance of our DCNN model and the DTPM strategy. Another interesting finding is that the DCNN model pretrained for image applications performs reasonably good in affective speech feature extraction. Further fine tuning on the target emotional speech datasets substantially promotes recognition performance.","","","10.1109/TMM.2017.2766843","National Natural Science Foundation of China; Zhejiang Provincial National Science Foundation of China; National 1000 Youth Talents Plan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8085174","Speech emotion recognition;feature learning;deep convolutional neural network;discriminant temporal pyramid matching;Lp-norm pooling","Speech;Feature extraction;Speech recognition;Emotion recognition;Convolution;Acoustics;Neural networks","emotion recognition;feature extraction;feedforward neural nets;image classification;image representation;learning (artificial intelligence);object detection;speech processing;support vector machines","speech emotion recognition;deep convolutional neural network;semantic gap;image classification;speech signals;log Mel-spectrograms;AlexNet DCNN model;discriminant temporal pyramid matching strategy;emotion classification;affective speech feature extraction;target emotional speech datasets;feature representations;object detection;RGB image representation;ImageNet dataset;DTPM strategy;optimal Lp-norm pooling;support vector machines;EMO-DB datasets;RML datasets;eNTERFACE05 datasets;BAUM-1s datasets;feature learning","","15","70","","","","","IEEE","IEEE Journals"
"AIF: An Artificial Intelligence Framework for Smart Wireless Network Management","G. Cao; Z. Lu; X. Wen; T. Lei; Z. Hu","Beijing University of Posts and Telecommunications, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China","IEEE Communications Letters","","2018","22","2","400","403","To solve the policy optimizing problem in many scenarios of smart wireless network management using a single universal algorithm, this letter proposes a universal learning framework, which is called AI framework based on deep reinforcement learning (DRL). This framework can also solve the problem that the state is painful to design in traditional RL. This AI framework adopts convolutional neural network and recurrent neural network to model the potential spatial features (i.e., location information) and sequential features from the raw wireless signal automatically. These features can be taken as the state definition of DRL. Meanwhile, this framework is suitable for many scenarios, such as resource management and access control due to DRL. The mean value of throughput, the standard deviation of throughput, and handover counts are used to evaluate its performance on the mobility management problem in the wireless local area network on a practical testbed. The results show that the framework gets significant improvements and learns intuitive features automatically.","","","10.1109/LCOMM.2017.2776917","Beijing Municipal Commission of Education; Nation Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8119495","Smart wireless network;deep learning;reinforcement learning;resource management","Feature extraction;Wireless networks;Algorithm design and analysis;Machine learning;Mathematical model","artificial intelligence;convolution;feedforward neural nets;learning (artificial intelligence);mobility management (mobile radio);recurrent neural nets;telecommunication computing;wireless LAN","access control;wireless local area network;artificial intelligence framework;smart wireless network management;deep reinforcement learning;convolutional neural network;recurrent neural network;wireless signal;mobility management","","7","11","","","","","IEEE","IEEE Journals"
"Shakeout: A New Approach to Regularized Deep Neural Network Training","G. Kang; J. Li; D. Tao","Faculty of Engineering and Information Technology, Center of AI, University of Technology Sydney, Ultimo, NSW, Australia; Faculty of Engineering and Information Technology, Center of AI, University of Technology Sydney, Ultimo, NSW, Australia; UBTech Sydney Artificial Intelligence Institute and the School of Information Technologies in the Faculty of Engineering and Information Technologies at The University of Sydney, Darlington, NSW, Australia","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","5","1245","1258","Recent years have witnessed the success of deep neural networks in dealing with a plenty of practical problems. Dropout has played an essential role in many successful deep neural networks, by inducing regularization in the model training. In this paper, we present a new regularized training approach: Shakeout. Instead of randomly discarding units as Dropout does at the training stage, Shakeout randomly chooses to enhance or reverse each unit's contribution to the next layer. This minor modification of Dropout has the statistical trait: the regularizer induced by Shakeout adaptively combines L0, L1 and L2 regularization terms. Our classification experiments with representative deep architectures on image datasets MNIST, CIFAR-10 and ImageNet show that Shakeout deals with over-fitting effectively and outperforms Dropout. We empirically demonstrate that Shakeout leads to sparser weights under both unsupervised and supervised settings. Shakeout also leads to the grouping effect of the input units in a layer. Considering the weights in reflecting the importance of connections, Shakeout is superior to Dropout, which is valuable for the deep model compression. Moreover, we demonstrate that Shakeout can effectively reduce the instability of the training process of the deep architecture.","","","10.1109/TPAMI.2017.2701831","Australian Research Council Projects; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7920425","Shakeout;dropout;regularization;sparsity;deep neural network","Training;Biological neural networks;Adaptation models;Computer architecture;Information technology;Computational modeling","image classification;learning (artificial intelligence);neural nets","representative deep architectures;Shakeout deals;Dropout;deep model compression;training process;deep architecture;regularized deep neural network training;model training;training stage;regularizer;unsupervised settings;supervised settings;L0 regularization terms;L2 regularization terms;L1 regularization terms;image datasets;ImageNet dataset;CIFAR-10 dataset;MNIST dataset","","3","65","","","","","IEEE","IEEE Journals"
"An All-Memristor Deep Spiking Neural Computing System: A Step Toward Realizing the Low-Power Stochastic Brain","P. Wijesinghe; A. Ankit; A. Sengupta; K. Roy","School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA; School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA; School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA; School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA","IEEE Transactions on Emerging Topics in Computational Intelligence","","2018","2","5","345","358","Deep analog artificial neural networks (ANNs) perform complex classification problems with remarkably high accuracy. However, they rely on humongous amount of power to perform the calculations, veiling the accuracy benefits. The biological brain, on the other hand, is significantly more powerful than such networks and consumes orders of magnitude less power, indicating us about some conceptual mismatch. Given that the biological neurons communicate using energy efficient trains of spikes, and the behavior is nondeterministic, incorporating these effects in deep artificial neural networks may drive us few steps toward a more realistic neuron. In this paper, we propose how the inherent stochasticity of nanoscale resistive devices can be harnessed to emulate the functionality of a spiking neuron that can be incorporated in deep stochastic spiking neural networks (SNN). At the algorithmic level, we propose how the training can be modified to convert an ANN to an SNN while supporting the stochastic activation function offered by these devices. We devise circuit architectures to incorporate stochastic memristive neurons along with memristive crossbars, which perform the functionality of the synaptic weights. We tested the proposed all-memristor deep stochastic SNN for image classification and observed only about 1% degradation in accuracy with the ANN baseline after incorporating the circuit and device related nonidealities. We witnessed that the network is robust to certain variations and consumes ~6.4 × less energy than its complementary metal oxide semiconductor (CMOS) counterpart.","","","10.1109/TETCI.2018.2829924","Center for Brain Inspired Computing; MARCO; DARPA sponsored JUMP center; Semiconductor Research Corporation; National Science Foundation; Intel Corporation; Vannevar Bush Fellowship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8471280","Memristor;stochasticity;deep stochastic spiking neural networks","Memristors;Neurons;Biological neural networks;Silicon;Resistance;Synapses;Switches","learning (artificial intelligence);memristors;neural nets;neurophysiology;pattern classification;stochastic processes","all-memristor deep spiking neural computing system;low-power stochastic brain;complex classification problems;biological brain;biological neurons;deep artificial neural networks;inherent stochasticity;nanoscale resistive devices;spiking neuron;deep stochastic spiking neural networks;stochastic activation function;stochastic memristive neurons;all-memristor deep stochastic SNN;ANN baseline;device related nonidealities;deep analog artificial neural networks;image classification","","6","52","","","","","IEEE","IEEE Journals"
"Joint Optical Performance Monitoring and Modulation Format/Bit-Rate Identification by CNN-Based Multi-Task Learning","X. Fan; Y. Xie; F. Ren; Y. Zhang; X. Huang; W. Chen; T. Zhangsun; J. Wang","School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China; Hitachi (China) Research and Development Co., Ltd., Beijing, China; School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China; School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China; School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China; School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China; School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China; School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China","IEEE Photonics Journal","","2018","10","5","1","12","A novel technique is proposed for joint multi-impairment optical performance monitoring (OPM) with bit-rate and modulation format identification (BR-MFI) in next-generation heterogeneous optic communication networks by convolution neural network (CNN)-based deep multi-task learning (MTL) on asynchronous delay-tap sampling phase portraits. Instead of treating the monitoring and identification tasks as separate problems, a novel MTL technique is used to joint optimization of them utilizing the ability of feature extraction and feature sharing. Compared with principal component analysis-based pattern recognition algorithm, CNN-based MTL achieves the better accuracies and has a shorter processing time (~56 ms). The combination signals of three modulation formats and two bit rates under various impairments are used in numerical simulation. For OPM, the results show monitoring of optical signal-to-noise ratio, chromatic dispersion, and differential group delay with root-mean-square error of 0.73 dB, 1.34 ps/nm, and 0.47 ps, respectively. Similarly, for BR-MFI, even in the case of limited training data, 100% accuracies can be achieved. Additionally, the effects of training data size, task weights, and model structure on CNN-based MTL performance are comprehensively studied. The proposed technique can intelligently analyze the signals of future heterogeneous optic communication networks, and the analysis results are helpful for better management of optical networks.","","","10.1109/JPHOT.2018.2869972","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities, China; State Key Laboratory of Advanced Optical Communication Systems Networks, China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8463576","Optical performance monitoring (OPM);bit-rate and modulation format identification (BR-MFI);convolution neural network (CNN);deep multi-task learning (MTL);asynchronous delay-tap sampling (ADTS)","Feature extraction;Task analysis;Monitoring;Convolution;Modulation;Optical fiber networks;Kernel","feature extraction;feedforward neural nets;learning (artificial intelligence);mean square error methods;next generation networks;optical fibre dispersion;optical fibre networks;optical fibre polarisation;optical modulation;optical noise;telecommunication computing","CNN-based multitask learning;joint multiimpairment optical performance monitoring;OPM;modulation format identification;BR-MFI;next-generation heterogeneous optic communication networks;convolution neural network-based deep multitask learning;asynchronous delay-tap sampling phase portraits;joint optimization;feature extraction;feature sharing;principal component analysis-based pattern recognition algorithm;modulation formats;bit rates;optical signal-to-noise ratio;differential group delay;task weights;CNN-based MTL performance;future heterogeneous optic communication networks;optical networks;joint optical performance monitoring and modulation format-bit-rate identification;MTL technique","","3","21","","","","","IEEE","IEEE Journals"
"Industrial Big Data Analytics for Prediction of Remaining Useful Life Based on Deep Learning","H. Yan; J. Wan; C. Zhang; S. Tang; Q. Hua; Z. Wang","School of Electrical Engineering, Guangdong Mechanical and Electrical College, Guangzhou, China; School of Mechanical and Automotive Engineering, South China University of Technology, Guangzhou, China; School of Mechanical and Automotive Engineering, South China University of Technology, Guangzhou, China; School of Mechanical and Automotive Engineering, South China University of Technology, Guangzhou, China; School of Mechanical and Electrical Engineering, Qingdao University, Qingdao, China; School of Mechanical Engineering, Hubei University of Arts and Science, Xiangyang, China","IEEE Access","","2018","6","","17190","17197","Due to the recent development of cyber-physical systems, big data, cloud computing, and industrial wireless networks, a new era of industrial big data is introduced. Deep learning, which brought a revolutionary change in computer vision, natural language processing, and a variety of other applications, has significant potential for solutions providing in sophisticated industrial applications. In this paper, a concept of device electrocardiogram (DECG) is presented, and an algorithm based on deep denoising autoencoder (DDA) and regression operation is proposed for the prediction of the remaining useful life of industrial equipment. First, the concept of electrocardiogram is explained. Then, a problem statement based on manufacturing scenario is presented. Subsequently, the architecture of the proposed algorithm called integrated DDA and the algorithm workflow are provided. Moreover, DECG is compared with traditional factory information system, and the feasibility and effectiveness of the proposed algorithm are validated experimentally. The proposed concept and algorithm combine typical industrial scenario and advance artificial intelligence, which has great potential to accelerate the implementation of industry 4.0.","","","10.1109/ACCESS.2018.2809681","Natural Science Foundation of Guangdong Province, China; National Key Research and Development Project; Major Projects for Numerical Control Machine; Natural Science Foundation of Hubei Province, China; Research Fund Program of Guangdong Provincial Key Laboratory of Computer Integrated Manufacturing; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8302913","Cyber-physical systems;deep learning;device electrocardiogram;industrial big data;industry 40","Machine learning;Production;Manufacturing;Maintenance engineering;Big Data;Hidden Markov models;Prediction algorithms","","","","8","39","","","","","IEEE","IEEE Journals"
"Geometric-Convolutional Feature Fusion Based on Learning Propagation for Facial Expression Recognition","Y. Tang; X. M. Zhang; H. Wang","School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; School of Computer Science and Engineering, South China University of Technology, Guangzhou, China","IEEE Access","","2018","6","","42532","42540","Facial expression is the main approach for humans to express their emotions. It is the temporal-spatial information that can be recognized by computers. In this paper, three video-based models are proposed for the facial expression recognition system (FERS). First, a differential geometric fusion network (DGFN) is proposed, which utilizes the technique of the handcrafted feature for traditional machine learning. The static geometric feature in the DGFN, which is based on the critical regions of psychology and the rules of physiology, is converted into the differential geometric feature by the geometric fusion model. Then deep-facial-sequential network (DFSN) is designed based on a multi-dimensional convolutional neural network (CNN). Finally, the DFSN-I is proposed, which is the combination of the DGFN and the DFSN taking advantages of both to achieve better performance. The experimental result shows that the combination of the handcrafted feature with prior experience and the auto-extracted feature provides better performance. It also shows that our DFSN and DFSN-I outperform the state-of-the-art methods on the Oulu-CASIA data set and achieve almost the best performance on CK+ compared with the other video-based methods.","","","10.1109/ACCESS.2018.2858278","Guangdong Science and Technology Department; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8417316","Facial expression recognition;computer vision;deep learning","Feature extraction;Face;Psychology;Face recognition;Physiology;Training;Computational modeling","convolution;emotion recognition;face recognition;feature extraction;feedforward neural nets;image fusion;learning (artificial intelligence);video signal processing","geometric-convolutional feature fusion;learning propagation;temporal-spatial information;video-based models;facial expression recognition system;differential geometric fusion network;DGFN;handcrafted feature;static geometric feature;differential geometric feature;geometric fusion model;deep-facial-sequential network;multidimensional convolutional neural network;DFSN-I;auto-extracted feature;video-based methods;machine learning;FERS system","","4","30","","","","","IEEE","IEEE Journals"
"Adaptive Noise Cancellation Using Deep Cerebellar Model Articulation Controller","Y. Tsa; H. Chu; S. Fang; J. Lee; C. Lin","Res. Center for Inf. Technol. Innovation, Taipei, Taiwan; Department of Electrical Engineering, Yuan Ze University, Taoyuan, Taiwan; Department of Electrical Engineering, Yuan Ze University, Taoyuan, Taiwan; Department of Electrical Engineering, Yuan Ze University, Taoyuan, Taiwan; Department of Electrical Engineering, Yuan Ze University, Taoyuan, Taiwan","IEEE Access","","2018","6","","37395","37402","This paper proposes a deep cerebellar model articulation controller (DCMAC) for adaptive noise cancellation (ANC). We expand upon the conventional CMAC by stacking single-layer CMAC models into multiple layers to form a DCMAC model, and derive a backpropagation training algorithm to learn the DCMAC parameters. Compared with the conventional CMAC, the DCMAC can characterize nonlinear transformations more effectively because of its deep structure. Experimental results confirm that the proposed DCMAC model outperforms the CMAC in terms of residual noise in an ANC task, showing that the DCMAC provides enhanced capability to model channel characteristics.","","","10.1109/ACCESS.2018.2827699","Ministry of Science and Technology, Taiwan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8341851","Cerebellar model articulation controller;deep learning;adaptive noise cancellation","Adaptation models;Adaptive filters;Noise cancellation;Maximum likelihood detection;Nonlinear filters;Stacking;Machine learning","backpropagation;cerebellar model arithmetic computers","ANC task;DCMAC model outperforms;nonlinear transformations;backpropagation training algorithm;model channel characteristics;deep structure;DCMAC parameters;single-layer CMAC models;conventional CMAC;adaptive noise cancellation;deep cerebellar model articulation controller","","","28","","","","","IEEE","IEEE Journals"
"Training Restricted Boltzmann Machines Using Modified Objective Function Based on Limiting the Free Energy Value","S. Guo; C. Zhou; B. Wang; X. Zheng","College of Mathematics and Computer Science, Zhejiang Normal University, Jinhua, China; College of Mathematics and Computer Science, Zhejiang Normal University, Jinhua, China; Key Laboratory of Advanced Design and Intelligent Computing, Ministry of Education, Dalian University, Dalian, China; Key Laboratory of Advanced Design and Intelligent Computing, Ministry of Education, Dalian University, Dalian, China","IEEE Access","","2018","6","","78542","78550","A restricted Boltzmann machine (RBM) is a generative model that can capture the probability distribution of data relevant to the problem domain and is usually deployed as the fundamental building block to form more complex deep architectures, such as deep belief network, deep Boltzmann machine, and deep stacked auto-encoder. In addition, the RBM itself can be used as a feature extractor to learn features from raw data. In addition, an RBM is a special type of energy-based model. This paper proposes a modified loss function as an example of an energy-based model defined by restricting the free energy value of the training data. This restriction punishes very low free energy value to reduce the model complexity, which is helpful to the training procedure of the RBM. We validate our method using the MNIST and MNIST-ROTATION datasets. Experiments reveal that the modified loss function behaves better in learning discriminative features as well as in providing better parameters when used to initialize deep feed-forward neural networks (DNN). The convergence speed of the DNN can improve by 44% on both datasets.","","","10.1109/ACCESS.2018.2885071","National Natural Science Foundation of China; Dalian Outstanding Young Science and Technology Talent Support Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8561270","Restricted Boltzmann machines;deep learning;feature extractor;loss function","Training;Computational modeling;Feature extraction;Complexity theory;Linear programming;Approximation algorithms;Data models","Boltzmann machines;feature extraction;feedforward neural nets;learning (artificial intelligence);statistical distributions","raw data;RBM;energy-based model;modified loss function;free energy value;training data;model complexity;training procedure;deep feed-forward;training restricted Boltzmann machines;modified objective function;restricted Boltzmann machine;generative model;fundamental building block;complex deep architectures;deep belief network;deep Boltzmann machine;deep stacked auto-encoder;feature extractor","","1","40","","","","","IEEE","IEEE Journals"
"Eye Recognition With Mixed Convolutional and Residual Network (MiCoRe-Net)","Z. Wang; C. Li; H. Shao; J. Sun","Department of Electrical Engineering and Computer Science, The University of Tennessee, Knoxville, TN, USA; Department of Electrical Engineering and Computer Science, The University of Tennessee, Knoxville, TN, USA; School of Information Science and Engineering, Shandong Normal University, Jinan, China; School of Information Science and Engineering, Shandong Normal University, Jinan, China","IEEE Access","","2018","6","","17905","17912","Although iris recognition has achieved big successes on biometric identification in recent years, difficulties in the collection of iris images with high resolution and in the segmentation of valid regions prevent it from applying to large-scale practical applications. In this paper, we present an eye recognition framework based on deep learning, which relaxes the data collection procedure, improves the anti-fake quality, and promotes the performance of biometric identification. Specifically, we propose and train a mixed convolutional and residual network (MiCoRe-Net) for the eye recognition task. Such an architecture inserts a convolutional layer between every two residual layers and takes the advantages from both of convolutional networks and residual networks. Experiment results show that the proposed approach achieves accuracies of 99.08% and 96.12% on the CASIA-Iris-IntervalV4 and the UBIRIS.v2 datasets, respectively, which outperforms other classical classifiers and deep neural networks with other architectures.","","","10.1109/ACCESS.2018.2812208","Natural Science Foundation for Distinguished Young Scholars of Shandong Province; Key Research and Development Foundation of Shandong Province; Natural Science Foundation of China; Shandong Provincial Key Research and Development Plan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8307048","Eye recognition;iris recognition;deep learning;convolutional neural network;deep residual network;mixed convolutional and residual network (MiCoReNet)","Iris recognition;Convolutional neural networks;Feature extraction;Image segmentation;Training;Task analysis","convolution;feature extraction;feedforward neural nets;image enhancement;iris recognition;learning (artificial intelligence)","MiCoRe-Net;iris recognition;biometric identification;eye recognition framework;data collection procedure;eye recognition task;deep neural networks;antifake quality;deep learning;mixed convolutional and residual network","","5","30","","","","","IEEE","IEEE Journals"
"Adaptive Pooling Operators for Weakly Labeled Sound Event Detection","B. McFee; J. Salamon; J. P. Bello","Music and Audio Research Laboratory and the Center for Data Science, New York University, New York, NY, USA; Music and Audio Research Laboratory, New York University, New York, NY, USA; Music and Audio Research Laboratory, New York University, New York, NY, USA","IEEE/ACM Transactions on Audio, Speech, and Language Processing","","2018","26","11","2180","2193","Sound event detection (SED) methods are tasked with labeling segments of audio recordings by the presence of active sound sources. SED is typically posed as a supervised machine learning problem, requiring strong annotations for the presence or absence of each sound source at every time instant within the recording. However, strong annotations of this type are both labor- and cost-intensive for human annotators to produce, which limits the practical scalability of SED methods. In this paper, we treat SED as a multiple instance learning (MIL) problem, where training labels are static over a short excerpt, indicating the presence or absence of sound sources but not their temporal locality. The models, however, must still produce temporally dynamic predictions, which must be aggregated (pooled) when comparing against static labels during training. To facilitate this aggregation, we develop a family of adaptive pooling operators - referred to as autopool - which smoothly interpolate between common pooling operators, such as min-, max-, or average-pooling, and automatically adapt to the characteristics of the sound sources in question. We evaluate the proposed pooling operators on three datasets, and demonstrate that in each case, the proposed methods outperform nonadaptive pooling operators for static prediction, and nearly match the performance of models trained with strong, dynamic annotations. The proposed method is evaluated in conjunction with convolutional neural networks, but can be readily applied to any differentiable model for time-series label prediction. While this paper focuses on SED applications, the proposed methods are general, and could be applied widely to MIL problems in any domain.","","","10.1109/TASLP.2018.2858559","Moore-Sloan Data Science Environment at NYU; National Science Foundation; Google Faculty Award; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8434391","Sound event detection;machine learning;multiple instance learning;deep learning","Standards;Event detection;Predictive models;Data models;Training;Task analysis;Machine learning","audio recording;audio signal processing;feedforward neural nets;learning (artificial intelligence);signal detection","segment labeling;weakly labeled sound event detection;autopool;min-pooling;max-pooling;convolutional neural networks;supervised machine learning problem;active sound sources;audio recordings;MIL problems;SED applications;time-series label prediction;dynamic annotations;strong annotations;static prediction;average-pooling;common pooling operators;adaptive pooling operators;temporally dynamic predictions;sound source;training labels;multiple instance learning problem;SED methods;human annotators","","7","76","","","","","IEEE","IEEE Journals"
"Energy Propagation in Deep Convolutional Neural Networks","T. Wiatowski; P. Grohs; H. Bölcskei","Department of Information Technology and Electrical Engineering, ETH Zürich, Zürich, Switzerland; Faculty of Mathematics, University of Vienna, Vienna, Austria; Department of Information Technology and Electrical Engineering, ETH Zürich, Zürich, Switzerland","IEEE Transactions on Information Theory","","2018","64","7","4819","4842","Many practical machine learning tasks employ very deep convolutional neural networks. Such large depths pose formidable computational challenges in training and operating the network. It is therefore important to understand how fast the energy contained in the propagated signals (a.k.a. feature maps) decays across layers. In addition, it is desirable that the feature extractor generated by the network be informative in the sense of the only signal mapping to the all-zeros feature vector being the zero input signal. This “trivial null-set” property can be accomplished by asking for “energy conservation” in the sense of the energy in the feature vector being proportional to that of the corresponding input signal. This paper establishes conditions for energy conservation (and thus for a trivial null-set) for a wide class of deep convolutional neural network-based feature extractors and characterizes corresponding feature map energy decay rates. Specifically, we consider general scattering networks employing the modulus non-linearity and we find that under mild analyticity and high-pass conditions on the filters (which encompass, inter alia, various constructions of Weyl-Heisenberg filters, wavelets, ridgelets, (α)-curvelets, and shearlets) the feature map energy decays at least polynomially fast. For broad families of wavelets and Weyl-Heisenberg filters, the guaranteed decay rate is shown to be exponential. Moreover, we provide handy estimates of the number of layers needed to have at least ((1-ε) 100)% of the input signal energy be contained in the feature vector.","","","10.1109/TIT.2017.2756880","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8051085","Machine learning;deep convolutional neural networks;scattering networks;energy decay and conservation;frame theory","Feature extraction;Convolution;Energy conservation;Neural networks;Scattering;Indexes","convolution;energy conservation;feature extraction;learning (artificial intelligence);polynomials;self-organising feature maps;vectors;wavelet transforms","deep convolutional neural network-based feature extractors;Weyl-Heisenberg filters;feature map energy decays;input signal energy;feature vector;energy propagation;signal mapping;zero input signal;energy conservation;machine learning tasks;computational challenges;signals propagation;trivial null-set property;networks scattering;wavelets;ridgelets;curvelets;shearlets","","2","55","","","","","IEEE","IEEE Journals"
"Deep Learning for Plant Species Classification using Leaf Vein Morphometric","J. W. Tan; S. Chang; S. Binti Abdul Kareem; H. J. Yap; K. Yong","Institute of Biological Sciences, Bioinformatics Programme, University of Malaya Faculty of Science, 69873 Kuala Lumpur, Kuala Lumpur Malaysia (e-mail: jingwei_92@siswa.um.edu.my); Institute of Biological Sciences, Bioinformatics Programme, University of Malaya Faculty of Science, 69873 Kuala Lumpur, Kuala Lumpur Malaysia (e-mail: siowwee@um.edu.my); Artificial Intelligent, University Malaya, Kuala Lumpur, Kuala Lumpur Malaysia (e-mail: sameem@um.edu.my); Faculty of Engineering, Universiti Malaya, Kuala Lumpur, Selangor Malaysia (e-mail: hjyap737@um.edu.my); Institute of Biological Sciences, University of Malaya Faculty of Science, 69873 Kuala Lumpur, Kuala Lumpur Malaysia (e-mail: yongkt@um.edu.my)","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2018","PP","99","1","1","Automated plant species identification system could help botanists and layman in identifying plant species rapidly. Deep learning is robust for feature extraction as it is superior in providing deeper information of images. In this research, a new CNN-based method named D-Leaf was proposed. The leaf images were pre-processed and the features were extracted by using three different Convolutional Neural Network (CNN) models namely pre-trained AlexNet, fine-tuned AlexNet and D-Leaf. These features were then classified by using five machine learning techniques, namely, Support Vector Machine (SVM), Artificial Neural Network (ANN), k-Nearest-Neighbour (k-NN), Naïve-Bayes (NB) and CNN. A conventional morphometric method computed the morphological measurements based on the Sobel segmented veins was employed for benchmarking purposes. The D-Leaf model achieved a comparable testing accuracy of 94.88% as compared to AlexNet (93.26%) and fine-tuned AlexNet (95.54%) models. In addition, CNN models performed better than the traditional morphometric measurements (66.55%). The features extracted from the CNN are found to be fitted well with the ANN classifier. D-Leaf can be an effective automated system for plant species identification as shown by the experimental results.","","","10.1109/TCBB.2018.2848653","University of Malaya Research Grant; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8388220","tropical tree;deep learning;Convolutional Network;leaf vein morphometric;feature extraction;classification;Artificial Neural Network","Feature extraction;Veins;Machine learning;Image color analysis;Shape;Support vector machines;Artificial neural networks","","","","2","","","","","","IEEE","IEEE Early Access Articles"
"Hyperspectral Unmixing Using a Neural Network Autoencoder","B. Palsson; J. Sigurdsson; J. R. Sveinsson; M. O. Ulfarsson","Faculty of Electrical and Computer Engineering, University of Iceland, Reykjavik, Iceland; Faculty of Electrical and Computer Engineering, University of Iceland, Reykjavik, Iceland; Faculty of Electrical and Computer Engineering, University of Iceland, Reykjavik, Iceland; Faculty of Electrical and Computer Engineering, University of Iceland, Reykjavik, Iceland","IEEE Access","","2018","6","","25646","25656","In this paper, we present a deep learning based method for blind hyperspectral unmixing in the form of a neural network autoencoder. We show that the linear mixture model implicitly puts certain architectural constraints on the network, and it effectively performs blind hyperspectral unmixing. Several different architectural configurations of both shallow and deep encoders are evaluated. Also, deep encoders are tested using different activation functions. Furthermore, we investigate the performance of the method using three different objective functions. The proposed method is compared to other benchmark methods using real data and previously established ground truths of several common data sets. Experiments show that the proposed method compares favorably to other commonly used hyperspectral unmixing methods and exhibits robustness to noise. This is especially true when using spectral angle distance as the network's objective function. Finally, results indicate that a deeper and a more sophisticated encoder does not necessarily give better results.","","","10.1109/ACCESS.2018.2818280","Icelandic Research Fund; Postdoctoral Research Fund at the University of Iceland; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8322133","Hyperspectral unmixing;autoencoder;deep learning;neural network;spectral angle distance;endmember extraction","Linear programming;Decoding;Hyperspectral imaging;Machine learning;Neural networks;Spatial resolution","geophysical image processing;hyperspectral imaging;image coding;iterative methods;learning (artificial intelligence);neural nets","neural network autoencoder;deep learning based method;blind hyperspectral unmixing;linear mixture model;architectural constraints;deep encoders;benchmark methods;shallow encoders;objective functions;activation functions","","8","47","","","","","IEEE","IEEE Journals"
"Tensor Deep Learning Model for Heterogeneous Data Fusion in Internet of Things","W. Wang; M. Zhang","Laboratory of Wireless Communication and Energy Transmission, Tianjin Normal University, Tianjin 300387, China (e-mail: weiwang@tjnu.edu.cn).; Laboratory of Wireless Communication and Energy Transmission, Tianjin Normal University, Tianjin 300387, China (e-mail: minzhang1215@163.com).","IEEE Transactions on Emerging Topics in Computational Intelligence","","2018","PP","99","1","10","With the rapid evolvement of the Internet and data acquisition technology as well as the continuous advancement of science and technology, the amount of data in many fields has reached the level of terabyte or petabyte and most data collection comes from the Internet of Things (IoT). The rapid advancement of IoT big data has provided valuable opportunities for the development of people in all areas of society. At the same time, it has also brought severe challenges to various types of current information processing systems. Effectively using the big data technology, discovering the hidden laws in big data, tapping the potential value of big data, and predicting the development trend of things to allocate resources more reasonably will promote the overall development of society. However, most of the IoT big data are presented as heterogeneous data, with high dimensions, different forms of expression, and a lot of redundant information. The current machine learning model works in vector space, which makes it impossible to gain big data features because vectors cannot simulate the highly nonlinear distribution of IoT big data. This paper presents a deep learning calculation model called tensor deep learning (TDL), which further improves big data feature learning and high-level feature fusion. It uses tensors to model the complexity of multisource heterogeneous data and extends the vector space data to the tensor space, when feature extraction in the tensor space is included. To fully understand the underlying data distribution, the tensor distance is adopted as the average square sum error term of the output layer reconstruction error. Based on the conventional back-propagation algorithm, this study proposes a high-order back-propagation algorithm to extend the data from the linear space to multiple linear space and train the parameters of the proposed model. Then, to evaluate its performance, the proposed TDL model is compared with the stacked auto encoder and the multimodal deep learning model. Furthermore, experiments are performed on two representative datasets, namely CUAVE and STL-10. Experimental results show that the proposed model not only excels in heterogeneous data fusion but also provides a higher recognition accuracy than the conventional deep learning model or the multimodal learning model for big data.","","","10.1109/TETCI.2018.2876568","Natural Youth Science Foundation of China; National Natural Science Foundation of China; Natural Science Foundation of China; Tianjin Research Program of Application Foundation and Advanced Technology; Tianjin Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8522024","Big data;heterogeneous data fusion;tensor feature extraction;tensor deep learning model","Tensile stress;Feature extraction;Data models;Big Data;Data integration;Data mining","","","","2","","","","","","IEEE","IEEE Early Access Articles"
"Evolutionary Feature Learning for 3-D Object Recognition","S. A. A. Shah; M. Bennamoun; F. Boussaid; L. While","The University of Western Australia, Crawley, WA, Australia; The University of Western Australia, Crawley, WA, Australia; The University of Western Australia, Crawley, WA, Australia; The University of Western Australia, Crawley, WA, Australia","IEEE Access","","2018","6","","2434","2444","3-D object recognition is a challenging task for many applications including autonomous robot navigation and scene understanding. Accurate recognition relies on the selection/learning of discriminative features that are in turn used to uniquely characterize the objects. This paper proposes a novel evolutionary feature learning (EFL) technique for 3-D object recognition. The proposed novel automatic feature learning approach can operate directly on 3-D raw data, alleviating the need for data pre-processing, human expertise and/or defining a large set of parameters. EFL offers smart search strategy to learn the best features in a huge feature space to achieve superior recognition performance. The proposed technique has been extensively evaluated for the task of 3-D object recognition on four popular data sets including Washington RGB-D (low resolution 3-D Video), CIN 2D3D, Willow 2D3D and ETH-80 object data set. Reported experimental results and evaluation against existing state-of-the-art methods (e.g., unsupervised dictionary learning and deep networks) show that the proposed EFL consistently achieves superior performance on all these data sets.","","","10.1109/ACCESS.2017.2783331","The University of Western Australia; Australian Research Council Linkage; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8207425","3-D object recognition;feature learning;evolutionary algorithms","Three-dimensional displays;Object recognition;Feature extraction;Two dimensional displays;Search problems;Machine learning","feature extraction;image colour analysis;learning (artificial intelligence);object recognition","autonomous robot navigation;discriminative features;evolutionary feature learning technique;EFL;unsupervised dictionary learning;data preprocessing;3-D object recognition;automatic feature learning approach;3D raw data;smart search strategy;Washington RGB-D;Willow 2D3D;ETH-80 object data set","","4","53","","","","","IEEE","IEEE Journals"
"Automated visual inspection of target parts for train safety based on deep learning","F. Zhou; Y. Song; L. Liu; D. Zheng","School of Instrumentation Science and Optoelectronics Engineering, Beihang University, People's Republic of China; School of Instrumentation Science and Optoelectronics Engineering, Beihang University, People's Republic of China; Beijing Institute of Aerospace Control Devices, People's Republic of China; School of Instrumentation Science and Optoelectronics Engineering, Beihang University, People's Republic of China","IET Intelligent Transport Systems","","2018","12","6","550","555","Visual inspection of target parts is a common approach to ensuring train safety. However, some key parts, such as fastening bolts, do not possess sufficient feature information, because they are usually small, polluted, or obscured. These factors affect inspection accuracy and can lead to serious accidents. Therefore, traditional visual inspection relying on feature extraction cannot always meet the requirements of high-accuracy inspection. Deep learning has considerable advantages in image recognition for autonomous information mining, but it requires a considerable amount of computation. To resolve the issues mentioned above, this study proposes a method that combines traditional visual inspection with deep learning. Traditional feature extraction is used to locate the targets approximately, which makes the deep learning purposeful and efficient. A composite neural network, stacked auto-encoder convolutional neural network (SAE-CNN), is provided to further improve the training efficiency. A SAE is added to a CNN so that the network can obtain optimum results faster and more accurately. Taking the inspection of centre plate bolts in a moving freight car as an example, the overall system and specific processes are described. The study results showed satisfactory accuracy. A related analysis and comparative experiment were also conducted.","","","10.1049/iet-its.2016.0338","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8403976","","","data mining;feature extraction;inspection;learning (artificial intelligence);neural nets;railway safety;traffic engineering computing","automated visual inspection;target parts;train safety;deep learning;inspection accuracy;feature extraction;image recognition;autonomous information mining;stacked auto-encoder convolutional neural network;composite neural network;SAE-CNN;training efficiency;centre plate bolts;moving freight car","","","22","","","","","IET","IET Journals"
"Anatomical Landmark Based Deep Feature Representation for MR Images in Brain Disease Diagnosis","M. Liu; J. Zhang; D. Nie; P. Yap; D. Shen","Department of Radiology and BRIC, University of North Carolina, Chapel Hill, NC, USA; Department of Radiology and BRIC, University of North Carolina, Chapel Hill, NC, USA; Department of Radiology and BRIC, University of North Carolina, Chapel Hill, NC, USA; Department of Radiology and BRIC, University of North Carolina, Chapel Hill, NC, USA; Department of Radiology and BRIC, University of North Carolina, Chapel Hill, NC, USA","IEEE Journal of Biomedical and Health Informatics","","2018","22","5","1476","1485","Most automated techniques for brain disease diagnosis utilize hand-crafted (e.g., voxel-based or region-based) biomarkers from structural magnetic resonance (MR) images as feature representations. However, these hand-crafted features are usually high-dimensional or require regions-of-interest defined by experts. Also, because of possibly heterogeneous property between the hand-crafted features and the subsequent model, existing methods may lead to sub-optimal performances in brain disease diagnosis. In this paper, we propose a landmark-based deep feature learning (LDFL) framework to automatically extract patch-based representation from MRI for automatic diagnosis of Alzheimer's disease. We first identify discriminative anatomical landmarks from MR images in a data-driven manner, and then propose a convolutional neural network for patch-based deep feature learning. We have evaluated the proposed method on subjects from three public datasets, including the Alzheimer's disease neuroimaging initiative (ADNI-1), ADNI-2, and the minimal interval resonance imaging in alzheimer's disease (MIRIAD) dataset. Experimental results of both tasks of brain disease classification and MR image retrieval demonstrate that the proposed LDFL method improves the performance of disease classification and MR image retrieval.","","","10.1109/JBHI.2018.2791863","National Institutes of Health; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8253440","Anatomical landmarks;convolutional neural network;classification;image retrieval;brain disease diagnosis","Feature extraction;Training;Dementia;Testing;Image retrieval","biomedical MRI;brain;diseases;feature extraction;image classification;image representation;image retrieval;learning (artificial intelligence);medical image processing;neural nets;neurophysiology","deep feature representation;MR images;brain disease diagnosis;structural magnetic resonance images;hand-crafted features;landmark-based deep feature learning framework;patch-based deep feature learning;Alzheimer's disease neuroimaging initiative;brain disease classification;MR image retrieval;MIRIAD dataset;convolutional neural network","","7","49","","","","","IEEE","IEEE Journals"
"Automatic Multi-Organ Segmentation on Abdominal CT With Dense V-Networks","E. Gibson; F. Giganti; Y. Hu; E. Bonmati; S. Bandula; K. Gurusamy; B. Davidson; S. P. Pereira; M. J. Clarkson; D. C. Barratt","Department of Medical Physics and Biomedical Engineering, UCL Centre for Medical Image Computing, University College London, London, U.K.; Department of Radiology, University College Hospital Trust, London, U.K.; Department of Medical Physics and Biomedical Engineering, UCL Centre for Medical Image Computing, University College London, London, U.K.; Department of Medical Physics and Biomedical Engineering, UCL Centre for Medical Image Computing, University College London, London, U.K.; UCL Centre for Medical Imaging, University College London, London, U.K.; Division of Surgery and Interventional Science, University College London, London, U.K.; Division of Surgery and Interventional Science, University College London, London, U.K.; Institute for Liver and Digestive Health, University College London, London, U.K.; Department of Medical Physics and Biomedical Engineering, UCL Centre for Medical Image Computing, University College London, London, U.K.; Department of Medical Physics and Biomedical Engineering, UCL Centre for Medical Image Computing, University College London, London, U.K.","IEEE Transactions on Medical Imaging","","2018","37","8","1822","1834","Automatic segmentation of abdominal anatomy on computed tomography (CT) images can support diagnosis, treatment planning, and treatment delivery workflows. Segmentation methods using statistical models and multi-atlas label fusion (MALF) require inter-subject image registrations, which are challenging for abdominal images, but alternative methods without registration have not yet achieved higher accuracy for most abdominal organs. We present a registration-free deep-learning-based segmentation algorithm for eight organs that are relevant for navigation in endoscopic pancreatic and biliary procedures, including the pancreas, the gastrointestinal tract (esophagus, stomach, and duodenum) and surrounding organs (liver, spleen, left kidney, and gallbladder). We directly compared the segmentation accuracy of the proposed method to the existing deep learning and MALF methods in a cross-validation on a multi-centre data set with 90 subjects. The proposed method yielded significantly higher Dice scores for all organs and lower mean absolute distances for most organs, including Dice scores of 0.78 versus 0.71, 0.74, and 0.74 for the pancreas, 0.90 versus 0.85, 0.87, and 0.83 for the stomach, and 0.76 versus 0.68, 0.69, and 0.66 for the esophagus. We conclude that the deep-learning-based segmentation represents a registration-free method for multi-organ abdominal CT segmentation whose accuracy can surpass current methods, potentially supporting image-guided navigation in gastrointestinal endoscopy procedures.","","","10.1109/TMI.2018.2806309","Cancer Research UK; National Institute for Health Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8291609","Abdominal CT;segmentation;deep learning;pancreas;gastrointestinal tract;stomach;duodenum;esophagus;liver;spleen;kidney;gallbladder","Image segmentation;Computed tomography;Liver;Kidney;Three-dimensional displays;Pancreas","biological organs;biomedical MRI;computerised tomography;endoscopes;image fusion;image registration;image segmentation;kidney;learning (artificial intelligence);liver;medical image processing;statistical analysis","image-guided navigation;multiorgan abdominal CT segmentation;registration-free method;multicentre data;existing deep learning;endoscopic pancreatic procedures;registration-free deep-learning-based segmentation algorithm;abdominal organs;alternative methods;abdominal images;inter-subject image registrations;statistical models;segmentation methods;computed tomography images;abdominal anatomy;automatic segmentation;automatic multiorgan segmentation","","8","54","","","","","IEEE","IEEE Journals"
"Survey on person re-identification based on deep learning","K. Wang; H. Wang; M. Liu; X. Xing; T. Han","College of Automation, Harbin Engineering University, People's Republic of China; College of Automation, Harbin Engineering University, People's Republic of China; College of Automation, Harbin Engineering University, People's Republic of China; College of Automation, Harbin Engineering University, People's Republic of China; Department of Statistics, University of California, Los Angeles, USA","CAAI Transactions on Intelligence Technology","","2018","3","4","219","227","Person re-identification (Re-ID) is a fundamental subject in the field of the computer vision technologies. The traditional methods of person Re-ID have difficulty in solving the problems of person illumination, occlusion and attitude change under complex background. Meanwhile, the introduction of deep learning opens a new way of person Re-ID research and becomes a hot spot in this field. This study reviews the traditional methods of person Re-ID, then the authors focus on the related papers about different person Re-ID frameworks on the basis of deep learning, and discusses their advantages and disadvantages. Finally, they propose the direction of further research, especially the prospect of person Re-ID methods based on deep learning.","","","10.1049/trit.2018.1001","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8603081","","","computer vision;learning (artificial intelligence);image matching;image representation;feature extraction","deep learning;computer vision technologies;person illumination;occlusion;attitude change;person Re-ID research;person Re-ID methods;person reidentification;person Re-ID frameworks;person matching;feature-based method;metric-based method;person representation","","2","62","","","","","IET","IET Journals"
"Sample Efficient Learning of Path Following and Obstacle Avoidance Behavior for Quadrotors","S. Stevšić; T. Nägeli; J. Alonso-Mora; O. Hilliges","Advanced Interactive Technologies Lab, Department of Computer Science, ETH Zürich, Zürich, Switzerland; Advanced Interactive Technologies Lab, Department of Computer Science, ETH Zürich, Zürich, Switzerland; Department of Cognitive Robotics, Delft University of Technology, CD Delft, The Netherlands; Advanced Interactive Technologies Lab, Department of Computer Science, ETH Zürich, Zürich, Switzerland","IEEE Robotics and Automation Letters","","2018","3","4","3852","3859","In this letter, we propose an algorithm for the training of neural network control policies for quadrotors. The learned control policy computes control commands directly from sensor inputs and is, hence, computationally efficient. An imitation learning algorithm produces a policy that reproduces the behavior of a supervisor. The supervisor provides demonstrations of path following and collision avoidance maneuvers. Due to the generalization ability of neural networks, the resulting policy performs local collision avoidance, while following a global reference path. The algorithm uses a time-free model-predictive path-following controller as a supervisor. The controller generates demonstrations by following few example paths. This enables an easy-to-implement learning algorithm that is robust to errors of the model used in the model-predictive controller. The policy is trained on the real quadrotor, which requires collision-free exploration around the example path. An adapted version of the supervisor is used to enable exploration. Thus, the policy can be trained from a relatively small number of examples on the real quadrotor, making the training sample efficient.","","","10.1109/LRA.2018.2856922","Schweizerischer Nationalfonds zur Förderung der Wissenschaftlichen Forschung; NWO Domain Applied Sciences; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8412596","Collision avoidance;deep learning in robotics and automation","Trajectory;Training;Collision avoidance;Robot sensing systems;Prediction algorithms;Predictive models;Computational modeling","collision avoidance;generalisation (artificial intelligence);helicopters;learning (artificial intelligence);mobile robots;neurocontrollers;predictive control","collision-free exploration;supervisor;quadrotor;training sample;sample efficient learning;obstacle avoidance behavior;neural network control policies;learned control policy computes;sensor inputs;imitation learning algorithm;collision avoidance maneuvers;generalization ability;neural networks;global reference path;time-free model-predictive path;local collision avoidance;model-predictive path-following controller;learning algorithm","","3","21","","","","","IEEE","IEEE Journals"
"Deep binary constraint hashing for fast image retrieval","Y. Li; Z. Miao; J. Wang; Y. Zhang","PLA University of Science & Technology., People's Republic of China; PLA University of Science & Technology., People's Republic of China; PLA University of Science & Technology., People's Republic of China; PLA University of Science & Technology., People's Republic of China","Electronics Letters","","2018","54","1","25","27","With the development of deep hashing learning, several end-to-end deep architectures have been proposed for fast image retrieval. However, learning to hash is essentially a mixed integer nonlinear optimisation problem with the non-deterministic polynomial-time (NP)-hard nature, which makes the standard back-propagation algorithm infeasible. A novel pairwise loss function with additional binary constraint via siamese network is proposed to improve the representation ability of hash codes. Compared to previous works, we force the output of each hidden node close to −1 or +1, which can produce more compact and discriminative hash codes. Extensive experimental results demonstrate that the method can generate more favourable results than existing state-of-the-art hash function learning methods with large margins.","","","10.1049/el.2017.3620","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8278058","","","image retrieval;integer programming;nonlinear programming;computational complexity;backpropagation","deep binary constraint hashing;fast image retrieval;deep hashing learning;end-to-end deep architectures;mixed integer nonlinear optimisation problem;NP-hard nature;standard backpropagation algorithm;pairwise loss function;siamese network;representation ability;hash codes;hash function learning methods","","2","15","","","","","IET","IET Journals"
"Tropical Cyclone Intensity Estimation Using a Deep Convolutional Neural Network","R. Pradhan; R. S. Aygun; M. Maskey; R. Ramachandran; D. J. Cecil","The University of Alabama in Huntsville, AL, USA; The University of Alabama in Huntsville, AL, USA; NASA Marshall Space Flight Center Huntsville, AL, USA; NASA Marshall Space Flight Center Huntsville, AL, USA; NASA Marshall Space Flight Center Huntsville, AL, USA","IEEE Transactions on Image Processing","","2018","27","2","692","702","Tropical cyclone intensity estimation is a challenging task as it required domain knowledge while extracting features, significant pre-processing, various sets of parameters obtained from satellites, and human intervention for analysis. The inconsistency of results, significant pre-processing of data, complexity of the problem domain, and problems on generalizability are some of the issues related to intensity estimation. In this study, we design a deep convolutional neural network architecture for categorizing hurricanes based on intensity using graphics processing unit. Our model has achieved better accuracy and lower root-mean-square error by just using satellite images than 'state-of-the-art' techniques. Visualizations of learned features at various layers and their deconvolutions are also presented for understanding the learning process.","","","10.1109/TIP.2017.2766358","NASA Earth Science Technology Office and its Advanced Information Systems Technology Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8082557","Deep learning;image processing;convolutional neural networks;tropical cyclone category and intensity estimation","Tropical cyclones;Hurricanes;Feature extraction;Neural networks;Estimation;Computer architecture","feature extraction;feedforward neural nets;geophysical image processing;learning (artificial intelligence);mean square error methods;storms","deep convolutional neural network architecture;learning process;tropical cyclone intensity estimation;domain knowledge;feature extraction;graphics processing unit;root-mean-square error;satellite images","","8","36","","","","","IEEE","IEEE Journals"
"Image Classification Based on the Boost Convolutional Neural Network","S. Lee; T. Chen; L. Yu; C. Lai","Institute of Technology Management, National Chiao Tung University, Hsinchu, Taiwan; National Pilot School of Software, Yunnan University, Kunming, China; National Pilot School of Software, Yunnan University, Kunming, China; Department of Information Management, Chung Yuan Christian University, Chungli, Taiwan","IEEE Access","","2018","6","","12755","12768","Convolutional neural networks (CNNs), which are composed of multiple processing layers to learn the representations of data with multiple abstract levels, are the most successful machine learning models in recent years. However, these models can have millions of parameters and many layers, which are difficult to train, and sometimes several days or weeks are required to tune the parameters. Within this paper, we present the usage of a trained deep convolutional neural network model to extract the features of the images, and then, used the AdaBoost algorithm to assemble the Softmax classifiers into recognizable images. This method resulted in a 3% increase of accuracy of the trained CNN models, and dramatically reduced the retraining time cost, and thus, it has good application prospects.","","","10.1109/ACCESS.2018.2796722","Key Laboratory of Software Engineering of Yunnan Province; Applied Basic Research Foundation of Yunnan Province; Yunnan Provincial Innovation Team; Natural Science Foundation of China; Ministry of Science and Technology of Taiwan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8269288","Convolutional neural network;ensemble learning;deep learning;boosting","Machine learning;Neurons;Convolution;Feature extraction;Biological neural networks;Computational modeling","feedforward neural nets;image classification;learning (artificial intelligence)","trained CNN models;image classification;convolutional neural networks;multiple processing layers;multiple abstract levels;successful machine learning models;trained deep convolutional neural network model;recognizable images","","10","20","","","","","IEEE","IEEE Journals"
"Quality Robust Mixtures of Deep Neural Networks","S. F. Dodge; L. J. Karam","Image, Video, and Usability Laboratory, Schoolof Electrical, Computer and Energy Engineering, Arizona State University, Tempe, AZ, USA; Image, Video, and Usability Laboratory, Schoolof Electrical, Computer and Energy Engineering, Arizona State University, Tempe, AZ, USA","IEEE Transactions on Image Processing","","2018","27","11","5553","5562","We study deep neural networks for classification of images with quality distortions. Deep network performance on poor quality images can be greatly improved if the network is fine-tuned with distorted data. However, it is difficult for a single fine-tuned network to perform well across multiple distortion types. We propose a mixture of experts-based ensemble method, MixQualNet, that is robust to multiple different types of distortions. The “experts” in our model are trained on a particular type of distortion. The output of the model is a weighted sum of the expert models, where the weights are determined by a separate gating network. The gating network is trained to predict weights for a particular distortion type and level. During testing, the network is blind to the distortion level and type, yet can still assign appropriate weights to the expert models. In order to reduce the computational complexity, we introduce weight sharing into the MixQualNet. We utilize the TreeNet weight sharing architecture as well as introduce the Inverted TreeNet architecture. While both weight sharing architectures reduce memory requirements, our proposed Inverted TreeNet also achieves improved accuracy.","","","10.1109/TIP.2018.2855966","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8410945","Saliency;human eye fixations;convolutional neural networks;deep learning","Distortion;Training;Neural networks;Robustness;Noise measurement;Computational modeling;Testing","computational complexity;image classification;learning (artificial intelligence);neural nets","weight sharing architectures;quality robust mixtures;deep neural networks;quality distortions;deep network performance;distorted data;fine-tuned network;multiple distortion types;weighted sum;distortion level;TreeNet weight sharing architecture;MixQualNet;expert-based ensemble method;image classification;gating network","","4","33","","","","","IEEE","IEEE Journals"
"A Massively Parallel Deep Rule-Based Ensemble Classifier for Remote Sensing Scenes","X. Gu; P. P. Angelov; C. Zhang; P. M. Atkinson","School of Computing and Communications, Lancaster University, Lancaster, U.K.; School of Computing and Communications, Lancaster University, Lancaster, U.K.; Lancaster Environment Centre, Lancaster University, Lancaster, U.K.; Lancaster Environment Centre, Lancaster University, Lancaster, U.K.","IEEE Geoscience and Remote Sensing Letters","","2018","15","3","345","349","In this letter, we propose a new approach for remote sensing scene classification by creating an ensemble of the recently introduced massively parallel deep (fuzzy) rule-based (DRB) classifiers trained with different levels of spatial information separately. Each DRB classifier consists of a massively parallel set of human-interpretable, transparent zero-order fuzzy IF...THEN... rules with a prototype-based nature. The DRB classifier can self-organize “from scratch” and self-evolve its structure. By employing the pretrained deep convolution neural network as the feature descriptor, the proposed DRB ensemble is able to exhibit human-level performance through a transparent and parallelizable training process. Numerical examples using benchmark data set demonstrate the superior accuracy of the proposed approach together with human-interpretable fuzzy rules autonomously generated by the DRB classifier.","","","10.1109/LGRS.2017.2787421","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8281516","Deep learning (DL);fuzzy rules;rule-based classifier;scene classification","Training;Image segmentation;Prototypes;Remote sensing;Semantics;Feature extraction;Sensors","feedforward neural nets;fuzzy set theory;geophysical image processing;image classification;learning (artificial intelligence);parallel processing;remote sensing","DRB classifier;massively parallel set;pretrained deep convolution neural network;DRB ensemble;human-level performance;transparent training process;parallelizable training process;human-interpretable fuzzy rules;ensemble classifier;remote sensing scene classification;massively parallel deep rule","","3","20","","","","","IEEE","IEEE Journals"
"Evolving Image Classification Architectures With Enhanced Particle Swarm Optimisation","B. Fielding; L. Zhang","Department of Computer and Information Sciences, Faculty of Engineering and Environment, Northumbria University, Newcastle upon Tyne, U.K.; Department of Computer and Information Sciences, Faculty of Engineering and Environment, Northumbria University, Newcastle upon Tyne, U.K.","IEEE Access","","2018","6","","68560","68575","Convolutional Neural Networks (CNNs) have become the de facto technique for image feature extraction in recent years. However, their design and construction remains a complicated task. As more developments are made in progressing the internal components of CNNs, the task of assembling them effectively from core components becomes even more arduous. To overcome these barriers, we propose the Swarm Optimized Block Architecture, combined with an enhanced adaptive particle swarm optimization (PSO) algorithm for deep CNN model evolution. The enhanced PSO model employs adaptive acceleration coefficients generated using several cosine annealing mechanisms to overcome stagnation. Specifically, we propose a combined training and structure optimization process for deep CNN model generation, where the proposed PSO model is utilized to explore a bespoke search space defined by a simplified block-based structure. The proposed PSO model not only devises deep networks specifically for image classification, but also builds and pre-trains models for transfer learning tasks. To significantly reduce the hardware and computational cost of the search, the devised CNN model is optimized and trained simultaneously, using a weight sharing mechanism and a final fine-tuning process. Our system compares favorably with related research for optimized deep network generation. It achieves an error rate of 4.78% on the CIFAR-10 image classification task, with 34 hours of combined optimization and training, and an error rate of 25.42% on the CIFAR-100 image data set in 36 hours. All experiments were performed on a single NVIDIA GTX 1080Ti consumer GPU.","","","10.1109/ACCESS.2018.2880416","RPPtv Ltd.; Northumbria University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8533601","Computer vision;convolutional neural networks;deep learning;evolutionary computation;image classification;particle swarm optimization","Computer architecture;Optimization;Task analysis;Training;Computational modeling;Feature extraction;Adaptation models","convolutional neural nets;feature extraction;image classification;learning (artificial intelligence);particle swarm optimisation;search problems","deep networks;transfer learning tasks;weight sharing mechanism;optimized deep network generation;CIFAR-10 image classification task;CIFAR-100 image data;image feature extraction;enhanced adaptive particle swarm optimization algorithm;deep CNN model evolution;enhanced PSO model;adaptive acceleration coefficients;cosine annealing mechanisms;structure optimization process;deep CNN model generation;bespoke search space;swarm optimized block architecture;convolutional neural networks;particle swarm optimisation;CNN model","","3","43","","","","","IEEE","IEEE Journals"
"Multimodal Deep Embedding via Hierarchical Grounded Compositional Semantics","Y. Zhuang; J. Song; F. Wu; X. Li; Z. Zhang; Y. Rui","College of Computer Science and Technology, Zhejiang University, Hangzhou, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China; Department of Computer Science, Binghamton University, Binghamton, NY, USA; Microsoft Research Asia, Beijing, China","IEEE Transactions on Circuits and Systems for Video Technology","","2018","28","1","76","89","For a number of important problems, isolated semantic representations of individual syntactic words or visual objects do not suffice, but instead a compositional semantic representation is required; for example, a literal phrase or a set of spatially concurrent objects. In this paper, we aim to harness the existing image-sentence databases to exploit the compositional nature of image-sentence data for multimodal deep embedding. In particular, we propose an approach called hierarchical-alike (bottom-up two layers) multimodal grounded compositional semantics (hiMoCS) learning. The proposed hiMoCS systemically captures the compositional semantic connotation of multimodal data in the setting of hierarchical-alike deep learning by modeling the inherent correlations between two modalities of collaboratively grounded semantics, such as the textual entity (with its describing attribute) and visual object, the phrase (e.g., subject-verb-object triplet), and spatially concurrent objects. We argue that hiMoCS is more appropriate to reflect the multimodal compositional semantics of the image and its narrative textual sentence, which are strongly coupled. We evaluate hiMoCS on the several benchmark data sets and show that the utilization of the hiMoCS (textual entities and visual objects, textual phrase, and spatially concurrent objects) achieves a much better performance than only using the flat grounded compositional semantics.","","","10.1109/TCSVT.2016.2606648","National Basic Research Program of China; NSFC; China Knowledge Centre for Engineering Sciences and Technology; Fundamental Research Funds for the Central Universities and the Zhejiang Provincial Engineering Center on Media Data Cloud Processing and Analysis; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7562283","Compositional semantics;multimodal analysis;multimodal embedding","Semantics;Visualization;Bicycles;Correlation;Machine learning;Buildings;Feature extraction","image processing;information retrieval;learning (artificial intelligence);natural language processing;object recognition;text analysis","image-sentence databases;image-sentence data;compositional nature;literal phrase;compositional semantic representation;individual syntactic words;isolated semantic representations;multimodal deep embedding;flat grounded compositional semantics;textual phrase;visual objects;benchmark data sets;narrative textual sentence;multimodal compositional semantics;spatially concurrent objects;subject-verb-object triplet;textual entity;collaboratively grounded semantics;hierarchical-alike deep learning;multimodal data;compositional semantic connotation;hiMoCS;multimodal grounded compositional semantics","","2","50","","","","","IEEE","IEEE Journals"
"Automatic Magnetic Resonance Image Prostate Segmentation Based on Adaptive Feature Learning Probability Boosting Tree Initialization and CNN-ASM Refinement","B. He; D. Xiao; Q. Hu; F. Jia","Research Laboratory for Medical Imaging and Digital Surgery, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Research Laboratory for Medical Imaging and Digital Surgery, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Research Laboratory for Medical Imaging and Digital Surgery, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Research Laboratory for Medical Imaging and Digital Surgery, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China","IEEE Access","","2018","6","","2005","2015","This paper proposes a method based on the active shape model (ASM) to segment the prostate in magnetic resonance (MR) images. Due to the great variability in appearance among different boundaries of the prostate and among subjects, the traditional ASM is weak in MR image prostate segmentation. To address these limitations, we investigated a novel ASM-based method by incorporating deep feature learning into our previous liver segmentation framework. First, an adaptive feature learning probability boosting tree (AFL-PBT) based on both simple handcrafted features and deep learned features was developed for prostate pre-segmentation and for further shape model initialization. The proposed AFL-PBT classifier also provided a boundary searching band, which made the ASM less sensitive to model initialization. Then, the convolutional neutral network (CNN) deep learning method was used to train a boundary model, which separated voxels into three types: near, inside, and outside the boundary. A three-level ASM based on the CNN boundary model was employed for the final segmentation refinement. On MICCAI PROMISE12 test data sets, the proposed method yielded a mean Dice score of 84% with a standard deviation of 4%. The experimental results demonstrated that the proposed method outperformed other ASM-based prostate MRI segmentation methods and achieved a level of accuracy comparable to that of state-of-the-art methods.","","","10.1109/ACCESS.2017.2781278","National Key Research and Development Program; NSFC-Shenzhen Union; Guangdong Scientific and Technology Program; Shenzhen Key Basic Science Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8170205","Prostate segmentation;probability boosting tree;convolutional neural network;active shape model","Image segmentation;Training;Feature extraction;Boosting;Adaptation models;Shape","biological organs;biomedical MRI;image classification;image segmentation;learning (artificial intelligence);liver;medical image processing;neural nets;probability","adaptive feature learning probability boosting tree initialization;CNN-ASM refinement;active shape model;deep learned features;shape model initialization;AFL-PBT classifier;boundary searching band;CNN boundary model;prostate MRI segmentation methods;automatic magnetic resonance image prostate segmentation;liver segmentation framework;convolutional neutral network;deep learning method;MICCAI PROMISE12 test data sets","","4","33","","","","","IEEE","IEEE Journals"
"SHPR-Net: Deep Semantic Hand Pose Regression From Point Clouds","X. Chen; G. Wang; C. Zhang; T. Kim; X. Ji","Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Electrical and Electronic Engineering, Imperial College London, London, U.K.; Department of Automation, Tsinghua University, Beijing, China","IEEE Access","","2018","6","","43425","43439","3-D hand pose estimation is an essential problem for human-computer interaction. Most of the existing depth-based hand pose estimation methods consume 2-D depth map or 3-D volume via 2-D/3-D convolutional neural networks. In this paper, we propose a deep semantic hand pose regression network (SHPR-Net) for hand pose estimation from point sets, which consists of two subnetworks: a semantic segmentation subnetwork and a hand pose regression subnetwork. The semantic segmentation network assigns semantic labels for each point in the point set. The pose regression network integrates the semantic priors with both input and late fusion strategy and regresses the final hand pose. Two transformation matrices are learned from the point set and applied to transform the input point cloud and inversely transform the output pose, respectively, which makes the SHPR-Net more robust to geometric transformations. Experiments on NYU, ICVL, and MSRA hand pose data sets demonstrate that our SHPR-Net achieves high performance on par with the start-of-the-art methods. We also show that our method can be naturally extended to hand pose estimation from the multi-view depth data and achieves further improvement on the NYU data set.","","","10.1109/ACCESS.2018.2863540","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8425735","Human computer interaction;hand pose estimation;deep learning;machine learning;point cloud","Three-dimensional displays;Semantics;Pose estimation;Feature extraction;Machine learning;Two dimensional displays;Transforms","computer vision;feedforward neural nets;image fusion;image segmentation;matrix algebra;pose estimation;regression analysis","semantic labels;2D depth map;3D convolutional neural networks;depth-based hand pose estimation methods;semantic segmentation network;2D convolutional neural networks;regression subnetwork;semantic segmentation subnetwork;point clouds;deep semantic hand pose regression;SHPR-Net achieves high performance;MSRA hand;input point cloud;point set;semantic priors","","3","66","","","","","IEEE","IEEE Journals"
"Patient2Vec: A Personalized Interpretable Deep Representation of the Longitudinal Electronic Health Record","J. Zhang; K. Kowsari; J. H. Harrison; J. M. Lobo; L. E. Barnes","Department of Systems and Information Engineering, University of Virginia, Charlottesville, VA, USA; Department of Systems and Information Engineering, University of Virginia, Charlottesville, VA, USA; Department of Public Health Sciences, University of Virginia, Charlottesville, VA, USA; Department of Public Health Sciences, University of Virginia, Charlottesville, VA, USA; Department of Systems and Information Engineering, University of Virginia, Charlottesville, VA, USA","IEEE Access","","2018","6","","65333","65346","The wide implementation of electronic health record (EHR) systems facilitates the collection of large-scale health data from real clinical settings. Despite the significant increase in adoption of EHR systems, these data remain largely unexplored, but present a rich data source for knowledge discovery from patient health histories in tasks, such as understanding disease correlations and predicting health outcomes. However, the heterogeneity, sparsity, noise, and bias in these data present many complex challenges. This complexity makes it difficult to translate potentially relevant information into machine learning algorithms. In this paper, we propose a computational framework, Patient2Vec, to learn an interpretable deep representation of longitudinal EHR data, which is personalized for each patient. To evaluate this approach, we apply it to the prediction of future hospitalizations using real EHR data and compare its predictive performance with baseline methods. Patient2Vec produces a vector space with meaningful structure, and it achieves an area under curve around 0.799, outperforming baseline methods. In the end, the learned feature importance can be visualized and interpreted at both the individual and population levels to bring clinical insights.","","","10.1109/ACCESS.2018.2875677","Jeffress Trust Award in Interdisciplinary Science; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8490816","Attention mechanism;gated recurrent unit;hospitalization;longitudinal electronic health record;personalization;representation learning","Logic gates;Medical services;Task analysis;Recurrent neural networks;Electronic medical records;Machine learning;Natural language processing","data acquisition;data mining;diseases;electronic health records;health care;learning (artificial intelligence)","patient health histories;disease correlations;machine learning algorithms;Patient2Vec;longitudinal EHR data;personalized interpretable deep representation;longitudinal electronic health record;electronic health record systems;EHR systems;large-scale health data collection;knowledge discovery;health outcomes;hospitalizations","","","42","","","","","IEEE","IEEE Journals"
"cC-GAN: A Robust Transfer-Learning Framework for HEp-2 Specimen Image Segmentation","Y. Li; L. Shen","College of Computer Science and Software Engineering, Computer Vision Institute, Shenzhen University, Shenzhen, China; College of Computer Science and Software Engineering, Computer Vision Institute, Shenzhen University, Shenzhen, China","IEEE Access","","2018","6","","14048","14058","Human epithelial type 2 (HEp-2) cell images play an important role for the detection of antinuclear autoantibodies in autoimmune diseases. As the HEp-2 cell has hundreds of different patterns, none of currently available HEp-2 datasets contain all of the types. Therefore, existing automatic processing systems for HEp-2 cells, e.g., cell segmentation and classification, needs to be transferred between different data sets. However, the performances of transferred system often dramatically decrease, especially when transferring supervised-approaches, e.g., deep learning network, from large dataset to the small but similar ones. In this paper, a novel transfer-learning framework using generative adversarial networks (cC-GAN) is proposed for robust segmentation of different HEp-2 datasets. The proposed cC-GAN tries to solve the overfitting problem of most deep learning networks and improves their transfer-capacity. An improved U-net, so-called Residual U-net (RU-net), is developed to work as the generator for cC-GAN model. The cC-GAN was first trained and tested using I3A dataset and then directly evaluated using MIVIA dataset, which is much smaller than I3A. The segmentation result demonstrates the excellent transferring-capacity of our cC-GAN framework, i.e., a new state-of-the-art segmentation accuracy of 75.27% was achieved on MIVIA without finetuning.","","","10.1109/ACCESS.2018.2808938","Natural Science Foundation of China; Science Foundation of Shenzhen; China Postdoctoral Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8301400","Cell segmentation;generative adversarial networks;fully convolutional network","Image segmentation;Gallium nitride;Generators;Computer architecture;Microprocessors;Training;Machine learning","cellular biophysics;diseases;image classification;image segmentation;learning (artificial intelligence);medical image processing;object detection","robust segmentation;deep learning network;transfer-capacity;cC-GAN model;cC-GAN framework;robust transfer-learning framework;HEp-2 specimen image segmentation;human epithelial type 2 cell images;HEp-2 cell;automatic processing systems;cell segmentation;transferred system;novel transfer-learning framework;generative adversarial networks;cell classification;HEp-2 datasets;antinuclear autoantibodies detection;autoimmune diseases;overfitting problem;improved U-net;residual U-net;RU-net;MIVIA dataset","","12","40","","","","","IEEE","IEEE Journals"
"Backpropagating Through the Air: Deep Learning at Physical Layer Without Channel Models","V. Raj; S. Kalyani","Department of Electrical Engineering, IIT Madras, Chennai, India; Department of Electrical Engineering, IIT Madras, Chennai, India","IEEE Communications Letters","","2018","22","11","2278","2281","Recent developments in applying deep learning techniques to train end-to-end communication systems have shown great promise in improving the overall performance of the system. However, most of the current methods for applying deep learning to train physical-layer characteristics assume the availability of the explicit channel model. Training a neural network requires the availability of the functional form all the layers in the network to calculate gradients for optimization. The unavailability of gradients in a physical channel forced previous works to adopt simulation-based strategies to train the network and then fine tune only the receiver part with the actual channel. In this letter, we present a practical method to train an end-to-end communication system without relying on explicit channel models. By utilizing stochastic perturbation techniques, we show that the proposed method can train a deep learning-based communication system in real channel without any assumption on channel models.","","","10.1109/LCOMM.2018.2868103","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8452950","Artificial neural networks;communication systems;optimization","Training;Communication systems;Receivers;Channel models;Machine learning;Transmitters;Neural networks","backpropagation;gradient methods;neural nets;optimisation;perturbation techniques;stochastic processes","physical layer;channel models;end-to-end communication system;neural network;gradients;deep learning-based communication system;backpropagation;optimization;simulation-based strategies;stochastic perturbation techniques","","10","15","","","","","IEEE","IEEE Journals"
"Pairwise Identity Verification via Linear Concentrative Metric Learning","L. Zheng; S. Duffner; K. Idrissi; C. Garcia; A. Baskurt","Université de Lyon, CNRS, INSA-Lyon, LIRIS, UMR5205, Lyon, France; Université de Lyon, CNRS, INSA-Lyon, LIRIS, UMR5205, Lyon, France; Université de Lyon, CNRS, INSA-Lyon, LIRIS, UMR5205, Lyon, France; Université de Lyon, CNRS, INSA-Lyon, LIRIS, UMR5205, Lyon, France; Université de Lyon, CNRS, INSA-Lyon, LIRIS, UMR5205, Lyon, France","IEEE Transactions on Cybernetics","","2018","48","1","324","335","This paper presents a study of metric learning systems on pairwise identity verification, including pairwise face verification and pairwise speaker verification, respectively. These problems are challenging because the individuals in training and testing are mutually exclusive, and also due to the probable setting of limited training data. For such pairwise verification problems, we present a general framework of metric learning systems and employ the stochastic gradient descent algorithm as the optimization solution. We have studied both similarity metric learning and distance metric learning systems, of either a linear or shallow nonlinear model under both restricted and unrestricted training settings. Extensive experiments demonstrate that with limited training pairs, learning a linear system on similar pairs only is preferable due to its simplicity and superiority, i.e., it generally achieves competitive performance on both the labeled faces in the wild face dataset and the NIST speaker dataset. It is also found that a pretrained deep nonlinear model helps to improve the face verification results significantly.","","","10.1109/TCYB.2016.2634011","China Scholarship Council; Laboratoire d’InfoRmatique en Image et Systèmes d’information; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7786904","Face verification;identity verification;metric learning;pairwise metric;siamese neural networks;speaker verification","Measurement;Face;Training;Learning systems;Training data;Data models;Cost function","face recognition;gradient methods;image representation;learning (artificial intelligence);probability;speaker recognition","pairwise identity verification;linear concentrative metric learning;pairwise face verification;pairwise speaker verification;training data;pairwise verification problems;stochastic gradient descent algorithm;similarity metric learning;distance metric learning systems;restricted training settings;unrestricted training settings;training pairs;linear system;face verification results","","2","74","","","","","IEEE","IEEE Journals"
"Deep Learning for Spatio-Temporal Modeling of Dynamic Spontaneous Emotions","D. A. AL CHANTI; A. Caplier","Image and Signal Processing, GIPSA-Lab, 84297 Saint Martin d'Heres, Rhône-Alpes France (e-mail: dawood.alchanti@gmail.com); Image and Signal Processing, GIPSA-Lab, 84297 Saint Martin d'Heres, Rhône-Alpes France (e-mail: alice.caplier@gipsa-lab.fr)","IEEE Transactions on Affective Computing","","2018","PP","99","1","1","Facial expressions involve dynamic morphological changes in a face, conveying information about the expresser's feelings. Each emotion has a specific spatial deformation over the face and temporal profile with distinct time segments. We aim at modeling the human dynamic emotional behavior by taking into consideration the visual content of the face and its evolution. But emotions can both speed-up or slow-down, therefore it is important to incorporate information from the local neighborhood frames (short-term dependencies) and the global setting (long-term dependencies) to summarize the segment context despite of its time variations. A 3D-Convolutional Neural Networks (3D-CNN) is used to learn early local spatiotemporal features. The 3D-CNN is designed to capture subtle spatiotemporal changes that may occur on the face. Then a Convolutional-Long-Short-Term-Memory (ConvLSTM) network is designed to learn semantic information by taking into account longer spatiotemporal dependencies. The ConvLSTM network helps considering the global visual saliency of the expression. That is locating and learning features in space and time that stand out from their local neighbors in order to signify distinctive facial expression features along the entire sequence. Non-variant representations based on aggregating global spatiotemporal features at increasingly fine resolutions are then done using a weighted Spatial Pyramid Pooling layer.","","","10.1109/TAFFC.2018.2873600","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8481451","3D-CNN;ConvLSTM;Deep Learning;Dynamic Emotion;Facial Expression;SPP-net;Spatiotemporal Features","Spatiotemporal phenomena;Visualization;Face recognition;Face;Videos;Machine learning;Computational modeling","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Real-time detection of distracted driving based on deep learning","D. Tran; H. Manh Do; W. Sheng; H. Bai; G. Chowdhary","School of Electrical and Computer Engineering, Oklahoma State University, USA; School of Electrical and Computer Engineering, Oklahoma State University, USA; School of Electrical and Computer Engineering, Oklahoma State University, USA; School of Mechanical and Aerospace Engineering, Oklahoma State University, USA; Department of Agricultural and Biological Engineering, University of Illinois at Urbana-Champaign, USA","IET Intelligent Transport Systems","","2018","12","10","1210","1219","Driver distraction is a leading factor in car crashes. With a goal to reduce traffic accidents and improve transportation safety, this study proposes a driver distraction detection system which identifies various types of distractions through a camera observing the driver. An assisted driving testbed is developed for the purpose of creating realistic driving experiences and validating the distraction detection algorithms. The authors collected a dataset which consists of images of the drivers in both normal and distracted driving postures. Four deep convolutional neural networks including VGG-16, AlexNet, GoogleNet, and residual network are implemented and evaluated on an embedded graphic processing unit platform. In addition, they developed a conversational warning system that alerts the driver in real-time when he/she does not focus on the driving task. Experimental results show that the proposed approach outperforms the baseline one which has only 256 neurons in the fully-connected layers. Furthermore, the results indicate that the GoogleNet is the best model out of the four for distraction detection in the driving simulator testbed.","","","10.1049/iet-its.2018.5172","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8532040","","","cameras;driver information systems;graphics processing units;learning (artificial intelligence);neural nets;object detection;road accidents;road safety;road traffic","driving simulator testbed;fully-connected layers;GoogleNet;AlexNet;VGG-16;camera;deep convolutional neural networks;traffic accident reduction;real-time detection;driving task;conversational warning system;embedded graphic processing unit platform;residual network;distracted driving postures;distraction detection algorithms;realistic driving experiences;assisted driving testbed;driver distraction detection system;transportation safety;car crashes;deep learning","","2","","","","","","IET","IET Journals"
"Learning Object Grasping for Soft Robot Hands","C. Choi; W. Schwarting; J. DelPreto; D. Rus","Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA","IEEE Robotics and Automation Letters","","2018","3","3","2370","2377","We present a three-dimensional deep convolutional neural network (3D CNN) approach for grasping unknown objects with soft hands. Soft hands are compliant and capable of handling uncertainty in sensing and actuation, but come at the cost of unpredictable deformation of the soft fingers. Traditional model-driven grasping approaches, which assume known models for objects, robot hands, and stable grasps with expected contacts, are inapplicable to such soft hands, since predicting contact points between objects and soft hands is not straightforward. Our solution adopts a deep CNN approach to find good caging grasps for previously unseen objects by learning effective features and a classifier from point cloud data. Unlike recent CNN models applied to robotic grasping which have been trained on 2D or 2.5D images and limited to a fixed top grasping direction, we exploit the power of a 3D CNN model to estimate suitable grasp poses from multiple grasping directions (top and side directions) and wrist orientations, which has great potential for geometry-related robotic tasks. Our soft hands guided by the 3D CNN algorithm show 87% successful grasping on previously unseen objects. A set of comparative evaluations shows the robustness of our approach with respect to noise and occlusions.","","","10.1109/LRA.2018.2810544","Boeing; National Science Foundation; National Science Foundation Graduate Research Fellowship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8304630","Perception for grasping and manipulation;deep learning in robotics and automation","Grasping;Three-dimensional displays;Robot sensing systems;Wrist;Solid modeling;Data models","feedforward neural nets;grippers;learning (artificial intelligence);robot vision","object grasping;soft robot hands;three-dimensional deep convolutional neural network approach;soft fingers;traditional model-driven grasping approaches;stable grasps;deep CNN approach;good caging grasps;unseen objects;recent CNN models;robotic grasping;fixed top grasping direction;3D CNN model;multiple grasping directions","","5","31","","","","","IEEE","IEEE Journals"
"Exploiting Target Data to Learn Deep Convolutional Networks for Scene-Adapted Human Detection","S. Wu; S. Wang; R. Laganière; C. Liu; H. Wong; Y. Xu","School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; VIVA Research Laboratory, School of Electrical Engineering and Computer Science, University of Ottawa, Ottawa, ON, Canada; Department of Computer Science, City University of Hong Kong, Hong Kong; Department of Computer Science, City University of Hong Kong, Hong Kong; School of Computer Science and Engineering, South China University of Technology, Guangzhou, China","IEEE Transactions on Image Processing","","2018","27","3","1418","1432","The difference between sample distributions of public data sets and specific scenes can be very significant. As a result, the deployment of generic human detectors in real-world scenes most often leads to sub-optimal detection performance. To avoid the labor-intensive task of manual annotations, we propose a semi-supervised approach for training deep convolutional networks on partially labeled data. To exploit a large amount of unlabeled target data, the knowledge learnt from public data sets is transferred to new model training by adapting an auxiliary detector to the target scene. We hypothesize that the components of the auxiliary detector capture essential human characteristics useful for constructing a scene-adapted detector. A selective ensemble algorithm is proposed to select a subset of the components relevant to the target scene for recombination. The resulting model is applied for collecting high-confidence samples from unlabeled target data. Furthermore, a deep convolutional network is trained by progressively labeling and selecting new training samples in a self-paced way. The detailed experimental evaluation verifies the effectiveness and superiority of the proposed approach in scene-specific human detection.","","","10.1109/TIP.2017.2779271","National Natural Science Foundation of China; Natural Science Fundation of Guangdong Province; Research Grants Council of the Hong Kong Special Administration Region; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8125769","Human detection;selective ensemble;self-paced learning;convolutional network","Detectors;Training;Feature extraction;Adaptation models;Data models;Labeling","data handling;feedforward neural nets;learning (artificial intelligence);object detection","public data sets;model training;target scene;resulting model;high-confidence samples;unlabeled target data;deep convolutional network;training samples;scene-specific human detection;sample distributions;specific scenes;generic human detectors;real-world scenes;semisupervised approach;partially labeled data;auxiliary detector;suboptimal detection performance;essential human characteristics;scene-adapted detector;selective ensemble algorithm","","3","62","","","","","IEEE","IEEE Journals"
"Fine-grained recognition of maritime vessels and land vehicles by deep feature embedding","B. Solmaz; E. Gundogdu; V. Yucesoy; A. Koç; A. A. Alatan","Aselsan Research Center, Turkey; Aselsan Research Center, Turkey; Aselsan Research Center, Turkey; Aselsan Research Center, Turkey; Department of Electrical and Electronics Engineering and Center for Image Analysis (OGAM), Middle East Technical University, Turkey","IET Computer Vision","","2018","12","8","1121","1132","Recent advances in large-scale image and video analysis have empowered the potential capabilities of visual surveillance systems. In particular, deep learning-based approaches bring in substantial benefits in solving certain computer vision problems such as fine-grained object recognition. Here, the authors mainly concentrate on classification and identification of maritime vessels and land vehicles, which are the key constituents of visual surveillance systems. Employing publicly available data sets for maritime vessels and land vehicles, the authors aim to improve visual recognition. Specifically, the authors focus on five tasks regarding visual recognition; coarse-grained classification, fine-grained classification, coarse-grained retrieval, fine-grained retrieval, and verification. To increase the performance in these tasks, the authors utilise a multi-task learning framework and present a novel loss function which simultaneously considers deep feature learning and classification by exploiting the available hierarchical labels of individual samples and the global statistics of distances between the data pairs. The authors observe that the proposed multi-task learning model improves the fine-grained recognition performance on MARVEL and Stanford Cars data sets, compared to training of a model targeting a single recognition task.","","","10.1049/iet-cvi.2018.5187","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8555966","","","image classification;learning (artificial intelligence);marine vehicles;object recognition;statistical analysis;traffic engineering computing;video retrieval","MARVEL data set;Stanford Cars data set;data pairs;hierarchical individual sample label;global statistics;loss function;multitask learning framework;verification task;fine-grained retrieval task;coarse-grained retrieval task;fine-grained classification task;coarse-grained classification task;visual recognition;land vehicle identification;land vehicle classification;maritime vessel identification;maritime vessel classification;fine-grained object recognition;computer vision problems;deep learning-based approaches;visual surveillance systems;large-scale video analysis;large-scale image analysis;deep feature embedding;fine-grained land vehicle recognition;fine-grained maritime vessel recognition","","","56","","","","","IET","IET Journals"
"Beyond Bilinear: Generalized Multimodal Factorized High-Order Pooling for Visual Question Answering","Z. Yu; J. Yu; C. Xiang; J. Fan; D. Tao","Key Laboratory of Complex Systems Modeling and Simulation, School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China; Key Laboratory of Complex Systems Modeling and Simulation, School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China; Key Laboratory of Complex Systems Modeling and Simulation, School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China; Department of Computer Science, University of North Carolina at Charlotte, Charlotte, NC, USA; UBTECH Sydney Artificial Intelligence Centre, Faculty of Engineering and Information Technologies, University of Sydney, Darlington, NSW, Australia","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","12","5947","5959","Visual question answering (VQA) is challenging, because it requires a simultaneous understanding of both visual content of images and textual content of questions. To support the VQA task, we need to find good solutions for the following three issues: 1) fine-grained feature representations for both the image and the question; 2) multimodal feature fusion that is able to capture the complex interactions between multimodal features; and 3) automatic answer prediction that is able to consider the complex correlations between multiple diverse answers for the same question. For fine-grained image and question representations, a “coattention” mechanism is developed using a deep neural network (DNN) architecture to jointly learn the attentions for both the image and the question, which can allow us to reduce the irrelevant features effectively and obtain more discriminative features for image and question representations. For multimodal feature fusion, a generalized multimodal factorized high-order pooling approach (MFH) is developed to achieve more effective fusion of multimodal features by exploiting their correlations sufficiently, which can further result in superior VQA performance as compared with the state-of-the-art approaches. For answer prediction, the Kullback-Leibler divergence is used as the loss function to achieve precise characterization of the complex correlations between multiple diverse answers with the same or similar meaning, which can allow us to achieve faster convergence rate and obtain slightly better accuracy on answer prediction. A DNN architecture is designed to integrate all these aforementioned modules into a unified model for achieving superior VQA performance. With an ensemble of our MFH models, we achieve the state-of-the-art performance on the large-scale VQA data sets and win the runner-up in VQA Challenge 2017.","","","10.1109/TNNLS.2018.2817340","National Natural Science Foundation of China; Natural Science Foundation of Zhejiang Province; Australian Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8334194","Coattention learning;deep learning;multimodal feature fusion;visual question answering (VQA)","Visualization;Task analysis;Feature extraction;Correlation;Natural languages;Computational modeling;Knowledge discovery","computer vision;feature extraction;image classification;image retrieval;learning (artificial intelligence);natural language processing;neural net architecture;question answering (information retrieval)","answer prediction;complex correlations;multiple diverse answers;generalized multimodal factorized high-order pooling;visual question answering;VQA task;fine-grained feature representations;fine-grained image;question representations;deep neural network architecture;multimodal feature fusion;MFH models;Kullback-Leibler divergence;DNN architecture","","8","51","","","","","IEEE","IEEE Journals"
"Exploiting Spatio-Temporal Structure With Recurrent Winner-Take-All Networks","E. Santana; M. S. Emigh; P. Zegers; J. C. Principe","Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA; Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA; Facultad de Ingenieria y Ciencias Aplicadas, Universidad de los Andes, Santiago, Chile; Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","8","3738","3746","We propose a convolutional recurrent neural network (ConvRNNs), with winner-take-all (WTA) dropout for high-dimensional unsupervised feature learning in multidimensional time series. We apply the proposed method for object recognition using temporal context in videos and obtain better results than comparable methods in the literature, including the deep predictive coding networks (DPCNs) previously proposed by Chalasani and Principe. Our contributions can be summarized as a scalable reinterpretation of the DPCNs trained end-to-end with backpropagation through time, an extension of the previously proposed WTA autoencoders to sequences in time, and a new technique for initializing and regularizing ConvRNNs.","","","10.1109/TNNLS.2017.2735903","University of Florida; Office of Naval Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8024156","Convolutional recurrent neural networks (ConvRNNs);deep learning;object recognition;unsupervised learning;winner-take-all (WTA)","Convolutional codes;Videos;Computer architecture;Object recognition;Predictive coding;Training;Feature extraction","backpropagation;feature extraction;image coding;object recognition;recurrent neural nets;spatiotemporal phenomena;time series;unsupervised learning","spatio-temporal structure;recurrent winner-take-all networks;convolutional recurrent neural network;winner-take-all dropout;high-dimensional unsupervised feature;multidimensional time series;object recognition;temporal context;deep predictive coding networks;scalable reinterpretation;WTA autoencoders;DPCN;ConvRNN;backpropagation","","1","48","","","","","IEEE","IEEE Journals"
"Deep Neural Network Structured Sparse Coding for Online Processing","H. Zhao; S. Ding; X. Li; H. Huang","The School of Computer Science and Engineering, The University of Aizu, Aizuwakamatsu, Japan; The School of Computer Science and Engineering, The University of Aizu, Aizuwakamatsu, Japan; The School of Computer Science and Engineering, The University of Aizu, Aizuwakamatsu, Japan; The School of Computer Science and Engineering, The University of Aizu, Aizuwakamatsu, Japan","IEEE Access","","2018","6","","74778","74791","Sparse coding, which aims at finding appropriate sparse representations of data with an overcomplete dictionary set, has become a mature class of methods with good efficiency in various areas, but it faces limitations in immediate processing such as real-time video denoising. Unsupervised deep neural network structured sparse coding (DNN-SC) algorithms can enhance the efficiency of iterative sparse coding algorithms to achieve the goal. In this paper, we first propose a sparse coding algorithm by adding the idea “weighted"" in the iterative shrinkage thresholding algorithm (ISTA), named WISTA, which can enjoy the benefit of the lp norm (0 <; p <; 1) sparsity constraint. Then, we propose two novel DNN-SC algorithms by combining deep learning with WISTA and the iterative half thresholding algorithm (IHTA), which is the l0.5 norm sparse coding algorithm. Furthermore, we present that by changing the loss function, the DNN can be learned supervisedly and unsupervisedly. Unsupervised learning is the key to ensure the DNN to be learned online during processing, which enables the use of the DNN-SC algorithms in applications lacking labels for signals. Synthetic data experiments show that WISTA can outperform ISTA and IHTA. Moreover, the DNNstructured WISTA can successfully achieve converged results of WISTA. In real-world data experiments, the procedure of utilizing DNN-SC algorithms in image denoising is first presented. All DNN-SC algorithms can accelerate at least 45 times while maintaining PSNR results compared with their corresponding sparse coding algorithms. Finally, the strategy of utilizing DNN-SC algorithms in real-time video denoising is presented. The video-denoising experiments show that the DNN-structured ISTA and WISTA can conduct real-time video denoising for 25 frames/s 360 × 480 pixels gray-scaled videos.","","","10.1109/ACCESS.2018.2882531","Ministry of Education, Culture, Sports, Science and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8542719","Sparse coding;deep neural network;weighted iterative shrinkage thresholding algorithm;unsupervised learning;real-time video denoising","Encoding;Signal processing algorithms;Streaming media;Iterative algorithms;Noise reduction;Neural networks;Dictionaries","compressed sensing;image coding;image denoising;image representation;iterative methods;neural nets;unsupervised learning;video signal processing","WISTA;real-time video denoising;unsupervised deep neural network;iterative sparse coding algorithms;iterative shrinkage thresholding algorithm;DNN-SC algorithms;iterative half thresholding algorithm;DNN-structured ISTA;sparse coding algorithms","","2","37","","","","","IEEE","IEEE Journals"
"Deep Learning based Multi-channel intelligent attack detection for Data Security","F. Jiang; Y. Fu; B. B. Gupta; F. Lou; S. Rho; F. Meng; Z. Tian","Harbin Institute of Technology, Department of Computer Science, Harbin, Heilongjiang China 150001 (e-mail: fjiang@hit.edu.cn); Institute of Computer Application, China Academy of Engineer Physics, Mianyang, Sichuan China (e-mail: fuyunsheng@163.com); Computer Engineering, National Institute of Technology Kurukshetra, 29057 Kurukshetra, Haryana India (e-mail: bbgupta.nitkkr@gmail.com); Institute of Computer Application, China Academy of Engineer Physics, Mianyang, Sichuan China (e-mail: louf108@caep.cn); Department of Media Software, Sungkyul University, Hanyang, Hanyang Korea (the Democratic People's Republic of) (e-mail: korea.smrho@gmail.com); Institute of Computer Application, China Academy of Engineer Physics, Mianyang, Sichuan China (e-mail: mengfz@caep.cn); Institute of Computer Application, China Academy of Engineer Physics, Mianyang, Sichuan China (e-mail: tianzhihong@hit.edu.cn)","IEEE Transactions on Sustainable Computing","","2018","PP","99","1","1","Deep learning, e.g., convolutional neural networks(CNNs) and Recurrent Neural Networks(RNNs), has achieved great success in image processing and natural language processing especially in high level vision applications such as recognition and understanding. However, it is rarely used to solve information security problems such as attack detection studied in this paper. Here, we move forward a step and propose a novel multi-channel intelligent attack detection method based on LSTM-RNNs. To achieve high accurate detection rate, data preprocessing, feature abstraction and multi-channel training and detection is seamlessly integrated into an end-to-end detection method. Data preprocessing provides high-quality data for subsequent processing, then different type of feature is extracted from the processed data as vector. Multi-channel processing is used to generate classifiers based on training neural network with different type of feature, which preserve attack feature of input vectors and classify the attack from normal data. With the result of the classifier's attack detection, we introduce a voting algorithm to decide whether the input data is an attack or not. Experimental results validate that the proposed attack detection method greatly outperforms several attack detection methods that use feature detection, Bayesian or SVM methods.","","","10.1109/TSUSC.2018.2793284","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8259310","Deep learning;attack detection;data security;sustainable computing;recurrent neural networks (RNNs)","Feature extraction;Training;Recurrent neural networks;Machine learning;Intrusion detection;Data preprocessing","","","","16","","","","","","IEEE","IEEE Early Access Articles"
"Caching for Mobile Social Networks with Deep Learning: Twitter Analysis for 2016 U.S. Election","K. C. Tsai; L. L. Wang; Z. Han","The University of Houston, Houston, Texas United States (e-mail: kevintsai159@gmail.com); School of Electronic Engineering, Beijing University of Posts and Telecommunications, Beijing, Beijing China 100088 (e-mail: liwang@bupt.edu.cn); ECE, University of Houston, Houston, Texas United States 77004 (e-mail: zhan2@uh.edu)","IEEE Transactions on Network Science and Engineering","","2018","PP","99","1","1","As the rise of the portable devices, people usually access the social media such as Twitter and Facebook through wireless networks. Therefore, data transmission rates significant important to the end users. In this work, we discuss the problem of context-aware data caching in the heterogeneous small cell networks to reduce the service delay and how the device-to-device (D2D) and device-to-infrastructure (D2I) improve the system social welfare. In the data-caching model, we explore three types of cache entities, macro cell base stations, small cell base stations, and end user devices. We propose a long short-term memory (LSTM) deep learning model to perform data analysis and extract information content from the data. By knowing the interest of the data to the cache entities, we can cache the data that will most likely to be requested by the end users to reduce service latency. In simulation, we show our proposed algorithm can efficiently reduce the service latency during 2016 U.S. presidential election where mobile user were urgent to request the election information through wireless networks. Comparing with other mechanisms such as using one-to-many matching algorithm or without D2D communication technology, our proposed algorithm improves significantly on the devices performance and system social welfare.","","","10.1109/TNSE.2018.2832075","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8353149","caching;D2D;D2I;deep learning;HetNet;matching;mobile social media network;natural language processing","Device-to-device communication;Mobile handsets;Twitter;Performance evaluation;Machine learning;Voting","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Diverse Region-Based CNN for Hyperspectral Image Classification","M. Zhang; W. Li; Q. Du","College of Information Science and Technology, Beijing University of Chemical Technology, Beijing, China; College of Information Science and Technology, Beijing University of Chemical Technology, Beijing, China; Department of Electrical and Computer Engineering, Mississippi State University, Mississippi State, MS, USA","IEEE Transactions on Image Processing","","2018","27","6","2623","2634","Convolutional neural network (CNN) is of great interest in machine learning and has demonstrated excellent performance in hyperspectral image classification. In this paper, we propose a classification framework, called diverse region-based CNN, which can encode semantic context-aware representation to obtain promising features. With merging a diverse set of discriminative appearance factors, the resulting CNN-based representation exhibits spatial-spectral context sensitivity that is essential for accurate pixel classification. The proposed method exploiting diverse region-based inputs to learn contextual interactional features is expected to have more discriminative power. The joint representation containing rich spectral and spatial information is then fed to a fully connected network and the label of each pixel vector is predicted by a softmax layer. Experimental results with widely used hyperspectral image data sets demonstrate that the proposed method can surpass any other conventional deep learning-based classifiers and other state-of-the-art classifiers.","","","10.1109/TIP.2018.2809606","National Natural Science Foundation of China; Beijing Natural Science Foundation; Beijing Nova Program; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8304691","Hyperspectral image;convolutional neural network;deep learning;pattern recognition","Feature extraction;Hyperspectral imaging;Data mining;Support vector machines;Machine learning","feature extraction;hyperspectral imaging;image classification;learning (artificial intelligence);neural nets","spatial-spectral context sensitivity;accurate pixel classification;contextual interactional features;rich spectral information;spatial information;conventional deep learning;hyperspectral image classification;convolutional neural network;machine learning;semantic context-aware representation;discriminative appearance factors;hyperspectral image data sets;diverse region-based CNN;softmax layer","","26","50","","","","","IEEE","IEEE Journals"
"ADMM-CSNet: A Deep Learning Approach for Image Compressive Sensing","Y. Yang; J. Sun; H. LI; Z. Xu","Institute for Information and System Sciences, Xi'an Jiaotong University, 12480 Xi'an, Shaanxi China 710049 (e-mail: yangyan92@stu.xjtu.edu.cn); School of Science, Xi'an Jiaotong University, Xi'an, Shaanxi China 710049 (e-mail: jiansun@mail.xjtu.edu.cn); School of Mathematics and Statistics, Xi'An JiaoTong University, XI AN, SHAAN XI China (e-mail: huibinli@mail.xjtu.edu.cn); Institute for Information and System Sciences, Xi'an Jiaotong University, 12480 Xi'an, Shaanxi China 710049 (e-mail: zbxu@mail.xjtu.edu.cn)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","PP","99","1","1","Compressive sensing (CS) is an effective technique for reconstructing image from a small amount of sampled data. It has been widely applied in medical imaging, remote sensing, image compression, etc. In this paper, we propose two versions of a novel deep learning architecture, dubbed as ADMM-CSNet, by combining the traditional model-based CS method and data-driven deep learning method for image reconstruction from sparsely sampled measurements. We first consider a generalized CS model for image reconstruction with undetermined regularizations in undetermined transform domains, and then two efficient solvers using Alternating Direction Method of Multipliers (ADMM) algorithm for optimizing the model are proposed. We further unroll and generalize the ADMM algorithm to be two deep architectures, in which all parameters of the CS model and the ADMM algorithm are discriminatively learned by end-to-end training. For both applications of fast CS complex-valued MR imaging and CS imaging of real-valued natural images, the proposed ADMM-CSNet achieved favorable reconstruction accuracy in fast computational speed compared with the traditional and the other deep learning methods.","","","10.1109/TPAMI.2018.2883941","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8550778","Compressive sensing;deep learning;MR Imaging;ADMM;ADMM-CSNet","Image reconstruction;Transforms;Imaging;Task analysis;Computer architecture;Data models","","","","2","","","","","","IEEE","IEEE Early Access Articles"
"Human Action Recognition by Learning Spatio-Temporal Features With Deep Neural Networks","L. Wang; Y. Xu; J. Cheng; H. Xia; J. Yin; J. Wu","Guangdong Provincial Key Laboratory of Robotics and Intelligent System, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Guangdong Provincial Key Laboratory of Robotics and Intelligent System, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Guangdong Provincial Key Laboratory of Robotics and Intelligent System, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Guangxi Normal University, Guilin, China; School of Automation, Beijing University of Posts and Telecommunications, Beijing, China; School of Electronic Engineering, Xidian University, Xi’an, China","IEEE Access","","2018","6","","17913","17922","Human action recognition is one of the fundamental challenges in robotics systems. In this paper, we propose one lightweight action recognition architecture based on deep neural networks just using RGB data. The proposed architecture consists of convolution neural network (CNN), long short-term memory (LSTM) units, and temporal-wise attention model. First, the CNN is used to extract spatial features to distinguish objects from the background with both local and semantic characteristics. Second, two kinds of LSTM networks are performed on the spatial feature maps of different CNN layers (pooling layer and fully-connected layer) to extract temporal motion features. Then, one temporal-wise attention model is designed after the LSTM to learn which parts in which frames are more important. Lastly, a joint optimization module is designed to explore intrinsic relations between two kinds of LSTM features. Experimental results demonstrate the efficiency of the proposed method.","","","10.1109/ACCESS.2018.2817253","National Natural Science Foundation of China; Guangdong Natural Science Funds; CAS Key Technology Talent Program; Shenzhen Technology Project; Guangdong Technology Program; Key Laboratory of Human–Machine Intelligence-Synergy Systems, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences; Shenzhen Engineering Laboratory for 3D Content Generating Technologies; CAS Key Technology Talent Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8319974","Artificial intelligent;human action recognition;attention model;deep neural networks;robotic system","Feature extraction;Convolution;Neural networks;Optimization;Computer architecture;Robots;Semantics","feature extraction;image motion analysis;image recognition;learning (artificial intelligence);neural nets","LSTM features;human action recognition;spatio-temporal features;deep neural networks;robotics systems;lightweight action recognition architecture;convolution neural network;short-term memory units;temporal-wise attention model;spatial features;LSTM networks;spatial feature maps;fully-connected layer;temporal motion features;long short-term memory;pooling layer;joint optimization module","","4","44","","","","","IEEE","IEEE Journals"
"Cancers classification based on deep neural networks and emotional learning approach","N. Jafarpisheh; M. Teshnehlab","K.N. Toosi University of Technology, Iran; K.N. Toosi University of Technology, Iran","IET Systems Biology","","2018","12","6","258","263","In the present era, enormous factors contribute to causing cancer. So cancer classification cannot rely only on doctor's thoughts. As a result, intelligent algorithms concerning doctor's help are inevitable. Therefore, the authors are motivated to suggest a novel algorithm to classify three cancer datasets; colon, ALL-AML, and leukaemia cancers. Their proposed algorithm is based on the deep neural network and emotional learning process. First of all, by applying the principal component analysis, they had a feature reduction. Then, they used deep neural as a feature extraction. Then, they implemented different classifiers; multi-layer perceptron, support vector machine (SVM), decision tree, and Gaussian mixture model. In the end, because in the real world, especially when working on systems biology, unpredictable events, and uncertainties are undeniable, the robustness of their model against uncertainties is important. So they added Gaussian noise to the input features of the first encoder in each dataset, then, they applied the stacked denoising method. Experimental results disclosed that, generally, using emotional learning increased the accuracy. In addition, the highest accuracy was gained by SVM, 91.66, 92.27, and 96.56% for colon, ALL-AML, and leukaemia, respectively. However, GMM led to the lowest accuracy. The best accuracy gained by GMM was 60%.","","","10.1049/iet-syb.2018.5002","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8543906","","","cancer;decision trees;feature extraction;Gaussian noise;Gaussian processes;learning (artificial intelligence);medical computing;multilayer perceptrons;pattern classification;principal component analysis;support vector machines","leukaemia cancers;deep neural network;principal component analysis;feature reduction;feature extraction;multilayer perceptron;decision tree;Gaussian mixture model;input features;ALL-AML;cancer classification;intelligent algorithms;cancer datasets;emotional learning process;support vector machine;SVM;stacked denoising method;Gaussian noise;colon cancer","","1","","","","","","IET","IET Journals"
"Deep learning-based real-time fine-grained pedestrian recognition using stream processing","W. Zhang; Z. Wang; X. Liu; H. Sun; J. Zhou; Y. Liu; W. Gong","School of Computer and Communication Engineering, China University of Petroleum, People's Republic of China; School of Computer and Communication Engineering, China University of Petroleum, People's Republic of China; School of Computer and Communication Engineering, China University of Petroleum, People's Republic of China; School of Computer and Communication Engineering, China University of Petroleum, People's Republic of China; University of Oulu, Finland; Concordia University, Canada; School of Computer and Communication Engineering, China University of Petroleum, People's Republic of China","IET Intelligent Transport Systems","","2018","12","7","602","609","Real-time recognition of pedestrian details can be very important in emergency situations for security reasons, such as traffic accidents identification from traffic video. However, this is challenging due to the needed accuracy of video data mining, and also the performance for real-time video processing. Here, the authors propose a solution for fine-grained pedestrian recognition in monitoring scenarios using deep learning and stream processing cloud computing, which is called DRPRS (deep learning-based real-time fine-grained pedestrian recognition using stream processing). The authors design an improved convolutional neural network (CNN) network called fine-CNN, which is a nine-layer neural network for detailed pedestrian recognition. In DRPRS, a pedestrian in a surveillance video is segmented and fine-grainedly recognised using improved single-shot detector and several fine-CNNs. DRPRS is supported by parallel mechanisms provided by Apache Storm stream processing framework. In addition, in order to further improve the recognition performance, a GPU-based scheduling algorithm is proposed to make full use of GPU resources in a cluster. The whole recognition process is deployed on a big video data processing platform to meet real-time requirements. DRPRS is extensively evaluated in terms of accuracy, fault tolerance, and performance, which show that the proposed approach is efficient.","","","10.1049/iet-its.2017.0329","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8436576","","","cloud computing;cluster computing;image recognition;image segmentation;learning (artificial intelligence);neural nets;parallel processing;pedestrians;video surveillance","big video data processing platform;GPU-based scheduling algorithm;fine-CNN;improved single-shot detector;surveillance video;improved convolutional neural network;DRPRS;stream processing cloud computing;real-time video processing;video data mining;traffic video;traffic accidents identification;deep learning-based real-time fine-grained pedestrian recognition","","2","27","","","","","IET","IET Journals"
"An Autoencoder-Based Image Reconstruction for Electrical Capacitance Tomography","J. Zheng; L. Peng","Department of Automation, Tsinghua National Laboratory for Information Science and Technology, Tsinghua University, Beijing, China; Department of Automation, Tsinghua National Laboratory for Information Science and Technology, Tsinghua University, Beijing, China","IEEE Sensors Journal","","2018","18","13","5464","5474","Electrical capacitance tomography (ECT) image reconstruction has developed decades and made great achievements, but there is still a need to find new theory framework to make image reconstruction results better and faster. Recent years, deep learning, which is based on different series of artificial neural networks good at mapping complicated nonlinear functions, is flourishing and adopted in many fields. In this paper, a supervised autoencoder neural network is proposed to solve the image reconstruction problem of ECT, which has an encoder network and a decoder network. A simulation-based data set consisting of 40 000 pairs of instances, of which each pair of sample has a capacitance vector and corresponding permittivity distribution vector, is used to train and test the performance of the autoencoder by 10-fold cross validation. Furthermore, data with artificial noise, data regarding flow pattern not in training data set, and experimental data from a practical ECT system, are used to test the generalization ability and practicability of the network, respectively. The preliminary results show that the proposed autoencoder-based image reconstruction algorithm for ECT is of providing better reconstruction results.","","","10.1109/JSEN.2018.2836337","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8358975","Electrical capacitance tomography;image reconstruction;machine learning;deep learning;autoencoder","Image reconstruction;Capacitance;Permittivity;Decoding;Neurons;Training;Machine learning","electric impedance imaging;encoding;image reconstruction;learning (artificial intelligence);medical image processing;neural nets;tomography","electrical capacitance tomography image reconstruction;theory framework;image reconstruction results;deep learning;different series;artificial neural networks;mapping complicated nonlinear functions;supervised autoencoder neural network;image reconstruction problem;encoder network;decoder network;capacitance vector;corresponding permittivity distribution vector;training data;experimental data;practical ECT system;image reconstruction algorithm;autoencoder-based image reconstruction algorithm","","3","35","","","","","IEEE","IEEE Journals"
"RANUS: RGB and NIR Urban Scene Dataset for Deep Scene Parsing","G. Choe; S. Kim; S. Im; J. Lee; S. G. Narasimhan; I. S. Kweon","School of Electrical Engineering, KAIST, Daejeon, South Korea; School of Electrical Engineering, KAIST, Daejeon, South Korea; School of Electrical Engineering, KAIST, Daejeon, South Korea; Adobe Research, San Jose, CA, USA; Carnegie Mellon University, Pittsburgh, PA, USA; School of Electrical Engineering, KAIST, Daejeon, South Korea","IEEE Robotics and Automation Letters","","2018","3","3","1808","1815","In this letter, we present a data-driven method for scene parsing of road scenes to utilize single-channel near-infrared (NIR) images. To overcome the lack of data problem in non-RGB spectrum, we define a new color space and decompose the task of deep scene parsing into two subtasks with two separate CNN architectures for chromaticity channels and semantic masks. For chromaticity estimation, we build a spatially-aligned RGB-NIR image database (40k urban scenes) to infer color information from RGB-NIR spectrum learning process and leverage existing scene parsing networks trained over already available RGB masks. From our database, we sample key frames and manually annotate them (4k ground truth masks) to finetune the network into the proposed color space. Hence, the key contribution of this work is to replace multispectral scene parsing methods with a simple yet effective approach using single NIR images. The benefits of using our algorithm and dataset are confirmed in the qualitative and quantitative experiments.","","","10.1109/LRA.2018.2801390","Ministry of Trade, Industry & Energy and the Korea Evaluation Institute of Industrial Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8279453","Deep learning in robotics and automation;semantic scene understanding","Cameras;Databases;Roads;Image color analysis;Image segmentation;Semantics","image colour analysis;image segmentation;learning (artificial intelligence);object detection","color space;multispectral scene;NIR urban scene dataset;deep scene parsing;data-driven method;road scenes;data problem;nonRGB spectrum;chromaticity channels;RGB-NIR image database;RGB-NIR spectrum learning process","","4","36","","","","","IEEE","IEEE Journals"
"Chinese vehicle license plate recognition using kernel-based extreme learning machine with deep convolutional features","Y. Yang; D. Li; Z. Duan","Chang'an University, People's Republic of China; Chang'an University, People's Republic of China; Chang'an University, People's Republic of China","IET Intelligent Transport Systems","","2018","12","3","213","219","License plate recognition (LPR) is an important component of intelligent transportation systems. Compared with letters and numbers, Chinese characters contain more information, making automatic recognition more difficult. Accurate Chinese LPR (CLPR) is determined by three factors: training dataset, feature extractor, and classifier. Most license plates with benchmark dataset contain only letters and numbers; thus, the authors build a large dataset for CLPR. Convolutional neural networks (CNNs) can be used to extract inherent image features, on all levels of abstraction. CNNs can be used for classification if they have a sufficient number of fully connected layers. This implies that CNNs must be trained using gradient descent-based methods, which often yields sub-optimal results. Extreme learning machines (ELMs) demonstrate impressive performance on classification, with good generalisation. Therefore, the authors propose a novel deep architecture for CLPR which combines a CNN and an ELM. Firstly, a CNN without fully connected layers, working as a feature extractor, learns deep features associated with characters in written Chinese. Then, a kernel-based ELM (KELM) classifier, which accepts CNN features as input, is utilised for classification. Compared with CNNs that use Softmax, support vector machines and ELMs, the CNN that uses KELM yields competitive results in a shorter training time.","","","10.1049/iet-its.2017.0136","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8307031","","","feature extraction;feedforward neural nets;image classification;learning (artificial intelligence);object recognition;traffic engineering computing","support vector machines;Softmax;classification;KELM classifier;feature extractor;ELM;CNN;convolutional neural networks;CLPR;deep convolutional features;kernel-based extreme learning machine;Chinese vehicle license plate recognition","","4","42","","","","","IET","IET Journals"
"A Deep Convolutional Neural Network-Based Framework for Automatic Fetal Facial Standard Plane Recognition","Z. Yu; E. Tan; D. Ni; J. Qin; S. Chen; S. Li; B. Lei; T. Wang","National Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, School of Biomedical Engineering, Health Science Center, Shenzhen University, Shenzhen, China; Beijing Sesame World Co., Ltd, Beijing, China; National Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, School of Biomedical Engineering, Health Science Center, Shenzhen University, Shenzhen, China; Centre for Smart Health, School of Nursing, The Hong Kong Polytechnic University, Hong Kong; National Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, School of Biomedical Engineering, Health Science Center, Shenzhen University, Shenzhen, China; Department of Ultrasound, Affiliated Shenzhen Maternal and Child Healthcare Hospital of Nanfang Medical University, Shenzhen, China; National Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, School of Biomedical Engineering, Health Science Center, Shenzhen University, Shenzhen, China; National Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Key Laboratory for Biomedical Measurements and Ultrasound Imaging, School of Biomedical Engineering, Health Science Center, Shenzhen University, Shenzhen, China","IEEE Journal of Biomedical and Health Informatics","","2018","22","3","874","885","Ultrasound imaging has become a prevalent examination method in prenatal diagnosis. Accurate acquisition of fetal facial standard plane (FFSP) is the most important precondition for subsequent diagnosis and measurement. In the past few years, considerable effort has been devoted to FFSP recognition using various hand-crafted features, but the recognition performance is still unsatisfactory due to the high intraclass variation of FFSPs and the high degree of visual similarity between FFSPs and other non-FFSPs. To improve the recognition performance, we propose a method to automatically recognize FFSP via a deep convolutional neural network (DCNN) architecture. The proposed DCNN consists of 16 convolutional layers with small 3 × 3 size kernels and three fully connected layers. A global average pooling is adopted in the last pooling layer to significantly reduce network parameters, which alleviates the overfitting problems and improves the performance under limited training data. Both the transfer learning strategy and a data augmentation technique tailored for FFSP are implemented to further boost the recognition performance. Extensive experiments demonstrate the advantage of our proposed method over traditional approaches and the effectiveness of DCNN to recognize FFSP for clinical diagnosis.","","","10.1109/JBHI.2017.2705031","National Natural Science Foundation of China; National Key Research and Develop Program; Guangdong Medical; Shenzhen Peacock Plan; Shenzhen Key Basic Research; National Natural Science Foundation of Shenzhen University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7930382","Deep convolutional neural network;standard plane recognition;transfer learning;ultrasound image","Standards;Feature extraction;Biomedical imaging;Ultrasonic imaging;Neural networks;Biomedical measurement;Image recognition","biomedical ultrasonics;convolution;face recognition;feedforward neural nets;learning (artificial intelligence);medical image processing;neural net architecture","DCNN;fully connected layers;global average pooling;pooling layer;network parameters;recognition performance;clinical diagnosis;automatic fetal facial standard plane recognition;ultrasound imaging;prevalent examination method;prenatal diagnosis;subsequent diagnosis;FFSP recognition;hand-crafted features;high intraclass variation;nonFFSPs;deep convolutional neural network architecture;convolutional layers;transfer learning strategy;data augmentation","","6","68","","","","","IEEE","IEEE Journals"
"Deep Neural Networks for Linear Sum Assignment Problems","M. Lee; Y. Xiong; G. Yu; G. Y. Li","College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China; College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China; College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA","IEEE Wireless Communications Letters","","2018","7","6","962","965","Many resource allocation issues in wireless communications can be modeled as assignment problems and can be solved online with global information. However, traditional methods for assignment problems take a lot of time to find the optimal solutions. In this letter, we solve the assignment problem using machine learning approach. Specifically, the linear sum assignment problems (LSAPs) are solved by the deep neural networks (DNNs). Since LSAP is a combinatorial optimization problem, it is first decomposed into several sub-assignment problems. Each of them is a classification problem and can be solved effectively with DNNs. Two kinds of DNNs, feed-forward neural network and convolutional neural network, are implemented to deal with the sub-assignment problems, respectively. Based on computer simulation, DNNs can effectively solve LSAPs with great time efficiency and only slight loss of accuracy.","","","10.1109/LWC.2018.2843359","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8371290","Linear sum assignment problem;deep neural network;machine learning;resource allocation","Training;Heuristic algorithms;Neural networks;Optimization;Approximation algorithms;Convergence;Resource management","combinatorial mathematics;feedforward neural nets;learning (artificial intelligence);optimisation;radio networks;resource allocation;telecommunication computing","machine learning;wireless communications;resource allocation;subassignment problems;DNN;convolutional neural network;feed-forward neural network;combinatorial optimization problem;deep neural networks;LSAP;linear sum assignment problems","","4","13","","","","","IEEE","IEEE Journals"
"Deep Coupling Autoencoder for Fault Diagnosis With Multimodal Sensory Data","M. Ma; C. Sun; X. Chen","State Key Laboratory for Manufacturing Systems Engineering, Xi'an Jiaotong University, Xi'an, China; State Key Laboratory for Manufacturing Systems Engineering, Xi'an Jiaotong University, Xi'an, China; State Key Laboratory for Manufacturing Systems Engineering, Xi'an Jiaotong University, Xi'an, China","IEEE Transactions on Industrial Informatics","","2018","14","3","1137","1145","Effective fault diagnosis of rotating machinery has multifarious benefits, such as improved safety, enhanced reliability, and reduced maintenance cost, for complex engineered systems. With many kinds of installed sensors for conducting fault diagnosis, one of the key tasks is to develop data fusion strategies that can effectively handle multimodal sensory signals. Most traditional methods use hand-crafted statistical features and then combine these multimodal features simply by concatenating them into a long vector to achieve data fusion. The present study proposes a deep coupling autoencoder (DCAE) model that handles the multimodal sensory signals not residing in a commensurate space, such as vibration and acoustic data, and integrates feature extraction of multimodal data seamlessly into data fusion for fault diagnosis. Specifically, a coupling autoencoder (CAE) is constructed to capture the joint information between different multimodal sensory data, and then a DCAE model is devised for learning the joint feature at a higher level. The CAE is developed by coupling hidden representations of two single-modal autoencoders, which can capture the joint information from multimodal data. The performance of the proposed method is evaluated by two experiments, which shows that the DCAE model succeeds in efficiently utilizing multisource sensory data to perform accurate fault diagnosis. Compared with other methods, the proposed method exhibits better performance.","","","10.1109/TII.2018.2793246","National Key Basic Program of China; National Natural Science Foundation of China; China Postdoctoral Science Foundation; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8259006","Coupling autoencoder (CAE);deep learning;fault diagnosis;multimodal information fusion","Fault diagnosis;Couplings;Feature extraction;Data integration;Sensors;Vibrations;Data models","encoding;fault diagnosis;feature extraction;learning (artificial intelligence);machinery;mechanical engineering computing;sensor fusion;statistical analysis","DCAE model;multisource sensory data;complex engineered systems;data fusion strategies;multimodal sensory signals;statistical features;multimodal features;deep coupling autoencoder model;acoustic data;multimodal data;joint information;single-modal autoencoders;fault diagnosis;rotating machinery;joint feature learning","","17","34","","","","","IEEE","IEEE Journals"
"The Empirical Study of Semi-Supervised Deep Fuzzy C-Mean Clustering for Software Fault Prediction","A. Arshad; S. Riaz; L. Jiao; A. Murthy","School of Computer Science and Technology, Xidian University, Xi’an, China; School of Computer Science and Technology, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education of China, International Joint Collaboration Laboratory of Intelligent Perception and Computation, International Research Center of Intelligent Perception and Computation, School of Artificial Intelligence, Xidian University, Xi’an, China; Professional Engineers in Ontario, North York, ON, Canada","IEEE Access","","2018","6","","47047","47061","Software fault prediction is a very consequent research topic for software quality assurance. The performance of fault prediction model depends on the features that are used to train it. Redundant and irrelevant features can hinder the performance of a classification model. In this paper, we propose an empirical study of two-stage data pre-processing technique on software fault prediction models. In the first stage, a novel semi-supervised deep Fuzzy C-Mean (DFCM) clustering-based feature extraction technique is proposed to create new features by utilizing deep multi-clusters of unlabeled and labeled data sets that tends to maximize intra-cluster class and intra-cluster feature by using FCM clustering. The FCM also utilizes to handle the class imbalance problem. In the second stage, we further ameliorate the prediction performance with coalescence of feature selection (using random-under sampling) to reduce the noisy data for classification. However, by the performance of the model results in the amalgamation of novel DFCM data pre-processing approach work better due to their ability to identify and amalgamation essential information in data features. An empirical study is designed on real-world software project (NASA & Eclipse) data set to evaluate the performance of DFCM by implemented different data pre-processing schemes on prediction models (C4.5, naive bayes, and 1-near neighbor (1-NN)), which are widely used in software fault prediction and further investigated the influencing factors in our approach. The result shows that the performance of the proposed DFCM feature extraction technique for data pre-processing is stable and effectiveness on all prediction models.","","","10.1109/ACCESS.2018.2866082","National Basic Research Program (973 Program) of China; National Natural Science Foundation of China; Fund for Foreign Scholars in University Research and Teaching Programs (the 111 Project); Major Research Plan of the National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8439927","Semi-supervised learning;Fuzzy C-Mean clustering;feature learning;software fault prediction","Software;Feature extraction;Predictive models;Data models;Classification algorithms;Training;Software algorithms","Bayes methods;feature extraction;learning (artificial intelligence);pattern classification;pattern clustering;software fault tolerance;software quality","software quality assurance;classification model;two-stage data pre-processing technique;software fault prediction models;deep multiclusters;unlabeled labeled data sets;intra-cluster class;FCM clustering;feature selection;data features;real-world software project data;DFCM feature extraction technique;DFCM data pre-processing approach;intra-cluster feature;semisupervised deep fuzzy c-mean clustering-based feature extraction technique;amalgamation","","3","87","","","","","IEEE","IEEE Journals"
"Disaggregating Transform Learning for Non-Intrusive Load Monitoring","M. Gaur; A. Majumdar","Department of Computer Science, Indraprastha Institute of Information Technology Delhi, New Delhi, India; Department of Electrical and Computer Engineering, Indraprastha Institute of Information Technology Delhi, New Delhi, India","IEEE Access","","2018","6","","46256","46265","This paper addresses the problem of energy disaggregation/non-intrusive load monitoring. It introduces a new method based on the transform learning formulation. Several recent techniques, such as discriminative sparse coding, powerlet disaggregation, and deep sparse coding, are based on the synthesis dictionary learning/sparse coding approach; ours is based on its analysis equivalent. The theoretical advantage of analysis dictionary compared to its synthesis counterpart is that the former can learn from fewer training s--this has implications in reducing the cost of energy disaggregation. Experiments have been carried out on two benchmark data sets-REDD and Dataport (Pecan Street). Comparison has been done with factorial HMM, discriminative sparse coding, powerlet disaggregation, and deep sparse coding. In the low training data regime, our method always excels over the others.","","","10.1109/ACCESS.2018.2850707","TCS Ph.D. Fellowship; Infosys Center for Artificial Intelligence at IIIT Delhi; DST IC-IMPACTS Indo-Canadian Grant; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8444965","Dictionary learning;energy disaggregation;non-intrusive load monitoring","Transforms;Machine learning;Dictionaries;Encoding;Training;Monitoring;Hidden Markov models","encoding;signal processing","learning formulation;discriminative sparse coding;powerlet disaggregation;deep sparse coding;analysis equivalent;analysis dictionary;synthesis counterpart;nonintrusive load monitoring;disaggregating transform learning;energy disaggregation;synthesis dictionary learning-sparse coding approach;REDD;Dataport","","2","30","","","","","IEEE","IEEE Journals"
"Multiple Attributes QoS Prediction via Deep Neural Model with Contexts","H. Wu; Z. Zhang; J. Luo; K. Yue; C. Hsu","School of Information Science and Engineering, Yunnan University, 12635 Kunming, Yunnan China (e-mail: haowu@ynu.edu.cn); School of Information Science and Engineering, Yunnan University, Kunming, Yunnan China (e-mail: zzxynu@gmail.com); School of Information Science and Engineering, Yunnan University, Kunming, Yunnan China (e-mail: luojcyun@hotmail.com); School of Information Science and Engineering, Yunnan University, Kunming, Yunnan China (e-mail: kyue@ynu.edu.cn); CS, Chung Hua University, Hsinchu, Taiwan Taiwan (e-mail: robertchh@gmail.com)","IEEE Transactions on Services Computing","","2018","PP","99","1","1","In recent years, various collaborative QoS prediction methods have been put forward to coping with the demand for efficient quality-of-service (QoS) evaluation, by drawing lessons from the recommender systems. However, there still remain some challenging issues on this direction, as how to effectively exploit complex contexts to improve prediction accuracy, and how to realize collaborative QoS prediction of multiple attributes. Inspired by the principles of deep learning, we have proposed a universal deep neural model (DNM) for making multiple attributes QoS prediction with contexts. In this model, contextual features are mapped into a shared latent space to semantically characterize them in the embedding layer. The contextual features with their higher-order interactions are captured through the interaction layer and the perception layers. Multi-tasks prediction is realized by stacking task-specific perception layers on the shared neural layers. Armed with these, DNM provides a powerful framework to integrate with various contextual features to realize multi-attributes QoS prediction. Experimental results from a large-scale QoS-specific dataset demonstrate that DNM achieves superior prediction accuracy in term of mean absolute error (MAE) compared with the state-of-the-art collaborative QoS prediction techniques. Additionally, the DNM model has a good robustness and extensibility on exploiting heterogeneous contextual features.","","","10.1109/TSC.2018.2859986","Special Funds for Science and Technology Research Project of Yunnan University; National Natural Science Foundation of China; China Postdoctoral Science Foundation funded project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8419326","QoS prediction;deep neural model;context-aware;multitask learning;feature embedding","Quality of service;Predictive models;Collaboration;Computational modeling;Context modeling;Task analysis;Cloud computing","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Learning pairwise SVM on hierarchical deep features for ear recognition","I. Omara; X. Wu; H. Zhang; Y. Du; W. Zuo","Harbin Institute of Technology (HIT), People's Republic of China; Harbin Institute of Technology (HIT), People's Republic of China; Harbin Institute of Technology (HIT), People's Republic of China; Northeast Agricultural University, People's Republic of China; Harbin Institute of Technology (HIT), People's Republic of China","IET Biometrics","","2018","7","6","557","566","Convolutional neural networks (CNNs)-based deep features have been demonstrated with remarkable performance in various vision tasks, such as image classification and face verification. Compared with the hand-crafted descriptors, deep features exhibit more powerful representation ability. Typically, higher layer features contain more semantic information, while lower layer features can provide more low-level description. In addition, it turns out that the fusion of different layer features will lead to superior performance. Here, we propose a novel approach for human ear identification by combining hierarchical deep features. First, hierarchical deep features are extracted from ear images using CNN pre-trained on large-scale data set. To enhance the feature representation and reduce the high dimension of deep features, the discriminant correlation analysis (DCA) is adopted for fusing deep features from different layers for further improvement. Owing to the lack of ear images per person, the authors propose to transform the ear identification problem to the binary classification by composing pairwise samples and resolve it with the pairwise support vector machine (SVM). Experiments are conducted on four public databases: USTB I, USTB II, IIT Delhi I, and IIT Delhi II. The proposed method achieves promising recognition rate and exhibits decent performance compared with the state-of-the-art methods.","","","10.1049/iet-bmt.2017.0087","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8519956","","","computer vision;convolution;ear;face recognition;feature extraction;feedforward neural nets;image classification;image representation;learning (artificial intelligence);pattern classification;support vector machines","learning pairwise SVM;ear recognition;DCA algorithm;discriminant correlation analysis algorithm;pairwise support vector machine;convolutional neural networks;CNN models;layer features;feature representation;ear images;hierarchical deep features","","1","","","","","","IET","IET Journals"
"Functional Contour-following via Haptic Perception and Reinforcement Learning","R. B. Hellman; C. Tekin; M. van der Schaar; V. J. Santos","Mechanical and Aerospace Engineering Department, University of California, Los Angeles, CA; Department of Electrical and Electronics Engineering, Bilkent University, Ankara, Turkey; Department of Electrical Engineering, University of California, Los Angeles, CA; Mechanical and Aerospace Engineering Department, University of California, Los Angeles, CA","IEEE Transactions on Haptics","","2018","11","1","61","72","Many tasks involve the fine manipulation of objects despite limited visual feedback. In such scenarios, tactile and proprioceptive feedback can be leveraged for task completion. We present an approach for real-time haptic perception and decision-making for a haptics-driven, functional contour-following task: the closure of a ziplock bag. This task is challenging for robots because the bag is deformable, transparent, and visually occluded by artificial fingertip sensors that are also compliant. A deep neural net classifier was trained to estimate the state of a zipper within a robot's pinch grasp. A Contextual Multi-Armed Bandit (C-MAB) reinforcement learning algorithm was implemented to maximize cumulative rewards by balancing exploration versus exploitation of the state-action space. The C-MAB learner outperformed a benchmark Q-learner by more efficiently exploring the state-action space while learning a hard-to-code task. The learned C-MAB policy was tested with novel ziplock bag scenarios and contours (wire, rope). Importantly, this work contributes to the development of reinforcement learning approaches that account for limited resources such as hardware life and researcher time. As robots are used to perform complex, physically interactive tasks in unstructured or unmodeled environments, it becomes important to develop methods that enable efficient and effective learning with physical testbeds.","","","10.1109/TOH.2017.2753233","National Science Foundation; Office of Naval Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8039205","Active touch;contour-following;decision making;haptic perception;manipulation;reinforcement learning","Robot sensing systems;Learning (artificial intelligence);Haptic interfaces;Real-time systems;Manipulators;Planning","control engineering computing;feedback;haptic interfaces;learning (artificial intelligence);manipulators;motion control;neurocontrollers;pattern classification","ziplock bag scenarios;physically interactive tasks;visual feedback;tactile feedback;proprioceptive feedback;task completion;real-time haptic perception;decision-making;functional contour-following task;robot pinch grasp;Contextual Multi-Armed Bandit reinforcement learning algorithm;C-MAB policy;hard-to-code task;benchmark Q-learner;C-MAB learner;state-action space;cumulative rewards;deep neural net classifier;artificial fingertip sensors","Algorithms;Computer Simulation;Equipment Design;Neural Networks (Computer);Reinforcement (Psychology);Robotics;Touch;Touch Perception","1","47","","","","","IEEE","IEEE Journals"
"Image Visual Realism: From Human Perception to Machine Computation","S. Fan; T. Ng; B. L. Koenig; J. S. Herberg; M. Jiang; Z. Shen; Q. Zhao","Smart Systems Institute, National University of Singapore, Singapore; Institute for Infocomm Research, Singapore; Department of Psychology, Southern Utah University, Cedar City, UT; Department of Psychology, National University of Singapore, Singapore; Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN; Smart Systems Institute, National University of Singapore, Singapore; Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","9","2180","2193","Visual realism is defined as the extent to which an image appears to people as a photo rather than computer generated. Assessing visual realism is important in applications like computer graphics rendering and photo retouching. However, current realism evaluation approaches use either labor-intensive human judgments or automated algorithms largely dependent on comparing renderings to reference images. We develop a reference-free computational framework for visual realism prediction to overcome these constraints. First, we construct a benchmark dataset of 2,520 images with comprehensive human annotated attributes. From statistical modeling on this data, we identify image attributes most relevant for visual realism. We propose both empirically-based (guided by our statistical modeling of human data) and deep convolutional neural network models to predict visual realism of images. Our framework has the following advantages: (1) it creates an interpretable and concise empirical model that characterizes human perception of visual realism; (2) it links computational features to latent factors of human image perception.","","","10.1109/TPAMI.2017.2747150","National Research Foundation; Prime Minister's Office, Singapore; International Research Centre; University of Minnesota Department of Computer Science and Engineering Start-up Fund (QZ); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8022957","Visual realism;human psychophysics;statistical modeling;convolutional neural network","Visualization;Computational modeling;Rendering (computer graphics);Benchmark testing;Solid modeling;Face","convolution;feedforward neural nets;image processing;learning (artificial intelligence);rendering (computer graphics);statistical analysis;visual perception","image visual realism;computer graphics rendering;labor-intensive human judgments;reference-free computational framework;human image perception;machine computation;statistical modeling;deep convolutional neural network model","","2","92","","","","","IEEE","IEEE Journals"
"A novel deep hybrid recommender system based on auto-encoder with neural collaborative filtering","Y. Liu; S. Wang; M. S. Khan; J. He","School of Computer Science and Engineering, and also with MOE Key Laboratory of Computer Network and Information Integration, Southeast University, Nanjing 211189, China; School of Computer Science and Engineering, and also with MOE Key Laboratory of Computer Network and Information Integration, Southeast University, Nanjing 211189, China; School of Computer Science and Engineering, and also with MOE Key Laboratory of Computer Network and Information Integration, Southeast University, Nanjing 211189, China; School of Computer Science and Engineering, and also with MOE Key Laboratory of Computer Network and Information Integration, Southeast University, Nanjing 211189, China","Big Data Mining and Analytics","","2018","1","3","211","221","Due to the widespread availability of implicit feedback (e.g., clicks and purchases), some researchers have endeavored to design recommender systems based on implicit feedback. However, unlike explicit feedback, implicit feedback cannot directly reflect user preferences. Therefore, although more challenging, it is also more practical to use implicit feedback for recommender systems. Traditional collaborative filtering methods such as matrix factorization, which regards user preferences as a linear combination of user and item latent vectors, have limited learning capacities and suffer from data sparsity and the cold-start problem. To tackle these problems, some authors have considered the integration of a deep neural network to learn user and item features with traditional collaborative filtering. However, there is as yet no research combining collaborative filtering and contentbased recommendation with deep learning. In this paper, we propose a novel deep hybrid recommender system framework based on auto-encoders (DHA-RS) by integrating user and item side information to construct a hybrid recommender system and enhance performance. DHA-RS combines stacked denoising auto-encoders with neural collaborative filtering, which corresponds to the process of learning user and item features from auxiliary information to predict user preferences. Experiments performed on the real-world dataset reveal that DHA-RS performs better than state-of-the-art methods.","","","10.26599/BDMA.2018.9020019","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8361573","","Collaboration;Feature extraction;Recommender systems;Neural networks;Data mining;Noise reduction;Computational modeling","collaborative filtering;learning (artificial intelligence);matrix decomposition;neural nets;recommender systems;relevance feedback","content-based recommendation;auxiliary information;deep neural network;item latent vectors;explicit feedback;implicit feedback;user preferences;neural collaborative filtering;item side information;DHA-RS;auto-encoder;deep hybrid recommender system framework;deep learning;collaborative filtering recommendation;item features","","","","","","","","TUP","TUP Journals"
"Learning Deconvolutional Network for Object Tracking","X. Lu; H. Huo; T. Fang; H. Zhang","Department of Automation, Shanghai Jiao Tong University, Shanghai, China; Department of Automation, Shanghai Jiao Tong University, Shanghai, China; Department of Automation, Shanghai Jiao Tong University, Shanghai, China; Zhengzhou University of Light Industry, Zhangzhou, China","IEEE Access","","2018","6","","18032","18041","Object tracking can be tackled by learning a model of tracking the target's appearance sequentially. Therefore, robust appearance representation is a critical step in visual tracking. Recently, deep convolution network has demonstrated remarkable ability in visual tracking via leveraging robust high-level features. To obtain these high-level features, convolution and pooling operations are executed alternatively in deep convolution network. However, these operations lead to low spatial resolution feature maps which degrade the localization precision in tracking. While low level features have sufficient spatial resolution, their representation ability is insufficient. To mitigate this issue, we exploited deconvolution network in visual tracking. This deconvolution network works as a learnable upsampling layer which takes low-resolution high-level feature maps as input and outputs enlarged feature maps. Meanwhile, the low level feature maps are fused with these high level feature maps via a summarization operation to better represent target appearance. We formulate the network training as a regression issue and train this network end to end. Extensive experiments on two tracking benchmarks demonstrate the effectiveness of our method.","","","10.1109/ACCESS.2018.2820004","National Natural Science Foundation of China; Science Fund for Creative Research Groups of the National Natural Science Foundation of China; National Natural Science Foundation of China; Key Science and Technology Program of Henan Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8326476","Object tracking;deep learning;deconvolution neural network;regression network","Deconvolution;Target tracking;Convolution;Feature extraction;Object tracking;Correlation;Visualization","image fusion;image resolution;learning (artificial intelligence);neural nets;object tracking;regression analysis","object tracking;robust appearance representation;visual tracking;deep convolution network;pooling operations;low spatial resolution feature maps;sufficient spatial resolution;representation ability;deconvolution network;network training;tracking benchmarks;low-resolution high-level feature maps;low level feature map fusion;regression issue;summarization operation;upsampling layer learning","","4","56","","","","","IEEE","IEEE Journals"
"Efficient Conversion of Deep Features to Compact Binary Codes Using Fourier Decomposition for Multimedia Big Data","J. Ahmad; K. Muhammad; J. Lloret; S. W. Baik","Intelligent Media Laboratory, Digital Contents Research Institute, Sejong University, Seoul, South Korea; Intelligent Media Laboratory, Digital Contents Research Institute, Sejong University, Seoul, South Korea; Instituto de Investigacion para la Gestion Integrada de Zonas Costeras, Universitat Politecnica de Valencia, València, Spain; Intelligent Media Laboratory, Digital Contents Research Institute, Sejong University, Seoul, South Korea","IEEE Transactions on Industrial Informatics","","2018","14","7","3205","3215","Exponential growth of multimedia data has been witnessed in recent years from various industries, such as e-commerce, health, transportation, and social networks, etc. Access to desired data in such gigantic datasets require sophisticated and efficient retrieval methods. In the last few years, neuronal activations generated by a pretrained convolutional neural network (CNN) have served as generic descriptors for various tasks including image classification, object detection and segmentation, and image retrieval. They perform incredibly well compared to hand-crafted features. However, these features are usually high dimensional, requiring a lot of memory and computations for indexing and retrieval. For very large datasets, utilization of these high dimensional features in raw form becomes infeasible. In this paper, a highly efficient method is proposed to transform high dimensional deep features into compact binary codes using bidirectional Fourier decomposition. This compact bit code saves memory and eases computations during retrieval. Further, these codes can also serve as hash codes, allowing very efficient access to images in large datasets using approximate nearest neighbor (ANN) search techniques. Our method does not require any training and achieves considerable retrieval accuracy with short length codes. It has been tested on features extracted from fully connected layers of a pretrained CNN. Experiments conducted with several large datasets reveal the effectiveness of our approach for a wide variety of datasets.","","","10.1109/TII.2018.2800163","National Research Foundation of Korea; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8276643","Deep learning;Fourier transform;hash codes;image retrieval;industrial informatics","Feature extraction;Binary codes;Image retrieval;Informatics;Multimedia communication;Industries;Task analysis","Big Data;binary codes;convolution;feature extraction;feedforward neural nets;learning (artificial intelligence);multimedia computing;nearest neighbour methods;search problems","hash codes;approximate nearest neighbor search techniques;short length codes;pretrained CNN;compact binary codes;multimedia big data;multimedia data;gigantic datasets;retrieval methods;neuronal activations;pretrained convolutional neural network;generic descriptors;high dimensional deep features;bidirectional Fourier decomposition;compact bit code;retrieval accuracy;deep feature conversion","","5","44","","","","","IEEE","IEEE Journals"
"A Fast Unsupervised Approach for Multi-Modality Surgical Trajectory Segmentation","H. Zhao; J. Xie; Z. Shao; Y. Qu; Y. Guan; J. Tan","Information Engineering College, Capital Normal University, Beijing, China; Information Engineering College, Capital Normal University, Beijing, China; Information Engineering College, Capital Normal University, Beijing, China; Engineering College, The University of Tennessee, Knoxville, TN, USA; Information Engineering College, Capital Normal University, Beijing, China; Engineering College, The University of Tennessee, Knoxville, TN, USA","IEEE Access","","2018","6","","56411","56422","To improve the efficiency of surgical trajectory segmentation for surgical assessment and robot learning in robot-assisted minimally invasive surgery, this paper presents a fast unsupervised method using video and kinematic data, followed by a promoting procedure to address the over-segmentation issue. An unsupervised deep learning network called dense convolutional encoder-decoder network (DCED-Net) is first proposed to extract more discriminative features from videos in an effective way. DCED-Net has several advantages. It compresses the encoding-decoding structure, strengthens the feature propagation, and avoids the manual annotation. To further improve the accuracy of segmentation, on one hand, a modified transition state clustering model is employed with a strategy of reducing the redundancy of transition points. On the other hand, the segmentation results are promoted by identifying the over-segmented trajectories based on predefined similarity measurements. Extensive experiments on the public data set JIGSAWS show that with our method, the percentage increase in accuracy is 20.3% and the percentage decrease in time cost is 92.6%.","","","10.1109/ACCESS.2018.2872635","Beijing Municipal Commission of Education; National Natural Science Foundation of China; National Key R–D Program of China; Beijing Municipal Science and Technology Commission; Capacity Building for Sci-Tech Innovation Fundamental Scientific Research Funds; Capital Normal University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8476566","Robot-assisted minimally invasive surgery;multi-modality trajectory segmentation;unsupervised deep learning;post-merger processing","Feature extraction;Trajectory;Surgery;Image reconstruction;Kinematics;Robots;Machine learning","feature extraction;image segmentation;medical image processing;medical robotics;surgery;unsupervised learning","DCED-Net;encoding-decoding structure;feature propagation;modified transition state clustering model;over-segmented trajectories;fast unsupervised approach;multimodality surgical trajectory segmentation;surgical assessment;robot learning;robot-assisted minimally invasive surgery;kinematic data;over-segmentation issue;unsupervised deep learning network;dense convolutional encoder-decoder network;discriminative features","","","34","","","","","IEEE","IEEE Journals"
"Human Activity Classification With Radar: Optimization and Noise Robustness With Iterative Convolutional Neural Networks Followed With Random Forests","Y. Lin; J. Le Kernec; S. Yang; F. Fioranelli; O. Romain; Z. Zhao","School of Electronic Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Engineering, University of Glasgow, Glasgow, U.K.; School of Engineering, University of Glasgow, Glasgow, U.K.; School of Engineering, University of Glasgow, Glasgow, U.K.; ETIS Laboratory (Information Processing and System Teams), Cergy-Pontoise University, Cergy-Pontoise, France; School of Electronic Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China","IEEE Sensors Journal","","2018","18","23","9669","9681","The accurate classification of activity patterns based on radar signatures is still an open problem and is a key to detect anomalous behavior for security and health applications. This paper presents a novel iterative convolutional neural network strategy with an autocorrelation pre-processing instead of the traditional micro-Doppler image pre-processing to classify activities or subjects accurately. The proposed strategy uses an iterative deep learning framework for the automatic definition and extraction of features. This is followed by a traditional supervised learning classifier to label different activities. Using three human subjects and their real motion captured data, 12 000 radar signatures were simulated by varying additive white Gaussian noise. In addition, 6720 experimental radar signatures were captured with a frequency-modulated continuous radar at 5.8 GHz with 400 MHz of instantaneous bandwidth from seven activities using one subject and 4800 signatures from five subjects while walking. The simulated and experimental data were both used to validate our proposed method, with signal-noise ratio varying from -20 to 20 dB and with 88.74% average accuracy at -10 dB and 100% peak accuracy at 15 dB. The proposed iterative convolutional neural networks followed with random forests not only outperform the feature-based methods using micro-Doppler images but also outperform the classification methods using other types of supervised classifiers after our proposed iterative convolutional neural network.","","","10.1109/JSEN.2018.2872849","National Natural Science Foundation of China; Engineering and Physical Sciences Research Council; China Scholarship Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8476568","Micro-Doppler;deep learning;convolution neural networks;random forests;radar","Feature extraction;Machine learning;Radar imaging;Sensors;Convolutional neural networks;Forestry","AWGN;Doppler radar;feature extraction;image classification;learning (artificial intelligence);neural nets;radar computing;radar imaging;radar target recognition","experimental radar signatures;accurate classification;noise robustness;optimization;human activity classification;random forests;iterative convolutional neural network;frequency-modulated continuous radar;additive white Gaussian noise;human subjects;traditional supervised learning classifier;automatic definition;iterative deep learning framework;microDoppler image pre-processing;autocorrelation pre-processing;convolutional neural network strategy;activity patterns;frequency 5.8 GHz;bandwidth 400.0 MHz","","4","34","","","","","IEEE","IEEE Journals"
"Faceness-Net: Face Detection through Deep Facial Part Responses","S. Yang; P. Luo; C. C. Loy; X. Tang","Department of Information Engineering, The Chinese University of Hong Kong, Xianggangdao, Hong Kong; Department of Information Engineering, The Chinese University of Hong Kong, Xianggangdao, Hong Kong; Department of Information Engineering, The Chinese University of Hong Kong, Xianggangdao, Hong Kong; Department of Information Engineering, The Chinese University of Hong Kong, Xianggangdao, Hong Kong","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","8","1845","1859","We propose a deep convolutional neural network (CNN) for face detection leveraging on facial attributes based supervision. We observe a phenomenon that part detectors emerge within CNN trained to classify attributes from uncropped face images, without any explicit part supervision. The observation motivates a new method for finding faces through scoring facial parts responses by their spatial structure and arrangement. The scoring mechanism is data-driven, and carefully formulated considering challenging cases where faces are only partially visible. This consideration allows our network to detect faces under severe occlusion and unconstrained pose variations. Our method achieves promising performance on popular benchmarks including FDDB, PASCAL Faces, AFW, and WIDER FACE.","","","10.1109/TPAMI.2017.2738644","SenseTime Group Limited; Hong Kong Innovation and Technology Support Programme; General Research Fund; Research Grants Council of the Hong Kong SAR; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8008833","Face detection;deep learning;convolutional neural network","Face;Proposals;Face detection;Detectors;Neural networks;Mouth;Training","convolution;face recognition;feedforward neural nets;image classification;learning (artificial intelligence);object detection","faceness-net;deep facial part responses;deep convolutional neural network;CNN;facial attributes;uncropped face images;explicit part supervision;WIDER FACE;face detection;spatial structure;unconstrained pose variation;PASCAL faces;FDDB;AFW","","9","58","","","","","IEEE","IEEE Journals"
"Integrated Deep Model for Face Detection and Landmark Localization From “In The Wild” Images","G. Storey; A. Bouridane; R. Jiang","Department of Computer and Information Sciences, Northumbria University, Newcastle Upon Tyne, U.K.; Department of Computer and Information Sciences, Northumbria University, Newcastle Upon Tyne, U.K.; Department of Computer and Information Sciences, Northumbria University, Newcastle Upon Tyne, U.K.","IEEE Access","","2018","6","","74442","74452","The tasks of face detection and landmark localisation are a key foundation for many facial analysis applications, while great advancements have been achieved in recent years there are still challenges to increase the precision of face detection. Within this paper, we present our novel method the Integrated Deep Model (IDM), fusing two state-of-the-art deep learning architectures, namely, Faster R-CNN and a stacked hourglass for improved face detection precision and accurate landmark localisation. Integration is achieved through the application of a novel optimisation function and is shown in experimental evaluation to increase accuracy of face detection specifically precision by reducing false positive detection's by an average of 62%. Our proposed IDM method is evaluated on the Annotated Faces In-The-Wild, Annotated Facial Landmarks In The Wild and the Face Detection Dataset and Benchmark face detection test sets and shows a high level of recall and precision when compared with previously proposed methods. Landmark localisation is evaluated on the Annotated Faces In-The-Wild and 300-W test sets, this specifically focuses on localisation accuracy from detected face bounding boxes when compared with baseline evaluations using ground truth bounding boxes. Our findings highlight only a small 0.005% maximum increase in error which is more profound for the subset of facial landmarks which border the face.","","","10.1109/ACCESS.2018.2882227","Engineering and Physical Sciences Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8540344","Computer vision;face detection;machine learning","Face detection;Face;Task analysis;Computational modeling;Computer architecture;Shape;Solid modeling","convolutional neural nets;face recognition;image annotation;learning (artificial intelligence)","ground truth bounding boxes;IDM method;stacked hourglass;Faster R-CNN;in the wild images;face bounding boxes detection;annotated facial landmarks;annotated faces in-the-wild;deep learning architectures;integrated deep model;landmark localization;false positive detection;improved face detection precision;facial analysis applications","","5","60","","","","","IEEE","IEEE Journals"
"EAC-Net: Deep Nets with Enhancing and Cropping for Facial Action Unit Detection","W. Li; F. Abtahi; Z. Zhu; L. Yin","Department of Electrical Engineering, Grove School of Engineering, CUNY City College, New York, NY; Department of Computer Science, CUNY Graduate Center, New York, NY; Department of Computer Science, Grove School of Engineering, CUNY City College, New York, NY; Department of Computer Science, Thomas J. Watson School of Engineering and Applied Science, SUNY Binghamton University, Binghamton, NY","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","11","2583","2596","In this paper, we propose a deep learning based approach for facial action unit (AU) detection by enhancing and cropping regions of interest of face images. The approach is implemented by adding two novel nets (a.k.a. layers): the enhancing layers and the cropping layers, to a pretrained convolutional neural network (CNN) model. For the enhancing layers (noted as E-Net), we have designed an attention map based on facial landmark features and apply it to a pretrained neural network to conduct enhanced learning. For the cropping layers (noted as C-Net), we crop facial regions around the detected landmarks and design individual convolutional layers to learn deeper features for each facial region. We then combine the E-Net and the C-Net to construct a so-called Enhancing and Cropping Net (EAC-Net), which can learn both features enhancing and region cropping functions effectively. The EAC-Net integrates three important elements, i.e., learning transfer, attention coding, and regions of interest processing, making our AU detection approach more efficient and more robust to facial position and orientation changes. Our approach shows a significant performance improvement over the state-of-the-art methods when tested on the BP4D and DISFA AU datasets. The EAC-Net with a slight modification also shows its potentials in estimating accurate AU intensities. We have also studied the performance of the proposed EAC-Net under two very challenging conditions: (1) faces with partial occlusion and (2) faces with large head pose variations. Experimental results show that (1) the EAC-Net learns facial AUs correlation effectively and predicts AUs reliably even with only half of a face being visible, especially for the lower half; (2) Our EAC-Net model also works well under very large head poses, which outperforms significantly a compared baseline approach. It further shows that the EAC-Net works much better without a face frontalization than with face frontalization through image warping as pre-processing, in terms of computational efficiency and AU detection accuracy.","","","10.1109/TPAMI.2018.2791608","US National Science Foundation; VentureWell; US National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8253509","Convolutional neural network;facial analysis;attention coding;regions of interest;facial occlusion;head poses","Gold;Lips;Face;Feature extraction;Convolutional codes;Encoding;Robustness","face recognition;feature extraction;image classification;learning (artificial intelligence);neural nets","deep nets;facial action unit detection;deep learning based approach;cropping layers;pretrained convolutional neural network model;facial landmark features;crop facial regions;design individual convolutional layers;facial region;region cropping functions;AU detection approach;EAC-Net learns facial AUs correlation","","6","42","","","","","IEEE","IEEE Journals"
"A Deep Neural Network With Spatial Pooling (DNNSP) for 3-D Point Cloud Classification","Z. Wang; L. Zhang; L. Zhang; R. Li; Y. Zheng; Z. Zhu","School of Land Science and Technology, China University of Geosciences, Beijing, China; Faculty of Geographical Science, Beijing Key Laboratory of Environmental Remote Sensing and Digital City, Beijing Normal University, Beijing, China; Faculty of Geographical Science, Beijing Key Laboratory of Environmental Remote Sensing and Digital City, Beijing Normal University, Beijing, China; Faculty of Geographical Science, Beijing Key Laboratory of Environmental Remote Sensing and Digital City, Beijing Normal University, Beijing, China; Faculty of Geographical Science, Beijing Key Laboratory of Environmental Remote Sensing and Digital City, Beijing Normal University, Beijing, China; Faculty of Geographical Science, Beijing Key Laboratory of Environmental Remote Sensing and Digital City, Beijing Normal University, Beijing, China","IEEE Transactions on Geoscience and Remote Sensing","","2018","56","8","4594","4604","The large number of object categories and many overlapping or closely neighboring objects in large-scale urban scenes pose great challenges in point cloud classification. Most works in deep learning have achieved a great success on regular input representations, but they are hard to be directly applied to classify point clouds due to the irregularity and inhomogeneity of the data. In this paper, a deep neural network with spatial pooling (DNNSP) is proposed to classify large-scale point clouds without rasterization. The DNNSP first obtains the point-based feature descriptors of all points in each point cluster. The distance minimum spanning tree-based pooling is then applied in the point feature representation to describe the spatial information among the points in the point clusters. The max pooling is next employed to aggregate the point-based features into the cluster-based features. To assure the DNNSP is invariant to the point permutation and sizes of the point clusters, the point-based feature representation is determined by the multilayer perception (MLP) and the weight sharing for each point is retained, which means that the weight of each point in the same layer is the same. In this way, the DNNSP can learn the features of points scaled from the entire regions to the centers of the point clusters, which makes the point cluster-based feature representations robust and discriminative. Finally, the cluster-based features are input to another MLP for point cloud classification. We have evaluated qualitatively and quantitatively the proposed method using several airborne laser scanning and terrestrial laser scanning point cloud data sets. The experimental results have demonstrated the effectiveness of our method in improving classification accuracy.","","","10.1109/TGRS.2018.2829625","Natural Science Foundation of Beijing Municipality; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8362791","Deep neural network;point cloud classification;spatial pooling","Three-dimensional displays;Feature extraction;Machine learning;Shape;Neural networks;Semantics;Aggregates","feature extraction;geophysical image processing;image classification;image representation;learning (artificial intelligence);multilayer perceptrons;trees (mathematics)","3D point cloud classification;multilayer perception;terrestrial laser scanning point cloud data sets;point cluster-based feature representations;cluster-based features;distance minimum spanning tree-based pooling;point-based feature descriptors;DNNSP;spatial pooling;deep neural network","","","63","","","","","IEEE","IEEE Journals"
"More Than a Feeling: Learning to Grasp and Regrasp Using Vision and Touch","R. Calandra; A. Owens; D. Jayaraman; J. Lin; W. Yuan; J. Malik; E. H. Adelson; S. Levine","Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, Berkeley, CA, USA; Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, Berkeley, CA, USA; Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, Berkeley, CA, USA; Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, Berkeley, CA, USA; Massachusetts Institute of Technology, Cambridge, MA, USA; Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, Berkeley, CA, USA; Massachusetts Institute of Technology, Cambridge, MA, USA; Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, Berkeley, CA, USA","IEEE Robotics and Automation Letters","","2018","3","4","3300","3307","For humans, the process of grasping an object relies heavily on rich tactile feedback. Most recent robotic grasping work, however, has been based only on visual input, and thus cannot easily benefit from feedback after initiating contact. In this letter, we investigate how a robot can learn to use tactile information to iteratively and efficiently adjust its grasp. To this end, we propose an end-to-end action-conditional model that learns regrasping policies from raw visuo-tactile data. This model - a deep, multimodal convolutional network - predicts the outcome of a candidate grasp adjustment, and then executes a grasp by iteratively selecting the most promising actions. Our approach requires neither calibration of the tactile sensors nor any analytical modeling of contact forces, thus reducing the engineering effort required to obtain efficient grasping policies. We train our model with data from about 6450 grasping trials on a two-finger gripper equipped with GelSight high-resolution tactile sensors on each finger. Across extensive experiments, our approach outperforms a variety of baselines at 1) estimating grasp adjustment outcomes, 2) selecting efficient grasp adjustments for quick grasping, and 3) reducing the amount of force applied at the fingers, while maintaining competitive performance. Finally, we study the choices made by our model and show that it has successfully acquired useful and interpretable grasping behaviors.","","","10.1109/LRA.2018.2852779","Berkeley DeepDrive; NVIDIA; Amazon; Toyota Research Institute; MIT Lincoln Labs; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8403291","Deep learning in robotics and automation;grasping;perception for grasping and manipulation;force and tactile sensing","Grasping;Tactile sensors;Force;Analytical models","dexterous manipulators;grippers;haptic interfaces;learning (artificial intelligence);robot vision;tactile sensors","regrasp;rich tactile feedback;visual input;initiating contact;tactile information;end-to-end action-conditional model;raw visuo-tactile data;deep network;multimodal convolutional network;candidate grasp adjustment;promising actions;analytical modeling;contact forces;efficient grasping policies;GelSight high-resolution tactile sensors;grasp adjustment outcomes;efficient grasp adjustments;quick grasping;useful grasping behaviors;interpretable grasping behaviors;robotic grasping work;regrasping policy learning;grasping trials;two-finger gripper","","16","41","","","","","IEEE","IEEE Journals"
"Unsupervised Person Re-identification by Deep Asymmetric Metric Embedding","H. Yu; A. Wu; W. Zheng","School of Data and Computer Science, SUN YAT-SEN University, Guangzhou, Guangdong China (e-mail: xKoven@gmail.com); School of Electronic Information and Technology, SUN YAT-SEN University, Guangzhou, Guangdong China (e-mail: wuancong@mail2.sysu.edu.cn); Department of Computer Science, SUN YAT-SEN University, Guangzhou, Guangdong China (e-mail: wszheng@ieee.org)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","PP","99","1","1","Person re-identification (Re-ID) aims to match identities across non-overlapping camera views. Researchers have proposed many Re-ID models which require quantities of cross-view pairwise labelled data. This limits their scalabilities to many applications where a large amount of cross-view data is available but unlabelled. Although some unsupervised Re-ID models have been proposed to address the scalability problem, they often suffer from the view-specific bias which is caused by dramatic variances across camera views, e.g., different illumination and viewpoints. The dramatic variances induce view-specific feature distortions, which is disturbing in finding cross-view discriminative information. We propose to explicitly address this problem by learning an asymmetric distance metric based on cross-view clustering. The asymmetric metric allows specific feature transformations for each view to tackle the specific feature distortions. We then design a novel unsupervised loss function to embed the asymmetric metric into a deep neural network to develop a novel unsupervised framework. In such a way, it jointly learns the feature representation and the unsupervised asymmetric metric. Our framework learns a compact cross-view cluster structure of Re-ID data, and thus help alleviate the view-specific bias and facilitate mining the potential cross-view discriminative information for unsupervised Re-ID. Extensive experiments show our framework's effectiveness.","","","10.1109/TPAMI.2018.2886878","Guangdong Province Science and Technology Innovation Leading Talents; National Key Research and Development Program of China; National Natural Science Foundation of China; Royal Society Newton Advanced Fellowship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8576568","Unsupervised person re-identification;unsupervised metric learning;unsupervised deep learning;cross-view clustering;deep clustering","Measurement;Cameras;Pattern matching;Distortion;Image color analysis;Feature extraction;Dictionaries","","","","3","","","","","","IEEE","IEEE Early Access Articles"
"Electric Locomotive Bearing Fault Diagnosis Using a Novel Convolutional Deep Belief Network","H. Shao; H. Jiang; H. Zhang; T. Liang","School of Aeronautics, Northwestern Polytechnical University, Xi&#x0027;an, China; School of Aeronautics, Northwestern Polytechnical University, Xi&#x0027;an, China; School of Aeronautics, Northwestern Polytechnical University, Xi&#x0027;an, China; School of Aeronautics, Northwestern Polytechnical University, Xi&#x0027;an, China","IEEE Transactions on Industrial Electronics","","2018","65","3","2727","2736","Bearing fault diagnosis is of significance to enhance the reliability and security of electric locomotive. In this paper, a novel convolutional deep belief network (CDBN) is proposed for bearing fault diagnosis. First, an auto-encoder is used to compress data and reduce the dimension. Second, a novel CDBN is constructed with Gaussian visible units to learn the representative features. Third, exponential moving average is employed to improve the performance of the constructed deep model. The proposed method is applied to analyze experimental signals collected from electric locomotive bearings. The results show that the proposed method is more effective than the traditional methods and standard deep learning methods.","","","10.1109/TIE.2017.2745473","National Natural Science Foundation of China; Shanghai Engineering Research Center of Civil Aircraft Health Monitoring Foundation of China; Innovation Foundation for Doctor Dissertation of Northwestern Polytechnical University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8016669","Convolutional deep belief network (CDBN);electric locomotive bearing;exponential moving average (EMA);fault diagnosis;feature learning","Fault diagnosis;Standards;Feature extraction;Machine learning;Convolution;Vibrations;Support vector machines","belief networks;convolution;data compression;electric locomotives;fault diagnosis;Gaussian processes;machine bearings;mechanical engineering computing;moving average processes","novel convolutional deep belief network;Gaussian visible units;electric locomotive bearings;electric locomotive bearing fault diagnosis;auto-encoder;exponential moving average","","29","33","Traditional","","","","IEEE","IEEE Journals"
"Deep Recurrent Neural Networks for Winter Vegetation Quality Mapping via Multitemporal SAR Sentinel-1","D. Ho Tong Minh; D. Ienco; R. Gaetano; N. Lalande; E. Ndikumana; F. Osman; P. Maurel","UMR-TETIS Laboratory, IRSTEA, University of Montpellier, Montpellier, France; UMR-TETIS Laboratory, IRSTEA, University of Montpellier, Montpellier, France; UMR-TETIS Laboratory, CIRAD, University of Montpellier, Montpellier, France; Envylis Cie, Villeneuve-les-Maguelone, France; UMR-TETIS Laboratory, IRSTEA, University of Montpellier, Montpellier, France; UMR-TETIS Laboratory, IRSTEA, University of Montpellier, Montpellier, France; UMR-TETIS Laboratory, IRSTEA, University of Montpellier, Montpellier, France","IEEE Geoscience and Remote Sensing Letters","","2018","15","3","464","468","Mapping winter vegetation quality is a challenging problem in remote sensing. This is due to cloud coverage in winter periods, leading to a more intensive use of radar rather than optical images. The aim of this letter is to provide a better understanding of the capabilities of Sentinel-1 radar images for winter vegetation quality mapping through the use of deep learning techniques. Analysis is carried out on a multitemporal Sentinel-1 data over an area around Charentes-Maritimes, France. This data set was processed in order to produce an intensity radar data stack from October 2016 to February 2017. Two deep recurrent neural network (RNN)-based classifiers were employed. Our work revealed that the results of the proposed RNN models clearly outperformed classical machine learning approaches (support vector machine and random forest).","","","10.1109/LGRS.2018.2794581","European Space Agency, Centre National d’Etudes Spatiales/Terre, Ocean, Surfaces Continentales, Atmosphere; National Research Agency within the framework of the program “Investissements d’Avenir” for the GEOSUD; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8277174","Gated recurrent unit (GRU);long short term memory (LSTM);multitemporal;recurrent neural network (RNN);Sentinel-1;synthetic aperture radar (SAR);vegetation quality","Synthetic aperture radar;Logic gates;Vegetation mapping;Time series analysis;Mathematical model;Recurrent neural networks;Neurons","geophysical image processing;image classification;learning (artificial intelligence);radar imaging;recurrent neural nets;remote sensing by radar;support vector machines;synthetic aperture radar;vegetation mapping","winter periods;Sentinel-1 radar images;winter vegetation quality mapping;deep learning techniques;multitemporal Sentinel-1 data;intensity radar data stack;deep recurrent neural network;multitemporal SAR Sentinel-1;France;Charentes-Maritimes;AD 2016 10 to 2017 02;RNN-based classifiers;support vector machine;random forest;classical machine learning approaches;optical images","","4","20","","","","","IEEE","IEEE Journals"
"Unconstrained ear recognition using deep neural networks","S. Dodge; J. Mounsef; L. Karam","Arizona State University, USA; Arizona State University, USA; Arizona State University, USA","IET Biometrics","","2018","7","3","207","214","The authors perform unconstrained ear recognition using transfer learning with deep neural networks (DNNs). First, they show how existing DNNs can be used as a feature extractor. The extracted features are used by a shallow classifier to perform ear recognition. Performance can be improved by augmenting the training dataset with small image transformations. Next, they compare the performance of the feature-extraction models with fine-tuned networks. However, because the datasets are limited in size, a fine-tuned network tends to over-fit. They propose a deep learning-based averaging ensemble to reduce the effect of over-fitting. Performance results are provided on unconstrained ear recognition datasets, the AWE and CVLE datasets as well as a combined AWE + CVLE dataset. They show that their ensemble results in the best recognition performance on these datasets as compared to DNN feature-extraction based models and single fine-tuned models.","","","10.1049/iet-bmt.2017.0208","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8340918","","","ear;feature extraction;image classification;learning (artificial intelligence);neural nets","training dataset;feature-extraction models;unconstrained ear recognition datasets;combined AWE + CVLE dataset;deep neural networks;transfer learning;feature extractor;DNNs;deep learning-based averaging ensemble;shallow classifier","","2","44","","","","","IET","IET Journals"
"Spatio–Spectral Representation Learning for Electroencephalographic Gait-Pattern Classification","S. K. Goh; H. A. Abbass; K. C. Tan; A. Al-Mamun; N. Thakor; A. Bezerianos; J. Li","Department of Electrical and Computer Engineering, Singapore Institute for Neurotechnology, National University of Singapore, Singapore; Trusted Autonomy Group, School of Engineering and Information Technology, University of New South Wales, Canberra, ACT, Australia; Department of Computer Science, City University of Hong Kong, Hong Kong; Department of Electrical and Computer Engineering, National University of Singapore, Singapore; Singapore Institute for Neurotechnology, National University of Singapore, Singapore; Singapore Institute for Neurotechnology, National University of Singapore, Singapore; Singapore Institute for Neurotechnology, National University of Singapore, Singapore","IEEE Transactions on Neural Systems and Rehabilitation Engineering","","2018","26","9","1858","1867","The brain plays a pivotal role in locomotion by coordinating muscles through interconnections that get established by the peripheral nervous system. To date, many attempts have been made to reveal the underlying mechanisms of humans' gait. However, decoding cortical processes associated with different walking conditions using EEG signals for gait-pattern classification is a less-explored research area. In this paper, we design an EEG-based experiment with four walking conditions (i.e., free walking, and exoskeleton-assisted walking at zero, low, and high assistive forces by the use of a unilateral exoskeleton to right lower limb). We proposed spatio-spectral representation learning (SSRL), a deep neural network topology with shared weights to learn the spatial and spectral representations of multi-channel EEG signals during walking. Adoption of weight sharing reduces the number of free parameters, while learning spatial and spectral equivariant features. SSRL outperformed state-of-the-art methods in decoding gait patterns, achieving a classification accuracy of 77.8%. Moreover, the features extracted in the intermediate layer of SSRL were observed to be more discriminative than the hand-crafted features. When analyzing the weights of the proposed model, we found an intriguing spatial distribution that is consistent with the distribution found in well-known motor-activated cortical regions. Our results show that SSRL advances the ability to decode human locomotion and it could have important implications for exoskeleton design, rehabilitation processes, and clinical diagnosis.","","","10.1109/TNSRE.2018.2864119","Ministry of Education - Singapore; Australian Research Council; Research Grants Council of the Hong Kong Special Administrative Region, China; National University of Singapore; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8428659","Spatio-spectral representation learning;electroencephalogram (EEG);exoskeleton;gait pattern;convolutional neural network","Electroencephalography;Legged locomotion;Brain modeling;Exoskeletons;Feature extraction;Machine learning;Biological neural networks","electroencephalography;feature extraction;gait analysis;learning (artificial intelligence);medical signal processing;muscle;neural nets;neurophysiology;patient rehabilitation;pattern classification","electroencephalographic gait-pattern classification;pivotal role;peripheral nervous system;less-explored research area;free walking;high assistive forces;unilateral exoskeleton;spatio-spectral representation learning;SSRL;deep neural network topology;spatial equivariant features;spectral equivariant features;exoskeleton design;humans gait;EEG signals;exoskeleton-assisted walking;low assistive forces;weight sharing adoption;hand-crafted features;intriguing spatial distribution;motor-activated cortical regions;decode human locomotion;rehabilitation processes;clinical diagnosis;cortical processes decoding;gait patterns decoding;muscles coordination","","","72","","","","","IEEE","IEEE Journals"
"Deep Gaussian Mixture-Hidden Markov Model for Classification of EEG Signals","M. Wang; S. Abdelfattah; N. Moustafa; J. Hu","School of Engineering and Information Technology, University of New South Wales Canberra at ADFA, Campbell, ACT, Australia; School of Engineering and Information Technology, University of New South Wales Canberra at ADFA, Campbell, ACT, Australia; School of Engineering and Information Technology, University of New South Wales Canberra at ADFA, Campbell, ACT, Australia; School of Engineering and Information Technology, University of New South Wales Canberra at ADFA, Campbell, ACT, Australia","IEEE Transactions on Emerging Topics in Computational Intelligence","","2018","2","4","278","287","Electroencephalography (EEG) signals are complex dynamic phenomena that exhibit nonlinear and nonstationary behaviors. These characteristics tend to undermine the reliability of existing hand-crafted EEG features that ignore time-varying information and impair the performances of classification models. In this paper, we propose a novel method that can automatically capture the nonstationary dynamics of EEG signals for diverse classification tasks. It consists of two components. The first component uses an autoregressive-deep variational autoencoder model for automatic feature extraction, and the second component uses a Gaussian mixture-hidden Markov model for EEG classification with the extracted features. We compare the performance of our proposed method and the state-of-the-art methods in two EEG classification tasks, subject, and event classification. Results show that our approach outperforms the others by averages of 15% ± 6.3 (p-value <; 0.05) and 22% ± 5.7 (p-value <; 0.05) for subject and event classifications, respectively.","","","10.1109/TETCI.2018.2829981","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8416796","EEG classification;time-series;deep learning;autoencoder;Gaussian mixture model;hidden Markov model","Electroencephalography;Brain modeling;Hidden Markov models;Feature extraction;Task analysis;Machine learning;Markov processes","electroencephalography;feature extraction;Gaussian processes;hidden Markov models;medical signal processing;signal classification","electroencephalography signals;complex dynamic phenomena;time-varying information;classification models;nonstationary dynamics;diverse classification tasks;autoregressive-deep variational autoencoder model;automatic feature extraction;EEG classification tasks;event classification;deep Gaussian mixture-hidden Markov model;EEG signal classification;hand-crafted EEG features","","4","37","","","","","IEEE","IEEE Journals"
"Prototype-Incorporated Emotional Neural Network","O. K. Oyedotun; A. Khashman","Interdisciplinary Center for Security, Reliability and Trust (SnT), University of Luxembourg, Luxembourg, Luxembourg; Final International University, Girne, Turkey","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","8","3560","3572","Artificial neural networks (ANNs) aim to simulate the biological neural activities. Interestingly, many “engineering” prospects in ANN have relied on motivations from cognition and psychology studies. So far, two important learning theories that have been subject of active research are the prototype and adaptive learning theories. The learning rules employed for ANNs can be related to adaptive learning theory, where several examples of the different classes in a task are supplied to the network for adjusting internal parameters. Conversely, the prototype-learning theory uses prototypes (representative examples); usually, one prototype per class of the different classes contained in the task. These prototypes are supplied for systematic matching with new examples so that class association can be achieved. In this paper, we propose and implement a novel neural network algorithm based on modifying the emotional neural network (EmNN) model to unify the prototype- and adaptive-learning theories. We refer to our new model as “prototype-incorporated EmNN”. Furthermore, we apply the proposed model to two real-life challenging tasks, namely, static hand-gesture recognition and face recognition, and compare the result to those obtained using the popular back-propagation neural network (BPNN), emotional BPNN (EmNN), deep networks, an exemplar classification model, and k-nearest neighbor.","","","10.1109/TNNLS.2017.2730179","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8010871","Emotional neural network (EmNN);face recognition;hand-gesture recognition;neural network;prototype learning","Prototypes;Adaptation models;Feature extraction;Biological neural networks;Training;Neurons","backpropagation;biology computing;cognition;face recognition;gesture recognition;learning (artificial intelligence);nearest neighbour methods;neural nets;psychology","emotional neural network model;EmNN;deep networks;artificial neural networks;ANN;biological neural activities;psychology studies;adaptive learning theories;prototype-learning theory;back-propagation neural network;cognition studies;hand-gesture recognition;face recognition;emotional BPNN;k-nearest neighbor","","","63","","","","","IEEE","IEEE Journals"
"Investigating Raw Wave Deep Neural Networks for End-to-End Speaker Spoofing Detection","H. Dinkel; Y. Qian; K. Yu","Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China","IEEE/ACM Transactions on Audio, Speech, and Language Processing","","2018","26","11","2002","2014","Recent advances in automatic speaker verification (ASV) lead to an increased interest in securing these systems for real-world applications. Malicious spoofing attempts against ASV systems can lead to serious security breaches. A spoofing attack within the context of ASV is a condition in which a (potentially harmful) person successfully masks as another, to the ASV system already known person by falsifying or manipulating data. While most previous work focuses on enhanced, spoof-aware features, end-to-end models can be a potential alternative. In this paper, we investigate the training of a raw wave front-ends for deep convolutional, long short-term memory (LSTM) and vanilla neural networks, which are analyzed for their suitability toward spoofing detection, regarding the influence of frame size, number of output neurons, and sequence length. A joint convolutional LSTM neural network (CLDNN) is proposed, which outperforms previous attempts on the BTAS2016 dataset (0.82% → 0.19% HTER), placing itself as the current state-of-the-art model for the dataset. We show that end-to-end approaches are appropriate for the important replay detection task and show that the proposed model is capable of distinguishing device-invariant spoofing attempts. Regarding the ASVspoof2015 dataset, the end-to-end solution achieves an equal error rate (EER) of 0.00% for the S1-S9 conditions. We show that the end-to-end approach based on a raw waveform input can outperform common cepstral features, without the use of context-dependent frame extensions. In addition, a cross-database (domain mismatch) scenario is also evaluated, which shows that the proposed CLDNN model trained on the BTAS2016 dataset achieves an EER of 25.7% on the ASVspoof2015 dataset.","","","10.1109/TASLP.2018.2851155","National Key Research and Development Program of China; NSFC; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8398462","Deep learning;end-to-end;speaker verification;spoofing detection","Feature extraction;Task analysis;Speech processing;Machine learning;Mel frequency cepstral coefficient;Biological neural networks","convolution;feature extraction;feedforward neural nets;recurrent neural nets;security of data;speaker recognition","raw wave deep neural networks;end-to-end speaker spoofing detection;automatic speaker verification;malicious spoofing attempts;ASV system;serious security breaches;spoofing attack;spoof-aware features;ASVspoof2015 dataset;convolutional LSTM neural network;deep convolutional long short-term memory;vanilla neural networks","","3","66","","","","","IEEE","IEEE Journals"
"DeMeshNet: Blind Face Inpainting for Deep MeshFace Verification","S. Zhang; R. He; Z. Sun; T. Tan","Center for Research on Intelligent Perception and Computing, National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Center for Research on Intelligent Perception and Computing, National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Center for Research on Intelligent Perception and Computing, National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Center for Research on Intelligent Perception and Computing, National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Information Forensics and Security","","2018","13","3","637","647","MeshFace photos have been widely used in many Chinese business organizations to protect ID face photos from being misused. The occlusions incurred by random meshes severely degenerate the performance of face verification systems, which raises the MeshFace verification problem between MeshFace and daily photos. Previous methods cast this problem as a typical low-level vision problem, i.e., blind inpainting. They recover perceptually pleasing clear ID photos from MeshFaces by enforcing pixel level similarity between the recovered ID images and the ground-truth clear ID images and then perform face verification on them. Essentially, face verification is conducted on a compact feature space rather than the image pixel space. Therefore, this paper argues that pixel level similarity and feature level similarity jointly offer the key to improve the verification performance. Based on this insight, we offer a novel feature oriented blind face inpainting framework. Specifically, we implement this by establishing a novel DeMeshNet, which consists of three parts. The first part addresses blind inpainting of the MeshFaces by implicitly exploiting extra supervision from the occlusion position to enforce pixel level similarity. The second part explicitly enforces a feature level similarity in the compact feature space, which can explore informative supervision from the feature space to produce better inpainting results for verification. The last part copes with face alignment within the net via a customized spatial transformer module when extracting deep facial features. All three parts are implemented within an end-to-end network that facilitates efficient optimization. Extensive experiments on two MeshFace data sets demonstrate the effectiveness of the proposed DeMeshNet as well as the insight of this paper.","","","10.1109/TIFS.2017.2763119","National Natural Science Foundation of China; Beijing Municipal Science and Technology Commission; State Key Development Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8067496","MeshFace;face verification;blind inpainting;deep learning;DeMeshNet;spatial transformer","Face;Feature extraction;Face recognition;Training;Facial features;Machine learning","computer vision;face recognition;feature extraction;image fusion;image matching;image representation","low-level vision problem;blind inpainting;clear ID photos;pixel level similarity;recovered ID images;compact feature space;image pixel space;feature level similarity;blind face inpainting framework;face alignment;deep facial features;MeshFace data sets;DeMeshNet;deep MeshFace verification;MeshFace photos;Chinese business organizations;ID face photos;face verification systems;MeshFace verification problem;daily photos","","5","59","","","","","IEEE","IEEE Journals"
"Improved Deep Hybrid Networks for Urban Traffic Flow Prediction Using Trajectory Data","Z. Duan; Y. Yang; K. Zhang; Y. Ni; S. Bajgain","School of Information and Engineering, Chang’an University, Xi’an, China; School of Information and Engineering, Chang’an University, Xi’an, China; School of Information and Engineering, Chang’an University, Xi’an, China; School of Information and Engineering, Chang’an University, Xi’an, China; School of Information and Engineering, Chang’an University, Xi’an, China","IEEE Access","","2018","6","","31820","31827","The urban traffic flow prediction is a significant issue in the intelligent transportation system. In consideration of nonlinear and spatial-temporal features of urban traffic data, we propose a deep hybrid neural network improved by greedy algorithm for urban traffic flow prediction with taxi GPS trace. The proposed deep neural network model first combines the convolutional neural network (CNN), which extracts the spatial features, with the long short term memory (LSTM), which captures the temporal information, to predict urban traffic flow. Then, the proposed model is trained by a greedy policy to short time consumption and improves accuracy when a network goes deeper. Experimental results with real taxis GPS trajectory data from Xi'an city show that the improved deep hybrid CNN-LSTM model can achieve higher prediction accuracy and shorter time consumption compared with existing methods.","","","10.1109/ACCESS.2018.2845863","Key Scientific and Technological Innovation Team of Shaanxi Province; International Scientific and Technological Cooperation Project of Shaanxi Province; China Scholarship Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8377977","Deep hybrid networks;greedy policy;trajectory data;urban traffic-flow prediction","Global Positioning System;Neural networks;Trajectory;Predictive models;Feature extraction;Data models;Public transportation","feedforward neural nets;Global Positioning System;intelligent transportation systems;learning (artificial intelligence);road traffic","deep hybrid neural network;urban traffic flow prediction;deep neural network model;convolutional neural network;taxis GPS trajectory data;improved deep hybrid CNN-LSTM model;intelligent transportation system;nonlinear features;spatial-temporal features;Xi'an city","","12","40","","","","","IEEE","IEEE Journals"
"Cross-Domain Sentiment Classification by Capsule Network With Semantic Rules","B. Zhang; X. Xu; M. Yang; X. Chen; Y. Ye","School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; College of Computer Science and Software, Shenzhen University, Shenzhen, China; School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China","IEEE Access","","2018","6","","58284","58294","Sentiment analysis is an important but challenging task. Remarkable success has been achieved on domains where sufficient labeled training data is available. Nevertheless, annotating sufficient data is labor-intensive and time-consuming, establishing significant barriers for adapting the sentiment classification systems to new domains. In this paper, we introduce a Capsule network for sentiment analysis in domain adaptation scenario with semantic rules (CapsuleDAR). CapsuleDAR exploits capsule network to encode the intrinsic spatial part-whole relationship constituting domain invariant knowledge that bridges the knowledge gap between the source and target domains. Furthermore, we also propose a rule network to incorporate the semantic rules into the capsule network to enhance the comprehensive sentence representation learning. Extensive experiments are conducted to evaluate the effectiveness of the proposed CapsuleDAR model on a real world data set of four domains. Experimental results demonstrate that CapsuleDAR achieves substantially better performance than the strong competitors for the cross-domain sentiment classification task.","","","10.1109/ACCESS.2018.2874623","National Natural Science Foundation of China; Shenzhen Science and Technology Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8488682","Cross-domain sentiment classification;capsule network;semantic rules;deep learning","Semantics;Knowledge engineering;Sentiment analysis;Machine learning;Machine learning algorithms;Computer science;Training data","learning (artificial intelligence);pattern classification;sentiment analysis","capsule network;semantic rules;sentiment analysis;sentiment classification systems;domain adaptation scenario;CapsuleDAR;domain invariant knowledge;rule network;cross-domain sentiment classification;deep learning","","3","37","","","","","IEEE","IEEE Journals"
"DeCNT: Deep Deformable CNN for Table Detection","S. A. Siddiqui; M. I. Malik; S. Agne; A. Dengel; S. Ahmed","German Research Center for Artificial Intelligence, Kaiserslautern, Germany; School of Electrical Engineering and Computer Science, National University of Sciences and Technology, Islamabad, Pakistan; German Research Center for Artificial Intelligence, Kaiserslautern, Germany; German Research Center for Artificial Intelligence, Kaiserslautern, Germany; German Research Center for Artificial Intelligence, Kaiserslautern, Germany","IEEE Access","","2018","6","","74151","74161","This paper presents a novel approach for the detection of tables present in documents, leveraging the potential of deep neural networks. Conventional approaches for table detection rely on heuristics that are error prone and specific to a dataset. In contrast, the presented approach harvests the potential of data to recognize tables of arbitrary layout. Most of the prior approaches for table detection are only applicable to PDFs, whereas, the presented approach directly works on images making it generally applicable to any format. The presented approach is based on a novel combination of deformable CNN with faster R-CNN/FPN. Conventional CNN has a fixed receptive field which is problematic for table detection since tables can be present at arbitrary scales along with arbitrary transformations (orientation). Deformable convolution conditions its receptive field on the input itself allowing it to mold its receptive field according to its input. This adaptation of the receptive field enables the network to cater for tables of arbitrary layout. We evaluated the proposed approach on two major publicly available table detection datasets: ICDAR-2013 and ICDAR-2017 POD. The presented approach was able to surpass the state-of-the-art performance on both ICDAR-2013 and ICDAR-2017 POD datasets with a F-measure of 0.994 and 0.968, respectively, indicating its effectiveness and superiority for the task of table detection.","","","10.1109/ACCESS.2018.2880211","Bundesministerium für Bildung und Forschung; Nvidia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8540832","Deep learning;representation learning;convolutional neural networks;object detection;deformable convolution;table detection;table spotting;faster R-CNN;FPN","Feature extraction;Convolution;Layout;Task analysis;Hidden Markov models;Data mining","document image processing;neural nets;object detection","deep deformable CNN;arbitrary layout;receptive field;fixed receptive field;deep neural networks;table detection datasets","","1","34","","","","","IEEE","IEEE Journals"
"Deep Active Learning with Contaminated Tags for Image Aesthetics Assessment","Z. Liu; Z. Wang; Y. Yao; L. Zhang; L. Shao","school of CSIE, Hefei University of Technology, Hefei, Anhui, China.; school of CSIE, Hefei University of Technology, Hefei, Anhui, China.; State Grid Zhejiang Electric Power Company Information & Telecommunication Branch,Hangzhou, China.; school of CSIE, Hefei University of Technology, Hefei, Anhui, China.; School of Computing Sciences, University of East Anglia, UK.","IEEE Transactions on Image Processing","","2018","PP","99","1","1","Image aesthetic quality assessment has becoming an indispensable technique that facilitates a variety of image applications, e.g., photo retargeting and non-realistic rendering. Conventional approaches suffer from the following limitations: 1) the inefficiency of semantically describing images due to the inherent tag noise and incompletion, 2) the difficulty of accurately reflecting how humans actively perceive various regions inside each image, and 3) the challenge of incorporating the aesthetic experiences of multiple users. To solve these problems, we propose a novel semi-supervised deep active learning (SDAL) algorithm, which discovers how humans perceive semantically important regions from a large quantity of images partially assigned with contaminated tags. More specifically, as humans usually attend to the foreground objects before understanding them, we extract a succinct set of BING (binarized normed gradients) [60]-based object patches from each image. To simulate human visual perception, we propose SDAL which hierarchically learns human gaze shifting path (GSP) by sequentially linking semantically important object patches from each scenery. Noticeably, SDLA unifies the semantically important regions discovery and deep GSP feature learning into a principled framework, wherein only a small proportion of tagged images are adopted. Moreover, based on the sparsity penalty, SDLA can optimally abandon the noisy or redundant low-level image features. Finally, by leveraging the deeply-learned GSP features, a probabilistic model is developed for image aesthetics assessment, where the experience of multiple professional photographers can be encoded. Besides, auxiliary quality-related features can be conveniently integrated into our probabilistic model. Comprehensive experiments on a series of benchmark image sets have demonstrated the superiority of our method. As a byproduct, eye tracking experiments have shown that GSPs generated by our SDAL are about 93% consistent with real human gaze shifting paths.","","","10.1109/TIP.2018.2828326","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8340874","Quality model;Semi-supervised;deep active learning;gaze shifting path;probabilistic model","Visualization;Feature extraction;Probabilistic logic;Computational modeling;Image color analysis;Semantics;Visual perception","","","","4","","","","","","IEEE","IEEE Early Access Articles"
"Deep Semantic Feature Learning for Software Defect Prediction","S. Wang; T. Liu; J. Nam; L. Tan","Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, Ontario Canada N2L 3G1 (e-mail: song.wang@uwaterloo.ca); Electrical and Computer Engineering, University of Waterloo, Waterloo, Ontario Canada (e-mail: t67liu@uwaterloo.ca); Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong, - Hong Kong - (e-mail: jcnam@postech.edu); Electrical and Computer Engineering, University of Waterloo, Waterloo, Ontario Canada N2L 3G1 (e-mail: lintan@uwaterloo.ca)","IEEE Transactions on Software Engineering","","2018","PP","99","1","1","Software defect prediction, which predicts defective code regions, can assist developers in finding bugs and prioritizing their testing efforts. Traditional defect prediction features often fail to capture the semantic differences between different programs. This degrades the performance of the prediction models built on these traditional features. Thus, the capability to capture the semantics in programs is required to build accurate prediction models. To bridge the gap between semantics and defect prediction features, we propose leveraging a powerful representation-learning algorithm, deep learning, to learn the semantic representations of programs automatically from source code files and code changes. Specifically, we leverage a deep belief network (DBN) to automatically learn semantic features using token vectors extracted from the programs' abstract syntax trees (AST) (for file-level defect prediction models) and source code changes (for change-level defect prediction models). We examine the effectiveness of our approach on two file-level defect prediction tasks (i.e., file-level within-project defect prediction and file-level cross-project defect prediction) and two change-level defect prediction tasks (i.e., change-level within-project defect prediction and change-level cross-project defect prediction). Our experimental results indicate that the DBN-based semantic features can significantly improve the examined defect prediction tasks. Specifically, the improvements of semantic features against existing traditional features (in F1) range from 2.1 to 41.9 percentage points for file-level within-project defect prediction, from 1.5 to 13.4 percentage points for file-level cross-project defect prediction, from 1.0 to 8.6 percentage points for change-level within-project defect prediction, and from 0.6 to 9.9 percentage points for change-level cross-project defect prediction.","","","10.1109/TSE.2018.2877612","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8502853","Defect prediction;quality assurance;deep learning;semantic features","Semantics;Predictive models;Feature extraction;Task analysis;Computer bugs;Data models","","","","3","","","","","","IEEE","IEEE Early Access Articles"
"An Inversion-Based Learning Approach for Improving Impromptu Trajectory Tracking of Robots With Non-Minimum Phase Dynamics","S. Zhou; M. K. Helwa; A. P. Schoellig","Dynamic Systems Lab, Institute for Aerospace Studies, University of Toronto, ON, Canada; Dynamic Systems Lab, Institute for Aerospace Studies, University of Toronto, ON, Canada; Dynamic Systems Lab, Institute for Aerospace Studies, University of Toronto, ON, Canada","IEEE Robotics and Automation Letters","","2018","3","3","1663","1670","This letter presents a learning-based approach for impromptu trajectory tracking for non-minimum phase systems, i.e., systems with unstable inverse dynamics. Inversion-based feedforward approaches are commonly used for improving tracking performance; however, these approaches are not directly applicable to non-minimum phase systems due to their inherent instability. In order to resolve the instability issue, existing methods have assumed that the system model is known and used preactuation or inverse approximation techniques. In this work, we propose an approach for learning a stable, approximate inverse of a non-minimum phase baseline system directly from its input-output data. Through theoretical discussions, simulations, and experiments on two different platforms, we show the stability of our proposed approach and its effectiveness for high-accuracy, impromptu tracking. Our approach also shows that including more information in the training, as is commonly assumed to be useful, does not lead to better performance but may trigger instability and impact the effectiveness of the overall approach.","","","10.1109/LRA.2018.2801471","OCE/SOSCIP TalentEdge Project #27901 and various NSERC research and equipment; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8279416","Model learning for control;deep learning in robotics and automation","Training;Trajectory;Robots;Stability analysis;Aerodynamics;Nonlinear systems","feedback;feedforward;learning (artificial intelligence);least squares approximations;robots;stability;trajectory control","learning approach;nonminimum phase dynamics;nonminimum phase systems;tracking performance;inverse approximation techniques;stable inverse;approximate inverse;nonminimum phase baseline system;impromptu trajectory tracking;inverse dynamics;feedforward approach;robot tracking","","2","22","","","","","IEEE","IEEE Journals"
"CNN-Based Joint Clustering and Representation Learning with Feature Drift Compensation for Large-Scale Image Data","C. Hsu; C. Lin","Department of Electrical Engineering, National Tsing Hua University, Hsinchu, Taiwan; Department of Electrical Engineering, National Tsing Hua University, Hsinchu, Taiwan","IEEE Transactions on Multimedia","","2018","20","2","421","429","Given a large unlabeled set of images how to efficiently and effectively group them into clusters based on extracted visual representations remains a challenging problem. To address this problem we propose a convolutional neural network (CNN) to jointly solve clustering and representation learning in an iterative manner. In the proposed method given an input image set we first randomly pick k samples and extract their features as initial cluster centroids using the proposed CNN with an initial model pretrained from the ImageNet dataset. Mini-batch k-means is then performed to assign cluster labels to individual input samples for a mini-batch of images randomly sampled from the input image set until all images are processed. Subsequently the proposed CNN simultaneously updates the parameters of the proposed CNN and the centroids of image clusters iteratively based on stochastic gradient descent. We also propose a feature drift compensation scheme to mitigate the drift error caused by feature mismatch in representation learning. Experimental results demonstrate the proposed method outperforms start-of-the-art clustering schemes in terms of accuracy and storage complexity on large-scale image sets containing millions of images.","","","10.1109/TMM.2017.2745702","Ministry of Science and Technology, Taiwan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8017517","Convolutional neural network (CNN);deep learning;image clustering;unsupervised learning","Feature extraction;Training;Visualization;Complexity theory;Clustering methods;Computer architecture","gradient methods;image classification;image representation;learning (artificial intelligence);neural nets","CNN;large-scale image data;convolutional neural network;iterative manner;initial cluster centroids;mini-batch k-means;cluster labels;image clusters;feature drift compensation scheme;feature mismatch;joint clustering and representation learning","","7","36","","","","","IEEE","IEEE Journals"
"Learning Cross-Modal Aligned Representation With Graph Embedding","Y. Zhang; J. Cao; X. Gu","Department of Electronic Engineering, Fudan University, Shanghai, China; Department of Electronic Engineering, Fudan University, Shanghai, China; Department of Electronic Engineering, Fudan University, Shanghai, China","IEEE Access","","2018","6","","77321","77333","The main task of cross-modal analysis is to learn discriminative representation shared across different modalities. In order to pursue aligned representation, conventional approaches tend to construct and optimize a linear projection or train a complex architecture of deep layers, yet it is difficult to compromise between accuracy and efficiency on modeling multimodal data. This paper proposes a novel graph-embedding learning framework implemented by neural networks. The learned embedding directly approximates the cross-modal aligned representation to perform cross-modal retrieval and image classification combining text information. Proposed framework extracts learned representation from a graph model and, simultaneously, trains a classifier under semi-supervised settings. For optimization, unlike previous methods based on the graph Laplacian regularization, a sampling strategy is adopted to generate training pairs to fully explore the inter-modal and intra-modal similarity relationship. Experimental results on various datasets show that the proposed framework outperforms other state-of-the-art methods on crossmodal retrieval. The framework also demonstrates convincing improvements on the new issue of image classification combining text information on Wiki dataset.","","","10.1109/ACCESS.2018.2881997","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8543794","Graph embedding learning;cross-modal retrieval;neural network;semi-supervised learning","Semantics;Neural networks;Feature extraction;Task analysis;Data models;Image classification;Correlation","graph theory;image classification;image representation;image retrieval;learning (artificial intelligence)","learning cross-modal aligned representation;graph embedding;cross-modal analysis;discriminative representation;cross-modal retrieval;image classification;text information;graph model;graph Laplacian regularization;training pairs;graph-embedding learning framework;inter-modal-intra-modal similarity relationship","","","53","","","","","IEEE","IEEE Journals"
"Interactive Medical Image Segmentation Using Deep Learning With Image-Specific Fine Tuning","G. Wang; W. Li; M. A. Zuluaga; R. Pratt; P. A. Patel; M. Aertsen; T. Doel; A. L. David; J. Deprest; S. Ourselin; T. Vercauteren","Department of Medical Physics and Biomedical Engineering, Wellcome EPSRC Centre for Interventional and Surgical Sciences, University College London, London, U.K.; Department of Medical Physics and Biomedical Engineering, Wellcome EPSRC Centre for Interventional and Surgical Sciences, University College London, London, U.K.; Department of Medical Physics and Biomedical Engineering, University College London, London, U.K.; Department of Medical Physics and Biomedical Engineering, Wellcome EPSRC Centre for Interventional and Surgical Sciences, University College London, London, U.K.; Department of Medical Physics and Biomedical Engineering, Wellcome EPSRC Centre for Interventional and Surgical Sciences, University College London, London, U.K.; Department of Radiology, University Hospitals KU Leuven, Leuven, Belgium; Department of Medical Physics and Biomedical Engineering, Wellcome EPSRC Centre for Interventional and Surgical Sciences, University College London, London, U.K.; Wellcome EPSRC Centre for Interventional and Surgical Sciences, Institute for Women’s Health, University College London, London, U.K.; Wellcome EPSRC Centre for Interventional and Surgical Sciences, Institute for Women’s Health, University College London, London, U.K.; Department of Medical Physics and Biomedical Engineering, Wellcome EPSRC Centre for Interventional and Surgical Sciences, University College London, London, U.K.; Department of Medical Physics and Biomedical Engineering, Wellcome EPSRC Centre for Interventional and Surgical Sciences, University College London, London, U.K.","IEEE Transactions on Medical Imaging","","2018","37","7","1562","1573","Convolutional neural networks (CNNs) have achieved state-of-the-art performance for automatic medical image segmentation. However, they have not demonstrated sufficiently accurate and robust results for clinical use. In addition, they are limited by the lack of image-specific adaptation and the lack of generalizability to previously unseen object classes (a.k.a. zero-shot learning). To address these problems, we propose a novel deep learning-based interactive segmentation framework by incorporating CNNs into a bounding box and scribble-based segmentation pipeline. We propose image-specific fine tuning to make a CNN model adaptive to a specific test image, which can be either unsupervised (without additional user interactions) or supervised (with additional scribbles). We also propose a weighted loss function considering network and interaction-based uncertainty for the fine tuning. We applied this framework to two applications: 2-D segmentation of multiple organs from fetal magnetic resonance (MR) slices, where only two types of these organs were annotated for training and 3-D segmentation of brain tumor core (excluding edema) and whole brain tumor (including edema) from different MR sequences, where only the tumor core in one MR sequence was annotated for training. Experimental results show that: 1) our model is more robust to segment previously unseen objects than state-of-the-art CNNs; 2) image-specific fine tuning with the proposed weighted loss function significantly improves segmentation accuracy; and 3) our method leads to accurate results with fewer user interactions and less user time than traditional interactive segmentation methods.","","","10.1109/TMI.2018.2791721","Wellcome Trust; Engineering and Physical Sciences Research Council; Engineering and Physical Sciences Research Council; Royal Society; University College London; Great Ormond Street Hospital Charity; University College London; Nvidia; Emerald, a GPU-accelerated High Performance Computer, made available by the Science and Engineering South Consortium operated in partnership with the STFC Rutherford-Appleton Laboratory; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8270673","Interactive image segmentation;convolutional neural network;fine-tuning;fetal MRI;brain tumor","Image segmentation;Training;Three-dimensional displays;Biomedical imaging;Two dimensional displays;Adaptation models;Testing","biomedical MRI;convolution;feedforward neural nets;human computer interaction;image segmentation;learning (artificial intelligence);medical image processing;user interfaces","image-specific fine tuning;convolutional neural networks;automatic medical image segmentation;image-specific adaptation;deep learning;2-D segmentation;3-D segmentation;interactive medical image segmentation;user interactions;bounding box;scribble-based segmentation;magnetic resonance slices","","15","37","CCBY","","","","IEEE","IEEE Journals"
"Knowledge-Guided Deep Fractal Neural Networks for Human Pose Estimation","G. Ning; Z. Zhang; Z. He","Department of Electrical Engineering and Computer Science, University of Missouri, Columbia, MO, USA; Department of Electrical Engineering and Computer Science, University of Missouri, Columbia, MO, USA; College of Information Engineering, Shenzhen University, Shenzhen, China","IEEE Transactions on Multimedia","","2018","20","5","1246","1259","Human pose estimation using deep neural networks aims to map input images with large variations into multiple body keypoints, which must satisfy a set of geometric constraints and interdependence imposed by the human body model. This is a very challenging nonlinear manifold learning process in a very high dimensional feature space. We believe that the deep neural network, which is inherently an algebraic computation system, is not the most efficient way to capture highly sophisticated human knowledge, for example those highly coupled geometric characteristics and interdependence between keypoints in human poses. In this work, we propose to explore how external knowledge can be effectively represented and injected into the deep neural networks to guide its training process using learned projections that impose proper prior. Specifically, we use the stacked hourglass design and inception-resnet module to construct a fractal network to regress human pose images into heatmaps with no explicit graphical modeling. We encode external knowledge with visual features, which are able to characterize the constraints of human body models and evaluate the fitness of intermediate network output. We then inject these external features into the neural network using a projection matrix learned using an auxiliary cost function. The effectiveness of the proposed inception-resnet module and the benefit in guided learning with knowledge projection is evaluated on two widely used human pose estimation benchmarks. Our approach achieves state-of-the-art performance on both datasets.","","","10.1109/TMM.2017.2762010","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8064661","Human pose estimation;fractal networks;knowledge-guided learning","Pose estimation;Neural networks;Training;Knowledge engineering;Fractals;Biological system modeling","feature extraction;learning (artificial intelligence);neural nets;pose estimation","human body model;intermediate network output;inception-resnet module;knowledge projection;multiple body keypoints;high dimensional feature space;highly sophisticated human knowledge;highly coupled geometric characteristics;nonlinear manifold learning process;knowledge-guided deep fractal neural networks;human pose estimation;geometric constraints;algebraic computation system;stacked hourglass design;projection matrix;auxiliary cost function","","12","75","","","","","IEEE","IEEE Journals"
"Image-to-Video Person Re-Identification With Temporally Memorized Similarity Learning","D. Zhang; W. Wu; H. Cheng; R. Zhang; Z. Dong; Z. Cai","Sun Yat-sen University, Guangzhou, China; Sun Yat-sen University, Guangzhou, China; Sun Yat-sen University, Guangzhou, China; Chinese University of Hong Kong, Hong Kong, China; ZTE Corporation, Shenzhen, China; Huizhou University, Huizhou, China","IEEE Transactions on Circuits and Systems for Video Technology","","2018","28","10","2622","2632","With the development of video surveillance in public safety field, there is an increasing research on person re-identification (re-id). In this paper, we address the image-to-video person re-id, in which the probe is an image and the gallery is consists of videos captured by nonoverlapping cameras. Compared with image, video sequence contains more temporal information that can be explored to improve the performance of re-identification system. However, it is challenging to model temporal information in the matching process of image-to-video person re-id. In this paper, we proposed a novel temporally memorized similarity learning neural network for this problem. In specific, the proposed network mainly consisted of two parts, including feature representation sub-network and similarity sub-network. In the first part, we adopted a convolutional neural network (CNN) to extract features from the input image. Given a video sequence of a person, features were first extracted from each its frame by using CNN and further forward to a long shot term memory (LSTM) network to encode the temporal information of video sequence. The outputs of LSTM were concatenated together as the feature vector of video sequences. Finally, the feature vectors of probe image and the video sequence were further forward to the similarity sub-network for distance metric learning. In the proposed framework, the feature representation and the similarity metric learning can be learned and optimized simultaneously. We evaluated the proposed framework on three public person re-id data sets, and the experimental results showed that the proposed approach is effective for the image-to-video person re-id.","","","10.1109/TCSVT.2017.2723429","National Natural Science Foundation of China; NSFC-Shenzhen Robotics Projects; Natural Science Foundation of Guangdong Province; Fundamental Research Funds for the Central Universities; ZTE Corporation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7968366","Person re-id;deep metric learning;LSTM","Feature extraction;Measurement;Video sequences;Image color analysis;Histograms;Probes;Cameras","cameras;convolution;feature extraction;feedforward neural nets;image representation;image sequences;learning (artificial intelligence);video signal processing;video surveillance","image-to-video person re-identification;public safety field;nonoverlapping cameras;image sequence;similarity learning neural network;feature representation sub-network;convolutional neural network;feature extraction;CNN;long shot term memory network;LSTM network;probe image feature vectors;distance metric learning;public person re-id data sets;similarity sub-network;video sequence;video surveillance","","5","60","","","","","IEEE","IEEE Journals"
"Learning an Intrinsic Image Decomposer Using Synthesized RGB-D Dataset","G. Han; X. Xie; J. Lai; W. Zheng","School of Data and Computer Science, Sun Yat-sen University, and Guangdong Key Laboratory of Information Security Technology, Guangzhou, China; School of Data and Computer Science, Sun Yat-sen University, and Guangdong Key Laboratory of Information Security Technology, Guangzhou, China; School of Data and Computer Science, Sun Yat-sen University, and Guangdong Key Laboratory of Information Security Technology, Guangzhou, China; School of Data and Computer Science, Sun Yat-sen University, and Guangdong Key Laboratory of Information Security Technology, Guangzhou, China","IEEE Signal Processing Letters","","2018","25","6","753","757","Intrinsic image decomposition refers to recover the albedo and shading from images, which is an ill-posed problem in signal processing. As realistic labeled data are severely lacking, it is difficult to apply learning methods in this issue. In this letter, we propose using a synthesized dataset to facilitate the solving of this problem. A physically based renderer is used to generate color images and their underlying ground-truth albedo and shading from three-dimensional models. Additionally, we render a Kinect-like noisy depth map for each instance. We utilize this synthetic dataset to train a deep neural network for intrinsic image decomposition and further fine-tune it for real-world images. Our model supports both RGB and RGB-D as input, and it employs both high-level and low-level features to avoid blurry outputs. Experimental results verify the effectiveness of our model on realistic images.","","","10.1109/LSP.2018.2820041","National Natural Science Foundation of China; Natural Science Foundation of Guangdong Province; Shenzhen Innovation Program; Fundamental Research Funds for the Central Universities; Tip-top Scientific and Technical Innovative Youth Talents of Guangdong special support program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8326532","Deep learning;image decomposition;intrinsic image;RGB-D","Lighting;Image resolution;Image decomposition;Noise measurement;Three-dimensional displays;Training;Cameras","feature extraction;image colour analysis;image texture;learning (artificial intelligence);neural nets;realistic images;rendering (computer graphics)","intrinsic image decomposer;synthesized RGB-D dataset;signal processing;realistic labeled data;learning methods;physically based renderer;color images;underlying ground-truth albedo;Kinect-like noisy depth map;realistic images;ill-posed problem;severely lacking;underlying ground-truth shading;deep neural network","","1","21","","","","","IEEE","IEEE Journals"
"Text2Video: An End-to-end Learning Framework for Expressing Text With Videos","X. Yang; T. Zhang; C. Xu","National Lab of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; National Lab of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; National Lab of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Multimedia","","2018","20","9","2360","2370","Video creation is a challenging and highly profession-al task that generally involves substantial manual efforts. To ease this burden, a better approach is to automatically produce new videos based on clips from the massive amount of existing videos according to arbitrary text. In this paper, we formulate video creation as a problem of retrieving a sequence of videos for a sentence stream. To achieve this goal, we propose a novel multimodal recurrent architecture for automatic video production. Compared with existing methods, the proposed model has three major advantages. First, it is the first completely integrated end-to-end deep learning system for real-world production to the best of our knowledge. We are among the first to address the problem of retrieving a sequence of videos for a sentence stream. Second, it can effectively exploit the correspondence between sentences and video clips through semantic consistency modeling. Third, it can model the visual coherence well by requiring that the produced videos should be organized coherently in terms of visual appearance. We have conducted extensive experiments on two applications, including video retrieval and video composition. The qualitative and quantitative results obtained on two public datasets used in the Large Scale Movie Description Challenge 2016 both demonstrate the effectiveness of the proposed model compared with other state-of-the-art algorithms.","","","10.1109/TMM.2018.2807588","National Natural Science Foundation of China; Beijing Natural Science Foundation; Key Research Program of Frontier Sciences, CAS; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8302915","Multimedia storytelling;video analysis;deep learning","Videos;Visualization;Semantics;Task analysis;Coherence;Motion pictures","learning (artificial intelligence);video communication;video retrieval;video signal processing;video streaming","text2Video;video creation;sentence stream;automatic video production;video clips;video retrieval;video composition;semantic model;recurrent architecture;end-to-end deep learning system","","2","69","","","","","IEEE","IEEE Journals"
"FlowNet: A Deep Learning Framework for Clustering and Selection of Streamlines and Stream Surfaces","J. Han; J. Tao; C. Wang","Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, Indiana United States (e-mail: jhan5@nd.edu); Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, Indiana United States (e-mail: jtao1@nd.edu); Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, Indiana United States (e-mail: chaoli.wang@nd.edu)","IEEE Transactions on Visualization and Computer Graphics","","2018","PP","99","1","1","For effective flow visualization, identifying representative flow lines or surfaces is an important problem which has been studied. However, no work can solve the problem for both lines and surfaces. In this paper, we present FlowNet, a single deep learning framework for clustering and selection of streamlines and stream surfaces. Given a collection of streamlines or stream surfaces generated from a flow field data set, our approach converts them into binary volumes and then employs an autoencoder to learn their respective latent feature descriptors. These descriptors are used to reconstruct binary volumes for error estimation and network training. Once converged, the feature descriptors can well represent flow lines or surfaces in the latent space. We perform dimensionality reduction of these feature descriptors and cluster the projection results accordingly. This leads to a visual interface for exploring the collection of flow lines or surfaces via clustering, filtering, and selection of representatives. Intuitive user interactions are provided for visual reasoning of the collection with ease. We validate and explain our deep learning framework from multiple perspectives, demonstrate the effectiveness of FlowNet using several flow field data sets of different characteristics, and compare our approach against state-of-the-art streamline and stream surface selection algorithms.","","","10.1109/TVCG.2018.2880207","NVIDIA; National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8532319","Flow visualization;streamlines;stream surfaces;deep learning;autoencoder;feature descriptor;clustering;selection","Three-dimensional displays;Surface reconstruction;Feature extraction;Data visualization;Analytical models","","","","2","","","","","","IEEE","IEEE Early Access Articles"
"Through Wall Human Detection Under Small Samples Based on Deep Learning Algorithm","Y. Li; W. Wang; Y. Jiang","College of Electronics and Communication Engineering, Tianjin Normal University, Tianjin, China; College of Electronics and Communication Engineering, Tianjin Normal University, Tianjin, China; College of Electronics and Communication Engineering, Tianjin Normal University, Tianjin, China","IEEE Access","","2018","6","","65837","65844","Through-wall human detection has vital and widely used applications for anti-terrorism, anti-explosion, and post-disaster relief. The through-wall human-target recognition using ultra-wideband radar-based technology was established in recent research. With the recent development of deep learning algorithms, classification algorithms have demonstrated a dynamic aptitude to learn important characteristics of the dataset by utilizing only a few sample sets. This paper focuses on studying the detection of a human target’s status behind wall in small sample conditions. In the deep learning network model, the autoencoder algorithm is chosen here to classify and identify human targets behind walls. Through automatic acquiring of the knowledge of inherent characteristics in the data, the autoencoder algorithm can extract the concise data-feature representations. Based on the autoencoder network, we add the denoising encoder and sparsity constraints to extract more efficient feature representations, thereby improving the classification and identification rates. In this paper, we classify and identify the behind-wall human-target states separately under single and multiple sensors under a small-sample condition, and then compare the results with those of other classification algorithms. The results illustrate that the use of multiple sensors is more effective than the use of a single sensor and that the adopted autoencoder algorithm enables more effective detection of human targets behind walls than other algorithms.","","","10.1109/ACCESS.2018.2877730","National Natural Science Foundation of China; National Natural Science Foundation of China; National Natural Science Foundation of China; Tianjin Research Program of Application Foundation and Advanced Technology; Tianjin Science Foundation; Tianjin Higher Education Creative Team Funds Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8502787","Autoencoder;deep learning;small sample;target identification;ultra-wideband radar","Classification algorithms;Feature extraction;Training;Support vector machines;Mathematical model;Kernel","","","","2","24","","","","","IEEE","IEEE Journals"
"UbeHealth: A Personalized Ubiquitous Cloud and Edge-Enabled Networked Healthcare System for Smart Cities","T. Muhammed; R. Mehmood; A. Albeshri; I. Katib","Department of Computer Science, King Abdulaziz University, Jeddah, Saudi Arabia; High Performance Computing Center, King Abdulaziz University, Jeddah, Saudi Arabia; Department of Computer Science, King Abdulaziz University, Jeddah, Saudi Arabia; Department of Computer Science, King Abdulaziz University, Jeddah, Saudi Arabia","IEEE Access","","2018","6","","32258","32285","Smart city advancements are driving massive transformations of healthcare, the largest global industry. The drivers include increasing demands for ubiquitous, preventive, and personalized healthcare, to be provided to the public at reduced risks and costs. Mobile cloud computing could potentially meet the future healthcare demands by enabling anytime, anywhere capture and analyses of patients' data. However, network latency, bandwidth, and reliability are among the many challenges hindering the realization of next-generation healthcare. This paper proposes a ubiquitous healthcare framework, UbeHealth, that leverages edge computing, deep learning, big data, high-performance computing (HPC), and the Internet of Things (IoT) to address the aforementioned challenges. The framework enables an enhanced network quality of service using its three main components and four layers. Deep learning, big data, and HPC are used to predict network traffic, which in turn are used by the Cloudlet and network layers to optimize data rates, data caching, and routing decisions. Application protocols of the traffic flows are classified, enabling the network layer to meet applications' communication requirements better and to detect malicious traffic and anomalous data. Clustering is used to identify the different kinds of data originating from the same application protocols. A proof of concept UbeHealth system has been developed based on the framework. A detailed literature review is used to capture the design requirements for the proposed system. The system is described in detail including the algorithmic implementation of the three components and four layers. Three widely used data sets are used to evaluate the UbeHealth system.","","","10.1109/ACCESS.2018.2846609","King Abdulaziz University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8382164","Cloudlets;deep learning;Internet of Things (IoT);mobile edge computing;mobile healthcare;preventive healthcare;traffic classification;traffic prediction;survey;fog computing;cloud computing;multimedia applications;smart cities","Medical services;Cloud computing;Edge computing;Quality of service;Machine learning;Smart cities;Internet of Things","Big Data;cloud computing;health care;Internet of Things;learning (artificial intelligence);medical computing;mobile computing;parallel processing;protocols;quality of service;smart cities","smart cities;mobile cloud computing;future healthcare demands;network latency;next-generation healthcare;ubiquitous healthcare framework;edge computing;deep learning;high-performance computing;HPC;network traffic;network layers;data rates;data caching;application protocols;anomalous data;Big Data;UbeHealth system;personalized ubiquitous cloud computing;edge-enabled networked healthcare system;personalized healthcare;patient data analysis;reliability;Internet of Things;IoT;enhanced network quality of service;routing decisions;traffic flows;malicious traffic detection","","8","145","","","","","IEEE","IEEE Journals"
"A Hybrid Network for ERP Detection and Analysis Based on Restricted Boltzmann Machine","J. Li; Z. L. Yu; Z. Gu; W. Wu; Y. Li; L. Jin","School of Automation Science and Engineering, South China University of Technology, Guangzhou, China; School of Automation Science and Engineering, South China University of Technology, Guangzhou, China; School of Automation Science and Engineering, South China University of Technology, Guangzhou, China; School of Automation Science and Engineering, South China University of Technology, Guangzhou, China; School of Automation Science and Engineering, South China University of Technology, Guangzhou, China; School of Electronic and Information Engineering, South China University of Technology, Guangzhou, China","IEEE Transactions on Neural Systems and Rehabilitation Engineering","","2018","26","3","563","572","Detecting and Please provide the correct one analyzing the event-related potential (ERP) remains an important problem in neuroscience. Due to the low signal-to-noise ratio and complex spatio-temporal patterns of ERP signals, conventional methods usually rely on ensemble averaging technique for reliable detection, which may obliterate subtle but important information in each trial of ERP signals. Inspired by deep learning methods, we propose a novel hybrid network termed ERP-NET. With hybrid deep structure, the proposed network is able to learn complex spatial and temporal patterns from single-trial ERP signals. To verify the effectiveness of ERP-NET, we carried out a few ERP detection experiments that the proposed model achieved cutting-edge performance. The experimental results demonstrate that the patterns learned by the ERP-NET are discriminative ERP components in which the ERP signals are properly characterized. More importantly, as an effective approach to single-trial analysis, ERP-NET is able to discover new ERP patterns which are significant to neuroscience study as well as BCI applications. Therefore, the proposed ERP-NET is a promising tool for the research on ERP signals.","","","10.1109/TNSRE.2018.2803066","National Natural Science Foundation of China; Natural Science Foundation of Guangdong; Guangzhou Project; Tip-Top Scientific and Technical Innovative Youth Talents of Guangdong Special Support Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8283586","Event-related potential (ERP);deep learning;neural network;temporal feature;spatial filter","Feature extraction;Brain modeling;Electroencephalography;Machine learning;Data models;Neuroscience;Algorithm design and analysis","bioelectric potentials;Boltzmann machines;electroencephalography;learning (artificial intelligence);medical signal detection;medical signal processing;neurophysiology","low signal-to-noise ratio;complex spatio-temporal patterns;deep learning methods;novel hybrid network;ERP-NET;complex spatial patterns;single-trial ERP signals;ERP detection experiments;discriminative ERP components;ERP patterns;neuroscience","Algorithms;Brain-Computer Interfaces;Electroencephalography;Event-Related Potentials, P300;Evoked Potentials;Humans;Neural Networks (Computer);Prosthesis Design;Signal Processing, Computer-Assisted;Signal-To-Noise Ratio","2","34","","","","","IEEE","IEEE Journals"
"Auxiliary Loss Multimodal GRU Model in Audio-Visual Speech Recognition","Y. Yuan; C. Tian; X. Lu","Center for Optical Imagery Analysis and Learning, Xi’an Institute of Optics and Precision Mechanics, Chinese Academy of Sciences, Xi’an, China; Center for Optical Imagery Analysis and Learning, Xi’an Institute of Optics and Precision Mechanics, Chinese Academy of Sciences, Xi’an, China; Center for Optical Imagery Analysis and Learning, Xi’an Institute of Optics and Precision Mechanics, Chinese Academy of Sciences, Xi’an, China","IEEE Access","","2018","6","","5573","5583","Audio-visual speech recognition (AVSR) utilizes both audio and video modalities for the robust automatic speech recognition. Most deep neural network (DNN) has achieved promising performances in AVSR owing to its generalized and nonlinear mapping ability. However, these DNN models have two main disadvantages: 1) the first disadvantage is that most models alleviate the AVSR problems neglecting the fact that the frames are correlated; and 2) the second disadvantage is the feature learned by the mentioned models is not credible. This is because the joint representation learned by the fusion fails to consider the specific information of categories, and the discriminative information is sparse, while the noise, reverberation, irrelevant image objection, and background are redundancy. Aiming at relieving these disadvantages, we propose the auxiliary loss multimodal GRU (alm-GRU) model including three parts: feature extraction, data augmentation, and fusion & recognition. The feature extraction and data augmentation are a complete effective solution for the processing raw complete video and training, and precondition for later core part: fusion & recognition using alm-GRU equipped with a novel loss which is an end-to-end network combining both fusion and recognition, furthermore considering the modal and temporal information. The experiments show the superiority of our model and necessity of the data augmentation and generative component in the benchmark data sets.","","","10.1109/ACCESS.2018.2796118","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8279447","Aduio-visual systems;recurrent neural networks;generative adversarial networks","Feature extraction;Hidden Markov models;Automatic speech recognition;Data models;Robustness;Training","audio-visual systems;feature extraction;image fusion;learning (artificial intelligence);neural nets;speech recognition;video signal processing","data augmentation;feature extraction;auxiliary loss multimodal GRU model;audio-visual speech recognition;video modalities;robust automatic speech recognition;deep neural network;generalized mapping ability;nonlinear mapping ability;DNN models;AVSR problems;video processing;alm-GRU model;feature learning;joint representation;fusion & recognition","","4","48","CCBY","","","","IEEE","IEEE Journals"
"Deep Gaussian Process-Based Bayesian Inference for Contaminant Source Localization","Y. Park; P. M. Tagade; H. Choi","Department of Aerospace Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Samsung Advanced Institute of Technology, Samsung R&D Institute, Bengaluru, India; Department of Aerospace Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea","IEEE Access","","2018","6","","49432","49449","This paper proposes a Bayesian framework for localization of multiple sources in the event of accidental hazardous contaminant release. The framework assimilates sensor measurements of the contaminant concentration with the integrated multizone computational fluid dynamics (multizone-CFD)-based contaminant fate and transport model. To ensure online tractability, we build deep Gaussian process-based emulators approximating multizone-CFD model. To effectively represent the transient response of the multizone-CFD model, the deep Gaussian processes are extended to matrix-variate architecture by adopting Kronecker products to the output covariance for each GP layer. The resultant deep matrix-variate Gaussian process emulators are used to define the likelihood of the Bayesian framework, while Markov chain Monte Carlo approach is used to sample from the posterior distribution. The proposed method is evaluated for single and multiple contaminant sources localization tasks modeled by CONTAM simulator in a single-story building of 30 zones, demonstrating that proposed approach accurately perform inference on locations of contaminant sources. Moreover, the proposed model not only shows outstanding regression performance but speed up training.","","","10.1109/ACCESS.2018.2867687","KAIST; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8449923","Bayesian methods;contaminant source localization;deep matrix-variate Gaussian processes;Gaussian processes;Monte Carlo methods;supervised learning","Bayes methods;Computational modeling;Gaussian processes;Atmospheric modeling;Global Positioning System;Covariance matrices;Buildings","Bayes methods;belief networks;computational fluid dynamics;contamination;distributed sensors;Gaussian processes;inference mechanisms;Markov processes;matrix algebra;Monte Carlo methods;regression analysis","single-story building;CONTAM simulator;sources localization tasks;deep matrix-variate Gaussian process emulators;matrix-variate architecture;multizone-CFD model;deep Gaussian process-based emulators;transport model;contaminant concentration;accidental hazardous contaminant release;contaminant source localization;deep gaussian process-based Bayesian inference;multiple contaminant sources localization tasks","","","58","","","","","IEEE","IEEE Journals"
"Multitask Autoencoder Model for Recovering Human Poses","J. Yu; C. Hong; Y. Rui; D. Tao","Department of Computer Science, Hangzhou Dianzi University, Hangzhou, China; Xiamen University of Technology, Xiamen, China; Lenovo Group Ltd, Beijing, China; UBTECH Sydney Artificial Intelligence Centre and the School of Information Technologies in the Faculty of Engineering and Information Technologies, University of Sydney, Darlington, Australia","IEEE Transactions on Industrial Electronics","","2018","65","6","5060","5068","Human pose recovery in videos is usually conducted by matching 2-D image features and retrieving relevant 3-D human poses. In the retrieving process, the mapping between images and poses is critical. Traditional methods assume this mapping relationship as local joint detection or global joint localization, which limits recovery performance of these methods since this two tasks are actually unified. In this paper, we propose a novel pose recovery framework by simultaneously learning the tasks of joint localization and joint detection. To obtain this framework, multiple manifold learning is used and the shared parameter is calculated. With them, multiple manifold regularizers are integrated and generalized eigendecomposition is utilized to achieve parameter optimization. In this way, pose recovery is boosted by both global mapping and local refinement. Experimental results on two popular datasets demonstrates that the recovery error has been reduced by 10%-20%, which proves the performance improvement of the proposed method.","","","10.1109/TIE.2017.2739691","National Natural Science Foundation of China; Australian Research Council; Zhejiang Provincial Natural Science Foundation of China; Fujian Provincial High School Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8010362","Autoencoder;deep learning;human pose recovery (HPR);manifold learning;multitask learning (MTL)","Feature extraction;Manifolds;Computational modeling;Encoding;Learning systems;Optimization;Electronic mail","eigenvalues and eigenfunctions;feature extraction;learning (artificial intelligence);optimisation;pose estimation","2-D image features;multitask autoencoder model;human poses recovery;3-D human poses;novel pose recovery framework;parameter optimization;eigendecomposition;multiple manifold regularizers;multiple manifold learning;global joint localization;local joint detection;retrieving process;global mapping","","17","51","","","","","IEEE","IEEE Journals"
"What Can I Do With This Tool? Self-Supervised Learning of Tool Affordances From Their 3-D Geometry","T. Mar; V. Tikhanoff; L. Natale","iCub Facility, Italian Institute of Technology, Genoa, Italy; iCub Facility, Italian Institute of Technology, Genoa, Italy; iCub Facility, Italian Institute of Technology, Genoa, Italy","IEEE Transactions on Cognitive and Developmental Systems","","2018","10","3","595","610","The ability to use tools can significantly increase the range of activities that an agent is capable of. Humans start using external objects since an early age to accomplish their goals, learning from interaction and observation the relationship between the objects used, their own actions, and the resulting effects, i.e., the tool affordances. Robots capable of autonomously learning affordances in a similar self-supervised way would be far more versatile and simpler to design than purpose-specific ones. This paper proposes and evaluates an approach to allow robots to learn tool affordances from interaction, and generalize them among similar tools based on their 3-D geometry. A set of actions is performed by the iCub robot with a large number of tools grasped in different poses, and the effects observed. Tool affordances are learned as a regression between tool-pose features and action-effect vector projections on respective self-organizing maps, which enables the system to avoid categorization and keep gradual representations of both elements. Moreover, we propose a set of robot-centric 3-D tool descriptors, and study their suitability for interaction scenarios, comparing also their performance against features derived from deep convolutional neural networks. Results show that the presented methods allow the robot to predict the effect of its tool use actions accurately, even for previously unseen tool and poses, and thereby to select the best action for a particular goal given a tool-pose.","","","10.1109/TCDS.2017.2717041","European FP7 ICT; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7953566","3-D features;affordances;humanoid robot;iCub;interaction learning;tool use","Tools;Three-dimensional displays;Robot kinematics;Feature extraction;Bayes methods;Geometry","convolution;feedforward neural nets;geometry;humanoid robots;learning (artificial intelligence);self-organising feature maps;vectors","self-supervised learning;tool-pose features;action-effect vector projections;autonomously learning affordance;iCub robot;self-organizing maps;robot-centric 3-D tool descriptor;deep convolutional neural network;3-D geometry","","1","81","","","","","IEEE","IEEE Journals"
"Mid-level deep Food Part mining for food image recognition","J. Zheng; L. Zou; Z. J. Wang","University of British Columbia, Canada; University of British Columbia, Canada; University of British Columbia, Canada","IET Computer Vision","","2018","12","3","298","304","There has been a growing interest in food image recognition for a wide range of applications. Among existing methods, mid-level image part-based approaches show promising performances due to their suitability for modelling deformable food parts (FPs). However, the achievable accuracy is limited by the FP representations based on low-level features. Benefiting from the capacity to learn powerful features with labelled data, deep learning approaches achieved state-of-the-art performances in several food image recognition problems. Both mid-level-based approaches and deep convolutional neural networks (DCNNs) approaches clearly have their respective advantages, but perhaps most importantly these two approaches can be considered complementary. As such, the authors propose a novel framework to better utilise DCNN features for food images by jointly exploring the advantages of both the mid-level-based approaches and the DCNN approaches. Furthermore, they tackle the challenge of training a DCNN model with the unlabelled mid-level parts data. They accomplish this by designing a clustering-based FP label mining scheme to generate part-level labels from unlabelled data. They test on three benchmark food image datasets, and the numerical results demonstrate that the proposed approach achieves competitive performance when compared with existing food image recognition approaches.","","","10.1049/iet-cvi.2016.0335","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8319340","","","data mining;feature extraction;feedforward neural nets;image recognition;image representation;learning (artificial intelligence)","benchmark food image datasets;unlabelled data;part-level labels generation;clustering-based FP label mining scheme;DCNN features;deep convolutional neural networks;deep learning approaches;FP representations;deformable food parts modelling;midlevel image part-based approaches;food image recognition;midlevel deep FP mining","","1","40","","","","","IET","IET Journals"
"Facial Expression Recognition Using Weighted Mixture Deep Neural Network Based on Double-Channel Facial Images","B. Yang; J. Cao; R. Ni; Y. Zhang","Department of Information Science and Engineering, Changzhou University, Changzhou, China; Department of Information Science and Engineering, Changzhou University, Changzhou, China; College of Mechanical and Electrical, Changzhou Textile Garment Institute, Changzhou, China; Department of Information Science and Engineering, Changzhou University, Changzhou, China","IEEE Access","","2018","6","","4630","4640","Facial expression recognition (FER) is a significant task for the machines to understand the emotional changes in human beings. However, accurate hand-crafted features that are highly related to changes in expression are difficult to extract because of the influences of individual difference and variations in emotional intensity. Therefore, features that can accurately describe the changes in facial expressions are urgently required. Method: A weighted mixture deep neural network (WMDNN) is proposed to automatically extract the features that are effective for FER tasks. Several pre-processing approaches, such as face detection, rotation rectification, and data augmentation, are implemented to restrict the regions for FER. Two channels of facial images, including facial grayscale images and their corresponding local binary pattern (LBP) facial images, are processed by WMDNN. Expression-related features of facial grayscale images are extracted by fine-tuning a partial VGG16 network, the parameters of which are initialized using VGG16 model trained on ImageNet database. Features of LBP facial images are extracted by a shallow convolutional neural network (CNN) built based on DeepID. The outputs of both channels are fused in a weighted manner. The result of final recognition is calculated using softmax classification. Results: Experimental results indicate that the proposed algorithm can recognize six basic facial expressions (happiness, sadness, anger, disgust, fear, and surprise) with high accuracy. The average recognition accuracies for benchmarking data sets “CK+,”“JAFFE,”and “Oulu-CASIA”are 0.970, 0.922, and 0.923, respectively. Conclusions: The proposed FER method outperforms the state-of-the-art FER methods based on the hand-crafted features or deep networks using one channel. Compared with the deep networks that use multiple channels, our proposed network can achieve comparable performance with easier procedures. Fine-tuning is effective to FER tasks with a well pre-trained model if sufficient samples cannot be collected.","","","10.1109/ACCESS.2017.2784096","National Natural Science Foundation of China; Natural Science Foundation of Jiangsu Province; Key Laboratory for New Technology Application of Road Conveyance of Jiangsu Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8214102","Facial expression recognition;double channel facial images;deep neural network;weighted mixture;softmax classification","Feature extraction;Face recognition;Image recognition;Face detection;Neural networks;Machine learning","emotion recognition;face recognition;feature extraction;image classification;learning (artificial intelligence);neural nets","average recognition accuracies;FER method;hand-crafted features;facial expression recognition;weighted mixture deep neural network;double-channel facial images;emotional changes;facial grayscale images;partial VGG16 network;LBP facial images;shallow convolutional neural network;local binary pattern facial images;emotional intensity;face detection;WMDNN;rotation rectification;data augmentation;expression-related features;ImageNet database;CNN;DeepID;softmax classification;CK+ benchmarking data sets;JAFFE;Oulu-CASIA;multiple channels","","12","36","","","","","IEEE","IEEE Journals"
"Hierarchical Extended Bilateral Motion Estimation-Based Frame Rate Upconversion Using Learning-Based Linear Mapping","S. Yoon; H. Kim; M. Kim","School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea","IEEE Transactions on Image Processing","","2018","27","12","5918","5932","We present a novel and effective learning-based frame rate upconversion (FRUC) scheme, using linear mapping. The proposed learning-based FRUC scheme consists of: 1) a new hierarchical extended bilateral motion estimation (HEBME) method; 2) a light-weight motion deblur (LWMD) method; and 3) a synthesis-based motion-compensated frame interpolation (S-MCFI) method. First, the HEBME method considerably enhances the accuracy of the motion estimation (ME), which can lead to a significant improvement of the FRUC performance. The proposed HEBME method consists of two ME pyramids with a three-layered hierarchy, where the motion vectors (MVs) are searched in a coarse-to-fine manner via each pyramid. The found MVs are further refined in an enhanced resolution of four times by jointly combining the MVs from the two pyramids. The HEBME method employs a new elaborate matching criterion for precise ME which effectively combines a bilateral absolute difference, an edge variance, pixel variances, and an MV difference among two consecutive blocks and its neighboring blocks. Second, the LWMD method uses the MVs found by the HEBME method and removes the small motion blurs in original frames via transformations by linear mapping. Third, the S-MCFI method finally generates interpolated frames by applying linear mapping kernels for the deblurred original frames. In consequence, our FRUC scheme is capable of precisely generating interpolated frames based on the HEBME for accurate ME, the S-MCFI for elaborate frame interpolation, and the LWMD for contrast enhancement. The experimental results show that our FRUC significantly outperforms the state-of-the-art non-deep learning-based schemes with an average of 1.42 dB higher in the peak signal-to-noise-ratio and shows comparable performance with the state-of-the-art deep learning-based scheme.","","","10.1109/TIP.2018.2861567","Institute for Information and Communications Technology Promotion (IITP); Korea Government (MSIT) (Intelligent High Realistic Visual Processing for Smart Broadcasting Media); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8423719","Frame rate up-conversion;bilateral motion estimation;linear mapping based motion compensate frame interpolation;linear mapping based motion deblur","Motion estimation;Reliability;Interpolation;UHDTV;Video sequences;Computational complexity","filtering theory;image matching;image motion analysis;image representation;image resolution;image restoration;image sequences;interpolation;learning (artificial intelligence);motion compensation;motion estimation","hierarchical extended bilateral motion estimation-based frame rate upconversion;effective learning-based frame rate upconversion;learning-based FRUC scheme;hierarchical extended bilateral motion estimation method;light-weight motion deblur method;synthesis-based motion-compensated frame interpolation method;HEBME method;FRUC performance;motion vectors;bilateral absolute difference;LWMD method;motion blurs;S-MCFI method;interpolated frames;linear mapping kernels;deblurred original frames;elaborate frame interpolation;MV;nondeep learning-based schemes;deep learning-based scheme","","","29","","","","","IEEE","IEEE Journals"
"Deep Dynamic Network Embedding for Link Prediction","T. Li; J. Zhang; P. S. Yu; Y. Zhang; Y. Yan","Key Laboratory of Speech Acoustics and Content Understanding, Institute of Acoustics, Chinese Academy of Sciences, Beijing, China; Department of Computer Science, Florida State University, Tallahassee, FL, USA; Department of Computer Science, The University of Illinois at Chicago, Chicago, IL, USA; Key Laboratory of Speech Acoustics and Content Understanding, Institute of Acoustics, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Speech Acoustics and Content Understanding, Institute of Acoustics, Chinese Academy of Sciences, Beijing, China","IEEE Access","","2018","6","","29219","29230","Network embedding task aims at learning low-dimension latent representations of vertices while preserving the structure of a network simultaneously. Most existing network embedding methods mainly focus on static networks, which extract and condense the network information without temporal information. However, in the real world, networks keep evolving, where the linkage states between the same vertex pairs at consequential timestamps have very close correlations. In this paper, we propose to study the network embedding problem and focus on modeling the linkage evolution in the dynamic network setting. To address this problem, we propose a deep dynamic network embedding method. More specifically, the method utilizes the historical information obtained from the network snapshots at past timestamps to learn latent representations of the future network. In the proposed embedding method, the objective function is carefully designed to incorporate both the network internal and network dynamic transition structures. Extensive empirical experiments prove the effectiveness of the proposed model on various categories of real-world networks, including a human contact network, a bibliographic network, and e-mail networks. Furthermore, the experimental results also demonstrate the significant advantages of the method compared with both the state-of-the-art embedding techniques and several existing baseline methods.","","","10.1109/ACCESS.2018.2839770","National Natural Science Foundation of China; National Key Research and Development Program; Key Science and Technology Project of the Xinjiang Uygur Autonomous Region; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8365780","Social network analysis;network embedding;link prediction;deep learning","Couplings;Task analysis;Correlation;Data models;Predictive models;Data mining;Electronic mail","complex networks;learning (artificial intelligence);Linked Data;network theory (graphs);neural nets","low-dimension latent representations;static networks;network information;temporal information;linkage states;network embedding problem;dynamic network setting;deep dynamic network embedding method;historical information;network snapshots;real-world networks;human contact network;bibliographic network;e-mail networks;embedding techniques;consequential timestamps;network internal structures;network embedding task","","8","29","","","","","IEEE","IEEE Journals"
"Cross-Layer Design Exploration for Energy-Quality Tradeoffs in Spiking and Non-Spiking Deep Artificial Neural Networks","B. Han; A. Ankit; A. Sengupta; K. Roy","Department of Electrical and Computer Engineering, Purdue University, West Lafayette, IN; Department of Electrical and Computer Engineering, Purdue University, West Lafayette, IN; Department of Electrical and Computer Engineering, Purdue University, West Lafayette, IN; Department of Electrical and Computer Engineering, Purdue University, West Lafayette, IN","IEEE Transactions on Multi-Scale Computing Systems","","2018","4","4","613","623","Deep learning convolutional artificial neural networks have achieved success in a large number of visual processing tasks and are currently utilized for many real-world applications like image search and speech recognition among others. However, despite achieving high accuracy in such classification problems, they involve significant computational resources. Over the past few years, non-spiking deep convolutional artificial neural network models have evolved into more biologically realistic and event-driven spiking deep convolutional artificial neural networks. Recent research efforts have been directed at developing mechanisms to convert traditional non-spiking deep convolutional artificial neural networks to the spiking ones where neurons communicate by means of spikes. However, there have been limited studies providing insights on the specific power, area, and energy benefits offered by the spiking deep convolutional artificial neural networks in comparison to their non-spiking counterparts. We perform a comprehensive study for hardware implementation of spiking/non-spiking deep convolutional artificial neural networks on MNIST, CIFAR10, and SVHN datasets. To this effect, we design AccelNN - a Neural Network Accelerator to execute neural network benchmarks and analyze the effects of circuit-architecture level techniques to harness event-drivenness. A comparative analysis between spiking and non-spiking versions of deep convolutional artificial neural networks is presented by performing trade-offs between recognition accuracy and corresponding power, latency and energy requirements.","","","10.1109/TMSCS.2017.2737625","Center for Spintronic Materials, Interfaces, and Novel Architectures (C-SPIN); StarNet Center; Semiconductor Research Corporation; National Science Foundation; Intel Corporation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8006240","Convolutional neural networks;neuromorphic systems;non-spiking neural networks;power-energy efficiency;spiking neural networks","Artificial neural networks;Convolutional neural networks;Machine learning;Computer architecture;Computational modeling;Deep learning;Energy efficiency;Neuromorphics","","","","3","33","","","","","IEEE","IEEE Journals"
"Indoor Positioning Based on Fingerprint-Image and Deep Learning","W. Shao; H. Luo; F. Zhao; Y. Ma; Z. Zhao; A. Crivello","School of Software Engineering, Beijing University of Posts and Telecommunications, Beijing, China; Beijing Key Laboratory of Mobile Computing and Pervasive Device, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; School of Software Engineering, Beijing University of Posts and Telecommunications, Beijing, China; Institute of Network Technology, Beijing University of Posts and Telecommunications, Beijing, China; Institute of Computer Science, University of Bern, Bern, Switzerland; Institute of Information Science and Technologies, Consiglio Nazionale delle Ricerche, Pisa, Italy","IEEE Access","","2018","6","","74699","74712","Wi-Fi and magnetic field fingerprinting have been a hot topic in indoor positioning researches because of their ubiquity and location-related features. Wi-Fi signals can provide rough initial positions, and magnetic fields can further improve the positioning accuracies, therefore many researchers have tried to combine the two signals for high-accuracy indoor localization. Currently, state-of-the-art solutions design separate algorithms to process different indoor signals. Outputs of these algorithms are generally used as inputs of data fusion strategies. These methods rely on computationally expensive particle filters, labor-intensive feature analysis, and time-consuming parameter tuning to achieve better accuracies. Besides, particle filters need to estimate the moving directions of particles, limiting smartphone orientation to be stable, and aligned with the user's moving directions. In this paper, we adopted a convolutional neural network (CNN) to implement an accurate and orientation-free positioning system. Inspired by the state-of-the-art image classification methods, we design a novel hybrid location image using Wi-Fi and magnetic field fingerprints, and then a CNN is employed to classify the locations of the fingerprint images. In order to prevent the overfitting problem of the positioning CNN on limited training datasets, we also propose to divide the learning process into two steps to adopt proper learning strategies for different network branches. We show that the CNN solution is able to automatically learn location patterns, thus significantly lower the workforce burden of designing a localization system. Our experimental results convincingly reveal that the proposed positioning method achieves an accuracy of about 1 m under different smartphone orientations, users, and use patterns.","","","10.1109/ACCESS.2018.2884193","National Basic Research Program of China (973 Program); National Natural Science Foundation of China; BUPT Excellent Ph.D. Students Foundation; Open Project of the Beijing Key Laboratory of Mobile Computing and Pervasive Device; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8554268","Indoor positioning;indoor localization;neural networks;fingerprint;feature extraction","Wireless fidelity;Magnetic fields;Fingerprint recognition;Training;Probabilistic logic;Image matching","convolutional neural nets;Global Positioning System;image classification;indoor navigation;learning (artificial intelligence);smart phones;wireless LAN","solution design separate algorithms;localization pattern system;positioning CNN solution;hybrid location image classification methods;orientation-free positioning system;indoor signals;indoor localization;deep learning strategies;fingerprint imaging;time-consuming parameter tuning;labor-intensive feature analysis;data fusion strategies;magnetic fields;rough initial positions;Wi-Fi signals;location-related features;indoor positioning researches;magnetic field fingerprinting;magnetic field fingerprints;convolutional neural network;smartphone orientation;particle filters","","4","47","","","","","IEEE","IEEE Journals"
"DeepEyes: Progressive Visual Analytics for Designing Deep Neural Networks","N. Pezzotti; T. Höllt; J. Van Gemert; B. P. F. Lelieveldt; E. Eisemann; A. Vilanova","Intelligent Systems department, Delft University of Technology, Delft, The Netherlands; Intelligent Systems department, Delft University of Technology, Delft, The Netherlands; Intelligent Systems department, Delft University of Technology, Delft, The Netherlands; Department of Radiology, Division of Image Processing, Leiden University Medical Center, Leiden, The Netherlands; Intelligent Systems department, Delft University of Technology, Delft, The Netherlands; Intelligent Systems department, Delft University of Technology, Delft, The Netherlands","IEEE Transactions on Visualization and Computer Graphics","","2018","24","1","98","108","Deep neural networks are now rivaling human accuracy in several pattern recognition problems. Compared to traditional classifiers, where features are handcrafted, neural networks learn increasingly complex features directly from the data. Instead of handcrafting the features, it is now the network architecture that is manually engineered. The network architecture parameters such as the number of layers or the number of filters per layer and their interconnections are essential for good performance. Even though basic design guidelines exist, designing a neural network is an iterative trial-and-error process that takes days or even weeks to perform due to the large datasets used for training. In this paper, we present DeepEyes, a Progressive Visual Analytics system that supports the design of neural networks during training. We present novel visualizations, supporting the identification of layers that learned a stable set of patterns and, therefore, are of interest for a detailed analysis. The system facilitates the identification of problems, such as superfluous filters or layers, and information that is not being captured by the network. We demonstrate the effectiveness of our system through multiple use cases, showing how a trained network can be compressed, reshaped and adapted to different problems.","","","10.1109/TVCG.2017.2744358","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8019872","Progressive visual analytics;deep neural networks;machine learning","Neurons;Training;Visual analytics;Neural networks;Three-dimensional displays;Layout;Kernel","data visualisation;image recognition;learning (artificial intelligence);neural net architecture","DeepEyes;pattern recognition problems;complex features;network architecture parameters;superfluous filters;trained network;deep neural networks;progressive visual analytics system","","23","50","Traditional","","","","IEEE","IEEE Journals"
"Bio-Inspired Deep Attribute Learning Towards Facial Aesthetic Prediction","M. Xu; F. Chen; L. Li; C. Shen; P. Lv; B. Zhou; R. Ji","Computer Science, School of Information Engeering, Zhengzhou, henan China (e-mail: iexumingliang@zzu.edu.cn); Cognitive Science, Xiamen University, 12466 Xiamen, Fujian China 361005 (e-mail: cfh3c@stu.xmu.edu.cn); School of Information Engeering, Computer Science, Zhengzhou University, 12636 Zhengzhou, Henan China (e-mail: liluzzu@163.com); Cognitive Science, Xiamen University, 12466 Xiamen, Fujian China (e-mail: schenxmu@stu.xmu.edu.cn); Center for Interdisciplinary Information Science Research, Zhengzhou University, 12636 Zhengzhou, Henan China (e-mail: Key_to_victory@163.com); Center for Interdisciplinary Information Science Research, Zhengzhou University, 12636 Zhengzhou, Henan China (e-mail: iebzhou@zzu.edu.cn); Cognitive Science, Xiamen University, Xiamen, Fujian China 361005 (e-mail: rrji@xmu.edu.cn)","IEEE Transactions on Affective Computing","","2018","PP","99","1","1","Computational prediction of facial aesthetics has attracted ever-increasing research focus. The key challenge lies in extracting discriminative and perception-aware features to characterize the facial beautifulness. To this end, the existing schemes simply adopt a direct feature mapping, which relies on handcraft-designed low-level features that cannot reflect human-level aesthetic perception. In this paper, we present a systematic framework towards designing biology-inspired, discriminative representation for facial aesthetic prediction. First, we design a group of biological experiments that adopt eye tracker to identify spatial regions of interest during the facial aesthetic judgments of subjects, which forms a Bio-inspired Facial Aesthetic Ontology (Bio-FAO) and is made public available. Second, we adopt the cutting-edge convolutional neural network to train a set of Bio-inspired Attribute features, termed Bio-AttriBank, which forms a mid-level interpretable representation corresponding to the aforementioned Bio-FAO. For a given image, the facial aesthetic prediction is then formulated as a classification problem over the Bio-AttriBank descriptor responses, which well bridges the affective gap, and provides explainable evidences on why/how a face is beautiful or not. We have carried out extensive experiments on both JAFFE and FaceWarehouse datasets. Superior performance gains in the experiments have demonstrated the merits of the proposed scheme.","","","10.1109/TAFFC.2018.2868651","open project of State Key Laboratory of virtual reality technology and system; Nature Science Foundation of China; National Key RD Program; Scientific Research Project of National Language Committee of China; Post Doctoral Innovative Talent Support Program; Nature Science Foundation of Fujian Province; China Post-Doctoral Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8454803","Facial aesthetic;Aesthetic concept;Bio-inspired attention;Deep learning","Feature extraction;Visualization;Face;Ontologies;Detectors;Bridges;Machine learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Image Reconstruction is a New Frontier of Machine Learning","G. Wang; J. C. Ye; K. Mueller; J. A. Fessler","Biomedical Imaging Center, BME and CBIS, RPI, Troy, NY, USA; Department of Bio/Brain Engineering, Department of Mathematical Sciences, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Department of Computer Science, Stony Brook University, Stony Brook, NY, USA; Department of EECS, University of Michigan, Ann Arbor, MI, USA","IEEE Transactions on Medical Imaging","","2018","37","6","1289","1296","Over past several years, machine learning, or more generally artificial intelligence, has generated overwhelming research interest and attracted unprecedented public attention. As tomographic imaging researchers, we share the excitement from our imaging perspective [item 1) in the Appendix], and organized this special issue dedicated to the theme of “Machine learning for image reconstruction.” This special issue is a sister issue of the special issue published in May 2016 of this journal with the theme “Deep learning in medical imaging” [item 2) in the Appendix]. While the previous special issue targeted medical image processing/analysis, this special issue focuses on data-driven tomographic reconstruction. These two special issues are highly complementary, since image reconstruction and image analysis are two of the main pillars for medical imaging. Together we cover the whole workflow of medical imaging: from tomographic raw data/features to reconstructed images and then extracted diagnostic features/readings.","","","10.1109/TMI.2018.2833635","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8359079","","Special issues and sections;Image reconstruction;Computed tomography;Magnetic resonance imaging;Iterative methods;Machine learning","artificial intelligence;feature extraction;image reconstruction;learning (artificial intelligence);medical image processing","image reconstruction;machine learning;image analysis;tomographic image;imaging perspective;artificial intelligence;medical image processing-analysis;deep learning;data-driven tomographic reconstruction;diagnostic feature extraction","","16","","","","","","IEEE","IEEE Journals"
"Integrating Deep Learning Approaches for Identifying News Reprint Relation","Y. Luo; F. Wang; J. Chen; L. Wang; D. D. Zeng","School of Management and Economics, Beijing Institute of Technology, Beijing, China; Beijing Wenge Technology Co., Ltd., Beijing, China; Communication Technology Bureau, Xinhua News Agency, Beijing, China; The State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; The State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China","IEEE Access","","2018","6","","72163","72172","With the rapid development of big data and new media technologies, a large amount of original news is generated and reprinted on the Internet via news portals. Identifying news reprint relations is of great importance for the analysis of news diffusion patterns and copyright protection. However, the amount of news data on the Internet creates a huge challenge for efficiently identifying news reprint relation. Some existing studies focus on computing the similarity of the full text of news reports, which is not always effective, because some reprints only excerpt some sentences of the original news reports. The core challenge of improving identification accuracy is excavating the potential semantic relevance between news articles at the sentence level. Inspired by deep learning and semantic-based text representation models, this paper proposes an approach for identifying news reprint relation by integrating deep learning approaches. First, news reports that are not related to the topic of the original news report are removed via topic correlation mining. Then, the potential semantic relevance is excavated at the sentence level through the integration of semantic analysis methods, and reprint relations are identified between news reports. The performance of the approach is empirically evaluated using a real-world dataset. Experimental results show that the semantic analysis model integration allows us to mine in-depth semantic associations between news stories and accurately identify news reprint relations. These results benefit news diffusion pattern analysis and copyright protection.","","","10.1109/ACCESS.2018.2882624","National Key R&D Program of China; National Natural Science Foundation of China; Chinese Academy of Sciences; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8542722","Deep learning;diffusion pattern;news reprint relation identification;semantic relevance;word embedding","Semantics;Computational modeling;Internet;Media;Portals;Correlation","","","","1","25","","","","","IEEE","IEEE Journals"
"Optimize Transfer Learning for Lung Diseases in Bronchoscopy Using a New Concept: Sequential Fine-Tuning","T. Tan; Z. Li; H. Liu; F. G. Zanjani; Q. Ouyang; Y. Tang; Z. Hu; Q. Li","Department of Biomedical Engineering, Eindhoven University of Technology, Eindhoven, The Netherlands; College of Aerospace Science and Engineering, National University of Defense Technology, Changsha, China; School Of Computer Science, University of Nottingham Malaysia Campus, Semenyih, Malaysia; Department of Electrical Engineering, Eindhoven University of Technology, Eindhoven, The Netherlands; Hunan Cancer Hospital, The Affiliated Cancer Hospital of Xiangya School of Medicine, Central South University, Changsha, China; First Hospital of Changsha City, Changsha, China; Hunan Cancer Hospital, The Affiliated Cancer Hospital of Xiangya School of Medicine, Central South University, Changsha, China; Department of Respiratory Medicine, Shanghai East Hospital, Tongji University School of Medicine, Shanghai, China","IEEE Journal of Translational Engineering in Health and Medicine","","2018","6","","1","8","Bronchoscopy inspection, as a follow-up procedure next to the radiological imaging, plays a key role in the diagnosis and treatment design for lung disease patients. When performing bronchoscopy, doctors have to make a decision immediately whether to perform a biopsy. Because biopsies may cause uncontrollable and life-threatening bleeding of the lung tissue, thus doctors need to be selective with biopsies. In this paper, to help doctors to be more selective on biopsies and provide a second opinion on diagnosis, we propose a computer-aided diagnosis (CAD) system for lung diseases, including cancers and tuberculosis (TB). Based on transfer learning (TL), we propose a novel TL method on the top of DenseNet: sequential fine-tuning (SFT). Compared with traditional fine-tuning (FT) methods, our method achieves the best performance. In a data set of recruited 81 normal cases, 76 TB cases and 277 lung cancer cases, SFT provided an overall accuracy of 82% while other traditional TL methods achieved an accuracy from 70% to 74%. The detection accuracy of SFT for cancers, TB, and normal cases are 87%, 54%, and 91%, respectively. This indicates that the CAD system has the potential to improve lung disease diagnosis accuracy in bronchoscopy and it may be used to be more selective with biopsies.","","","10.1109/JTEHM.2018.2865787","Hunan Provincial Natural Science Foundation of China; Health and Family Planning Commission of Hunan Province Foundation; Changsha City Technology Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8438558","Bronchoscopy;lung cancer;tuberculosis;DenseNet;deep learning;sequential fine-tuning;computer-aided diagnosis;transfer learning","Lung;Cancer;Bronchoscopy;Biopsy;Training;Biomedical imaging","biological tissues;cancer;learning (artificial intelligence);lung;medical computing;patient diagnosis","DenseNet;tuberculosis;CAD system;sequential fine-tuning;fine-tuning methods;novel TL method;computer-aided diagnosis system;lung tissue;life-threatening bleeding;lung disease patients;treatment design;radiological imaging;bronchoscopy inspection;optimize transfer learning;biopsy;lung disease diagnosis accuracy;SFT;traditional TL methods;memory size 76.0 TByte","","2","51","","","","","IEEE","IEEE Journals"
"Sustainable Deep Learning at Grid Edge for Real-time High Impedance Fault Detection","T. Sirojan; S. Lu; B. T. Phung; D. Zhang; E. Ambikairajah","School of Electrical Engineering and Telecommunications, University of New South Wales, Sydney, New South Wales Australia (e-mail: t.sirojan@unsw.edu.au); School of Electrical Engineering and Telecommunications, University of New South Wales, Sydney, New South Wales Australia (e-mail: shibo.lu@unsw.edu.au); School of Electrical Engineering and Telecommunications, University of New South Wales, Sydney, New South Wales Australia (e-mail: toan.phung@unsw.edu.au); School of Electrical Engineering and Telecommunications, University of New South Wales, Sydney, New South Wales Australia (e-mail: daming.zhang@unsw.edu.au); School of Electrical Engineering and Telecommunications, University of New South Wales, Sydney, New South Wales Australia (e-mail: e.ambikairajah@unsw.edu.au)","IEEE Transactions on Sustainable Computing","","2018","PP","99","1","1","High impedance faults (HIFs) on overhead power lines are known to cause fires. They are difficult to detect using conventional protection relays because the fault current is insufficient to cause tripping. The delay in detecting HIFs can result in severe bushfires and energy losses; hence a high throughput, low latency detection scheme needs to be developed for HIF detection. Moreover, the complexities associated with HIF detection demands signal processing techniques combined with artificial intelligence to achieve higher detection accuracy. This paper proposes a sustainable deep learning-based approach in an edge device, that can be mounted on top of a power pole to detect HIFs in real-time. Data acquisition, feature extraction, and deep learning based fault identification are performed in an embedded edge node to achieve higher throughput, reduced latency as well as offload the network traffic. Furthermore, optimization techniques such as hardware parallelism and pipelining are adapted to achieve real-time fault identification on edge devices while ensuring the efficient usage of its limited resources. Real-time implementation of the proposed system is validated through laboratory experiments and the results demonstrate the suitability of edge computing to detect HIFs in terms of reduced detection latency (115.2 ms) and higher detection accuracy (98.67%).","","","10.1109/TSUSC.2018.2879960","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8526333","Deep learning;Edge computing;Embedded Artificial Intelligence;Real-time fault detection;Sensor data analytics;Signal processing;Sustainable computing","Real-time systems;Image edge detection;Edge computing;Fires;Cloud computing;Fault detection;Artificial intelligence","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Robot-Assisted Pedestrian Regulation Based on Deep Reinforcement Learning","Z. Wan; C. Jiang; M. Fahad; Z. Ni; Y. Guo; H. He","Department of Electrical, Computer and Biomedical Engineering, University of Rhode Island, Kingston, RI 02881 USA.; Department of Electrical and Computer Engineering, Stevens Institute of Technology, Hoboken, NJ 07030 USA.; Department of Electrical and Computer Engineering, Stevens Institute of Technology, Hoboken, NJ 07030 USA.; Department of Electrical Engineering and Computer Science, South Dakota State University, Brookings, SD 57007 USA; Department of Electrical and Computer Engineering, Stevens Institute of Technology, Hoboken, NJ 07030 USA.; Department of Electrical, Computer and Biomedical Engineering, University of Rhode Island, Kingston, RI 02881 USA (e-mail: he@ele.uri.edu).","IEEE Transactions on Cybernetics","","2018","PP","99","1","14","Pedestrian regulation can prevent crowd accidents and improve crowd safety in densely populated areas. Recent studies use mobile robots to regulate pedestrian flows for desired collective motion through the effect of passive human-robot interaction (HRI). This paper formulates a robot motion planning problem for the optimization of two merging pedestrian flows moving through a bottleneck exit. To address the challenge of feature representation of complex human motion dynamics under the effect of HRI, we propose using a deep neural network to model the mapping from the image input of pedestrian environments to the output of robot motion decisions. The robot motion planner is trained end-to-end using a deep reinforcement learning algorithm, which avoids hand-crafted feature detection and extraction, thus improving the learning capability for complex dynamic problems. Our proposed approach is validated in simulated experiments, and its performance is evaluated. The results demonstrate that the robot is able to find optimal motion decisions that maximize the pedestrian outflow in different flow conditions, and the pedestrian-accumulated outflow increases significantly compared to cases without robot regulation and with random robot motion.","","","10.1109/TCYB.2018.2878977","US National Science Foundation; US National Science Foundation; US National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8540942","Deep reinforcement learning (DRL);human-robot interaction (HRI);pedestrian flow regulation","Robot motion;Feature extraction;Navigation;Planning;Robot sensing systems;Collision avoidance","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Deep Convolutional Neural Network for Complex Wetland Classification Using Optical Remote Sensing Imagery","M. Rezaee; M. Mahdianpari; Y. Zhang; B. Salehi","CRC Laboratory in Advanced Geomatics Image Processing, Department of Geodesy and Geomatics Engineering, University of New Brunswick, Fredericton, NB, Canada; St. John's, NL, Canada; CRC Laboratory in Advanced Geomatics Image Processing, Department of Geodesy and Geomatics Engineering, University of New Brunswick, Fredericton, NB, Canada; St. John's, NL, Canada","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2018","11","9","3030","3039","The synergistic use of spatial features with spectral properties of satellite images enhances thematic land cover information, which is of great significance for complex land cover mapping. Incorporating spatial features within the classification scheme have been mainly carried out by applying just low-level features, which have shown improvement in the classification result. By contrast, the application of high-level spatial features for classification of satellite imagery has been underrepresented. This study aims to address the lack of high-level features by proposing a classification framework based on convolutional neural network (CNN) to learn deep spatial features for wetland mapping using optical remote sensing data. Designing a fully trained new convolutional network is infeasible due to the limited amount of training data in most remote sensing studies. Thus, we applied fine tuning of a pre-existing CNN. Specifically, AlexNet was used for this purpose. The classification results obtained by the deep CNN were compared with those based on well-known ensemble classifiers, namely random forest (RF), to evaluate the efficiency of CNN. Experimental results demonstrated that CNN was superior to RF for complex wetland mapping even by incorporating the small number of input features (i.e., three features) for CNN compared to RF (i.e., eight features). The proposed classification scheme is the first attempt, investigating the potential of fine-tuning pre-existing CNN, for land cover mapping. It also serves as a baseline framework to facilitate further scientific research using the latest state-of-art machine learning tools for processing remote sensing data.","","","10.1109/JSTARS.2018.2846178","Government of Canada through the federal Department of Environment and Climate Change, Natural Sciences and Engineering Research Council of Canada; Research and Development Corporation of Newfoundland and Labrador; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8401505","AlexNet;convolutional neural network (CNN);deep learning;random forest (RF);spatial feature;wetland mapping","Wetlands;Remote sensing;Feature extraction;Convolutional neural networks;Optical imaging;Optical sensors;Satellites","feature extraction;geophysical image processing;image classification;image enhancement;neural nets;remote sensing;wetlands","deep convolutional neural network;complex wetland classification;optical remote sensing imagery;complex land cover mapping;classification scheme;low-level features;high-level spatial features;satellite imagery;classification framework;optical remote sensing data;deep CNN;complex wetland mapping;satellite images;thematic land cover information;convolutional neural network","","3","33","","","","","IEEE","IEEE Journals"
"Coherent Deep-Net Fusion To Classify Shots In Concert Videos","J. Lin; W. Wei; T. Liu; Y. Yang; H. Wang; H. Tyan; H. M. Liao","Department of Electrical Engineering, Yuan Ze University, Chung-Li, Taiwan; Academia Sinica, Institute of Information Science, Taipei, Taiwan; Institute of Information Sciences, Acadamia Sinica, Taipei, Taiwan; Research Center for IT Innovation, Academia Sinica, Taipei, Taiwan; Institute of Information Sciences, Acadamia Sinica, Taipei, Taiwan; Information and Computer Engineering, Chung Yuan Christian University, Taoyuan, Taiwan; Institute of Information Sciences, Acadamia Sinica, Taipei, Taiwan","IEEE Transactions on Multimedia","","2018","20","11","3123","3136","Varying types of shots is a fundamental element in the language of film, commonly used by a visual storytelling director. The technique is often used in creating professional recordings of a live concert, but meanwhile may not be appropriately applied in audience recordings of the same event. Such variations could cause the task of classifying shots in concert videos, professional or amateur, very challenging. To achieve more reliable shot classification, we propose a novel probabilistic-based approach, named as coherent classification net (CC-Net), by addressing three crucial issues. First, we focus on learning more effective features by fusing the layer-wise outputs extracted from a deep convolutional neural network (CNN), pretrained on a large-scale data set for object recognition. Second, we introduce a frame-wise classification scheme, the error weighted deep cross-correlation model (EW-Deep-CCM), to boost the classification accuracy. Specifically, the deep neural network-based cross-correlation model (deep-CCM) is constructed to not only model the extracted feature hierarchies of CNN independently, but also relate the statistical dependencies of paired features from different layers. Then, a Bayesian error weighting scheme for a classifier combination is adopted to explore the contributions from individual Deep-CCM classifiers to enhance the accuracy of shot classification in each image frame. Third, we feed the frame-wise classification results to a linear-chain conditional random field module to refine the shot predictions by taking into account the global and temporal regularities. We provide extensive experimental results on a data set of live concert videos to demonstrate the advantage of the proposed CC-Net over existing popular fusion approaches for shot classification.","","","10.1109/TMM.2018.2820904","MOST; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8327906","Types of shots;convolutional neural networks;live concert;language of film","Videos;Visualization;Mashups;Image color analysis;Feature extraction;Head;Task analysis","Bayes methods;convolution;feature extraction;feedforward neural nets;image classification;image motion analysis;learning (artificial intelligence);object recognition;statistical analysis;video signal processing","visual storytelling director;professional recordings;audience recordings;reliable shot classification;coherent classification net;CC-Net;layer-wise outputs;deep convolutional neural network;frame-wise classification scheme;EW-Deep-CCM;deep neural network-based cross-correlation model;Bayesian error weighting scheme;classifier combination;shot predictions;live concert videos;object recognition;temporal regularities;global regularities;linear-chain conditional random field module;deep-CCM classifiers;statistical dependencies;feature hierarchies extraction;coherent deep-net fusion;probabilistic-based approach","","1","32","","","","","IEEE","IEEE Journals"
"Deep Learning-Based Obstacle Detection and Classification With Portable Uncalibrated Patterned Light","M. Cornacchia; B. Kakillioglu; Y. Zheng; S. Velipasalar","Department of Electrical Engineering and Computer Science, Syracuse University, Syracuse, NY, USA; Department of Electrical Engineering and Computer Science, Syracuse University, Syracuse, NY, USA; Department of Electrical Engineering and Computer Science, Syracuse University, Syracuse, NY, USA; Department of Electrical Engineering and Computer Science, Syracuse University, Syracuse, NY, USA","IEEE Sensors Journal","","2018","18","20","8416","8425","Autonomous navigation and obstacle avoidance systems are critically relevant and important for visually impaired people, assisted driving applications, and autonomous robots. Even though there has been significant amount of work on obstacle detection and avoidance using LiDAR and camera data, there has not been much effort focusing on providing a lightweight, cost conscious, energy efficient, reliable, and portable solution for the visually impaired. We propose a new method for autonomous obstacle detection and classification, which incorporates a different and novel type of sensor, namely, patterned light field, with camera. The proposed device is small in size, easily carried, as well as low cost. The grid, projected by the patterned light source, is apparent and differentiable as the sensing system is hand carried in natural indoor and outdoor environments over and toward different types of obstacles. Our proposed approach exploits these patterns, without calibration, by employing deep learning techniques, including a convolutional neural network-based classification on individual frames. We further refine our approach by smoothing the frame-based classifications over multiple frames using long short-term memory units. The proposed method provides very promising results with overall detection and classification accuracies of 98.37% for the binary case as well as 95.97% and 92.62% for two different multi-class scenarios. These results represent the average number of sequences correctly detected and classified and were obtained on a sequence-based analysis of over 120 sequences from four different users.","","","10.1109/JSEN.2018.2865306","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8438986","Structured light;activity classification;convolutional neural network;long-short term memory;obstacle detection;obstacle classification","Cameras;Three-dimensional displays;Estimation;Navigation;Calibration;Robot vision systems","cameras;collision avoidance;convolution;feedforward neural nets;handicapped aids;learning (artificial intelligence);mobile robots;optical radar;pattern classification;robot vision","portable uncalibrated patterned light;obstacle avoidance systems;visually impaired people;assisted driving applications;autonomous robots;camera data;lightweight cost conscious;portable solution;autonomous obstacle detection;patterned light field;patterned light source;sensing system;deep learning techniques;convolutional neural network-based classification;frame-based classifications;sequence-based analysis;multiclass scenarios;long short-term memory units","","","39","","","","","IEEE","IEEE Journals"
"Wind Speed Extrapolation Using Machine Learning Methods and LiDAR Measurements","M. A. Mohandes; S. Rehman","King Fahd University of Petroleum & Minerals, Dhahran, Saudi Arabia; King Fahd University of Petroleum & Minerals, Dhahran, Saudi Arabia","IEEE Access","","2018","6","","77634","77642","Accurate wind energy assessments require wind speed (WS) at the hub height. The cost of WS measurements grows enormously with height. This paper utilizes deep neural network (DNN) algorithm for the extrapolation of the WS to higher heights based on measured values at lower heights. LiDAR measurements at lower heights are used for training the system and at higher heights for performance analysis. These measurements are made at 10, 20, ..., and 120 m heights. First, the measured WS values at 10-40 m were used to extrapolate values up to 120 m. In the second scenario, the WS at 10-50 m were used to extrapolate values up to 120 m. This continued until the last scenario, in which the WS at 10-100 m were used to estimate values at 110 and 120 m. A relationship between heights of measurements and the accuracy of the WS estimation at hub height is presented. The WS extrapolated using the present approach is compared with the measured values and with local wind shear exponent (LWSE)-based extrapolated WS. Furthermore, to analyze the performance of the DNN relative to other machine learning methods, we compared its performance with that of classical feedforward artificial neural networks trained using a genetic algorithm to find the initial weights and the Levemberg-Marquardt (LM) method (GANN) for training. The mean absolute percent error between measured and extrapolated WS at height 120 m based on measurements between 10-50 musing DNN, GANN, and LWSE are 9.65%, 12.77%, and 9.79%, respectively.","","","10.1109/ACCESS.2018.2883677","King Abdulaziz City for Science and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8570732","Extrapolation;machine learning;renewable energy;wind speed profile","Wind speed;Extrapolation;Laser radar;Machine learning;Training;Sea measurements;Neural networks","extrapolation;learning (artificial intelligence);neural nets;optical radar;power engineering computing;wind power;wind power plants;wind turbines","wind speed extrapolation;machine learning methods;LiDAR measurements;accurate wind energy assessments;hub height;WS measurements;deep neural network algorithm;higher heights;measured values;lower heights;measured WS values;WS estimation;local wind shear exponent-based extrapolated WS;measured extrapolated WS;DNN algorithm;LWSE;size 120.0 m;size 120.0 m;size 110.0 m;size 10.0 m to 40.0 m;size 10.0 m to 50.0 m;size 10.0 m to 100.0 m","","1","36","","","","","IEEE","IEEE Journals"
"Generative Model With Coordinate Metric Learning for Object Recognition Based on 3D Models","Y. Wang; W. Deng","School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China; School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China","IEEE Transactions on Image Processing","","2018","27","12","5813","5826","One of the bottlenecks in acquiring a perfect database for deep learning is the tedious process of collecting and labeling data. In this paper, we propose a generative model trained with synthetic images rendered from 3D models which can reduce the burden on collecting real training data and make the background conditions more realistic. Our architecture is composed of two sub-networks: a semantic foreground object reconstruction network based on Bayesian inference and a classification network based on multi-triplet cost training for avoiding overfitting on the monotone synthetic object surface and utilizing accurate information of synthetic images like object poses and lighting conditions which are helpful for recognizing regular photos. First, our generative model with metric learning utilizes additional foreground object channels generated from semantic foreground object reconstruction sub-network for recognizing the original input images. Multi-triplet cost function based on poses is used for metric learning which makes it possible to train an effective categorical classifier purely based on synthetic data. Second, we design a coordinate training strategy with the help of adaptive noise applied on the inputs of both of the concatenated sub-networks to make them benefit from each other and avoid inharmonious parameter tuning due to different convergence speeds of two sub-networks. Our architecture achieves the state-of-the-art accuracy of 50.5% on the ShapeNet database with data migration obstacle from synthetic images to real images. This pipeline makes it applicable to do recognition on real images only based on 3D models. Our codes are available at https://github.com/wangyida/gm-cml.","","","10.1109/TIP.2018.2858553","National Natural Science Foundation of China; Beijing Nova Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8417952","Bayesian rendering;triplet cost;synthetic image;semantic reconstruction;coordinate training;metric learning","Image reconstruction;Training;Semantics;Solid modeling;Three-dimensional displays;Measurement;Task analysis","belief networks;feature extraction;image reconstruction;image representation;image segmentation;learning (artificial intelligence);object recognition;stereo image processing","generative model;semantic foreground object reconstruction sub-network;multitriplet cost function;synthetic data;concatenated sub-networks;data migration obstacle;synthetic images;coordinate metric learning;object recognition;deep learning;training data;semantic foreground object reconstruction network;classification network;monotone synthetic object surface","","","38","","","","","IEEE","IEEE Journals"
"Fight Recognition in Video Using Hough Forests and 2D Convolutional Neural Network","I. Serrano; O. Deniz; J. L. Espinosa-Aranda; G. Bueno","VISILAB Group, E. T. S. I. Industriales, University of Castilla–La Mancha, Ciudad Real, Spain; VISILAB Group, E. T. S. I. Industriales, University of Castilla–La Mancha, Ciudad Real, Spain; VISILAB Group, E. T. S. I. Industriales, University of Castilla–La Mancha, Ciudad Real, Spain; VISILAB Group, E. T. S. I. Industriales, University of Castilla–La Mancha, Ciudad Real, Spain","IEEE Transactions on Image Processing","","2018","27","10","4787","4797","While action recognition has become an important line of research in computer vision, the recognition of particular events, such as aggressive behaviors, or fights, has been relatively less studied. These tasks may be extremely useful in several video surveillance scenarios, such as psychiatric wards, prisons, or even in personal camera smartphones. Their potential usability has led to a surge of interest in developing fight or violence detectors. One of the key aspects in this case is efficiency, that is, these methods should be computationally fast. “Handcrafted” spatio-temporal features that account for both motion and appearance information can achieve high accuracy rates, albeit the computational cost of extracting some of those features is still prohibitive for practical applications. The deep learning paradigm has been recently applied for the first time to this task too, in the form of a 3D convolutional neural network that processes the whole video sequence as input. However, results in human perception of other's actions suggest that, in this specific task, motion features are crucial. This means that using the whole video as input may add both redundancy and noise in the learning process. In this paper, we propose a hybrid “handcrafted/learned” feature framework which provides better accuracy than the previous feature learning method, with similar computational efficiency. The proposed method is compared to three related benchmark data sets. The method outperforms the different state-of-the-art methods in two of the three considered benchmark data sets.","","","10.1109/TIP.2018.2845742","Ministerio de Economía y Competitividad; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8375994","Fight recognition;violence recognition;Hough forests;deep learning;2D convolutional neuronal network","Feature extraction;Task analysis;Three-dimensional displays;Video sequences;Machine learning;Convolutional neural networks;Detectors","computer vision;feature extraction;feedforward neural nets;image motion analysis;image sequences;learning (artificial intelligence);object detection;video signal processing;video surveillance","hough forests;2D convolutional neural network;action recognition;computer vision;aggressive behaviors;video surveillance scenarios;appearance information;computational cost;deep learning paradigm;3D convolutional neural network;video sequence;motion features;spatio-temporal features;fight recognition;motion information","","4","54","","","","","IEEE","IEEE Journals"
"Building-A-Nets: Robust Building Extraction From High-Resolution Remote Sensing Images With Adversarial Networks","X. Li; X. Yao; Y. Fang","Institute of Remote Sensing and Digital Earth, Chinese Academy of Sciences, Beijing, China; Institute of Remote sensing and Digital Earth, Chinese Academy of Sciences, Beijing, China; Department of Electrical and Computer Engineering, New York University, Brooklyn, NY, USA","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2018","11","10","3680","3687","With the proliferation of high-resolution remote sensing sensor and platforms, vast amounts of aerial image data are becoming easily accessed. High-resolution aerial images provide sufficient structural and texture information for image recognition while also raise new challenges for existing segmentation methods. In recent years, deep neural networks have gained much attention in remote sensing field and achieved remarkable performance for high-resolution remote sensing images segmentation. However, there still exists spatial inconsistency problems caused by independently pixelwise classification while ignoring high-order regularities. In this paper, we developed a novel deep adversarial network, named Building-A-Nets, that jointly trains a deep convolutional neural network (generator) and an adversarial discriminator network for the robust segmentation of building rooftops in remote sensing images. More specifically, the generator produces pixelwise image classification map using a fully convolutional DenseNet model, whereas the discriminator tends to enforce forms of high-order structural features learned from ground-truth label map. The generator and discriminator compete with each other in an adversarial learning process until the equivalence point is reached to produce the optimal segmentation map of building objects. Meanwhile, a soft weight coefficient is adopted to balance the operation of the pixelwise classification and high-order structural feature learning. Experimental results show that our Building-A-Net can successfully detect and rectify spatial inconsistency on aerial images while archiving superior performances compared to other state-of-the-art building extraction methods. Code is available at https://github.com/lixiang-ucas/Building-A-Nets.","","","10.1109/JSTARS.2018.2865187","Jiangsu Province Geographic Information Research Project; National Science technology Support Plan Project of China; China Scholarship Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453267","Adversarial network;building extraction;fully convolutional DenseNet (FC-DenseNet);remote sensing;structural feature learning","Remote sensing;Generators;Feature extraction;Image segmentation;Training;Buildings;Gallium nitride","feature extraction;geophysical image processing;image classification;image recognition;image segmentation;image texture;learning (artificial intelligence);neural nets;remote sensing","deep neural networks;high-resolution remote sensing images segmentation;independently pixelwise classification;high-order regularities;deep adversarial network;deep convolutional neural network;adversarial discriminator network;robust segmentation;image classification map;high-order structural features;adversarial learning process;optimal segmentation map;high-order structural feature learning;Building-A-Net;robust Building extraction;high-resolution remote sensing sensor;aerial image data;high-resolution aerial images;image recognition","","1","37","","","","","IEEE","IEEE Journals"
"A Deep Feature Optimization Fusion Method for Extracting Bearing Degradation Features","L. Zhao; X. Wang","Department of Precision Instrument, State Key Laboratory of Precision Measurement Technology and Instruments, Tsinghua University, Beijing, China; Department of Precision Instrument, State Key Laboratory of Precision Measurement Technology and Instruments, Tsinghua University, Beijing, China","IEEE Access","","2018","6","","19640","19653","Centrifugal pumps with bearings are widely used in nuclear power plants. A challenge in datadriven prognostic technologies for centrifugal pump bearings is to evaluate their degradation features, which can be combined into degradation trajectory; however, the massive data gathered continuously from condition monitoring systems has created challenges to extracting degradation features effectively. The traditional degradation feature extraction methods are highly reliant on prior knowledge and diagnostic expertise, have limited capacities for learning the complex relationships between the degradation features and the massive amounts of measurement data, and their feature design processes are not automated and require intensive human labor. Deep neural networks offer remarkable abilities to extract features from massive data, and they can be used to automatically extract highly abstracted features that correlate well with bearing degradation. Therefore, to extract centrifugal pump bearing degradation features from massive amounts of vibration data, this paper proposes a deep feature optimization fusion method. First, data from the vibration-frequencydomain are mapped to a nonlinear spatial domain using an enhanced autoencoder. Second, the neural nodes in the last hidden layer of the enhanced autoencoder are divided into several child modules. The minimum quantization errors of each child module are used as the candidate degradation features. Finally, the optimal degradation trajectory is obtained via a weighted fusion of the candidate degradation features. The optimal weighting coefficients are calculated using the grey wolf optimizer algorithm. In this paper, experiments were performed using the IEEE PHM2012 bearing prognostic data set and a centrifugal pump bearing conditionmonitoring data set. The results demonstrate that the degradation trajectory obtained using the proposed method offers stronger predictive capabilities than do those obtained using other methods, thereby improving the accuracy of predictions of the bearings' remaining useful life.","","","10.1109/ACCESS.2018.2824352","Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8335247","Centrifugal pump bearings;degradation feature extraction;deep neural network;grey wolf optimizer","Feature extraction;Degradation;Data mining;Pumps;Optimization;Trajectory;Biological system modeling","condition monitoring;fault diagnosis;feature extraction;frequency-domain analysis;learning (artificial intelligence);machine bearings;mechanical engineering computing;neural nets;optimisation;pumps;remaining life assessment;vibrations","deep feature optimization fusion method;measurement data;feature design processes;deep neural networks;centrifugal pump bearing degradation features;vibration data;candidate degradation features;optimal degradation trajectory;prognostic data;condition monitoring data;degradation features extraction;grey wolf optimizer algorithm;vibration-frequency domain","","9","42","CCBY","","","","IEEE","IEEE Journals"
"Three-Dimensional Attention-Based Deep Ranking Model for Video Highlight Detection","Y. Jiao; Z. Li; S. Huang; X. Yang; B. Liu; T. Zhang","Jiangsu University of Science and Technology, Zhenjiang, China; College of Information Engineering, Xiangtan University, Xiangtan, China; Jiangsu University of Science and Technology, Zhenjiang, China; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Moshanghua Tech Company, Ltd., Beijing, China; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Multimedia","","2018","20","10","2693","2705","The video highlight detection task is to localize key elements (moments of user's major or special interest) in a video. Most of existing highlight detection approaches extract features from the video segment as a whole without considering the difference of local features both temporally and spatially. Due to the complexity of video content, this kind of mixed features will impact the final highlight prediction. In temporal extent, not all frames are worth watching because some of them only contain the background of the environment without human or other moving objects. In spatial extent, it is similar that not all regions in each frame are highlights especially when there are lots of clutters in the background. To solve the above problem, we propose a novel three-dimensional (3-D) (spatial+temporal) attention model that can automatically localize the key elements in a video without any extra supervised annotations. Specifically, the proposed attention model produces attention weights of local regions along both the spatial and temporal dimensions of the video segment. The regions of key elements in the video will be strengthened with large weights. Thus, the more effective feature of the video segment is obtained to predict the highlight score. The proposed 3-D attention scheme can be easily integrated into a conventional end-to-end deep ranking model that aims to learn a deep neural network to compute the highlight score of each video segment. Extensive experimental results on the YouTube and SumMe datasets demonstrate that the proposed approach achieves significant improvement over state-of-the-art methods. With the proposed 3-D attention model, video highlights can be accurately retrieved in spatial and temporal dimensions without human supervision in several domains, such as gymnastics, parkour, skating, skiing, surfing, and dog activities, on the public datasets.","","","10.1109/TMM.2018.2815998","National Natural Science Foundation of China; Key Research Program of Frontier Sciences, CAS; Postgraduate Research & Practice Innovation Program of Jiangsu Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8316891","Video highlight detection;attention model;deep ranking","Feature extraction;Three-dimensional displays;Solid modeling;Computational modeling;Games;Task analysis;Support vector machines","feature extraction;image segmentation;learning (artificial intelligence);neural nets;object detection;video retrieval;video signal processing","highlight score;video segment;video highlights;spatial dimensions;temporal dimensions;dimensional attention-based deep ranking model;video highlight detection task;highlight detection approaches;local features;video content;final highlight prediction;temporal extent;attention weights;local regions;3-D attention scheme;conventional end-to-end deep ranking model","","","60","","","","","IEEE","IEEE Journals"
"Neural Network Detection of Data Sequences in Communication Systems","N. Farsad; A. Goldsmith","Department of Electrical Engineering, Stanford University, Stanford, CA, USA; Department of Electrical Engineering, Stanford University, Stanford, CA, USA","IEEE Transactions on Signal Processing","","2018","66","21","5663","5678","We consider detection based on deep learning, and show it is possible to train detectors that perform well without any knowledge of the underlying channel models. Moreover, when the channel model is known, we demonstrate that it is possible to train detectors that do not require channel state information (CSI). In particular, a technique we call a sliding bidirectional recurrent neural network (SBRNN) is proposed for detection where, after training, the detector estimates the data in real time as the signal stream arrives at the receiver. We evaluate this algorithm, as well as other neural network (NN) architectures, using the Poisson channel model, which is applicable to both optical and molecular communication systems. In addition, we also evaluate the performance of this detection method applied to data sent over a molecular communication platform, where the channel model is difficult to model analytically. We show that SBRNN is computationally efficient, and can perform detection under various channel conditions without knowing the underlying channel model. We also demonstrate that the bit error rate performance of the proposed SBRNN detector is better than that of a Viterbi detector with imperfect CSI as well as that of other NN detectors that have been previously proposed. Finally, we show that the SBRNN can perform well in rapidly changing channels, where the coherence time is on the order of a single symbol duration.","","","10.1109/TSP.2018.2868322","NSF Center for Science of Information; ONR; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8454325","Machine learning;deep learning;supervised learning;communication systems;detection;optical communication;free-space optical communication;molecular communication","Detectors;Channel models;Detection algorithms;Communication systems;Channel estimation;Receivers;Artificial neural networks","channel estimation;error statistics;learning (artificial intelligence);molecular communication (telecommunication);neural net architecture;Poisson equation;recurrent neural nets;sequences;telecommunication computing;Viterbi detection;wireless channels","NN detectors;neural network detection;data sequences;deep learning;channel state information;sliding bidirectional recurrent neural network;neural network architectures;Poisson channel model;optical communication systems;molecular communication systems;detection method;channel conditions;bit error rate performance;SBRNN detector;Viterbi detector;signal stream;receiver","","20","66","","","","","IEEE","IEEE Journals"
"Automatic Facial Expression Recognition System Using Deep Network-Based Data Fusion","A. Majumder; L. Behera; V. K. Subramanian","Department of Electrical Engineering, Indian Institute of Technology Kanpur, Kanpur, India; Department of Electrical Engineering, Indian Institute of Technology Kanpur, Kanpur, India; Department of Electrical Engineering, Indian Institute of Technology Kanpur, Kanpur, India","IEEE Transactions on Cybernetics","","2018","48","1","103","114","This paper presents a novel automatic facial expressions recognition system (AFERS) using the deep network framework. The proposed AFERS consists of four steps: 1) geometric features extraction; 2) regional local binary pattern (LBP) features extraction; 3) fusion of both the features using autoencoders; and 4) classification using Kohonen self-organizing map (SOM)-based classifier. This paper makes three distinct contributions. The proposed deep network consisting of autoencoders and the SOM-based classifier is computationally more efficient and performance wise more accurate. The fusion of geometric features with LBP features using autoencoders provides better representation of facial expression. The SOM-based classifier proposed in this paper has been improved by making use of a soft-threshold logic and a better learning algorithm. The performance of the proposed approach is validated on two widely used databases (DBs): 1) MMI and 2) extended Cohn-Kanade (CK+). An average recognition accuracy of 97.55% in MMI DB and 98.95% in CK+ DB are obtained using the proposed algorithm. The recognition results obtained from fused features are found to be distinctly superior to both recognition using individual features as well as recognition with a direct concatenation of the individual feature vectors. Simulation results validate that the proposed AFERS is more efficient as compared to the existing approaches.","","","10.1109/TCYB.2016.2625419","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7747479","Autoencoder;deep network;facial expression recognition system;self-organizing map (SOM);support vector machine (SVM)","Feature extraction;Face;Face recognition;Data integration;Support vector machines;Computer architecture;Active appearance model","emotion recognition;face recognition;feature extraction;image classification;learning (artificial intelligence);self-organising feature maps;sensor fusion","automatic facial expression recognition system;AFERS;deep network framework;autoencoders;Kohonen self-organizing map;geometric features;LBP features;soft-threshold logic;average recognition accuracy;fused features;individual feature vectors;SOM-based classifier;deep network-based data fusion;feature extraction","","14","53","","","","","IEEE","IEEE Journals"
"Learning a Deep Single Image Contrast Enhancer from Multi-Exposure Images","J. Cai; S. Gu; L. Zhang","Department of Computing, The Hong Kong Polytechnic University, Hong Kong; Department of Computing, The Hong Kong Polytechnic University, Hong Kong; Department of Computing, The Hong Kong Polytechnic University, Hong Kong","IEEE Transactions on Image Processing","","2018","27","4","2049","2062","Due to the poor lighting condition and limited dynamic range of digital imaging devices, the recorded images are often under-/over-exposed and with low contrast. Most of previous single image contrast enhancement (SICE) methods adjust the tone curve to correct the contrast of an input image. Those methods, however, often fail in revealing image details because of the limited information in a single image. On the other hand, the SICE task can be better accomplished if we can learn extra information from appropriately collected training data. In this paper, we propose to use the convolutional neural network (CNN) to train a SICE enhancer. One key issue is how to construct a training data set of low-contrast and high-contrast image pairs for end-to-end CNN learning. To this end, we build a large-scale multi-exposure image data set, which contains 589 elaborately selected high-resolution multi-exposure sequences with 4,413 images. Thirteen representative multi-exposure image fusion and stack-based high dynamic range imaging algorithms are employed to generate the contrast enhanced images for each sequence, and subjective experiments are conducted to screen the best quality one as the reference image of each scene. With the constructed data set, a CNN can be easily trained as the SICE enhancer to improve the contrast of an under-/over-exposure image. Experimental results demonstrate the advantages of our method over existing SICE methods with a significant margin.","","","10.1109/TIP.2018.2794218","Hong Kong RGC GRF; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8259342","Single image contrast enhancement;multi-exposure image fusion;convolutional neural network","Dynamic range;Image sequences;Lighting;Imaging;Heuristic algorithms;Training data;Training","feature extraction;image colour analysis;image enhancement;image fusion;image segmentation;image sensors;learning (artificial intelligence);neural nets","overexposure image;SICE methods;single image contrast enhancement methods;constructed data set;reference image;high dynamic range imaging algorithms;high-resolution multiexposure sequences;large-scale multiexposure image data set;end-to-end CNN learning;high-contrast image pairs;training data set;SICE enhancer;appropriately collected training data;SICE task;recorded images;digital imaging devices;limited dynamic range;poor lighting condition;multiexposure images;deep single image contrast enhancer","","19","60","","","","","IEEE","IEEE Journals"
"Prediction of Bearing Remaining Useful Life With Deep Convolution Neural Network","L. Ren; Y. Sun; H. Wang; L. Zhang","School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; Department of ICT and Natural Sciences, Norwegian University of Science and Technology, Aalesund, Norway; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China","IEEE Access","","2018","6","","13041","13049","Cyber-physical-social system (CPSS) has drawn tremendous attention in industrial applications such as industrial Internet of Things (IIoT). As the fundamental component of IIoT, bearings play an increasingly important role in CPSS for IIoT. Better understanding of bearing working conditions and degradation patterns so as to more accurately predict the remaining useful life (RUL), becomes an urgent demand for industrial prognostics in IIoT. The data-driven approach has indicated good potential, but the prediction accuracy is still not satisfactory. This paper proposes a new method for the prediction of bearing RUL based on deep convolution neural network (CNN). A new feature extraction method is presented to obtain the eigenvector, named the spectrum-principal-energy-vector. The eigenvector is suitable for deep CNN. In the prediction phase, we propose a smoothing method to deal with the discontinuity problem found in the prediction results. To the best of our knowledge, we are the first to propose such a smoothing method for bearing RUL prediction. Experiments show that our method can significantly improve the prediction accuracy of bearing RUL.","","","10.1109/ACCESS.2018.2804930","National Science Foundation of China; National High Technology Research and Development Program of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8289436","Cyber-physical-social system;industrial big data;deep learning;RUL prediction;deep convolution neural network","Vibrations;Feature extraction;Frequency-domain analysis;Neural networks;Predictive models;Convolution;Time-domain analysis","condition monitoring;cyber-physical systems;feature extraction;Internet of Things;mechanical engineering computing;neural nets;remaining life assessment;rolling bearings","deep convolution neural network;feature extraction method;eigenvector;spectrum-principal-energy-vector;smoothing method;bearing RUL prediction;bearing remaining useful life;cyber-physical-social system;bearing working conditions;degradation patterns;industrial Internet of Things;IIoT fundamental component;RUL prediction;industrial prognostics demand","","15","21","","","","","IEEE","IEEE Journals"
"Traditional Machine Learning for Pitch Detection","T. Drugman; G. Huybrechts; V. Klimkov; A. Moinet","Amazon Development Center Germany, Aachen, Germany; Amazon Development Center Germany, Aachen, Germany; Amazon Development Center Germany, Aachen, Germany; Amazon Development Center Germany, Aachen, Germany","IEEE Signal Processing Letters","","2018","25","11","1745","1749","Pitch detection is a fundamental problem in speech processing as F0 is used in a large number of applications. Recent papers have proposed deep learning for robust pitch tracking. In this letter, we consider voicing detection as a classification problem and F0 contour estimation as a regression problem. For both tasks, acoustic features from multiple domains and traditional machine learning methods are used. The discrimination power of existing and proposed features is assessed through mutual information. Multiple supervised and unsupervised approaches are compared. A significant relative reduction of voicing errors over the best baseline is obtained-20% with the best clustering method (K-means) and 45% with a multi-layer perceptron. For F0 contour estimation, the benefits of regression techniques are limited though. We investigate whether those objective gains translate in a parametric synthesis task. Clear perceptual preferences are observed for the proposed approach over two widely used baselines (robust algorithm for pitch tracking (RAPT) and distributed inline-filter operation (DIO)).","","","10.1109/LSP.2018.2874155","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8481420","Fundamental frequency;pitch detection;pitch tracking;voicing decision;speech synthesis","Feature extraction;Machine learning;Task analysis;Cepstral analysis;Training;Signal processing algorithms","acoustic signal processing;estimation theory;feature extraction;learning (artificial intelligence);multilayer perceptrons;regression analysis;signal classification;speech processing","pitch detection;fundamental problem;machine learning methods;relative reduction;multilayer perceptron;parametric synthesis task;regression techniques;clustering method;discrimination power;acoustic features;regression problem;F0 contour estimation;classification problem;robust pitch tracking;deep learning;speech processing","","","41","","","","","IEEE","IEEE Journals"
"Spatiotemporal Satellite Image Fusion Using Deep Convolutional Neural Networks","H. Song; Q. Liu; G. Wang; R. Hang; B. Huang","Nanjing, China; Nanjing, China; Nanjing, China; Nanjing, China; Hong Kong","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2018","11","3","821","829","We propose a novel spatiotemporal fusion method based on deep convolutional neural networks (CNNs) under the application background of massive remote sensing data. In the training stage, we build two five-layer CNNs to deal with the problems of complicated correspondence and large spatial resolution gaps between MODIS and Landsat images. Specifically, we first learn a nonlinear mapping CNN between MODIS and low-spatial-resolution (LSR) Landsat images and then learn a super-resolution CNN between LSR Landsat and original Landsat images. In the prediction stage, instead of directly taking the outputs of CNNs as the fusion result, we design a fusion model consisting of high-pass modulation and a weighting strategy to make full use of the information in prior images. Specifically, we first map the input MODIS images to transitional images via the learned nonlinear mapping CNN and further improve the transitional images to LSR Landsat images via the fusion model; then, via the learned SR CNN, the LSR Landsat images are supersolved to transitional images, which are further improved to Landsat images via the fusion model. Compared with the previous learning-based fusion methods, mainly referring to the sparse-representation-based methods, our CNNs-based spatiotemporal method has the following advantages: 1) automatically extracting effective image features; 2) learning an end-to-end mapping between MODIS and LSR Landsat images; and 3) generating more favorable fusion results. To examine the performance of the proposed fusion method, we conduct experiments on two representative Landsat-MODIS datasets by comparing with the sparse-representation-based spatiotemporal fusion model. The quantitative evaluations on all possible prediction dates and the comparison of fusion results on one key date in both visual effect and quantitative evaluations demonstrate that the proposed method can generate more accurate fusion results.","","","10.1109/JSTARS.2018.2797894","National Natural Science Foundation of China; Foundation of Jiangsu Province of China; National Social and Scientific Fund Program; HKRGC General Research Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8291042","Convolutional neural network (CNN);nonlinear mapping (NLM);spatial resolution;temporal resolution","Remote sensing;Earth;Artificial satellites;Spatial resolution;MODIS;Spatiotemporal phenomena;Training","feature extraction;feedforward neural nets;geophysical image processing;image fusion;image representation;image resolution;learning (artificial intelligence);remote sensing","Landsat-MODIS datasets;end-to-end mapping learning;automatic effective image feature extraction;MODIS images;massive remote sensing data;low-spatial-resolution Landsat images;accurate fusion results;spatiotemporal fusion model;representative Landsat-MODIS datasets;spatiotemporal method;sparse-representation-based methods;learned SR CNN;LSR Landsat images;learned nonlinear mapping CNN;transitional images;prior images;super-resolution CNN;spatial resolution gaps;spatiotemporal fusion method;deep convolutional neural networks;spatiotemporal satellite image fusion","","9","35","","","","","IEEE","IEEE Journals"
"A Deep Spatiotemporal Perspective for Understanding Crowd Behavior","Y. Li","Department of Pattern Analysis and Computer Vision, Istituto Italiano di Tecnologia, Genoa, Italy","IEEE Transactions on Multimedia","","2018","20","12","3289","3297","Understanding crowd behavior is a pivotal step toward urban scene analysis. This is considered a very challenging task and has rarely been addressed to date due to the complexity of motion dynamics co-occurring across a given scene, which involves spatial and temporal dependencies. Unlike the mainstream research, which usually treats the temporal and spatial dependencies in a crowd separately, this paper presents a deep end-to-end approach that jointly considers the spatiotemporal information, leading to a rich understanding of crowd behavior. We first extract the displacement information describing crowd motion patterns from tracklets/trajectories. This information is subsequently fed into a convolutional layer to learn the underlying motion patterns and create high-level representations. The derived representations are used as inputs to a long short-term memory-based architecture to learn the underlying spatiotemporal cues in a single operation for the entire crowd in a given scene. We evaluate our approach on a widely used, large-scale benchmark datasets for three critical applications: pedestrian path forecasting, destination estimation, and holistic crowd behavior classification. The results show a drastic improvement compared to recently trending works.","","","10.1109/TMM.2018.2834873","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8356584","Computer vision;crowd behavior understanding;spatiotemporal dependencies;deep neural networks","Spatiotemporal phenomena;Network architecture;Neural networks;Computer vision;Legged locomotion","behavioural sciences computing;computer vision;feature extraction;image classification;image motion analysis;image sequences;learning (artificial intelligence);neural nets;object detection;object tracking;spatiotemporal phenomena;video signal processing;video surveillance","motion dynamics;spatial dependencies;temporal dependencies;deep end-to-end approach;spatiotemporal information;displacement information;crowd motion patterns;high-level representations;short-term memory-based architecture;holistic crowd behavior classification;deep spatiotemporal perspective;urban scene analysis;spatiotemporal cues;pedestrian path forecasting;destination estimation","","3","41","","","","","IEEE","IEEE Journals"
"Mobile Demand Forecasting via Deep Graph-Sequence Spatiotemporal Modeling in Cellular Networks","L. Fang; X. Cheng; H. Wang; L. Yang","Department of Electrical and Computer Engineering, Colorado State University, Fort Collins, CO, USA; State Key Laboratory of Advanced Optical Communication Systems and Networks, School of Electronics Engineering and Computer Science, Peking University, Beijing, China; Department of Statistics, Colorado State University, Fort Collins, CO, USA; Department of Electrical and Computer Engineering, Colorado State University, Fort Collins, CO, USA","IEEE Internet of Things Journal","","2018","5","4","3091","3101","The demand forecasting plays a crucial role in the predictive physical and virtualized network management in cellular networks, which can effectively reduce both the capital and operational expenditures by fully exploiting the network infrastructure. In this paper, we study the per-cell demand forecasting in cellular networks. The success of demand forecasting relies on the effective modeling of both the spatial and temporal aspects of the per-cell demand time series. However, the main challenge of the spatial relevancy modeling in the per-cell demand forecasting is the irregular spatial distribution of cells in a network, where applying grid-based models (e.g., convolutional neural networks) would lead to degradation of spatial granularity. In this paper, we propose to model the spatial relevancy among cells by a dependency graph based on spatial distances among cells without the loss of spatial granularity. Such spatial distance-based graph modeling is confirmed by the spatiotemporal analysis via semivariogram, which suggests that the relevancy between any two cells declines as their spatial distance increases. Hence, the graph convolutional networks and long short-term memory (LSTM) from deep learning are employed to model the spatial and temporal aspects, respectively. In addition, the deep graph-sequence model, graph convolutional LSTM, is further employed to simultaneously characterize both the spatial and temporal aspects of mobile demand forecasting. Experiments demonstrate that our proposed graph-sequence demand forecasting model could achieve a superior forecasting performance compared with the other two proposed models as well as the traditional auto regression integrated moving average time series model.","","","10.1109/JIOT.2018.2832071","National Natural Science Foundation of China; National Science and Technology Major Project; National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8353154","Communication system traffic;mobile learning;statistical learning","Demand forecasting;Predictive models;Cellular networks;Poles and towers;Time series analysis;Convolution;Spatiotemporal phenomena","autoregressive moving average processes;convolution;demand forecasting;feedforward neural nets;forecasting theory;graph theory;learning (artificial intelligence);mobile computing;time series","grid-based models;auto regression integrated moving average time series model;virtualized network management;predictive physical network management;deep graph-sequence spatiotemporal modeling;graph-sequence demand forecasting model;mobile demand forecasting;graph convolutional LSTM;graph convolutional networks;spatial distance-based graph modeling;dependency graph;convolutional neural networks;per-cell demand time series;cellular networks;per-cell demand forecasting","","3","31","","","","","IEEE","IEEE Journals"
"LiDAR Data Classification Using Morphological Profiles and Convolutional Neural Networks","A. Wang; X. He; P. Ghamisi; Y. Chen","Higher Education Key Laboratory for Measure and Control Technology and Instrumentations of Heilongjiang, Harbin University of Science and Technology, Harbin, China; Higher Education Key Laboratory for Measure and Control Technology and Instrumentations of Heilongjiang, Harbin University of Science and Technology, Harbin, China; Remote Sensing Technology Institute, German Aerospace Center, Wessling, Germany; School of Electronics and Information Engineering, Harbin Institute of Technology, Harbin, China","IEEE Geoscience and Remote Sensing Letters","","2018","15","5","774","778","In recent years, deep learning-based methods, especially convolutional neural networks (CNNs), have shown their capabilities in remote sensing data processing. The efficacy of light detection and ranging (LiDAR) has been already proven in a wide variety of research areas. Most of the existing methods do not extract the informative features from LiDAR-derived rasterized digital surface models (LiDAR-DSM) data in a deep manner. In order to utilize the advantages of deep models for the classification of LiDAR-derived features, deep CNN is proposed here to hierarchically extract the robust and discriminant features of the input data. Moreover, morphological profiles and multiattribute profiles (MAPs) are investigated to enrich the inputs of the CNN and further to improve the ultimate classification performance. Furthermore, a new activation function, sigmoid-weighted linear units (SiLUs), is introduced. The proposed frameworks are tested on two LiDAR-DSMs (i.e., Bayview Park and Houston data sets). The MAP-CNNs with SiLU outperform original CNNs by 6.62% and 6.88% in terms of overall accuracy on Bayview Park and Houston data sets, respectively, when the number of training samples of each class is 40.","","","10.1109/LGRS.2018.2810276","Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8319917","Convolutional neural network (CNN);deep learning;feature extraction (FE);light detection and ranging (LiDAR);morphological profile (MP);multiattribute profile (MAP);sigmoid-weighted linear units (SiLUs)","Feature extraction;Data mining;Laser radar;Data models;Robustness;Iron;Shape","feature extraction;image classification;learning (artificial intelligence);neural nets;optical radar","morphological profiles;convolutional neural networks;deep learning-based methods;remote sensing data processing;informative features;rasterized digital surface models;LiDAR-DSM;deep CNN;multiattribute profiles;ultimate classification performance;MAP-CNNs;SiLU outperform original CNNs;LiDAR data classification;light detection and ranging;Bayview Park dataset;Houston dataset","","3","18","","","","","IEEE","IEEE Journals"
"Left Atrial Appendage Segmentation Using Fully Convolutional Neural Networks and Modified Three-Dimensional Conditional Random Fields","C. Jin; J. Feng; L. Wang; H. Yu; J. Liu; J. Lu; J. Zhou","Department of Automation, the State Key Lab of Intelligent Technologies and Systems, and the Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China; Department of Automation, the State Key Lab of Intelligent Technologies and Systems, and the Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China; Department of Automation, the State Key Lab of Intelligent Technologies and Systems, and the Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China; Department of Automation, the State Key Lab of Intelligent Technologies and Systems, and the Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China; Department of Automation, the State Key Lab of Intelligent Technologies and Systems, and the Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China; Department of Automation, the State Key Lab of Intelligent Technologies and Systems, and the Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China; Department of Automation, the State Key Lab of Intelligent Technologies and Systems, and the Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China","IEEE Journal of Biomedical and Health Informatics","","2018","22","6","1906","1916","Thrombosis has become a global disease threatening human health. The left atrial appendage (LAA) is a major source of thrombosis in patients with atrial fibrillation (AF). Positive correlation exists between LAA volume and AF risk. LAA morphology has been suggested to influence thromboembolic risk in AF patients and to help predict thromboembolic events in low-risk patient groups. Automatic segmentation of LAA can greatly help physicians diagnose AF. In consideration of the large anatomical variations of the LAA, we proposed a robust method for automatic LAA segmentation on computed tomographic angiography (CTA) data using fully convolutional neural networks with three-dimensional (3-D) conditional random fields (CRFs). After manual localization of ROI of LAA, we adopted the FCN in natural image segmentation and transferred their learned models by fine-tuning the networks to segment each 2-D LAA slice. Subsequently, we used a modified dense 3-D CRF that accounts for the 3-D spatial information and larger contextual information to refine the segmentations of all slices. Our method was evaluated on 150 sets of CTA data using five-fold cross validation. Compared with manual annotation, we obtained a mean dice overlap of 94.76% and a mean volume overlap of 91.10% with a computation time of less than 40 s per volume. Experimental results demonstrated the robustness of our method in dealing with large anatomical variations and computational efficiency for adoption in a daily clinical routine.","","","10.1109/JBHI.2018.2794552","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8260863","Deep learning;fully convolutional neural networks (FCNs);left atrial appendage (LAA);LAA closure surgery segmentation;3–D conditional random field (CRF)","Image segmentation;Computed tomography;Convolutional neural networks;Biomedical imaging;Atrial fibrillation;Deep learning;Brain modeling;Thrombosis","blood vessels;cardiology;computerised tomography;convolution;diagnostic radiography;diseases;feedforward neural nets;image segmentation;learning (artificial intelligence);medical image processing;random processes;risk analysis","convolutional neural networks;image segmentation;left atrial appendage segmentation;LAA segmentation;three-dimensional conditional random fields;disease;human health;CTA;CRFs;2-D LAA slice;contextual information;five-fold cross validation;learned models;AF patients;thromboembolic risk;LAA morphology;AF risk;atrial fibrillation;thrombosis;anatomical variations;3-D spatial information;computed tomographic angiography data","","4","39","","","","","IEEE","IEEE Journals"
"Move Prediction Using Deep Convolutional Neural Networks in Hex","C. Gao; R. Hayward; M. Müller","Department of Computing Science, University of Alberta, Edmonton, AB, Canada; Department of Computing Science, University of Alberta, Edmonton, AB, Canada; Department of Computing Science, University of Alberta, Edmonton, AB, Canada","IEEE Transactions on Games","","2018","10","4","336","343","Using deep convolutional neural networks for move prediction has led to massive progress in computer Go. Like Go, Hex has a large branching factor that limits the success of shallow and selective search. We show that deep convolutional neural networks can be used to produce reliable move evaluation in the game of Hex. We begin by collecting self-play games of MoHex 2.0. We then train the neural networks by canonical maximum likelihood. The trained model was evaluated by playing against top programs Wolve and MoHex 2.0. Without any search, the resulting neural network produces similar playing strength as the highly optimized Resistance evaluation function used in Wolve. Finally, using the neural networks as prior knowledge, the reigning Monte-Carlo-tree-search-based world champion player MoHex 2.0 can be enhanced.","","","10.1109/TG.2017.2785042","Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8226781","Deep learning;games; ${Hex}$ ;Monte Carlo tree search;move prediction","Bridges;Games;Resistance;Monte Carlo methods;Computational modeling","computer games;learning (artificial intelligence);maximum likelihood estimation;Monte Carlo methods;neural nets;search problems;tree searching;trees (mathematics)","deep convolutional neural networks;Monte-Carlo-tree-search-based world champion player;canonical maximum likelihood;MoHex 2.0","","","55","","","","","IEEE","IEEE Journals"
"End-to-End Blind Image Quality Assessment Using Deep Neural Networks","K. Ma; W. Liu; K. Zhang; Z. Duanmu; Z. Wang; W. Zuo","Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China","IEEE Transactions on Image Processing","","2018","27","3","1202","1213","We propose a multi-task end-to-end optimized deep neural network (MEON) for blind image quality assessment (BIQA). MEON consists of two sub-networks-a distortion identification network and a quality prediction network-sharing the early layers. Unlike traditional methods used for training multi-task networks, our training process is performed in two steps. In the first step, we train a distortion type identification sub-network, for which large-scale training samples are readily available. In the second step, starting from the pre-trained early layers and the outputs of the first sub-network, we train a quality prediction sub-network using a variant of the stochastic gradient descent method. Different from most deep neural networks, we choose biologically inspired generalized divisive normalization (GDN) instead of rectified linear unit as the activation function. We empirically demonstrate that GDN is effective at reducing model parameters/layers while achieving similar quality prediction performance. With modest model complexity, the proposed MEON index achieves state-of-the-art performance on four publicly available benchmarks. Moreover, we demonstrate the strong competitiveness of MEON against state-of-the-art BIQA models using the group maximum differentiation competition methodology.","","","10.1109/TIP.2017.2774045","Natural Sciences and Engineering Research Council of Canada; NSFC; CSC; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8110690","Blind image quality assessment;deep neural networks;multi-task learning;generalized divisive normalization;gMAD competition","Training;Image quality;Image coding;Nonlinear distortion;Neural networks","distortion;image representation;learning (artificial intelligence);neural nets","deep neural network;distortion identification network;training process;distortion type identification sub-network;large-scale training samples;quality prediction sub-network;similar quality prediction performance;end-to-end blind image quality assessment;quality prediction network;MEON index;group maximum differentiation competition methodology","","33","57","","","","","IEEE","IEEE Journals"
"Semisupervised Classification of Polarimetric SAR Image via Superpixel Restrained Deep Neural Network","J. Geng; X. Ma; J. Fan; H. Wang","School of Information and Communication Engineering, Dalian University of Technology, Dalian, China; School of Information and Communication Engineering, Dalian University of Technology, Dalian, China; Department of Ocean Remote Sensing, National Marine Environmental Monitoring Center, Dalian, China; School of Information and Communication Engineering, Dalian University of Technology, Dalian, China","IEEE Geoscience and Remote Sensing Letters","","2018","15","1","122","126","The classification of polarimetric synthetic aperture radar (PolSAR) image is of crucial significance for SAR applications. In this letter, a superpixel restrained deep neural network with multiple decisions (SRDNN-MDs) is proposed for PolSAR image classification, which not only extracts effective superpixel spatial features and degrades the influence of speckle noises but also deals with the limited training samples. First, the polarimetric features of coherency matrix and Yamaguchi decomposition are extracted as initial features, and superpixel segmentation is conducted on the Pauli color-coded image to acquire the superpixel averaged features. Then, an SRDNN based on sparse autoencoders is proposed to capture superpixel correlative features and reduce speckle noises. After that, MDs, including nonlocal decision and local decision, are developed to select credible testing samples. Finally, our deep network is updated by the extended training set to yield the final classification map. Experimental results demonstrate that the proposed SRDNN-MD yields higher accuracies compared with other related approaches, which indicate that the proposed method is able to capture superpixel correlative information and adds the information of unlabeled samples to improve the classification performance.","","","10.1109/LGRS.2017.2777450","National Key Research and Development Program of China; National Natural Science Foundation of China; Foundation of High Resolution Special Research; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8168823","Autoencoders;deep learning;polarimetric synthetic aperture radar (PolSAR);semisupervised classification","Training;Feature extraction;Testing;Scattering;Matrix decomposition;Image segmentation;Speckle","geophysical image processing;image classification;image segmentation;learning (artificial intelligence);neural nets;radar imaging;radar polarimetry;speckle;synthetic aperture radar;terrain mapping","polarimetric SAR image;superpixel restrained deep neural network;polarimetric synthetic aperture radar image;SAR applications;PolSAR image classification;speckle noises;polarimetric features;coherency matrix;Yamaguchi decomposition;superpixel segmentation;superpixel correlative features;superpixel correlative information","","8","16","","","","","IEEE","IEEE Journals"
"Deep Feature Fusion for Iris and Periocular Biometrics on Mobile Devices","Q. Zhang; H. Li; Z. Sun; T. Tan","School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; Center for Research on Intelligent Perception and Computing, National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Center for Research on Intelligent Perception and Computing, National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Center for Research on Intelligent Perception and Computing, National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Information Forensics and Security","","2018","13","11","2897","2912","The quality of iris images on mobile devices is significantly degraded due to hardware limitations and less constrained environments. Traditional iris recognition methods cannot achieve high identification rate using these low-quality images. To enhance the performance of mobile identification, we develop a deep feature fusion network that exploits the complementary information presented in iris and periocular regions. The proposed method first applies maxout units into the convolutional neural networks (CNNs) to generate a compact representation for each modality and then fuses the discriminative features of two modalities through a weighted concatenation. The parameters of convolutional filters and fusion weights are simultaneously learned to optimize the joint representation of iris and periocular biometrics. To promote the iris recognition research on mobile devices under near-infrared (NIR) illumination, we publicly release the CASIA-Iris-Mobile-V1.0 database, which in total includes 11 000 NIR iris images of both eyes from 630 Asians. It is the largest NIR mobile iris database as far as we know. On the newly built CASIA-Iris-M1-S3 data set, the proposed method achieves 0.60% equal error rate and 2.32% false non-match rate at false match rate =10-5, which are obviously better than unimodal biometrics as well as traditional fusion methods. Moreover, the proposed model requires much fewer storage spaces and computational resources than general CNNs.","","","10.1109/TIFS.2018.2833033","National Natural Science Foundation of China; National Key Research and Development Program of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8356122","Iris recognition;periocular recognition;deep feature fusion;adaptive weights;mobile devices","Iris recognition;Mobile handsets;Databases;Lighting;Machine learning;Sensors","biometrics (access control);feature extraction;feedforward neural nets;image fusion;image matching;image recognition;iris recognition;learning (artificial intelligence)","mobile devices;CASIA-Iris-Mobile-V;largest NIR mobile iris database;false match rate;traditional fusion methods;periocular biometrics;hardware limitations;low-quality images;mobile identification;deep feature fusion network;convolutional neural networks;discriminative features;convolutional filters;fusion weights;iris recognition research;CNN;CASIA-Iris-M1-S3","","7","65","","","","","IEEE","IEEE Journals"
"Incremental Learning Through Deep Adaptation","A. Rosenfeld; J. K. Tsotsos","EECS, York University, Toronto, Ontario Canada M3J 1P3 (e-mail: amir.rosenfeld@gmail.com); Computer Science & Engineering, York University, Toronto, Ontario Canada (e-mail: tsotsos@cse.yorku.ca)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","PP","99","1","1","Given an existing trained neural network, it is often desirable to learn new capabilities without hindering performance of those already learned. Existing approaches either learn sub-optimal solutions, require joint training, or incur a substantial increment in the number of parameters for each added domain, typically as many as the original network. We propose a method called Deep Adaptation Modules (DAM) that constrains newly learned filters to be linear combinations of existing ones. DAMs precisely preserve performance on the original domain, require a fraction (typically 13%, dependent on network architecture) of the number of parameters compared to standard fine-tuning procedures and converge in less cycles of training to a comparable or better level of performance. When coupled with standard network quantization techniques, we further reduce the parameter cost to around 3% of the original with negligible or no loss in accuracy. The learned architecture can be controlled to switch between various learned representations, enabling a single network to solve a task from multiple different domains. We conduct extensive experiments showing the effectiveness of our method on a range of image classification tasks and explore different aspects of its behavior.","","","10.1109/TPAMI.2018.2884462","Canada Research Chairs; Air Force Office of Scientific Research; Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8554156","Incremental Learning;Transfer Learning;Domain Adaptation","Task analysis;Switches;Training;Neural networks;Computer architecture;Convolutional codes","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Deep Spatial Contextual Long-Term Recurrent Convolutional Network for Saliency Detection","N. Liu; J. Han","School of Automation, Northwestern Polytechnical University, Xi’an, China; School of Automation, Northwestern Polytechnical University, Xi’an, China","IEEE Transactions on Image Processing","","2018","27","7","3264","3274","Traditional saliency models usually adopt hand-crafted image features and human-designed mechanisms to calculate local or global contrast. In this paper, we propose a novel computational saliency model, i.e., deep spatial contextual long-term recurrent convolutional network (DSCLRCN), to predict where people look in natural scenes. DSCLRCN first automatically learns saliency related local features on each image location in parallel. Then, in contrast with most other deep network based saliency models which infer saliency in local contexts, DSCLRCN can mimic the cortical lateral inhibition mechanisms in human visual system to incorporate global contexts to assess the saliency of each image location by leveraging the deep spatial long short-term memory (DSLSTM) model. Moreover, we also integrate scene context modulation in DSLSTM for saliency inference, leading to a novel deep spatial contextual LSTM (DSCLSTM) model. The whole network can be trained end-to-end and works efficiently when testing. Experimental results on two benchmark datasets show that DSCLRCN can achieve state-of-the-art performance on saliency detection. Furthermore, the proposed DSCLSTM model can significantly boost the saliency detection performance by incorporating both global spatial interconnections and scene context modulation, which may uncover novel inspirations for studies on them in computational saliency models.","","","10.1109/TIP.2018.2817047","National Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8319456","Saliency detection;eye fixation prediction;convolutional neural networks;long short-term memory;global context;scene context","Feature extraction;Visualization;Context modeling;Computational modeling;Saliency detection;Task analysis;Modulation","feature extraction;learning (artificial intelligence);recurrent neural nets","deep spatial contextual long-term recurrent convolutional network;traditional saliency models;hand-crafted image features;DSCLRCN;saliency related local features;image location;short-term memory model;scene context modulation;saliency inference;deep spatial contextual LSTM model;DSCLSTM model;saliency detection performance;global spatial interconnections;computational saliency model;human-designed mechanisms;natural scenes;cortical lateral inhibition mechanisms;human visual system;deep spatial long short-term memory;deep spatial contextual LSTM","","17","70","","","","","IEEE","IEEE Journals"
"Geometric Correspondence Network for Camera Motion Estimation","J. Tang; J. Folkesson; P. Jensfelt","Centre for Autonomous Systems at KTH Royal Institute of Technology, Stockholm, Sweden; Centre for Autonomous Systems at KTH Royal Institute of Technology, Stockholm, Sweden; Centre for Autonomous Systems at KTH Royal Institute of Technology, Stockholm, Sweden","IEEE Robotics and Automation Letters","","2018","3","2","1010","1017","In this paper, we propose a new learning scheme for generating geometric correspondences to be used for visual odometry. A convolutional neural network (CNN) combined with a recurrent neural network (RNN) are trained together to detect the location of keypoints as well as to generate corresponding descriptors in one unified structure. The network is optimized by warping points from source frame to reference frame, with a rigid body transform. Essentially, learning from warping. The overall training is focused on movements of the camera rather than movements within the image, which leads to better consistency in the matching and ultimately better motion estimation. Experimental results show that the proposed method achieves better results than both related deep learning and hand crafted methods. Furthermore, as a demonstration of the promise of our method we use a naive SLAM implementation based on these keypoints and get a performance on par with ORB-SLAM.","","","10.1109/LRA.2018.2794624","Wallenberg Autonomous Systems and Software Program; European Unions Horizon; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8260906","Visual-based navigation;SLAM;deep learning in robotics and automation","Cameras;Motion estimation;Feature extraction;Simultaneous localization and mapping;Machine learning","cameras;feature extraction;image matching;learning (artificial intelligence);mobile robots;motion estimation;neural nets;pose estimation;recurrent neural nets;robot vision;SLAM (robots)","geometric correspondence network;camera motion estimation;convolutional neural network;CNN;recurrent neural network;unified structure;warping points;source frame;reference frame;visual odometry method;deep learning;keypoints location;hand crafted method;naive SLAM implementation;ORB-SLAM","","2","52","","","","","IEEE","IEEE Journals"
"Query Intent Recognition Based on Multi-Class Features","L. Qiu; Y. Chen; H. Jia; Z. Zhang","School of Information Engineering, Minzu University of China, Beijing, China; School of Information Engineering, Minzu University of China, Beijing, China; International School, Beijing University of Posts and Telecommunications, Beijing, China; School of Information Engineering, Minzu University of China, Beijing, China","IEEE Access","","2018","6","","52195","52204","In order to enhance the user search experience of the search engine, an intent recognition search based on natural language input is proposed. By using reality mining technology to obtain the potential consciousness information from the query expression, search engines can better predict the query results that meet users' requirements. With the development of conventional machine learning and deep learning, it is possible to further improve the accuracy of prediction results. This paper adopts a similarity calculation method based on long short-term memory (LSTM) and a traditional machine learning method based on multi-feature extraction. It is found that entity features can significantly improve the accuracy of intention classification. Second, the accuracy of intention classification based on the feature sequence constructed by key entities is up to 94.16% in the field of manual labeling by using the BiLSTM classification model.","","","10.1109/ACCESS.2018.2869585","National Natural Science Foundation of China; Project of Humanities and Social Sciences of the Ministry of Education of China; Beijing University of Posts and Telecommunications; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8458426","Intent recognition;multi-class;long short term memory (LSTM);reality mining;deep learning","Machine learning;Search engines;Feature extraction;Semantics;Data models;Computer architecture","data mining;feature extraction;learning (artificial intelligence);pattern classification;query processing;search engines","multiclass features;user search experience;search engine;intent recognition search;natural language input;reality mining technology;query expression;deep learning;similarity calculation method;short-term memory;multifeature extraction;entity features;intention classification;feature sequence;query intent recognition;BiLSTM classification model;consciousness information","","1","24","","","","","IEEE","IEEE Journals"
"Efficient Hardware Architectures for Deep Convolutional Neural Network","J. Wang; J. Lin; Z. Wang","School of Electronic Science and Engineering, Nanjing University, Nanjing, China; School of Electronic Science and Engineering, Nanjing University, Nanjing, China; School of Electronic Science and Engineering, Nanjing University, Nanjing, China","IEEE Transactions on Circuits and Systems I: Regular Papers","","2018","65","6","1941","1953","Convolutional neural network (CNN) is the state-of-the-art deep learning approach employed in various applications. Real-time CNN implementations in resource limited embedded systems are becoming highly desired recently. To ensure the programmable flexibility and shorten the development period, field programmable gate array is appropriate to implement the CNN models. However, the limited bandwidth and on-chip memory storage are the bottlenecks of the CNN acceleration. In this paper, we propose efficient hardware architectures to accelerate deep CNN models. The theoretical derivation of parallel fast finite impulse response algorithm (FFA) is introduced. Based on FFAs, the corresponding fast convolution units (FCUs) are developed for the computation of convolutions in the CNN models. Novel data storage and reuse schemes are proposed, where all intermediate pixels are stored on-chip and the bandwidth requirement is reduced. We choose one of the largest and most accurate networks, VGG16, and implement it on Xilinx Zynq ZC706 and Virtex VC707 boards, respectively. We achieve the top-5 accuracy of 86.25% using an equal distance non-uniform quantization method. It is estimated that the average performances are 316.23 GOP/s under 172-MHz working frequency on Xilinx ZC706 and 1250.21 GOP/s under 170-MHz working frequency on VC707, respectively. In brief, the proposed design outperforms the existing works significantly, in particular, surpassing related designs by more than two times in terms of resource efficiency.","","","10.1109/TCSI.2017.2767204","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8118295","Convolutional neural network (CNN);field programmable gate array (FPGA) platform;fast FIR algorithm;on-chip data storage scheme","Convolution;Kernel;Hardware;Computer architecture;Computational modeling;Finite impulse response filters;Real-time systems","embedded systems;feedforward neural nets;field programmable gate arrays;learning (artificial intelligence);parallel algorithms;parallel architectures;quantisation (signal);resource allocation;storage management","resource efficiency;efficient hardware architectures;deep convolutional neural network;deep learning approach;real-time CNN implementations;resource limited embedded systems;programmable flexibility;field programmable gate array;on-chip memory storage;CNN acceleration;deep CNN models;parallel fast finite impulse response algorithm;bandwidth requirement;Virtex VC707 boards;equal distance nonuniform quantization method;fast convolution units;Xilinx Zynq ZC706 board;frequency 172 MHz;frequency 170 MHz","","13","31","","","","","IEEE","IEEE Journals"
"Human-level face verification with intra-personal factor analysis and deep face representation","S. Munasinghe; C. Fookes; S. Sridharan","Image and Video Research Lab, Queensland University of Technology, Australia; Image and Video Research Lab, Queensland University of Technology, Australia; Image and Video Research Lab, Queensland University of Technology, Australia","IET Biometrics","","2018","7","5","467","473","The last two decades have seen an escalating interest in methods for large-scale unconstrained face recognition. While the promise of computer vision systems to efficiently and accurately verify and identify faces in naturally occurring circumstances still remains elusive, recent advances in deep learning are taking us closer to human-level recognition. In this study, the authors propose a new paradigm which employs deep features in a feature extractor and intra-personal factor analysis as a recogniser. The proposed new strategy represents the face changes of a person using identity specific components and the intra-personal variation through reinterpretation of a Bayesian generative factor analysis model. The authors employ the expectation-maximisation algorithm to calculate model parameters which cannot be observed directly. Recognition outcomes achieved through benchmarking on large-scale wild databases, Labeled Faces in the Wild (LFW) and Youtube Face (YTF), clearly prove that the proposed approach provides remarkable face verification performance improvement over state-of-the-art approaches.","","","10.1049/iet-bmt.2017.0050","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8440886","","","Bayes methods;computer vision;expectation-maximisation algorithm;face recognition;feature extraction;image representation;learning (artificial intelligence)","Youtube face recognition;Labeled face recognition;intrapersonal factor analysis;human-level face verification;remarkable face verification performance improvement;recognition outcomes;intra-personal variation;feature extractor;deep features;human-level recognition;deep learning;computer vision systems;large-scale unconstrained face recognition;deep face representation","","","","","","","","IET","IET Journals"
"Robust Automated VHF Modulation Recognition Based on Deep Convolutional Neural Networks","R. Li; L. Li; S. Yang; S. Li","National Key Laboratory of Science and Technology on Communications, University of Electronic Science and Technology of China, Chengdu, China; National Key Laboratory of Science and Technology on Communications, University of Electronic Science and Technology of China, Chengdu, China; School of Electronic Engineering, Xidian University, Xi’an, China; National Key Laboratory of Science and Technology on Communications, University of Electronic Science and Technology of China, Chengdu, China","IEEE Communications Letters","","2018","22","5","946","949","This letter proposes a novel modulation recognition algorithm for very high frequency (VHF) radio signals, which is based on antinoise processing and deep sparse-filtering convolutional neural network (AN-SF-CNN). First, the cyclic spectra of modulated signals are calculated, and then, low-rank representation is performed on cyclic spectra to reduce disturbances existed in VHF radio signals. After that, before fine tuning the CNN, we propose a sparse-filtering criterion to unsupervised pretrain the network layer-by-layer, which improves generalization effectively. Several experiments are taken on seven kinds of modulated signals, and the simulation results show that, compared with the traditional methods and some renowned deep learning methods, the proposed method can achieve higher or equivalent classification accuracy, and presents robustness against noises.","","","10.1109/LCOMM.2018.2809732","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8302885","Automated modulation recognition (AMR);convolutional neural networks (CNNs);cyclic spectrum;low-rank representation (LRR);sparse filter","Training;Convolution;Frequency modulation;Noise reduction;Fading channels;Phase modulation","convolution;feedforward neural nets;filtering theory;learning (artificial intelligence);modulation;signal classification;telecommunication computing;VHF radio propagation","high frequency radio signals;antinoise processing;AN-SF-CNN;cyclic spectra;modulated signals;low-rank representation;VHF radio signals;layer-by-layer;renowned deep learning methods;robust automated VHF modulation recognition;deep convolutional neural networks;novel modulation recognition algorithm;classification accuracy;deep sparse-filtering convolutional neural network","","3","8","","","","","IEEE","IEEE Journals"
"Progressive Learning of Topic Modeling Parameters: A Visual Analytics Framework","M. El-Assady; R. Sevastjanova; F. Sperrle; D. Keim; C. Collins","University of Konstanz, Germany; University of Konstanz, Germany; University of Konstanz, Germany; University of Konstanz, Germany; University of Ontario Institute of Technology, Canada","IEEE Transactions on Visualization and Computer Graphics","","2018","24","1","382","391","Topic modeling algorithms are widely used to analyze the thematic composition of text corpora but remain difficult to interpret and adjust. Addressing these limitations, we present a modular visual analytics framework, tackling the understandability and adaptability of topic models through a user-driven reinforcement learning process which does not require a deep understanding of the underlying topic modeling algorithms. Given a document corpus, our approach initializes two algorithm configurations based on a parameter space analysis that enhances document separability. We abstract the model complexity in an interactive visual workspace for exploring the automatic matching results of two models, investigating topic summaries, analyzing parameter distributions, and reviewing documents. The main contribution of our work is an iterative decision-making technique in which users provide a document-based relevance feedback that allows the framework to converge to a user-endorsed topic distribution. We also report feedback from a two-stage study which shows that our technique results in topic model quality improvements on two independent measures.","","","10.1109/TVCG.2017.2745080","DARPA Big Mechanism Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8019825","Topic Model Configuration;Reinforcement Learning;Feature Detection and Tracking;Iterative Optimization","Analytical models;Adaptation models;Computational modeling;Visual analytics;Data models;Learning (artificial intelligence)","decision making;interactive systems;learning (artificial intelligence);relevance feedback;text analysis","progressive learning;topic modeling parameters;thematic composition;text corpora;modular visual analytics framework;reinforcement learning process;document corpus;algorithm configurations;parameter space analysis;document separability;model complexity;interactive visual workspace;topic summaries;parameter distributions;iterative decision-making technique;user-endorsed topic distribution;topic model quality improvements;topic model adaptability;topic model understandability","","10","43","Traditional","","","","IEEE","IEEE Journals"
"Deep Construction of an Affective Latent Space via Multimodal Enactment","G. Boccignone; D. Conte; V. Cuculo; A. D’Amelio; G. Grossi; R. Lanzarotti","Department of Computer Science, PHuSeLab, University of Milan, Milan, Italy; Computer Science Laboratory, University of Tours, Tours, France; Department of Computer Science, PHuSeLab, University of Milan, Milan, Italy; Department of Computer Science, PHuSeLab, University of Milan, Milan, Italy; Department of Computer Science, PHuSeLab, University of Milan, Milan, Italy; Department of Computer Science, PHuSeLab, University of Milan, Milan, Italy","IEEE Transactions on Cognitive and Developmental Systems","","2018","10","4","865","880","We draw on a simulationist approach to the analysis of facially displayed emotions, e.g., in the course of a face-to-face interaction between an expresser and an observer. At the heart of such perspective lies the enactment of the perceived emotion in the observer. We propose a novel probabilistic framework based on a deep latent representation of a continuous affect space, which can be exploited for both the estimation and the enactment of affective states in a multimodal space (visible facial expressions and physiological signals). The rationale behind the approach lies in the large body of evidence from affective neuroscience showing that when we observe emotional facial expressions, we react with congruent facial mimicry. Further, in more complex situations, affect understanding is likely to rely on a comprehensive representation grounding the reconstruction of the state of the body associated with the displayed emotion. We show that our approach can address such problems in a unified and principled perspective, thus avoiding ad hoc heuristics while minimizing learning efforts.","","","10.1109/TCDS.2017.2788820","Italian Government-MIUR, Future in Research Fund through project “Interpreting emotions: A Computational Tool Integrating Facial Expressions and Biosignals Based Shape Analysis and Bayesian Networks.”; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8242671","Bayesian models;deep learning;emotion;human–agent interaction;simulation","Observers;Computational modeling;Face recognition;Visualization;Emotion recognition;Psychology","behavioural sciences computing;emotion recognition;face recognition;learning (artificial intelligence)","affective latent space;multimodal enactment;simulationist approach;face-to-face interaction;expresser;observer;perceived emotion;deep latent representation;continuous affect space;affective states;multimodal space;visible facial expressions;physiological signals;affective neuroscience;emotional facial expressions;congruent facial mimicry;comprehensive representation grounding;displayed emotion;unified perspective;principled perspective;probabilistic framework","","2","93","","","","","IEEE","IEEE Journals"
"Training Very Deep CNNs for General Non-Blind Deconvolution","R. Wang; D. Tao","Union Visual Innovation Technology Co., Ltd., Shenzhen, China; UBTECH Sydney Artificial Intelligence Centre and the School of Information Technologies, Faculty of Engineering and Information Technologies, The University of Sydney, Darlington, NSW, Australia","IEEE Transactions on Image Processing","","2018","27","6","2897","2910","Non-blind image deconvolution is an ill-posed problem. The presence of noise and band-limited blur kernels makes the solution of this problem non-unique. Existing deconvolution techniques produce a residual between the sharp image and the estimation that is highly correlated with the sharp image, the kernel, and the noise. In most cases, different restoration models must be constructed for different blur kernels and different levels of noise, resulting in low computational efficiency or highly redundant model parameters. Here we aim to develop a single model that handles different types of kernels and different levels of noise: general non-blind deconvolution. Specifically, we propose a very deep convolutional neural network that predicts the residual between a pre-deconvolved image and the sharp image rather than the sharp image. The residual learning strategy makes it easier to train a single model for different kernels and different levels of noise, encouraging high effectiveness and efficiency. Quantitative evaluations demonstrate the practical applicability of the proposed model for different blur kernels. The model also shows the state-of-the-art performance on synthesized blurry images.","","","10.1109/TIP.2018.2815084","Australian Research Council Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8315039","Deep CNNs;residual learning;non-blind deconvolution","Deconvolution;Kernel;Image restoration;Computational modeling;Training;Convolution;Task analysis","deconvolution;image restoration;learning (artificial intelligence);neural nets","deep convolutional neural network;pre-deconvolved image;sharp image;single model;synthesized blurry images;nonblind image deconvolution;band-limited blur kernels;deconvolution techniques;different restoration models;highly redundant model parameters;blur kernels;quantitative evaluations","","3","56","","","","","IEEE","IEEE Journals"
"Deep Endoscope: Intelligent Duct Inspection for the Avionic Industry","S. Martelli; L. Mazzei; C. Canali; P. Guardiani; S. Giunta; A. Ghiazza; I. Mondino; F. Cannella; V. Murino; A. D. Bue","Pattern Analysis and Computer Vision (PAVIS), Istituto Italiano di Tecnologia (IIT), Genova, Italy; Pattern Analysis and Computer Vision (PAVIS), Istituto Italiano di Tecnologia (IIT), Genova, Italy; Advanced Robotics, Istituto Italiano di Tecnologia (IIT), Genova, Italy; Advanced Robotics, Istituto Italiano di Tecnologia (IIT), Genova, Italy; AvioAero, 10040 Rivalta di Torino, Italy; AvioAero, 10040 Rivalta di Torino, Italy; AvioAero, 10040 Rivalta di Torino, Italy; Advanced Robotics, Istituto Italiano di Tecnologia (IIT), Genova, Italy; Pattern Analysis and Computer Vision (PAVIS), Istituto Italiano di Tecnologia (IIT), Genova, Italy; Visual Geometry and Modeling (VGM), Istituto Italiano di Tecnologia (IIT), Genova, Italy","IEEE Transactions on Industrial Informatics","","2018","14","4","1701","1711","We present the first autonomous endoscope for the visual inspection of very small ducts and cavities, up to a 6-mm diameter. The system has been designed, implemented, and tested in a challenging industrial scenario and in strict collaboration with an avionic industry partner. The inspected objects are metallic gearboxes eventually presenting different residuals (e.g., sand, machining swarfs, and metallic dust) inside the oil ducts. The automatic system is actuated by a robotic arm that moves the endoscope with a microcamera inside the gearbox duct, while a deep-learning-based spatio-temporal image analysis module detects, classifies, and localizes defects in real time. Feedback is given to the robotic arm in order to move or extract the endoscope given the detected anomalies. Evaluation provides a detection rate of nearly 98% given different tests with different types of residuals and duct structures.","","","10.1109/TII.2018.2807797","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8295126","Deep learning;robotic endoscope;visual inspection","Ducts;Inspection;Robots;Endoscopes;Task analysis;Visualization;Probes","aerospace industry;automatic optical inspection;avionics;ducts;endoscopes;gears;industrial manipulators;learning (artificial intelligence);robot vision","spatio-temporal image analysis module;gearbox duct;robotic arm;oil ducts;metallic dust;metallic gearboxes;avionic industry partner;visual inspection;autonomous endoscope;intelligent duct inspection;deep endoscope","","","42","","","","","IEEE","IEEE Journals"
"Deep hashing network for material defect image classification","K. Yang; Z. Sun; A. Wang; R. Liu; Q. Sun; Y. Wang","Taiyuan University of Science and Technology, People's Republic of China; Taiyuan University of Science and Technology, People's Republic of China; Taiyuan University of Science and Technology, People's Republic of China; Taiyuan University of Science and Technology, People's Republic of China; Taiyuan University of Science and Technology, People's Republic of China; Taiyuan University of Science and Technology, People's Republic of China","IET Computer Vision","","2018","12","8","1112","1120","Common non-destructive material testing technology has some well-known problems such as slow detection, low detection accuracy, and low level of information obtained. To solve these problems, this study applied recent advances in convolution neural networks to propose an effective deep learning network using casting datasets. The approach achieves non-destructive material testing with automatic, intelligent detection technology. For most existing deep learning networks, an image is eventually transformed into a multidimensional visual feature vector for comparison and classification. However, such vectors may not optimally improve detection precision and speed, and can lead to significant storage problems. A deep hashing network is proposed in which images are mapped into compact binary codes. There are three key components: (i) a sub-network with multiple convolution-pooling layers to capture image representations; (ii) a hashing layer to generate compact binary hash codes; (iii) an encoder module to divide the image feature vector from the output of the sub-network above into multiple branches, each encoded into one hash bit. Extensive experiments using a casting dataset show promising performance compared with the state-of-the-art approach.","","","10.1049/iet-cvi.2018.5286","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8555953","","","feature extraction;feedforward neural nets;image classification;image coding;image representation;image retrieval;materials science computing;unsupervised learning","intelligent detection technology;multidimensional visual feature vector;deep hashing network;multiple convolution-pooling layers;image representations;compact binary hash codes;image feature vector;material defect image classification;nondestructive material testing technology;convolution neural networks;automatic detection technology;hashing layer;deep learning networks","","","28","","","","","IET","IET Journals"
"Automatic Generation of Workload Profiles Using Unsupervised Learning Pipelines","D. B. Prats; J. L. Berral; D. Carrera","Departament d’Arquitectura de Computadors, Universitat Politècnica de Catalunya, Barcelona, Spain; Departament d’Arquitectura de Computadors, Universitat Politècnica de Catalunya, Barcelona, Spain; Departament d’Arquitectura de Computadors, Universitat Politècnica de Catalunya, Barcelona, Spain","IEEE Transactions on Network and Service Management","","2018","15","1","142","155","The complexity of resource usage and power consumption on cloud-based applications makes the understanding of application behavior through expert examination difficult. The difficulty increases when applications are seen as “black boxes,” where only external monitoring can be retrieved. Furthermore, given the different amount of scenarios and applications, automation is required. Here, we examine and model application behavior by finding behavior phases. We use conditional restricted Boltzmann machines (CRBMs) to model time-series containing resources traces measurements like CPU, memory, and IO. CRBMs can be used to map a given historic window of trace behavior into a single vector. This low dimensional and time-aware vector can be passed through clustering methods, from simplistic ones like k-means to more complex ones like those based on hidden Markov models. We use these methods to find phases of similar behavior in the workloads. Our experimental evaluation shows that the proposed method is able to identify different phases of resource consumption across different workloads. We show that the distinct phases contain specific resource patterns that distinguish them.","","","10.1109/TNSM.2017.2786047","European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation programme; Ministry of Economy of Spain; Generalitat de Catalunya; ICREA Academia program; BSC-CNS Severo Ochoa program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8240924","Unsupervised learning;CRBM;deep learning;workload modeling;phase detection;MapReduce","Hidden Markov models;Measurement;Telemetry;Monitoring;Memory management","Boltzmann machines;hidden Markov models;pattern clustering;power aware computing;power consumption;time series;unsupervised learning","resource patterns;unsupervised learning pipelines;workload profiles;automatic generation;specific resource patterns;resource consumption;hidden Markov models;clustering methods;low dimensional time-aware vector;trace behavior;time-series containing resources;CRBMs;conditional restricted Boltzmann machines;behavior phases;model application behavior;external monitoring;black boxes;expert examination;power consumption;resource usage","","","38","CCBY","","","","IEEE","IEEE Journals"
"Compensating Delays and Noises in Motion Control of Autonomous Electric Vehicles by Using Deep Learning and Unscented Kalman Predictor","Y. Li; G. Yin; W. Zhuang; N. Zhang; J. Wang; K. Geng","School of Mechanical Engineering, Southeast University, Nanjing 211189, China. He is now with the Department of Mechanical Engineering, City College of New York, New York, NY 10031 USA.; School of Mechanical Engineering, Southeast University, Nanjing 211189, China (e-mail: ygd@seu.edu.cn).; School of Mechanical Engineering, Southeast University, Nanjing 211189, China.; School of Mechanical Engineering, Southeast University, Nanjing 211189, China.; School of Mechanical Engineering, Southeast University, Nanjing 211189, China.; School of Mechanical Engineering, Southeast University, Nanjing 211189, China.","IEEE Transactions on Systems, Man, and Cybernetics: Systems","","2018","PP","99","1","13","Accurate knowledge of the vehicle states is the foundation of vehicle motion control. However, in real implementations, sensory signals are always corrupted by delays and noises. Network induced time-varying delays and measurement noises can be a hazard in the active safety of over-actuated electric vehicles (EVs). In this paper, a brain-inspired proprioceptive system based on state-of-the-art deep learning and data fusion technique is proposed to solve this problem in autonomous four-wheel actuated EVs. A deep recurrent neural network (RNN) is trained by the noisy and delayed measurement signals to make accurate predictions of the vehicle motion states. Then unscented Kalman predictor, which is the adaption of unscented Kalman filter in time-varying-delay situations, combines the predictions of the RNN and corrupted sensory signals to provide better perceptions of the locomotion. Simulations with a high-fidelity, CarSim, full-vehicle model are carried out to show the effectiveness of our RNN framework and the entire proprioceptive system.","","","10.1109/TSMC.2018.2850367","National Natural Science Foundation of China; National Key Research and Development Program in China; Six Talent Peaks Project in Jiangsu Province; Qing Lan Project and the Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8411139","Deep learning (DL);four-wheel independently actuated (FWIA) autonomous electric vehicles;network-induced delays;recurrent neural networks (RNNs);unscented Kalman predictor (UKP)","Delays;Recurrent neural networks;Kalman filters;Brain modeling;Vehicle dynamics;Computational modeling;Electric vehicles","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Gating Neural Network for Large Vocabulary Audiovisual Speech Recognition","F. Tao; C. Busso","Department of Electrical and Computer Engineering, The University of Texas at Dallas, Richardson, TX, USA; Department of Electrical and Computer Engineering, The University of Texas at Dallas, Richardson, TX, USA","IEEE/ACM Transactions on Audio, Speech, and Language Processing","","2018","26","7","1290","1302","Audio-based automatic speech recognition (A-ASR) systems are affected by noisy conditions in real-world applications. Adding visual cues to the ASR system is an appealing alternative to improve the robustness of the system, replicating the audiovisual perception process used during human interactions. A common problem observed when using audiovisual automatic speech recognition (AV-ASR) is the drop in performance when speech is clean. In this case, visual features may not provide complementary information, introducing variability that negatively affects the performance of the system. The experimental evaluation in this study clearly demonstrates this problem when we train an audiovisual state-of-the-art hybrid system with a deep neural network (DNN) and hidden Markov models (HMMs). This study proposes a framework that addresses this problem, improving, or at least, maintaining the performance when visual features are used. The proposed approach is a deep learning solution with a gating layer that diminishes the effect of noisy or uninformative visual features, keeping only useful information. The framework is implemented with a subset of the audiovisual CRSS-4ENGLISH-14 corpus which consists of 61 h of speech from 105 subjects simultaneously collected with multiple cameras and microphones. The proposed framework is compared with conventional HMMs with observation models implemented with either a Gaussian mixture model or DNNs. We also compare the system with a multi-stream HMM system. The experimental evaluation indicates that the proposed framework outperforms alternative methods under all configurations, showing the robustness of the gating-based framework for AV-ASR.","","","10.1109/TASLP.2018.2815268","National Science Foundation CAREER; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8314740","Audiovisual large vocabulary automatic speech recognition;Multimodal deep learning;speech recognition","Hidden Markov models;Speech;Visualization;Feature extraction;Speech recognition;Noise measurement;Machine learning","audio-visual systems;Gaussian processes;hidden Markov models;learning (artificial intelligence);neural nets;speech recognition;vocabulary","gating neural network;vocabulary audiovisual speech recognition;noisy conditions;real-world applications;visual cues;audiovisual perception process;human interactions;audiovisual automatic speech recognition;AV-ASR;complementary information;deep learning solution;gating layer;noisy features;uninformative visual features;audiovisual CRSS-4ENGLISH-14 corpus;observation models;multistream HMM system;hybrid system","","4","61","","","","","IEEE","IEEE Journals"
"Learning Discrete Matrix Factorization Models","D. M. Nguyen; E. Tsiligianni; N. Deligiannis","Department of Electronics and Informatics (ETRO), Vrije Universiteit Brussel, Brussels, Belgium; Department of Electronics and Informatics (ETRO), Vrije Universiteit Brussel, Brussels, Belgium; Department of Electronics and Informatics (ETRO), Vrije Universiteit Brussel, Brussels, Belgium","IEEE Signal Processing Letters","","2018","25","5","720","724","Matrix factorization is among the most popular approaches for matrix completion, with recent advances including gradient-based and deep-learning-based methods. Even though many applications involve matrices with discrete values, most of the existing matrix factorization models focus on the continuous domain. Discretization is applied as an additional step, often using a heuristic mapping that results in sub-optimal solutions, which either do not take into account the structure of the matrix or introduce significant quantization errors. In this letter, we propose a novel method that allows gradient-based and deep-learning-based methods to jointly learn both the matrix factorization model and a discretization operator. By introducing a loss function that accounts for the reconstruction error with respect to the discrete predictions, we obtain a discrete matrix completion algorithm with high reconstruction accuracy. Experiments using well-known datasets show the improvement obtained by the proposed algorithm over the state of the art.","","","10.1109/LSP.2018.2823268","Fonds Wetenschappelijk Onderzoek; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8331131","Big data;continuous approximation;deep neural networks;matrix factorization","Quantization (signal);Signal processing algorithms;Optimization;Training;Big Data;Prediction algorithms;Matrix converters","gradient methods;learning (artificial intelligence);matrix decomposition;optimisation","discretization operator;discrete predictions;discrete matrix completion algorithm;discrete matrix factorization models;discrete values;continuous domain;quantization errors;loss function;reconstruction error;high reconstruction accuracy;deep-learning-based methods;gradient-based methods","","1","41","","","","","IEEE","IEEE Journals"
"A Novel 1-D Convolution Neural Network With SVM Architecture for Real-Time Detection Applications","S. Lekha; M. Suchetha","School of Electronics Engineering, Vellore Institute of Technology, Chennai, India; School of Electronics Engineering, Vellore Institute of Technology, Chennai, India","IEEE Sensors Journal","","2018","18","2","724","731","To enhance the performance and sensitivity of continuous monitoring systems for detection of chronic diseases, selection of optimal machine learning algorithms is pivotal. Presently, the commonly used algorithms face constraints, such as high computational cost and lack of optimal feature selection on application to real time signals thereby reducing the efficiency of such analysis. Deep learning approaches, such as the convolution neural network, overcome these drawbacks by calculating automated features from raw signal and classifying the derived features. This architecture shows good merits. However, the use of fully connected multi-layer perceptron algorithms have shown low classification performance. This paper proposes to develop a modified deep learning convolution neural network algorithm integrated with support vector machines to address the drawbacks present in multi-layer perceptron and thereby improving the overall performance of real-time detection applications. The system is validated on real-time breath signals for non-invasive detection of diabetes. The performance of this proposed algorithm is evaluated and compared with the existing technique.","","","10.1109/JSEN.2017.2780178","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8166741","Deep learning algorithm;multi-layer perceptron;support vector machines;detection systems;diabetes","Support vector machines;Feature extraction;Neural networks;Convolution;Computer architecture;Algorithm design and analysis;Sensors","diseases;feature extraction;image classification;image recognition;learning (artificial intelligence);medical image processing;multilayer perceptrons;pneumodynamics;support vector machines","SVM architecture;real-time detection applications;continuous monitoring systems;optimal feature selection;time signals;automated features;raw signal;multilayer perceptron algorithms;modified deep learning convolution neural network algorithm;support vector machines;real-time breath signals;noninvasive detection;1-d convolution neural network;chronic diseases detection;optimal machine learning algorithms;derived feature classification","","5","32","","","","","IEEE","IEEE Journals"
"A Variation-Tolerant In-Memory Machine Learning Classifier via On-Chip Training","S. K. Gonugondla; M. Kang; N. R. Shanbhag","Department of Electrical and Computer Engineering, University of Illinois at Urbana–Champaign, Urbana, IL, USA; IBM Thomas J. Watson Research Center, Yorktown Heights, NY, USA; Department of Electrical and Computer Engineering, University of Illinois at Urbana–Champaign, Urbana, IL, USA","IEEE Journal of Solid-State Circuits","","2018","53","11","3163","3173","This paper presents a robust deep in-memory machine learning classifier with a stochastic gradient descent (SGD)-based on-chip trainer using a standard 16-kB 6T SRAM array. The deep in-memory architecture (DIMA) enhances both energy efficiency and throughput over conventional digital architectures by reading multiple bits per bit line (BL) per read cycle and by employing mixed-signal processing in the periphery of the bit-cell array. Though these techniques improve the energy efficiency and latency, DIMA's analog nature makes it sensitive to process, voltage, and temperature (PVT) variations, especially under reduced BL swings. On-chip training enables DIMA to adapt to chip-specific variations in PVT as well as data statistics, thereby further enhancing its energy efficiency. The 65-nm CMOS prototype IC demonstrates this improvement by realizing an on-chip trainable support vector machine. By learning chipspecific weights, on-chip training enables robust operation under reduced BL swing leading to a 2.4 times reduction in energy over an off-chip trained DIMA. The prototype IC in 65-nm CMOS consumes 42 pJ/decision at 32 M decisions/s, corresponding to 3.12 TOPS/W (1 OP = one 8-b × 8-b MAC) during inference, thereby achieving a reduction of 21 times in energy and 100 times in energy-delay product as compared with a conventional digital architecture. The energy overhead of training is <;26% per decision for SGD batch sizes of 128 and higher.","","","10.1109/JSSC.2018.2867275","Systems On Nanoscale Information fabriCs (SONIC), one of the six SRC STARnet Centers, sponsored by MARCO and DARPA; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8463601","Always-on;inference;in-memory;machine learning (ML);mixed signal;on-chip learning;process variations;stochastic gradient descent (SGD)","Computer architecture;System-on-chip;Training;Support vector machines;Random access memory;Prototypes","CMOS memory circuits;gradient methods;integrated circuit design;learning (artificial intelligence);low-power electronics;memory architecture;mixed analogue-digital integrated circuits;pattern classification;SRAM chips;stochastic processes;support vector machines","process, voltage, and temperature variations;multiple bits per bit line;6T SRAM array;variation-tolerant in-memory machine classifier;DIMA analog nature;CMOS prototype IC;data statistics;deep in-memory architecture;chip-specific variations;reduced BL swing;temperature variations;bit-cell array;mixed-signal processing;read cycle;conventional digital architecture;energy efficiency;stochastic gradient descent-based on-chip trainer;on-chip training;energy-delay product;off-chip trained DIMA;on-chip trainable support vector machine;size 65 nm;OP","","8","27","","","","","IEEE","IEEE Journals"
"DesnowNet: Context-Aware Deep Network for Snow Removal","Y. Liu; D. Jaw; S. Huang; J. Hwang","Alibaba DAMO Academy, Hangzhou, China; Department of Electronic Engineering, National Taipei University of Technology, Taipei, Taiwan; Department of Electronic Engineering, National Taipei University of Technology, Taipei, Taiwan; Department of Electrical Engineering, University of Washington, Seattle, WA, USA","IEEE Transactions on Image Processing","","2018","27","6","3064","3073","Existing learning-based atmospheric particle-removal approaches such as those used for rainy and hazy images are designed with strong assumptions regarding spatial frequency, trajectory, and translucency. However, the removal of snow particles is more complicated because they possess additional attributes of particle size and shape, and these attributes may vary within a single image. Currently, hand-crafted features are still the mainstream for snow removal, making significant generalization difficult to achieve. In response, we have designed a multistage network named DesnowNet to in turn deal with the removal of translucent and opaque snow particles. We also differentiate snow attributes of translucency and chromatic aberration for accurate estimation. Moreover, our approach individually estimates residual complements of the snow-free images to recover details obscured by opaque snow. Additionally, a multi-scale design is utilized throughout the entire network to model the diversity of snow. As demonstrated in the qualitative and quantitative experiments, our approach outperforms state-of-the-art learning-based atmospheric phenomena removal methods and one semantic segmentation baseline on the proposed Snow100K dataset. The results indicate our network would benefit applications involving computer vision and graphics.","","","10.1109/TIP.2018.2806202","Ministry of Science and Technology of the Republic of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8291596","Snow removal;deep learning;convolutional neural networks;image enhancement;image restoration","Snow;Rain;Feature extraction;Image color analysis;Shape;Atmospheric modeling;Image restoration","image segmentation;learning (artificial intelligence);snow","DesnowNet;context-aware deep network;snow removal;hazy images;spatial frequency;snow particles;particle size;hand-crafted features;multistage network;opaque snow;snow-free images;atmospheric phenomena removal methods;Snow100K dataset;snow attributes;atmospheric particle-removal approach;chromatic aberration;semantic segmentation baseline;computer vision","","8","39","","","","","IEEE","IEEE Journals"
"Beyond Knowledge Distillation: Collaborative Learning for Bidirectional Model Assistance","J. Wang; W. Wang; W. Gao","School of Electronic and Computer Engineering, Peking University, Shenzhen, China; School of Electronic and Computer Engineering, Peking University, Shenzhen, China; School of Electronic Engineering and Computer Science, Peking University, Beijing, China","IEEE Access","","2018","6","","39490","39500","Knowledge distillation (KD) is a powerful technique that enables a well-trained large model to assist a small model. However, KD is constrained in a teacher-student manner. Thus, this method may not be appropriate in general situations, where the learning abilities of two models are uncertain or not significantly different. In this paper, we propose a collaborative learning (CL) method, which is a flexible strategy to achieve bidirectional model assistance for two models using a mutual knowledge base (MKB). The MKB is used to collect mutual information and provide assistance, and it is updated along with the learning process of the two models and separately deployed when converged. We show that CL can be applied to any two deep neural networks and is easily extended to multiple networks. Compared with the teacher-student framework, CL can achieve bidirectional assistance and does not impose specific requirements on the involved models, such as pretraining and different abilities. The experimental results demonstrate that CL can efficiently improve the learning ability and convergence speed of the two models, with superior performance to a series of relevant methods, such as ensemble learning and a series of KD-based methods. More importantly, we show that the state-of-the-art models, such as DenseNet, can be greatly improved using CL along with other popular models.","","","10.1109/ACCESS.2018.2854918","Shenzhen Peacock Plan; Shenzhen Key Laboratory for Intelligent Multimedia and Virtual Reality; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409945","Bidirectional model assistance;collaborative learning;deep neural networks;mutual knowledge base","Collaborative work;Adaptation models;Neural networks;Training;Task analysis;Computational modeling;Knowledge engineering","computer aided instruction","knowledge distillation;bidirectional model assistance;teacher-student manner;learning ability;collaborative learning method;CL;mutual knowledge base;MKB;teacher-student framework;ensemble learning;KD-based methods","","","55","","","","","IEEE","IEEE Journals"
"Multi-instance multi-label learning of natural scene images: via sparse coding and multi-layer neural network","H. Zhang; W. Wu; D. Wang","School of Information Engineering, Wuhan University of Science and Technology, People's Republic of China; School of Information Engineering, Wuhan University of Science and Technology, People's Republic of China; School of Information Engineering, Wuhan University of Science and Technology, People's Republic of China","IET Computer Vision","","2018","12","3","305","311","The classification of natural scene images is multi-instance multi-label (MIML) for many labels that exist in a natural scene image. The traditional method of solving MIML is to degenerate it into single-instance single-label learning (SISL). However, the precision of the method could decrease due to information loss during the degeneration process. How to reasonably solve the MIML problem is key to obtaining high accuracy in this research area. An MIML algorithm based on instances via combining sparse coding with a deep neural network is proposed. First, an instance-based sparse representation with dictionary learning is adopted. Second, an MIML description model based on a deep network is proposed, which can realise parameter self-learning in combination with sparse representations. Third, the residuals of the sparse representation are introduced to the deep neural network. The results of the experiments show that the method outperforms a number of state-of-the-art approaches.","","","10.1049/iet-cvi.2016.0338","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8319338","","","image coding;image representation;learning (artificial intelligence);multilayer perceptrons","multiinstance multilabel learning;natural scene images;sparse coding;multilayer neural network;MIML algorithm;information loss;degeneration process;deep neural network;instance-based sparse representation;dictionary learning;MIML description model;parameter self-learning","","1","53","","","","","IET","IET Journals"
"Adaptive Deep Learning-Based Air Quality Prediction Model Using the Most Relevant Spatial-Temporal Relations","P. Soh; J. Chang; J. Huang","Institute of Computer and Communication Engineering, National Cheng Kung University, Tainan, Taiwan; Department of Electrical Engineering, National Cheng Kung University, Tainan, Taiwan; Department of Electrical Engineering, National Cheng Kung University, Tainan, Taiwan","IEEE Access","","2018","6","","38186","38199","Air pollution has become an extremely serious problem, with particulate matter having a significantly greater impact on human health than other contaminants. The small diameter of fine particulate matter (PM2.5) allows it to penetrate deep into the alveoli as far as the bronchioles, interfering with a gas exchange within the lungs. Long-term exposure to particulate matter has been shown to cause the cardiovascular disease, respiratory disease, and increase the risk of lung cancers. Therefore, forecasting air quality has also become important to help guide individual actions. This paper aims to forecast air quality for up to 48 h using a combination of multiple neural networks, including an artificial neural network, a convolutional neural network, and a long-short-term memory to extract spatial-temporal relations. The proposed predictive model considers various meteorology data from the previous few hours as well as information related to the elevation space to extract terrain impact on air quality. The model includes trends from multiple locations, extracted from correlations between adjacent locations, and among similar locations in the temporal domain. Experiments employing Taiwan and Beijing data sets show that the proposed model achieves excellent performance and outperforms current state-of-the-art methods.","","","10.1109/ACCESS.2018.2849820","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8392677","Dynamic time warping(DTW);convolutional neural network(CNN);long-short-term memory(LSTM);spatio-temporal analysis;big data;air quality forecast","Air quality;Atmospheric modeling;Predictive models;Neural networks;Wind forecasting;Lung;Data mining","air pollution;air quality;environmental science computing;feedforward neural nets;learning (artificial intelligence)","adaptive deep learning;meteorology data;Beijing data set;Taiwan data set;air quality prediction model;predictive model;spatial-temporal relations;long-short-term memory;convolutional neural network;artificial neural network;lung cancers;respiratory disease;cardiovascular disease;fine particulate matter;air pollution","","5","35","","","","","IEEE","IEEE Journals"
"Fully Connected Network-Based Intra Prediction for Image Coding","J. Li; B. Li; J. Xu; R. Xiong; W. Gao","Institute of Digital Media, School of Electronic Engineering and Computer Science, Peking University, Beijing, China; Microsoft Research Asia, Beijing, China; Microsoft Research Asia, Beijing, China; Institute of Digital Media, School of Electronic Engineering and Computer Science, Peking University, Beijing, China; Institute of Digital Media, School of Electronic Engineering and Computer Science, Peking University, Beijing, China","IEEE Transactions on Image Processing","","2018","27","7","3236","3247","This paper proposes a deep learning method for intra prediction. Different from traditional methods utilizing some fixed rules, we propose using a fully connected network to learn an end-to-end mapping from neighboring reconstructed pixels to the current block. In the proposed method, the network is fed by multiple reference lines. Compared with traditional single line-based methods, more contextual information of the current block is utilized. For this reason, the proposed network has the potential to generate better prediction. In addition, the proposed network has good generalization ability on different bitrate settings. The model trained from a specified bitrate setting also works well on other bitrate settings. Experimental results demonstrate the effectiveness of the proposed method. When compared with high efficiency video coding reference software HM-16.9, our network can achieve an average of 3.4% bitrate saving. In particular, the average result of 4K sequences is 4.5% bitrate saving, where the maximum one is 7.4%.","","","10.1109/TIP.2018.2817044","National Basic Research Program of China; National Key Research and Development Program of China; National Natural Science Foundation of China; Beijing Natural Science Foundation; Cooperative Medianet Innovation Center; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8319436","HEVC;image coding;intra prediction;deep learning;fully connected network","Image coding;Bit rate;Machine learning;Encoding;Transform coding;Image reconstruction;Software","graph theory;image coding;image reconstruction;image sequences;learning (artificial intelligence);network theory (graphs);prediction theory","fully connected network;image coding;deep learning method;end-to-end mapping;current block;multiple reference lines;intraprediction;pixels reconstruction;bitrate settings;4K sequences","","13","46","","","","","IEEE","IEEE Journals"
"Locomotion Activity Recognition Using Stacked Denoising Autoencoders","F. Gu; K. Khoshelham; S. Valaee; J. Shang; R. Zhang","Department of Infrastructure Engineering, University of Melbourne, Parkville, VIC, Australia; Department of Infrastructure Engineering, University of Melbourne, Parkville, VIC, Australia; Department of Electrical and Computer Engineering, University of Toronto, Toronto, Canada; Faculty of Information Engineering, China University of Geosciences and the National Engineering Research Center for Geographic Information System, Wuhan, China; Department of Computing Information Systems, University of Melbourne, Parkville, VIC, Australia","IEEE Internet of Things Journal","","2018","5","3","2085","2093","Locomotion activity recognition (LAR) is important for a number of applications, such as indoor localization, fitness tracking, and aged care. Existing methods usually use handcrafted features, which requires expert knowledge and is laborious, and the achieved result might still be suboptimal. To relieve the burden of designing and selecting features, we propose a deep learning method for LAR by using data from multiple sensors available on most smart devices. Experimental results show that the proposed method, which learns useful features automatically, outperforms conventional classifiers that require the hand-engineering of features. We also show that the combination of sensor data from four sensors (accelerometer, gyroscope, magnetometer, and barometer) achieves a higher accuracy than other combinations or individual sensors.","","","10.1109/JIOT.2018.2823084","National Natural Science Foundation of China; China Scholarship Council—University of Melbourne Research Scholarship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8331081","Activity recognition;autoencoder;deep learning;motion state recognition;neural network;smartphone sensor","Feature extraction;Activity recognition;Magnetic sensors;Intelligent sensors;Machine learning;Accelerometers","accelerometers;feature extraction;feature selection;gyroscopes;image denoising;learning (artificial intelligence);sensors","sensor data;locomotion activity recognition;LAR;indoor localization;fitness tracking;aged care;handcrafted features;expert knowledge;deep learning method;multiple sensors;selecting features;stacked denoising autoencoders;smart devices;hand-engineering;accelerometer;gyroscope;magnetometer;barometer","","2","47","","","","","IEEE","IEEE Journals"
"Visual Representation and Classification by Learning Group Sparse Deep Stacking Network","J. Li; H. Chang; J. Yang; W. Luo; Y. Fu","Department of Electrical and Computer Engineering, Northeastern University, Boston, MA, USA; School of Computer Science and Technology, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Technology, Nanjing University of Science and Technology, Nanjing, China; College of Mathematics and Informatics, South China Agricultural University, Guangzhou, China; Department of Electrical and Computer Engineering, Northeastern University, Boston, MA, USA","IEEE Transactions on Image Processing","","2018","27","1","464","476","Deep stacking networks (DSNs) have been successfully applied in classification tasks. Its architecture builds upon blocks of simplified neural network modules (SNNM). The hidden units are assumed to be independent in the SNNM module. However, this assumption prevents SNNM from learning the local dependencies between hidden units to better capture the information in the input data for the classification task. In addition, the hidden representations of input data in each class can be expectantly split into a group in real-world classification applications. Therefore, we propose two kinds of group sparse SNNM modules by mixing  $l_{1}$ -norm and  $l_{2}$ -norm. The first module learns the local dependencies among hidden units by dividing them into non-overlapping groups. The second module splits the representations of samples in different classes into separate groups to cluster the samples in each class. A group sparse DSN (GS-DSN) is constructed by stacking the group sparse SNNM modules. Experimental results further verify that our GS-DSN model outperforms the relevant classification methods. Particularly, GS-DSN achieves the state-of-the-art performance (99.1%) on 15-Scene.","","","10.1109/TIP.2017.2765833","National Science Foundation of USA, IIS award; National Science Foundation of China; National Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8080266","Deep learning;stacking network;sparse representation;image classification","Stacking;Training;Biological neural networks;Dictionaries;Encoding","","","","3","60","","","","","IEEE","IEEE Journals"
"Disc-Aware Ensemble Network for Glaucoma Screening From Fundus Image","H. Fu; J. Cheng; Y. Xu; C. Zhang; D. W. K. Wong; J. Liu; X. Cao","Agency for Science, Technology and Research, Institute for Infocomm Research, Singapore; Chinese Academy of Sciences, Cixi Institute of Biomedical Engineering, Ningbo, China; CVTE Research, Guangzhou Shiyuan Electronics Co., Ltd., Guangzhou, China; School of Computer Science and Technology, Tianjin University, Tianjin, China; Agency for Science, Technology and Research, Institute for Infocomm Research, Singapore; Chinese Academy of Sciences, Cixi Institute of Biomedical Engineering, Ningbo, China; State Key Laboratory of Information Security, Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Medical Imaging","","2018","37","11","2493","2501","Glaucoma is a chronic eye disease that leads to irreversible vision loss. Most of the existing automatic screening methods first segment the main structure and subsequently calculate the clinical measurement for the detection and screening of glaucoma. However, these measurement-based methods rely heavily on the segmentation accuracy and ignore various visual features. In this paper, we introduce a deep learning technique to gain additional image-relevant information and screen glaucoma from the fundus image directly. Specifically, a novel disc-aware ensemble network for automatic glaucoma screening is proposed, which integrates the deep hierarchical context of the global fundus image and the local optic disc region. Four deep streams on different levels and modules are, respectively, considered as global image stream, segmentation-guided network, local disc region stream, and disc polar transformation stream. Finally, the output probabilities of different streams are fused as the final screening result. The experiments on two glaucoma data sets (SCES and new SINDI data sets) show that our method outperforms other state-of-the-art algorithms.","","","10.1109/TMI.2018.2837012","National Key Research and Development Plan; Ningbo 3315 Innovation Team; National Natural Science Foundation of China; Chinese Academy of Sciences; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8359118","Deep learning;glaucoma screening;optic disc segmentation;neural network","Streaming media;Image segmentation;Optical imaging;Biomedical optical imaging;Visualization;Optical fiber networks;Feature extraction","diseases;eye;feature extraction;image segmentation;learning (artificial intelligence);medical image processing;probability;vision defects","chronic eye disease;clinical measurement;deep learning technique;automatic glaucoma screening;deep hierarchical context;global fundus image;local optic disc region;global image stream;segmentation-guided network;local disc region stream;disc polar transformation stream;final screening result;vision loss;disc-aware ensemble network;image-relevant information;output probabilities","","6","33","","","","","IEEE","IEEE Journals"
"Indoor Relocalization in Challenging Environments With Dual-Stream Convolutional Neural Networks","R. Li; Q. Liu; J. Gui; D. Gu; H. Hu","Department of Computer Science and Electronic Engineering, University of Essex, Colchester, U.K.; Department of Computer Science and Electronic Engineering, University of Essex, Colchester, U.K.; Department of Computer Science and Electronic Engineering, University of Essex, Colchester, U.K.; Department of Computer Science and Electronic Engineering, University of Essex, Colchester, U.K.; Department of Computer Science and Electronic Engineering, University of Essex, Colchester, U.K.","IEEE Transactions on Automation Science and Engineering","","2018","15","2","651","662","This paper presents an indoor relocalization system using a dual-stream convolutional neural network (CNN) with both color images and depth images as the network inputs. Aiming at the pose regression problem, a deep neural network architecture for RGB-D images is introduced, a training method by stages for the dual-stream CNN is presented, different depth image encoding methods are discussed, and a novel encoding method is proposed. By introducing the range information into the network through a dual-stream architecture, we not only improved the relocalization accuracy by about 20% compared with the state-of-the-art deep learning method for pose regression, but also greatly enhanced the system robustness in challenging scenes such as large-scale, dynamic, fast movement, and night-time environments. To the best of our knowledge, this is the first work to solve the indoor relocalization problems based on deep CNNs with RGB-D camera. The method is first evaluated on the Microsoft 7-Scenes data set to show its advantage in accuracy compared with other CNNs. Large-scale indoor relocalization is further presented using our method. The experimental results show that 0.3 m in position and 4° in orientation accuracy could be obtained. Finally, this method is evaluated on challenging indoor data sets collected from motion capture system. The results show that the relocalization performance is hardly affected by dynamic objects, motion blur, or night-time environments.","","","10.1109/TASE.2017.2664920","China Scholarship Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7869254","Convolutional neural network (CNN);deep learning;depth encoding;pose regression;relocalization","Feature extraction;Image coding;Cameras;Robustness;Image color analysis;Neural networks;Color","convolution;feedforward neural nets;image coding;image colour analysis;image motion analysis;learning (artificial intelligence);regression analysis","dual-stream convolutional neural network;color images;depth images;pose regression problem;deep neural network architecture;RGB-D images;dual-stream CNN;dual-stream architecture;deep learning method;indoor relocalization problems;large-scale indoor relocalization;image encoding methods","","7","36","","","","","IEEE","IEEE Journals"
"Paired Recurrent Autoencoders for Bidirectional Translation Between Robot Actions and Linguistic Descriptions","T. Yamada; H. Matsunaga; T. Ogata","Department of Intermedia Art and Science, Waseda University, Tokyo, Japan; Department of Intermedia Art and Science, Waseda University, Tokyo, Japan; Department of Intermedia Art and Science, Waseda University, Tokyo, Japan","IEEE Robotics and Automation Letters","","2018","3","4","3441","3448","We propose a novel deep learning framework for bidirectional translation between robot actions and their linguistic descriptions. Our model consists of two recurrent autoencoders (RAEs). One RAE learns to encode action sequences as fixed-dimensional vectors in a way that allows the sequences to be reproduced from the vectors by its decoder. The other RAE learns to encode descriptions in a similar way. In the learning process, in addition to reproduction losses, we create another loss function whereby the representations of an action and its corresponding description approach each other in the latent vector space. Across the shared representation, the trained model can produce a linguistic description given a robot action. The model is also able to generate an appropriate action by receiving a linguistic instruction, conditioned on the current visual input. Visualization of the latent representations shows that the robot actions are embedded in a semantically compositional way in the vector space by being learned jointly with descriptions.","","","10.1109/LRA.2018.2852838","Japan Society for the Promotion of Science (JSPS); JST CREST; Ministry of Education, Culture, Sports, Science and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8403309","Deep learning in robotics and automation;AI-based methods;neurorobotics","Robots;Linguistics;Decoding;Visualization;Feature extraction;Image reconstruction;Training","data visualisation;language translation;learning (artificial intelligence);linguistics;robots;vectors","robot action;linguistic description;RAE;action sequences;fixed-dimensional vectors;learning process;latent vector space;linguistic instruction;paired recurrent autoencoders;bidirectional translation;deep learning framework;latent representation visualization","","1","34","","","","","IEEE","IEEE Journals"
"Trading-Off Accuracy and Energy of Deep Inference on Embedded Systems: A Co-Design Approach","N. K. Jayakodi; A. Chatterjee; W. Choi; J. R. Doppa; P. P. Pande","NA; NA; NA; NA; NA","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","","2018","37","11","2881","2893","Deep neural networks have seen tremendous success for different modalities of data including images, videos, and speech. This success has led to their deployment in mobile and embedded systems for real-time applications. However, making repeated inferences using deep networks on embedded systems poses significant challenges due to constrained resources (e.g., energy and computing power). To address these challenges, we develop a principled co-design approach. Building on prior work, we develop a formalism referred as coarse-to-fine networks (C2F Nets) that allow us to employ classifiers of varying complexity to make predictions. We propose a principled optimization algorithm to automatically configure C2F Nets for a specified tradeoff between accuracy and energy consumption for inference. The key idea is to select a classifier on-the-fly whose complexity is proportional to the hardness of the input example: simple classifiers for easy inputs and complex classifiers for hard inputs. We perform comprehensive experimental evaluation using four different C2F Net architectures on multiple real-world image classification tasks. Our results show that optimized C2F Net can reduce the energy delay product by 27% to 60% with no loss in accuracy when compared to the baseline solution, where all predictions are made using the most complex classifier in C2F Net.","","","10.1109/TCAD.2018.2857338","National Science Foundation; Army Research Office; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8412559","Approximate computing;Bayesian optimization (BO);deep neural networks (DNNs);embedded systems;hardware and software co-design;inference","Hardware;Optimization;Computer architecture;Computational modeling;Software;Convolution;Task analysis","embedded systems;image classification;inference mechanisms;learning (artificial intelligence);neural nets;optimisation","simple classifiers;complex classifier;energy delay product;deep inference;embedded systems;deep neural networks;principled co-design approach;coarse-to-fine networks;principled optimization algorithm;energy consumption;real-world image classification;C2F net architectures","","1","36","","","","","IEEE","IEEE Journals"
"Anomalous Sound Detection Using Deep Audio Representation and a BLSTM Network for Audio Surveillance of Roads","Y. Li; X. Li; Y. Zhang; M. Liu; W. Wang","School of Electronic and Information Engineering, South China University of Technology, Guangzhou, China; School of Electronic and Information Engineering, South China University of Technology, Guangzhou, China; School of Electronic and Information Engineering, South China University of Technology, Guangzhou, China; School of Electronic and Information Engineering, South China University of Technology, Guangzhou, China; School of Electronic and Information Engineering, South China University of Technology, Guangzhou, China","IEEE Access","","2018","6","","58043","58055","Surveillance systems based on image analysis can automatically detect road accidents to ensure a quick intervention by rescue teams. However, in some situations, the visual information is insufficiently reliable, whereas the use of a sound detector can greatly improve the overall reliability of the surveillance system. In this paper, we focus on detecting two classes of anomalous sounds for audio surveillance on roads, i.e., tire skidding and car crash, whose occurrences are an evidently acoustic indication of road accidents or disruptions. In the proposed method, we extract a feature of deep audio representation (DAR) and then use a classifier of a bidirectional long short-term memory network to determine the class of the sound to which each test audio segment belongs. We propose a framework based on multiple-stage deep autoencoder network (DAN) to extract the DAR, which fuses complementary information from several input features and thus can be more discriminative and robust than those input features. In the experiments, we discuss the influences of the parameter settings of the DAN's hidden layers on the performance of DAR and compare the DAR with other features. Furthermore, the proposed method is compared to the state-of-the-art methods. In evaluating the data with various signal-to-noise ratios, the results show that the DAR outperforms other features, and the proposed method is superior to the state-of-the-art methods for detecting anomalous sounds on roads.","","","10.1109/ACCESS.2018.2872931","National Natural Science Foundation of China; National Laboratory of Pattern Recognition; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8478265","Deep audio representation;bidirectional long short-term memory network;accident detection;audio surveillance","Feature extraction;Roads;Surveillance;Support vector machines;Accidents;Mel frequency cepstral coefficient","acoustic signal processing;audio signal processing;image classification;image segmentation;learning (artificial intelligence);object detection;recurrent neural nets;road accidents;road safety;speech processing;surveillance;traffic engineering computing;video signal processing","anomalous sound detection;deep audio representation;BLSTM network;audio surveillance;roads;surveillance system;image analysis;road accidents;visual information;sound detector;tire skidding;car crash;DAR;multiple-stage deep autoencoder network;bidirectional long short-term memory network","","1","63","","","","","IEEE","IEEE Journals"
"On The Expressive Power of Scientific Manuscripts","G. S. Mahalakshmi; R. Siva; S. Sendhilkumar","Department of Computer Science and Engineering, Anna University Chennai, 29817 Chennai, Tamil Nadu India 600025 (e-mail: thamizhini@gmail.com); Department of Computer Science and Engineering, KCG College of Technology, 304308 Chennai, Tamil Nadu India (e-mail: sivavb6@gmail.com); Department of Information Science and Technology, Anna University Chennai, 29817 Chennai, Tamil Nadu India (e-mail: sskumar2k@gmail.com)","IEEE Transactions on Emerging Topics in Computing","","2018","PP","99","1","1","Every research manuscript is appreciated in the form of citations. Citations are expected to carry the essence of the underlying base paper by some rhetorical means. However, this is not true in reality. Citation manipulations are equally possible which shall be identified using research semantics. This paper discusses machine learning based approaches for analyzing research citations with the aim of finding quality research citations. On analyzing the semantics of the research manuscript and the respective citations, this paper proposes various metrics for citation quality analysis including deep cite, raw expressive power, expressive power and normalized expressive power.","","","10.1109/TETC.2018.2870179","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8466913","Citation Analysis;Semantic Analysis;Citation Quality;Machine Learning;Text mining;Availability Index;Article Metrics;Deep Learning;Expressive Power","Machine learning;Bibliometrics;Semantics;Text mining;Measurement;Indexes;Analytical models","","","","2","","","","","","IEEE","IEEE Early Access Articles"
"Deep learning features for robust facial kinship verification","A. Tidjani; A. Taleb-Ahmed; D. Samai; A. Kamal Eddine","Univ Ouargla, Algeria; University of Valenciennes, France; Univ Ouargla, Algeria; Univ Ouargla, Algeria","IET Image Processing","","2018","12","12","2336","2345","Facial automatic kinship verification is a novel challenging research problem in computer vision. It performs the automatic examining of the facial attributes and expecting whether two persons have a biological kin relation or not. In this study, the authors introduce a novel learning method for kinship verification which consists of four main stages. (i) A discrete cosine transform network (DCTNet) applied to each face image in order to extract the most significant inherited facial features through convolutional layers based on 2D DCT filter bank. (ii) The response of the last layer is binarised and partitioned into non-overlapping block-wise histograms. (iii) A tied rank normalisation is used to eliminate the disparity of histogram vectors of DCTNet. (iv) The last stage is to distinguish between the different pairs. The distances between data points in the same classes (positive pairs) are as small as possible, while the distances are as large as possible between data points in different classes (negative pairs). Experiments are conducted on three public databases (UBKinFace, KinFaceW-I, and KinFaceW-II). They show significant performance improvements compared to state-of-the-art methods.","","","10.1049/iet-ipr.2018.5552","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8556293","","","channel bank filters;discrete cosine transforms;feature extraction;image filtering;learning (artificial intelligence);vectors","UBKinFace database;KinFaceW-I database;KinFaceW-II database;histogram vector diparity elimination;nonoverlapping blockwise histograms;feature extraction;discrete cosine transform network;deep learning method;computer vision;facial automatic kinship verification;robust facial kinship verification;tied rank normalisation;2D DCT filter bank;convolutional layers;DCTNet;biological kin relation","","1","","","","","","IET","IET Journals"
"Deep Learning Based NLOS Identification With Commodity WLAN Devices","J. Choi; W. Lee; J. Lee; J. Lee; S. Kim","Intel Labs, Intel Corporation, Santa Clara, CA, USA; Advanced Standard and Development Laboratory, LG Electronics, Seoul, South Korea; Department of Electrical Engineering, Seoul National University, Seoul, South Korea; Department of Electrical Engineering, Gachon University, Seongnam, South Korea; Department of Electrical Engineering, Seoul National University, Seoul, South Korea","IEEE Transactions on Vehicular Technology","","2018","67","4","3295","3303","Identifying line-of-sight (LOS) and non-LOS channel conditions can improve the performance of many wireless applications, such as signal strength-based localization algorithms. For this purpose, channel state information (CSI) obtained by commodity IEEE 802.11n devices can be used, because it contains information about channel impulse response (CIR). However, because of the limited sampling rate of the devices, a high-resolution CIR is not available, and it is difficult to detect the existence of an LOS path from a single CSI measurement, but it can be inferred from the variation pattern of CSI over time. To this end, we propose a recurrent neural network (RNN) model, which takes a series of CSI to identify the corresponding channel condition. We collect numerous measurement data under an indoor office environment, train the proposed RNN model, and compare the performance with those of existing schemes that use handcrafted features. The proposed method efficiently learns a nonlinear relationship between input and output, and thus, yields high accuracy even for data obtained in a very short period.","","","10.1109/TVT.2017.2780121","National Research Foundation of Korea; Korean Government (MSIP); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8166758","Line-of-sight identification;indoor localization;channel state information;recurrent neural network;long short-term memory","Receivers;Transmitters;Wireless LAN;Wireless communication;Data models;Bandwidth;Recurrent neural networks","indoor radio;learning (artificial intelligence);recurrent neural nets;transient response;wireless channels;wireless LAN","NLOS identification;commodity WLAN devices;wireless applications;signal strength-based localization algorithms;channel impulse response;sampling rate;high-resolution CIR;LOS path;single CSI measurement;recurrent neural network model;RNN model;channel state information;measurement data collection;deep learning;line-of-sight channel conditions;nonLOS channel conditions;LOS channel conditions;commodity IEEE 802.11n devices;indoor office environment","","10","31","","","","","IEEE","IEEE Journals"
"Convolutional Invasion and Expansion Networks for Tumor Growth Prediction","L. Zhang; L. Lu; R. M. Summers; E. Kebebew; J. Yao","Radiology and Imaging Sciences Department, Imaging Biomarkers and Computer-Aided Diagnosis Laboratory and the Clinical Image Processing Service, National Institutes of Health Clinical Center, Bethesda, MD, USA; Radiology and Imaging Sciences Department, Imaging Biomarkers and Computer-Aided Diagnosis Laboratory and the Clinical Image Processing Service, National Institutes of Health Clinical Center, Bethesda, MD, USA; Radiology and Imaging Sciences Department, Imaging Biomarkers and Computer-Aided Diagnosis Laboratory and the Clinical Image Processing Service, National Institutes of Health Clinical Center, Bethesda, MD, USA; Endocrine Oncology Branch, National Cancer Institute, National Institutes of Health, Bethesda, MD, USA; Radiology and Imaging Sciences Department, Imaging Biomarkers and Computer-Aided Diagnosis Laboratory and the Clinical Image Processing Service, National Institutes of Health Clinical Center, Bethesda, MD, USA","IEEE Transactions on Medical Imaging","","2018","37","2","638","648","Tumor growth is associated with cell invasion and mass-effect, which are traditionally formulated by mathematical models, namely reaction-diffusion equations and biomechanics. Such models can be personalized based on clinical measurements to build the predictive models for tumor growth. In this paper, we investigate the possibility of using deep convolutional neural networks to directly represent and learn the cell invasion and mass-effect, and to predict the subsequent involvement regions of a tumor. The invasion network learns the cell invasion from information related to metabolic rate, cell density, and tumor boundary derived from multimodal imaging data. The expansion network models the mass-effect from the growing motion of tumor mass. We also study different architectures that fuse the invasion and expansion networks, in order to exploit the inherent correlations among them. Our network can easily be trained on population data and personalized to a target patient, unlike most previous mathematical modeling methods that fail to incorporate population data. Quantitative experiments on a pancreatic tumor data set show that the proposed method substantially outperforms a state-of-the-art mathematical model-based approach in both accuracy and efficiency, and that the information captured by each of the two subnetworks is complementary.","","","10.1109/TMI.2017.2774044","Intramural Research Program at the NIH Clinical Center; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8110658","Tumor growth prediction;Deep learning;Convolutional neural network;Model personalization","Tumors;Computer architecture;Mathematical model;Microprocessors;Predictive models;Sociology;Statistics","biomechanics;computerised tomography;feedforward neural nets;learning (artificial intelligence);medical image processing;positron emission tomography;tumours","cell invasion;mass-effect;cell density;tumor boundary;multimodal imaging data;tumor mass;pancreatic tumor data;tumor growth prediction;reaction-diffusion equations;biomechanics;predictive models;deep convolutional neural networks;convolutional invasion network;convolutional expansion network","Female;Humans;Image Processing, Computer-Assisted;Machine Learning;Male;Models, Biological;Multimodal Imaging;Neoplasm Invasiveness;Neoplasms;Neural Networks (Computer);Pancreatic Neoplasms;Precision Medicine","3","45","","","","","IEEE","IEEE Journals"
"Approximate Computing for Long Short Term Memory (LSTM) Neural Networks","S. Sen; A. Raghunathan","School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA; School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","","2018","37","11","2266","2276","Long Short Term Memory (LSTM) networks are a class of recurrent neural networks that are widely used for machine learning tasks involving sequences, including machine translation, text generation, and speech recognition. Large-scale LSTMs, which are deployed in many real-world applications, are highly compute intensive. To address this challenge, we propose AxLSTM, an application of approximate computing to improve the execution efficiency of LSTMs. An LSTM is composed of cells, each of which contains a cell state along with multiple gating units that control the addition and removal of information from the state. The LSTM execution proceeds in timesteps, with a new symbol of the input sequence processed at each timestep. AxLSTM consists of two techniques-Dynamic Timestep Skipping (DTS) and Dynamic State Reduction (DSR). DTS identifies, at runtime, input symbols that are likely to have little or no impact on the cell state and skips evaluating the corresponding timesteps. In contrast, DSR reduces the size of the cell state in accordance with the complexity of the input sequence, leading to a reduced number of computations per timestep. We describe how AxLSTM can be applied to the most common application of LSTMs, viz., sequence-to-sequence learning. We implement AxLSTM within the TensorFlow deep learning framework and evaluate it on 3 state-of-the-art sequence-to-sequence models. On a 2.7 GHz Intel Xeon server with 128 GB memory and 32 processor cores, AxLSTM achieves 1.08 × -1.31× speedups with minimal loss in quality, and 1.12 × -1.37× speedups when moderate reductions in quality are acceptable.","","","10.1109/TCAD.2018.2858362","Semiconductor Research Corporation; Defense Advanced Research Projects Agency; National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8417946","Approximate computing;long short term memory (LSTM) networks;sequence-to-sequence learning","Approximate computing;Logic gates;Recurrent neural networks;Machine learning;Computational modeling;Task analysis","learning (artificial intelligence);recurrent neural nets","approximate computing;long Short Term Memory neural networks;recurrent neural networks;machine learning tasks;machine translation;text generation;speech recognition;AxLSTM;cell state;input sequence;DTS;DSR;sequence-to-sequence learning;TensorFlow deep learning framework;LSTM execution;dynamic state reduction;dynamic timestep skipping;Intel Xeon server","","3","42","","","","","IEEE","IEEE Journals"
"Hierarchical Recurrent Neural Hashing for Image Retrieval With Hierarchical Convolutional Features","X. Lu; Y. Chen; X. Li","Xi’an Institute of Optics and Precision Mechanics, Chinese Academy of Sciences, Xi’an, China; Xi’an Institute of Optics and Precision Mechanics, Chinese Academy of Sciences, Xi’an, China; Xi’an Institute of Optics and Precision Mechanics, Chinese Academy of Sciences, Xi’an, China","IEEE Transactions on Image Processing","","2018","27","1","106","120","Hashing has been an important and effective technology in image retrieval due to its computational efficiency and fast search speed. The traditional hashing methods usually learn hash functions to obtain binary codes by exploiting hand-crafted features, which cannot optimally represent the information of the sample. Recently, deep learning methods can achieve better performance, since deep learning architectures can learn more effective image representation features. However, these methods only use semantic features to generate hash codes by shallow projection but ignore texture details. In this paper, we proposed a novel hashing method, namely hierarchical recurrent neural hashing (HRNH), to exploit hierarchical recurrent neural network to generate effective hash codes. There are three contributions of this paper. First, a deep hashing method is proposed to extensively exploit both spatial details and semantic information, in which, we leverage hierarchical convolutional features to construct image pyramid representation. Second, our proposed deep network can exploit directly convolutional feature maps as input to preserve the spatial structure of convolutional feature maps. Finally, we propose a new loss function that considers the quantization error of binarizing the continuous embeddings into the discrete binary codes, and simultaneously maintains the semantic similarity and balanceable property of hash codes. Experimental results on four widely used data sets demonstrate that the proposed HRNH can achieve superior performance over other state-of-the-art hashing methods.","","","10.1109/TIP.2017.2755766","National Natural Science Foundation of China; Key Research Program of Frontier Sciences, CAS; Young Top-notch Talent Program of Chinese Academy of Sciences; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8048518","Image retrieval;supervised hashing;hierarchical convolutional features;hierarchical RNN","Convolutional codes;Semantics;Binary codes;Image retrieval;Feature extraction;Recurrent neural networks;Training data","binary codes;convolution;cryptography;feature extraction;file organisation;image representation;image retrieval;learning (artificial intelligence);neural nets;recurrent neural nets","hierarchical recurrent neural hashing;hierarchical recurrent neural network;deep hashing method;deep network;discrete binary codes;image retrieval;hash functions;hand-crafted features;deep learning methods;deep learning architectures;hash codes;hierarchical convolutional features;convolutional feature maps;image representation features","","20","72","Traditional","","","","IEEE","IEEE Journals"
"Automatic Image Cropping for Visual Aesthetic Enhancement Using Deep Neural Networks and Cascaded Regression","G. Guo; H. Wang; C. Shen; Y. Yan; H. M. Liao","Fujian Key Laboratory of Sensing and Computing for Smart City, and the School of Information Science and Engineering, Xiamen University, Xiamen, China; Fujian Key Laboratory of Sensing and Computing for Smart City, and the School of Information Science and Engineering, Xiamen University, Xiamen, China; Australian Center for Visual Technologies, and the School of Computer Science, University of Adelaide, Adelaide, SA, Australia; Fujian Key Laboratory of Sensing and Computing for Smart City, and the School of Information Science and Engineering, Xiamen University, Xiamen, China; Institute of Information Science, Academia Sinica, Taipei, Taiwan","IEEE Transactions on Multimedia","","2018","20","8","2073","2085","Despite recent progress, computational visual aesthetic is still challenging. Image cropping, which refers to the removal of unwanted scene areas, is an important step to improve the aesthetic quality of an image. However, it is challenging to evaluate whether cropping leads to aesthetically pleasing results because the assessment is typically subjective. In this paper, we propose a novel cascaded cropping regression (CCR) method to perform image cropping by learning the knowledge from professional photographers. The proposed CCR method improves the convergence speed of the cascaded method, which directly uses random-ferns regressors. In addition, a two-step learning strategy is proposed and used in the CCR method to address the problem of lacking labelled cropping data. Specifically, a deep convolutional neural network (CNN) classifier is first trained on large-scale visual aesthetic datasets. The deep CNN model is then designed to extract features from several image cropping datasets, upon which the cropping bounding boxes are predicted by the proposed CCR method. Experimental results on public image cropping datasets demonstrate that the proposed method significantly outperforms several state-of-the-art image cropping methods.","","","10.1109/TMM.2018.2794262","National Natural Science Foundation of China; Natural Science Foundation of Fujian Province of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8259308","Image cropping;cascaded cropping regression;convolutional neural network;random-ferns regressor","Feature extraction;Visualization;Training;Agriculture;Computer vision","convolution;feature extraction;feedforward neural nets;image classification;image enhancement;learning (artificial intelligence);regression analysis","CCR method;two-step learning strategy;labelled cropping data;deep convolutional neural network classifier;large-scale visual aesthetic datasets;deep CNN model;cropping bounding boxes;public image cropping datasets;automatic image cropping;visual aesthetic enhancement;cascaded cropping regression method;computational visual aesthetic enhancement;image aesthetic quality;professional photographers;convergence speed;random-ferns regressors;features extraction","","1","41","","","","","IEEE","IEEE Journals"
"High-Resolution PolSAR Scene Classification With Pretrained Deep Convnets and Manifold Polarimetric Parameters","W. Wu; H. Li; L. Zhang; X. Li; H. Guo","Institute of Remote Sensing and Digital Earth, Chinese Academy of Sciences, Beijing, China; Information Engineering School, Nanchang University, Nanchang, China; Institute of Remote Sensing and Digital Earth, Chinese Academy of Sciences, Beijing, China; Institute of Remote Sensing and Digital Earth, Chinese Academy of Sciences, Beijing, China; Institute of Remote Sensing and Digital Earth, Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Geoscience and Remote Sensing","","2018","56","10","6159","6168","How to jointly use spatial and polarimetric information in PolSAR analysis has long been an open question. Benefiting from advanced architectures and large visual databases, deep convolutional neural networks or deep convnets (DCNNs) can generate high-level spatial features and achieve state-of-the-art performance in image analyses. However, because PolSAR data are not only multiband but also complex valued, these models cannot be easily borrowed to process them. In light of this problem, we develop a new data set to explore the abilities and potentials of DCNN on PolSAR scene classification. We observe that these models learn fixed semantic information in each layer and adapt to a different data type via changing middle-level filters. Instead of detecting colorful patterns, filters for PolSAR data tend to generate features in separate colors, which may naturally enable the network to differentiate polarimetric mechanisms. Therefore, an ensemble transfer learning framework is proposed to incorporate manifold polarimetric decompositions into a DCNN without throwing away the prelearned spatial analytic ability. Different polarimetric parameters can reflect polarization mechanisms in diverse aspects and introduce new discriminative features to enhance the object recognition. The framework achieves 99.5% validation accuracy and may benefit PolSAR applications in a wide spectrum of fields.","","","10.1109/TGRS.2018.2833156","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8363061","Image classification;neural network applications;radar polarimetry;synthetic aperture radar (SAR)","Data models;Backscatter;Synthetic aperture radar;Remote sensing;Image color analysis;Training;Optical sensors","convolution;feature extraction;feedforward neural nets;image classification;learning (artificial intelligence);object recognition;radar imaging;radar polarimetry;synthetic aperture radar;visual databases","image analyses;PolSAR data;DCNN;semantic information;high-resolution PolSAR scene classification;pretrained deep convnets;spatial information;polarimetric information;visual databases;deep convolutional neural networks;high-level spatial features;transfer learning framework;polarimetric parameters;middle-level filters;polarimetric mechanisms;colorful patterns detection;object recognition;manifold polarimetric decompositions","","2","27","","","","","IEEE","IEEE Journals"
"Deep Action Parsing in Videos With Large-Scale Synthesized Data","L. Liu; Y. Zhou; L. Shao","Inception Institute of Artificial Intelligence, Abu Dhabi, United Arab Emirates; Inception Institute of Artificial Intelligence, Abu Dhabi, United Arab Emirates; Inception Institute of Artificial Intelligence, Abu Dhabi, United Arab Emirates","IEEE Transactions on Image Processing","","2018","27","6","2869","2882","Action parsing in videos with complex scenes is an interesting but challenging task in computer vision. In this paper, we propose a generic 3D convolutional neural network in a multi-task learning manner for effective Deep Action Parsing (DAP3D-Net) in videos. Particularly, in the training phase, action localization, classification, and attributes learning can be jointly optimized on our appearance-motion data via DAP3D-Net. For an upcoming test video, we can describe each individual action in the video simultaneously as: Where the action occurs, What the action is, and How the action is performed. To well demonstrate the effectiveness of the proposed DAP3D-Net, we also contribute a new Numerous-category Aligned Synthetic Action data set, i.e., NASA, which consists of 200 000 action clips of over 300 categories and with 33 pre-defined action attributes in two hierarchical levels (i.e., low-level attributes of basic body part movements and high-level attributes related to action motion). We learn DAP3D-Net using the NASA data set and then evaluate it on our collected Human Action Understanding data set and the public THUMOS data set. Experimental results show that our approach can accurately localize, categorize, and describe multiple actions in realistic videos.","","","10.1109/TIP.2018.2813530","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8315465","Action parsing;3D convolutional neural network;action localization and classification;attributes learning;NASA and HAU","Videos;NASA;Three-dimensional displays;Solid modeling;Data models;Task analysis;Convolutional neural networks","learning (artificial intelligence);neural nets;video signal processing","large-scale synthesized data;generic 3D convolutional neural network;multitask learning manner;effective Deep Action Parsing;DAP3D;action localization;appearance-motion data;public THUMOS data;collected Human Action Understanding data;NASA data set;high-level attributes related to action motion;Numerous-category Aligned Synthetic Action data","","1","64","","","","","IEEE","IEEE Journals"
"SPFTN: A Joint Learning Framework for Localizing and Segmenting Objects in Weakly Labeled Videos","D. Zhang; J. Han; L. Yang; D. Xu","School of Automation, Northwestern Polytechnical University, Xi'an, Shaanxi China (e-mail: zdw2006yyy@mail.nwpu.edu.cn); School of Automation, Northwestern Polytechnical University, Xi'an, Shaanxi China (e-mail: junweihan2010@gmail.com); School of Automation, Xi'an, Shaanxi China (e-mail: nwpuyangle@gmail.com); School of Electrical and Information Engineering, The University of Sydney, Sydney, New South Wales Australia 2006 (e-mail: dong.xu@sydney.edu.au)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","PP","99","1","1","Object localization and segmentation in weakly labeled videos are two interesting yet challenging tasks. Models built for simultaneous object localization and segmentation have been explored in the conventional fully supervised learning scenario to boost the performance of each task. However, none of the existing works has attempted to jointly learn object localization and segmentation models under weak supervision. To this end, we propose a joint learning framework called Self-Paced Fine-Tuning Network (SPFTN) for localizing and segmenting objects in weakly labelled videos. Learning the deep model jointly for object localization and segmentation under weak supervision is very challenging as the learning process of each single task would face serious ambiguity issue due to the lack of bounding-box or pixel-level supervision. To address this problem, our proposed deep SPFTN model is carefully designed with a novel multi-task self-paced learning objective, which leverages the task-specific prior knowledge and the knowledge that has been already captured to infer the confident training samples for each task. By aggregating the confident knowledge from each single task to mine reliable patterns and learning deep feature representation for both tasks, the proposed learning framework can address the ambiguity issue under weak supervision with simple optimization. Comprehensive experiments on the large-scale YouTube-Objects and DAVIS datasets demonstrate that the proposed approach achieves superior performance when compared with other state-of-the-art methods and the baseline networks/models.","","","10.1109/TPAMI.2018.2881114","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8533384","Weakly labeled videos;object segmentation;video object localization;deep neural networks;self-paced learning","Videos;Task analysis;Reliability;Supervised learning;Object segmentation;Semantics;Feature extraction","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Long Short-Term Memory Recurrent Neural Network for Remaining Useful Life Prediction of Lithium-Ion Batteries","Y. Zhang; R. Xiong; H. He; M. G. Pecht","National Engineering Laboratory for Electric Vehicles, Department of Vehicle Engineering, School of Mechanical Engineering, Beijing Institute of Technology, Beijing, China; National Engineering Laboratory for Electric Vehicles, Department of Vehicle Engineering, School of Mechanical Engineering, Beijing Institute of Technology, Beijing, China; National Engineering Laboratory for Electric Vehicles, Department of Vehicle Engineering, School of Mechanical Engineering, Beijing Institute of Technology, Beijing, China; Center for Advanced Life Cycle Engineering, University of Maryland, College Park, MD, USA","IEEE Transactions on Vehicular Technology","","2018","67","7","5695","5705","Remaining useful life (RUL) prediction of lithium-ion batteries can assess the battery reliability to determine the advent of failure and mitigate battery risk. The existing RUL prediction techniques for lithium-ion batteries are inefficient for learning the long-term dependencies among the capacity degradations. This paper investigates deep-learning-enabled battery RUL prediction. The long short-term memory (LSTM) recurrent neural network (RNN) is employed to learn the long-term dependencies among the degraded capacities of lithium-ion batteries. The LSTM RNN is adaptively optimized using the resilient mean square back-propagation method, and a dropout technique is used to address the overfitting problem. The developed LSTM RNN is able to capture the underlying long-term dependencies among the degraded capacities and construct an explicitly capacity-oriented RUL predictor, whose long-term learning performance is contrasted to the support vector machine model, the particle filter model, and the simple RNN model. Monte Carlo simulation is combined to generate a probabilistic RUL prediction. Experimental data from multiple lithium-ion cells at two different temperatures is deployed for model construction, verification, and comparison. The developed method is able to predict the battery's RUL independent of offline training data, and when some offline data is available, the RUL can be predicted earlier than in the traditional methods.","","","10.1109/TVT.2018.2805189","National Natural Science Foundation of China; Beijing Nova Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8289406","Lithium-ion battery;remaining useful life;deep learning;long short-term memory;Monte Carlo simulation","Degradation;Lithium-ion batteries;Predictive models;Mathematical model;Support vector machines;Data models","learning (artificial intelligence);Monte Carlo methods;particle filtering (numerical methods);power engineering computing;recurrent neural nets;remaining life assessment;secondary cells;support vector machines","degraded capacities;explicitly capacity-oriented RUL predictor;long-term learning performance;probabilistic RUL prediction;multiple lithium-ion cells;short-term memory recurrent neural network;useful life prediction;lithium-ion batteries;battery reliability;battery risk;long-term dependencies;deep-learning-enabled battery RUL prediction;LSTM RNN;RUL prediction techniques","","25","38","","","","","IEEE","IEEE Journals"
"Distilling the Knowledge From Handcrafted Features for Human Activity Recognition","Z. Chen; Le Zhang; Z. Cao; J. Guo","Singapore; Singapore; Guangzhou, China; Guangzhou, China","IEEE Transactions on Industrial Informatics","","2018","14","10","4334","4342","Human activity recognition is a core problem in intelligent automation systems due to its far-reaching applications including ubiquitous computing, health-care services, and smart living. Due to the nonintrusive property of smartphones, smartphone sensors are widely used for the identification of human activities. However, unlike applications in vision or data mining domain, feature embedding from deep neural networks performs much worse in terms of recognition accuracy than properly designed handcrafted features. In this paper, we posit that feature embedding from deep neural networks may convey complementary information and propose a novel knowledge distilling strategy to improve its performance. More specifically, an efficient shallow network, i.e., single-layer feedforward neural network (SLFN), with handcrafted features is utilized to assist a deep long short-term memory (LSTM) network. On the one hand, the deep LSTM network is able to learn features from raw sensory data to encode temporal dependencies. On the other hand, the deep LSTM network can also learn from SLFN to mimic how it generalizes. Experimental results demonstrate the superiority of the proposed method in terms of recognition accuracy against several state-of-the-art methods in the literature.","","","10.1109/TII.2018.2789925","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8247224","Deep long short-term memory (LSTM) network;human activity recognition;knowledge distilling;smartphone sensors;single-layer feedforward neural network (SLFN)","Activity recognition;Smart phones;Neural networks;Feature extraction;Machine learning;Support vector machines","data mining;feature extraction;feedforward neural nets;learning (artificial intelligence);sensors;smart phones;ubiquitous computing","human activity recognition;intelligent automation systems;ubiquitous computing;health-care services;smart living;smartphone sensors;human activities;deep neural networks;knowledge distilling strategy;single-layer feedforward neural network;deep LSTM network;shallow network;long short-term memory network;sensory data;data mining","","2","37","","","","","IEEE","IEEE Journals"
"Unsupervised Deep Hashing With Pseudo Labels for Scalable Image Retrieval","H. Zhang; L. Liu; Y. Long; L. Shao","School of Computer Science and Engineering, Nanjing University of Science and Technology and University of East Anglia, Nanjing, China; JD Artificial Intelligence Research (JDAIR), Beijing, China; Open Lab, School of Computing, University of Newcastle, Newcastle upon Tyne, U.K.; JD Artificial Intelligence Research (JDAIR), Beijing, China","IEEE Transactions on Image Processing","","2018","27","4","1626","1638","In order to achieve efficient similarity searching, hash functions are designed to encode images into low-dimensional binary codes with the constraint that similar features will have a short distance in the projected Hamming space. Recently, deep learning-based methods have become more popular, and outperform traditional non-deep methods. However, without label information, most state-of-the-art unsupervised deep hashing (DH) algorithms suffer from severe performance degradation for unsupervised scenarios. One of the main reasons is that the ad-hoc encoding process cannot properly capture the visual feature distribution. In this paper, we propose a novel unsupervised framework that has two main contributions: 1) we convert the unsupervised DH model into supervised by discovering pseudo labels; 2) the framework unifies likelihood maximization, mutual information maximization, and quantization error minimization so that the pseudo labels can maximumly preserve the distribution of visual features. Extensive experiments on three popular data sets demonstrate the advantages of the proposed method, which leads to significant performance improvement over the state-of-the-art unsupervised hashing algorithms.","","","10.1109/TIP.2017.2781422","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8170292","Image retrieval;unsupervised hashing;pseudo labels","Binary codes;Quantization (signal);Visualization;Semantics;Correlation;Robustness;Feature extraction","binary codes;file organisation;image coding;image retrieval;quantisation (signal);unsupervised learning","quantization error minimization;likelihood maximization;data sets;unsupervised deep hashing algorithms;label information;nondeep methods;deep learning-based methods;projected Hamming space;low-dimensional binary codes;efficient similarity searching;scalable image retrieval;visual features;mutual information maximization;pseudolabels;unsupervised DH model;visual feature distribution;ad-hoc encoding process","","4","60","","","","","IEEE","IEEE Journals"
"Multi-scale deep neural network for salient object detection","F. Xiao; W. Deng; L. Peng; C. Cao; K. Hu; X. Gao","Key Laboratory of Intelligent Computing & Information Processing of Ministry of Education, Xiangtan University, People's Republic of China; Key Laboratory of Intelligent Computing & Information Processing of Ministry of Education, Xiangtan University, People's Republic of China; Key Laboratory of Intelligent Computing & Information Processing of Ministry of Education, Xiangtan University, People's Republic of China; Key Laboratory of Intelligent Computing & Information Processing of Ministry of Education, Xiangtan University, People's Republic of China; Key Laboratory of Intelligent Computing & Information Processing of Ministry of Education, Xiangtan University, People's Republic of China; Key Laboratory of Intelligent Computing & Information Processing of Ministry of Education, Xiangtan University, People's Republic of China","IET Image Processing","","2018","12","11","2036","2041","Salient object detection is a fundamental problem and has been received a great deal of attention in computer vision. Recently, deep learning model became a powerful tool for image feature extraction. In this study, the authors propose a multi-scale deep neural network (MSDNN) for salient object detection. The proposed model first extracts global high-level features and context information over the whole source image with the recurrent convolutional neural network. Then several stacked deconvolutional layers are adopted to get the multi-scale feature representation and obtain a series of saliency maps. Finally, the authors investigate a fusion convolution module to build a final pixel level saliency map. The proposed model is extensively evaluated on six salient object detection benchmark datasets. Results show that the authors' deep model significantly outperforms other 12 state-of-the-art approaches.","","","10.1049/iet-ipr.2018.5631","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8502724","","","computer vision;feature extraction;image representation;learning (artificial intelligence);neural nets;object detection","multiscale deep neural network;computer vision;deep learning model;image feature extraction;context information;global high-level feature extraction;stacked deconvolutional layers;multiscale feature representation;fusion convolution module;pixel level saliency map;salient object detection benchmark datasets","","","37","","","","","IET","IET Journals"
"A Joint Convolutional Neural Networks and Context Transfer for Street Scenes Labeling","Q. Wang; J. Gao; Y. Yuan","School of Computer ScienceUnmanned System Research Institute; Center for OPTical IMagery Analysis and Learning, School of Computer Science, Northwestern Polytechnical University, Xi’an, China; Center for OPTical IMagery Analysis and Learning, School of Computer Science, Northwestern Polytechnical University, Xi’an, China","IEEE Transactions on Intelligent Transportation Systems","","2018","19","5","1457","1470","Street scene understanding is an essential task for autonomous driving. One important step toward this direction is scene labeling, which annotates each pixel in the images with a correct class label. Although many approaches have been developed, there are still some weak points. First, many methods are based on the hand-crafted features whose image representation ability is limited. Second, they cannot label foreground objects accurately due to the data set bias. Third, in the refinement stage, the traditional Markov random filed inference is prone to over smoothness. For improving the above problems, this paper proposes a joint method of priori convolutional neural networks at superpixel level (called as “priori s-CNNs”) and soft restricted context transfer. Our contributions are threefold: 1) a priori s-CNNs model that learns priori location information at superpixel level is proposed to describe various objects discriminatingly; 2) a hierarchical data augmentation method is presented to alleviate data set bias in the priori s-CNNs training stage, which improves foreground objects labeling significantly; and 3) a soft restricted MRF energy function is defined to improve the priori s-CNNs model's labeling performance and reduce the over smoothness at the same time. The proposed approach is verified on CamVid data set (11 classes) and SIFT Flow Street data set (16 classes) and achieves a competitive performance.","","","10.1109/TITS.2017.2726546","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; Open Research Fund of Key Laboratory of Spectral Imaging Technology, Chinese Academy of Sciences; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8012463","Scene labeling;convolutional neural networks;deep learning;label transfer;street scenes;data augmentation","Labeling;Training;Feature extraction;Three-dimensional displays;Neural networks;Data mining;Computational modeling","feature extraction;feedforward neural nets;image annotation;image representation;learning (artificial intelligence);Markov processes","autonomous driving;correct class label;foreground objects;refinement stage;priori convolutional neural networks;superpixel level;priori location information;hierarchical data augmentation method;s-CNNs training stage;soft restricted MRF energy function;CamVid data set;joint convolutional neural networks and context transfer;street scenes labeling;hand-crafted features;image representation;Markov random filed inference;s-CNN model;SIFT flow street data set;MRF energy function","","41","41","","","","","IEEE","IEEE Journals"
"An Architecture to Accelerate Convolution in Deep Neural Networks","A. Ardakani; C. Condo; M. Ahmadi; W. J. Gross","Department of Electrical and Computer Engineering, McGill University, Montréal, QC, Canada; Department of Electrical and Computer Engineering, McGill University, Montréal, QC, Canada; Department of Computer Engineering, Polytechnique Montréal, Montréal, QC, Canada; Department of Electrical and Computer Engineering, McGill University, Montréal, QC, Canada","IEEE Transactions on Circuits and Systems I: Regular Papers","","2018","65","4","1349","1362","In the past few years, the demand for real-time hardware implementations of deep neural networks (DNNs), especially convolutional neural networks (CNNs), has dramatically increased, thanks to their excellent performance on a wide range of recognition and classification tasks. When considering real-time action recognition and video/image classification systems, latency is of paramount importance. Therefore, applications strive to maximize the accuracy while keeping the latency under a given application-specific maximum: in most cases, this threshold cannot exceed a few hundred milliseconds. Until now, the research on DNNs has mainly focused on achieving a better classification or recognition accuracy, whereas very few works in literature take in account the computational complexity of the model. In this paper, we propose an efficient computational method, which is inspired by a computational core of fully connected neural networks, to process convolutional layers of state-of-the-art deep CNNs within strict latency requirements. To this end, we implemented our method customized for VGG and VGG-based networks which have shown state-of-the-art performance on different classification/recognition data sets. The implementation results in 65-nm CMOS technology show that the proposed accelerator can process convolutional layers of VGGNet up to 9.5 times faster than state-of-the-art accelerators reported to-date while occupying 3.5 mm2.","","","10.1109/TCSI.2017.2757036","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8070363","Convolutional neural networks;deep neural network;machine learning;hardware implementation;pattern recognition;very large scale integration (VLSI)","Convolution;Neurons;Computer architecture;Complexity theory;Neural networks;Hardware;Three-dimensional displays","CMOS integrated circuits;convolution;feedforward neural nets;image classification","accelerate convolution;deep neural networks;real-time hardware implementations;convolutional neural networks;classification tasks;fully connected neural networks;convolutional layers;strict latency requirements;DNN;computational complexity;deep CNN;real-time action recognition;video-image classification systems;application-specific maximum;classification-recognition data sets","","9","42","","","","","IEEE","IEEE Journals"
"Image Dehazing Using Residual-Based Deep CNN","J. Li; G. Li; H. Fan","School of Computer Science and Technology, Shandong Technology and Business University, Yantai, China; School of Computer Science and Technology, Shandong Technology and Business University, Yantai, China; School of Computer Science and Technology, Shandong Technology and Business University, Yantai, China","IEEE Access","","2018","6","","26831","26842","There is a series of image degradation in the image acquired in haze and other weather. The single image dehazing is a challenging and ill-posed problem. Using deep neural network methods, it solves the drawbacks of manually designing haze-related features. This paper proposes a dehazing algorithm using residual-based deep CNN. The network model is divided into two phases: in the first stage, a haze image is input, and the transmission map is estimated by network; in the second stage, the ratio of foggy image and transmission map is used as input, and the residual network is used to remove haze. It avoids the estimation of atmospheric light and improves the efficiency of dehazing. To train the proposed network, we use the NYU2 depth dataset as the training set. In the full-reference metric peak signal to noise ratio, structural similarity, and feature similarity and no-reference metric Spatial-Spectral Entropy-based Quality, Blind/Referenceless Image Spatial Quality Evaluator, and Natural Image Quality Evaluator aspect, the experimental results confirm the efficiency and robustness of the proposed method.","","","10.1109/ACCESS.2018.2833888","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8355803","Image dehazing;residual network;deep learning;convolutional neural network","Atmospheric modeling;Scattering;Image restoration;Training;Convolutional neural networks","entropy;feature extraction;image denoising;image enhancement;image restoration;neural nets","image degradation;single image dehazing;deep neural network methods;transmission map;foggy image;residual network;NYU2 depth dataset;full-reference metric peak signal;natural image quality evaluator;blind-referenceless image spatial quality evaluator;residual-based deep CNN;ill-posed problem;atmospheric light;no-reference metric;spatial-spectral entropy-based quality","","8","32","","","","","IEEE","IEEE Journals"
"Scatter Artifacts Removal Using Learning-Based Method for CBCT in IGRT System","S. Xie; C. Yang; Z. Zhang; H. Li","College of Telecommunications & Information Engineering, Nanjing University of Posts and Telecommunications, Nanjing, China; College of Telecommunications & Information Engineering, Nanjing University of Posts and Telecommunications, Nanjing, China; Department of Oncology, Xiangya Hospital Central South University, Changsha, China; College of Telecommunications & Information Engineering, Nanjing University of Posts and Telecommunications, Nanjing, China","IEEE Access","","2018","6","","78031","78037","Cone-beam-computed tomography (CBCT) has shown enormous potential in recent years, but it is limited by severe scatter artifacts. This paper proposes a scatter-correction algorithm based on a deep convolutional neural network to reduce artifacts for CBCT in an image-guided radiation therapy (IGRT) system. A two-step registration method that is essential in our algorithm is implemented to preprocess data before training. The testing result on real data acquired from the IGRT system demonstrates the ability of our approach to learn artifacts distribution. Furthermore, the proposed method can be applied to enhance the performance on such applications as dose estimation and segmentation.","","","10.1109/ACCESS.2018.2884704","University Natural Science Research Project of Jiangsu Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8558562","CBCT;scatter correction;image registration;deep CNN","Computed tomography;Training;Scattering;Convolution;Learning systems;X-ray imaging;Hospitals","computerised tomography;convolutional neural nets;data acquisition;image registration;learning (artificial intelligence);medical image processing;radiation therapy","CBCT;IGRT system;cone-beam-computed tomography;severe scatter artifacts;scatter-correction algorithm;deep convolutional neural network;image-guided radiation therapy system;two-step registration method;artifact distribution;scatter artifact removal;real data acquisition","","2","46","","","","","IEEE","IEEE Journals"
"Low-Dose CT Image Denoising Using a Generative Adversarial Network With Wasserstein Distance and Perceptual Loss","Q. Yang; P. Yan; Y. Zhang; H. Yu; Y. Shi; X. Mou; M. K. Kalra; Y. Zhang; L. Sun; G. Wang","Department of Biomedical Engineering, Rensselaer Polytechnic Institute, Troy, NY, USA; Department of Biomedical Engineering, Rensselaer Polytechnic Institute, Troy, NY, USA; Department of Electrical and Computer Engineering, University of Massachusetts Lowell, Lowell, MA, USA; Department of Electrical and Computer Engineering, University of Massachusetts Lowell, Lowell, MA, USA; Institute of Image Processing and Pattern Recognition, Xian Jiaotong University, Xian, China; Institute of Image Processing and Pattern Recognition, Xian Jiaotong University, Xian, China; Department of Radiology, Massachusetts General Hospital, Harvard Medical School, Boston, MA, USA; College of Computer Science, Sichuan University, Chengdu, China; Department of Radiology, Huaxi MR Research Center, West China Hospital, Sichuan University, Chengdu, China; Department of Biomedical Engineering, Rensselaer Polytechnic Institute, Troy, NY, USA","IEEE Transactions on Medical Imaging","","2018","37","6","1348","1357","The continuous development and extensive use of computed tomography (CT) in medical practice has raised a public concern over the associated radiation dose to the patient. Reducing the radiation dose may lead to increased noise and artifacts, which can adversely affect the radiologists' judgment and confidence. Hence, advanced image reconstruction from low-dose CT data is needed to improve the diagnostic performance, which is a challenging problem due to its ill-posed nature. Over the past years, various low-dose CT methods have produced impressive results. However, most of the algorithms developed for this application, including the recently popularized deep learning techniques, aim for minimizing the mean-squared error (MSE) between a denoised CT image and the ground truth under generic penalties. Although the peak signal-to-noise ratio is improved, MSE- or weighted-MSE-based methods can compromise the visibility of important structural details after aggressive denoising. This paper introduces a new CT image denoising method based on the generative adversarial network (GAN) with Wasserstein distance and perceptual similarity. The Wasserstein distance is a key concept of the optimal transport theory and promises to improve the performance of GAN. The perceptual loss suppresses noise by comparing the perceptual features of a denoised output against those of the ground truth in an established feature space, while the GAN focuses more on migrating the data noise distribution from strong to weak statistically. Therefore, our proposed method transfers our knowledge of visual perception to the image denoising task and is capable of not only reducing the image noise level but also trying to keep the critical information at the same time. Promising results have been obtained in our experiments with clinical CT images.","","","10.1109/TMI.2018.2827462","National Natural Science Foundation of China; National Institute of Biomedical Imaging and Bioengineering/National Institutes of Health; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8340157","Low dose CT;image denoising;deep learning;perceptual loss;WGAN","Computed tomography;Gallium nitride;Noise reduction;Image reconstruction;Image denoising;Biomedical imaging;Machine learning","computerised tomography;image denoising;image reconstruction;learning (artificial intelligence);mean square error methods;medical image processing","data noise distribution;image denoising task;image noise level;clinical CT images;low-dose CT image denoising;Wasserstein distance;continuous development;computed tomography;artifacts;low-dose CT data;diagnostic performance;low-dose CT methods;mean-squared error;denoised CT image;peak signal-to-noise ratio;weighted-MSE-based methods;aggressive denoising;CT image denoising method;denoised output;image reconstruction;radiation dose;popularized deep learning techniques","","33","48","","","","","IEEE","IEEE Journals"
"Prediction of Protein Secondary Structure With Clonal Selection Algorithm and Multilayer Perceptron","B. Çarklı Yavuz; N. Yurtay; O. Ozkan","Department of Information Systems Engineering, Sakarya University, Sakarya, Turkey; Department of Computer Engineering, Sakarya University, Sakarya, Turkey; Department of Electrical and Electronics Engineering, Sakarya University, Sakarya, Turkey","IEEE Access","","2018","6","","45256","45261","The recent studies indicate that the protein secondary structure provides very important advantages in determining the function of a protein, treating numerous diseases and drug design. Determining the secondary structure in the laboratory environment is both costly and challenging. Therefore, the prediction of protein secondary structure has been an important study field of bioinformatics and computational biology for many years. The aim of this paper was to provide a contribution to the prediction of protein secondary structure using the nature-inspired methods. The data in the first phase were trained with clonal selection algorithm (CSA) which was modeled by being inspired by the live immune system. The classification was then performed with multilayer perceptron which is one of the deep learning methods modeled by being inspired by the biological nervous system. The results obtained indicated that training of the data with CSA prior to classification contributed positively to classification success.","","","10.1109/ACCESS.2018.2864665","Research Fund of the Sakarya University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8432429","Clonal selection algorithm;deep learning;hemoglobin protein;multilayer perceptron;prediction of protein secondary structure","Proteins;Machine learning;Amino acids;Prediction algorithms;Immune system;Classification algorithms;Artificial neural networks","bioinformatics;biology computing;diseases;drugs;learning (artificial intelligence);molecular biophysics;multilayer perceptrons;pattern classification;proteins","deep learning methods;biological nervous system;CSA;bioinformatics;computational biology;drug design;numerous diseases;protein secondary structure prediction;multilayer perceptron;clonal selection algorithm","","2","37","","","","","IEEE","IEEE Journals"
"Densely Connected Discriminative Correlation Filters for Visual Tracking","C. Peng; F. Liu; J. Yang; N. Kasabov","Institute of Image Processing and Pattern Recognition, Shanghai Jiao Tong University, Shanghai, China; Institute of Image Processing and Pattern Recognition, Shanghai Jiao Tong University, Shanghai, China; Institute of Image Processing and Pattern Recognition, Shanghai Jiao Tong University, Shanghai, China; Knowledge Engineering and Discovery Research Institute, Auckland University of Technology, Auckland, New Zealand","IEEE Signal Processing Letters","","2018","25","7","1019","1023","Discriminative Correlation Filters (DCFs)-based approaches have recently achieved competitive performance in visual tracking. However, such conventional DCF-based trackers often lack the discriminative ability due to the shallow architecture. As a result, they can hardly tackle drastic appearance variations and easily drift when the target suffers heavy occlusions. To address this issue, a novel densely connected DCFs framework is proposed for visual tracking. We incorporate multiple nested DCFs into the deep learning architecture, and then train the compact network with the data-specific target. Specifically, feature maps and interim response maps are shared and reused throughout the whole network. By doing so, the implicit information carried out by each DCF is fully exploited to enhance the model representation ability during the tracking process. Moreover, a multiscale estimation scheme is developed to account for scale variations. Experimental results on the benchmarks demonstrate that the proposed approach achieves outstanding performance compared to the existing state-of-the-art trackers.","","","10.1109/LSP.2018.2836360","National Natural Science Foundation of China; 973 Plan of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8359334","Correlation filters;deep learning;visual tracking","Target tracking;Correlation;Feature extraction;Visualization;Machine learning;Estimation;Training","image representation;learning (artificial intelligence);object tracking","densely connected discriminative Correlation Filters;visual tracking;discriminative ability;shallow architecture;drastic appearance variations;DCFs framework;multiple nested DCFs;deep learning architecture;data-specific target;interim response maps;model representation ability;tracking process","","1","41","","","","","IEEE","IEEE Journals"
"Exploiting Feature and Class Relationships in Video Categorization with Regularized Deep Neural Networks","Y. Jiang; Z. Wu; J. Wang; X. Xue; S. Chang","School of Computer Science, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China; School of Computer Science and Software Engineering, East China Normal University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China; Department of Electrical Engineering, Columbia University, New York, NY","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","2","352","364","In this paper, we study the challenging problem of categorizing videos according to high-level semantics such as the existence of a particular human action or a complex event. Although extensive efforts have been devoted in recent years, most existing works combined multiple video features using simple fusion strategies and neglected the utilization of inter-class semantic relationships. This paper proposes a novel unified framework that jointly exploits the feature relationships and the class relationships for improved categorization performance. Specifically, these two types of relationships are estimated and utilized by imposing regularizations in the learning process of a deep neural network (DNN). Through arming the DNN with better capability of harnessing both the feature and the class relationships, the proposed regularized DNN (rDNN) is more suitable for modeling video semantics. We show that rDNN produces better performance over several state-of-the-art approaches. Competitive results are reported on the well-known Hollywood2 and Columbia Consumer Video benchmarks. In addition, to stimulate future research on large scale video categorization, we collect and release a new benchmark dataset, called FCVID, which contains 91,223 Internet videos and 239 manually annotated categories.","","","10.1109/TPAMI.2017.2670560","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7857793","Video categorization;deep neural networks;regularization;feature fusion;class relationships;benchmark dataset","Semantics;Feature extraction;Neural networks;Benchmark testing;Visualization;Correlation;Internet","feature extraction;image classification;image representation;Internet;learning (artificial intelligence);neural nets;video signal processing","multiple video features;simple fusion strategies;inter-class semantic relationships;class relationships;human action;categorization performance;internet videos;video categorization;FCVID;deep neural network regularization;complex event;learning process;high-level video semantics;Columbia consumer video benchmarks;manually annotated categories;Hollywood2 consumer video benchmarks;benchmark dataset;exploiting feature relationships","","22","74","","","","","IEEE","IEEE Journals"
"Multi-Context Integrated Deep Neural Network Model for Next Location Prediction","J. Liao; T. Liu; M. Liu; J. Wang; Y. Wang; H. Sun","State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; School of Business, Guilin University of Electronic Technology, Guilin, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China","IEEE Access","","2018","6","","21980","21990","The prediction of next location for users in location-based social networks has become an increasing significant requirement since it can benefit both users and business. However, existing methods lack an integrated analysis of sequence context, input contexts, and user preferences in a unified way, and result in an unsatisfactory prediction. Moreover, the interaction between different kinds of input contexts has not been investigated. In this paper, we propose a multi-context integrated deep neural network model (MCI-DNN) to improve the accuracy of the next location prediction. In this model, we integrate sequence context, input contexts, and user preferences into a cohesive framework. First, we model sequence context and interaction of different kinds of input contexts jointly by extending the recurrent neural network to capture the semantic pattern of user behaviors from check-in records. After that, we design a feedforward neural network to capture high-level user preferences from check-in data and incorporate that into MCI-DNN. To deal with different kinds of input contexts in the form of multi-field categorical, we adopt embedding representation technology to automatically learn dense feature representations of input contexts. Experimental results on two typical real-world data sets show that the proposed model outperforms the current state-of-the-art approaches by about 57.12% for Foursquare and 76.4% for Gowalla on average regarding F1-score@5.","","","10.1109/ACCESS.2018.2827422","National Natural Science Foundation of China; Beijing Municipal Natural Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8340154","Location-based social networks;next location prediction;deep neural network;sequence prediction;multi-context","Context modeling;Predictive models;Hidden Markov models;Neural networks;Computational modeling;Trajectory;Business","feature extraction;feedforward neural nets;learning (artificial intelligence);recurrent neural nets;social networking (online)","recurrent neural network;feedforward neural network;multicontext integrated deep neural network model;user preferences;location prediction;social networks;integrated analysis;MCI-DNN;semantic pattern;embedding technology;learning features;Gowalla","","3","41","","","","","IEEE","IEEE Journals"
"Margin Loss: Making Faces More Separable","R. Gao; F. Yang; W. Yang; Q. Liao","Shenzhen Key Laboratory of Information Science and Technology, Shenzhen Engineering Laboratory of IS&DCP and the Department of Electronic Engineering, Graduate School at Shenzhen, Tsinghua University, Beijing, China; Shenzhen Key Laboratory of Information Science and Technology, Shenzhen Engineering Laboratory of IS&DCP and the Department of Electronic Engineering, Graduate School at Shenzhen, Tsinghua University, Beijing, China; Shenzhen Key Laboratory of Information Science and Technology, Shenzhen Engineering Laboratory of IS&DCP and the Department of Electronic Engineering, Graduate School at Shenzhen, Tsinghua University, Beijing, China; Shenzhen Key Laboratory of Information Science and Technology, Shenzhen Engineering Laboratory of IS&DCP and the Department of Electronic Engineering, Graduate School at Shenzhen, Tsinghua University, Beijing, China","IEEE Signal Processing Letters","","2018","25","2","308","312","The key point of face recognition is creating a discriminative feature representation to ensure intraclass compactness and interclass separability. Softmax loss is widely used in deep learning networks, but it is indirect for face verification. Center loss is effective to improve intraclass compactness, while interclass distances are ignored. In this letter, we propose a novel loss function, termed margin loss, to enlarge distances of interclass and reduce intraclass variations simultaneously. Margin loss aims to focus on samples hard to classify by a distance margin. Different from Softmax loss, margin loss is based on Euclidean distances that can directly measure face similarity. Experiments on different datasets have demonstrated the effectiveness of our method.","","","10.1109/LSP.2017.2789251","National Natural Science Foundation of China; National Basic Research Program of China (973 Program); Special Foundation for the Development of Strategic Emerging Industries of Shenzhen; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8245803","Center loss;deep learning;margin loss","Training;Face recognition;Machine learning;Loss measurement;Signal processing algorithms;Databases","face recognition;image representation;learning (artificial intelligence)","face similarity measure;Euclidean distances;distance margin;interclass distance;intraclass variation reduction;loss function;intraclass compactness;interclass distances;center loss;face verification;deep learning networks;Softmax loss;discriminative feature representation;face recognition;margin loss","","2","26","","","","","IEEE","IEEE Journals"
"Robust 3-D Human Detection in Complex Environments With a Depth Camera","L. Tian; M. Li; Y. Hao; J. Liu; G. Zhang; Y. Q. Chen","School of Computer Science, Shanghai Key Laboratory of Intelligent Information Processing, Fudan University, Shanghai, China; School of Computer Science, Shanghai Key Laboratory of Intelligent Information Processing, Fudan University, Shanghai, China; School of Computer Science, Shanghai Key Laboratory of Intelligent Information Processing, Fudan University, Shanghai, China; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Computer Science, Shanghai Key Laboratory of Intelligent Information Processing, Fudan University, Shanghai, China; School of Computer Science, Shanghai Key Laboratory of Intelligent Information Processing, Fudan University, Shanghai, China","IEEE Transactions on Multimedia","","2018","20","9","2249","2261","Human detection has received great attention during the past few decades, which is yet still a challenging problem. In this paper, we focus on the problem of 3-D human detection, i.e., finding the human bodies and determining their 3-D coordinates in complex 3-D space using depth data only. Since the traditional sliding-window-based approaches for target localization are time-consuming and the recent deep-learning-based object detectors generate too many region proposals, we propose to utilize the candidate head-top locating stage to efficiently and quickly find the plausible head-top locations. In the second stage, we propose a Depth map, Multiorder depth template, and Height difference map representation encoding three channels of information for each candidate region to utilize the neural network pretrained on large-scale well-annotated datasets to classify the candidate regions. We evaluate our method on four publicly available challenging datasets. Extensive experimental results demonstrate that the proposed method is superior to the state-of-the-art methods while achieving real-time performance.","","","10.1109/TMM.2018.2803526","Science and Technology Commission of Shanghai Municipality; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8283786","3D human detection;depth data;real-time;deep learning","Three-dimensional displays;Feature extraction;Detectors;Machine learning;Proposals;Cameras;Object detection","cameras;learning (artificial intelligence);neural nets;object detection","candidate head-top locating stage;complex environments;depth camera;neural network;height difference map representation;multiorder depth template;3-D human detection;deep-learning-based object detectors;sliding-window-based approaches;depth map","","3","52","","","","","IEEE","IEEE Journals"
"Artificial Intelligent System for Automatic Depression Level Analysis Through Visual and Vocal Expressions","A. Jan; H. Meng; Y. F. B. A. Gaus; F. Zhang","Department of Electronic and Computer Engineering, Brunel University London UB8 3PH, U.K.; Department of Electronic and Computer Engineering, Brunel University London UB8 3PH, U.K.; Department of Electronic and Computer Engineering, Brunel University London UB8 3PH, U.K.; Department of Electronic and Computer Engineering, Brunel University London UB8 3PH, U.K.","IEEE Transactions on Cognitive and Developmental Systems","","2018","10","3","668","680","A human being's cognitive system can be simulated by artificial intelligent systems. Machines and robots equipped with cognitive capability can automatically recognize a humans mental state through their gestures and facial expressions. In this paper, an artificial intelligent system is proposed to monitor depression. It can predict the scales of Beck depression inventory II (BDI-II) from vocal and visual expressions. First, different visual features are extracted from facial expression images. Deep learning method is utilized to extract key visual features from the facial expression frames. Second, spectral low-level descriptors and mel-frequency cepstral coefficients features are extracted from short audio segments to capture the vocal expressions. Third, feature dynamic history histogram (FDHH) is proposed to capture the temporal movement on the feature space. Finally, these FDHH and audio features are fused using regression techniques for the prediction of the BDI-II scales. The proposed method has been tested on the public Audio/Visual Emotion Challenges 2014 dataset as it is tuned to be more focused on the study of depression. The results outperform all the other existing methods on the same dataset.","","","10.1109/TCDS.2017.2721552","School of Engineering and Design; Thomas Gerald Gray PGR Scholarship; Royal Society; National Natural Science Foundation of China; Majlis Amanah Rakyat; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7997822","Artificial system;Beck depression inventory (BDI);deep learning;depression;facial expression;regression;vocal expression","Visualization;Feature extraction;Face;Machine learning;Intelligent systems;History;Histograms","cognitive systems;emotion recognition;face recognition;feature extraction;image segmentation;learning (artificial intelligence);regression analysis","artificial intelligent system;automatic depression level analysis;vocal expressions;humans mental state;visual expressions;facial expression images;BDI-II scales;Beck depression inventory;cognitive system;gestures expressions;monitor depression;feature extraction;deep learning method;audio segments;FDHH;regression techniques;public audio-visual emotion challenges;history histogram","","9","64","","","","","IEEE","IEEE Journals"
"Spatial Sequential Recurrent Neural Network for Hyperspectral Image Classification","X. Zhang; Y. Sun; K. Jiang; C. Li; L. Jiao; H. Zhou","Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, School of Artificial Intelligence, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, School of Artificial Intelligence, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, School of Artificial Intelligence, Xidian University, Xi’an, China; Xi’an Jiaotong University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, School of Artificial Intelligence, Xidian University, Xi’an, China; University of Leicester, Leicester, U.K.","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2018","11","11","4141","4155","In hyperspectral image processing, classification is one of the most popular research topics. In recent years, research progress made in deep-learning-based hierarchical feature extraction and classification has shown a great power in many applications. In this paper, we propose a novel local spatial sequential (LSS) method, which is used in a recurrent neural network (RNN). Using this model, we can extract local and semantic information for hyperspectral image classification. First, we extract low-level features from hyperspectral images, including texture and differential morphological profiles. Second, we combine the low-level features together and propose a method to construct the LSS features. Afterwards, we build an RNN and use the LSS features as the input to train the network for optimizing the system parameters. Finally, the high-level semantic features generated by the RNN is fed into a softmax layer for the final classification. In addition, a nonlocal spatial sequential method is presented for the recurrent neural network model (NLSS-RNN) to further enhance the classification performance. NLSS-RNN finds nonlocal similar structures to a given pixel and extracts corresponding LSS features, which not only preserve the local spatial information, but also integrate the information of nonlocal similar samples. The experimental results on three publicly accessible datasets show that our proposed method can obtain competitive performance compared with several state-of-the-art classifiers.","","","10.1109/JSTARS.2018.2844873","National Natural Science Foundation of China; joint fund of the Equipment Research of Ministry of Education; U.K. Engineering and Physical Sciences Research Council; Royal Society-Newton Advanced Fellowship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8399509","Deep learning;high-level semantic feature;hyperspectral image (HSI) classification;low-level feature;recurrent neural network (RNN)","Feature extraction;Recurrent neural networks;Machine learning;Hyperspectral imaging;Computer architecture;Feedforward neural networks","feature extraction;image classification;learning (artificial intelligence);recurrent neural nets","local spatial information;spatial sequential recurrent neural network;hyperspectral image classification;hyperspectral image processing;popular research topics;deep-learning-based hierarchical feature extraction;local spatial sequential method;local information;semantic information;low-level features;hyperspectral images;high-level semantic features;nonlocal spatial sequential method;recurrent neural network model;NLSS-RNN;LSS feature extraction","","3","59","","","","","IEEE","IEEE Journals"
"Deep Reinforcement Learning Based Dynamic Channel Allocation Algorithm in Multibeam Satellite Systems","S. Liu; X. Hu; W. Wang","Key Laboratory of Universal Wireless Communications, Ministry of Education, Beijing University of Posts and Telecommunications, Beijing, China; Key Laboratory of Universal Wireless Communications, Ministry of Education, Beijing University of Posts and Telecommunications, Beijing, China; Key Laboratory of Universal Wireless Communications, Ministry of Education, Beijing University of Posts and Telecommunications, Beijing, China","IEEE Access","","2018","6","","15733","15742","Dynamic channel allocation (DCA) is the key technology to efficiently utilize the spectrum resources and decrease the co-channel interference for multibeam satellite systems. Most works allocate the channel on the basis of the beam traffic load or the user terminal distribution of the current moment. These greedy-like algorithms neglect the intrinsic temporal correlation among the sequential channel allocation decisions, resulting in the spectrum resources underutilization. To solve this problem, a novel deep reinforcement learning (DRL)-based DCA (DRL-DCA) algorithm is proposed. Specifically, the DCA optimization problem, which aims at minimizing the service blocking probability, is formulated in the multibeam satellite systems. Due to the temporal correlation property, the DCA optimization problem is modeled as the Markov decision process (MDP) which is the dominant analytical approach in DRL. In modeled MDP, the system state is reformulated into an image-like fashion, and then, convolutional neural network is used to extract useful features. Simulation results show that the DRL-DCA algorithm can decrease the blocking probability and improve the carried traffic and spectrum efficiency compared with other channel allocation algorithms.","","","10.1109/ACCESS.2018.2809581","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8302493","Dynamic channel allocation (DCA);multibeam satellite systems;Markov decision process (MDP);deep reinforcement learning (DRL);blocking probability","Satellites;Optimization;Channel allocation;Heuristic algorithms;Dynamic scheduling;Feature extraction;Interference","","","","7","24","","","","","IEEE","IEEE Journals"
"A Case of On-Chip Memory Subsystem Design for Low-Power CNN Accelerators","Y. Wang; H. Li; X. Li","State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","","2018","37","10","1971","1984","The rapid development of machine learning is enabling a plenty of novel applications, such as image and speech recognition for embedded and mobile devices. However, state-of-the-art deep learning models like convolutional neural networks (CNNs) are demanding so much on-chip storage and compute resources that they cannot be smoothly handled by low-power mobile or embedded systems. In order to fit large CNN models into mobile or more cutting-edge devices for IoT or cyberphysics applications, we proposed an efficient on-chip memory architecture for CNN inference acceleration, and showed its application to in-house single-instruction multiple-data structure machine learning processor. The redesigned on-chip memory subsystem, Memsqueezer, includes an active weight buffer and data buffer set that embraces specialized compression methods to reduce the footprint of CNN parameters (weights) and activation data, respectively. Memsqueezer buffer can compress the data and weight set according to the dataflow in computation, and it also includes a built-in redundancy detection mechanism that actively scans through the working-set of CNNs to boost their inference performance by eliminating the computation redundancy in CNN models. In our experiments, it is shown that the CNN processors with Memsqueezer buffers achieve more than 2× performance improvement and reduces 85% energy consumption on average over the conventional buffer design with the same area budget.","","","10.1109/TCAD.2017.2778060","National Natural Science Foundation of China; National Key Research and Development Program of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8165964","Convolutional neural network (CNN);deep learning;low power;memory subsystem","System-on-chip;Bandwidth;Computational modeling;Kernel;Computer architecture;Two dimensional displays;Acceleration","convolution;data compression;data structures;embedded systems;feedforward neural nets;learning (artificial intelligence);logic design;memory architecture;microprocessor chips;speech recognition","image recognition;deep learning models;CNN processors;computation redundancy;inference performance;redundancy detection mechanism;compression methods;data buffer;active weight buffer;multiple-data structure machine learning processor;CNN inference acceleration;on-chip memory architecture;cyberphysics applications;cutting-edge devices;CNN models;embedded systems;compute resources;on-chip storage;convolutional neural networks;mobile devices;embedded devices;speech recognition;low-power CNN accelerators;On-Chip Memory Subsystem Design;conventional buffer design;Memsqueezer buffer","","","33","","","","","IEEE","IEEE Journals"
"Deep Monocular Depth Estimation via Integration of Global and Local Predictions","Y. Kim; H. Jung; D. Min; K. Sohn","School of Electrical and Electronic Engineering, Yonsei University, Seoul, South Korea; School of Electrical and Electronic Engineering, Yonsei University, Seoul, South Korea; Department of Computer Science and Engineering, Ewha Womans University, Seoul, South Korea; School of Electrical and Electronic Engineering, Yonsei University, Seoul, South Korea","IEEE Transactions on Image Processing","","2018","27","8","4131","4144","Recent works on machine learning have greatly advanced the accuracy of single image depth estimation. However, the resulting depth images are still over-smoothed and perceptually unsatisfying. This paper casts depth prediction from single image as a parametric learning problem. Specifically, we propose a deep variational model that effectively integrates heterogeneous predictions from two convolutional neural networks (CNNs), named global and local networks. They have contrasting network architecture and are designed to capture the depth information with complementary attributes. These intermediate outputs are then combined in the integration network based on the variational framework. By unrolling the optimization steps of Split Bregman iterations in the integration network, our model can be trained in an end-to-end manner. This enables one to simultaneously learn an efficient parameterization of the CNNs and hyper-parameter in the variational method. Finally, we offer a new data set of 0.22 million RGB-D images captured by Microsoft Kinect v2. Our model generates realistic and discontinuity-preserving depth prediction without involving any low-level segmentation or superpixels. Intensive experiments demonstrate the superiority of the proposed method in a range of RGB-D benchmarks, including both indoor and outdoor scenarios.","","","10.1109/TIP.2018.2836318","Next Generation Information Computing Development Program through the National Research Foundation of Korea (NRF), Ministry of Science, ICT; Basic Science Research Program through the NRF; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8359371","Depth estimation;2D-to-3D conversion;non-parametric sampling;convolutional neural networks;RGB-D database","Estimation;Predictive models;Databases;Training;Optimization;Measurement;Computational modeling","convolution;feedforward neural nets;image colour analysis;iterative methods;learning (artificial intelligence);variational techniques","deep monocular depth estimation;local predictions;single image depth estimation;parametric learning problem;deep variational model;convolutional neural networks;CNNs;local networks;network architecture;integration network;Split Bregman iterations;variational method;RGB-D images;discontinuity-preserving depth prediction;depth images;global networks;Microsoft Kinect v2;global predictions","","5","59","","","","","IEEE","IEEE Journals"
"Image Super-Resolution With Parametric Sparse Model Learning","Y. Li; W. Dong; X. Xie; G. Shi; J. Wu; X. Li","State Key Laboratory on Integrated Services Networks, School of Artificial Intelligence, Xidian University, Xi’an, China; State Key Laboratory on Integrated Services Networks, School of Artificial Intelligence, Xidian University, Xi’an, China; School of Artificial Intelligence, Xidian University, Xi’an, China; School of Artificial Intelligence, Xidian University, Xi’an, China; School of Artificial Intelligence, Xidian University, Xi’an, China; Lane Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, WV, USA","IEEE Transactions on Image Processing","","2018","27","9","4638","4650","Recovering a high-resolution (HR) image from its low-resolution (LR) version is an ill-posed inverse problem. Learning accurate prior of HR images is of great importance to solve this inverse problem. Existing super-resolution (SR) methods either learn a non-parametric image prior from training data (a large set of LR/HR patch pairs) or estimate a parametric prior from the LR image analytically. Both methods have their limitations: the former lacks flexibility when dealing with different SR settings; while the latter often fails to adapt to spatially varying image structures. In this paper, we propose to take a hybrid approach toward image SR by combining those two lines of ideas-that is, a parametric sparse prior of HR images is learned from the training set as well as the input LR image. By exploiting the strengths of both worlds, we can more accurately recover the sparse codes and therefore HR image patches than conventional sparse coding approaches. Experimental results show that the proposed hybrid SR method significantly outperforms existing model-based SR methods and is highly competitive to current state-of-the-art learning-based SR methods in terms of both subjective and objective image qualities.","","","10.1109/TIP.2018.2837865","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8360397","Image super-resolution;parametric model learning;sparse representation;deep neural networks","Dictionaries;Laplace equations;Estimation;Image coding;Mixture models;Spatial resolution","image reconstruction;image resolution;inverse problems;learning (artificial intelligence)","parametric sparse model learning;high-resolution image;inverse problem;HR images;nonparametric image;training data;LR/HR patch pairs;spatially varying image structures;hybrid approach;image SR;training set;input LR image;sparse codes;image patches;hybrid SR method;subjective image qualities;objective image qualities;low-resolution image;image super-resolution","","4","45","","","","","IEEE","IEEE Journals"
"False Alarm Reduction in Atrial Fibrillation Detection Using Deep Belief Networks","B. Taji; A. D. C. Chan; S. Shirmohammadi","School of Electrical Engineering and Computer Science, University of Ottawa, ON, Canada; Department of Systems and Computer Engineering, Carleton University, ON, Canada; School of Electrical Engineering and Computer Science, University of Ottawa, ON, Canada","IEEE Transactions on Instrumentation and Measurement","","2018","67","5","1124","1131","We propose and validate a novel method to reduce the false alarm (FA) rate caused by poor-quality electrocardiogram (ECG) signal measurement during atrial fibrillation (AFib) detection. A deep belief network is used to differentiate acceptable from unacceptable ECG segments. To validate the method, eight different levels of ECG quality are provided by artificially contaminating ECG records, from the MIT-BIH AFib database, with motion artifact from the MIT-BIH noise stress test database. ECG segments classified as “unacceptable,” in terms of signal quality, are restricted from AFib detection process. Results are evaluated for each level of quality and compared to AFib detection algorithm performance when ECGs of each level of quality are applied to it without performing any classification. Our results show that AFib detection performance for ECG with high signal-to-noise ratio (SNR) is minimally affected by this FA reduction approach. For clean ECG (no added noise), the AFib detection accuracy was 87%, without and with FA reduction. For ECG, with an SNR of -20 dB, the performance of AFib detection is markedly decreased with an accuracy of 58.7%; however, with FA reduction (using our method) the accuracy was increased to 81%.","","","10.1109/TIM.2017.2769198","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8122053","Atrial fibrillation (AFib) detection;deep belief networks (DBN);false alarm (FA);machine learning;noise","Electrocardiography;Machine learning algorithms;Detection algorithms;Signal to noise ratio;Heart;Feature extraction;Neural networks","belief networks;electrocardiography;medical disorders;medical signal detection;medical signal processing;signal classification","false alarm reduction;atrial fibrillation detection;deep belief network;false alarm rate;poor-quality electrocardiogram signal measurement;unacceptable ECG segments;ECG quality;ECG records;MIT-BIH AFib database;MIT-BIH noise stress test database;signal quality;AFib detection process;AFib detection algorithm performance;FA reduction approach;clean ECG;AFib detection accuracy;signal-to-noise ratio;motion artifact","","4","53","","","","","IEEE","IEEE Journals"
"A High Energy Efficient Reconfigurable Hybrid Neural Network Processor for Deep Learning Applications","S. Yin; P. Ouyang; S. Tang; F. Tu; X. Li; S. Zheng; T. Lu; J. Gu; L. Liu; S. Wei","Institute of Microelectronics, Tsinghua University, Beijing, China; School of Electronics and Information Engineering, Beihang University, Beijing, China; Institute of Microelectronics, Tsinghua University, Beijing, China; Institute of Microelectronics, Tsinghua University, Beijing, China; Institute of Microelectronics, Tsinghua University, Beijing, China; Institute of Microelectronics, Tsinghua University, Beijing, China; Institute of Microelectronics, Tsinghua University, Beijing, China; Institute of Microelectronics, Tsinghua University, Beijing, China; Institute of Microelectronics, Tsinghua University, Beijing, China; Institute of Microelectronics, Tsinghua University, Beijing, China","IEEE Journal of Solid-State Circuits","","2018","53","4","968","982","Hybrid neural networks (hybrid-NNs) have been widely used and brought new challenges to NN processors. Thinker is an energy efficient reconfigurable hybrid-NN processor fabricated in 65-nm technology. To achieve high energy efficiency, three optimization techniques are proposed. First, each processing element (PE) supports bit-width adaptive computing to meet various bit-widths of neural layers, which raises computing throughput by 91% and improves energy efficiency by 1.93× on average. Second, PE array supports on-demand array partitioning and reconfiguration for processing different NNs in parallel, which results in 13.7% improvement of PE utilization and improves energy efficiency by 1.11×. Third, a fused data pattern-based multi-bank memory system is designed to exploit data reuse and guarantee parallel data access, which improves computing throughput and energy efficiency by 1.11× and 1.17×, respectively. Measurement results show that this processor achieves 5.09-TOPS/W energy efficiency at most.","","","10.1109/JSSC.2017.2778281","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8207783","Energy efficiency;hybrid neural networks (hybrid-NNs);memory banking;reconfigurable computing;resource partitioning","Artificial neural networks;Arrays;Acceleration;Throughput;Speech recognition","coprocessors;learning (artificial intelligence);logic design;memory architecture;microprocessor chips;neural nets;parallel architectures;reconfigurable architectures","high energy efficient reconfigurable hybrid neural network processor;deep learning applications;NN processors;bit-width adaptive computing;neural layers;computing throughput;on-demand array partitioning;hybrid-NN;fused data pattern-based multibank memory system;parallel data access","","19","30","","","","","IEEE","IEEE Journals"
"Smart-Log: A Deep-Learning Based Automated Nutrition Monitoring System in the IoT","P. Sundaravadivel; K. Kesavan; L. Kesavan; S. P. Mohanty; E. Kougianos","Department of Electrical Engineering, University of Texas at Tyler, Tyler, TX, USA; Department of Computer Science and Engineering, University of Texas at Arlington, Arlington, TX, USA; Versa Networks, San Jose, CA, USA; Department of Computer Science and Engineering, University of North Texas, Denton, TX, USA; Department of Engineering Technology, University of North Texas, Denton, TX, USA","IEEE Transactions on Consumer Electronics","","2018","64","3","390","398","A correct balance of nutrient intake is very important, particularly in infants. When the body is deprived of essential nutrients, it can lead to serious disease and organ deterioration which can cause serious health issues in adulthood. Automated monitoring of the nutritional content of food provided to infants, not only at home but also in daycare facilities, is essential for their healthy development. To address this challenge, this paper presents a new Internet of Things (IoT)-based fully automated nutrition monitoring system, called Smart-Log, to advance the state-of-art in smart healthcare. For the realization of Smart-Log, a novel 5-layer perceptron neural network and a Bayesian network-based accurate meal prediction algorithm are presented in this paper. Smart-Log is prototyped as a consumer electronics product which consists of WiFi enabled sensors for food nutrition quantification, and a smart phone application that collects nutritional facts of the food ingredients. The Smart-Log prototype uses an open IoT platform for data analytics and storage. Experimental results consisting of 8172 food items for 1000 meals show that the prediction accuracy of Smart-Log is 98.6%.","","","10.1109/TCE.2018.2867802","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8449987","Internet of Things (IoT);consumer electronics;smart healthcare;smart home;food monitoring;nutrition monitoring","Monitoring;Intelligent sensors;Bayes methods;Medical services;Microcontrollers;Internet of Things","belief networks;health care;Internet of Things;learning (artificial intelligence);medical computing;mobile computing;multilayer perceptrons;paediatrics;patient monitoring;smart phones","IoT;nutrient intake;infants;smart healthcare;5-layer perceptron neural network;Bayesian network-based accurate meal prediction algorithm;food nutrition quantification;smart phone application;nutritional facts;Smart-Log prototype;automated nutrition monitoring system;Internet of Things;deep-learning;daycare facilities","","7","39","","","","","IEEE","IEEE Journals"
"Deep learning-based approach to latent overlapped fingerprints mask segmentation","B. Stojanović; O. Marques; A. Nešković","University of Belgrade, Serbia; Florida Atlantic University, USA; University of Belgrade, Serbia","IET Image Processing","","2018","12","11","1934","1942","Overlapped fingerprints can be potentially present in several civil applications and criminal investigations. Segmentation of overlapped fingerprints is a required step in the process of fingerprint separation and subsequent verification. Overlapped fingerprint segmentation is performed manually (and the resulting manually drawn masks are a required additional input) in all of the overlapped latent fingerprints separation approaches in the literature, which make them only semi-automatic. This study proposes a novel overlapped fingerprint mask segmentation approach, thereby filling that gap in the development of fully automated fingerprint separation solutions. The proposed method uses convolutional neural networks to classify image blocks into three classes - background, single region, and overlapped region. The proposed approach shows satisfactory performance on three different datasets and opens the door for full automation of fingerprint separation algorithms, which is a very promising research area.","","","10.1049/iet-ipr.2017.1227","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8502723","","","feedforward neural nets;fingerprint identification;image classification;image segmentation;learning (artificial intelligence)","overlapped region class;single region class;background class;image block classification;convolutional neural networks;subsequent verification;fully automated fingerprint separation solutions;criminal investigations;civil applications;latent overlapped fingerprints mask segmentation;deep learning-based approach","","1","41","","","","","IET","IET Journals"
"DeepSS: Exploring Splice Site Motif Through Convolutional Neural Network Directly From DNA Sequence","X. Du; Y. Yao; Y. Diao; H. Zhu; Y. Zhang; S. Li","Key Laboratory of Intelligent Computing and Signal Processing of Ministry of Education, School of Computer Science and Technology, Anhui University, Hefei, China; Key Laboratory of Intelligent Computing and Signal Processing of Ministry of Education, School of Computer Science and Technology, Anhui University, Hefei, China; Key Laboratory of Intelligent Computing and Signal Processing of Ministry of Education, School of Computer Science and Technology, Anhui University, Hefei, China; Key Laboratory of Intelligent Computing and Signal Processing of Ministry of Education, School of Computer Science and Technology, Anhui University, Hefei, China; Key Laboratory of Intelligent Computing and Signal Processing of Ministry of Education, School of Computer Science and Technology, Anhui University, Hefei, China; Department of Medical Imaging, Western University, London, ON, Canada","IEEE Access","","2018","6","","32958","32978","Splice sites prediction and interpretation are crucial to the understanding of complicated mechanisms underlying gene transcriptional regulation. Although existing computational approaches can classify true/false splice sites, the performance mostly relies on a set of sequence- or structure-based features and model interpretability is relatively weak. In viewing of these challenges, we report a deep learning-based framework (DeepSS), which consists of DeepSS-C module to classify splice sites and DeepSS-M module to detect splice sites sequence pattern. Unlike previous feature construction and model training process, DeepSS-C module accomplishes feature learning during the whole model training. Compared with state-of-the-art algorithms, experimental results show that the DeepSS-C module yields more accurate performance on six publicly donor/acceptor splice sites data sets. In addition, the parameters of the trained DeepSS-M module are used for model interpretation and downstream analysis, including: 1) genome factors detection (the truly relevant motifs that induce the related biological process happen) via filters from deep learning perspective; 2) analyzing the ability of CNN filters on motifs detection; 3) co-analysis of filters and motifs on DNA sequence pattern. DeepSS is freely available at http://ailab.ahu.edu.cn:8087/DeepSS/index.html.","","","10.1109/ACCESS.2018.2848847","National Natural Science Foundation of China; Provincial Natural Science Research Program of Higher Education Institutions of Anhui province; Natural Science Foundation of Anhui Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8387825","Splice sites;convolutional neural network;feature extraction;motifs","Feature extraction;DNA;Machine learning;Support vector machines;Encoding;Training;Bioinformatics","biochemistry;bioinformatics;biology computing;DNA;feature extraction;feedforward neural nets;genetics;genomics;learning (artificial intelligence);microorganisms;molecular biophysics;proteins;proteomics;random processes","splice site motif;convolutional neural network;sites prediction;gene transcriptional regulation;computational approaches;true/false splice sites;structure-based features;model interpretability;deep learning-based framework;splice sites sequence pattern;model training;DeepSS-C module accomplishes;publicly donor/acceptor splice sites data sets;model interpretation;downstream analysis;deep learning perspective;motifs detection;feature construction;biological process;CNN filters","","","68","","","","","IEEE","IEEE Journals"
"Energy-Efficient Classification for Resource-Constrained Biomedical Applications","M. Shoaran; B. A. Haghi; M. Taghavi; M. Farivar; A. Emami-Neyestanak","School of Electrical and Computer Engineering, Cornell University, Ithaca, NY, USA; Electrical Engineering Department, California Institute of Technology, Pasadena, CA, USA; Electrical Engineering Department, California Institute of Technology, Pasadena, CA, USA; Google, Mountain View, CA, USA; Electrical Engineering Department, California Institute of Technology, Pasadena, CA, USA","IEEE Journal on Emerging and Selected Topics in Circuits and Systems","","2018","8","4","693","707","Biomedical applications often require classifiers that are both accurate and cheap to implement. Today, deep neural networks achieve the state-of-the-art accuracy in most learning tasks that involve large data sets of unstructured data. However, the application of deep learning techniques may not be beneficial in problems with limited training sets and computational resources, or under domain-specific test time constraints. Among other algorithms, ensembles of decision trees, particularly the gradient boosted models have recently been very successful in machine learning competitions. Here, we propose an efficient hardware architecture to implement gradient boosted trees in applications under stringent power, area, and delay constraints, such as medical devices. Specifically, we introduce the concepts of asynchronous tree operation and sequential feature extraction to achieve an unprecedented energy and area efficiency. The proposed architecture is evaluated in automated seizure detection for epilepsy, using 3074 h of intracranial EEG data from 26 patients with 393 seizures. Average F1 scores of 99.23% and 87.86% are achieved for random and block-wise splitting of data into train/test sets, respectively, with an average detection latency of 1.1 s. The proposed classifier is fabricated in a 65-nm TSMC process, consuming 41.2 nJ/class in a total area of 540 × 1850 μm2. This design improves the stateof-the-art by 27× reduction in energy-area-latency product. Moreover, the proposed gradient-boosting architecture offers the flexibility to accommodate variable tree counts specific to each patient, to trade the predictive accuracy with energy. This patient-specific and energy-quality scalable classifier holds great promise for low-power sensor data classification in biomedical applications.","","","10.1109/JETCAS.2018.2844733","Heritage Medical Research Institute; Swiss NSF Fellowship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8374841","Gradient boosted trees;hardware architecture;on-chip classifier;decision tree;accuracy;feature extraction;latency;seizure detection;energy-quality scaling","Feature extraction;Support vector machines;Machine learning;Decision trees;Electroencephalography;Epilepsy","decision trees;electroencephalography;energy conservation;feature extraction;learning (artificial intelligence);medical signal processing;neural nets;power aware computing;signal classification","gradient-boosting architecture;energy-quality scalable classifier;low-power sensor data classification;energy-efficient classification;resource-constrained biomedical applications;deep neural networks;domain-specific test time constraints;decision trees;gradient boosted trees;automated seizure detection;intracranial EEG data;deep learning;machine learning;feature extraction;hardware architecture;signal classification","","7","46","","","","","IEEE","IEEE Journals"
"An Enhanced Deep Extreme Learning Machine for Integrated Modular Avionics Health State Estimation","Z. Gao; C. Ma; Z. She; X. Dong","School of Aeronautics, Northwestern Polytechnical University, Xi’an, China; School of Aeronautics, Northwestern Polytechnical University, Xi’an, China; School of Aeronautics, Northwestern Polytechnical University, Xi’an, China; School of Aeronautics, Northwestern Polytechnical University, Xi’an, China","IEEE Access","","2018","6","","65813","65823","Integrated modular avionics (IMA) is one of the most advanced systems whose performance deeply impact on the security of civil aircraft. In order to enhance the safety and reliability of aircraft, the health state of the IMA must be estimated accurately. Since IMA is a real-time system, the estimation algorithm should have fast learning speed to satisfy the real-time requirement. In this paper, an enhanced deep extreme learning machine is developed to estimate the health states of IMA. First, the enhanced deep extreme learning machine is built in a novel fashion by using a dropout technique and extreme learning machine autoencoder. Second, multiple-enhanced deep extreme learning machines with different activation functions are employed to estimate the health states, simultaneously. Finally, a synthesis strategy is designed to combine all the results of different enhanced deep extreme learning machines. In such a manner, the robust and accurate estimation results can be obtained. In order to collect the data under different health states, a performance degradation model of IMA is built by the intermittent faults. The proposed method is applied to health state estimation, and the results confirm that the proposed method can present a superior estimation to the conventional methods.","","","10.1109/ACCESS.2018.2878813","National Natural Science Foundation of China; Aeronautical Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8528439","Integrated modular avionics;extreme learning machine;health state;intermittent faults","Aerospace electronics;State estimation;Real-time systems;Feature extraction;Aircraft","","","","1","38","","","","","IEEE","IEEE Journals"
"Heterogeneous Face Recognition by Margin-Based Cross-Modality Metric Learning","J. Huo; Y. Gao; Y. Shi; W. Yang; H. Yin","State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; School of Electrical and Electronic Engineering, University of Manchester, Manchester, U.K.","IEEE Transactions on Cybernetics","","2018","48","6","1814","1826","Heterogeneous face recognition deals with matching face images from different modalities or sources. The main challenge lies in cross-modal differences and variations and the goal is to make cross-modality separation among subjects. A margin-based cross-modality metric learning (MCM2L) method is proposed to address the problem. A cross-modality metric is defined in a common subspace where samples of two different modalities are mapped and measured. The objective is to learn such metrics that satisfy the following two constraints. The first minimizes pairwise, intrapersonal cross-modality distances. The second forces a margin between subject specific intrapersonal and interpersonal cross-modality distances. This is achieved by defining a hinge loss on triplet-based distance constraints for efficient optimization. It allows the proposed method to focus more on optimizing distances of those subjects whose intrapersonal and interpersonal distances are hard to separate. The proposed method is further extended to a kernelized MCM2L (KMCM2L). Both methods have been evaluated on an ID card face dataset and two other cross-modality benchmark datasets. Various feature extraction methods have also been incorporated in the study, including recent deep learned features. In extensive experiments and comparisons with the state-of-the-art methods, the MCM2L and KMCM2L methods achieved marked improvements in most cases.","","","10.1109/TCYB.2017.2715660","National Science Foundation of China; Young Elite Scientists Sponsorship Program by CAST; Collaborative Innovation Center of Novel Software Technology and Industrialization; China Scholarship Council through the University of Manchester; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7959077","Face recognition;large margin classifier;metric learning;multimodality learning","Measurement;Feature extraction;Face recognition;Face;Training;Optimization;Force","face recognition;feature extraction;image matching;learning (artificial intelligence)","margin;cross-modality metric learning;heterogeneous face recognition deals;face images;cross-modal differences;cross-modality separation;subject specific intrapersonal cross-modality distances;interpersonal cross-modality distances;triplet-based distance constraints;intrapersonal distances;interpersonal distances;ID card face dataset;cross-modality benchmark datasets;cross-modal variations","","4","48","","","","","IEEE","IEEE Journals"
"Video Dynamics Detection Using Deep Neural Networks","K. Zheng; W. Q. Yan; P. Nand","Department of Computer Science, Auckland University of Technology, Auckland, New Zealand; Department of Computer Science, Auckland University of Technology, Auckland, New Zealand; Department of Computer Science, Auckland University of Technology, Auckland, New Zealand","IEEE Transactions on Emerging Topics in Computational Intelligence","","2018","2","3","224","234","In recent years, deep neural networks (DNNs) have achieved a remarkable progression in solving many complex problems. DNNs are suitable for dealing with the problems related to time series, such as speech recognition and natural language processing. Video dynamics detection, for instance, is time dependent. Apparently, video dynamics detection needs to utilize the present, previous, and next frames of a given video. If a frame change occurs, it triggers whether a video event happens or not. In this paper, video dynamics detection based on deep learning is implemented and our contributions are to effectively improve the accuracy of video dynamics detection. The contributions of this paper are as follows: 1) increasing the accuracy rate to 96% compared to an FSM-based video dynamics detection in real time; 2) By combining convolutional neural network and recurrent neural network (RNN) together, the training time is greatly reduced as we expected.","","","10.1109/TETCI.2017.2778716","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239714","Recurrent neural network (RNN);LSTM;CNN;video dynamics detection","Hidden Markov models;Logic gates;Streaming media;Computational modeling;Surveillance;Recurrent neural networks","feedforward neural nets;finite state machines;learning (artificial intelligence);recurrent neural nets;time series;video signal processing","video dynamics detection;deep neural networks;training time;recurrent neural network;convolutional neural network;accuracy rate;deep learning;time series","","","42","","","","","IEEE","IEEE Journals"
"A Deep Multi-Modal CNN for Multi-Instance Multi-Label Image Classification","L. Song; J. Liu; B. Qian; M. Sun; K. Yang; M. Sun; S. Abbas","Department of Computer Science and Technology, National Engineering Lab of Big Data Analytics, Xi’an Jiaotong University, Xi’an, China; Department of Computer Science and Technology, National Engineering Lab of Big Data Analytics, Xi’an Jiaotong University, Xi’an, China; Department of Computer Science and Technology, National Engineering Lab of Big Data Analytics, Xi’an Jiaotong University, Xi’an, China; Division of Computer Science and Engineering, School of Electrical Engineering and Computer Science, Louisiana State University, Baton Rouge, LA, USA; Department of Computer Science and Technology, SPKLSTN Lab, Xi’an Jiaotong University, Xi’an, China; School of Foreign Studies, Xi’an Jiaotong University, Xi’an, China; Department of Computer Science and Technology, SPKLSTN Lab, Xi’an Jiaotong University, Xi’an, China","IEEE Transactions on Image Processing","","2018","27","12","6025","6038","Deep convolutional neural networks (CNNs) have shown superior performance on the task of single-label image classification. However, the applicability of CNNs to multi-label images still remains an open problem, mainly because of two reasons. First, each image is usually treated as an inseparable entity and represented as one instance, which mixes the visual information corresponding to different labels. Second, the correlations amongst labels are often overlooked. To address these limitations, we propose a deep multi-modal CNN for multi-instance multi-label image classification, called MMCNN-MIML. By combining CNNs with multi-instance multi-label (MIML) learning, our model represents each image as a bag of instances for image classification and inherits the merits of both CNNs and MIML. In particular, MMCNN-MIML has three main appealing properties: 1) it can automatically generate instance representations for MIML by exploiting the architecture of CNNs; 2) it takes advantage of the label correlations by grouping labels in its later layers; and 3) it incorporates the textual context of label groups to generate multi-modal instances, which are effective in discriminating visually similar objects belonging to different groups. Empirical studies on several benchmark multi-label image data sets show that MMCNN-MIML significantly outperforms the state-of-the-art baselines on multi-label image classification tasks.","","","10.1109/TIP.2018.2864920","National Basic Research Program of China (973 Program); National Natural Science Foundation of China; Innovative Research Group of the National Natural Science Foundation of China; Innovation Research Team of Ministry of Education; China Scholarship Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8432496","CNN;multi-label image classification;MIML;label correlations;context information","Image classification;Feature extraction;Convolutional neural networks","convolution;feedforward neural nets;image classification;learning (artificial intelligence)","multiinstance multilabel learning;MMCNN-MIML;label correlations;label groups;deep multimodal CNN;multiinstance multilabel image classification;single-label image classification;multilabel image data sets;deep convolutional neural networks;visual information;textual context","","5","63","","","","","IEEE","IEEE Journals"
"Visual and Semantic Knowledge Transfer for Large Scale Semi-Supervised Object Detection","Y. Tang; J. Wang; X. Wang; B. Gao; E. Dellandréa; R. Gaizauskas; L. Chen","National Institutes of Health (NIH) Clinical Center, Bethesda, MD; Department of Computer Science, The University of Sheffield, Sheffield, United Kingdom; École Centrale de Lyon, Écully, France; Department of Advanced Robotics (ADVR), Istituto Italiano di Tecnologia (IIT), Genova, Italy; École Centrale de Lyon, Écully, France; Department of Computer Science, The University of Sheffield, Sheffield, United Kingdom; École Centrale de Lyon, Écully, France","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","12","3045","3058","Deep CNN-based object detection systems have achieved remarkable success on several large-scale object detection benchmarks. However, training such detectors requires a large number of labeled bounding boxes, which are more difficult to obtain than image-level annotations. Previous work addresses this issue by transforming image-level classifiers into object detectors. This is done by modeling the differences between the two on categories with both image-level and bounding box annotations, and transferring this information to convert classifiers to detectors for categories without bounding box annotations. We improve this previous work by incorporating knowledge about object similarities from visual and semantic domains during the transfer process. The intuition behind our proposed method is that visually and semantically similar categories should exhibit more common transferable properties than dissimilar categories, e.g. a better detector would result by transforming the differences between a dog classifier and a dog detector onto the cat class, than would by transforming from the violin class. Experimental results on the challenging ILSVRC2013 detection dataset demonstrate that each of our proposed object similarity based knowledge transfer methods outperforms the baseline methods. We found strong evidence that visual similarity and semantic relatedness are complementary for the task, and when combined notably improve detection, achieving state-of-the-art detection performance in a semi-supervised setting.","","","10.1109/TPAMI.2017.2771779","French Research Agency; Agence Nationale de Recherche (ANR); Visen project; Partner University Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8103045","Object detection;convolutional neural networks;semi-supervised learning;transfer learning;visual similarity;semantic similarity;weakly supervised object detection","Semisupervised learning;Semantics;Convolutional neural networks;Learning systems;Object detection;Training data","image classification;learning (artificial intelligence);object detection","visual knowledge transfer;semantic knowledge transfer;scale semisupervised object detection;deep CNN-based object detection systems;remarkable success;large-scale object detection benchmarks;labeled bounding boxes;image-level annotations;image-level classifiers;object detectors;bounding box annotations;object similarities;visual domains;semantic domains;transfer process;semantically similar categories;common transferable properties;dog classifier;dog detector;object similarity based knowledge transfer methods;visual similarity;semantic relatedness;state-of-the-art detection performance;semisupervised setting","","2","67","","","","","IEEE","IEEE Journals"
"Attributed Social Network Embedding","L. Liao; X. He; H. Zhang; T. Chua","National University of Singapore, Singapore; National University of Singapore, Singapore; Nanyang Technological University, Singapore; National University of Singapore, Singapore","IEEE Transactions on Knowledge and Data Engineering","","2018","30","12","2257","2270","Embedding network data into a low-dimensional vector space has shown promising performance for many real-world applications, such as node classification and entity retrieval. However, most existing methods focused only on leveraging network structure. For social networks, besides the network structure, there also exists rich information about social actors, such as user profiles of friendship networks and textual content of citation networks. These rich attribute information of social actors reveal the homophily effect, exerting huge impacts on the formation of social networks. In this paper, we explore the rich evidence source of attributes in social networks to improve network embedding. We propose a generic Attributed Social Network Embedding framework (ASNE), which learns representations for social actors (i.e., nodes) by preserving both the structural proximity and attribute proximity. While the structural proximity captures the global network structure, the attribute proximity accounts for the homophily effect. To justify our proposal, we conduct extensive experiments on four real-world social networks. Compared to the state-of-the-art network embedding approaches, ASNE can learn more informative representations, achieving substantial gains on the tasks of link prediction and node classification. Specifically, ASNE significantly outperforms node2vec with an 8.2 percent relative improvement on the link prediction task, and a 12.7 percent gain on the node classification task.","","","10.1109/TKDE.2018.2819980","National Research Foundation Singapore; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8326519","Social network representation;homophily;deep learning","Task analysis;Distance measurement;Neural networks;Computational modeling;Deep learning","citation analysis;graph theory;learning (artificial intelligence);network theory (graphs);pattern classification;social networking (online);text analysis;vectors","attributed social network embedding framework;homophily effect;node classification task;ASNE;textual content;social networks;citation networks;friendship networks;leveraging network structure;entity retrieval;structural proximity captures;social actors","","10","64","","","","","IEEE","IEEE Journals"
"SMEConvNet: A Convolutional Neural Network for Spotting Spontaneous Facial Micro-Expression From Long Videos","Z. Zhang; T. Chen; H. Meng; G. Liu; X. Fu","Chongqing Key Laboratory of Nonlinear Circuit and Intelligent Information Processing, Southwest University, Chongqing, China; Chongqing Key Laboratory of Nonlinear Circuit and Intelligent Information Processing, Southwest University, Chongqing, China; Chongqing Key Laboratory of Nonlinear Circuit and Intelligent Information Processing, Southwest University, Chongqing, China; Chongqing Key Laboratory of Nonlinear Circuit and Intelligent Information Processing, Southwest University, Chongqing, China; Chinese Academy of Sciences, Institute of Psychology, Beijing, China","IEEE Access","","2018","6","","71143","71151","Micro-expression is a subtle and involuntary facial expression that may reveal the hidden emotion of human beings. Spotting micro-expression means to locate the moment when the micro-expression happens, which is a primary step for micro-expression recognition. Previous work in micro-expression spotting focus on spotting micro-expression from short video, and with hand-crafted features. In this paper, we present a methodology for spotting micro-expression from long videos. Specifically, a new convolutional neural network named spotting micro-expression convolutional network was designed for extracting features from video clips, which is the first time that deep learning is used in micro-expression spotting. Then, a feature matrix processing method was proposed for spotting the apex frame from long video, which uses a sliding window and takes the characteristics of micro-expression into account to search the apex frame. Experimental results demonstrate that the proposed method can achieve a better performance than the existing state-of-art methods.","","","10.1109/ACCESS.2018.2879485","National Natural Science Foundation of China; National Natural Science Foundation of China; German Research Foundation (DFG) under project Cross Modal Learning; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8522030","Spotting micro-expression;apex frame;convolutional neural network;deep learning","Videos;Feature extraction;Face;Indexes;Convolutional neural networks;Microsoft Windows","convolutional neural nets;emotion recognition;face recognition;feature extraction;learning (artificial intelligence);video signal processing","microexpression recognition;convolutional neural network;spotting microexpression convolutional network;involuntary facial expression;microexpression spotting;feature matrix processing method;deep learning","","6","39","","","","","IEEE","IEEE Journals"
"Ship Detection From Thermal Remote Sensing Imagery Through Region-Based Deep Forest","F. Yang; Q. Xu; B. Li; Y. Ji","Beijing Key Laboratory of Digital Media, School of Computer Science and Engineering, Beihang University, Beijing, China; Beijing Key Laboratory of Digital Media, School of Computer Science and Engineering, Beihang University, Beijing, China; Beijing Key Laboratory of Digital Media, School of Computer Science and Engineering, Beihang University, Beijing, China; Beijing Remote Sensing Information Institute, Beijing, China","IEEE Geoscience and Remote Sensing Letters","","2018","15","3","449","453","Ship detection from thermal remote sensing imagery is a challenging task because of cluttered scenes and variable appearances of ships. In this letter, we propose a novel detection algorithm named region-based deep forest (RDF) toward overcoming these existing issues. The RDF consists of a simple region proposal network and a deep forest ensemble. The region proposal network trained over gradient features robustly generates a small number of candidates that precisely cover ship targets in various backgrounds. The deep forest ensemble adaptively learns features from remote sensing data and discriminates real ships from region proposals efficiently. The training process of deep forest ensemble is efficient and users can control training cost according to computational resource available. Experimental results on numerous thermal satellite images demonstrate the superior performance of our method compared with state-of-the-art methods.","","","10.1109/LGRS.2018.2793960","National Natural Science Foundation of China; Army Equipment Research Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8277182","Deep forest;region proposal;ship detection;thermal satellite imagery","Marine vehicles;Proposals;Nonhomogeneous media;Training;Radio frequency;Remote sensing;Microsoft Windows","feature extraction;geophysical image processing;image classification;learning (artificial intelligence);object detection;remote sensing;ships","deep forest ensemble;numerous thermal satellite images;ship detection;thermal remote sensing imagery;novel detection algorithm named region;RDF;simple region proposal network;ship targets;remote sensing data;ships","","2","14","","","","","IEEE","IEEE Journals"
"CNN-Based Projected Gradient Descent for Consistent CT Image Reconstruction","H. Gupta; K. H. Jin; H. Q. Nguyen; M. T. McCann; M. Unser","Biomedical Imaging Group, École Polytechnique Fédérale de Lausanne, Lausanne, Switzerland; Biomedical Imaging Group, École Polytechnique Fédérale de Lausanne, Lausanne, Switzerland; Biomedical Imaging Group, École Polytechnique Fédérale de Lausanne, Lausanne, Switzerland; Center for Biomedical Imaging, Signal Processing Core and the Biomedical Imaging Group, École Polytechnique Fédérale de Lausanne, Lausanne, Switzerland; Biomedical Imaging Group, École Polytechnique Fédérale de Lausanne, Lausanne, Switzerland","IEEE Transactions on Medical Imaging","","2018","37","6","1440","1453","We present a new image reconstruction method that replaces the projector in a projected gradient descent (PGD) with a convolutional neural network (CNN). Recently, CNNs trained as image-to-image regressors have been successfully used to solve inverse problems in imaging. However, unlike existing iterative image reconstruction algorithms, these CNN-based approaches usually lack a feedback mechanism to enforce that the reconstructed image is consistent with the measurements. We propose a relaxed version of PGD wherein gradient descent enforces measurement consistency, while a CNN recursively projects the solution closer to the space of desired reconstruction images. We show that this algorithm is guaranteed to converge and, under certain conditions, converges to a local minimum of a non-convex inverse problem. Finally, we propose a simple scheme to train the CNN to act like a projector. Our experiments on sparse-view computed-tomography reconstruction show an improvement over total variation-based regularization, dictionary learning, and a state-of-the-art deep learning-based direct reconstruction technique.","","","10.1109/TMI.2018.2832656","European Research Council (H2020-ERC Project GlobalBioIm); European Union’s Horizon 2020 Framework Programme for Research and Innovation (call 2015); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8353870","Deep learning;inverse problems;biomedical image reconstruction;low-dose computed tomography","Image reconstruction;Inverse problems;Biomedical measurement;Computed tomography;Convex functions;Iterative methods","computerised tomography;gradient methods;image reconstruction;inverse problems;learning (artificial intelligence);medical image processing;neural nets","PGD;convolutional neural network;image-to-image regressors;iterative image reconstruction algorithms;nonconvex inverse problem;CT image reconstruction;CNN-based projected gradient descent;dictionary learning;deep learning-based direct reconstruction technique;sparse-view computed-tomography reconstruction;variation-based regularization;feedback mechanism","","9","58","CCBY","","","","IEEE","IEEE Journals"
"Learning Context Flexible Attention Model for Long-Term Visual Place Recognition","Z. Chen; L. Liu; I. Sa; Z. Ge; M. Chli","Vision for Robotics Lab, ETH Zurich, Zurich, Switzerland; School of Computer Science, University of Adelaide, Adelaide, SA, Australia; Autonomous Systems Lab, ETH Zurich, Zurich, Switzerland; eResearch Centre, University of Monash, Melbourne, Australia; Vision for Robotics Lab, ETH Zurich, Zurich, Switzerland","IEEE Robotics and Automation Letters","","2018","3","4","4015","4022","Identifying regions of interest in an image has long been of great importance in a wide range of tasks, including place recognition. In this letter, we propose a novel attention mechanism with flexible context, which can be incorporated into existing feedforward network architecture to learn image representations for long-term place recognition. In particular, in order to focus on regions that contribute positively to place recognition, we introduce a multiscale context-flexible network to estimate the importance of each spatial region in the feature map. Our model is trained end-to-end for place recognition and can detect regions of interest of arbitrary shape. Extensive experiments have been conducted to verify the effectiveness of our approach and the results demonstrate that our model can achieve consistently better performance than the state of the art on standard benchmark datasets. Finally, we visualize the learned attention maps to generate insights into what attention the network has learned.","","","10.1109/LRA.2018.2859916","Swiss National Science Foundation; EC's Horizon 2020 Programme; European Union's Horizon 2020 research and innovation Programme; Swiss State Secretariat for Education, Research and Innovation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8421024","Localization;deep learning in robotics and automation;visual-based navigation","Feature extraction;Visualization;Image recognition;Task analysis;Context modeling;Shape;Data mining","feature extraction;feedforward neural nets;image recognition;image representation;learning (artificial intelligence);neural net architecture;object detection;object recognition","context flexible attention model;long-term visual place recognition;attention mechanism;image representations;multiscale context-flexible network;spatial region;feedforward network architecture;feature map;region of interest detection;arbitrary shape detection;standard benchmark datasets;learned attention map visualization","","3","39","","","","","IEEE","IEEE Journals"
"DLoBD: A Comprehensive Study of Deep Learning over Big Data Stacks on HPC Clusters","X. Lu; H. Shi; R. Biswas; M. H. Javed; D. K. Panda","Department of Computer Science and Engineering, The Ohio State University, Columbus, OH, USA; Department of Computer Science and Engineering, The Ohio State University, Columbus, OH, USA; Department of Computer Science and Engineering, The Ohio State University, Columbus, OH, USA; Department of Computer Science and Engineering, The Ohio State University, Columbus, OH, USA; Department of Computer Science and Engineering, The Ohio State University, Columbus, OH, USA","IEEE Transactions on Multi-Scale Computing Systems","","2018","4","4","635","648","Deep Learning over Big Data (DLoBD) is an emerging paradigm to mine value from the massive amount of gathered data. Many Deep Learning frameworks, like Caffe, TensorFlow, etc., start running over Big Data stacks, such as Apache Hadoop and Spark. Even though a lot of activities are happening in the field, there is a lack of comprehensive studies on analyzing the impact of RDMA-capable networks and CPUs/GPUs on DLoBD stacks. To fill this gap, we propose a systematical characterization methodology and conduct extensive performance evaluations on four representative DLoBD stacks (i.e., CaffeOnSpark, TensorFlowOnSpark, MMLSpark/CNTKOnSpark, and BigDL) to expose the interesting trends regarding performance, scalability, accuracy, and resource utilization. Our observations show that RDMA-based design for DLoBD stacks can achieve up to 2.7x speedup compared to the IPoIB-based scheme. The RDMA scheme also scales better and utilizes resources more efficiently than IPoIB. For most cases, GPU-based schemes can outperform CPU-based designs, but we see that for LeNet on MNIST, CPU + MKL can achieve better performance than GPU and GPU + cuDNN on 16 nodes. Through our evaluation and an in-depth analysis on TensorFlowOnSpark, we find that there are large rooms to improve the designs of current-generation DLoBD stacks.","","","10.1109/TMSCS.2018.2845886","US National Science Foundation; US National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8378049","DLoBD;deep learning;big data;CaffeOnSpark;TensorFlowOnSpark;MMLSpark (CNTKOnSpark);BigDL;RDMA","Machine learning;Big Data;Graphics processing units;Training data;Parallel processing;Deep learning","","","","2","30","","","","","IEEE","IEEE Journals"
"Continuous Dropout","X. Shen; X. Tian; T. Liu; F. Xu; D. Tao","CAS Key Laboratory of Technology in Geo-Spatial Information Processing and Application Systems, University of Science and Technology of China, Hefei, China; CAS Key Laboratory of Technology in Geo-Spatial Information Processing and Application Systems, University of Science and Technology of China, Hefei, China; UBTech Sydney Artificial Intelligence Institute, School of Information Technologies, Faculty of Engineering and Information Technologies, The University of Sydney, Sydney, NSW, Australia; CAS Key Laboratory of Brain Function and Disease, School of Life Sciences, University of Science and Technology of China, Hefei, China; UBTech Sydney Artificial Intelligence Institute, School of Information Technologies, Faculty of Engineering and Information Technologies, The University of Sydney, Sydney, NSW, Australia","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","9","3926","3937","Dropout has been proven to be an effective algorithm for training robust deep networks because of its ability to prevent overfitting by avoiding the co-adaptation of feature detectors. Current explanations of dropout include bagging, naive Bayes, regularization, and sex in evolution. According to the activation patterns of neurons in the human brain, when faced with different situations, the firing rates of neurons are random and continuous, not binary as current dropout does. Inspired by this phenomenon, we extend the traditional binary dropout to continuous dropout. On the one hand, continuous dropout is considerably closer to the activation characteristics of neurons in the human brain than traditional binary dropout. On the other hand, we demonstrate that continuous dropout has the property of avoiding the co-adaptation of feature detectors, which suggests that we can extract more independent feature detectors for model averaging in the test stage. We introduce the proposed continuous dropout to a feedforward neural network and comprehensively compare it with binary dropout, adaptive dropout, and DropConnect on Modified National Institute of Standards and Technology, Canadian Institute for Advanced Research-10, Street View House Numbers, NORB, and ImageNet large scale visual recognition competition-12. Thorough experiments demonstrate that our method performs better in preventing the co-adaptation of feature detectors and improves test performance.","","","10.1109/TNNLS.2017.2750679","973 Project; National Key Research and Development Program of China; National Natural Science Foundation of China; Youth Innovation Promotion Association of the Chinese Academy of Sciences; Fok Ying Tung Education Foundation; Australian Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8057594","Co-adaptation;deep learning;dropout;overfitting;regularization","Training;Feature extraction;Biological neural networks;Detectors;Neurons;Artificial neural networks;Robustness","Bayes methods;brain;feature extraction;feedforward neural nets;learning (artificial intelligence);medical computing","continuous dropout;feature detectors;adaptive dropout;sex in evolution;regularization;naive Bayes;bagging;DropConnect;feedforward neural network;neurons activation patterns;human brain;deep networks;binary dropout","","","34","","","","","IEEE","IEEE Journals"
"GCRNN: Group-Constrained Convolutional Recurrent Neural Network","S. Lin; G. C. Runger","School of Computing, Informatics, and Decision Systems Engineering, Arizona State University, Tempe, AZ, USA; Department of Biomedical Informatics, School of Computing, Informatics, and Decision Systems Engineering, Arizona State University, Tempe, AZ, USA","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","10","4709","4718","In this paper, we propose a new end-to-end deep neural network model for time-series classification (TSC) with emphasis on both the accuracy and the interpretation. The proposed model contains a convolutional network component to extract high-level features and a recurrent network component to enhance the modeling of the temporal characteristics of TS data. In addition, a feedforward fully connected network with the sparse group lasso (SGL) regularization is used to generate the final classification. The proposed architecture not only achieves satisfying classification accuracy, but also obtains good interpretability through the SGL regularization. All these networks are connected and jointly trained in an end-to-end framework, and it can be generally applied to TSC tasks across different domains without the efforts of feature engineering. Our experiments in various TS data sets show that the proposed model outperforms the traditional convolutional neural network model for the classification accuracy, and also demonstrate how the SGL contributes to a better model interpretation.","","","10.1109/TNNLS.2017.2772336","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8169670","Convolutional neural network (CNN);deep learning;recurrent neural network (RNN);regularization;sparse group lasso (SGL);time-series classification (TSC)","Feature extraction;Data models;Recurrent neural networks;Brain modeling;Training","convolution;feature extraction;feedforward neural nets;learning (artificial intelligence);pattern classification;recurrent neural nets;time series","TSC;convolutional neural network model;GCRNN;model interpretation;TS data sets;SGL regularization;sparse group lasso regularization;convolutional network component;time-series classification;end-to-end deep neural network model;group-constrained convolutional recurrent neural network","","3","42","","","","","IEEE","IEEE Journals"
"DroNet: Learning to Fly by Driving","A. Loquercio; A. I. Maqueda; C. R. del-Blanco; D. Scaramuzza","Robotics and Perception Group, Department of Informatics, and Department of Neuroinformatics, University of Zurich and ETH Zurich, Zurich, Switzerland; Grupo de Tratamiento de Imágenes, Information Processing and Telecommunications Center and ETSI Telecomunicación, Universidad Politécnica de Madrid, Madrid, Spain; Grupo de Tratamiento de Imágenes, Information Processing and Telecommunications Center and ETSI Telecomunicación, Universidad Politécnica de Madrid, Madrid, Spain; Robotics and Perception Group, Department of Informatics, and Department of Neuroinformatics, University of Zurich and ETH Zurich, Zurich, Switzerland","IEEE Robotics and Automation Letters","","2018","3","2","1088","1095","Civilian drones are soon expected to be used in a wide variety of tasks, such as aerial surveillance, delivery, or monitoring of existing architectures. Nevertheless, their deployment in urban environments has so far been limited. Indeed, in unstructured and highly dynamic scenarios, drones face numerous challenges to navigate autonomously in a feasible and safe way. In contrast to traditional “map-localize-plan” methods, this letter explores a data-driven approach to cope with the above challenges. To accomplish this, we propose DroNet: a convolutional neural network that can safely drive a drone through the streets of a city. Designed as a fast eight-layers residual network, DroNet produces two outputs for each single input image: A steering angle to keep the drone navigating while avoiding obstacles, and a collision probability to let the UAV recognize dangerous situations and promptly react to them. The challenge is however to collect enough data in an unstructured outdoor environment such as a city. Clearly, having an expert pilot providing training trajectories is not an option given the large amount of data required and, above all, the risk that it involves for other vehicles or pedestrians moving in the streets. Therefore, we propose to train a UAV from data collected by cars and bicycles, which, already integrated into the urban environment, would not endanger other vehicles and pedestrians. Although trained on city streets from the viewpoint of urban vehicles, the navigation policy learned by DroNet is highly generalizable. Indeed, it allows a UAV to successfully fly at relative high altitudes and even in indoor environments, such as parking lots and corridors. To share our findings with the robotics community, we publicly release all our datasets, code, and trained networks.","","","10.1109/LRA.2018.2795643","Swiss National Center of Competence Research Robotics; Swiss National Science Foundation; SNSF-ERC; Ministerio de Economía, Industria y Competitividad (AEI/FEDER); Spanish Government; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8264734","Learning from demonstration;deep learning in robotics and automation;aerial systems: perception and autonomy","Drones;Navigation;Urban areas;Robots;Training;Automobiles","aerospace computing;autonomous aerial vehicles;collision avoidance;control engineering computing;feedforward neural nets;image sensors;learning (artificial intelligence);mobile robots;robot vision;surveillance","DroNet;civilian drones;aerial surveillance;urban environment;unstructured scenarios;highly dynamic scenarios;data-driven approach;bicycles;cars;obstacle avoidance;traditional map-localize-plan method;dangerous situation recognition;drone navigation;trained networks;indoor environments;relative high altitudes;navigation policy;urban vehicles;city streets;pedestrians;training trajectories;unstructured outdoor environment;UAV;collision probability;steering angle;single input image;eight-layers residual network;convolutional neural network","","32","28","","","","","IEEE","IEEE Journals"
"Automatic Water-Body Segmentation From High-Resolution Satellite Images via Deep Networks","Z. Miao; K. Fu; H. Sun; X. Sun; M. Yan","Key Laboratory of Spatial Information Processing and Application System Technology, Institute of Electronics, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Spatial Information Processing and Application System Technology, Institute of Electronics, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Spatial Information Processing and Application System Technology, Institute of Electronics, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Spatial Information Processing and Application System Technology, Institute of Electronics, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Spatial Information Processing and Application System Technology, Institute of Electronics, Chinese Academy of Sciences, Beijing, China","IEEE Geoscience and Remote Sensing Letters","","2018","15","4","602","606","Water-body segmentation is an important issue in remote sensing and image interpretation. Classic methods for counteracting this problem usually include the construction of index features by combining different spectra, however, these methods are essentially rule-based and fail to take advantage of context information. Additionally, as the quality of image resolution improves, these methods are proved to be inadequate. With the rise of convolutional neural networks (CNN), the level of research about segmentation has taken a huge leap, but the field is still facing an increasing demand for data and the problem of blurring boundaries. In this letter, a new segmentation network called restricted receptive field deconvolution network (RRF DeconvNet) is proposed, with which to extract water bodies from high-resolution remote sensing images. Compared with natural images, remote sensing images have a weaker pixel neighborhood relativity; in consideration of this challenge, an RRF DeconvNet compresses the redundant layers in the original DeconvNet and no longer relies on a pretrained model. In addition, to tackle the blurring boundaries that occur in CNN, a new loss function called edges weighting loss is proposed to train segmentation networks, which has been shown to significantly sharpen the segmentation boundaries in results. Experiments, based on Google Earth images for water-body segmentation, are presented in this letter to prove our method.","","","10.1109/LGRS.2018.2794545","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8286914","Deep learning;neural network;remote sensing;segmentation;water body","Convolution;Image segmentation;Remote sensing;Deconvolution;Kernel;Indexes;Image resolution","feature extraction;feedforward neural nets;geophysical image processing;image classification;image representation;image resolution;image segmentation;learning (artificial intelligence);remote sensing","Google Earth images;automatic water-body segmentation;high-resolution satellite images;deep networks;image interpretation;convolutional neural networks;CNN;blurring boundaries;segmentation network;receptive field deconvolution network;RRF DeconvNet;high-resolution remote sensing images;natural images;segmentation boundaries;loss function;edges weighting loss","","3","20","","","","","IEEE","IEEE Journals"
"Deep Multimodal Subspace Clustering Networks","M. Abavisani; V. M. Patel","Department of Electrical and Computer Engineering, Rutgers University, Piscataway, NJ, USA; Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD, USA","IEEE Journal of Selected Topics in Signal Processing","","2018","12","6","1601","1614","We present convolutional neural network based approaches for unsupervised multimodal subspace clustering. The proposed framework consists of three main stages-multimodal encoder, self-expressive layer, and multimodal decoder. The encoder takes multimodal data as input and fuses them to a latent space representation. The self-expressive layer is responsible for enforcing the self-expressiveness property and acquiring an affinity matrix corresponding to the data points. The decoder reconstructs the original input data. The network uses the distance between the decoder's reconstruction and the original input in its training. We investigate early, late, and intermediate fusion techniques and propose three different encoders corresponding to them for spatial fusion. The self-expressive layers and multimodal decoders are essentially the same for different spatial fusion-based approaches. In addition to various spatial fusion-based methods, an affinity fusion-based network is also proposed in which the self-expressive layer corresponding to different modalities is enforced to be the same. Extensive experiments on three datasets show that the proposed methods significantly outperform the state-of-the-art multimodal subspace clustering methods.","","","10.1109/JSTSP.2018.2875385","Office of Naval Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8488484","Deep multimodal subspace clustering;multi-view subspace clustering;multimodal learning;subspace clustering","Clustering methods;Clustering algorithms;Network architecture;Convolutional neural networks","image coding;image fusion;matrix algebra;neural nets;pattern clustering;unsupervised learning","multimodal encoder;spatial fusion-based approaches;unsupervised multimodal subspace clustering;convolutional neural network;deep multimodal subspace clustering networks;state-of-the-art multimodal subspace clustering methods;affinity fusion-based network;spatial fusion-based methods;different encoders;intermediate fusion techniques;original input data;data points;self-expressiveness property;self-expressive layer;latent space representation;multimodal data;multimodal decoder","","4","66","","","","","IEEE","IEEE Journals"
"Person Re-Identification by Pose Invariant Deep Metric Learning With Improved Triplet Loss","M. Chen; Y. Ge; X. Feng; C. Xu; D. Yang","Key Laboratory of Dependable Service Computing in Cyber Physical Society, Ministry of Education, Chongqing University, Chongqing, China; Key Laboratory of Dependable Service Computing in Cyber Physical Society, Ministry of Education, Chongqing University, Chongqing, China; Department of Computer Science and Engineering, Chongqing University of Technology, Chongqing, China; Department of Computer Science and Engineering, Chongqing University of Technology, Chongqing, China; School of Big Data and Software Engineering, Chongqing University, Chongqing, China","IEEE Access","","2018","6","","68089","68095","Person re-identification (re-ID) is a challenging problem in the community which aims at identifying person in a surveillance video. Despite recent advance in the field of computer vision, person re-ID still presents great challenge since person’s presence is various under different illumination, viewpoints, occlusion, and background clutter. In this paper, to exploit more discriminative information of person’s appearance, we propose a novel pose invariant deep metric learning (PIDML) method under an improved triplet loss for person re-ID. Our approach contributes the misalignment problem and distance metric simultaneously, which are two key problems for person re-ID. Extensive experiments show that our proposed method could achieve favorable accuracy while compared with the state-of-the-art techniques on the challenging Market-1501, CUHK03, and VIPeR datasets.","","","10.1109/ACCESS.2018.2879490","Fundamental Research Funds for the Central Universities; Graduate Research and Innovation Foundation of Chongqing, China; National Natural Science Foundation of China; Chongqing Research Program of Basic Research and Frontier Technology; Humanity and Social Science Youth Foundation, Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8522036","Person re-identification;metric learning;multiview learning;triplet loss function","Measurement;Feature extraction;Training;Computer vision;Lighting;Task analysis","","","","2","46","","","","","IEEE","IEEE Journals"
"Learning-Based Image Reconstruction via Parallel Proximal Algorithm","E. Bostan; U. S. Kamilov; L. Waller","Department of Electrical Engineering & Computer Sciences, University of California, Berkeley, CA, USA; Departments of Computer Science & Engineering and Electrical & Systems Engineering, Washington University in St. Louis, St. Louis, MO, USA; Department of Electrical Engineering & Computer Sciences, University of California, Berkeley, CA, USA","IEEE Signal Processing Letters","","2018","25","7","989","993","In the past decade, sparsity-driven regularization has led to the advancement of image reconstruction algorithms. Traditionally, such regularizers rely on analytical models of sparsity [e.g., total variation (TV)]. However, more recent methods are increasingly centered around data-driven arguments inspired by deep learning. In this letter, we propose to generalize TV regularization by replacing the 11 -penalty with an alternative prior that is trainable. Specifically, our method learns the prior via extending the recently proposed fast parallel proximal algorithm to incorporate data-adaptive proximal operators. The proposed framework does not require additional inner iterations for evaluating the proximal mappings of the corresponding learned prior. Moreover, our formalism ensures that the training and reconstruction processes share the same algorithmic structure, making the endto-end implementation intuitive. As an example, we demonstrate our algorithm on the problem of deconvolution in a fluorescence microscope.","","","10.1109/LSP.2018.2833812","Schweizerischer Nationalfonds zur Förderung der Wissenschaftlichen Forschung; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8355585","Image reconstruction;inverse problems;iterative shrinkage;learning;statistical modeling","TV;Image reconstruction;Signal processing algorithms;Training;Transforms;Computational modeling;Analytical models","image reconstruction;iterative methods;learning (artificial intelligence);parallel algorithms","deep learning;TV regularization;data-adaptive proximal operators;proximal mappings;parallel proximal algorithm;image reconstruction algorithms;total variation;sparsity-driven regularization;deconvolution;fluorescence microscope","","1","40","","","","","IEEE","IEEE Journals"
"Summarization of User-Generated Sports Video by Using Deep Action Recognition Features","A. Tejero-de-Pablos; Y. Nakashima; T. Sato; N. Yokoya; M. Linna; E. Rahtu","Graduate School of Information Science, Nara Institute of Science and Technology, Nara, Japan; Graduate School of Information Science, Nara Institute of Science and Technology, Japan; Graduate School of Information Science, Nara Institute of Science and Technology, Nara, Japan; Graduate School of Information Science, Nara Institute of Science and Technology, Nara, Japan; Center for Machine Vision and Signal Analysis, University of Oulu, Oulu, Finland; Department of Signal Processing, Tampere University of Technology, Tampere, Finland","IEEE Transactions on Multimedia","","2018","20","8","2000","2011","Automatically generating a summary of a sports video poses the challenge of detecting interesting moments, or highlights, of a game. Traditional sports video summarization methods leverage editing conventions of broadcast sports video that facilitate the extraction of high-level semantics. However, user-generated videos are not edited and, thus, traditional methods are not suitable to generate a summary. In order to solve this problem, this paper proposes a novel video summarization method that uses players' actions as a cue to determine the highlights of the original video. A deep neural-network-based approach is used to extract two types of action-related features and to classify video segments into interesting or uninteresting parts. The proposed method can be applied to any sports in which games consist of a succession of actions. Especially, this paper considers the case of Kendo (Japanese fencing) as an example of a sport to evaluate the proposed method. The method is trained using Kendo videos with ground truth labels that indicate the video highlights. The labels are provided by annotators possessing a different experience with respect to Kendo to demonstrate how the proposed method adapts to different needs. The performance of the proposed method is compared with several combinations of different features, and the results show that it outperforms previous summarization methods.","","","10.1109/TMM.2018.2794265","Japan Society for the Promotion of Science; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8259321","Sports video summarization;user-generated video;action recognition;deep learning;3D convolutional neural networks;long short-term memory","Feature extraction;Semantics;Games;Three-dimensional displays;Cameras;Hidden Markov models","feature extraction;image segmentation;neural nets;sport;video signal processing","high-level semantics;deep neural-network-based approach;action-related features;video segments;interesting parts;uninteresting parts;Kendo videos;video highlights;deep action recognition features;player action;Japanese fencing;user-generated sport video summarization method","","3","60","","","","","IEEE","IEEE Journals"
"DNN Engine: A 28-nm Timing-Error Tolerant Sparse Deep Neural Network Processor for IoT Applications","P. N. Whatmough; S. K. Lee; D. Brooks; G. Wei","Arm Research, Boston, MA, USA; School of Engineering and Applied Science, Harvard University, Cambridge, MA, USA; School of Engineering and Applied Science, Harvard University, Cambridge, MA, USA; School of Engineering and Applied Science, Harvard University, Cambridge, MA, USA","IEEE Journal of Solid-State Circuits","","2018","53","9","2722","2731","This paper presents a 28-nm system-on-chip (SoC) for Internet of things (IoT) applications with a programmable accelerator design that implements a powerful fully connected deep neural network (DNN) classifier. To reach the required low energy consumption, we exploit the key properties of neural network algorithms: parallelism, data reuse, small/sparse data, and noise tolerance. We map the algorithm to a very large scale integration (VLSI) architecture based around an singleinstruction, multiple-data data path with hardware support to exploit data sparsity by completely eliding unnecessary computation and data movement. This approach exploits sparsity, without compromising the parallel computation. We also exploit the inherent algorithmic noise-tolerance of neural networks, by introducing circuit-level timing violation detection to allow worst case voltage guard-bands to be minimized. The resulting intermittent timing violations may result in logic errors, which conventionally need to be corrected. However, in lieu of explicit error correction, we cope with this by accentuating the noise tolerance of neural networks. The measured test chip achieves high classification accuracy (98.36% for the MNIST test set), while tolerating aggregate timing violation rates>10-1. The accelerator achieves a minimum energy of 0.36 μJ/inference at 667 MHz; maximum throughput at 1.2 GHz and 0.57 μJ/inference; or a 10% margined operating point at 1 GHz and 0.58 μJ/inference.","","","10.1109/JSSC.2018.2841824","Defense Advanced Research Projects Agency; Intel Corporation; Arm Inc.; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8387436","Deep neural networks (DNNs);hardware accelerators;Internet of things (IoT);machine learning (ML);razor;system-on-chip (SoC);timing error detection and correction;timing error tolerance","Neural networks;Random access memory;Neurons;Hardware;Timing;System-on-chip;Internet of Things","energy consumption;error correction;Internet of Things;microprocessor chips;neural nets;power aware computing;system-on-chip;VLSI","DNN engine;IoT applications;programmable accelerator design;deep neural network classifier;neural network algorithms;noise tolerance;data sparsity;parallel computation;system-on-chip;internet of things applications;energy consumption;very large scale integration architecture;error correction;deep neural network processor;SoC;VLSI","","8","39","","","","","IEEE","IEEE Journals"
"Deep Semantic Segmentation in an AUV for Online Posidonia Oceanica Meadows Identification","M. Martin-Abadal; E. Guerrero-Font; F. Bonin-Font; Y. Gonzalez-Cid","Departament de Ciències Matemàtiques i Informàtica, Universitat de les Illes Balears, Palma, Spain; Departament de Ciències Matemàtiques i Informàtica, Universitat de les Illes Balears, Palma, Spain; Departament de Ciències Matemàtiques i Informàtica, Universitat de les Illes Balears, Palma, Spain; Departament de Ciències Matemàtiques i Informàtica, Universitat de les Illes Balears, Palma, Spain","IEEE Access","","2018","6","","60956","60967","Recent studies have shown evidence of a significant decline of the Posidonia oceanica (P.O.) meadows on a global scale. The monitoring and mapping of these meadows are fundamental tools for measuring their status. We present an approach based on a deep neural network to automatically perform a highprecision semantic segmentation of the P.O. meadows in sea-floor images, offering several improvements over the state-of-the-art techniques. Our network demonstrates outstanding performance over diverse test sets, reaching a precision of 96.57% and an accuracy of 96.81%, surpassing the reliability of labeling the images manually. Moreover, the network is implemented in an autonomous underwater vehicle, performing an online P.O. segmentation, which will be used to generate real-time semantic coverage maps.","","","10.1109/ACCESS.2018.2875412","Ministerio de Economía y Competitividad; SOIB through the project ESF, Youth Guarantee; Government of the Balearic Islands through Vicepresidencia i Conselleria d’Innovació, Recerca i Turisme; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8489861","Deep learning;online semantic segmentation;Posidonia oceanica;autonomous underwater vehicle","Semantics;Training;Image segmentation;Neural networks;Computer architecture;Decoding;Cameras","autonomous underwater vehicles;image segmentation;neural nets;oceanographic techniques;seafloor phenomena;underwater equipment","diverse test sets;real-time semantic coverage maps;deep semantic segmentation;AUV;online Posidonia oceanica meadows identification;fundamental tools;deep neural network;highprecision semantic segmentation;sea-floor images","","6","33","","","","","IEEE","IEEE Journals"
"Adaptive Very Deep Convolutional Residual Network for Noise Robust Speech Recognition","T. Tan; Y. Qian; H. Hu; Y. Zhou; W. Ding; K. Yu","Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China","IEEE/ACM Transactions on Audio, Speech, and Language Processing","","2018","26","8","1393","1405","Although great progress has been made in automatic speech recognition, significant performance degradation still exists in noisy environments. Our previous work has demonstrated the superior noise robustness of very deep convolutional neural networks (VDCNN). Based on our work on VDCNNs, this paper proposes a more advanced model referred to as the very deep convolutional residual network (VDCRN). This new model incorporates batch normalization and residual learning, showing more robustness than previous VDCNNs.Then, to alleviate the mismatch between the training and testing conditions, model adaptation and adaptive training are developed and compared for the new VDCRN. This paper focuses on factor aware training (FAT) and cluster adaptive training (CAT). For FAT, a unified framework is explored. For CAT, two schemes are first explored to construct the bases in the canonical model; furthermore, a factorized version of CAT is designed to address multiple nonspeech variabilities in one model. Finally, a complete multipass system is proposed to achieve the best system performance in the noisy scenarios. The proposed new approaches are evaluated on three different tasks: Aurora4 (simulated data with additive noise and channel distortion), CHiME4 (both simulated and real data with additive noise and reverberation), and the AMI meeting transcription task (real data with significant reverberation).The evaluation not only includes different noisy conditions, but also covers both simulated and real noisy data. The experiments show that the new VDCRN is more robust, and the adaptation on this model can further significantly reduce the word error rate (WER). The proposed best architecture obtains consistent and very large improvements on all tasks compared to the baseline VDCNN or long short-term memory. Particularly, on Aurora4 a new milestone 5.67% WER is achieved by only improving acoustic modeling.","","","10.1109/TASLP.2018.2825432","China NSFC projects; Shanghai Sailing Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8336909","Robust speech recognition;convolutional neural network;residual learning;factor aware training;cluster adaptive training","Training;Adaptation models;Noise measurement;Speech recognition;Cats;Task analysis;Speech","feedforward neural nets;reverberation;speech recognition","noisy environments;superior noise robustness;deep convolutional neural networks;advanced model;VDCRN;residual learning;testing conditions;model adaptation;FAT;cluster adaptive training;CAT;canonical model;system performance;noisy scenarios;Aurora4;additive noise;channel distortion;reverberation;different noisy conditions;simulated data;real noisy data;acoustic modeling;noise robust speech recognition;automatic speech recognition;performance degradation;adaptive very deep convolutional residual network;CHiME4;AMI;transcription task;word error rate;WER","","7","63","","","","","IEEE","IEEE Journals"
"Depth-Adaptive Deep Neural Network for Semantic Segmentation","B. Kang; Y. Lee; T. Q. Nguyen","Department of Electrical and Computer Engineering, University of California—San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California—San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California—San Diego, La Jolla, CA, USA","IEEE Transactions on Multimedia","","2018","20","9","2478","2490","In this paper, we present the depth-adaptive deep neural network using a depth map for semantic segmentation. Typical deep neural networks receive inputs at the predetermined locations regardless of the distance from the camera. This fixed receptive field presents a challenge to generalize the features of objects at various distances in neural networks. Specifically, the predetermined receptive fields are too small at a short distance, and vice versa. To overcome this challenge, we develop a neural network that is able to adapt the receptive field not only for each layer but also for each neuron at the spatial location. To adjust the receptive field, we propose the depth-adaptive multiscale (DaM) convolution layer consisting of the adaptive perception neuron and the in-layer multiscale neuron. The adaptive perception neuron is to adjust the receptive field at each spatial location using the corresponding depth information. The in-layer multiscale neuron is to apply the different size of the receptive field at each feature space to learn features at multiple scales. The proposed DaM convolution is applied to two fully convolutional neural networks. We demonstrate the effectiveness of the proposed neural networks on the publicly available RGB-D dataset for semantic segmentation and the novel hand segmentation dataset for hand-object interaction. The experimental results show that the proposed method outperforms the state-of-the-art methods without any additional layers or preprocessing/postprocessing.","","","10.1109/TMM.2018.2798282","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8269325","Semantic segmentation;convolutional neural networks;deep learning","Convolution;Neurons;Biological neural networks;Semantics;Image segmentation;Cameras;Image color analysis","convolution;feedforward neural nets;image colour analysis;image segmentation;learning (artificial intelligence)","semantic segmentation;depth map;spatial location;depth-adaptive multiscale convolution layer;adaptive perception neuron;receptive field;convolutional neural networks;DaM convolution;RGB-D dataset","","4","47","","","","","IEEE","IEEE Journals"
"Recurrent-OctoMap: Learning State-Based Map Refinement for Long-Term Semantic Mapping With 3-D-Lidar Data","L. Sun; Z. Yan; A. Zaganidis; C. Zhao; T. Duckett","Lincoln Centre for Autonomous Systems (L-CAS), University of Lincoln, Lincoln, U.K.; Laboratoire Electronique, Informatique et Image, CNRS, University of Technology of Belfort-Montbéliard (UTBM), Belfort, France; Lincoln Centre for Autonomous Systems (L-CAS), University of Lincoln, Lincoln, U.K.; Lincoln Centre for Autonomous Systems (L-CAS), University of Lincoln, Lincoln, U.K.; Lincoln Centre for Autonomous Systems (L-CAS), University of Lincoln, Lincoln, U.K.","IEEE Robotics and Automation Letters","","2018","3","4","3749","3756","This letter presents a novel semantic mapping approach, Recurrent-OctoMap, learned from long-term three-dimensional (3-D) Lidar data. Most existing semantic mapping approaches focus on improving semantic understanding of single frames, rather than 3-D refinement of semantic maps (i.e. fusing semantic observations). The most widely used approach for the 3-D semantic map refinement is “Bayes update,” which fuses the consecutive predictive probabilities following a Markov-chain model. Instead, we propose a learning approach to fuse the semantic features, rather than simply fusing predictions from a classifier. In our approach, we represent and maintain our 3-D map as an OctoMap, and model each cell as a recurrent neural network, to obtain a Recurrent-OctoMap. In this case, the semantic mapping process can be formulated as a sequence-to-sequence encoding-decoding problem. Moreover, in order to extend the duration of observations in our Recurrent-OctoMap, we developed a robust 3-D localization and mapping system for successively mapping a dynamic environment using more than two weeks of data, and the system can be trained and deployed with arbitrary memory length. We validate our approach on the ETH long-term 3-D Lidar dataset. The experimental results show that our proposed approach outperforms the conventional “Bayes update” approach.","","","10.1109/LRA.2018.2856268","European Union's Horizon 2020 research and innovation programme; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8411109","Mapping;simultaneous localization and mapping (SLAM);deep learning in robotics and automation;object detection;segmentation and categorization","Semantics;Three-dimensional displays;Laser radar;Two dimensional displays;Simultaneous localization and mapping;Feature extraction;Recurrent neural networks","Bayes methods;image motion analysis;image representation;image sequences;learning (artificial intelligence);Markov processes;optical radar;recurrent neural nets","3-D semantic map refinement;consecutive predictive probabilities;learning approach;semantic features;recurrent neural network;Recurrent-OctoMap;semantic mapping process;mapping system;state-based map refinement;long-term semantic mapping;3-D-Lidar data;semantic understanding;3-D refinement;semantic observations;Bayes update;sequence-to-sequence encoding-decoding;robust 3-D localization and mapping system;dynamic environment;arbitrary memory length;ETH long-term 3-D Lidar dataset","","4","37","","","","","IEEE","IEEE Journals"
"Additive Margin Softmax for Face Verification","F. Wang; J. Cheng; W. Liu; H. Liu","Department of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; Department of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; College of Computing, Georgia Institute of Technology, Atlanta, GA, USA; Department of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China","IEEE Signal Processing Letters","","2018","25","7","926","930","In this letter, we propose a conceptually simple and intuitive learning objective function, i.e., additive margin softmax, for face verification. In general, face verification tasks can be viewed as metric learning problems, even though lots of face verification models are trained in classification schemes. It is possible when a large-margin strategy is introduced into the classification model to encourage intraclass variance minimization. As one alternative, angular softmax has been proposed to incorporate the margin. In this letter, we introduce another kind of margin to the softmax loss function, which is more intuitive and interpretable. Experiments on LFW and MegaFace show that our algorithm performs better when the evaluation criteria are designed for very low false alarm rate.","","","10.1109/LSP.2018.2822810","National Natural Science Foundation of China; State Key Laboratory of Synthetical Automation for Process Industries; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8331118","Deep learning;face verification;metric learning","Additives;Face;Measurement;Visualization;Annealing;Task analysis;Training","face recognition;image classification;learning (artificial intelligence);minimisation","softmax loss function;additive margin softmax;face verification tasks;metric learning problems;face verification models;classification schemes;classification model;angular softmax;learning objective function;intraclass variance minimization","","36","26","","","","","IEEE","IEEE Journals"
"Structured AutoEncoders for Subspace Clustering","X. Peng; J. Feng; S. Xiao; W. Yau; J. T. Zhou; S. Yang","College of Computer Science, Sichuan University, Chengdu, China; Department of ECE, National University of Singapore, Singapore; 3OmniVision Technologies Singapore Pte. Ltd., Singapore; Institute for Infocomm Research, A*STAR, Singapore; Institute of High Performance Computing, A*STAR, Singapore; AI Lab, TAL Education Group, College of Electronics and Information Engineering, Sichuan University, Chengdu, China","IEEE Transactions on Image Processing","","2018","27","10","5076","5086","Existing subspace clustering methods typically employ shallow models to estimate underlying subspaces of unlabeled data points and cluster them into corresponding groups. However, due to the limited representative capacity of the employed shallow models, those methods may fail in handling realistic data without the linear subspace structure. To address this issue, we propose a novel subspace clustering approach by introducing a new deep model - Structured AutoEncoder (StructAE). The StructAE learns a set of explicit transformations to progressively map input data points into nonlinear latent spaces while preserving the local and global subspace structure. In particular, to preserve local structure, the StructAE learns representations for each data point by minimizing reconstruction error with respect to itself. To preserve global structure, the StructAE incorporates a prior structured information by encouraging the learned representation to preserve specified reconstruction patterns over the entire data set. To the best of our knowledge, StructAE is one of the first deep subspace clustering approaches. Extensive experiments show that the proposed StructAE significantly outperforms 15 state-of-the-art subspace clustering approaches in terms of five evaluation metrics.","","","10.1109/TIP.2018.2848470","Fundamental Research Funds for the Central Universities; National Natural Science Foundation of China; Sichuan University; NUS; MOE Tier-I; MOE Tier-I; NUS IDS; ECRA; MOE Tier-II; Singapore’s RIE2020 AME-Programmatic; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8387808","Unsupervised deep learning;locality preservation;globality preservation;spectral clustering","Neural networks;Image reconstruction;Kernel;Clustering algorithms;Clustering methods;Manifolds;Data models","data handling;learning (artificial intelligence);neural nets;pattern clustering","StructAE;prior structured information;deep subspace clustering approaches;subspace clustering methods;underlying subspaces;unlabeled data points;employed shallow models;novel subspace clustering approach;deep model;nonlinear latent spaces;local subspace structure;global subspace structure;local structure preservation;input data points;structured autoencoders;limited representative capacity;realistic data handling;reconstruction error minimization;data set;evaluation metrics","","21","57","","","","","IEEE","IEEE Journals"
"Gabor Convolutional Networks","S. Luan; C. Chen; B. Zhang; J. Han; J. Liu","School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; Department of Electrical and Computer Engineering, The University of North Carolina at Charlotte, Charlotte, NC, USA; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; School of Computing and Communications, Lancaster University, Lancaster, U.K.; Noah’s Ark Lab, Huawei Technologies Co. Ltd., Shenzhen, China","IEEE Transactions on Image Processing","","2018","27","9","4357","4366","In steerable filters, a filter of arbitrary orientation can be generated by a linear combination of a set of “basis filters.” Steerable properties dominate the design of the traditional filters, e.g., Gabor filters and endow features the capability of handling spatial transformations. However, such properties have not yet been well explored in the deep convolutional neural networks (DCNNs). In this paper, we develop a new deep model, namely, Gabor convolutional networks (GCNs or Gabor CNNs), with Gabor filters incorporated into DCNNs such that the robustness of learned features against the orientation and scale changes can be reinforced. By manipulating the basic element of DCNNs, i.e., the convolution operator, based on Gabor filters, GCNs can be easily implemented and are readily compatible with any popular deep learning architecture. We carry out extensive experiments to demonstrate the promising performance of our GCNs framework, and the results show its superiority in recognizing objects, especially when the scale and rotation changes take place frequently. Moreover, the proposed GCNs have much fewer network parameters to be learned and can effectively reduce the training complexity of the network, leading to a more compact deep learning model while still maintaining a high feature representation capacity. The source code can be found at https://github.com/bczhangbczhang.","","","10.1109/TIP.2018.2835143","Natural Science Foundation of China; Shenzhen Peacock Plan; Open Projects Program of National Laboratory of Pattern Recognition; National Basic Research Program of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8357578","Gabor CNNs;Gabor filters;convolutional neural networks;orientation;kernel modulation","Convolution;Robustness;Feature extraction;Training;Kernel;Gabor filters;Convolutional neural networks","feature extraction;feedforward neural nets;Gabor filters;image representation;learning (artificial intelligence);object recognition","convolution operator;Gabor filters;compact deep learning model;Gabor convolutional networks;steerable filters;deep convolutional neural networks;GCN;steerable properties;DCNN;deep learning architecture;Gabor CNN","","14","43","","","","","IEEE","IEEE Journals"
"Channel State Information Prediction for 5G Wireless Communications: A Deep Learning Approach","C. Luo; J. Ji; Q. Wang; X. Chen; P. Li","Department of Electrical Engineering and Computer Science, Case Western Reserve University, Cleveland, Ohio United States (e-mail: changqing.luo@case.edu); Case Western Reserve University School of Medicine, 12304 Cleveland, Ohio United States (e-mail: jxj405@case.edu); Department of Electrical Engineering and Computer Science, Case Western Reserve University, Cleveland, Ohio United States (e-mail: qxw204@case.edu); Department of Electrical Engineering and Computer Science, Case Western Reserve University, Cleveland, Ohio United States (e-mail: xxc296@case.edu); Department of Electrical Engineering and Computer Science, Case Western Reserve University, Cleveland, Ohio United States 44106 (e-mail: lipan@case.edu)","IEEE Transactions on Network Science and Engineering","","2018","PP","99","1","1","Channel state information (CSI) estimation is one of the most fundamental problems in wireless communication systems. Various methods, so far, have been developed to conduct CSI estimation, which usually requires high computational complexity. However, these methods are not suitable for 5G wireless communications due to many techniques (e.g., massive MIMO, OFDM, and millimeter-Wave (mmWave)) to be employed in 5G wireless communication systems. In this paper, we propose an efficient online CSI prediction scheme, called OCEAN, for predicting CSI from historical data in 5G wireless communication systems. Specifically, we first identify several important features affecting the CSI of a radio link and a data sample consists of the information of these features and the CSI. We then design a learning framework that is a combination of a CNN (convolutional neural network) and an LSTM (long short term with memory) network. We further develop an offline-online two-step training mechanism, enabling the prediction results to be more stable when applied in practical 5G wireless communication systems. To validate OCEAN's efficacy, we conduct extensive experiments by considering four typical case studies, i.e., two outdoor and two indoor scenarios. The experiment results show that OCEAN not only obtains the predicted CSI values very quickly but also achieves highly accurate CSI prediction with up to 2.650% - 3.457% average difference ratio (ADR) between the predicted and measured CSI.","","","10.1109/TNSE.2018.2848960","Division of Computer and Network Systems; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8395053","Channel state estimation;5G wireless communications;deep learning","Wireless communication;5G mobile communication;Estimation;Channel estimation;MIMO communication;Oceans;Fading channels","","","","25","","","","","","IEEE","IEEE Early Access Articles"
"Object-Location-Aware Hashing for Multi-Label Image Retrieval via Automatic Mask Learning","C. Huang; S. Yang; Y. Pan; H. Lai","School of Information Technology in Education, South China Normal University, Guangzhou, China; Guangdong Key Laboratory of Big Data Analysis and Processing, School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; Guangdong Key Laboratory of Big Data Analysis and Processing, School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; Guangdong Key Laboratory of Big Data Analysis and Processing, School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China","IEEE Transactions on Image Processing","","2018","27","9","4490","4502","Learning-based hashing is a leading approach of approximate nearest neighbor search for large-scale image retrieval. In this paper, we develop a deep supervised hashing method for multi-label image retrieval, in which we propose to learn a binary “mask” map that can identify the approximate locations of objects in an image, so that we use this binary “mask” map to obtain length-limited hash codes which mainly focus on an image's objects but ignore the background. The proposed deep architecture consists of four parts: 1) a convolutional sub-network to generate effective image features; 2) a binary “mask” sub-network to identify image objects' approximate locations; 3) a weighted average pooling operation based on the binary “mask” to obtain feature representations and hash codes that pay most attention to foreground objects but ignore the background; and 4) the combination of a triplet ranking loss designed to preserve relative similarities among images and a cross entropy loss defined on image labels. We conduct comprehensive evaluations on four multi-label image data sets. The results indicate that the proposed hashing method achieves superior performance gains over the state-of-the-art supervised or unsupervised hashing baselines.","","","10.1109/TIP.2018.2839522","National Science Foundation of China; S&T Projects of Guangdong Province; GDUPS (2015); Guangzhou Science Technology and Innovation Commission; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8361839","Hash coding;image retrieval;deep convolutional networks","Training;Integrated circuits;Databases;Training data;Encyclopedias;Electronic publishing","binary codes;entropy;feature extraction;file organisation;image coding;image representation;image retrieval;location based services;nearest neighbour methods","multilabel image retrieval;automatic mask learning;approximate nearest neighbor search;large-scale image retrieval;deep supervised hashing method;binary mask map;hash codes;image objects;foreground objects;image labels;multilabel image data sets;supervised hashing baselines;unsupervised hashing baselines;image features;object-location-aware hashing;cross entropy loss;learning-based hashing","","1","39","","","","","IEEE","IEEE Journals"
"Flower classification using deep convolutional neural networks","H. Hiary; H. Saadeh; M. Saadeh; M. Yaqub","The University of Jordan, Jordan; The University of Jordan, Jordan; The University of Jordan, Jordan; Institute of Biomedical Engineering, University of Oxford, UK","IET Computer Vision","","2018","12","6","855","862","Flower classification is a challenging task due to the wide range of flower species, which have a similar shape, appearance or surrounding objects such as leaves and grass. In this study, the authors propose a novel two-step deep learning classifier to distinguish flowers of a wide range of species. First, the flower region is automatically segmented to allow localisation of the minimum bounding box around it. The proposed flower segmentation approach is modelled as a binary classifier in a fully convolutional network framework. Second, they build a robust convolutional neural network classifier to distinguish the different flower types. They propose novel steps during the training stage to ensure robust, accurate and real-time classification. They evaluate their method on three well known flower datasets. Their classification results exceed 97% on all datasets, which are better than the state-of-the-art in this domain.","","","10.1049/iet-cvi.2017.0155","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8435127","","","biology computing;botany;feedforward neural nets;learning (artificial intelligence);object recognition;pattern classification","training stage;robust convolutional neural network classifier;two-step deep learning classifier;flower species;deep convolutional neural networks;flower classification","","","","","","","","IET","IET Journals"
"Hyperspectral Unmixing via Deep Convolutional Neural Networks","X. Zhang; Y. Sun; J. Zhang; P. Wu; L. Jiao","Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, School of Artificial Intelligence, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, School of Artificial Intelligence, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, School of Artificial Intelligence, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, School of Artificial Intelligence, Xidian University, Xi’an, China; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, School of Artificial Intelligence, Xidian University, Xi’an, China","IEEE Geoscience and Remote Sensing Letters","","2018","15","11","1755","1759","Hyperspectral unmixing (HU) is a method used to estimate the fractional abundances corresponding to endmembers in each of the mixed pixels in the hyperspectral remote sensing image. In recent times, deep learning has been recognized as an effective technique for hyperspectral image classification. In this letter, an end-to-end HU method is proposed based on the convolutional neural network (CNN). The proposed method uses a CNN architecture that consists of two stages: the first stage extracts features and the second stage performs the mapping from the extracted features to obtain the abundance percentages. Furthermore, a pixel-based CNN and cube-based CNN, which can improve the accuracy of HU, are presented in this letter. More importantly, we also use dropout to avoid overfitting. The evaluation of the complete performance is carried out on two hyperspectral data sets: Jasper Ridge and Urban. Compared with that of the existing method, our results show significantly higher accuracy.","","","10.1109/LGRS.2018.2857804","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8432512","Convolutional neural networks (CNNs);end-to-end model;spectral unmixing;spectral–spatial information","Feature extraction;Hyperspectral imaging;Convolution;Artificial neural networks;Indexes;Kernel","feature extraction;hyperspectral imaging;image classification;learning (artificial intelligence);recurrent neural nets","hyperspectral unmixing;deep convolutional neural networks;hyperspectral remote sensing image;deep learning;hyperspectral image classification;end-to-end HU method;convolutional neural network;CNN architecture;pixel-based CNN;hyperspectral data sets;Jasper Ridge dataset;Urban dataset","","2","20","","","","","IEEE","IEEE Journals"
"Deep Multimodal Feature Analysis for Action Recognition in RGB+D Videos","A. Shahroudy; T. Ng; Y. Gong; G. Wang","School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; Institute for Infocomm Research, 1 Fusionopolis Way, Singapore; Institute of Artificial Intelligence and Robotics, Xián Jiaotong University, Shaanxi, China; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","5","1045","1058","Single modality action recognition on RGB or depth sequences has been extensively explored recently. It is generally accepted that each of these two modalities has different strengths and limitations for the task of action recognition. Therefore, analysis of the RGB+D videos can help us to better study the complementary properties of these two types of modalities and achieve higher levels of performance. In this paper, we propose a new deep autoencoder based shared-specific feature factorization network to separate input multimodal signals into a hierarchy of components. Further, based on the structure of the features, a structured sparsity learning machine is proposed which utilizes mixed norms to apply regularization within components and group selection between them for better classification performance. Our experimental results show the effectiveness of our cross-modality feature analysis framework by achieving state-of-the-art accuracy for action classification on five challenging benchmark datasets.","","","10.1109/TPAMI.2017.2691321","National Research Foundation Singapore; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7892950","Multimodal analysis;RGB+D;action recognition;structured sparsity","Feature extraction;Videos;Three-dimensional displays;Skeleton;Robustness;Correlation;Sensors","feature extraction;image classification;image representation;learning (artificial intelligence)","deep multimodal feature analysis;RGB+D videos;single modality action recognition;depth sequences;deep autoencoder;shared-specific feature factorization network;input multimodal signals;structured sparsity learning machine;cross-modality feature analysis framework;action classification;complementary properties","","21","90","","","","","IEEE","IEEE Journals"
"A 3D Atrous Convolutional Long Short-Term Memory Network for Background Subtraction","Z. Hu; T. Turki; N. Phan; J. T. L. Wang","Department of Computer Science, King Abdulaziz University, Jeddah, Saudi Arabia; Department of Computer Science, King Abdulaziz University, Jeddah, Saudi Arabia; College of Computing, New Jersey Institute of Technology, Newark, NJ, USA; Department of Computer Science, King Abdulaziz University, Jeddah, Saudi Arabia","IEEE Access","","2018","6","","43450","43459","Background subtraction, or foreground detection, is a challenging problem in video processing. This problem is mainly concerned with a binary classification task, which designates each pixel in a video sequence as belonging to either the background or foreground scene. Traditional approaches for tackling this problem lack the power of capturing deep information in videos from a dynamic environment encountered in real-world applications, thus often achieving low accuracy and unsatisfactory performance. In this paper, we introduce a new 3-D atrous convolutional neural network, used as a deep visual feature extractor, and stack convolutional long short-term memory (ConvLSTM) networks on top of the feature extractor to capture long-term dependences in video data. This novel architecture is named a 3-D atrous ConvLSTM network. The new network can capture not only deep spatial information but also long-term temporal information in the video data. We train the proposed 3-D atrous ConvLSTM network with focal loss to tackle the class imbalance problem commonly seen in background subtraction. Experimental results on a wide range of videos demonstrate the effectiveness of our approach and its superiority over existing methods.","","","10.1109/ACCESS.2018.2861223","King Abdulaziz University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8423055","Background subtraction;foreground segmentation;deep learning;3D atrous convolution;convolutional LSTM network","Three-dimensional displays;Convolution;Machine learning;Kernel;Video sequences;Spatial resolution;Convolutional neural networks","feature extraction;feedforward neural nets;image sequences;object detection;pattern classification;video signal processing","3D atrous convolutional long short-term memory network;background subtraction;foreground detection;video processing;binary classification task;video sequence;deep information;3-D atrous convolutional neural network;deep visual feature extractor;short-term memory networks;video data;3-D atrous ConvLSTM network;deep spatial information;long-term temporal information;class imbalance problem","","6","37","","","","","IEEE","IEEE Journals"
"Supervised Deep Feature Extraction for Hyperspectral Image Classification","B. Liu; X. Yu; P. Zhang; A. Yu; Q. Fu; X. Wei","Institute of Surveying and Mapping, Zhengzhou, China; Institute of Surveying and Mapping, Zhengzhou, China; Institute of Surveying and Mapping, Zhengzhou, China; Institute of Surveying and Mapping, Zhengzhou, China; Institute of Surveying and Mapping, Zhengzhou, China; Institute of Surveying and Mapping, Zhengzhou, China","IEEE Transactions on Geoscience and Remote Sensing","","2018","56","4","1909","1921","Hyperspectral image classification has become a research focus in recent literature. However, well-designed features are still open issues that impact on the performance of classifiers. In this paper, a novel supervised deep feature extraction method based on siamese convolutional neural network (S-CNN) is proposed to improve the performance of hyperspectral image classification. First, a CNN with five layers is designed to directly extract deep features from hyperspectral cube, where the CNN can be intended as a nonlinear transformation function. Then, the siamese network composed by two CNNs is trained to learn features that show a low intraclass and high interclass variability. The important characteristic of the presented approach is that the S-CNN is supervised with a margin ranking loss function, which can extract more discriminative features for classification tasks. To demonstrate the effectiveness of the proposed feature extraction method, the features extracted from three widely used hyperspectral data sets are fed into a linear support vector machine (SVM) classifier. The experimental results demonstrate that the proposed feature extraction method in conjunction with a linear SVM classifier can obtain better classification performance than that of the conventional methods.","","","10.1109/TGRS.2017.2769673","Key Laboratory of Satellite Mapping Technology and Application, National Administration of Surveying Mapping and Geoinformation; National Natural Science Foundation of China; Scientific and Technological Project in Henan Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8116758","Convolutional neural network (CNN);deep feature extraction;hyperspectral image classification;siamese network;support vector machine (SVM)","Feature extraction;Hyperspectral imaging;Support vector machines;Euclidean distance;Training","feature extraction;hyperspectral imaging;image classification;learning (artificial intelligence);neural nets;support vector machines","hyperspectral image classification;siamese convolutional neural network;S-CNN;hyperspectral cube;classification tasks;classification performance;supervised deep feature extraction method;discriminative feature extraction;hyperspectral data sets;nonlinear transformation function;high interclass variability;low intraclass variability;margin ranking loss function;linear support vector machine classifier;linear SVM classifier","","17","43","","","","","IEEE","IEEE Journals"
"Multi-Slot Spectrum Auction in Heterogeneous Networks Based on Deep Feedforward Network","F. Zhao; Y. Zhang; Q. Wang","Guangxi Colleges and Universities Key Laboratory of Complex System Optimization and Big Data Processing, Yulin Normal University, Yulin, China; Key Laboratory of Cognitive Radio and Information Processing, Guilin University of Electronic Technology, Guilin, China; Guangxi Colleges and Universities Key Laboratory of Complex System Optimization and Big Data Processing, Yulin Normal University, Yulin, China","IEEE Access","","2018","6","","45113","45119","A spectrum auction is a promising approach with respect to efficiently allocating spectrum among unlicensed users. In this paper, we study the spectrum auction based on the waveform and air-interface of wireless users, the interests of the channel for the auction, and the interference they suffered during communication as well as their economic capability. How to make the analysis and the integration of such multiple factors is a key problem for multi-slot spectrum auction. To address the problem, we adopt the deep feedforward network algorithm to perform waveform and air-interface data analysis and integration for multi-slot spectrum auction. Simulation results are presented to verify the effectiveness of the proposed algorithm in the small cell network. Our approach could be used to 5G where heterogeneous wireless networks will be applied extensively and spectrum auction decision is made based on deep learning and different user patterns.","","","10.1109/ACCESS.2018.2865437","National Natural Science Foundation of China; Projects of Education Department of Guangxi; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8438331","Deep feedforward network;dynamic spectrum auction;heterogeneous networks;multi-slot;small cell;waveform and air-interface","Interference;Neural networks;Computer architecture;Heterogeneous networks;Feedforward systems;Microprocessors;Resource management","5G mobile communication;data analysis;feedforward neural nets;learning (artificial intelligence)","5G;air-interface data analysis;heterogeneous wireless networks;deep feedforward network algorithm;heterogeneous networks;multislot spectrum auction","","2","28","","","","","IEEE","IEEE Journals"
"Selective CS: An Energy-Efficient Sensing Architecture for Wireless Implantable Neural Decoding","C. Song; A. Wang; F. Lin; J. Xiao; X. Yao; W. Xu","Department of Computer Science and Engineering, The State University of New York at Buffalo, Buffalo, NY, USA; Department of Computer Science and Engineering, The State University of New York at Buffalo, Buffalo, NY, USA; Department of Computer Science and Engineering, University of Colorado Denver, Denver, CO, USA; School of Electronics and Control Engineering, Chang’an University, Xi’an, China; Department of Computer Science and Engneering, Zhejiang University of Technology, Hangzhou, China; Department of Computer Science and Engineering, The State University of New York at Buffalo, Buffalo, NY, USA","IEEE Journal on Emerging and Selected Topics in Circuits and Systems","","2018","8","2","201","210","The spike classification is a critical step in the implantable neural decoding. The energy efficiency issue in the sensor node is a big challenge for the entire system. Compressive sensing (CS) theory provides a potential way to tackle this problem by reducing the data volume on the communication channel. However, the constant transmission of the compressed data is still energy-hungry. On the other hand, the feasibility of direct analysis in compression domain is mathematically demonstrated. This advance empowers the in-sensor light-weight signal analysis on the compressed data. In this paper, we propose a novel selective CS architecture for energy-efficient wireless implantable neural decoding based on compression analysis and deep learning. Specifically, we develop a two-stage classification procedure, including a light-weight coarse-grained screening module in the sensor and an accurate fine-grained analysis module in the server. To achieve better energy efficiency, the screening module is designed by the Softmax regression, which can complete the low-effort classification task at the sensor end and screen the high-effort task to transmit their compressed measurements to the remote server. The fine-grained analysis located in server end is constructed by the customized deep residual neural network. It can not only promote the spike classification accuracy, but also benefit the model quality of in-sensor Softmax model. The extensive experimental results indicate that our proposed selective CS architecture can gain more than 60% energy savings than the conventional CS architecture, yet even improve the accuracy of state-of-the-art CS architectures.","","","10.1109/JETCAS.2018.2809906","U.S. National Science Foundation; National Science Foundation of China; International Science and Technology Cooperation and Exchanges Plan in ShaanXi Province of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8302908","Compressed sensing;energy-efficient architecture;deep learning","Computer architecture;Machine learning;Wireless communication;Decoding;Wireless sensor networks;Compressed sensing;Servers","compressed sensing;data compression;decoding;electronic engineering computing;learning (artificial intelligence);neural nets;pattern classification;power aware computing;wireless sensor networks","compressive sensing theory;in-sensor light-weight signal analysis;compression analysis;two-stage classification procedure;light-weight coarse-grained screening module;fine-grained analysis module;low-effort classification task;customized deep residual neural network;in-sensor Softmax model;data compression;spike classification;energy-efficiency sensing architecture;wireless implantable neural decoding;CS architecture","","","50","","","","","IEEE","IEEE Journals"
"A Fungus Spores Dataset and a Convolutional Neural Network Based Approach for Fungus Detection","M. W. Tahir; N. A. Zaidi; A. A. Rao; R. Blank; M. J. Vellekoop; W. Lang","Institute for Microsensors, Actuators and Systems, University of Bremen, Bremen, Germany; Institute for Microsensors, Actuators and Systems, University of Bremen, Bremen, Germany; Data and Analytics Department, KPMG AGWPG, Düsseldorf, Germany; Institute for Microsensors, Actuators and Systems, University of Bremen, Bremen, Germany; Institute for Microsensors, Actuators and Systems, University of Bremen, Bremen, Germany; Institute for Microsensors, Actuators and Systems, University of Bremen, Bremen, Germany","IEEE Transactions on NanoBioscience","","2018","17","3","281","290","Fungus is enormously notorious for food, human health, and archives. Fungus sign and symptoms in medical science are non-specific and asymmetrical for extremely large areas resulting into a challenging task of fungal detection. Various traditional and computer vision techniques were applied to meet the challenge of early fungus detection. On the other hand, features learned through the convolutional neural network (CNN) provided state-of-the-art results in many other applications of object detection and classification. However, the large amount of data is an essential prerequisite for its effective application. In pursuing this idea, we present a novel fungus dataset of its kind, with the goal of advancing the state of the art in fungus classification by placing the question of fungus detection. This is achieved by gathering various images of complex fungal spores by extracting samples from contaminated fruits, archives, and laboratory-incubated fungus colonies. These images primarily consisted of five different types of fungus spores and dirt. An optical sensor system was utilized to obtain these images, which were further annotated to mark fungal spores as a region of interest using specially designed graphical user interface. As a result, 40,800 labeled images were used to develop the fungus dataset to aid in precise fungus detection and classification. The other main objective of this research was to develop a CNN-based approach for the detection of fungus and distinguish different types of fungus. A CNN architecture was designed, and it showed the promising results with an accuracy of 94.8%. The obtained results proved the possibility of early detection of several types of fungus spores using CNN and could estimate all possible threats due to fungus.","","","10.1109/TNB.2018.2839585","Deutscher Akademischer Austauschdienst; Higher Education Commission, Pakistan; Bundesministerium für Bildung und Forschung; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8362745","Convolutional neural network;deep learning;fungus detection;fungus dataset;microbial detection;mold detection;mold dataset","Convolution;Computer vision;Computer architecture;Nanobioscience;Convolutional neural networks;Fungi;Biological neural networks","computer vision;convolution;feedforward neural nets;graphical user interfaces;image classification;microorganisms;object detection;object recognition;optical sensors","convolutional neural network based approach;fungal detection;object detection;fungus classification;laboratory-incubated fungus colonies;fungus spores dataset;fungus symptoms;computer vision techniques;optical sensor system;region of interest;graphical user interface;CNN architecture","Databases, Factual;Deep Learning;Fungi;Image Processing, Computer-Assisted;Microscopy;Neural Networks (Computer);Spores, Fungal","1","41","","","","","IEEE","IEEE Journals"
"Learning-Based Energy-Efficient Data Collection by Unmanned Vehicles in Smart Cities","B. Zhang; C. H. Liu; J. Tang; Z. Xu; J. Ma; W. Wang","Beijing University of Posts and Telecommunications, Beijing, China; Beijing Institute of Technology, Beijing, China; Department of Computer Science and Engineering, Syracuse University, Syracuse, NY, USA; Department of Computer Science and Engineering, Syracuse University, Syracuse, NY, USA; Beijing University of Posts and Telecommunications, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China","IEEE Transactions on Industrial Informatics","","2018","14","4","1666","1676","Mobile crowdsourcing (MCS) is now an important source of information for smart cities, especially with the help of unmanned aerial vehicles (UAVs) and driverless cars. They are equipped with different kinds of high-precision sensors, and can be scheduled/controlled completely during data collection, which will make MCS system more robust. However, they are limited to energy constraint, especially for long-term, long-distance sensing tasks, and cities are almost too crowded to set stationary charging station. Towards this end, in this paper we propose to leverage emerging deep reinforcement learning (DRL) techniques for enabling model-free unmanned vehicles control, and present a novel and highly effective control framework, called “DRL-RVC.” It utilizes the powerful convolutional neural network for feature extraction of the necessary information (including sample distribution, traffic flow, etc.), then makes decisions under the guidance of the deep Q network. That is, UAVs will cruise in the city without control and collect most required data in the sensing region, while mobile unmanned charging station will reach the charging point in the shortest possible time. Finally, we validate and evaluate the proposed framework via extensive simulations based on a real dataset in Rome. Extensive simulation results well justify the effectiveness and robustness of our approach.","","","10.1109/TII.2017.2783439","National Natural Science Foundation of China; China Postdoctoral Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8207610","Data crowdsourcing;energy-efficiency;smart city","Sensors;Charging stations;Mobile communication;Data collection;Unmanned vehicles;Urban areas","autonomous aerial vehicles;data acquisition;energy conservation;feature extraction;feedforward neural nets;learning (artificial intelligence);smart cities","highly effective control framework;DRL-RVC;deep Q network;UAVs;sensing region;mobile unmanned charging station;charging point;robustness;energy-efficient data collection;smart cities;mobile crowdsourcing;driverless cars;high-precision sensors;MCS system;energy constraint;long-distance sensing tasks;stationary charging station;deep reinforcement learning techniques;model-free unmanned vehicles control;convolutional neural network","","17","34","","","","","IEEE","IEEE Journals"
"Deep Learning Markov Random Field for Semantic Segmentation","Z. Liu; X. Li; P. Luo; C. C. Loy; X. Tang","Department of Information Engineering, Chinese University of Hong Kong, Shatin, Hong Kong SAR; Department of Information Engineering, Chinese University of Hong Kong, Shatin, Hong Kong SAR; Department of Information Engineering, Chinese University of Hong Kong, Shatin, Hong Kong SAR; Department of Information Engineering, Chinese University of Hong Kong, Shatin, Hong Kong SAR; Department of Information Engineering, Chinese University of Hong Kong, Shatin, Hong Kong SAR","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","8","1814","1828","Semantic segmentation tasks can be well modeled by Markov Random Field (MRF). This paper addresses semantic segmentation by incorporating high-order relations and mixture of label contexts into MRF. Unlike previous works that optimized MRFs using iterative algorithm, we solve MRF by proposing a Convolutional Neural Network (CNN), namely Deep Parsing Network (DPN), which enables deterministic end-to-end computation in a single forward pass. Specifically, DPN extends a contemporary CNN to model unary terms and additional layers are devised to approximate the mean field (MF) algorithm for pairwise terms. It has several appealing properties. First, different from the recent works that required many iterations of MF during back-propagation, DPN is able to achieve high performance by approximating one iteration of MF. Second, DPN represents various types of pairwise terms, making many existing models as its special cases. Furthermore, pairwise terms in DPN provide a unified framework to encode rich contextual information in high-dimensional data, such as images and videos. Third, DPN makes MF easier to be parallelized and speeded up, thus enabling efficient inference. DPN is thoroughly evaluated on standard semantic image/video segmentation benchmarks, where a single DPN model yields state-of-the-art segmentation accuracies on PASCAL VOC 2012, Cityscapes dataset and CamVid dataset.","","","10.1109/TPAMI.2017.2737535","SenseTime Group Limited and the General Research Fund sponsored; Research Grants Council of the Hong Kong SAR; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8006236","Semantic image/video segmentation;Markov random field;convolutional neural network","Image segmentation;Semantics;Markov random fields;Videos;Computational modeling;Neural networks;Computer architecture","convolution;feedforward neural nets;graph theory;image segmentation;learning (artificial intelligence);Markov processes;object detection;random processes;video signal processing","high-order relations;MRF;iterative algorithm;Convolutional Neural Network;Deep Parsing Network;deterministic end-to-end computation;single forward pass;unary terms;pairwise terms;standard semantic image/video segmentation benchmarks;Markov Random Field;semantic segmentation tasks;mean field algorithm;single DPN model","","8","61","","","","","IEEE","IEEE Journals"
"Benchmark Data Set and Method for Depth Estimation From Light Field Images","M. Feng; Y. Wang; J. Liu; L. Zhang; H. F. M. Zaki; A. Mian","College of Electrical and Information Engineering, Hunan University, Changsha, China; College of Electrical and Information Engineering, Hunan University, Changsha, China; School of Computer Science and Software Engineering, The University of Western Australia, Perth, Crawley, WA, Australia; School of Software, Xidian University, Xi’an, China; School of Computer Science and Software Engineering, The University of Western Australia, Perth, Crawley, WA, Australia; School of Computer Science and Software Engineering, The University of Western Australia, Perth, Crawley, WA, Australia","IEEE Transactions on Image Processing","","2018","27","7","3586","3598","Convolutional neural networks (CNNs) have performed extremely well for many image analysis tasks. However, supervised training of deep CNN architectures requires huge amounts of labeled data, which is unavailable for light field images. In this paper, we leverage on synthetic light field images and propose a two-stream CNN network that learns to estimate the disparities of multiple correlated neighborhood pixels from their epipolar plane images (EPIs). Since the EPIs are unrelated except at their intersection, a two-stream network is proposed to learn convolution weights individually for the EPIs and then combine the outputs of the two streams for disparity estimation. The CNN estimated disparity map is then refined using the central RGB light field image as a prior in a variational technique. We also propose a new real world data set comprising light field images of 19 objects captured with the Lytro Illum camera in outdoor scenes and their corresponding 3D pointclouds, as ground truth, captured with the 3dMD scanner. This data set will be made public to allow more precise 3D pointcloud level comparison of algorithms in the future which is currently not possible. Experiments on the synthetic and real world data sets show that our algorithm outperforms existing state of the art for depth estimation from light field images.","","","10.1109/TIP.2018.2814217","China Scholarship Council and National Natural Science Foundation of China; Australian Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8310559","Depth estimation;disparity;light field;two stream CNN;deep learning;plenoptic camera;Lytro camera","Estimation;Cameras;Three-dimensional displays;Streaming media;Image resolution;Machine learning;Image color analysis","cameras;image colour analysis;image sensors;learning (artificial intelligence);neural nets;stereo image processing","depth estimation;benchmark data set;convolutional neural networks;image analysis tasks;deep CNN architectures;synthetic light field images;two-stream CNN network;epipolar plane images;disparity estimation;central RGB light field image;supervised training;multiple correlated neighborhood pixels;Lytro Illum camera;outdoor scenes;3dMD scanner;3D pointcloud level","","4","59","","","","","IEEE","IEEE Journals"
"DFUNet: Convolutional Neural Networks for Diabetic Foot Ulcer Classification","M. Goyal; N. D. Reeves; A. K. Davison; S. Rajbhandari; J. Spragg; M. H. Yap","Centre for Advanced Computational Science, School of Computing, Mathematics and Digital Technology, Manchester Metropolitan University, Manchester M15 6BH, U.K. (e-mail: M.Yap@mmu.ac.uk).; Research Centre for Musculoskeletal Science and Sports Medicine, School of Healthcare Science, Manchester Metropolitan University, Manchester M15 6BH, U.K. (e-mail: n.reeves@mmu.ac.uk).; Centre of Imaging Sciences, University of Manchester, Manchester M13 9PL, U.K. (e-mail: adrian.davison@manchester.ac.uk).; Lancashire Teaching Hospital, Preston PR2 9HT, U.K. (e-mail: Satyan.Rajbhandari@lthtr.nhs.uk).; Lancashire Care NHS Foundation Trust, Preston PR5 6AW, U.K. (e-mail: Jennifer.Spragg@Lancashirecare.nhs.uk).; Centre for Advanced Computational Science, School of Computing, Mathematics and Digital Technology, Manchester Metropolitan University, Manchester M15 6BH, U.K.","IEEE Transactions on Emerging Topics in Computational Intelligence","","2018","PP","99","1","12","Globally, in 2016, 1 out of 11 adults suffered from diabetes mellitus. Diabetic foot ulcers (DFU) are a major complication of this disease, which if not managed properly can lead to amputation. Current clinical approaches to DFU treatment rely on patient and clinician vigilance, which has significant limitations, such as the high cost involved in the diagnosis, treatment, and lengthy care of the DFU. We collected an extensive dataset of foot images, which contain DFU from different patients. In this DFU classification problem, we assessed the two classes as normal skin (healthy skin) and abnormal skin (DFU). In this paper, we have proposed the use of machine learning algorithms to extract the features for DFU and healthy skin patches to understand the differences in the computer vision perspective. This experiment is performed to evaluate the skin conditions of both classes that are at high risk of misclassification by computer vision algorithms. Furthermore, we used convolutional neural networks for the first time in this binary classification. We have proposed a novel convolutional neural network architecture, DFUNet, with better feature extraction to identify the feature differences between healthy skin and the DFU. Using 10-fold cross validation, DFUNet achieved an AUC score of 0.961. This outperformed both the traditional machine learning and deep learning classifiers we have tested. Here, we present the development of a novel and highly sensitive DFUNet for objectively detecting the presence of DFUs. This novel approach has the potential to deliver a paradigm shift in diabetic foot care among diabetic patients, which represent a cost-effective, remote, and convenient healthcare solution.","","","10.1109/TETCI.2018.2866254","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8464076","Diabetic foot ulcers;classification;deep learning;convolutional neural networks;DFUNet","Skin;Diabetes;Feature extraction;Computer vision;Wounds;Machine learning","","","","4","","","","","","IEEE","IEEE Early Access Articles"
"GOSELO: Goal-Directed Obstacle and Self-Location Map for Robot Navigation Using Reactive Neural Networks","A. Kanezaki; J. Nitta; Y. Sasaki","National Institute of Advanced Industrial Science and Technology, Tokyo, Japan; National Institute of Advanced Industrial Science and Technology, Tokyo, Japan; National Institute of Advanced Industrial Science and Technology, Tokyo, Japan","IEEE Robotics and Automation Letters","","2018","3","2","696","703","Robot navigation using deep neural networks has been drawing a great deal of attention. Although reactive neural networks easily learn expert behaviors and are computationally efficient, they suffer from generalization of policies learned in specific environments. As such, reinforcement learning and value iteration approaches for learning generalized policies have been proposed. However, these approaches are more costly. In this letter, we tackle the problem of learning reactive neural networks that are applicable to general environments. The key concept is to crop, rotate, and rescale an obstacle map according to the goal location and the agent's current location so that the map representation will be better correlated with self-movement in the general navigation task, rather than the layout of the environment. Furthermore, in addition to the obstacle map, we input a map of visited locations that contains the movement history of the agent, in order to avoid failures that the agent travels back and forth repeatedly over the same location. Experimental results reveal that the proposed network outperforms the state-of-the-art value iteration network in the grid-world navigation task. We also demonstrate that the proposed model can be well generalized to unseen obstacles and unknown terrain. Finally, we demonstrate that the proposed system enables a mobile robot to successfully navigate in a real dynamic environment.","","","10.1109/LRA.2017.2783400","New Energy and Industrial Technology Development Organization; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8207619","Deep learning in robotics and automation;visual-based navigation;recognition","Navigation;Path planning;Robots;Neural networks;Agriculture;Computational modeling","learning (artificial intelligence);mobile robots;navigation;neurocontrollers;path planning","grid-world navigation task;robot navigation;reactive neural networks;deep neural networks;reinforcement learning;general environments;obstacle map;goal location;map representation;general navigation task;visited locations","","2","23","","","","","IEEE","IEEE Journals"
"Cross-Domain Traffic Scene Understanding: A Dense Correspondence-Based Transfer Learning Approach","S. Di; H. Zhang; C. Li; X. Mei; D. Prokhorov; H. Ling","School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China; School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China; School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China; Toyota Research Institute, North America, Ann Arbor, MI, USA; Toyota Research Institute, North America, Ann Arbor, MI, USA; Department of Computer and Information Sciences, Temple University, Philadelphia, PA, USA","IEEE Transactions on Intelligent Transportation Systems","","2018","19","3","745","757","Understanding traffic scene images taken from vehicle mounted cameras is important for high-level tasks, such as advanced driver assistance systems and autonomous driving. It is a challenging problem due to large variations under different weather or illumination conditions. In this paper, we tackle the problem of traffic scene understanding from a cross-domain perspective. We attempt to understand the traffic scene from images taken from the same location but under different weather or illumination conditions (e.g., understanding the same traffic scene from images on a rainy night with the help of images taken on a sunny day). To this end, we propose a dense correspondence-based transfer learning (DCTL) approach, which consists of three main steps: 1) extracting deep representations of traffic scene images via a fine-tuned convolutional neural network; 2) constructing compact and effective representations via cross-domain metric learning and subspace alignment for cross-domain retrieval; and 3) transferring the annotations from the retrieved best matching image to the test image based on cross-domain dense correspondences and a probabilistic Markov random field. To verify the effectiveness of our DCTL approach, we conduct extensive experiments on a challenging data set, which contains 1828 images from six weather or illumination conditions.","","","10.1109/TITS.2017.2702012","National Natural Science Foundation of China; Beijing Natural Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7934021","Traffic scene understanding;semantic segmentation;transfer learning;dense correspondence;road scene;vehicle environment perception","Meteorology;Training;Lighting;Feature extraction;Measurement;Semantics;Image segmentation","computer vision;driver information systems;feedforward neural nets;image matching;image segmentation;learning (artificial intelligence);Markov processes;object detection","transfer learning approach;traffic scene images;cross-domain metric learning;subspace alignment;cross-domain retrieval;retrieved best matching image;test image;cross-domain dense correspondences;cross-domain traffic scene understanding;dense correspondence;vehicle mounted cameras;high-level tasks;advanced driver assistance systems;different weather;cross-domain perspective;DCTL approach;probabilistic Markov random field","","4","66","","","","","IEEE","IEEE Journals"
"Exploring Web Images to Enhance Skin Disease Analysis Under A Computer Vision Framework","Y. Xia; L. Zhang; L. Meng; Y. Yan; L. Nie; X. Li","College of Computer Sciences, Zhejiang University, Hangzhou, China; Department of Electric Engineering and Information System, Hefei University of Technology, Hefei, China; Joint NTU-UBC Research Center of Excellence in Active Living for the Elderly, Nanyang Technological University, Singapore; Department of Information Engineering and Computer Science, University of Trento, Trento, Italy; School of Computer Science and Technology, Shandong University, Jinan, China; Center for Optical Imagery Analysis and Learning, State Key Laboratory of Transient Optics and Photonics, Xi’an Institute of Optics and Precision Mechanics, Chinese Academy of Sciences, Xi’an, China","IEEE Transactions on Cybernetics","","2018","48","11","3080","3091","To benefit the skin care, this paper aims to design an automatic and effective visual analysis framework, with the expectation of recognizing the skin disease from a given image conveying the disease affected surface. This task is nontrivial, since it is hard to collect sufficient well-labeled samples. To address such problem, we present a novel transfer learning model, which is able to incorporate external knowledge obtained from the rich and relevant Web images contributed by grassroots. In particular, we first construct a target domain by crawling a small set of images from vertical and professional dermatological websites. We then construct a source domain by collecting a large set of skin disease related images from commercial search engines. To reinforce the learning performance in the target domain, we initially build a learning model in the target domain, and then seamlessly leverage the training samples in the source domain to enhance this learning model. The distribution gap between these two domains are bridged by a linear combination of Gaussian kernels. Instead of training models with low-level features, we resort to deep models to learn the succinct, invariant, and high-level image representations. Different from previous efforts that focus on a few types of skin diseases with a small and confidential set of images generated from hospitals, this paper targets at thousands of commonly seen skin diseases with publicly accessible Web images. Hence the proposed model is easily repeatable by other researchers and extendable to other disease types. Extensive experiments on a real-world dataset have demonstrated the superiority of our proposed method over the state-of-the-art competitors.","","","10.1109/TCYB.2017.2765665","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8093746","Skin disease inference;transfer learning","Skin;Diseases;Visualization;Training;Hospitals;Feature extraction","computer vision;data visualisation;diseases;hospitals;image representation;Internet;learning (artificial intelligence);search engines;skin","target domain;source domain;learning performance;succinct level image representations;high-level image representations;publicly accessible Web images;disease types;computer vision framework;automatic analysis framework;transfer learning model;rich Web images;skin disease analysis;skin care;visual analysis framework;well-labeled samples;grassroots;dermatological websites;commercial search engines;training samples;distribution gap;Gaussian kernels.;invariant level image representations;hospitals","","1","57","","","","","IEEE","IEEE Journals"
"Linear Disentangled Representation Learning for Facial Actions","X. Xiang; T. D. Tran","Department of Computer Science, Johns Hopkins University, Baltimore, MD, USA; Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD, USA","IEEE Transactions on Circuits and Systems for Video Technology","","2018","28","12","3539","3544","Limited annotated data available for the recognition of facial expression and particularly action units makes it hard to train a deep network which can learn disentangled invariant features. However, a supervised linear model is undemanding in terms of training data. In this paper, we propose an elegant linear model to untangle facial actions from expressive face videos which contain a mixture of linearly-representable attributes. Previous attempts require an explicit decoupling of identity and expression which is practically inexact. Instead, we exploit the low-rank property across frames to implicitly subtract the intrinsic neutral face, which are modeled jointly with sparse representation only on the residual expression components. On CK+, our one-shot C-HiSLR on raw-face pixel-intensities performs far more competitive than conventional shape+SVM models with landmark detection and two-stepped SRC of the same type yet applied on manually prepared expression components. It is also comparable with the piecewise linear model DCS and temporal models, such as CRF and Bayes nets. We apply it to action unit (AU) recognition on MPI-VDB achieving a decent performance. As expression is a mixture of AUs, the result gives hopes of approximating an expression using a piecewise linear model.","","","10.1109/TCSVT.2017.2771150","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8101548","Face video;facial expression;low-rank","Face recognition;Videos;Computational modeling;Machine learning;Dictionaries;Training data","emotion recognition;face recognition;feature extraction;image representation;learning (artificial intelligence);support vector machines","deep network;disentangled invariant features;supervised linear model;training data;elegant linear model;untangle facial actions;expressive face videos;linearly-representable attributes;low-rank property;intrinsic neutral face;sparse representation;residual expression components;pixel-intensities performs;conventional shape+SVM models;manually prepared expression components;action unit;piecewise linear model;representation learning;facial expression","","1","18","","","","","IEEE","IEEE Journals"
"Hyper-parameters optimisation of deep CNN architecture for vehicle logo recognition","F. C. Soon; H. Y. Khaw; J. H. Chuah; J. Kanesan","University of Malaya, Malaysia; University of Malaya, Malaysia; University of Malaya, Malaysia; University of Malaya, Malaysia","IET Intelligent Transport Systems","","2018","12","8","939","946","The training of deep convolutional neural network (CNN) for classification purposes is critically dependent on the expertise of hyper-parameters tuning. This study aims to minimise the user variability in training CNN by automatically searching and optimising the CNN architecture, particularly in the field of vehicle logo recognition system. For this purpose, the architecture and hyper-parameters of CNN were selected according to the implementation of the stochastic method of particle swarm optimisation on the training–testing data. After obtaining the optimised hyper-parameters, the CNN is fine-tuned and trained to ensure better network convergence and classification performance. In this study, a total of 14,950 vehicle logo images are divided into two independent training and testing sets. In addition, these images are segmented coarsely, thus the requirement of precise logo segmentation is obviated in this work. The learned features of the CNN were sufficiently discriminative to be classified using multiclass Softmax classifier. With implementation using a graphics processing unit (GPU), the computation time of the proposed method is acceptable for real-time application. The experimental results explicitly prove that the authors’ approach outperforms most of the state-of-the-art methods, achieving an accuracy of 99.1% over 13 vehicle manufacturers.","","","10.1049/iet-its.2018.5127","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8461271","","","image classification;image segmentation;object recognition;feedforward neural nets;graphics processing units;road vehicles;intelligent transportation systems;particle swarm optimisation;stochastic processes","hyper-parameters optimisation;deep CNN architecture;deep convolutional neural network architecture;vehicle logo recognition system;classification purposes;hyper-parameters tuning;stochastic method;particle swarm optimisation;training-testing data;network convergence;classification performance;training set;testing set;image segmentation;precise logo segmentation;multiclass Softmax classifier;intelligent transportation systems;computation time;graphics processing unit","","2","29","","","","","IET","IET Journals"
"Recurrent neural networks for remote sensing image classification","M. I. Lakhal; H. Çevikalp; S. Escalera; F. Ofli","Queen Mary University of London, UK; Eskisehir Osmangazi University, Turkey; University of Barcelona and Computer Vision Center, Spain; Qatar Computing Research Institute, HBKU, Qatar","IET Computer Vision","","2018","12","7","1040","1045","Automatically classifying an image has been a central problem in computer vision for decades. A plethora of models has been proposed, from handcrafted feature solutions to more sophisticated approaches such as deep learning. The authors address the problem of remote sensing image classification, which is an important problem to many real world applications. They introduce a novel deep recurrent architecture that incorporates high-level feature descriptors to tackle this challenging problem. Their solution is based on the general encoder–decoder framework. To the best of the authors’ knowledge, this is the first study to use a recurrent network structure on this task. The experimental results show that the proposed framework outperforms the previous works in the three datasets widely used in the literature. They have achieved a state-of-the-art accuracy rate of 97.29% on the UC Merced dataset.","","","10.1049/iet-cvi.2017.0420","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8466254","","","remote sensing;geophysical image processing;recurrent neural nets;image classification;feature extraction;learning (artificial intelligence);computer vision","recurrent neural networks;remote sensing image classification;automatic image classification;computer vision;deep learning;deep recurrent architecture;high-level feature descriptors;general encoder-decoder framework;recurrent network structure;UC Merced dataset;RS-19 dataset;Brazilian Coffee Scenes dataset","","","39","","","","","IET","IET Journals"
"Cross-View Discriminative Feature Learning for Person Re-Identification","A. Borgia; Y. Hua; E. Kodirov; N. M. Robertson","ISSS, Heriot-Watt University, Edinburgh, U.K.; EEECS/ECIT, Queen’s University Belfast, Belfast, U.K.; Research Division, Anyvision, Belfast, U.K.; EEECS/ECIT, Queen’s University Belfast, Belfast, U.K.","IEEE Transactions on Image Processing","","2018","27","11","5338","5349","The viewpoint variability across a network of non-overlapping cameras is a challenging problem affecting person re-identification performance. In this paper, we investigate how to mitigate the cross-view ambiguity by learning highly discriminative deep features under the supervision of a novel loss function. The proposed objective is made up of two terms, the steering meta center term and the enhancing centers dispersion term, that steer the training process to mining effective intra-class and inter-class relationships in the feature domain of the identities. The effect of our loss supervision is to generate a more expanded feature space of compact classes where the overall level of the inter-identities' interference is reduced. Compared with the existing metric learning techniques, this approach has the advantage of achieving a better optimization because it jointly learns the embedding and the metric contextually. Our technique, by dismissing side-sources of performance gain, proves to enhance the CNN invariance to viewpoint without incurring increased training complexity (like in Siamese or triplet networks) and outperforms many related state-of-the-art techniques on Market-1501 and CUHK03.","","","10.1109/TIP.2018.2851098","Heriot-Watt University; Roke, Part of the Chemring Group; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8398470","Viewpoint;loss function;multi-camera;person re-id;discriminative features","Training;Cameras;Measurement;Task analysis;Feature extraction;Face;Electronic mail","feature extraction;image representation;learning (artificial intelligence)","discriminative deep features;loss function;feature space;metric learning techniques;person re-identification performance;cross-view discriminative feature learning;triplet networks;compact classes;loss supervision;feature domain;inter-class relationships;enhancing centers;steering meta center term;cross-view ambiguity;nonoverlapping cameras;viewpoint variability","","4","57","","","","","IEEE","IEEE Journals"
"Travel Time Prediction: Based on Gated Recurrent Unit Method and Data Fusion","J. Zhao; Y. Gao; Y. Qu; H. Yin; Y. Liu; H. Sun","School of Traffic and Transportation, Beijing Jiaotong University, Beijing, China; School of Mechanical, Electronic and Control Engineering, Beijing Jiaotong University, Beijing, China; State Key Laboratory of Rail Traffic Control and Safety, Beijing Jiaotong University, Beijing, China; State Key Laboratory of Rail Traffic Control and Safety, Beijing Jiaotong University, Beijing, China; School of Mechanical, Electronic and Control Engineering, Beijing Jiaotong University, Beijing, China; School of Traffic and Transportation, Beijing Jiaotong University, Beijing, China","IEEE Access","","2018","6","","70463","70472","Travel time prediction is the basis for the implementation of advanced traveler information systems and advanced transport management systems in intelligent transportation systems. Many studies have shown that the fusion of multi-source data can achieve higher precision prediction of travel time than the travel time prediction based on single source data. In recent years, with the continuous development of China's expressways, traffic detectors such as dedicated short-range communications (DSRC) and remote transportation microwave sensors (RTMS) have been installed on both sides of the road, which provides a basis for the prediction of travel time by fusing multi-source data. At the same times, the deep learning methods show good performance in prediction. So, this paper uses the deep learning algorithm to realize the travel time prediction based on DSRC data and the RTMS data. First, the travel times are, respectively, extracted based on the DSRC data and the RTMS data. Then, both travel time values are input into the gated recurrent unit (GRU) model to obtain travel time prediction results based on multi-source data. Finally, based on the data of the Jinggangao Highway, the accuracy of the algorithm is verified and compared with the traditional data fusion method. The results show that the GRU model can achieve better accuracy of travel time prediction with data fusion.","","","10.1109/ACCESS.2018.2878799","National Natural Science Foundation of China; National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8515184","Highway;travel time prediction;deep learning;gated recurrent unit;data fusion","Detectors;Data integration;Predictive models;Road transportation;Data models;Prediction algorithms","intelligent transportation systems;learning (artificial intelligence);recurrent neural nets;road traffic control;sensor fusion","multisource data;data fusion;DSRC data;RTMS data;travel time values;travel time prediction;traveler information systems;gated recurrent unit method;transport management systems;intelligent transportation systems;deep learning algorithm;dedicated short-range communications;remote transportation microwave sensors;GRU model;GRU model","","4","33","","","","","IEEE","IEEE Journals"
"Onboard Observation Task Planning for an Autonomous Earth Observation Satellite Using Long Short-Term Memory","S. Peng; H. Chen; C. Du; J. Li; N. Jing","College of Electronic Science, National University of Defense Technology, Changsha, China; College of Electronic Science, National University of Defense Technology, Changsha, China; College of Electronic Science, National University of Defense Technology, Changsha, China; College of Electronic Science, National University of Defense Technology, Changsha, China; College of Electronic Science, National University of Defense Technology, Changsha, China","IEEE Access","","2018","6","","65118","65129","Onboard observation task planning plays an essential role in satellite autonomy, which has attracted considerable attention from researchers in recent years. Most of the existing studies solve the satellite onboard observation task planning problem (SOOTP) by searching algorithms. However, the limited computing resources and the changes of onboard condition present a new challenge for these methods. In this paper, we develop a sequential decision-making model and propose a deep learning-based planning method to solve the SOOTP. Instead of generating a short-term or long-term plan in advance, the sequential decisionmaking model enables the satellite to decide the observation task to execute in real-time. In the deep learning-based planning method, a long short-term memory-based encoding network is designed to extract the features and a classification network is used to make such a decision. In the experiment, we compared our method with the gated recurrent unit network and other three searching algorithms based on five scenarios. The experimental results show that our method can solve problems with 90.3%-93.7% accuracy, 2.19%-3.95% profit gap, and 0.004-0.006 s response time per task, which confirms its feasibility.","","","10.1109/ACCESS.2018.2877687","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8502754","Satellite autonomy;onboard observation task planning;sequential decision-making;deep learning;long short-term memory","Task analysis;Planning;Satellites;Decision making;Energy states;Maintenance engineering","artificial satellites;decision making;feature extraction;learning (artificial intelligence);mobile robots;path planning;pattern classification;recurrent neural nets;search problems","satellite onboard observation task planning;searching algorithms;onboard condition;sequential decision-making model;satellite autonomy;autonomous Earth observation satellite;deep learning-based planning method;long short-term memory-based encoding network;feature extraction;classification network","","1","32","","","","","IEEE","IEEE Journals"
"Fast Automatic Vehicle Annotation for Urban Traffic Surveillance","Y. Zhou; L. Liu; L. Shao; M. Mellor","School of Computing Sciences, University of East Anglia, Norwich, U.K.; School of Computing Sciences, University of East Anglia, Norwich, U.K.; School of Computing Sciences, University of East Anglia, Norwich, U.K.; Createc, Cockermouth, U.K.","IEEE Transactions on Intelligent Transportation Systems","","2018","19","6","1973","1984","Automatic vehicle detection and annotation for streaming video data with complex scenes is an interesting but challenging task for intelligent transportation systems. In this paper, we present a fast algorithm: detection and annotation for vehicles (DAVE), which effectively combines vehicle detection and attributes annotation into a unified framework. DAVE consists of two convolutional neural networks: a shallow fully convolutional fast vehicle proposal network (FVPN) for extracting all vehicles' positions, and a deep attributes learning network (ALN), which aims to verify each detection candidate and infer each vehicle's pose, color, and type information simultaneously. These two nets are jointly optimized so that abundant latent knowledge learned from the deep empirical ALN can be exploited to guide training the much simpler FVPN. Once the system is trained, DAVE can achieve efficient vehicle detection and attributes annotation for real-world traffic surveillance data, while the FVPN can be independently adopted as a real-time high-performance vehicle detector as well. We evaluate the DAVE on a new self-collected urban traffic surveillance data set and the public PASCAL VOC2007 car and LISA 2010 data sets, with consistent improvements over existing algorithms.","","","10.1109/TITS.2017.2740303","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8082130","Vehicle detection;attributes annotation;latent knowledge guidance;joint learning;deep networks","Vehicle detection;Surveillance;Proposals;Image color analysis;Training;Real-time systems","automobiles;convolution;feature extraction;feedforward neural nets;learning (artificial intelligence);object detection;road traffic;surveillance;traffic information systems","high-performance vehicle detector;urban traffic surveillance data;LISA 2010 data sets;automatic vehicle detection;intelligent transportation systems;fast algorithm;DAVE;convolutional neural networks;ALN;automatic vehicle annotation;streaming video data;detection and annotation for vehicles;convolutional fast vehicle proposal network;FVPN;vehicle positions extraction;deep attributes learning network;public PASCAL VOC2007 car","","3","49","","","","","IEEE","IEEE Journals"
"The Identification of the Emotionality of Metaphorical Expressions Based on a Manually Annotated Chinese Corpus","D. Zhang; H. Lin; P. Zheng; L. Yang; S. Zhang","School of Software, Dalian University of Technology, Dalian, China; School of Computer Science and Technology, Dalian University of Technology, Dalian, China; School of Computer Science and Technology, Dalian University of Technology, Dalian, China; School of Computer Science and Technology, Dalian University of Technology, Dalian, China; School of Computer Science and Technology, Dalian University of Technology, Dalian, China","IEEE Access","","2018","6","","71241","71248","Metaphorical expressions are frequently used to convey emotions in human communication. However, there is limited research on the detection of emotionality in metaphorical expressions, although a number of studies have focused on sentiment analysis and metaphor detection separately. We, therefore, attempt to identify emotions in Chinese metaphorical texts. We first construct a manual corpus with an annotation scheme, which contains annotations of metaphor, and emotional categories. We then use the corpus as a train-and-test set to identify the emotions in metaphorical expressions automatically with three methods. The first method is based on a field dictionary and field conflict. The second method is based on a support vector machine. The third method is based on deep learning, and it applies the long short-term memory model to identify the emotion of metaphor. The experimental results show that the third method performs better in identifying metaphor tasks, while the first method works better for emotion classification. In this paper, we compared the strength of heuristic, stochastic, and deep learning approaches, which contributes to a challenging natural language processing issue: the detection of emotionality in metaphor.","","","10.1109/ACCESS.2018.2881270","National Natural Science Foundation of China; National Natural Science Foundation of China; Ministry of Education; MOE; FRF; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8534384","Emotionality of metaphor;understanding of semantics;deep learning;field conflict","Sentiment analysis;Dictionaries;Semantics;Linguistics;Support vector machines;Task analysis","computational linguistics;emotion recognition;learning (artificial intelligence);pattern classification;recurrent neural nets;sentiment analysis;support vector machines","metaphorical expressions;metaphor tasks;emotion classification;emotionality;manually annotated Chinese;Chinese metaphorical texts;emotional categories;sentiment analysis;train-and-test set;support vector machine;deep learning;long short-term memory model;natural language processing","","","65","","","","","IEEE","IEEE Journals"
"Deep Manifold Preserving Autoencoder for Classifying Breast Cancer Histopathological Images","Y. Feng; L. Zhang; J. Mo","college of computer science, Sichuan University, 12530 Chengdu, SiChuan China 610065 (e-mail: fengyangqin@outlook.com); college of computer science, Sichuan University, 12530 Chengdu, SiChuan China 610065 (e-mail: leizhang@scu.edu.cn); college of computer science, Sichuan University, 12530 Chengdu, Sichuan China (e-mail: mojuan2016@gmail.com)","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2018","PP","99","1","1","Classifying breast cancer histopathological images automatically is an important task in computer assisted pathology analysis. However, extracting informative and non-redundant features for histopathological image classification is challenging due to the appearance variability caused by the heterogeneity of the disease, the tissue preparation, and staining processes. In this paper, we propose a new feature extractor, called deep manifold preserving autoencoder, to learn discriminative features from unlabeled data. Then, we integrate the proposed feature extractor with a softmax classifier to classify breast cancer histopathology images. Specifically, it learns hierarchal features from unlabeled image patches by minimizing the distance between its input and output, and simultaneously preserving the geometric structure of the whole input data set. After the unsupervised training, we connect the encoder layers of the trained deep manifold preserving autoencoder with a softmax classifier to construct a cascade model and fine-tune this deep neural network with labeled training data. The proposed method learns discriminative features by preserving the structure of the input datasets from the manifold learning view and minimizing reconstruction error from the deep learning view from a large amount of unlabeled data. Extensive experiments on the public breast cancer dataset (BreaKHis) demonstrate the effectiveness of the proposed method.","","","10.1109/TCBB.2018.2858763","Fok Ying Tung Education Foundation; Foundation for Youth Science and Technology Innovation Research Team of Sichuan Province; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8417906","Histopathological image classification;breast cancer diagnose;manifold learning;autoencoder;deep neural networks","Breast cancer;Manifolds;Feature extraction;Neural networks;Training;Computer architecture","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Semi-Supervised Image Classification With Self-Paced Cross-Task Networks","S. Wu; Q. Ji; S. Wang; H. Wong; Z. Yu; Y. Xu","School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; Department of Computer Science, City University of Hong Kong, Kowloon, Hong Kong, China; School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; School of Computer Science and Engineering, South China University of Technology, Guangzhou, China","IEEE Transactions on Multimedia","","2018","20","4","851","865","In a semi-supervised setting, direct training of a deep discriminative model on partially labeled images often suffers from overfitting and poor performance, because only a small number of labeled images are available, and errors in label propagation are, in many cases, inevitable. In this paper, we introduce an auxiliary clustering task to explore the structure of the image data, and judiciously weigh unlabeled data to alleviate the influence of ambiguous data on model training. For this purpose, we propose a cross-task network composed of two streams to jointly learn two tasks: classification and clustering. Based on the model predictions, a large number of pairwise constraints can be generated from unlabeled images, and are fed to the clustering stream. Since pairwise constraints encode weak supervision information, the clustering is tolerant of errors in labeling. Unlabeled images are weighted according to the distances to the clusters discovered, and a better discriminative model is trained on the classification stream associated with a weighted softmax loss. Furthermore, a self-paced learning paradigm is adopted to gradually train our deep model from easy examples to difficult ones. Experimental results on widely used image classification datasets confirm the effectiveness and superiority of the proposed approach.","","","10.1109/TMM.2017.2758522","National Natural Science Foundation of China; Natural Science Foundation of Guangdong Province; Research Grants Council of the Hong Kong Special Administration Region; City University of Hong Kong; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8054702","Image classification;semi-supervised learning;cross-task network;self-paced paradigm","Training;Data models;Semisupervised learning;Streaming media;Labeling;Predictive models","image classification;learning (artificial intelligence);pattern classification;pattern clustering","semisupervised image classification;self-paced cross-task networks;direct training;deep discriminative model;partially labeled images;overfitting performance;poor performance;label propagation;auxiliary clustering task;image data;unlabeled data;ambiguous data;model training;cross-task network;model predictions;pairwise constraints;unlabeled images;clustering stream;weak supervision information;classification stream;deep model;image classification datasets","","3","71","","","","","IEEE","IEEE Journals"
"Class-Aware Fully Convolutional Gaussian and Poisson Denoising","T. Remez; O. Litany; R. Giryes; A. M. Bronstein","School of Electrical Engineering, Tel Aviv University, Tel Aviv, Israel; School of Electrical Engineering, Tel Aviv University, Tel Aviv, Israel; School of Electrical Engineering, Tel Aviv University, Tel Aviv, Israel; Department of Computer Science, Technion–Israel Institute of Technology, Haifa, Israel","IEEE Transactions on Image Processing","","2018","27","11","5707","5722","We propose a fully convolutional neural-network architecture for image denoising which is simple yet powerful. Its structure allows to exploit the gradual nature of the denoising process, in which the shallow layers handle local noise statistics, while deeper layers recover edges and enhance textures. Our method advances the state of the art when trained for different noise levels and distributions (both Gaussian and Poisson). In addition, we show that making the denoiser class-aware by exploiting semantic class information boosts the performance, enhances the textures, and reduces the artifacts.","","","10.1109/TIP.2018.2859044","ERC-StG RAPID PI Bronstein; ERC-StG SPADE PI Giryes; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8418389","Image denoising;Gaussian noise;Poisson noise;video denoising;deep learning;fully convolutional networks;class-aware denoising","Noise reduction;Image denoising;Gaussian noise;Convolutional neural networks;Neural networks;Deep learning","feedforward neural nets;Gaussian processes;image denoising;image texture;learning (artificial intelligence)","image denoising;denoising process;shallow layers;local noise statistics;deeper layers;textures;denoiser class-aware;semantic class information;class-aware fully convolutional Gaussian;Poisson denoising;fully convolutional neural-network architecture;noise levels","","3","66","","","","","IEEE","IEEE Journals"
"Failing to Learn: Autonomously Identifying Perception Failures for Self-Driving Cars","M. S. Ramanagopal; C. Anderson; R. Vasudevan; M. Johnson-Roberson","Robotics Institute, University of Michigan, Ann Arbor, MI, USA; Robotics Institute, University of Michigan, Ann Arbor, MI, USA; Mechanical Engineering, University of Michigan, Ann Arbor, MI, USA; Department of Naval Architecture and Marine Engineering, University of Michigan, Ann Arbor, MI, USA","IEEE Robotics and Automation Letters","","2018","3","4","3860","3867","One of the major open challenges in self-driving cars is the ability to detect cars and pedestrians to safely navigate in the world. Deep learning-based object detector approaches have enabled great advances in using camera imagery to detect and classify objects. But for a safety critical application, such as autonomous driving, the error rates of the current state of the art are still too high to enable safe operation. Moreover, the characterization of object detector performance is primarily limited to testing on prerecorded datasets. Errors that occur on novel data go undetected without additional human labels. In this letter, we propose an automated method to identify mistakes made by object detectors without ground truth labels. We show that inconsistencies in the object detector output between a pair of similar images can be used as hypotheses for false negatives (e.g., missed detections) and using a novel set of features for each hypothesis, an off-the-shelf binary classifier can be used to find valid errors. In particular, we study two distinct cues-temporal and stereo inconsistencies-using data that are readily available on most autonomous vehicles. Our method can be used with any camera-based object detector and we illustrate the technique on several sets of real world data. We show that a state-of-the-art detector, tracker, and our classifier trained only on synthetic data can identify valid errors on KITTI tracking dataset with an average precision of 0.94. We also release a new tracking dataset with 104 sequences totaling 80,655 labeled pairs of stereo images along with ground truth disparity from a game engine to facilitate further research.","","","10.1109/LRA.2018.2857402","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8412512","Computer vision for transportation;object detection;segmentation and categorization;visual learning","Detectors;Cameras;Object recognition;Autonomous automobiles;Object detection;Autonomous vehicles;Testing","image classification;learning (artificial intelligence);object detection;stereo image processing;traffic engineering computing","self-driving cars;camera imagery;autonomous driving;ground truth labels;off-the-shelf binary classifier;autonomous vehicles;camera-based object detector;KITTI tracking dataset;deep learning-based object detector approaches","","4","24","","","","","IEEE","IEEE Journals"
"Content-Attention Representation by Factorized Action-Scene Network for Action Recognition","J. Hou; X. Wu; Y. Sun; Y. Jia","Beijing Laboratory of Intelligent Information Technology, School of Computer Science, Beijing Institute of Technology, Beijing, China; Beijing Laboratory of Intelligent Information Technology, School of Computer Science, Beijing Institute of Technology, Beijing, China; Beijing Laboratory of Intelligent Information Technology, School of Computer Science, Beijing Institute of Technology, Beijing, China; Beijing Laboratory of Intelligent Information Technology, School of Computer Science, Beijing Institute of Technology, Beijing, China","IEEE Transactions on Multimedia","","2018","20","6","1537","1547","During action recognition in videos, irrelevant motions in the background can greatly degrade the performance of recognizing specific actions with which we actually concern ourself here. In this paper, a novel deep neural network, called factorized action-scene network (FASNet), is proposed to encode and fuse the most relevant and informative semantic cues for action recognition. Specifically, we decompose the FASNet into two components. One is a newly designed encoding network, named content attention network (CANet), which encodes local spatial-temporal features to learn the action representations with good robustness to the noise of irrelevant motions. The other is a fusion network, which integrates the pretrained CANet to fuse the encoded spatial-temporal features with contextual scene feature extracted from the same video, for learning more descriptive and discriminative action representations. Moreover, different from the existing deep learning based tasks for generic action recognition, which applies softmax loss function as the training guidance, we formulate two loss functions for guiding the proposed model to accomplish more specific action recognition tasks, i.e., the multilabel correlation loss for multilabel action recognition and the triplet loss for complex event detection. Extensive experiments on the Hollywood2 dataset and the TRECVID MEDTest 14 dataset show that our method achieves superior performance compared with the state-of-the-art methods.","","","10.1109/TMM.2017.2771462","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8101020","Deep neural network;multi-label action recognition;complex event detection","Videos;Feature extraction;Training;Encoding;Event detection;Three-dimensional displays","content-based retrieval;convolution;feature extraction;image classification;image motion analysis;image representation;learning (artificial intelligence);neural nets;object detection;object recognition;probability;spatiotemporal phenomena;video coding","deep neural network;local spatial-temporal features;irrelevant motions;discriminative action representations;generic action recognition;multilabel action recognition;network fusion;content-attention representation;factorized action-scene network;FASNet;informative semantic cues;content attention network;CANet;contextual scene feature extraction;softmax loss function;multilabel correlation loss;triplet loss;complex event detection;Hollywood2 dataset;videos;deep learning based tasks;state-of-the-art methods;spatial-temporal features encoding;RECVID;MEDTest","","4","55","","","","","IEEE","IEEE Journals"
"Pulmonary Artery–Vein Classification in CT Images Using Deep Learning","P. Nardelli; D. Jimenez-Carretero; D. Bermejo-Pelaez; G. R. Washko; F. N. Rahaghi; M. J. Ledesma-Carbayo; R. San José Estépar","Applied Chest Imaging Laboratory, Brigham and Women’s Hospital, Harvard Medical School, Boston, MA, USA; Biomedical Image Technologies, Universidad Politécnica de Madrid, Madrid, Spain; Biomedical Image Technologies, Universidad Politécnica de Madrid, Madrid, Spain; Applied Chest Imaging Laboratory, Brigham and Women’s Hospital, Harvard Medical School, Boston, MA, USA; Applied Chest Imaging Laboratory, Brigham and Women’s Hospital, Harvard Medical School, Boston, MA, USA; Biomedical Image Technologies, Universidad Politécnica de Madrid, Madrid, Spain; Applied Chest Imaging Laboratory, Brigham and Women’s Hospital, Harvard Medical School, Boston, MA, USA","IEEE Transactions on Medical Imaging","","2018","37","11","2428","2440","Recent studies show that pulmonary vascular diseases may specifically affect arteries or veins through different physiologic mechanisms. To detect changes in the two vascular trees, physicians manually analyze the chest computed tomography (CT) image of the patients in search of abnormalities. This process is time consuming, difficult to standardize, and thus not feasible for large clinical studies or useful in real-world clinical decision making. Therefore, automatic separation of arteries and veins in CT images is becoming of great interest, as it may help physicians to accurately diagnose pathological conditions. In this paper, we present a novel, fully automatic approach to classify vessels from chest CT images into arteries and veins. The algorithm follows three main steps: first, a scale-space particles segmentation to isolate vessels; then a 3-D convolutional neural network (CNN) to obtain a first classification of vessels; finally, graph-cuts' optimization to refine the results. To justify the usage of the proposed CNN architecture, we compared different 2-D and 3-D CNNs that may use local information from bronchus- and vessel-enhanced images provided to the network with different strategies. We also compared the proposed CNN approach with a random forests (RFs) classifier. The methodology was trained and evaluated on the superior and inferior lobes of the right lung of 18 clinical cases with noncontrast chest CT scans, in comparison with manual classification. The proposed algorithm achieves an overall accuracy of 94%, which is higher than the accuracy obtained using other CNN architectures and RF. Our method was also validated with contrast-enhanced CT scans of patients with chronic thromboembolic pulmonary hypertension to demonstrate that our model generalizes well to contrast-enhanced modalities. The proposed method outperforms state-of-the-art methods, paving the way for future use of 3-D CNN for artery/vein classification in CT images.","","","10.1109/TMI.2018.2833385","National Heart, Lung, and Blood Institute; Ministerio de Economía y Competitividad; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354838","Artery-vein separation;pulmonar vascular disease;automatic classification;pulmonary vessels;machine learning;lung","Computed tomography;Arteries;Three-dimensional displays;Veins;Image segmentation;Lung;Computer architecture","blood vessels;computerised tomography;diseases;image classification;image enhancement;image segmentation;learning (artificial intelligence);lung;medical image processing;neural nets","3D convolutional neural network;clinical cases;physiologic mechanisms;clinical studies;tomography image;vascular trees;pulmonary vascular diseases;recent studies;pulmonary artery-vein classification;pulmonary hypertension;contrast-enhanced CT scans;manual classification;noncontrast chest CT scans;CNN approach;vessel-enhanced images;CNN architecture;scale-space particles segmentation;chest CT images;fully automatic approach;real-world clinical decision making","","1","34","","","","","IEEE","IEEE Journals"
"Active Learning With Convolutional Neural Networks for Hyperspectral Image Classification Using a New Bayesian Approach","J. M. Haut; M. E. Paoletti; J. Plaza; J. Li; A. Plaza","Department of Technology of Computers and Communications, Hyperspectral Computing Laboratory, Polytechnic School of Cáceres, University of Extremadura, Cáceres, Spain; Department of Technology of Computers and Communications, Hyperspectral Computing Laboratory, Polytechnic School of Cáceres, University of Extremadura, Cáceres, Spain; Department of Technology of Computers and Communications, Hyperspectral Computing Laboratory, Polytechnic School of Cáceres, University of Extremadura, Cáceres, Spain; Guangdong Provincial Key Laboratory of Urbanization and Geosimulation, Center of Integrated Geographic Information Analysis, School of Geography and Planning, Sun Yat-sen University, Guangzhou, China; Department of Technology of Computers and Communications, Hyperspectral Computing Laboratory, Polytechnic School of Cáceres, University of Extremadura, Cáceres, Spain","IEEE Transactions on Geoscience and Remote Sensing","","2018","56","11","6440","6461","Hyperspectral imaging is a widely used technique in remote sensing in which an imaging spectrometer collects hundreds of images (at different wavelength channels) for the same area on the surface of the earth. In the last two decades, several methods (unsupervised, supervised, and semisupervised) have been proposed to deal with the hyperspectral image classification problem. Supervised techniques have been generally more popular, despite the fact that it is difficult to collect labeled samples in real scenarios. In particular, deep neural networks, such as convolutional neural networks (CNNs), have recently shown a great potential to yield high performance in the hyperspectral image classification. However, these techniques require sufficient labeled samples in order to perform properly and generalize well. Obtaining labeled data is expensive and time consuming, and the high dimensionality of hyperspectral data makes it difficult to design classifiers based on limited samples (for instance, CNNs overfit quickly with small training sets). Active learning (AL) can deal with this problem by training the model with a small set of labeled samples that is reinforced by the acquisition of new unlabeled samples. In this paper, we develop a new AL-guided classification model that exploits both the spectral information and the spatial-contextual information in the hyperspectral data. The proposed model makes use of recently developed Bayesian CNNs. Our newly developed technique provides robust classification results when compared with other state-of-the-art techniques for hyperspectral image classification.","","","10.1109/TGRS.2018.2838665","Ministerio de Educación, Secretaría de Estado de Educación, Formación Profesional y Universidades, por la que se convocan ayudas para la formación de profesorado universitario, de los subprogramas de Formación y de Movilidad incluidos en el Programa Estatal de Promoción del Talento y su Empleabilidad, en el marco del Plan Estatal de Investigación Científica y Técnica y de Innovación 2013–2016; National Natural Science Foundation of China; National Key Research and Development Program of China; Natural Science Foundation of Guangdong Province; MINECO project TIN2015-63646-C5-5-R; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8390931","Active learning (AL);Bayesian-convolutional neural network (B-CNN);hyperspectral remote sensing image classification","Hyperspectral imaging;Feature extraction;Training;Bayes methods;Imaging;Neural networks","belief networks;convolution;feedforward neural nets;geophysical image processing;image classification;learning (artificial intelligence);remote sensing","imaging spectrometer;hyperspectral image classification problem;deep neural networks;convolutional neural networks;sufficient labeled samples;hyperspectral data;active learning;hyperspectral imaging;Bayesian CNN","","17","102","","","","","IEEE","IEEE Journals"
"Mobile Phone Clustering From Speech Recordings Using Deep Representation and Spectral Clustering","Y. Li; X. Zhang; X. Li; Y. Zhang; J. Yang; Q. He","School of Electronic and Information Engineering, South China University of Technology, Guangzhou, China; School of Electronic and Information Engineering, South China University of Technology, Guangzhou, China; School of Electronic and Information Engineering, South China University of Technology, Guangzhou, China; School of Electronic and Information Engineering, South China University of Technology, Guangzhou, China; School of Electronic and Information Engineering, South China University of Technology, Guangzhou, China; School of Electronic and Information Engineering, South China University of Technology, Guangzhou, China","IEEE Transactions on Information Forensics and Security","","2018","13","4","965","977","Considerable attention has been paid to acquisition device recognition over the past decade in the forensic community, especially in digital image forensics. In contrast, acquisition device clustering from speech recordings is a new problem that aims to merge the recordings acquired by the same device into a single cluster without having prior information about the recordings and training classifiers in advance. In this paper, we propose a method for mobile phone clustering from speech recordings by using a new feature of deep representation and a spectral clustering algorithm. The new feature is learned by a deep auto-encoder network for representing the intrinsic trace left behind by each phone in the recordings, and spectral clustering is used to merge recordings acquired by the same phone into a single cluster. The impacts of the structures of the deep auto-encoder network on the performance of the new feature are discussed. Different features are compared with one another. The proposed method is compared with others and evaluated under special conditions. The results show that the proposed method is effective under these conditions and the new feature outperforms other features.","","","10.1109/TIFS.2017.2774505","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8113574","Deep representation;spectral clustering;mobile phone clustering;acquisition device recognition;speech forensics","Mobile handsets;Speech;Feature extraction;Mel frequency cepstral coefficient;Speech recognition;Forensics;Fingerprint recognition","audio recording;mobile computing;mobile handsets;pattern clustering;spectral analysis;speech coding","deep auto-encoder network;mobile phone clustering;speech recordings;deep representation;acquisition device recognition;forensic community;digital image forensics;spectral clustering algorithm","","1","44","","","","","IEEE","IEEE Journals"
"Minutiae-Based Weighting Aggregation of Deep Convolutional Features for Vein Recognition","J. Wang; K. Yang; Z. Pan; G. Wang; M. Li; Y. Li","School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, China; School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, China; School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, China; School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, China; School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, China; School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, China","IEEE Access","","2018","6","","61640","61650","Deep convolutional neural network (DCNN) has achieved an outstanding performance in large-scale image recognition task because of its discriminative feature representation ability, and pre-trained DCNN models trained for one task have also been applied to domains that are different from their original purposes. Inspired by this idea, a novel hand-dorsa vein recognition model is constructed by adopting DCNN pre-trained on a large-scale database as a universal feature descriptor. However, due to the sparse distribution property of vein information, it is difficult to employ pre-trained DCNN model to extract discriminative deep convolutional features. Therefore, to obtain useful and discriminative deep convolutional features, a novel minutiae-based weighting aggregation (MWA) method is proposed. In specific, the proposed global max-pooling of preserving spatial position information is applied on the feature maps of convolutional layer to localize the minutiae of vein information, and then the minutiae feature of vein image is regarded as the mask that is named as minutiae feature mask, to select deep convolutional features that contain minutiae feature information of vein image. The final feature representation is formed by concatenating each selected deep convolutional feature that is generated by each minutiae feature mask. Series rigorous experiments on the lab-made database are conducted to evidence the effectiveness and feasibility of the proposed MWA for vein recognition. What's more, an additional experiment with subset of PolyU database illustrates its generalization ability and robustness.","","","10.1109/ACCESS.2018.2876396","Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8493468","Pre-trained DCNN;hand-dorsa vein recognition;minutiae-based weighting aggregation;global max-pooling of preserving spatial position information;minutiae feature mask","Veins;Feature extraction;Task analysis;Image recognition;Computational modeling;Databases;Shape","convolutional neural nets;feature extraction;image classification;image matching;image representation;learning (artificial intelligence);neural nets;vein recognition","convolutional neural network;large-scale image recognition task;discriminative feature representation ability;hand-dorsa vein recognition model;universal feature descriptor;vein information;discriminative deep convolutional features;feature maps;convolutional layer;vein image;minutiae feature mask;feature representation;deep convolutional feature;pretrained DCNN models;minutiae-based weighting aggregation;global max-pooling","","3","40","","","","","IEEE","IEEE Journals"
"Deep Learning Models Based on Distributed Feature Representations for Alternative Splicing Prediction","M. Oubounyt; Z. Louadi; H. Tayara; K. To Chong","Department of Information and Electronics Engineering, Chonbuk National University, Jeonju, South Korea; Department of Information and Electronics Engineering, Chonbuk National University, Jeonju, South Korea; Department of Information and Electronics Engineering, Chonbuk National University, Jeonju, South Korea; Division of Electronic Engineering, and Advanced Research Center of Electronics and Information, Chonbuk National University, Jeonju, South Korea","IEEE Access","","2018","6","","58826","58834","Alternative splicing (AS) is a fundamental step in mRNA maturation and gene expression. The advancement in RNA sequencing technologies has shed light on the role of AS in increasing protein isoform diversity. AS is recognized to be involved in the regulation of both physiological and pathological functions, hence it is an essential part of the study of gene regulation development and diseases. With the recent advances in machine learning, there is an interest in developing accurate deep learning based computational models for AS prediction. In this paper, we propose a convolutional neural network and multilayer perceptron models to tackle the AS prediction task as classification and regression. These models use feature representations learned from genomic data and cellular context. Unlike previous works which use hand-crafted feature extraction, we propose an automatic feature learning approach to avoid explicit and predefined feature extraction. The proposed approach is based on the adaptation of two extensively used natural language processing techniques, namely word2vec and doc2vec. In order to understand the effects of different representation learning techniques, many experiments have been conducted to predict AS based on the cassette exons and cell type. Overall, experimental results on five tissues data set prove that learning features from genome sequence add a significant improvement to AS outcome prediction in both classification and regression tasks.","","","10.1109/ACCESS.2018.2874208","National Research Foundation of Korea; National Research Foundation of Korea; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8485330","Alternative splicing (AS);convolution neural network (CNN);cassette exons;feature representations","Splicing;Feature extraction;Computational modeling;Predictive models;Machine learning;Proteins;Data models","","","","2","31","","","","","IEEE","IEEE Journals"
"MS-CapsNet: A Novel Multi-Scale Capsule Network","C. Xiang; L. Zhang; Y. Tang; W. Zou; C. Xu","Shenzhen Key Laboratory of Advanced Machine Learning and Applications, College of Information Engineering, Shenzhen University, Shenzhen, China; INSA de Rennes, IETR (Institut d’Electronique et de Telecommunication de Rennes) - UMR CNRS 6164, Rennes, France; Shenzhen Key Laboratory of Advanced Machine Learning and Applications, College of Information Engineering, Shenzhen University, Shenzhen, China; Shenzhen Key Laboratory of Advanced Machine Learning and Applications, College of Information Engineering, Shenzhen University, Shenzhen, China; College of Mathematics and Statistics, Shenzhen University, Shenzhen, China","IEEE Signal Processing Letters","","2018","25","12","1850","1854","Capsule network is a novel architecture to encode the properties and spatial relationships of the feature in an image, which shows encouraging results on image classification. However, the original capsule network is not suitable for some classification tasks, where the target objects are complex internal representations. Hence, we propose a multi-scale capsule network that is more robust and efficient for feature representation in image classification. The proposed multi-scale capsule network consists of two stages. In the first stage, structural and semantic information are obtained by multi-scale feature extraction. In the second stage, the hierarchy of features is encoded to multi-dimensional primary capsules. Moreover, we propose an improved dropout to enhance the robustness of the capsule network. Experimental results show that our method has a competitive performance on FashionMNIST and CIFAR10 datasets.","","","10.1109/LSP.2018.2873892","NSFC; Natural Science Foundation of Shenzhen; Interdisciplinary Innovation Team of Shenzhen University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8481393","Capsule networks;multi-scale;capsule dropout;deep learning","Feature extraction;Encoding;Semantics;Convolutional codes","feature extraction;image classification;image representation;network theory (graphs)","image classification;feature representation;multiscale feature extraction;multidimensional primary capsules;multiscale capsule network;complex internal representations;structural information;semantic information;FashionMNIST datasets;CIFAR10 datasets","","10","23","","","","","IEEE","IEEE Journals"
"Optimally Connected Deep Belief Net for Click Through Rate Prediction in Online Advertising","R. Xu; M. Wang; Y. Xie","Key Laboratory of Intelligent Computing and Signal Processing, Ministry of Education, Anhui University, Hefei, China; School of Computer Science and Technology, Anhui University, Hefei, China; Key Laboratory of Intelligent Computing and Signal Processing, Ministry of Education, Anhui University, Hefei, China","IEEE Access","","2018","6","","43009","43020","Many researches of machine learning aim to improve the click prediction of online advertisement (ads). One important method is to investigate the pairwise relevance among instances on impression data and the global interaction among the key features of instances. However, the feature extraction ability is not effective for large amounts of variables in prediction process. In this paper, we propose a novel model named optimally connected deep belief net (OCDBN) for click prediction with rotation codes whitening technology based on optimal mean removal. According to what we have learned, OCDBN is the first method that tries to utilize optimal mean removal technology to improve the effectiveness of click through the rate prediction. OCDBN is capable of extracting global primary features of input instances with various elements, which can be implemented for single and sequential ads impression. Extensive experiments have been performed to show the effectiveness of our architecture by modeling different types of input instances. After implementing comprehensive experiments in a 16-nodes cluster with 32 vCPUs on Amazon EC2, the results also show that the architecture significantly outperforms the existing models in accuracy, coefficient of determination, sparsity, and perplexity of click prediction.","","","10.1109/ACCESS.2018.2861429","National Natural Science Foundation of China; 973 Project; Natural Science Foundation of Anhui Province; Humanities and Social Sciences in Universities of Anhui Province; Anhui University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8430515","Online advertising;click through rate;restricted Boltzmann machine;cloud computing","Feature extraction;Machine learning;Predictive models;Advertising;Computational modeling;Robustness;Data mining","advertising;belief networks;feature extraction;Internet;learning (artificial intelligence)","optimally connected deep belief net;rate prediction;online advertising;click prediction;online advertisement;global interaction;key features;feature extraction ability;prediction process;OCDBN;optimal mean removal technology;global primary features;input instances;single ads impression;sequential ads impression;vCPU;Amazon EC2","","2","39","","","","","IEEE","IEEE Journals"
"Exploring Context with Deep Structured Models for Semantic Segmentation","G. Lin; C. Shen; A. van den Hengel; I. Reid","School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science, University of Adelaide, Adelaide, SA, Australia; School of Computer Science, University of Adelaide, Adelaide, SA, Australia; School of Computer Science, University of Adelaide, Adelaide, SA, Australia","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","6","1352","1366","We propose an approach for exploiting contextual information in semantic image segmentation, and particularly investigate the use of patch-patch context and patch-background context in deep CNNs. We formulate deep structured models by combining CNNs and Conditional Random Fields (CRFs) for learning the patch-patch context between image regions. Specifically, we formulate CNN-based pairwise potential functions to capture semantic correlations between neighboring patches. Efficient piecewise training of the proposed deep structured model is then applied in order to avoid repeated expensive CRF inference during the course of back propagation. For capturing the patch-background context, we show that a network design with traditional multi-scale image inputs and sliding pyramid pooling is very effective for improving performance. We perform comprehensive evaluation of the proposed method. We achieve new state-of-the-art performance on a number of challenging semantic segmentation datasets.","","","10.1109/TPAMI.2017.2708714","ARC Future Fellowship; ARC Laureate Fellowship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7934393","Semantic segmentation;convolutional neural networks;conditional random fields;contextual models","Semantics;Context;Image segmentation;Context modeling;Training;Image resolution;Neural networks","feedforward neural nets;image capture;image classification;image segmentation;learning (artificial intelligence)","deep structured model;semantic image segmentation;patch-patch context;patch-background context;deep CNNs;semantic correlations;neighboring patches;traditional multiscale image inputs;sliding pyramid pooling;semantic segmentation datasets;network design","","7","60","","","","","IEEE","IEEE Journals"
"BreakingNews: Article Annotation by Image and Text Processing","A. Ramisa; F. Yan; F. Moreno-Noguer; K. Mikolajczyk","Institut de Robòtica i Informàtica Industrial, CSIC-UPC, Barcelona, Spain; Centre for Vision, Speech and Signal Processing, University of Surrey, Guildford, United Kingdom; Institut de Robòtica i Informàtica Industrial, CSIC-UPC, Barcelona, Spain; Department of Electrical and Electronic Engineering, Imperial College London, London, United Kingdom","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","5","1072","1085","Building upon recent Deep Neural Network architectures, current approaches lying in the intersection of Computer Vision and Natural Language Processing have achieved unprecedented breakthroughs in tasks like automatic captioning or image retrieval. Most of these learning methods, though, rely on large training sets of images associated with human annotations that specifically describe the visual content. In this paper we propose to go a step further and explore the more complex cases where textual descriptions are loosely related to the images. We focus on the particular domain of news articles in which the textual content often expresses connotative and ambiguous relations that are only suggested but not directly inferred from images. We introduce an adaptive CNN architecture that shares most of the structure for multiple tasks including source detection, article illustration and geolocation of articles. Deep Canonical Correlation Analysis is deployed for article illustration, and a new loss function based on Great Circle Distance is proposed for geolocation. Furthermore, we present BreakingNews, a novel dataset with approximately 100K news articles including images, text and captions, and enriched with heterogeneous meta-data (such as GPS coordinates and user comments). We show this dataset to be appropriate to explore all aforementioned problems, for which we provide a baseline performance using various Deep Learning architectures, and different representations of the textual and visual features. We report very promising results and bring to light several limitations of current state-of-the-art in this kind of domain, which we hope will help spur progress in the field.","","","10.1109/TPAMI.2017.2721945","MINECO project RobInstruct; Spanish State Research Agency; ERA-net CHISTERA project VISEN; EPSRC EP/K01904X/2 Visen; EP/N007743/1 FACER2VM; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7964736","News dataset;story illustration;geolocation;caption generation;vision and text","Geology;Visualization;Global Positioning System;Computer architecture;Computer vision;Correlation;Natural language processing","computer vision;image annotation;image retrieval;learning (artificial intelligence);natural language processing;neural net architecture;text analysis","BreakingNews;article annotation;text processing;Computer Vision;Natural Language Processing;automatic captioning;learning methods;training sets;human annotations;visual content;textual descriptions;news articles;textual content;adaptive CNN architecture;article illustration;Deep Canonical Correlation Analysis;Great Circle Distance;Deep Learning architectures;textual features;visual features;image processing;source detection;deep neural network architectures;image retrieval;article geolocation;loss function;heterogeneous meta-data;temperature 100.0 K","","3","86","","","","","IEEE","IEEE Journals"
"Dynamic Energy Optimization in Chip Multiprocessors Using Deep Neural Networks","M. G. Moghaddam; W. Guan; C. Ababei","Department of Electrical and Computer Engineering, Marquette University, Milwaukee, WI, USA; Department of Electrical and Computer Engineering, Marquette University, Milwaukee, WI, USA; Department of Electrical and Computer Engineering, Marquette University, Milwaukee, WI, USA","IEEE Transactions on Multi-Scale Computing Systems","","2018","4","4","649","661","We investigate the use of deep neural network (DNN) models for energy optimization under performance constraints in chip multiprocessor systems. We introduce a dynamic energy management algorithm implemented in three phases. In the first phase, training data is collected by running several selected instrumented benchmarks. A training data point represents a pair of values of cores’ workload characteristics and of optimal voltage/frequency (V/F) pairs. This phase employs Kalman filtering for workload prediction and an efficient heuristic algorithm based on dynamic voltage and frequency scaling. The second phase represents the training process of the DNN model. In the last phase, the DNN model is used to directly identify V/F pairs that can achieve lower energy consumption without performance degradation beyond the acceptable threshold set by the user. Simulation results on 16 and 64 core network-on-chip based architectures demonstrate that the proposed approach can achieve up to 55 percent energy reduction for 10 percent performance degradation constraints. In addition, the proposed DNN approach is compared against existing approaches based on reinforcement learning and Kalman filtering and found that it provides average improvements in energy-delay-product (EDP) of 6.3 and 6 percent for the 16 core architecture and of 7.4 and 5.5 percent for the 64 core architecture.","","","10.1109/TMSCS.2018.2870438","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8466912","Chip multiprocessors;energy optimization;Kalman filter;reinforcement learning;deep neural network","Optimization;Kalman filters;Reinforcement learning;Prediction algorithms;Energy consumption;Artificial neural networks","","","","","32","","","","","IEEE","IEEE Journals"
"Zero-Shot Learning Based on Deep Weighted Attribute Prediction","X. Wang; C. Chen; Y. Cheng; X. Chen; Y. Liu","School of Information and Control Engineering, China University of Mining and Technology, Xuzhou 221116, China.; School of Information and Control Engineering, China University of Mining and Technology, Xuzhou 221116, China.; School of Information and Control Engineering, China University of Mining and Technology, Xuzhou 221116, China (e-mail: chengyuhu@163.com).; Department of Electronic Science and Technology, University of Science and Technology of China, Hefei 230027, China.; Department of Biomedical Engineering, Hefei University of Technology, Hefei 230009, China.","IEEE Transactions on Systems, Man, and Cybernetics: Systems","","2018","PP","99","1","10","In zero-shot learning, attributes play as a bridge from original images to class labels. Therefore, to achieve accurate zero-shot image classification, we mainly focus on improving attribute prediction accuracy by taking full advantage of prior information about attribute from two aspects. First, we present a new attribute classifier called deep attribute prediction (DeepAP) model by using supervised deep convolutional neural networks (DCNNs), where the attribute label information participates in the training of DCNNs. Unlike common DCNNs that are usually used to extract image features, the constructed DCNNs are used to directly predict attribute values from the original input images. Thus, the designed DeepAP model can serve as the mapping from low-level image features to high-level semantic attributes in the traditional direct attribute prediction (DAP) model. Second, another prior information about attribute, i.e., class-attribute matrix is used to mine the attribute-class correlation with sparse representation coefficients. Since the attribute-class correlation can reflect different contributions of attributes to classification, we use it to define attribute weights and incorporate the idea of weighted attributes into DeepAP to form the deep weighted attribute prediction (DWAP) model. Experiments on three real datasets show that DWAP outperforms the deep attribute network and DAP on attribute prediction and zero-shot image classification.","","","10.1109/TSMC.2018.2837670","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8385127","Attribute prediction;attribute weight;convolutional neural network;sparse representation coefficient (SRC);zero-shot learning","Feature extraction;Training;Predictive models;Semantics;Testing;Support vector machines;Neural networks","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Complementary Tracking via Dual Color Clustering and Spatio-Temporal Regularized Correlation Learning","J. Fan; H. Song; K. Zhang; Q. Liu; W. Lian","B-DAT, CICAEET, Nanjing University of Information Science and Technology, Nanjing, China; B-DAT, CICAEET, Nanjing University of Information Science and Technology, Nanjing, China; B-DAT, CICAEET, Nanjing University of Information Science and Technology, Nanjing, China; B-DAT, CICAEET, Nanjing University of Information Science and Technology, Nanjing, China; Department of Computer Science, Changzhi University, Changzhi, China","IEEE Access","","2018","6","","56526","56538","Recently, a simple, yet effective and efficient tracker named Staple has achieved promising performance in terms of efficiency and accuracy on a series of visual tracking benchmarks. Staple is equipped with complementary learners of discriminative correlation filters (DCFs) and color histograms, which are robust to both color changes and deformations. However, it has some drawbacks: 1) Staple only employs standard color histograms with the same quantization step for all sequences, which does not consider the specific structural information of target in each sequence, thereby affecting its discriminative capability to separate target from background. 2) The standard DCFs are efficient but suffer from unwanted boundary effects, leading to failures in some challenging scenarios. To address these issues, we present a dual color clustering and spatio-temporal regularized correlation regressions-based complementary tracker (CSCT). The proposed CSCT includes two components with complementary merits to adaptively deal with significant color variations and deformations for each sequence: First, we design a novel color clustering-based histogram model that first adaptively divides the colors of the target in the 1st frame into several cluster centers, and then the cluster centers are taken as references to construct adaptive color histograms for targets in the coming frames, which enable to adapt significant target deformations. Second, we propose to learn spatio-temporal regularized CFs, which not only enable to avoid boundary effects but also provides a more robust appearance model than the discriminative CFs in Staple in the case of large appearance variations. Compared to Staple, our CSCT with handcrafted features achieves a gain of 5.9%, 3.4%, and 1.5% on OTB100, Temple-Color, and VOT2016 benchmarks in terms of AUC and EAO scores, respectively. Moreover, our CSCT performs favorably against several state-of-the-art trackers, including the deep learning-based trackers.","","","10.1109/ACCESS.2018.2872691","National Natural Science Foundation of China; Natural Science Foundation of Jiangsu Province; Applied Basic Research Project in Shanxi Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8476545","Visual tracking;correlation filter;color histograms;spatio-temporal regularization","Color;Histograms;Target tracking;Robustness;Image color analysis;Correlation","correlation methods;feature extraction;image colour analysis;learning (artificial intelligence);object tracking;regression analysis","color changes;standard color histograms;specific structural information;discriminative capability;unwanted boundary effects;dual color clustering;complementary merits;significant color variations;color clustering-based histogram model;cluster centers;adaptive color histograms;Staple;CSCT performs;deep learning-based trackers;complementary tracking;visual tracking benchmarks;complementary learners;target deformations;Temple-Color benchmark;V0T2016 benchmark;OTB100 benchmark;discriminative correlation filters;spatio-temporal regularized CF;standard DCF;spatio-temporal regularized correlation learning","","2","39","","","","","IEEE","IEEE Journals"
"3-D Convolutional Encoder-Decoder Network for Low-Dose CT via Transfer Learning From a 2-D Trained Network","H. Shan; Y. Zhang; Q. Yang; U. Kruger; M. K. Kalra; L. Sun; W. Cong; G. Wang","Department of Biomedical Engineering, Rensselaer Polytechnic Institute, Troy, NY, USA; College of Computer Science, Sichuan University, Chengdu, China; Department of Biomedical Engineering, Rensselaer Polytechnic Institute, Troy, NY, USA; Department of Biomedical Engineering, Rensselaer Polytechnic Institute, Troy, NY, USA; Department of Radiology, Massachusetts General Hospital, Harvard Medical School, Boston, MA, USA; Department of Radiology, Huaxi MR Research Center, West China Hospital, Sichuan University, Chengdu, China; Department of Biomedical Engineering, Rensselaer Polytechnic Institute, Troy, NY, USA; Department of Biomedical Engineering, Rensselaer Polytechnic Institute, Troy, NY, USA","IEEE Transactions on Medical Imaging","","2018","37","6","1522","1534","Low-dose computed tomography (LDCT) has attracted major attention in the medical imaging field, since CT-associated X-ray radiation carries health risks for patients. The reduction of the CT radiation dose, however, compromises the signal-to-noise ratio, which affects image quality and diagnostic performance. Recently, deep-learning-based algorithms have achieved promising results in LDCT denoising, especially convolutional neural network (CNN) and generative adversarial network (GAN) architectures. This paper introduces a conveying path-based convolutional encoder-decoder (CPCE) network in 2-D and 3-D configurations within the GAN framework for LDCT denoising. A novel feature of this approach is that an initial 3-D CPCE denoising model can be directly obtained by extending a trained 2-D CNN, which is then fine-tuned to incorporate 3-D spatial information from adjacent slices. Based on the transfer learning from 2-D to 3-D, the 3-D network converges faster and achieves a better denoising performance when compared with a training from scratch. By comparing the CPCE network with recently published work based on the simulated Mayo data set and the real MGH data set, we demonstrate that the 3-D CPCE denoising model has a better performance in that it suppresses image noise and preserves subtle structures.","","","10.1109/TMI.2018.2832217","National Natural Science Foundation of China; Science and Technology Project of the Sichuan Province of China; National Institute of Biomedical Imaging and Bioengineering/National Institutes of Health; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8353466","Low-dose CT;denoising;convolutional neural network;generative adversarial network;3D spatial information","Noise reduction;Three-dimensional displays;Two dimensional displays;Computed tomography;Gallium nitride;Solid modeling;Linear programming","computerised tomography;feedforward neural nets;image coding;image denoising;image reconstruction;learning (artificial intelligence);medical image processing","low-dose CT;transfer learning;low-dose computed tomography;medical imaging field;health risks;CT radiation dose;signal-to-noise ratio;image quality;diagnostic performance;deep-learning-based algorithms;LDCT denoising;GAN framework;denoising performance;CPCE network;image noise;2D trained network;3D configurations;2D CNN;3D spatial information;3D convolutional encoder-decoder network;CT-associated X-ray radiation;convolutional neural network;path-based convolutional encoder-decoder network;2D configurations;generative adversarial network architectures;3D CPCE denoising model;subtle structure preservation;image noise suppression","","9","46","","","","","IEEE","IEEE Journals"
"A Framework of Rapid Regional Tsunami Damage Recognition From Post-event TerraSAR-X Imagery Using Deep Neural Networks","Y. Bai; C. Gao; S. Singh; M. Koch; B. Adriano; E. Mas; S. Koshimura","Graduate School of Engineering, Tohoku University, Sendai, Japan; Department of Computer Science, The University of Hong Kong, Hong Kong; Department of Computer Science, University of California at Irvine, Irvine, CA, USA; Center for Remote Sensing, Boston, MA, USA; International Research Institute of Disaster Science, Tohoku University, Sendai, Japan; International Research Institute of Disaster Science, Tohoku University, Sendai, Japan; International Research Institute of Disaster Science, Tohoku University, Sendai, Japan","IEEE Geoscience and Remote Sensing Letters","","2018","15","1","43","47","Near real-time building damage mapping is an indispensable prerequisite for governments to make decisions for disaster relief. With high-resolution synthetic aperture radar (SAR) systems, such as TerraSAR-X, the provision of such products in a fast and effective way becomes possible. In this letter, a deep learning-based framework for rapid regional tsunami damage recognition using post-event SAR imagery is proposed. To perform such a rapid damage mapping, a series of tile-based image split analysis is employed to generate the data set. Next, a selection algorithm with the SqueezeNet network is developed to swiftly distinguish between built-up (BU) and nonbuilt-up regions. Finally, a recognition algorithm with a modified wide residual network is developed to classify the BU regions into wash away, collapsed, and slightly damaged regions. Experiments performed on the TerraSAR-X data from the 2011 Tohoku earthquake and tsunami in Japan show a BU region extraction accuracy of 80.4% and a damage-level recognition accuracy of 74.8%, respectively. Our framework takes around 2 h to train on a new region, and only several minutes for prediction.","","","10.1109/LGRS.2017.2772349","JST CREST, Japan; China Scholarship Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8126255","Deep neural networks;framework;post-event TerraSAR-X imagery;rapid;regional tsunami damage recognition","Synthetic aperture radar;Tiles;Tsunami;Image recognition;Training;Neural networks","disasters;earthquakes;feature extraction;feature selection;geophysical image processing;image recognition;learning (artificial intelligence);neural nets;remote sensing by radar;synthetic aperture radar;tsunami","deep neural networks;high-resolution synthetic aperture radar systems;recognition algorithm;modified wide residual network;BU region extraction accuracy;damage-level recognition accuracy;SAR imagery;regional tsunami damage recognition;TerraSAR-X imagery;building damage mapping;SAR systems;tile-based image split analysis;selection algorithm;SqueezeNet network;AD 2011;Tohoku earthquake;Japan","","2","24","","","","","IEEE","IEEE Journals"
"Demultiplexing Colored Images for Multispectral Photometric Stereo via Deep Neural Networks","Y. Ju; L. Qi; H. Zhou; J. Dong; L. Lu","Department of Computer Science and Technology, Ocean University of China, Qingdao, China; Department of Computer Science and Technology, Ocean University of China, Qingdao, China; Department of Informatics, University of Leicester, Leicester, U.K.; Department of Computer Science and Technology, Ocean University of China, Qingdao, China; Department of Computer Science and Technology, Ocean University of China, Qingdao, China","IEEE Access","","2018","6","","30804","30818","Recovering fine-scale surface shapes is a challenging task in computer vision. Multispectral photometric stereo is one of the popular methods as it can handle non-rigid/moving objects and produces per-pixel dense results. However, the colored images captured by practical multispectral photometric stereo setups are aliased in RGB channels. Existing solutions require prior information to calibrate few points and estimates whole surface normal by the calibration, while prior information is not always available and accurate. Differing from previous solutions which require calibration or other prior information, we first formulate the problem in a learning framework, which directly seeks the per-pixel mapping of the aliased and spectrum-multiplexed pixel response to the anti-aliased and demultiplexed counterpart. In this paper, we propose to use a novel deep neural networks framework as the “demultiplexer”. By using “demultiplexer”and classic photometric stereo, our method can reconstruct a dense and accurate surface normal from a single-frame colored image without any prior information nor extra information injected. We build an imaging device to collect images of different materials under colored lights and white lights. We conducted extensive experiments on our data set and a public data set. The results show that the proposed fully connected network successfully demultiplexes the colorful image and produces satisfactory surface estimation.","","","10.1109/ACCESS.2018.2840138","International Science and Technology Cooperation Program of China; National Natural Science Foundation of China; Engineering and Physical Sciences Research Council; Royal Society-Newton Advanced Fellowship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8364553","Multispectal photometric stereo;spectrum demultiplexing;normal estimation;deep neural networks","Lighting;Gray-scale;Neural networks;Calibration;Cameras;Fabrics;Surface reconstruction","calibration;computer vision;image colour analysis;image reconstruction;learning (artificial intelligence);neural nets;stereo image processing","colorful image;colored lights;imaging device;single-frame colored image;accurate surface normal;dense surface normal;classic photometric stereo;demultiplexer stereo;deep neural networks framework;practical multispectral photometric stereo setups;nonrigid/moving objects;fine-scale surface shapes;satisfactory surface estimation","","","26","","","","","IEEE","IEEE Journals"
"Bridgeout: Stochastic Bridge Regularization for Deep Neural Networks","N. Khan; J. Shah; I. Stavness","Department of Computer Science, University of Saskatchewan, Saskatoon, Canada; British Malaysian Institute, Universiti Kuala Lumpur, Kuala Lumpur, Malaysia; Department of Computer Science, University of Saskatchewan, Saskatoon, Canada","IEEE Access","","2018","6","","42961","42970","A major challenge in training deep neural networks is overfitting, i.e. inferior performance on unseen test examples compared to performance on training examples. To reduce overfitting, stochastic regularization methods have shown superior performance compared to deterministic weight penalties on a number of image recognition tasks. Stochastic methods, such as Dropout and Shakeout, in expectation, are equivalent to imposing a ridge and elastic-net penalty on the model parameters, respectively. However, the choice of the norm of the weight penalty is problem dependent and is not restricted to {L1, L2}. Therefore, in this paper, we propose the Bridgeout stochastic regularization technique and prove that it is equivalent to an Lq penalty on the weights, where the norm q can be learned as a hyperparameter from data. Experimental results show that Bridgeout results in sparse model weights, improved gradients, and superior classification performance compared with Dropout and Shakeout on synthetic and real data sets.","","","10.1109/ACCESS.2018.2863606","Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8425643","Bridge regularization;deep neural networks;dropout;image classification;neural network regularization;neural network training","Training;Stochastic processes;Biological neural networks;Neurons;Bridges;Data models","image recognition;learning (artificial intelligence);neural nets;stochastic processes","sparse model weights;stochastic bridge regularization;deep neural networks;stochastic regularization methods;deterministic weight penalties;image recognition tasks;elastic-net penalty;model parameters;weight penalty;Lq penalty;bridgeout stochastic regularization technique","","1","40","","","","","IEEE","IEEE Journals"
"Object Classification With Joint Projection and Low-Rank Dictionary Learning","H. Foroughi; N. Ray; H. Zhang","Department of Computing Science, University of Alberta, Edmonton, AB, Canada; Department of Computing Science, University of Alberta, Edmonton, AB, Canada; Department of Computing Science, University of Alberta, Edmonton, AB, Canada","IEEE Transactions on Image Processing","","2018","27","2","806","821","For an object classification system, the most critical obstacles toward real-world applications are often caused by large intra-class variability, arising from different lightings, occlusion, and corruption, in limited sample sets. Most methods in the literature would fail when the training samples are heavily occluded, corrupted or have significant illumination or viewpoint variations. Besides, most of the existing methods and especially deep learning-based methods, need large training sets to achieve a satisfactory recognition performance. Although using the pre-trained network on a generic large-scale data set and fine-tune it to the small-sized target data set is a widely used technique, this would not help when the content of base and target data sets are very different. To address these issues simultaneously, we propose a joint projection and low-rank dictionary learning method using dual graph constraints. Specifically, a structured class-specific dictionary is learned in the low-dimensional space, and the discrimination is further improved by imposing a graph constraint on the coding coefficients, that maximizes the intra-class compactness and inter-class separability. We enforce structural incoherence and low-rank constraints on sub-dictionaries to reduce the redundancy among them, and also make them robust to variations and outliers. To preserve the intrinsic structure of data, we introduce a supervised neighborhood graph into the framework to make the proposed method robust to small-sized and high-dimensional data sets. Experimental results on several benchmark data sets verify the superior performance of our method for object classification of small-sized data sets, which include a considerable amount of different kinds of variation, and may have high-dimensional feature vectors.","","","10.1109/TIP.2017.2766446","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8082519","Joint projection and dictionary learning;sparse representation;low-rank regularization;object classification;occlusion and corruption;intra-class variation","Dictionaries;Training;Noise measurement;Lighting","graph theory;image classification","joint projection;object classification system;critical obstacles;real-world applications;intra-class variability;deep learning-based methods;satisfactory recognition performance;low-rank dictionary learning method;dual graph constraints;structured class-specific dictionary;graph constraint;intra-class compactness;inter-class separability;low-rank constraints;sub-dictionaries;supervised neighborhood graph;benchmark data sets;small-sized data sets","","2","47","","","","","IEEE","IEEE Journals"
"User-Centric View of Unmanned Aerial Vehicle Transmission Against Smart Attacks","L. Xiao; C. Xie; M. Min; W. Zhuang","Department of Communication Engineering, Xiamen University, Xiamen, China; Department of Communication Engineering, Xiamen University, Xiamen, China; Department of Communication Engineering, Xiamen University, Xiamen, China; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada","IEEE Transactions on Vehicular Technology","","2018","67","4","3420","3430","Unmanned aerial vehicle (UAV) systems are vulnerable to smart attackers, who are selfish and subjective end-users and use smart radio devices to change their attack types and policies based on the ongoing UAV transmission and network states. In this paper, we apply prospect theory to formulate a subjective smart attack game for the UAV transmission, in which a smart attacker Eve makes subjective decisions to choose the attack type such as jamming, spoofing, and eavesdropping without knowing the attack detection accuracy of the UAV system, and the UAV transmit power on multiple radio channels is chosen to resist smart attacks. Reinforcement-learning-based UAV power allocation strategies are proposed to achieve the optimal power allocation against smart attacks without knowing the attack model and the channel model in the dynamic game. A deep Q-learning-based UAV power allocation strategy combines Q-learning and deep learning to accelerate the learning speed for the case with a large number of channel states and attack modes. Simulation results show that our proposed UAV power allocation strategy can suppress the attack motivation of subjective smart attackers and increase the secrecy capacity and the utility of the UAV system.","","","10.1109/TVT.2017.2785414","National Natural Science Foundation of China; National Mobile Communications Research Laboratory, Southeast University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8231220","Smart attacks;UAV;prospect theory;game theory;reinforcement learning","Resource management;Games;Jamming;Unmanned aerial vehicles;Security;Mobile communication","aircraft control;autonomous aerial vehicles;game theory;jamming;learning (artificial intelligence);mobile communication;mobile robots;radiocommunication;remotely operated vehicles;telecommunication security","subjective smart attack game;smart attacker Eve;attack type;attack detection accuracy;UAV system;UAV transmit power;subjective smart attackers;unmanned aerial vehicle transmission;unmanned aerial vehicle systems;subjective end-users;smart radio devices;user-centric view;UAV transmission;jamming;spoofing;eavesdropping;UAV power transmission;multiple radio channels;reinforcement-learning-based UAV power allocation strategies;optimal power allocation;deep Q-learning-based UAV power allocation strategy","","18","34","","","","","IEEE","IEEE Journals"
"Gait Anomaly Detection of Subjects With Parkinson’s Disease Using a Deep Time Series-Based Approach","G. Paragliola; A. Coronato","National Research Council, Institute for High-Performance Computing and Networking, Naples, Italy; National Research Council, Institute for High-Performance Computing and Networking, Naples, Italy","IEEE Access","","2018","6","","73280","73292","Parkinson’s disease (PD) is a cognitive degenerative disorder of the central nervous system that mainly affects the motor system. The earliest symptoms evidence a general deficit of coordination and an unsteady gait. Current approaches for the evaluation and assessment of gait disturbances in PD have proved to be expensive, inconvenient and ineffective in the detection of anomalous walking patterns. In this paper, we address these issues by defining a deep time series-based approach for the detection of anomalous walking patterns in the gait dynamics of elderly people by analyzing the acceleration values of their movements. The results show a training accuracy and testing accuracy of over 90% with an accuracy improvement of 4.28% in comparison with related works.","","","10.1109/ACCESS.2018.2882245","eAsy inteLligent service Platform for Healthy Aging (ALPHA) Project; “Realization of services and tools for Public Administrations for the implementation of the Electronic Health Record”; Convention between the Agency for Digital Italy of the Presidency of the Council of Ministers and the National Research Council of Italy; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8540355","Deep learning;convolutional neural network;long short-term memory;human behavior recognition;gait classification;neurodegenerative;diseases;deep neural network","Legged locomotion;Feature extraction;Diseases;Training;Support vector machines;Hidden Markov models;Acceleration","","","","3","37","","","","","IEEE","IEEE Journals"
"Sound Event Recognition Using Auditory-Receptive-Field Binary Pattern and Hierarchical-Diving Deep Belief Network","C. Wang; J. Wang; A. Santoso; C. Chiang; C. Wu","Department of Computer Science and Information Engineering, National Central University, Taoyuan City, Taiwan; Department of Computer Science and Information Engineering, National Central University, Taoyuan City, Taiwan; Department of Computer Science and Information Engineering, National Central University, Taoyuan City, Taiwan; Department of Computer Science and Information Engineering, National Central University, Taoyuan City, Taiwan; Department of Computer Science and Information Engineering, National Cheng Kung University, Tainan City, Taiwan","IEEE/ACM Transactions on Audio, Speech, and Language Processing","","2018","26","8","1336","1351","Automatic sound event recognition (SER) has recently attracted renewed interest. Although practical SER system has many useful applications in everyday life, SER is challenging owing to the variations among sounds and noises in the real-world environment. This paper presents a novel feature extraction and classification method to solve the problem of SER. An audio-visual descriptor, called the auditory-receptive-field binary pattern, is designed based on the spectrogram image feature, the cepstral features, and the human auditory receptive field model. The extracted features are then fed into a classifier to perform event classification. The proposed classifier, called the hierarchical-diving deep belief network, is a deep neural network system that hierarchically learns the discriminative characteristics from physical feature representation to the abstract concept. The performance of our proposed system was verified using several experiments under various conditions. Using the RWCP dataset, the proposed system achieved a recognition rate of 99.27% for real-world sound data in 105 categories. Under noisy conditions, the developed system is very robust, with which it achieved 95.06% recognition rate with 0 dB signal-to-noise ratio. Using the TUT sound event dataset, the proposed system achieves error rates of 0.81 and 0.73 in sound event detection in home and residential area scenes. The experimental results reveal that the proposed system outperformed the other systems in this field.","","","10.1109/TASLP.2017.2738443","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8007276","Auditory receptive fields binary patterns;environmental sound;hierarchical diving deep belief network;spectrogram image feature","Feature extraction;Spectrogram;Speech recognition;Hidden Markov models;Data mining;Speech;Neural networks","audio signal processing;belief networks;cepstral analysis;feature extraction;image classification;image representation;neural nets;speech recognition","hierarchical-diving deep belief network;deep neural network system;physical feature representation;sound event detection;auditory-receptive-field binary pattern;automatic sound event recognition;practical SER system;classification method;audio-visual descriptor;spectrogram image feature;cepstral features;human auditory receptive field model;sound event classification;feature extraction","","2","46","","","","","IEEE","IEEE Journals"
"Crafting GBD-Net for Object Detection","X. Zeng; W. Ouyang; J. Yan; H. Li; T. Xiao; K. Wang; Y. Liu; Y. Zhou; B. Yang; Z. Wang; H. Zhou; X. Wang","Chinese University of Hong Kong and Sensetime Group Limited, Shatin, Hong Kong; School of Electrical and Information Engineering, University of Sydney, Camperdown, NSW, Australia; Sensetime Group Limited, Shatin, Hong Kong; Department of Electronic Engineering, Chinese University of Hong Kong, Shatin, Hong Kong; Department of Electronic Engineering, Chinese University of Hong Kong, Shatin, Hong Kong; Department of Electronic Engineering, Chinese University of Hong Kong, Shatin, Hong Kong; Sensetime Group Limited, Shatin, Hong Kong; Sensetime Group Limited, Shatin, Hong Kong; Sensetime Group Limited, Shatin, Hong Kong; Department of Electronic Engineering, Chinese University of Hong Kong, Shatin, Hong Kong; Department of Electronic Engineering, Chinese University of Hong Kong, Shatin, Hong Kong; Department of Electronic Engineering, Chinese University of Hong Kong, Shatin, Hong Kong","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","9","2109","2123","The visual cues from multiple support regions of different sizes and resolutions are complementary in classifying a candidate box in object detection. Effective integration of local and contextual visual cues from these regions has become a fundamental problem in object detection. In this paper, we propose a gated bi-directional CNN (GBD-Net) to pass messages among features from different support regions during both feature learning and feature extraction. Such message passing can be implemented through convolution between neighboring support regions in two directions and can be conducted in various layers. Therefore, local and contextual visual patterns can validate the existence of each other by learning their nonlinear relationships and their close interactions are modeled in a more complex way. It is also shown that message passing is not always helpful but dependent on individual samples. Gated functions are therefore needed to control message transmission, whose on-or-offs are controlled by extra visual evidence from the input sample. The effectiveness of GBD-Net is shown through experiments on three object detection datasets, ImageNet, Pascal VOC2007 and Microsoft COCO. Besides the GBD-Net, this paper also shows the details of our approach in winning the ImageNet object detection challenge of 2016, with source code provided on https://github.com/craftGBD/craftGBD. In this winning system, the modified GBD-Net, new pretraining scheme and better region proposal designs are provided. We also show the effectiveness of different network structures and existing techniques for object detection, such as multi-scale testing, left-right flip, bounding box voting, NMS, and context.","","","10.1109/TPAMI.2017.2745563","SenseTime Group Limited; Research Grants Council of Hong Kong; the Hong Kong Innovation and Technology Support Programme; National Natural Science Foundation of China; ONR; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8017422","Convolutional neural network;CNN;deep learning;deep model;object detection","Object detection;Rabbits;Visualization;Feature extraction;Head;Proposals;Logic gates","feature extraction;feedforward neural nets;image classification;learning (artificial intelligence);message passing;object detection","multiple support regions;contextual visual cues;feature learning;feature extraction;message passing;neighboring support regions;contextual visual patterns;message transmission;ImageNet object detection challenge;modified GBD-Net;local visual cues;network structures;candidate box classification;gated bidirectional CNN;local visual patterns;ImageNet object detection dataset;Pascal VOC2007 object detection dataset;Microsoft COCO object detection dataset;multiscale testing;left-right flip;bounding box voting","","6","49","","","","","IEEE","IEEE Journals"
"Pedestrian Detection by Feature Selected Self-Similarity Features","X. Fu; R. Yu; W. Zhang; L. Feng; S. Shao","National Key Laboratory of Science and Technology on Communications, University of Electronic Science and Technology of China, Chengdu, China; Department of Computer Science, University College London, London, U.K.; Department of Computer Science, Shanghai Jiao Tong University, Shanghai, China; Engineering and Technology College, Sichuan Open University, Chengdu, China; National Key Laboratory of Science and Technology on Communications, University of Electronic Science and Technology of China, Chengdu, China","IEEE Access","","2018","6","","14223","14237","This paper is concerned with the pedestrian detection problem. In this area, boosted decision tree (BDT) methods are highly successful and very efficient. However, to achieve the best performance, most BDT methods require a large number of input features, which make the algorithm scale poorly to largescale data. Inspired by the effectiveness of self-similarity (SS) features, we use linear discriminant analysis to select features in the SS features according to their generalized Rayleigh quotient, leading to a small number but most discriminative features. These features are called feature selected self-similarity (FSSS) features. The FSSS features are only used for the late stages of the BDT cascade, making the training and detecting much more efficient. Extensive experiments on four well-known data sets demonstrate that the FSSS features are highly effective and the trained pedestrian detector achieves state-of-the-art performance among all existing non-deep-learning methods on several benchmarks. We also compare our method with deep learning methods and show its superiority in high-quality localization and will be a good complement to deep learning methods.","","","10.1109/ACCESS.2018.2803160","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8286891","Boosted decision tree;linear discriminant analysis;pedestrian detection;self-similarity features","Feature extraction;Microsoft Windows;Machine learning;Computational efficiency;Decision trees;Detectors;Benchmark testing","decision trees;feature extraction;learning (artificial intelligence);object detection;pattern classification;pedestrians;traffic engineering computing","BDT methods;linear discriminant analysis;SS features;discriminative features;feature selected self-similarity features;FSSS features;BDT cascade;trained pedestrian detector;existing nondeep-learning methods;deep learning methods;pedestrian detection problem;boosted decision tree methods","","","70","","","","","IEEE","IEEE Journals"
"Unsupervised Domain Adaptation by Mapped Correlation Alignment","Y. Zhang; N. Wang; S. Cai; L. Song","School of Computer Science and Technology, Harbin Engineering University, Harbin, China; School of Computer Science and Technology, Harbin Engineering University, Harbin, China; School of Computer Science and Technology, Huaqiao University, Xiamen, China; School of Computer Science and Technology, Harbin Engineering University, Harbin, China","IEEE Access","","2018","6","","44698","44706","The goal of unsupervised domain adaptation aims to utilize labeled data from source domain to annotate the target-domain data, which has none of the labels. Existing work uses Siamese network-based models to minimize the domain discrepancy to learn a domain-invariant feature. Alignment of the second-order statistics (covariances) of source and target distributions has been proven an effective method. Previous papers use Euclidean methods or geodesic methods (log-Euclidean) to measure the distance. However, covariances lay on a Riemannian manifold, and both methods cannot accurately calculate the Riemannian distance, so they cannot align the distribution well. To tackle the distribution alignment problem, this paper proposes mapped correlation alignment (MCA), a novel technique for end-to-end domain adaptation with deep neural networks. This method maps covariances from Riemannian manifold to reproducing kernel Hilbert space and uses Gaussian radial basis function-based positive definite kernels on manifolds to calculate the inner product on reproducing kernel Hilbert space, and then uses Euclidean metric accurate measuring the distance to align the distribution better. This paper builds an end-to-end model to minimize both the classification loss and the MCA loss. The model can be trained efficiently using backpropagation. Experiments show that the MCA method yields the state-of-the-art results on standard domain adaptation data sets.","","","10.1109/ACCESS.2018.2865249","National Natural Science Foundation of China; Basic Research Project; Technical Foundation Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8434290","Transfer learning;domain adaptation;deep learning;image recognition","Kernel;Manifolds;Training;Feature extraction;Correlation;Euclidean distance;Covariance matrices","backpropagation;handwriting recognition;higher order statistics;Hilbert spaces;image classification;image representation;neural nets;radial basis function networks;unsupervised learning","unsupervised domain adaptation;mapped correlation alignment;source domain;target-domain data;Siamese network-based models;domain discrepancy;domain-invariant feature;second-order statistics;target distributions;Euclidean methods;geodesic methods;Riemannian distance;distribution alignment problem;end-to-end domain adaptation;deep neural networks;reproducing kernel Hilbert space;Gaussian radial basis function-based positive definite kernels;end-to-end model;standard domain adaptation data sets;MCA method","","","36","","","","","IEEE","IEEE Journals"
"NetworkAI: An Intelligent Network Architecture for Self-Learning Control Strategies in Software Defined Networks","H. Yao; T. Mai; X. Xu; P. Zhang; M. Li; Y. Liu","State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; Beijing Advanced Innovation Center for Future Internet Technology, Beijing University of Technology, Beijing, China; Beijing Advanced Innovation Center for Future Internet Technology, Beijing University of Technology, Beijing, China; College of Computer and Communication Engineering, China University of Petroleum (East China), Shandong, China; Department of Electronic and Computer Engineering, Brunel University London, Uxbridge, U.K.; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China","IEEE Internet of Things Journal","","2018","5","6","4319","4327","The past few years have witnessed a wide deployment of software defined networks facilitating a separation of the control plane from the forwarding plane. However, the work on the control plane largely relies on a manual process in configuring forwarding strategies. To address this issue, this paper presents NetworkAI, an intelligent architecture for self-learning control strategies in software defined networking networks. NetworkAI employs deep reinforcement learning and incorporates network monitoring technologies, such as the in-band network telemetry to dynamically generate control policies and produces a near optimal decision. Simulation results demonstrated the effectiveness of NetworkAI.","","","10.1109/JIOT.2018.2859480","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities of China University of Petroleum (East China); Natural Science Foundation of Shandong Province; National Basic Research Program (973) of China; China Research Project on Key Technology Strategy of Infrastructure Security for Information Network Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8419242","Deep reinforcement learning (DRL);in-band network telemetry (INT);NetworkAI;software defined networks","Monitoring;Computer architecture;Machine learning;Internet of Things;Process control;Real-time systems","","","","6","37","","","","","IEEE","IEEE Journals"
"SOMDNCD: Image Change Detection Based on Self-Organizing Maps and Deep Neural Networks","R. Xiao; R. Cui; M. Lin; L. Chen; Y. Ni; X. Lin","College of Mathematics and Informatics, Fujian Normal University, Fuzhou, China; College of Mathematics and Informatics, Fujian Normal University, Fuzhou, China; College of Mathematics and Informatics, Fujian Normal University, Fuzhou, China; College of Mathematics and Informatics, Fujian Normal University, Fuzhou, China; College of Mathematics and Informatics, Fujian Normal University, Fuzhou, China; College of Mathematics and Informatics, Fujian Normal University, Fuzhou, China","IEEE Access","","2018","6","","35915","35925","Image change detection is a research hotspot in many fields of application, such as environmental monitoring, disaster investigation, urban research, and more. How to reduce the influence of speckle noise when conducting change detection in an acquired synthetic aperture radar (SAR) image is a challenging issue. This research shows that reasonably balancing noise suppression with the preservation of the edges of regions is the key to generating a good change map. Therefore, a new image detection method based on a selforganizing map and deep neural network (SOMDNCD) is proposed. First, the method uses a median filter to improve the difference image that is generated by the mean-ratio operator, which reduces the influence of the image point noise on generating difference maps. Compared with the difference map formed by the logarithmic ratio operator, the edge information in the image is excellently retained and the missed detection rate is reduced; second, the network preprocesses the difference map, obtains a preliminary change map, and divides the pixels of the difference map into three types: no change, noise, and change. Finally, a deep neural network is used to train a noise-like training set on the network to reduce the residual noise in the change class and obtain the final change graph. The experimental results show that compared with other current mainstream methods, the proposed SOMDNCD change detection method directly addresses noise and is universal for a variety of data sets. The proposed method exhibits a lower missed detection rate in the SAR image data set and a more ideal false alarm rate than other methods.","","","10.1109/ACCESS.2018.2849110","Great Project of the Fujian Province Science and Technology Plan; City School Cooperation Project of the Fuzhou Science and Technology Bureau; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8388197","Image change detection;median filter;self-organizing map;deep neural network;unsupervised learning","","geophysical image processing;median filters;neural nets;object detection;radar imaging;self-organising feature maps;synthetic aperture radar","speckle noise;noise suppression;image detection method;selforganizing map;deep neural network;SAR image data;image change detection;self-organizing maps;change detection;synthetic aperture radar image","","6","29","","","","","IEEE","IEEE Journals"
"GANViz: A Visual Analytics Approach to Understand the Adversarial Game","J. Wang; L. Gou; H. Yang; H. Shen","Department of Computer Science and Engineering, Ohio State University, Columbus, OH; Visa Research, Palo Alto, CA; Visa Research, Palo Alto, CA; Department of Computer Science and Engineering, Ohio State University, Columbus, OH","IEEE Transactions on Visualization and Computer Graphics","","2018","24","6","1905","1917","Generative models bear promising implications to learn data representations in an unsupervised fashion with deep learning. Generative Adversarial Nets (GAN) is one of the most popular frameworks in this arena. Despite the promising results from different types of GANs, in-depth understanding on the adversarial training process of the models remains a challenge to domain experts. The complexity and the potential long-time training process of the models make it hard to evaluate, interpret, and optimize them. In this work, guided by practical needs from domain experts, we design and develop a visual analytics system, GANViz, aiming to help experts understand the adversarial process of GANs in-depth. Specifically, GANViz evaluates the model performance of two subnetworks of GANs, provides evidence and interpretations of the models' performance, and empowers comparative analysis with the evidence. Through our case studies with two real-world datasets, we demonstrate that GANViz can provide useful insight into helping domain experts understand, interpret, evaluate, and potentially improve GAN models.","","","10.1109/TVCG.2018.2816223","US National Science Foundation; US Department of Energy; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8320546","Generative adversarial nets;deep learning;model interpretation;visual analytics","Gallium nitride;Training;Feature extraction;Visual analytics;Analytical models;Neurons;Neural networks","data analysis;data visualisation;unsupervised learning","GANViz;visual analytics approach;adversarial game;generative models;data representations;unsupervised fashion;deep learning;Generative Adversarial Nets;in-depth understanding;adversarial training process;domain experts;long-time training process;visual analytics system;GAN models","","10","33","","","","","IEEE","IEEE Journals"
"Vehicle Detection and Counting in High-Resolution Aerial Images Using Convolutional Regression Neural Network","H. Tayara; K. Gil Soo; K. T. Chong","Department of Information and Electronics Engineering, Chonbuk National University, Jeonju, South Korea; Institute of International Studies, Chonbuk National University, Jeonju, South Korea; Department of Information and Electronics Engineering, Chonbuk National University, Jeonju, South Korea","IEEE Access","","2018","6","","2220","2230","Vehicle detection and counting in aerial images have become an interesting research focus since the last decade. It is important for a wide range of applications, such as urban planning and traffic management. However, this task is a challenging one due to the small size of the vehicles, their different types and orientations, and similarity in their visual appearance, and some other objects, such as air conditioning units on buildings, trash bins, and road marks. Many methods have been introduced in the literature for solving this problem. These methods are either based on shallow learning or deep learning approaches. However, these methods suffer from relatively low precision and recall rate. This paper introduces an automated vehicle detection and counting system in aerial images. The proposed system utilizes convolution neural network to regress a vehicle spatial density map across the aerial image. It has been evaluated on two publicly available data sets, namely, Munich and Overhead Imagery Research Data Set. The experimental results show that our proposed system is efficient and effective, and produces higher precision and recall rate than the comparative methods.","","","10.1109/ACCESS.2017.2782260","BK21 PLUS; Brain Research Program through the National Research Foundation of Korea; Ministry of Science, ICT and Future Planning; Ministry of Trade, Industry and Energy and the Korea Institute for Advancement of Technology through the International Cooperative Research and Development Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8186148","Aerial images;convolution neural network (CNN);deep learning;regression;vehicle detection","Vehicle detection;Feature extraction;Automobiles;Training;Sensors;Support vector machines","computer vision;feature extraction;learning (artificial intelligence);neural nets;object detection;object recognition;traffic engineering computing","deep learning approaches;Munich;overhead imagery research data set;low precision;comparative methods;vehicle spatial density map;automated vehicle detection;recall rate;traffic management;urban planning;convolutional regression neural network;high-resolution aerial images","","13","36","","","","","IEEE","IEEE Journals"
"SV-RCNet: Workflow Recognition From Surgical Videos Using Recurrent Convolutional Network","Y. Jin; Q. Dou; H. Chen; L. Yu; J. Qin; C. Fu; P. Heng","Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong; Centre for Smart Health, School of Nursing, The Hong Kong Polytechnic University, Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong","IEEE Transactions on Medical Imaging","","2018","37","5","1114","1126","We propose an analysis of surgical videos that is based on a novel recurrent convolutional network (SV-RCNet), specifically for automatic workflow recognition from surgical videos online, which is a key component for developing the context-aware computer-assisted intervention systems. Different from previous methods which harness visual and temporal information separately, the proposed SV-RCNet seamlessly integrates a convolutional neural network (CNN) and a recurrent neural network (RNN) to form a novel recurrent convolutional architecture in order to take full advantages of the complementary information of visual and temporal features learned from surgical videos. We effectively train the SV-RCNet in an end-to-end manner so that the visual representations and sequential dynamics can be jointly optimized in the learning process. In order to produce more discriminative spatio-temporal features, we exploit a deep residual network (ResNet) and a long short term memory (LSTM) network, to extract visual features and temporal dependencies, respectively, and integrate them into the SV-RCNet. Moreover, based on the phase transition-sensitive predictions from the SV-RCNet, we propose a simple yet effective inference scheme, namely the prior knowledge inference (PKI), by leveraging the natural characteristic of surgical video. Such a strategy further improves the consistency of results and largely boosts the recognition performance. Extensive experiments have been conducted with the MICCAI 2016 Modeling and Monitoring of Computer Assisted Interventions Workflow Challenge dataset and Cholec80 dataset to validate SV-RCNet. Our approach not only achieves superior performance on these two datasets but also outperforms the state-of-the-art methods by a significant margin.","","","10.1109/TMI.2017.2787657","Research Grants Council of Hong Kong Special Administrative Region; Shenzhen Science and Technology Program; Hong Kong Polytechnic University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8240734","Recurrent convolutional network;surgical workflow recognition;joint learning of spatio-temporal features;very deep residual network;long short-term memory","Surgery;Videos;Visualization;Feature extraction;Computational modeling;Hidden Markov models;Computer architecture","convolution;feature extraction;feedforward neural nets;image recognition;inference mechanisms;learning (artificial intelligence);medical image processing;recurrent neural nets;surgery;video signal processing","surgical video;automatic workflow recognition;temporal information;SV-RCNet;convolutional neural network;recurrent neural network;convolutional architecture;visual features;deep residual network;long short term memory network;recurrent convolutional network;discriminative spatiotemporal features;inference scheme;context-aware computer-assisted intervention systems;learning process","Algorithms;Databases, Factual;Humans;Image Processing, Computer-Assisted;Neural Networks (Computer);Software;Video-Assisted Surgery;Workflow","3","49","","","","","IEEE","IEEE Journals"
"Group-Sensitive Triplet Embedding for Vehicle Reidentification","Y. Bai; Y. Lou; F. Gao; S. Wang; Y. Wu; L. Duan","Institute of Digital Media, Peking University, Beijing, China; Institute of Digital Media, Peking University, Beijing, China; Institute of Digital Media, Peking University, Beijing, China; Department of Computer Science, City University of Hong Kong, Hong KongChina; Beijing Laboratory of Intelligent Information Technology, School of Computer Science, Beijing Institute of Technology, Beijing, China; Institute of Digital Media, Peking University, Beijing, China","IEEE Transactions on Multimedia","","2018","20","9","2385","2399","The widespread use of surveillance cameras toward smart and safe cities poses the critical but challenging problem of vehicle reidentification (Re-ID). The state-of-the-art research work performed vehicle Re-ID relying on deep metric learning with a triplet network. However, most existing methods basically ignore the impact of intraclass variance-incorporated embedding on the performance of vehicle reidentification, in which robust fine-grained features for large-scale vehicle Re-ID have not been fully studied. In this paper, we propose a deep metric learning method, group-sensitive-triplet embedding (GS-TRE), to recognize and retrieve vehicles, in which intraclass variance is elegantly modeled by incorporating an intermediate representation “group” between samples and each individual vehicle in the triplet network learning. To capture the intraclass variance attributes of each individual vehicle, we utilize an online grouping method to partition samples within each vehicle ID into a few groups, and build up the triplet samples at multiple granularities across different vehicle IDs as well as different groups within the same vehicle ID to learn fine-grained features. In particular, we construct a large-scale vehicle database “PKU-Vehicle,” consisting of 10 million vehicle images captured by different surveillance cameras in several cities, to evaluate the vehicle Re-ID performance in real-world video surveillance applications. Extensive experiments over benchmark datasets VehicleID, VeRI, and CompCar have shown that the proposed GS-TRE significantly outperforms the state-of-the-art approaches for vehicle Re-ID.","","","10.1109/TMM.2018.2796240","National Natural Science Foundation of China; National Basic Research Program of China (973 Program); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8265213","Vehicle re-identification;metric learning, intra-class variance;embedding;retrieval;surveillance","Measurement;Surveillance;Visualization;Licenses;Cameras;Urban areas","learning (artificial intelligence);object recognition;traffic engineering computing;video surveillance","robust fine-grained features;deep metric learning method;group-sensitive-triplet embedding;intermediate representation group;individual vehicle;triplet network learning;intraclass variance attributes;online grouping method;surveillance cameras;vehicle images;intraclass variance-incorporated embedding;Re-ID relying;vehicle reidentification;group-sensitive triplet embedding;Re-ID performance;large-scale vehicle database PKU-Vehicle;triplet samples;vehicle ID","","11","64","","","","","IEEE","IEEE Journals"
"Deep Power Control: Transmit Power Control Scheme Based on Convolutional Neural Network","W. Lee; M. Kim; D. Cho","Department of Information and Communication Engineering, Institute of Marine Industry, Gyeongsang National University, Tongyeong, South Korea; Department of Communication Systems, EURECOM, Biot, France; School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea","IEEE Communications Letters","","2018","22","6","1276","1279","In this letter, deep power control (DPC), which is the first transmit power control framework based on a convolutional neural network (CNN), is proposed. In DPC, the transmit power control strategy to maximize either spectral efficiency (SE) or energy efficiency (EE) is learned by means of a CNN. While conventional power control schemes require a considerable number of computations, in DPC, the transmit power of users can be determined using far fewer computations enabling real-time processing. We also propose a form of DPC that can be performed in a distributed manner with local channel state information, allowing the signaling overhead to be greatly reduced. Through simulations, we show that the DPC can achieve almost the same or even higher SE and EE than a conventional power control scheme, with a much lower computation time.","","","10.1109/LCOMM.2018.2825444","Basic Science Research Program through the National Research Foundation of Korea (NRF); Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8335785","Deep learning;convolutional neural network;transmit power control;spectral efficiency;energy efficiency","Power control;Convolution;Transmitters;Training;Optimization;Receivers;Neural networks","neurocontrollers;power control;telecommunication channels;telecommunication control;telecommunication networks;telecommunication signalling","convolutional neural network;CNN;DPC;energy efficiency;transmit power control scheme;deep power control scheme;spectral efficiency;SE;EE;channel state information;signaling overhead","","25","11","","","","","IEEE","IEEE Journals"
"Evolving Head Tracking Routines With Brain Programming","G. Olague; D. E. Hernández; E. Clemente; M. Chan-Ley","Department of Computer Science, Center for Scientific Research and Higher Education of Ensenada, Ensenada, México; TecNM, Tijuana Institute of Technology, Tijuana, México; TecNM, Ensenada Institute of Technology, Ensenada, México; Department of Computer Science, Center for Scientific Research and Higher Education of Ensenada, Ensenada, México","IEEE Access","","2018","6","","26254","26270","Visual tracking has long been studied in computer vision, and it has many practical applications such as surveillance and security, traffic control, human-computer interaction, and activity or behavior recognition to mention but a few. Head tracking attempts to follow a person's head within a video sequence. This paper presents a methodology that automatically designs an artificial dorsal stream for the problem of head tracking. Multiple visual operators are synthesized to obtain several visual and conspicuity maps that are fused into a saliency map, which is converted to a binary image, thus defining the proto-object. The automatic design of visual attention programs for the problem of head tracking is achieved through an optimization process following the Darwinian paradigm of artificial evolution. Artificial brains are synthesized using multiple visual operators embedded within a complex hierarchical procedure consisting of several key processes such as center-surround mechanisms, normalization, and pyramid-scale processes. The proposed strategy robustly handles many difficulties including occlusion, distraction, and illumination, and the resulting programs are real-time systems that are able to track a person's head with enough accuracy to automatically control the camera. Extensive experimentation shows that the proposed method outperforms several state-of-the-art methods in the challenging problem of head tracking.","","","10.1109/ACCESS.2018.2831633","Consejo Nacional de Ciencia y Tecnología; Seventh Framework Programme of the European Union through the Marie Curie International Research Staff Scheme, FP-PEOPLE-2013-IRSES, Project Analysis and Classification of Mental States of Vigilance with Evolutionary Computation; Centro de Investigación Científica y de Educación Superior de Ensenada, Baja California; TecNM Project 6474.18-P, “Navegación de robots móviles como un sistema adaptativo complejo.”; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8352651","Automatic programming;brain modeling;deep genetic programming;deep learning;learning;optimization;proto-object;saliency;surveillance;tracking;trajectory;visual attention","Head;Visualization;Target tracking;Feature extraction;Magnetic heads;Computational modeling","brain;cognitive systems;computer vision;image sequences;learning (artificial intelligence);medical computing;object detection;programming;real-time systems;video signal processing","multiple visual operators;visual maps;conspicuity maps;visual attention programs;visual tracking;head tracking routines;brain programming;video sequence;Darwinian paradigm;artificial evolution;real-time systems","","2","71","","","","","IEEE","IEEE Journals"
"Deep Variational and Structural Hashing","V. E. Liong; J. Lu; L. Duan; Y. Tan","Interdisciplinary Graduate School, Nanyang Technological University, Singapore, Singapore Singapore (e-mail: veniceer001@e.ntu.edu.sg); Department of Automation, Tsinghua University, Beijing, Beijing China 100084 (e-mail: lujiwen@tsinghua.edu.cn); Institute of Digital Media, Peking University, Beijing, Beijing China (e-mail: lingyu@pku.edu.cn); School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore, Singapore Singapore (e-mail: EYPTan@ntu.edu.sg)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","PP","99","1","1","In this paper, we propose a deep variational and structural hashing (DVStH) method to learn compact binary codes for multimedia retrieval. Unlike most existing deep hashing methods which use a series of convolution and fully-connected layers to learn binary features, we develop a probabilistic framework to infer latent feature representations inside the network. Then, we design a struct layer, instead of a bottleneck hash layer, to obtain the binary codes through a simple encoding procedure. By doing these, we are able to obtain binary codes discriminatively and generatively. To make it applicable to cross-modal multimedia retrieval, we extend our method to a cross-modal deep variational and structural hashing (CM-DVStH). We design a deep fusion network with a struct layer to maximize the correlation between image-text input pairs during the training so that a unified binary code can be obtained. We then design modality-specific hashing networks suitable for the out-of-sample extension. Here, we train a network for each modality which outputs a latent representation that is as close as possible to the binary codes inferred from the fusion network. Experimental results on five benchmark datasets are presented to show the efficacy of the proposed approach.","","","10.1109/TPAMI.2018.2882816","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8543225","Scalable image search;fast similarity search;hashing;deep learning;cross-modal retrieval","Binary codes;Training;Visualization;Semantics;Quantization (signal);Probabilistic logic;Convolution","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"SMT Solder Joint Inspection via a Novel Cascaded Convolutional Neural Network","N. Cai; G. Cen; J. Wu; F. Li; H. Wang; X. Chen","School of Information Engineering, Guangdong University of Technology, Guangzhou, China; School of Information Engineering, Guangdong University of Technology, Guangzhou, China; School of Information Engineering, Guangdong University of Technology, Guangzhou, China; School of Information Engineering, Guangdong University of Technology, Guangzhou, China; School of Electromechanical Engineering, Guangdong University of Technology, Guangzhou, China; School of Electromechanical Engineering, Guangdong University of Technology, Guangzhou, China","IEEE Transactions on Components, Packaging and Manufacturing Technology","","2018","8","4","670","677","Due to the excellent self-learning ability of deep learning, we propose a novel deep-learning-based method to inspect surface-mount technology (SMT) solder joints in this paper. In contrast to the state-of-the-art learning-based methods in which low-level features are extracted before learning, our method directly implements the inspection task without low-level feature extraction, which is based on a novel cascaded convolutional neural network (CNN). Three kinds of CNNs with different network parameters compose the proposed cascaded CNN. First, one kind of CNN is employed to adaptively learn the regions of interest (ROIs) of SMT solder joint images. Then, both the learned ROIs and the entire solder joint images are fed into the other two kinds of CNNs, respectively. Finally, inspection results are achieved by the learned cascaded CNN. Comparison experiments indicate that our proposed method can achieve more excellent inspection performance for SMT solder joints than that of the state-of-the-art methods.","","","10.1109/TCPMT.2018.2789453","National Natural Science Foundation of China; Guangdong Natural Science Foundation; Guangdong Science and Technology Plan; Guangzhou Science and Technology Plan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8272435","Cascaded network;convolutional neural networks (CNNs);regions of interest (ROIs);surface-mount technology (SMT) solder joint inspection;weighted-sum scheme","Soldering;Inspection;Feature extraction;Computer architecture;Convolutional neural networks;Task analysis","convolution;electronic engineering computing;feature extraction;feedforward neural nets;inspection;learning (artificial intelligence);production engineering computing;solders;surface mount technology","SMT solder joint inspection;novel cascaded convolutional neural network;excellent self-learning ability;deep learning;surface-mount technology solder joints;low-level feature extraction;learned ROIs;entire solder joint images;learned cascaded CNN;excellent inspection performance;SMT solder joints","","3","24","","","","","IEEE","IEEE Journals"
"Deep Disentangling Siamese Network for Frontal Face Synthesis Under Neutral Illumination","T. Zhang; H. Wang; Q. Dong","National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, Beijing, China; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China","IEEE Signal Processing Letters","","2018","25","9","1344","1348","Recently, it has been observed that face-recognition performance can be noticeably enhanced through frontal face synthesis. In this letter, a deep disentangling Siamese network (DSN) is proposed for frontal face synthesis. More specifically, we cast frontal face synthesis as the encoder-disentangling-decoder process of profile faces, and a salient feature of our DSN is that a pair of images with arbitrary identities, poses, and illuminations is used as the input rather than a single image used in many existing works. The process consists of the following three stages: 1)First, the representations of a pair of face images are learned by the Siamese encoder module.2)Then, the interpretable representations are disentangled into the identity, pose, and illumination representations separately.3)Finally, the identity representation is transferred into the frontal face image using the decoder module. The proposed network is evaluated on the face recognition and synthesis problem. Quantitative and qualitative evaluations on the benchmarks demonstrate that the proposed face synthesis network performs better than the state-of-the-art methods.","","","10.1109/LSP.2018.2858558","National Natural Science Foundation of China; Strategic Priority Research Program of the Chinese Academy of Sciences; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8418800","Discriminative representation learning;disentangled representation;frontal face synthesis;pose and illumination prediction;Siamese network","Face;Lighting;Face recognition;Decoding;Convolution;Three-dimensional displays;Training","face recognition;feature extraction;image coding;image representation;learning (artificial intelligence);neural nets;pose estimation","deep disentangling Siamese network;frontal face synthesis;encoder-disentangling-decoder process;frontal face image;face recognition;face synthesis network;neutral illumination;face image representation;Siamese encoder module;pose representations;illumination representations","","","28","","","","","IEEE","IEEE Journals"
"DCF-BoW: Build Match Graph Using Bag of Deep Convolutional Features for Structure From Motion","J. Wan; A. Yilmaz; L. Yan","Beijing Key Laboratory of Spatial Information Integration and Its Applications, School of Earth and Space Sciences, Peking University, Beijing, China; Department of Civil, Environment and Geodetic Engineering, The Ohio State University, Columbus, OH, USA; Beijing Key Laboratory of Spatial Information Integration and Its Applications, School of Earth and Space Sciences, Peking University, Beijing, China","IEEE Geoscience and Remote Sensing Letters","","2018","15","12","1847","1851","Matching a large number of images is quite time-consuming for structure from motion (SfM) due to the image matching by comparing features between all image pairs. In this letter, a bag of deep convolutional features (DCF-BoW) model is proposed to create match graph to reduce the number of matches. First, the convolutional feature map of an image is extracted using the VGG-16 convolutional neural network trained on ImageNet. Then, each local region in the original image can be represented by a feature vector in the feature map. The feature vectors are normalized and used to construct a bag of words model, which could convert each image into a DCF-BoW representation. Finally, the match graph is constructed by selecting the top 10 images with the highest similarities, which are calculated by computing the distances between those DCF-BoW representations. The experiment results show that the proposed DCF-BoW can create the match graph effectively in short time and find the potential overlapping image pairs. The match graph created by the proposed DCF-BoW is better than those built by DBoW3 and VocabTree, which is clearly showed in precision-recall curve on the Urban data set. The results of the SfM reconstruction based on the match graph created by the proposed DCF-BoW are slightly worse than those of the exhaustive matching, while the number of matches is reduced by 97.4% and 92.1%, respectively, on the Urban and South Building data sets.","","","10.1109/LGRS.2018.2864116","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8444049","DCF-BoW;deep convolutional features;match graph;structure from motion (SfM)","Feature extraction;Visualization;Buildings;Computational modeling;Vocabulary;Task analysis;Data mining","convolutional neural nets;feature extraction;graph theory;image classification;image matching;image reconstruction;image representation;image segmentation;learning (artificial intelligence)","exhaustive matching;potential overlapping image pairs;DCF-BoW representation;feature vector;VGG-16 convolutional neural network;convolutional feature map;deep convolutional features model;image matching;build match graph","","","19","","","","","IEEE","IEEE Journals"
"Deep Scalogram Representations for Acoustic Scene Classification","Z. Ren; K. Qian; Y. Wang; Z. Zhang; V. Pandit; A. Baird; B. Schuller","University of Augsburg, Germany; Technische Universitat Munchen, Germany, and also with University of Augsburg, Germany; Mitsubishi Electric Research Laboratories, Cambridge MA 02139, USA; Imperial College London, UK; University of Augsburg, Germany; University of Augsburg, Germany; Imperial College London, UK, and also with University of Augsburg, Germany","IEEE/CAA Journal of Automatica Sinica","","2018","5","3","662","669","Spectrogram representations of acoustic scenes have achieved competitive performance for acoustic scene classification. Yet, the spectrogram alone does not take into account a substantial amount of time-frequency information. In this study, we present an approach for exploring the benefits of deep scalogram representations, extracted in segments from an audio stream. The approach presented firstly transforms the segmented acoustic scenes into bump and morse scalograms, as well as spectrograms; secondly, the spectrograms or scalograms are sent into pre-trained convolutional neural networks; thirdly, the features extracted from a subsequent fully connected layer are fed into (bidirectional) gated recurrent neural networks, which are followed by a single highway layer and a softmax layer; finally, predictions from these three systems are fused by a margin sampling value strategy. We then evaluate the proposed approach using the acoustic scene classification data set of 2017 IEEE AASP Challenge on Detection and Classification of Acoustic Scenes and Events (DCASE). On the evaluation set, an accuracy of 64.0 % from bidirectional gated recurrent neural networks is obtained when fusing the spectrogram and the bump scalogram, which is an improvement on the 61.0 % baseline result provided by the DCASE 2017 organisers. This result shows that extracted bump scalograms are capable of improving the classification accuracy, when fusing with a spectrogram-based system.","","","10.1109/JAS.2018.7511066","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8332139","Acoustic scene classiﬁcation (ASC);(bidirectional) gated recurrent neural networks ((B) GRNNs);convolutional neural networks (CNNs);deep scalogram representation;spectrogram representation","Feature extraction;Spectrogram;Acoustics;Task analysis;Time-frequency analysis;Wavelet transforms;Recurrent neural networks","feature extraction;image classification;image representation;learning (artificial intelligence);recurrent neural nets","deep scalogram representations;spectrogram representations;time-frequency information;transforms the segmented acoustic scenes;morse scalograms;pre-trained convolutional neural networks;subsequent fully connected layer;single highway layer;acoustic scene classification data;Events U+0028 DCASE U+0029;bidirectional gated recurrent neural networks;bump scalogram;extracted bump scalograms","","5","","","","","","IEEE","IEEE Journals"
"An sEMG-Based Human–Robot Interface for Robotic Hands Using Machine Learning and Synergies","R. Meattini; S. Benatti; U. Scarcia; D. De Gregorio; L. Benini; C. Melchiorri","Department of Electrical, Electronic and Information Engineering, University of Bologna, Bologna, Italy; Department of Electrical, Electronic and Information Engineering, University of Bologna, Bologna, Italy; Department of Electrical, Electronic and Information Engineering, University of Bologna, Bologna, Italy; Department of Electrical, Electronic and Information Engineering, University of Bologna, Bologna, Italy; Department of Electrical, Electronic and Information Engineering, University of Bologna, Bologna, Italy; Department of Electrical, Electronic and Information Engineering, University of Bologna, Bologna, Italy","IEEE Transactions on Components, Packaging and Manufacturing Technology","","2018","8","7","1149","1158","Developing natural control strategies represents an intriguing challenge in the design of human-robot interface (HRI) systems. The teleoperation of robotic grasping devices, especially in industrial, rescue, and aerospace applications, is mostly based on nonintuitive approaches, such as remote controllers. On the other hand, recent research efforts target solutions that mimic the human ability to manage multifinger grasps and finely modulate grasp impedance. Since electromyography (EMG) contains information about human motion control, it is possible to leverage such neuromuscular knowledge to teleoperate robotic hands for grasping tasks. In this paper, we present an HRI system based on eight fully differential EMG sensors connected to a wearable sensor node for acquisition and processing. By virtue of a novel bio-inspired approach, the embedded myocontroller merges pattern recognition and factorization techniques to combine a natural selection of the robotic hand configuration with the proportional control of the related grasps. The HRI system has been fully designed, implemented, and tested on two robotic hands: a dexterous anthropomorphic hand and a three-fingered industrial gripper mounted on a robotic manipulator. The results of the test performed on four able-bodied subjects show success rates greater than 90% reached in grasping objects that require different hand shapes and impedance regulations for the task completion. The outcomes also show that the users modulate the bio-inspired degrees of control in a natural manner, proving the pertinence of the proposed system for an effective human-like control of robotic grasping devices in a wearable form factor.","","","10.1109/TCPMT.2018.2799987","University of Bologna through the FARB Linea 2 Funding Action; Micropower Deep Learning SNF project; EuroCPS EU projects; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8301546","Electromyography (EMG) sensors;embedded systems;human–robot interface (HRI);industrial gripper;grasping;non-negative matrix factorization (NMF);pattern recognition;robotic hands","Muscles;Service robots;Grasping;Electromyography;Task analysis;Robot kinematics","dexterous manipulators;electromyography;end effectors;grippers;human-robot interaction;industrial manipulators;learning (artificial intelligence);motion control;pattern recognition;signal processing;telerobotics","sEMG-based human-robot interface;robotic hands;natural control strategies;human-robot interface systems;robotic grasping devices;remote controllers;multifinger grasps;human motion control;grasping tasks;HRI system;fully differential EMG sensors;factorization techniques;robotic hand configuration;proportional control;dexterous anthropomorphic hand;robotic manipulator;pattern recognition;machine learning;grasp impedance;embedded myocontroller","","10","49","","","","","IEEE","IEEE Journals"
"Estimating Depth From Monocular Images as Classification Using Deep Fully Convolutional Residual Networks","Y. Cao; Z. Wu; C. Shen","School of Computer Science, The University of Adelaide, Adelaide, SA, Australia; School of Computer Science, The University of Adelaide, Adelaide, SA, Australia; School of Computer Science, The University of Adelaide, Adelaide, SA, Australia","IEEE Transactions on Circuits and Systems for Video Technology","","2018","28","11","3174","3182","Depth estimation from single monocular images is a key component in scene understanding. Most existing algorithms formulate depth estimation as a regression problem due to the continuous property of depths. However, the depth value of input data can hardly be regressed exactly to the ground-truth value. In this paper, we propose to formulate depth estimation as a pixelwise classification task. Specifically, we first discretize the continuous ground-truth depths into several bins and label the bins according to their depth ranges. Then, we solve the depth estimation problem as classification by training a fully convolutional deep residual network. Compared with estimating the exact depth of a single point, it is easier to estimate its depth range. More importantly, by performing depth classification instead of regression, we can easily obtain the confidence of a depth prediction in the form of probability distribution. With this confidence, we can apply an information gain loss to make use of the predictions that are close to ground-truth during training, as well as fully-connected conditional random fields for post-processing to further improve the performance. We test our proposed method on both indoor and outdoor benchmark RGB-Depth datasets and achieve state-of-the-art performance.","","","10.1109/TCSVT.2017.2740321","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8010878","Classification;deep residual networks;depth estimation","Estimation;Training;Semantics;Network architecture;Predictive models;Neural networks;Probability distribution","convolution;estimation theory;feature extraction;feedforward neural nets;image classification;image colour analysis;image segmentation;learning (artificial intelligence);object detection;prediction theory;probability;random processes;regression analysis","deep fully convolutional residual networks;single monocular images;depth value;ground-truth value;depth estimation problem;depth range;depth classification;depth prediction;indoor benchmark RGB-Depth datasets;outdoor benchmark RGB-Depth datasets;regression problem;pixelwise classification task;probability distribution;information gain loss;fully-connected conditional random fields;post-processing","","14","35","","","","","IEEE","IEEE Journals"
"Deep residual network with regularised fisher framework for detection of melanoma","N. N. Sultana; B. Mandal; N. B. Puhan","School of Electrical Sciences, Indian Institute of Technology, India; School of Computing and Mathematics, Keele University, UK; School of Electrical Sciences, Indian Institute of Technology, India","IET Computer Vision","","2018","12","8","1096","1104","Of all the skin cancer that is prevalent, melanoma has the highest mortality rates. Melanoma becomes life threatening when it penetrates deep into the dermis layer unless detected at an early stage, it becomes fatal since it has a tendency to migrate to other parts of our body. This study presents an automated non-invasive methodology to assist the clinicians and dermatologists for detection of melanoma. Unlike conventional computational methods which require (expensive) domain expertise for segmentation and hand crafted feature computation and/or selection, a deep convolutional neural network-based regularised discriminant learning framework which extracts low-dimensional discriminative features for melanoma detection is proposed. Their approach minimises the whole of within-class variance information and maximises the total class variance information. The importance of various subspaces arising in the within-class scatter matrix followed by dimensionality reduction using total class variance information is analysed for melanoma detection. Experimental results on ISBI 2016, MED-NODE, PH2 and the recent ISBI 2017 databases show the efficacy of their proposed approach as compared to other state-of-the-art methodologies.","","","10.1049/iet-cvi.2018.5238","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8555965","","","cancer;feature extraction;image classification;image segmentation;learning (artificial intelligence);medical image processing;neural nets;skin","low-dimensional discriminative features;discriminant learning framework;deep convolutional neural network-based;hand crafted feature computation;segmentation;conventional computational methods;noninvasive methodology;early stage;dermis layer;highest mortality rates;skin cancer;regularised fisher framework;residual network;melanoma detection;total class variance information;within-class variance information","","3","46","","","","","IET","IET Journals"
"Automated Breast Ultrasound Lesions Detection Using Convolutional Neural Networks","M. H. Yap; G. Pons; J. Martí; S. Ganau; M. Sentís; R. Zwiggelaar; A. K. Davison; R. Martí","School of Computing, Mathematics and Digital Technology, Manchester Metropolitan University, Manchester, U.K.; Universitat Oberta de Catalunya, Barcelona, Spain; Department of Computer Science, University of Girona, Girona, Spain; Radiology Department, UDIAT-Centre Diagnòstic, Corporació Parc Taulí, Sabadell, Spain; Radiology Department, UDIAT-Centre Diagnòstic, Corporació Parc Taulí, Sabadell, Spain; Department of Computer Science, Aberystwyth University, Aberystwyth, U.K.; Centre for Imaging Sciences, Faculty of Biology Medicine and Health, University of Manchester, Manchester, U.K.; Department of Computer Science, University of Girona, Girona, Spain","IEEE Journal of Biomedical and Health Informatics","","2018","22","4","1218","1226","Breast lesion detection using ultrasound imaging is considered an important step of computer-aided diagnosis systems. Over the past decade, researchers have demonstrated the possibilities to automate the initial lesion detection. However, the lack of a common dataset impedes research when comparing the performance of such algorithms. This paper proposes the use of deep learning approaches for breast ultrasound lesion detection and investigates three different methods: a Patch-based LeNet, a U-Net, and a transfer learning approach with a pretrained FCN-AlexNet. Their performance is compared against four state-of-the-art lesion detection algorithms (i.e., Radial Gradient Index, Multifractal Filtering, Rule-based Region Ranking, and Deformable Part Models). In addition, this paper compares and contrasts two conventional ultrasound image datasets acquired from two different ultrasound systems. Dataset A comprises 306 (60 malignant and 246 benign) images and Dataset B comprises 163 (53 malignant and 110 benign) images. To overcome the lack of public datasets in this domain, Dataset B will be made available for research purposes. The results demonstrate an overall improvement by the deep learning approaches when assessed on both datasets in terms of True Positive Fraction, False Positives per image, and F-measure.","","","10.1109/JBHI.2017.2731873","Spanish Ministry of Economy and Competitiveness under Project SMARTER; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8003418","Breast cancer;convolutional neural networks;lesion detection;transfer learning;ultrasound imaging","Lesions;Fractals;Ultrasonic imaging;Imaging;Filtering;Breast cancer","biological organs;biomedical ultrasonics;cancer;image segmentation;learning (artificial intelligence);mammography;medical image processing;neural nets","convolutional neural networks;breast lesion detection;ultrasound imaging;deep learning approaches;breast ultrasound lesion detection;transfer learning approach;state-of-the-art lesion detection algorithms;conventional ultrasound image datasets;ultrasound systems;pretrained FCN-AlexNet;Patch-based LeNet;U-Net;computer-aided diagnosis systems","","20","43","","","","","IEEE","IEEE Journals"
"Multitask Learning for Phone Recognition of Underresourced Languages Using Mismatched Transcription","V. H. Do; N. F. Chen; B. P. Lim; M. A. Hasegawa-Johnson","Advanced Digital Sciences Center, Singapore; Institute for Infocomm Research, Singapore; Institute for Infocomm Research, Singapore; University of Illinois at Urbana–Champaign, Champaign, IL, USA","IEEE/ACM Transactions on Audio, Speech, and Language Processing","","2018","26","3","501","514","It is challenging to obtain large amounts of native (matched) labels for speech audio in underresourced languages. This challenge is often due to a lack of literate speakers of the language, or in extreme cases, a lack of universally acknowledged orthography as well. One solution is to increase the amount of labeled data by using mismatched transcription, which employs transcribers who do not speak the underresourced language of interest called the target language (in place of native speakers), to transcribe what they hear as nonsense speech in their own annotation language (≠ target language). Previous uses of mismatched transcription converted it to a probabilistic transcription (PT), but PT is limited by the errors of nonnative perception. This paper proposes, instead, a multitask learning framework in which one deep neural network (DNN) is trained to optimize two separate tasks: acoustic modeling of a small number of matched transcription with matched target-language graphemes; and acoustic modeling of a large number of mismatched transcription with mismatched annotation-language graphemes. We find that: first, the multitask learning framework gives significant improvement over monolingual, semisupervised learning, multilingual DNN training, and transfer learning baselines; second, a Gaussian Mixture Model-Hidden-Markov Model (GMM-HMM) model adapted using PT improves alignments, thereby improving training; and third, bottleneck features trained on the mismatched transcriptions lead to even better alignments, resulting in further performance gains of the multitask DNN. Our experiments are conducted on the IARPA Georgian and Vietnamese BABEL corpora as well as on our newly collected speech corpus of Singapore Hokkien, an underresourced language with no standard written form.","","","10.1109/TASLP.2017.2782360","Advanced Digital Sciences Center from Singapore's Agency for Science, Technology, and Research (A*STAR); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8186239","Phone recognition;mismatched transcription;probabilistic transcription;multi-task learning;under-resourced languages","Acoustics;Speech;Hidden Markov models;Adaptation models;Speech recognition;Data models;Probabilistic logic","acoustic signal processing;Gaussian processes;hidden Markov models;learning (artificial intelligence);natural language processing;neural nets;speech processing;speech recognition","underresourced language;mismatched transcription;annotation language;probabilistic transcription;multitask learning framework;acoustic modeling;matched target-language graphemes;mismatched annotation-language graphemes;Gaussian Mixture Model;Hidden-Markov Model;speech audio","","2","59","","","","","IEEE","IEEE Journals"
"F-SVM: Combination of Feature Transformation and SVM Learning via Convex Relaxation","X. Wu; W. Zuo; L. Lin; W. Jia; D. Zhang","School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; School of Computer and Information, Hefei University of Technology, Hefei, China; School of Science and Engineering, The Chinese University of Hong Kong, Shenzhen, China","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","11","5185","5199","The generalization error bound of the support vector machine (SVM) depends on the ratio of the radius and margin. However, conventional SVM only considers the maximization of the margin but ignores the minimization of the radius, which restricts its performance when applied to joint learning of feature transformation and the SVM classifier. Although several approaches have been proposed to integrate the radius and margin information, most of them either require the form of the transformation matrix to be diagonal, or are nonconvex and computationally expensive. In this paper, we suggest a novel approximation for the radius of the minimum enclosing ball in feature space, and then propose a convex radius-margin-based SVM model for joint learning of feature transformation and the SVM classifier, i.e., F-SVM. A generalized block coordinate descent method is adopted to solve the F-SVM model, where the feature transformation is updated via the gradient descent and the classifier is updated by employing the existing SVM solver. By incorporating with kernel principal component analysis, F-SVM is further extended for joint learning of nonlinear transformation and the classifier. F-SVM can also be incorporated with deep convolutional networks to improve image classification performance. Experiments on the UCI, LFW, MNIST, CIFAR-10, CIFAR-100, and Caltech101 data sets demonstrate the effectiveness of F-SVM.","","","10.1109/TNNLS.2018.2791507","National Defense Science and Technology Innovation Special Zone Project of China; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8281033","Convex relaxation;max margin;radius-margin error bound;support vector machine (SVM)","Support vector machines;Kernel;Measurement;Principal component analysis;Computational modeling;Training;Data models","gradient methods;learning (artificial intelligence);matrix algebra;principal component analysis;support vector machines","margin information;transformation matrix;feature space;convex radius-margin-based SVM model;feature transformation;SVM classifier;F-SVM model;nonlinear transformation;support vector machine;conventional SVM solver","","6","46","","","","","IEEE","IEEE Journals"
"Do Convolutional Neural Networks Learn Class Hierarchy?","A. Bilal; A. Jourabloo; M. Ye; X. Liu; L. Ren","Bosch Research North AmericaPalo Alto, CA; Michigan State University; Bosch Research North AmericaPalo Alto, CA; Michigan State University; Bosch Research North AmericaPalo Alto, CA","IEEE Transactions on Visualization and Computer Graphics","","2018","24","1","152","162","Convolutional Neural Networks (CNNs) currently achieve state-of-the-art accuracy in image classification. With a growing number of classes, the accuracy usually drops as the possibilities of confusion increase. Interestingly, the class confusion patterns follow a hierarchical structure over the classes. We present visual-analytics methods to reveal and analyze this hierarchy of similar classes in relation with CNN-internal data. We found that this hierarchy not only dictates the confusion patterns between the classes, it furthermore dictates the learning behavior of CNNs. In particular, the early layers in these networks develop feature detectors that can separate high-level groups of classes quite well, even after a few training epochs. In contrast, the latter layers require substantially more epochs to develop specialized feature detectors that can separate individual classes. We demonstrate how these insights are key to significant improvement in accuracy by designing hierarchy-aware CNNs that accelerate model convergence and alleviate overfitting. We further demonstrate how our methods help in identifying various quality issues in the training data.","","","10.1109/TVCG.2017.2744683","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8017618","Convolutional Neural Networks;deep learning;image classification;large-scale classification;confusion matrix","Data visualization;Training;Neurons;Feature extraction;Training data;Image recognition","data visualisation;feedforward neural nets;image classification","convolutional neural networks;state-of-the-art accuracy;image classification;growing number;class confusion patterns;hierarchical structure;visual-analytics methods;similar classes;CNN-internal data;learning behavior;early layers;specialized feature detectors;individual classes;class hierarchy learning;hierarchy-aware CNN design;model convergence;training data","","12","77","Traditional","","","","IEEE","IEEE Journals"
"Asymmetric Adaptation of Deep Features for Cross-Domain Classification in Remote Sensing Imagery","N. Ammour; L. Bashmal; Y. Bazi; M. M. Al Rahhal; M. Zuair","Computer Engineering Department, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia; Computer Engineering Department, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia; Computer Engineering Department, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia; Information Science Department, College of Computer and Information Sciences-MZ, King Saud University, Riyadh, Saudi Arabia; Computer Engineering Department, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia","IEEE Geoscience and Remote Sensing Letters","","2018","15","4","597","601","In this letter, we introduce an asymmetric adaptation neural network (AANN) method for cross-domain classification in remote sensing images. Before the adaptation process, we feed the features obtained from a pretrained convolutional neural network to a denoising autoencoder (DAE) to perform dimensionality reduction. Then the first hidden layer of AANN (placed on the top of DAE) maps the labeled source data to the target space, while the subsequent layers control the separation between the available land-cover classes. To learn its weights, the network minimizes an objective function composed of two losses related to the distance between the source and target data distributions and class separation. The results of experiments conducted on six scenarios built from three benchmark scene remote sensing data sets (i.e., Merced, KSA, and AID data sets) are reported and discussed.","","","10.1109/LGRS.2018.2800642","Deanship of Scientific Research at King Saud University through the Local Research Group Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8291513","Asymmetric adaptation neural network (AANN);cross-domain classification;deep features","Feature extraction;Neural networks;Training;Niobium;Feeds;Remote sensing;Linear programming","feedforward neural nets;geophysical image processing;image classification;image coding;learning (artificial intelligence);remote sensing","DAE;dimensionality reduction;hidden layer;AANN;labeled source data;target space;class separation;benchmark scene remote sensing data sets;deep features;cross-domain classification;remote sensing imagery;asymmetric adaptation neural network method;remote sensing images;pretrained convolutional neural network;denoising autoencoder;land-cover classes;objective function;source data distribution;target data distribution;Merced data set;KSA data set;AID data set","","6","14","","","","","IEEE","IEEE Journals"
"Combining High Speed ELM Learning with a Deep Convolutional Neural Network Feature Encoding for Predicting Protein-RNA Interactions","L. Wang; Z. You; D. Huang; F. Zhou","Zaozhuang, Shandong China (e-mail: leiwang@cumt.edu.cn); Xinjiang Technical Institute of Physics and Chemistry, Chinese Academy of Science, China University of Mining and Technology, Ürümqi, Xingjiang China (e-mail: zhuhongyou@ms.xjb.ac.cn); Computer Science Department, Tongji University, Shanghai, ShangHai China (e-mail: dshuang@tongji.edu.cn); Changchun, Jilin China (e-mail: FengfengZhou@gmail.com)","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2018","PP","99","1","1","Emerging evidence has shown that RNA plays a crucial role in many cellular processes, and their biological functions are primarily achieved by binding with a variety of proteins. High-throughput biological experiments provide a lot of valuable information for the initial identification of RNA-protein interactions (RPIs), but with the increasing complexity of RPIs networks, this method gradually falls into expensive and time-consuming situations. Therefore, there is an urgent need for high speed and reliable methods to predict RNA-protein interactions. In this study, we propose a computational method for predicting the RNA-protein interactions using sequence information. The deep learning convolution neural network (CNN) algorithm is utilized to mine the hidden high-level discriminative features from the RNA and protein sequences and feed it into the extreme learning machine (ELM) classifier. The experimental results with 5-fold cross-validation indicate that the proposed method achieves superior performance on benchmark datasets (RPI1807, RPI2241 and RPI369) with the accuracy of 98.83%, 90.83% and 85.63%, respectively. We further evaluate the performance of the proposed model by comparing it with the state-of-the-art SVM classifier and other existing methods on the same benchmark data set. The experimental results show our model can serve as a useful tool for predicting RNA-protein interactions.","","","10.1109/TCBB.2018.2874267","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8482290","Convolution neural network;Extreme learning machine;RNA-Protein interactions;sequence","Proteins;RNA;Convolution;Neural networks;Benchmark testing;Feature extraction;Sparse matrices","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Novel Image Steganography Method via Deep Convolutional Generative Adversarial Networks","D. Hu; L. Wang; W. Jiang; S. Zheng; B. Li","School of Computer and Information, Hefei University of Technology, Hefei, China; School of Computer and Information, Hefei University of Technology, Hefei, China; School of Computer and Information, Hefei University of Technology, Hefei, China; School of Computer and Information, Hefei University of Technology, Hefei, China; College of Information Engineering, Shenzhen University, Shenzhen, China","IEEE Access","","2018","6","","38303","38314","The security of image steganography is an important basis for evaluating steganography algorithms. Steganography has recently made great progress in the long-term confrontation with steganalysis. To improve the security of image steganography, steganography must have the ability to resist detection by steganalysis algorithms. Traditional embedding-based steganography embeds the secret information into the content of an image, which unavoidably leaves a trace of the modification that can be detected by increasingly advanced machine-learning-based steganalysis algorithms. The concept of steganography without embedding (SWE), which does not need to modify the data of the carrier image, appeared to overcome the detection of machine-learning-based steganalysis algorithms. In this paper, we propose a novel image SWE method based on deep convolutional generative adversarial networks. We map the secret information into a noise vector and use the trained generator neural network model to generate the carrier image based on the noise vector. No modification or embedding operations are required during the process of image generation, and the information contained in the image can be extracted successfully by another neural network, called the extractor, after training. The experimental results show that this method has the advantages of highly accurate information extraction and a strong ability to resist detection by state-of-the-art image steganalysis algorithms.","","","10.1109/ACCESS.2018.2852771","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8403208","Steganography;without embedding;coverless;generative adversarial networks","Gallium nitride;Distortion;Brain modeling;Training;Digital images;Resists;Transform coding","data encapsulation;feedforward neural nets;image coding;learning (artificial intelligence);steganography","image steganography method;machine-learning-based steganalysis algorithms;traditional embedding-based steganography;long-term confrontation;state-of-the-art image steganalysis algorithms;image generation;carrier image;trained generator neural network model;noise vector;secret information;deep convolutional generative adversarial networks;image SWE method","","10","38","","","","","IEEE","IEEE Journals"
"Multicolumn RBF Network","A. O. Hoori; Y. Motai","Department of Electrical and Computer Engineering, Virginia Commonwealth University, Richmond, VA, USA; Department of Electrical and Computer Engineering, Virginia Commonwealth University, Richmond, VA, USA","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","4","766","778","This paper proposes the multicolumn RBF network (MCRN) as a method to improve the accuracy and speed of a traditional radial basis function network (RBFN). The RBFN, as a fully connected artificial neural network (ANN), suffers from costly kernel inner-product calculations due to the use of many instances as the centers of hidden units. This issue is not critical for small datasets, as adding more hidden units will not burden the computation time. However, for larger datasets, the RBFN requires many hidden units with several kernel computations to generalize the problem. The MCRN mechanism is constructed based on dividing a dataset into smaller subsets using the k-d tree algorithm. N resultant subsets are considered as separate training datasets to train N individual RBFNs. Those small RBFNs are stacked in parallel and bulged into the MCRN structure during testing. The MCRN is considered as a well-developed and easy-to-use parallel structure, because each individual ANN has been trained on its own subsets and is completely separate from the other ANNs. This parallelized structure reduces the testing time compared with that of a single but larger RBFN, which cannot be easily parallelized due to its fully connected structure. Small informative subsets provide the MCRN with a regional experience to specify the problem instead of generalizing it. The MCRN has been tested on many benchmark datasets and has shown better accuracy and great improvements in training and testing times compared with a single RBFN. The MCRN also shows good results compared with those of some machine learning techniques, such as the support vector machine and k-nearest neighbors.","","","10.1109/TNNLS.2017.2650865","Higher Committee of Education Development of Iraq; National Science Foundation CAREER; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7828142","Deep neural network;k-d tree;k-nearest neighbors (KNNs);kernel;radial basis function networks (RBFNs)","Training;Kernel;Testing;Machine learning;Radial basis function networks;Convergence","learning (artificial intelligence);radial basis function networks;set theory;support vector machines","dataset;hidden units;computation time;kernel computations;MCRN mechanism;N resultant subsets;N individual RBFNs;MCRN structure;parallel structure;parallelized structure;testing time;fully connected structure;informative subsets;benchmark datasets;multicolumn RBF network;traditional radial basis function network;fully connected artificial neural network;training datasets","","1","33","","","","","IEEE","IEEE Journals"
"A Deep Neural Networks Approach to Automatic Recognition Systems for Volcano-Seismic Events","M. Titos; A. Bueno; L. García; C. Benítez","Department of Signal Theory, Telematic and Communications, University of Granada, Granada, Spain; Department of Signal Theory, Telematic and Communications, University of Granada, Granada, Spain; Department of Signal Theory, Telematic and Communications, University of Granada, Granada, Spain; Department of Signal Theory, Telematic and Communications, University of Granada, Granada, Spain","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2018","11","5","1533","1544","Deep neural networks (DNNs) could help to identify the internal sources of volcano-seismic events. However, direct applications of DNNs are challenging, given the multiple seismic sources and the small size of available datasets. In this paper, we propose a novel approach in the field of volcano seismology to classify volcano-seismic events based on fully connected DNNs. Two DNN architectures with different weights scheme initialization are studied: stacked denoising autoencoders and deep belief networks. Using a combined feature vector of linear prediction coefficients and statistical properties, we evaluate classification performance on seven different classes of isolated seismic events. These proposed architectures are compared to multilayer perceptron, support vector machine, and random forest. Experimental results show that DNNs can efficiently capture complex relationships of volcano-seismic data and achieve better classification performance with faster convergence when compared to classical models.","","","10.1109/JSTARS.2018.2803198","TEC2015- 68752 (MINECO/FEDER); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8307075","Artificial intelligence;feedforward neural networks;geoscience and remote sensing;geophysical signal processing;multilayer neural networks;neural networks;remote monitoring;remote sensing;signal processing;volcanoes;volcanic activity","Volcanoes;Neural networks;Data models;Feature extraction;Computer architecture;Training;Remote sensing","belief networks;feature extraction;geophysical techniques;geophysics computing;learning (artificial intelligence);neural net architecture;pattern classification;seismology;statistical analysis;volcanology","volcano seismology;volcano-seismic events;fully connected DNNs;deep belief networks;isolated seismic events;volcano-seismic data;deep neural networks approach;automatic recognition systems;multiple seismic sources;DNN architectures;combined feature vector;linear prediction coefficients;statistical properties;classification performance","","7","53","","","","","IEEE","IEEE Journals"
"Nonlocal Similarity Modeling and Deep CNN Gradient Prior for Super Resolution","C. Ren; X. He; Y. Pu","College of Electronics and Information Engineering, Sichuan University, Chengdu, China; College of Electronics and Information Engineering, Sichuan University, Chengdu, China; College of Computer Science, Sichuan University, Chengdu, China","IEEE Signal Processing Letters","","2018","25","7","916","920","This letter presents a novel super-resolution (SR) method via nonlocal similarity modeling and deep convolutional neural network (CNN) gradient prior (GP). Specifically, on the one hand, the group similarity reliability (GSR) strategy is proposed for improving the adaptive high-dimensional nonlocal total variation (AHNLTV) model [statistical prior, GSR-based AHNLTV (GA)], which captures the structures of the underlying high-resolution (HR) image via the image itself. On the other hand, the GP is learned by using the deep CNN (learned prior), which predicts the gradients from external images. Finally, the GA-GP approach is proposed by incorporating the two complementary priors. The results show that GA-GP achieves better performance than other state-of-the-art SR methods.","","","10.1109/LSP.2018.2829766","National Postdoctoral Program for Innovative Talents of China; Post-Doctoral Research and Development Foundation of Sichuan University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8345640","Gradient prior (GP);group similarity reliability (GSR);nonlocal similarity;super resolution","Image resolution;Reliability;Nickel;Convolution;Image reconstruction;Feature extraction;Signal resolution","convolution;feedforward neural nets;gradient methods;image resolution","learned prior;GA-GP approach;nonlocal similarity modeling;deep CNN gradient;group similarity reliability strategy;GSR;super-resolution method;high-resolution image;AHNLTV;deep convolutional neural network gradient prior;adaptive high-dimensional nonlocal total variation model","","","39","","","","","IEEE","IEEE Journals"
"Building Emotional Machines: Recognizing Image Emotions Through Deep Neural Networks","H. Kim; Y. Kim; S. J. Kim; I. Lee","Department of Computer Science, Yonsei University, Seoul, South Korea; Department of Computer Science, Yonsei University, Seoul, South Korea; Department of Computer Science, Yonsei University, Seoul, South Korea; Department of Computer Science, Yonsei University, Seoul, South Korea","IEEE Transactions on Multimedia","","2018","20","11","2980","2992","An image is a very effective tool for conveying emotions. Many researchers have investigated emotions in images by using various features extracted from images. In this paper, we focus on two high-level features, the object and the background, and assume that the semantic information in images is a good cue for predicting emotions. An object is one of the most important elements that define an image, and we discover through experiments that there is a high correlation between the objects and emotions in images in most cases. Even with the same object, there may be slight differences in emotion due to different backgrounds, and we use the semantic information of the background to improve the prediction performance. By combining the different levels of features, we build an emotion-based feedforward deep neural network that produces the emotion values of a given image. The output emotion values in our framework are continuous values in two-dimensional space (valence and arousal), which are more effective than using a small number of emotion categories to describe emotions. Experiments confirm the effectiveness of our network in predicting the emotions of images.","","","10.1109/TMM.2018.2827782","Samsung Research Funding Center of Samsung Electronics; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8344491","Emotion prediction;image emotion;deep network","Feature extraction;Emotion recognition;Machine learning;Predictive models;Databases;Task analysis;Psychology","emotion recognition;feature extraction;feedforward neural nets","emotion categories;image emotions;high-level features;semantic information;feedforward deep neural network;emotional machines;feature extraction","","","62","","","","","IEEE","IEEE Journals"
"Convolution in Convolution for Network in Network","Y. Pang; M. Sun; X. Jiang; X. Li","School of Electrical and Information Enginnering, Tianjin University, Tianjin, China; School of Electrical and Information Enginnering, Tianjin University, Tianjin, China; School of Electrical and Information Enginnering, Tianjin University, Tianjin, China; Center for OPTical IMagery Analysis and Learning, State Key Laboratory of Transient Optics and Photonics, Xi’an Institute of Optics and Precision Mechanics, Chinese Academy of Sciences, Xi’an, China","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","5","1587","1597","Network in network (NiN) is an effective instance and an important extension of deep convolutional neural network consisting of alternating convolutional layers and pooling layers. Instead of using a linear filter for convolution, NiN utilizes shallow multilayer perceptron (MLP), a nonlinear function, to replace the linear filter. Because of the powerfulness of MLP and 1 × 1 convolutions in spatial domain, NiN has stronger ability of feature representation and hence results in better recognition performance. However, MLP itself consists of fully connected layers that give rise to a large number of parameters. In this paper, we propose to replace dense shallow MLP with sparse shallow MLP. One or more layers of the sparse shallow MLP are sparely connected in the channel dimension or channel-spatial domain. The proposed method is implemented by applying unshared convolution across the channel dimension and applying shared convolution across the spatial dimension in some computational layers. The proposed method is called convolution in convolution (CiC). The experimental results on the CIFAR10 data set, augmented CIFAR10 data set, and CIFAR100 data set demonstrate the effectiveness of the proposed CiC method.","","","10.1109/TNNLS.2017.2676130","National Basic Research Program of China (973 Program); National Natural Science Foundation of China; Research Fund of Hainan Tropical Ocean University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7879808","Convolution in convolution (CiC);convolutional neural networks (CNNs);image recognition;network in network (NiN)","Convolution;Feature extraction;Neural networks;Kernel;Learning systems;Sun;Data mining","multilayer perceptrons;nonlinear functions","NiN;deep convolutional neural network;convolutional layers;pooling layers;shallow multilayer perceptron;dense shallow MLP;sparse shallow MLP;unshared convolution;shared convolution;network in network;nonlinear function;feature representation;convolution in convolution;CiC method","","13","51","","","","","IEEE","IEEE Journals"
"ScatterNet: A Deep Subjective Similarity Model for Visual Analysis of Scatterplots","Y. Ma; A. K. H. Tung; W. Wang; X. Gao; Z. Pan; W. Chen","Computer Science, State Key Lab of CAD&CG, Zhejiang University, Hangzhou, Zhejiang China (e-mail: yuxinma@asu.edu); Department of Computer Science, National University of Singapore, Singapore, Singapore Singapore 148955 (e-mail: atung@comp.nus.edu.sg); Computer Sicence, National University of Singapore, Singapore, Singapore Singapore (e-mail: wangwei@comp.nus.edu.sg); Computer Science, Hangzhou Normal University, Hangzhou, Zhejiang China (e-mail: geekplux@gmail.com); Digital Media and Interaction (DMI) Research Center, Hangzhou Normal University, Hangzhou, Zhejiang China (e-mail: zgpan@cad.zju.edu.cn); Zhejiang University, State Key Lab of CAD&CG, Hangzhou, Zhejiang China 310058 (e-mail: chenwei@cad.zju.edu.cn)","IEEE Transactions on Visualization and Computer Graphics","","2018","PP","99","1","1","Similarity measuring methods are widely adopted in a broad range of visualization applications. In this work, we address the challenge of representing human perception in the visual analysis of scatterplots by introducing a novel deep-learning-based approach, ScatterNet, captures perception-driven similarities of such plots. The approach exploits deep neural networks to extract semantic features of scatterplot images for similarity calculation. We create a large labeled dataset consisting of similar and dissimilar images of scatterplots to train the deep neural network. We conduct a set of evaluations including performance experiments and a user study to demonstrate the effectiveness and efficiency of our approach. The evaluations confirm that the learned features capture the human perception of scatterplot similarity effectively. We describe two scenarios to show how ScatterNet can be applied in visual analysis applications.","","","10.1109/TVCG.2018.2875702","The National Research Foundation Prime Ministers Office Singapore under its Strategic Capability Research Centres Funding Initiative N-CRiPT; Singapore Ministry of Education Academic Research Fund Tier 1; National Key R D Program of China; Key National Natural Science Foundation of China; National Natural Science Foundation of China; National 973 Program of China; The National Research Foundation Prime Ministers Office Singapore under its International Research Centre Funding Initiative SeSaMe Center; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8490694","Scatterplot;similarity measuring;deep learning;visualization;visual exploration","Visualization;Feature extraction;Measurement;Neural networks;Personal area networks;Visual perception;Computational modeling","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Energy-Efficient Mapping of LTE-A PHY Signal Processing Tasks on Microservers","A. Das; F. Catthoor; A. Bourdoux; B. Gyselinckx","Department of Electrical and Computer Engineering, Drexel University, Philadelphia, PA, USA; IMEC, Leuven, Belgium; IMEC, Leuven, Belgium; IMEC, Leuven, Belgium","IEEE Transactions on Green Communications and Networking","","2018","2","2","397","407","Centralized radio access network (C-RAN) is a network architecture that is emerging as a key technology enabler for 5G mobile networks as capacity demands for mobile traffic continue to proliferate. Essentially, C-RAN involves separating the remote radio heads from baseband units to be processed in the cloud. A systematic design of C-RAN involves mapping of individual baseband signal processing tasks to general purpose cloud infrastructures, such as the microserver to reduce the energy footprint. In this paper, we start with mapping the lowest protocol stack, i.e., the physical layer (PHY), which is characterized by strict latency and dynamic data rate. To achieve this, we explore the use of machine intelligence for energyefficient mapping of PHY signal processing on microservers. Fundamental to this approach is: 1) the use of principal component analysis to represent workload from multi-dimensional hardware performance statistics, demonstrating 99.88% correlation with the critical PHY processing latency and 2) the use of deep learning to model latency and predict dynamic workload for on-demand resource allocation, resulting in up to 36% reduction in hardware usage. These principles are built into a cross-layer run-time framework, which adapts resource allocation in response to time-varying data rate, guaranteeing latency, and improving energy efficiency by up to 48% (average 28%).","","","10.1109/TGCN.2018.2794477","EUH2020 Grant NeuRAM3 Cube (Neural computing Architectures in Advanced Monolithic 3D-VLSI Nano-Technologies); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8260840","Centralized radio access network (C-RAN);LTE-advanced;physical layer (PHY);neural network;deep learning;principal component analysis (PCA)","Hardware;Signal processing;Correlation;Baseband;Base stations;Principal component analysis","cellular radio;cloud computing;energy conservation;learning (artificial intelligence);Long Term Evolution;mobile computing;principal component analysis;radio access networks;resource allocation;signal processing;telecommunication traffic","energy-efficient mapping;microserver;centralized radio access network;C-RAN;network architecture;key technology enabler;5G mobile networks;capacity demands;mobile traffic;remote radio;baseband units;systematic design;individual baseband signal processing tasks;general purpose cloud infrastructures;energy footprint;physical layer;dynamic data rate;machine intelligence;PHY signal processing;principal component analysis;multidimensional hardware performance statistics;critical PHY processing;dynamic workload;on-demand resource allocation;cross-layer run-time framework;time-varying data rate;protocol stack;lte-a phy signal processing tasks;deep learning","","","41","","","","","IEEE","IEEE Journals"
"Efficient Group-n Encoding and Decoding for Facial Age Estimation","Z. Tan; J. Wan; Z. Lei; R. Zhi; G. Guo; S. Z. Li","Center for Biometrics and Security Research & National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Center for Biometrics and Security Research & National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Center for Biometrics and Security Research & National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, P. R. China; Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, WV; Center for Biometrics and Security Research & National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","11","2610","2623","Different ages are closely related especially among the adjacent ages because aging is a slow and extremely non-stationary process with much randomness. To explore the relationship between the real age and its adjacent ages, an age group-n encoding (AGEn) method is proposed in this paper. In our model, adjacent ages are grouped into the same group and each age corresponds to n groups. The ages grouped into the same group would be regarded as an independent class in the training stage. On this basis, the original age estimation problem can be transformed into a series of binary classification sub-problems. And a deep Convolutional Neural Networks (CNN) with multiple classifiers is designed to cope with such sub-problems. Later, a Local Age Decoding (LAD) strategy is further presented to accelerate the prediction process, which locally decodes the estimated age value from ordinal classifiers. Besides, to alleviate the imbalance data learning problem of each classifier, a penalty factor is inserted into the unified objective function to favor the minority class. To compare with state-of-the-art methods, we evaluate the proposed method on FG-NET, MORPH II, CACD and Chalearn LAP 2015 databases and it achieves the best performance.","","","10.1109/TPAMI.2017.2779808","National Key Research and Development Plan; Chinese National Natural Science Foundation Projects; Science and Technology Development Fund of Macau; NVIDIA GPU donation program and AuthenMetric R&D Funds; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8141981","Age estimation;deep learning;convolutional neural network;age grouping;data imbalance","Estimation;Face;Training;Aging;Decoding;Encoding;Correlation","computer vision;face recognition;feedforward neural nets;image classification;learning (artificial intelligence)","facial Age;adjacent ages;aging;age group-n encoding method;original age estimation problem;Local Age Decoding strategy;estimated age value;deep convolutional neural networks;multiple classifiers;imbalance data learning;FG-NET databases;Chalearn LAP 2015 databases;MORPH II databases;CACD databases","","3","60","","","","","IEEE","IEEE Journals"
"A Sparse-View CT Reconstruction Method Based on Combination of DenseNet and Deconvolution","Z. Zhang; X. Liang; X. Dong; Y. Xie; G. Cao","Institute of Biomedical and Health Engineering, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Institute of Biomedical and Health Engineering, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Department of Biomedical Engineering and Mechanics, Virginia Polytechnic Institute and State University, Blacksburg, VA, USA; Institute of Biomedical and Health Engineering, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Department of Biomedical Engineering and Mechanics, Virginia Polytechnic Institute and State University, Blacksburg, VA, USA","IEEE Transactions on Medical Imaging","","2018","37","6","1407","1417","Sparse-view computed tomography (CT) holds great promise for speeding up data acquisition and reducing radiation dose in CT scans. Recent advances in reconstruction algorithms for sparse-view CT, such as iterative reconstruction algorithms, obtained high-quality image while requiring advanced computing power. Lately, deep learning (DL) has been widely used in various applications and has obtained many remarkable outcomes. In this paper, we propose a new method for sparse-view CT reconstruction based on the DL approach. The method can be divided into two steps. First, filter backprojection (FBP) was used to reconstruct the CT image from sparsely sampled sinogram. Then, the FBP results were fed to a DL neural network, which is a DenseNet and deconvolution-based network (DD-Net). The DD-Net combines the advantages of DenseNet and deconvolution and applies shortcut connections to concatenate DenseNet and deconvolution to accelerate the training speed of the network; all of those operations can greatly increase the depth of network while enhancing the expression ability of the network. After the training, the proposed DD-Net achieved a competitive performance relative to the state-of-the-art methods in terms of streaking artifacts removal and structure preservation. Compared with the other state-of-the-art reconstruction methods, the DD-Net method can increase the structure similarity by up to 18% and reduce the root mean square error by up to 42%. These results indicate that DD-Net has great potential for sparse-view CT image reconstruction.","","","10.1109/TMI.2018.2823338","Dr. Guohua Cao’s CAREER Award from the U.S. National Science Foundation; National Key Research and Develop Program of China; Union of Production, Study and Research Project of Guangdong Province; Technological Breakthrough Project of Shenzhen City; Natural Science Foundation of Guangdong Province; UCAS Joint PhD Training Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8331861","Sparse-view CT;CT reconstruction;deep learning;DenseNet;deconvolution","Computed tomography;Image reconstruction;Deconvolution;Neural networks;Reconstruction algorithms;X-ray imaging;Training","computerised tomography;data acquisition;deconvolution;image denoising;image reconstruction;iterative methods;learning (artificial intelligence);mean square error methods;medical image processing;neural nets","DL neural network;training speed;state-of-the-art reconstruction methods;DD-Net method;sparse-view CT image reconstruction;sparse-view CT reconstruction method;sparse-view computed tomography;data acquisition;CT scans;iterative reconstruction algorithms;sparsely sampled sinogram;high-quality image;radiation dose;deep learning;deconvolution-based network;streaking artifacts removal;structure preservation;structure similarity;root mean square error","","3","63","","","","","IEEE","IEEE Journals"
"Automatic Tool Landmark Detection for Stereo Vision in Robot-Assisted Retinal Surgery","T. Probst; K. Maninis; A. Chhatkuli; M. Ourak; E. V. Poorten; L. Van Gool","Computer Vision Lab, ETH, Z&#x00FC;rich, Switzerland; Computer Vision Lab, ETH, Z&#x00FC;rich, Switzerland; Computer Vision Lab, ETH, Z&#x00FC;rich, Switzerland; Katholieke Universiteit Leuven, Leuven, Belgium; Katholieke Universiteit Leuven, Leuven, Belgium; Computer Vision Lab, ETH, Katholieke Universiteit Leuven, Z&#x00FC;rich, Leuven, SwitzerlandBelgium","IEEE Robotics and Automation Letters","","2018","3","1","612","619","Computer vision and robotics are being increasingly applied in medical interventions. Especially in interventions where extreme precision is required, they could make a difference. One such application is robot-assisted retinal microsurgery. In recent works, such interventions are conducted under a stereo-microscope, and with a robot-controlled surgical tool. The complementarity of computer vision and robotics has, however, not yet been fully exploited. In order to improve the robot control, we are interested in three-dimensional (3-D) reconstruction of the anatomy and in automatic tool localization using a stereo microscope. In this letter, we solve this problem for the first time using a single pipeline, starting from uncalibrated cameras to reach metric 3-D reconstruction and registration, in retinal microsurgery. The key ingredients of our method are 1) surgical tool landmark detection, and 2) 3-D reconstruction with the stereo microscope, using the detected landmarks. To address the former, we propose a novel deep learning method that detects and recognizes keypoints in high-definition images at higher than real-time speed. We use the detected two-dimensional keypoints along with their corresponding 3-D coordinates obtained from the robot sensors to calibrate the stereo microscope using an affine projection model. We design an online 3-D reconstruction pipeline that makes use of smoothness constraints and performs robot-to-camera registration. The entire pipeline is extensively validated on open-sky porcine eye sequences. Quantitative and qualitative results are presented for all steps.","","","10.1109/LRA.2017.2778020","EU Framework Programme for Research and Innovation Horizon 2020; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8120159","Tool landmark detection;3D reconstruction;robot-assisted surgery;deep learning","Cameras;Tools;Retina;Microscopy;Robot kinematics;Calibration","cameras;eye;image reconstruction;image registration;image sequences;learning (artificial intelligence);medical robotics;robot vision;stereo image processing;surgery","robot sensors;stereo microscope;robot-to-camera registration;automatic tool landmark detection;stereo vision;computer vision;medical interventions;retinal microsurgery;stereo-microscope;automatic tool localization;3D coordinates;open-sky porcine eye sequences;two-dimensional keypoints;deep learning method;robot-controlled surgical tool;robot-assisted retinal microsurgery;landmark detection;3D reconstruction","","3","31","Traditional","","","","IEEE","IEEE Journals"
"Integrating Deep Semantic Segmentation Into 3-D Point Cloud Registration","A. Zaganidis; L. Sun; T. Duckett; G. Cielniak","Lincoln Centre for Autonomous Systems (LCAS), University of Lincoln, Lincoln LN6 7TS, U.K.; Lincoln Centre for Autonomous Systems (LCAS), University of Lincoln, Lincoln LN6 7TS, U.K.; Lincoln Centre for Autonomous Systems (LCAS), University of Lincoln, Lincoln LN6 7TS, U.K.; Lincoln Centre for Autonomous Systems (LCAS), University of Lincoln, Lincoln LN6 7TS, U.K.","IEEE Robotics and Automation Letters","","2018","3","4","2942","2949","Point cloud registration is the task of aligning 3D scans of the same environment captured from different poses. When semantic information is available for the points, it can be used as a prior in the search for correspondences to improve registration. Semantic-assisted Normal Distributions Transform (SE-NDT) is a new registration algorithm that reduces the complexity of the problem by using the semantic information to partition the point cloud into a set of normal distributions, which are then registered separately. In this letter we extend the NDT registration pipeline by using PointNet, a deep neural network for segmentation and classification of point clouds, to learn and predict per-point semantic labels. We also present the Iterative Closest Point (ICP) equivalent of the algorithm, a special case of Multichannel Generalized ICP. We evaluate the performance of SE-NDT against the state of the art in point cloud registration on the publicly available classification data set Semantic3d.net. We also test the trained classifier and algorithms on dynamic scenes, using a sequence from the public dataset KITTI. The experiments demonstrate the improvement of the registration in terms of robustness, precision and speed, across a range of initial registration errors, thanks to the inclusion of semantic information.","","","10.1109/LRA.2018.2848308","European Unions Horizon 2020 research and innovation programme; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8387438","Localization;SLAM;robotics in agriculture and forestry","Semantics;Three-dimensional displays;Transforms;Gaussian distribution;Iterative closest point algorithm;Image color analysis;Partitioning algorithms","image registration;image segmentation;iterative methods;learning (artificial intelligence);neural nets;normal distribution;transforms","3D point cloud registration;iterative closest point equivalent;point cloud partitioning;semantic-assisted normal distribution transform;registration errors;semantic labels;deep semantic segmentation;Semantic3d.net;publicly available classification data set;deep neural network;NDT registration pipeline;registration algorithm;SE-NDT","","5","20","","","","","IEEE","IEEE Journals"
"Generic Proposal Evaluator: A Lazy Learning Strategy Toward Blind Proposal Quality Assessment","Q. Wu; H. Li; F. Meng; K. N. Ngan","School of Electronic Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Electronic Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Electronic Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Electronic Engineering, University of Electronic Science and Technology of China, Chengdu, China","IEEE Transactions on Intelligent Transportation Systems","","2018","19","1","306","319","Existing detection or recognition systems typically select one state-of-the-art proposal algorithm to produce massive object-covered candidate windows, and a quality metric specifically designed for this algorithm is utilized to single out small amounts of proposals. However, in practice, the accuracies of different proposal algorithms significantly change from one image content to another one. To obtain more robust proposal results, a generic proposal evaluator (GPE) is highly desired, which could choose optimal candidate windows across multiple proposal algorithms. In this paper, we propose a lazy learning strategy to train the GPE, which aims to blindly estimate the quality of each proposal without accessing to its manual annotation. Unlike the traditional end-to-end framework that learns a universal model from all training samples, we try to build query-specific training subset for each given proposal, where only its k-nearest-neighborhoods are collected from all labeled candidate windows. Benefits from the capability of updating the regression parameters for different visual contents, the proposed method delivers a higher quality prediction accuracy even with respect to the deep neural network learned by end-to-end method. Experimental results confirm that the proposed algorithm significantly outperforms many state-of-the-art proposal quality metrics.","","","10.1109/TITS.2017.2750070","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8057586","Object proposal;blind proposal quality assessment;lazy learning","Proposals;Measurement;Quality assessment;Algorithm design and analysis;Training;Visualization","image motion analysis;learning (artificial intelligence);neural nets;regression analysis;video signal processing","GPE;query-specific training subset;higher quality prediction accuracy;generic proposal evaluator;lazy learning strategy;blind proposal quality assessment;massive object-covered candidate windows;optimal candidate windows","","2","66","","","","","IEEE","IEEE Journals"
"Compressed Sensing MRI Reconstruction Using a Generative Adversarial Network With a Cyclic Loss","T. M. Quan; T. Nguyen-Duc; W. Jeong","Ulsan National Institute of Science and Technology, Ulsan, South Korea; Ulsan National Institute of Science and Technology, Ulsan, South Korea; Ulsan National Institute of Science and Technology, Ulsan, South Korea","IEEE Transactions on Medical Imaging","","2018","37","6","1488","1497","Compressed sensing magnetic resonance imaging (CS-MRI) has provided theoretical foundations upon which the time-consuming MRI acquisition process can be accelerated. However, it primarily relies on iterative numerical solvers, which still hinders their adaptation in time-critical applications. In addition, recent advances in deep neural networks have shown their potential in computer vision and image processing, but their adaptation to MRI reconstruction is still in an early stage. In this paper, we propose a novel deep learning-based generative adversarial model, RefineGAN, for fast and accurate CS-MRI reconstruction. The proposed model is a variant of fullyresidual convolutional autoencoder and generative adversarial networks (GANs), specifically designed for CS-MRI formulation; it employs deeper generator and discriminator networks with cyclic data consistency loss for faithful interpolation in the given under-sampled k-space data. In addition, our solution leverages a chained networkto further enhance the reconstruction quality. RefineGAN is fast and accurate-the reconstruction process is extremely rapid, as low as tens of milliseconds for reconstruction of a 256 × 256 image, because it is one-way deployment on a feed-forward network, and the image quality is superior even for extremely low sampling rate (as low as 10%) due to the data-driven nature of the method. We demonstrate that RefineGAN outperforms the state-of-the-art CS-MRI methods by a large margin in terms of both running time and image quality via evaluation using several open-source MRI databases.","","","10.1109/TMI.2018.2820120","2017 Research Fund of UNIST; Bio & Medical Technology Development Program of the National Research Foundation of Korea (NRF) funded by the Ministry of Science and ICT (MSIT); Next-Generation Information Computing Development Program through the NRF funded by the MSIT; Basic Science Research Program through the NRF funded by the Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8327637","Compressed sensing;MRI;GAN;DiscoGAN;CycleGAN","Image reconstruction;Magnetic resonance imaging;Machine learning;Gallium nitride;Training;Image quality;Databases","biomedical MRI;compressed sensing;feedforward neural nets;image coding;image reconstruction;image sampling;interpolation;learning (artificial intelligence);medical image processing","theoretical foundations;time-consuming MRI acquisition process;iterative numerical solvers;time-critical applications;deep neural networks;image processing;RefineGAN;fast CS-MRI reconstruction;accurate CS-MRI reconstruction;generative adversarial network;CS-MRI formulation;deeper generator;discriminator networks;cyclic data consistency loss;under-sampled k-space data;reconstruction quality;reconstruction process;feed-forward network;image quality;extremely low sampling rate;open-source MRI databases;compressed sensing magnetic resonance imaging;compressed sensing MRI reconstruction;computer vision;deep learning-based generative adversarial model;fully-residual convolutional autoencoder;interpolation","","15","37","","","","","IEEE","IEEE Journals"
"Deep Recurrent Neural Networks for Prostate Cancer Detection: Analysis of Temporal Enhanced Ultrasound","S. Azizi; S. Bayat; P. Yan; A. Tahmasebi; J. T. Kwak; S. Xu; B. Turkbey; P. Choyke; P. Pinto; B. Wood; P. Mousavi; P. Abolmaesumi","Department of Electrical and Computer Engineering, The University of British Columbia, Vancouver, Canada; Department of Electrical and Computer Engineering, The University of British Columbia, Vancouver, Canada; Rensselaer Polytechnic Institute, Troy, NY, USA; Philips Research North America, Cambridge, MA, USA; Department of Computer Engineering, Sejong University, Seoul, South Korea; National Institutes of Health Research Center, Bethesda, MD, USA; National Institutes of Health Research Center, Bethesda, MD, USA; National Institutes of Health Research Center, Bethesda, MD, USA; National Institutes of Health Research Center, Bethesda, MD, USA; National Institutes of Health Research Center, Bethesda, MD, USA; School of Computing, Queen’s University, Kingston, Canada; Department of Electrical and Computer Engineering, The University of British Columbia, Vancouver, Canada","IEEE Transactions on Medical Imaging","","2018","37","12","2695","2703","Temporal enhanced ultrasound (TeUS), comprising the analysis of variations in backscattered signals from a tissue over a sequence of ultrasound frames, has been previously proposed as a new paradigm for tissue characterization. In this paper, we propose to use deep recurrent neural networks (RNN) to explicitly model the temporal information in TeUS. By investigating several RNN models, we demonstrate that long short-term memory (LSTM) networks achieve the highest accuracy in separating cancer from benign tissue in the prostate. We also present algorithms for in-depth analysis of LSTM networks. Our in vivo study includes data from 255 prostate biopsy cores of 157 patients. We achieve area under the curve, sensitivity, specificity, and accuracy of 0.96, 0.76, 0.98, and 0.93, respectively. Our result suggests that temporal modeling of TeUS using RNN can significantly improve cancer detection accuracy over previously presented works.","","","10.1109/TMI.2018.2849959","Natural Sciences and Engineering Research Council of Canada; Philips; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8395313","Temporal enhanced ultrasound;deep learning;recurrent neural network;long short-term memory;prostate cancer;cancer detection","Ultrasonic imaging;Biopsy;Logic gates;Recurrent neural networks;Principal component analysis;Prostate cancer","biological organs;biological tissues;biomedical ultrasonics;cancer;medical image processing;recurrent neural nets","deep recurrent neural networks;prostate cancer detection;temporal enhanced ultrasound;TeUS;backscattered signals;ultrasound frames;tissue characterization;temporal information;RNN models;benign tissue;in-depth analysis;LSTM networks;temporal modeling;cancer detection accuracy;long short-term memory networks;prostate biopsy cores;in vivo study","","1","49","","","","","IEEE","IEEE Journals"
"Personnel Recognition and Gait Classification Based on Multistatic Micro-Doppler Signatures Using Deep Convolutional Neural Networks","Z. Chen; G. Li; F. Fioranelli; H. Griffiths","Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; School of Engineering, University of Glasgow, Glasgow, U.K.; Department of Electronic and Electrical Engineering, University College London, London, U.K.","IEEE Geoscience and Remote Sensing Letters","","2018","15","5","669","673","In this letter, we propose two methods for personnel recognition and gait classification using deep convolutional neural networks (DCNNs) based on multistatic radar micro-Doppler signatures. Previous DCNN-based schemes have mainly focused on monostatic scenarios, whereas directional diversity offered by multistatic radar is exploited in this letter to improve classification accuracy. We first propose the voted monostatic DCNN (VMo-DCNN) method, which trains DCNNs on each receiver node separately and fuses the results by binary voting. By merging the fusion step into the network architecture, we further propose the multistatic DCNN (Mul-DCNN) method, which performs slightly better than VMo-DCNN. These methods are validated on real data measured with a 2.4-GHz multistatic radar system. Experimental results show that the Mul-DCNN achieves over 99% accuracy in armed/unarmed gait classification using only 20% training data and similar performance in two-class personnel recognition using 50% training data, which are higher than the accuracy obtained by performing DCNN on a single radar node.","","","10.1109/LGRS.2018.2806940","National Natural Science Foundation of China; Shenzhen Fundamental Research Program; Royal Society Newton Advanced Fellowship; IET A. F. Harvey Prize; Engineering and Physical Sciences Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8307105","Convolutional neural networks;data fusion;deep learning;micro-Doppler;multistatic radar;target classification","Spectrogram;Personnel;Multistatic radar;Task analysis;Doppler effect;Receivers","Doppler radar;feedforward neural nets;gait analysis;radar signal processing;radar target recognition;signal classification","multistatic microDoppler signatures;deep convolutional neural networks;multistatic radar microDoppler signatures;voted monostatic DCNN;binary voting;network architecture;multistatic DCNN method;VMo-DCNN;armed/unarmed gait classification;two-class personnel recognition;single radar node;Mul-DCNN;multistatic radar system","","16","29","","","","","IEEE","IEEE Journals"
"Mobile Stride Length Estimation With Deep Convolutional Neural Networks","J. Hannink; T. Kautz; C. F. Pasluosta; J. Barth; S. Schülein; K. Gaßmann; J. Klucken; B. M. Eskofier","Digital Sports Group, Department of Computer Science, University of Erlangen-Nürnberg (FAU), Erlangen, Germany; Digital Sports Group, Department of Computer Science, University of Erlangen-Nürnberg (FAU), Erlangen, Germany; Digital Sports Group, Department of Computer Science, University of Erlangen-Nürnberg (FAU), Erlangen, Germany; Digital Sports Group, Department of Computer Science, University of Erlangen-Nürnberg (FAU), Erlangen, Germany; Geriatrics Centre Erlangen, Waldkrankenhaus St. Marien, Erlangen, Germany; Geriatrics Centre Erlangen, Waldkrankenhaus St. Marien, Erlangen, Germany; Department of Molecular Neurology, University Hospital Erlangen, University of Erlangen-Nürnberg (FAU), Erlangen, Germany; Digital Sports Group, Department of Computer Science, University of Erlangen-Nürnberg (FAU), Erlangen, Germany","IEEE Journal of Biomedical and Health Informatics","","2018","22","2","354","362","Objective: Accurate estimation of spatial gait characteristics is critical to assess motor impairments resulting from neurological or musculoskeletal disease. Currently, however, methodological constraints limit clinical applicability of state-of-the-art double integration approaches to gait patterns with a clear zero-velocity phase. Methods: We describe a novel approach to stride length estimation that uses deep convolutional neural networks to map stride-specific inertial sensor data to the resulting stride length. The model is trained on a publicly available and clinically relevant benchmark dataset consisting of 1220 strides from 101 geriatric patients. Evaluation is done in a tenfold cross validation and for three different stride definitions. Results: Even though best results are achieved with strides defined from midstance to midstance with average accuracy and precision of 0.01 ± 5.37 cm, performance does not strongly depend on stride definition. The achieved precision outperforms state-of-the-art methods evaluated on the same benchmark dataset by 3.0 cm (36%). Conclusion: Due to the independence of stride definition, the proposed method is not subject to the methodological constrains that limit applicability of state-of-the-art double integration methods. Furthermore, it was possible to improve precision on the benchmark dataset. Significance: With more precise mobile stride length estimation, new insights to the progression of neurological disease or early indications might be gained. Due to the independence of stride definition, previously uncharted diseases in terms of mobile gait analysis can now be investigated by retraining and applying the proposed method.","","","10.1109/JBHI.2017.2679486","University of Erlangen-Nürnberg (FAU); Emerging Fields Initiative (EFIMoves); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7875162","Deep learning;convolutional neural networks;mobile gait analysis;stride length;regression","Estimation;Mobile communication;Diseases;Biological system modeling;Senior citizens;Mathematical model;Magnetic domains","diseases;feedforward neural nets;gait analysis;geriatrics;medical diagnostic computing;neurophysiology;patient rehabilitation;sensors","deep convolutional neural networks;Accurate estimation;spatial gait characteristics;neurological disease;musculoskeletal disease;clinical applicability;double integration approaches;zero-velocity phase;publicly available benchmark dataset;clinically relevant benchmark dataset;stride definition;double integration methods;precise mobile stride length estimation;mobile gait analysis;stride-specific inertial sensor data","","7","43","","","","","IEEE","IEEE Journals"
"Toward Ultralightweight Remote Sensing With Harmonic Lenses and Convolutional Neural Networks","A. V. Nikonorov; M. V. Petrov; S. A. Bibikov; P. Y. Yakimov; V. V. Kutikova; Y. V. Yuzifovich; A. A. Morozov; R. V. Skidanov; N. L. Kazanskiy","Samara National Research University, Samara, Russia; Samara National Research University, Samara, Russia; Samara National Research University, Samara, Russia; Samara National Research University, Samara, Russia; Samara National Research University, Samara, Russia; Samara National Research University, Samara, Russia; Image Processing Systems Institute - Branch of the Federal Scientific Research Centre “Crystallography and Photonics” of Russian Academy of Sciences, Samara, Russia; Image Processing Systems Institute - Branch of the Federal Scientific Research Centre “Crystallography and Photonics” of Russian Academy of Sciences, Samara, Russia; Image Processing Systems Institute - Branch of the Federal Scientific Research Centre “Crystallography and Photonics” of Russian Academy of Sciences, Samara, Russia","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2018","11","9","3338","3348","In this paper, we describe our advances in manufacturing a 256-layer 7-μm thick harmonic lens with 150 and 300 mm focal distances combined with color correction, deconvolution, and a feedforwarding deep learning neural network capable of producing images approaching photographic visual quality. While reconstruction of images taken with diffractive optics was presented in previous works, this paper is the first to use deep neural networks during the restoration step. The level of imaging quality we achieved with our imaging system can facilitate the emergence of ultralightweight remote sensing cameras for nano- and pico-satellites, and for aerial remote sensing systems onboard small UAVs and solar-powered airplanes.","","","10.1109/JSTARS.2018.2856538","Advanced Research Foundation; Presidential Grant of Russian Federatio; Russian Foundation for Basic Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8424456","Color correction;deconvolution;deep learning;harmonic lens;point spread function (PSF) estimation;remote sensing","Lenses;Harmonic analysis;Optical diffraction;Optical imaging;Remote sensing;Image color analysis","autonomous aerial vehicles;cameras;deconvolution;feedforward neural nets;geophysical image processing;image sensors;lenses;optical images;remote sensing","feedforward deep learning neural network;ultralightweight remote sensing;UAV;solar-powered airplanes;aerial remote sensing systems;ultralightweight remote sensing cameras;imaging system;deep neural networks;diffractive optics;photographic visual quality;deconvolution;color correction;convolutional neural networks;harmonic lens","","","39","","","","","IEEE","IEEE Journals"
"Speech Quality Assessment Over Lossy Transmission Channels Using Deep Belief Networks","E. T. Affonso; R. L. Rosa; D. Z. Rodríguez","Universidade Federal de Lavras, Lavras, MG, Brazil; Universidade Federal de Lavras, Lavras, MG, Brazil; Universidade Federal de Lavras, Lavras, MG, Brazil","IEEE Signal Processing Letters","","2018","25","1","70","74","Nowadays, there are several telephone services based on IP networks. However, the networks can present many disturbances, such as packet loss rate (PLR), which is one of the most impairing network factors. An impaired speech communication affects the users' quality of experience; hence, the assessment of speech quality is relevant to the telephone operators. Therefore, the determination of a methodology to predict a speech quality with a higher accuracy in telephone services is relevant. In this context, this letter introduces a novel nonintrusive speech quality classifier (SQC) model based on deep belief networks (DBN), in which the support vector machine with radial basis function kernel is the classifier applied in DBN, in order to identify four speech quality classes. A speech database was built, based on unimpaired speech files of public databases, in which different PLR models and values are applied, and a standardized intrusive method is used to calculate the index quality of each file. Results show that SQC largely overcomes the results obtained by ITU-T Recommendation P.563. Also, subjective tests are performed to validate the SQC performance, and it reached an accuracy of 95% on speech quality classification. Furthermore, a solution architecture is introduced, demonstrating the usefulness and flexibility of the proposed SQC.","","","10.1109/LSP.2017.2773536","Fundação de Amparo à Pesquisa do Estado de São Paulo; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8107591","Deep belief networks (DBN);machine learning;packet loss rate (PLR);speech quality assessment","Speech;Packet loss;Speech recognition;Quality assessment;Hidden Markov models;Indexes","belief networks;feature extraction;IP networks;radial basis function networks;speech coding;speech processing;speech recognition;support vector machines","packet loss rate;impaired speech communication;telephone operators;telephone services;nonintrusive speech quality classifier model;SQC;deep belief networks;DBN;speech quality classes;speech database;unimpaired speech files;index quality;speech quality classification;speech quality assessment;lossy transmission channels;IP networks;user quality of experience;support vector machine;radial basis function kernel;public databases;PLR model;standardized intrusive method;P.563 ITU-T recommendation","","11","46","Traditional","","","","IEEE","IEEE Journals"
"Finding the key","","","Electronics Letters","","2018","54","19","1099","1099","","","","10.1049/el.2018.6772","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8464104","","","public key cryptography;learning (artificial intelligence)","deep learning-assisted side channel attacks;cryptographic circuit secret keys;DL-SCA method;DL-assisted attack method;AES cryptographic circuit;advanced encryption standard","","","","","","","","IET","IET Journals"
"Symmetrical Dense-Shortcut Deep Fully Convolutional Networks for Semantic Segmentation of Very-High-Resolution Remote Sensing Images","G. Chen; X. Zhang; Q. Wang; F. Dai; Y. Gong; K. Zhu","State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2018","11","5","1633","1644","Semantic segmentation has emerged as a mainstream method in very-high-resolution remote sensing land-use/land-cover applications. In this paper, we first review the state-of-the-art semantic segmentation models in both computer vision and remote sensing fields. Subsequently, we introduce two semantic segmentation frameworks: SNFCN and SDFCN, both of which contain deep fully convolutional networks with shortcut blocks. We adopt an overlay strategy as the postprocessing method. Based on our frameworks, we conducted experiments on two online ISPRS datasets: Vaihingen and Potsdam. The results indicate that our frameworks achieve higher overall accuracy than the classic FCN-8s and SegNet models. In addition, our postprocessing method can increase the overall accuracy by about 1%-2% and help to eliminate “salt and pepper” phenomena and block effects.","","","10.1109/JSTARS.2018.2810320","LIESMARS Special Research; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8326706","Convolutional neural networks (CNN);deep learning (DL);fully convolutional networks (FCN);remote sensing;SDFCN;semantic segmentation","Image segmentation;Semantics;Remote sensing;Feature extraction;Decoding;Labeling;Training","computer vision;convolution;feedforward neural nets;geophysical image processing;image resolution;image segmentation;land cover;land use;remote sensing","mainstream method;very-high-resolution remote sensing land-use/land-cover applications;semantic segmentation models;computer vision;remote sensing fields;semantic segmentation frameworks;shortcut blocks;postprocessing method;symmetrical dense-shortcut deep fully convolutional networks","","6","63","","","","","IEEE","IEEE Journals"
"Motion Switching With Sensory and Instruction Signals by Designing Dynamical Systems Using Deep Neural Network","K. Suzuki; H. Mori; T. Ogata","Artificial Intelligence Laboratories, Fujitsu Laboratories Ltd., Kanagawa, Japan; Department of Intermedia Art and Science, School of Fundamental Science and Engineering, Waseda University, Tokyo, Japan; Department of Intermedia Art and Science, School of Fundamental Science and Engineering, Waseda University, Tokyo, Japan","IEEE Robotics and Automation Letters","","2018","3","4","3481","3488","To ensure that a robot is able to accomplish an extensive range of tasks, it is necessary to achieve a flexible combination of multiple behaviors. This is because the design of task motions suited to each situation would become increasingly difficult as the number of situations and the types of tasks performed by them increase. To handle the switching and combination of multiple behaviors, we propose a method to design dynamical systems based on point attractors that accept (i) “instruction signals” for instruction-driven switching. We incorporate the (ii) “instruction phase” to form a point attractor and divide the target task into multiple subtasks. By forming an instruction phase that consists of point attractors, the model embeds a subtask in the form of trajectory dynamics that can be manipulated using sensory and instruction signals. Our model comprises two deep neural networks: A convolutional autoencoder and a multiple time-scale recurrent neural network. In this study, we apply the proposed method to manipulate soft materials. To evaluate our model, we design a cloth-folding task that consists of four subtasks and three patterns of instruction signals, which indicate the direction of motion. The results depict that the robot can perform the required task by combining subtasks based on sensory and instruction signals. And, our model determined the relations among these signals using its internal dynamics.","","","10.1109/LRA.2018.2853651","AIST; MEXT; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8405582","Deep learning in robotics and automation;AI-based methods;humanoid robots","Task analysis;Robot sensing systems;Switches;Dynamics;Feature extraction;Switching systems","control engineering computing;feedforward neural nets;humanoid robots;manipulators;recurrent neural nets","instruction signals;deep neural network;task motions;point attractor;instruction phase;target task;multiple subtasks;multiple time-scale recurrent neural network;cloth-folding task;dynamical systems;instruction-driven switching;motion switching;trajectory dynamics;sensory signals;convolutional autoencoder;soft materials","","","20","","","","","IEEE","IEEE Journals"
"Rotation-Insensitive and Context-Augmented Object Detection in Remote Sensing Images","K. Li; G. Cheng; S. Bu; X. You","Zhengzhou Institute of Surveying and Mapping, Zhengzhou, China; School of Automation, Northwestern Polytechnical University, Xi’an, China; School of Automation, Northwestern Polytechnical University, Xi’an, China; Zhengzhou Institute of Surveying and Mapping, Zhengzhou, China","IEEE Transactions on Geoscience and Remote Sensing","","2018","56","4","2337","2348","Most of the existing deep-learning-based methods are difficult to effectively deal with the challenges faced for geospatial object detection such as rotation variations and appearance ambiguity. To address these problems, this paper proposes a novel deep-learning-based object detection framework including region proposal network (RPN) and local-contextual feature fusion network designed for remote sensing images. Specifically, the RPN includes additional multiangle anchors besides the conventional multiscale and multiaspect-ratio ones, and thus can deal with the multiangle and multiscale characteristics of geospatial objects. To address the appearance ambiguity problem, we propose a double-channel feature fusion network that can learn local and contextual properties along two independent pathways. The two kinds of features are later combined in the final layers of processing in order to form a powerful joint representation. Comprehensive evaluations on a publicly available ten-class object detection data set demonstrate the effectiveness of the proposed method.","","","10.1109/TGRS.2017.2778300","National Natural Science Foundation of China; Project of Science and Technology Innovation of Henan Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8240988","Convolutional neural networks (CNNs);object detection;remote sensing images;restricted Boltzmann machine (RBM)","Object detection;Proposals;Feature extraction;Remote sensing;Geospatial analysis;Context modeling;Satellites","geophysical image processing;image fusion;image representation;learning (artificial intelligence);object detection;remote sensing","local properties;contextual properties;ten-class object detection data;context-augmented object detection;remote sensing images;geospatial object detection;rotation variations;RPN;local-contextual feature fusion network;multiangle characteristics;multiscale characteristics;appearance ambiguity problem;double-channel feature fusion network;deep-learning-based methods;multiangle anchors;rotation-insensitive object detection;conventional multiscale multiaspect-ratio;joint representation;deep-learning-based object detection framework","","31","57","","","","","IEEE","IEEE Journals"
"Supervised Committee of Convolutional Neural Networks in Automated Facial Expression Analysis","G. Pons; D. Masip","Department of Computer Science, Universitat Oberta de Catalunya, Barcelona, Spain; Department of Computer Science, Universitat Oberta de Catalunya, Barcelona, Spain","IEEE Transactions on Affective Computing","","2018","9","3","343","350","Automated emotion recognition from facial images is an unsolved problem in computer vision. Although recent methods achieve close to human accuracy in controlled scenarios, the recognition of emotions in the wild remains a challenging problem. Recent advances in Deep learning have supposed a significant breakthrough in many computer vision tasks, including facial expression analysis. Particularly, the use of Deep Convolutional Neural Networks has attained the best results in the recent public challenges. The current state-of-the-art algorithms suggest that the use of ensembles of CNNs can outperform individual CNN classifiers. Two key considerations influence these results: (i) The design of CNNs involves the adjustment of parameters that allow diversity and complementarity in the partial classification results, and (ii) the final classification rule that assembles the result of the committee. In this paper we propose to improve the assembling of the committee by introducing supervised learning on the ensemble computation. We train a CNN on the posterior-class probabilities resulting from the individual members allowing to capture non-linear dependencies among committee members, and to learn this combination from data. The validation shows an accuracy 5 percent higher with respect to previous state-of-the art results based on averaging classifiers, and 4 percent to the majority voting rule.","","","10.1109/TAFFC.2017.2753235","Spanish Ministry of Economy and Competitiveness; NVIDIA Hardware; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8039231","Facial emotion recognition;hierarchical committee;convolutional neural networks","Emotion recognition;Training;Databases;Computer architecture;Computer vision","computer vision;convolution;emotion recognition;face recognition;feedforward neural nets;image classification;learning (artificial intelligence);probability","supervised committee;automated facial expression analysis;automated emotion recognition;facial images;assembling;supervised learning;ensemble computation;deep learning;computer vision;deep convolutional neural networks;CNN classifiers;probability results","","3","46","","","","","IEEE","IEEE Journals"
"Semantic SLAM Based on Object Detection and Improved Octomap","L. Zhang; L. Wei; P. Shen; W. Wei; G. Zhu; J. Song","School of Computer Science and Technology, Xidian University, Xi’an, China; School of Computer Science and Technology, Xidian University, Xi’an, China; School of Computer Science and Technology, Xidian University, Xi’an, China; Shaanxi Key Laboratory for Network Computing and Security Technology, School of Computer Science and Engineering, Xi'an University of Technology, Xi’an, China; School of Computer Science and Technology, Xidian University, Xi’an, China; School of Computer Science and Technology, Xidian University, Xi’an, China","IEEE Access","","2018","6","","75545","75559","Due to the development of the computer vision, machine learning, and deep learning technologies, the research community focuses not only on the traditional SLAM problems, such as geometric mapping and localization, but also on semantic SLAM. In this paper, we propose a Semantic SLAM system which builds the semantic maps with object-level entities, and it is integrated into the RGB-D SLAM framework. The system combines object detection module that is realized by the deep-learning method, and localization module with RGB-D SLAM seamlessly. In the proposed system, object detection module is used to perform object detection and recognition, and localization module is utilized to get the exact location of the camera. The two modules are integrated together to obtain the semantic maps of the environment. Furthermore, to improve the computational efficiency of the framework, an improved Octomap based on the Fast Line Rasterization Algorithm is constructed. Meanwhile, for the sake of accuracy and robustness of the semantic map, conditional random field is employed to do the optimization. Finally, we evaluate our Semantic SLAM through three different tasks, i.e., localization, object detection, and mapping. Specifically, the accuracy of localization and the mapping speed is evaluated on TUM data set. Compared with ORB-SLAM2 and original RGB-D SLAM, our system, respectively, got 72.9% and 91.2% improvements in dynamic environments localization evaluated by root-mean-square error. With the improved Octomap, the proposed Semantic SLAM is 66.5% faster than the original RGB-D SLAM. We also demonstrate the efficiency of object detection through quantitative evaluation in an automated inventory management task on a real-world data sets recorded over a realistic office.","","","10.1109/ACCESS.2018.2873617","Key Research and Development Program of Shaanxi Province; Scientific Research Program Funded by the Shaanxi Provincial Education Department; Specialized Research Fund for the Doctoral Program of Higher Education of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8482266","CRF;Octomap;semantic messages;SLAM","Semantics;Simultaneous localization and mapping;Three-dimensional displays;Object detection;Cameras;Feature extraction","feature extraction;image colour analysis;learning (artificial intelligence);mean square error methods;mobile robots;neural nets;object detection;robot vision;SLAM (robots)","root-mean-square error;computer vision;fast line rasterization algorithm;semantic SLAM system;Octomap;deep learning technologies;semantic map;localization module;deep-learning method;object detection module;RGB-D SLAM framework;object-level entities","","4","55","","","","","IEEE","IEEE Journals"
"Tensor-factorized neural networks","J. Chien; Y. Bao","Department of Electrical and Computer Engineering, National Chiao Tung University, Hsinchu, Taiwan; Department of Electrical and Computer Engineering, National Chiao Tung University, Hsinchu, Taiwan","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","5","1998","2011","The growing interests in multiway data analysis and deep learning have drawn tensor factorization (TF) and neural network (NN) as the crucial topics. Conventionally, the NN model is estimated from a set of one-way observations. Such a vectorized NN is not generalized for learning the representation from multiway observations. The classification performance using vectorized NN is constrained, because the temporal or spatial information in neighboring ways is disregarded. More parameters are required to learn the complicated data structure. This paper presents a new tensor-factorized NN (TFNN), which tightly integrates TF and NN for multiway feature extraction and classification under a unified discriminative objective. This TFNN is seen as a generalized NN, where the affine transformation in an NN is replaced by the multilinear and multiway factorization for tensor-based NN. The multiway information is preserved through layerwise factorization. Tucker decomposition and nonlinear activation are performed in each hidden layer. The tensor-factorized error backpropagation is developed to train TFNN with the limited parameter size and computation time. This TFNN can be further extended to realize the convolutional TFNN (CTFNN) by looking at small subtensors through the factorized convolution. Experiments on real-world classification tasks demonstrate that TFNN and CTFNN attain substantial improvement when compared with an NN and a convolutional NN, respectively.","","","10.1109/TNNLS.2017.2690379","Ministry of Science and Technology, Taiwan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7902201","Neural network (NN);pattern classification;tensor factorization (TF);tensor-factorized error backpropagation","Tensile stress;Artificial neural networks;Feature extraction;Backpropagation;Convolution;Training;Speech","affine transforms;data analysis;data structures;feature extraction;learning (artificial intelligence);matrix decomposition;neural nets;pattern classification;tensors","vectorized NN;multiway observations;multiway feature extraction;multilinear factorization;multiway factorization;multiway information;layerwise factorization;multiway data analysis;deep learning;tensor-factorized neural networks;one-way observations;spatial information;temporal information;neighboring ways;unified discriminative objective;affine transformation;tucker decomposition;nonlinear activation;tensor-factorized error backpropagation;convolutional TFNN;CTFNN;complicated data structure","","4","39","","","","","IEEE","IEEE Journals"
"Learning Reasoning-Decision Networks for Robust Face Alignment","H. Liu; J. Lu; M. Guo; S. Wu; J. Zhou","Information Engineering, Ningxia University, Yinchuan, Ningxia China 750021 (e-mail: liuhao@nxu.edu.cn); Department of Automation, Tsinghua University, Beijing, Beijing China 100084 (e-mail: lujiwen@tsinghua.edu.cn); Department of Automation, Tsinghua University, 12442 Beijing, Beijing China (e-mail: gmh14@mails.tsinghua.edu.cn); School of Information Engineering, Ningxia University, 56693 Yinchuan, Ningxia China (e-mail: pswuu@nxu.edu.cn); Department of Automation, Tsinghua University, Beijing, Beijing China 100084 (e-mail: jzhou@tsinghua.edu.cn)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","PP","99","1","1","In this paper, we propose an end-to-end reasoning-decision networks (RDN) approach for robust face alignment via policy gradient. Unlike the conventional coarse-to-fine approaches which likely lead to bias prediction due to poor initialization, our approach aims to learn a policy by leveraging raw pixels to reason a subset of shape candidates, sequentially making plausible decisions to remove outliers for robust initialization. To achieve this, we formulate face alignment as a Markov decision process by defining an agent, which typically interacts with a trajectory of states, actions, state transitions and rewards. The agent seeks an optimal shape searching policy over the whole shape space by maximizing a discounted sum of the received values. To further improve the alignment performance, we develop an LSTM-based value function to evaluate the shape quality. During the training procedure, we adjust the gradient of our value function in directions of the policy gradient. This prevents our training goal from being trapped into local optima entangled by both the pose deformations and appearance variations especially in unconstrained environments. Experimental results show that our proposed RDN consistently outperforms most state-of-the-art approaches on four widely-evaluated challenging datasets.","","","10.1109/TPAMI.2018.2885298","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8570839","Face alignment;deep neural networks;deep reinforcement learning;policy gradient","Shape;Face;Training;Neural networks;Two dimensional displays;Computer architecture","","","","4","","","","","","IEEE","IEEE Early Access Articles"
"The Extreme Value Machine","E. M. Rudd; L. P. Jain; W. J. Scheirer; T. E. Boult","Department of Computer Science, University of Colorado Colorado Springs, Colorado Springs, CO, 80918; Department of Computer Science, University of Colorado Colorado Springs, Colorado Springs, CO, 80918; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN; Department of Computer Science, University of Colorado Colorado Springs, Colorado Springs, CO, 80918","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","3","762","768","It is often desirable to be able to recognize when inputs to a recognition function learned in a supervised manner correspond to classes unseen at training time. With this ability, new class labels could be assigned to these inputs by a human operator, allowing them to be incorporated into the recognition function-ideally under an efficient incremental update mechanism. While good algorithms that assume inputs from a fixed set of classes exist, e.g., artificial neural networks and kernel machines, it is not immediately obvious how to extend them to perform incremental learning in the presence of unknown query classes. Existing algorithms take little to no distributional information into account when learning recognition functions and lack a strong theoretical foundation. We address this gap by formulating a novel, theoretically sound classifier-the Extreme Value Machine (EVM). The EVM has a well-grounded interpretation derived from statistical Extreme Value Theory (EVT), and is the first classifier to be able to perform nonlinear kernel-free variable bandwidth incremental learning. Compared to other classifiers in the same deep network derived feature space, the EVM is accurate and efficient on an established benchmark partition of the ImageNet dataset.","","","10.1109/TPAMI.2017.2707495","US National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7932895","Machine learning;supervised classification;open set recognition;open world recognition;statistical extreme value theory","Training;Kernel;Bandwidth;Visualization;Pattern recognition;Calibration;Extraterrestrial measurements","learning (artificial intelligence);neural nets;pattern classification","extreme value machine;artificial neural networks;kernel machines;unknown query classes;EVM;statistical Extreme Value Theory;classifier;nonlinear kernel-free variable bandwidth incremental learning;deep network derived feature space;recognition function;recognition function learning;incremental update mechanism","","5","49","","","","","IEEE","IEEE Journals"
"Combining Convolutional Neural Network With Recursive Neural Network for Blood Cell Image Classification","G. Liang; H. Hong; W. Xie; L. Zheng","Fujian Provincial Academic Engineering Research Centre in Industrial Intellectual Techniques and Systems, College of Engineering, Huaqiao University, Quanzhou, China; Fujian Provincial Academic Engineering Research Centre in Industrial Intellectual Techniques and Systems, College of Engineering, Huaqiao University, Quanzhou, China; Fujian Provincial Academic Engineering Research Centre in Industrial Intellectual Techniques and Systems, College of Engineering, Huaqiao University, Quanzhou, China; Fujian Provincial Academic Engineering Research Centre in Industrial Intellectual Techniques and Systems, College of Engineering, Huaqiao University, Quanzhou, China","IEEE Access","","2018","6","","36188","36197","The diagnosis of blood-related diseases involves the identification and characterization of a patient's blood sample. As such, automated methods for detecting and classifying the types of blood cells have important medical applications in this field. Although deep convolutional neural network (CNN) and the traditional machine learning methods have shown good results in the classification of blood cell images, they are unable to fully exploit the long-term dependence relationship between certain key features of images and image labels. To resolve this problem, we have introduced the recurrent neural networks (RNNs). Specifically, we combined the CNN and RNN in order to propose the CNN-RNN framework that can deepen the understanding of image content and learn the structured features of images and to begin endto-end training of big data in medical image analysis. In particular, we apply the transfer learning method to transfer the weight parameters that were pre-trained on the ImageNet dataset to the CNN section and adopted a custom loss function to allow our network to train and converge faster and with more accurate weight parameters. Experimental results show that compared with the other CNN models such as ResNet and Inception V3, our proposed network model is more accurate and efficient in classifying blood cell images.","","","10.1109/ACCESS.2018.2846685","Xiamen Municipal Bureau of Science and Technology; Technology Bureau of Quanzhou; Huaqiao University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8402091","Artificial intelligence;convolutional neural network;recurrent neural network;transfer learning","Classification algorithms;Feature extraction;Convolutional neural networks;Support vector machines;White blood cells;Image classification","blood;diseases;image classification;learning (artificial intelligence);medical image processing;recurrent neural nets","important medical applications;deep convolutional neural network;traditional machine learning methods;blood cell images;long-term dependence relationship;image labels;recurrent neural networks;CNN-RNN framework;image content;medical image analysis;transfer learning method;CNN models;network model;recursive neural network;blood cell image classification;blood-related diseases","","9","43","","","","","IEEE","IEEE Journals"
"Generalized Multi-View Embedding for Visual Recognition and Cross-Modal Retrieval","G. Cao; A. Iosifidis; K. Chen; M. Gabbouj","Laboratory of Signal Processing, Tampere University of Technology, Tampere, Finland; Laboratory of Signal Processing, Tampere University of Technology, Tampere, Finland; Laboratory of Signal Processing, Tampere University of Technology, Tampere, Finland; Laboratory of Signal Processing, Tampere University of Technology, Tampere, Finland","IEEE Transactions on Cybernetics","","2018","48","9","2542","2555","In this paper, the problem of multi-view embedding from different visual cues and modalities is considered. We propose a unified solution for subspace learning methods using the Rayleigh quotient, which is extensible for multiple views, supervised learning, and nonlinear embeddings. Numerous methods including canonical correlation analysis, partial least square regression, and linear discriminant analysis are studied using specific intrinsic and penalty graphs within the same framework. Nonlinear extensions based on kernels and (deep) neural networks are derived, achieving better performance than the linear ones. Moreover, a novel multi-view modular discriminant analysis is proposed by taking the view difference into consideration. We demonstrate the effectiveness of the proposed multi-view embedding methods on visual object recognition and cross-modal image retrieval, and obtain superior results in both applications compared to related methods.","","","10.1109/TCYB.2017.2742705","National Science Foundation; Academy of Finland; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8026149","Cross-modal retrieval;multi-view discriminant embedding;multi-view subspace learning;visual recognition","Kernel;Visualization;Neural networks;Correlation;Covariance matrices;Image retrieval;Learning systems","feature extraction;graph theory;image recognition;image retrieval;learning (artificial intelligence);least mean squares methods;neural nets;object recognition;regression analysis","visual recognition;cross-modal retrieval;subspace learning methods;Rayleigh quotient;supervised learning;nonlinear embeddings;canonical correlation analysis;partial least square regression;linear discriminant analysis;visual object recognition;generalized multiview embedding;multiview modular discriminant analysis;neural networks;kernels;penalty graphs","","11","60","","","","","IEEE","IEEE Journals"
"An Improved Splicing Localization Method by Fully Convolutional Networks","B. Chen; X. Qi; Y. Wang; Y. Zheng; H. J. Shim; Y. Shi","Jiangsu Engineering Center of Network Monitoring, School of Computer and Software, Nanjing University of Information Science and Technology, Nanjing, China; Jiangsu Engineering Center of Network Monitoring, School of Computer and Software, Nanjing University of Information Science and Technology, Nanjing, China; School of Atmospheric Physics, Nanjing University of Information Science and Technology, Nanjing, China; Jiangsu Engineering Center of Network Monitoring, School of Computer and Software, Nanjing University of Information Science and Technology, Nanjing, China; Jiangsu Engineering Center of Network Monitoring, School of Computer and Software, Nanjing University of Information Science and Technology, Nanjing, China; Jiangsu Engineering Center of Network Monitoring, School of Computer and Software, Nanjing University of Information Science and Technology, Nanjing, China","IEEE Access","","2018","6","","69472","69480","Liu and Pun proposed a method based on fully convolutional network (FCN) and conditional random field (CRF) to locate spliced regions in synthesized images from different source images. However, their work has two drawbacks: 1) FCN often smooths detailed structures and ignores small objects and 2) CRF is employed as a standalone post-processing step disconnected from the FCN. Therefore, an improved method is proposed in this paper to overcome these two drawbacks. For the first drawback, region proposal network is introduced into the FCN to enhance the learning of object regions. For the second one, the use of CRF is changed to make the whole network an end-to-end learning system. Moreover, the proposed method uses three FCNs (FCN8, FCN16, and FCN32) with different upsampling layers, and all the three FCNs are initialized from VGG-16 network. Experimental results on three publicly available datasets (DVMM dataset, CASIA v1.0 dataset, and CASIA v2.0 dataset) demonstrate that the proposed method can achieve a better performance than the state-of-the-art methods including some conventional methods and some deep learning-based methods.","","","10.1109/ACCESS.2018.2880433","National Natural Science Foundation of China; PAPD Fund; Qing Lan Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8531703","Splicing localization;fully convolutional network;region proposal network;conditional random field","Splicing;Proposals;Learning systems;Feature extraction;Convolution;Kernel;Information science","feature extraction;image classification;image texture;learning (artificial intelligence)","CASIA v2.0 dataset;CASIA v1.0 dataset;DVMM dataset;FCN32;source images;splicing localization method;region proposal network;standalone post-processing step;synthesized images;spliced regions;conditional random field;fully convolutional network;deep learning-based methods;state-of-the-art methods;VGG-16 network;FCN16;FCN8;end-to-end learning system","","","35","","","","","IEEE","IEEE Journals"
"Deep Neural Network Compression by In-Parallel Pruning-Quantization","F. Tung; G. Mori","Computing Science, Simon Fraser University, 1763 Burnaby, British Columbia Canada (e-mail: ftung@sfu.ca); Computing Science, Simon Fraser University, Burnaby, British Columbia Canada V5A 1S6 (e-mail: mori@cs.sfu.ca)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","PP","99","1","1","Deep neural networks enable state-of-the-art accuracy on visual recognition tasks such as image classification and object detection. However, modern networks contain millions of learned connections, and the current trend is towards deeper and more densely connected architectures. This poses a challenge to the deployment of state-of-the-art networks on resource-constrained systems, such as smartphones or mobile robots. In general, a more efficient utilization of computation resources would assist in deployment scenarios from embedded platforms to computing clusters running ensembles of networks. In this paper, we propose a deep network compression algorithm that performs weight pruning and quantization jointly, and in parallel with fine-tuning. Our approach takes advantage of the complementary nature of pruning and quantization and recovers from premature pruning errors, which is not possible with two-stage approaches. In experiments on ImageNet, CLIP-Q (Compression Learning by In-Parallel Pruning-Quantization) improves the state-of-the-art in network compression on AlexNet, VGGNet, GoogLeNet, and ResNet. We additionally demonstrate that CLIP-Q is complementary to efficient network architecture design by compressing MobileNet and ShuffleNet, and that CLIP-Q generalizes beyond convolutional networks by compressing a memory network for visual question answering.","","","10.1109/TPAMI.2018.2886192","Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8573867","deep learning;neural network compression;weight pruning;weight quantization;Bayesian optimization","Quantization (signal);Image coding;Neural networks;Visualization;Training;Convolution;Network architecture","","","","2","","","","","","IEEE","IEEE Early Access Articles"
"Multi-Layer Perceptron Model on Chip for Secure Diabetic Treatment","H. Rathore; L. Wenzel; A. K. Al-Ali; A. Mohamed; X. Du; M. Guizani","Department of Computer Science and Engineering, Qatar University, Doha, Qatar; National Instruments, Austin, TX, USA; Department of Computer Science and Engineering, Qatar University, Doha, Qatar; Department of Computer Science and Engineering, Qatar University, Doha, Qatar; Department of Computer and Information Sciences, Temple University, Philadelphia, PA, USA; Department of Electrical and Computer Engineering, University of Idaho, Moscow, ID, USA","IEEE Access","","2018","6","","44718","44730","Diabetic patients use therapy from the insulin pump, a type of implantable medical device, for the infusion of insulin to control blood glucose level. While these devices offer many clinical benefits, there has been a recent increase in the number of cases, wherein, the wireless communication channel of such devices has been compromised. This not only causes the device to malfunction but also potentially threatens the patient's life. In this paper, a neural networks-based multi-layer perceptron model was designed for real-time medical device security. Machine learning algorithms are among the most effective and broadly utilized systems for classification, identification, and segmentation. Although they are effective, they are both computationally and memory intensive, making them hard to be deployed on low-power embedded frameworks. In this paper, we present an on-chip neural system network for securing diabetic treatment. The model achieved 98.1% accuracy in classifying fake versus genuine glucose measurements. The proposed model was comparatively evaluated with a linear support vector machine which achieved only 90.17% accuracy with negligible precision and recall. Moreover, the proposal estimates the reliability of the framework through the use of the Bayesian network. The proposed approach enhances the reliability of the overall framework by 18% when only one device is secured, and over 90% when all devices are secured.","","","10.1109/ACCESS.2018.2854822","Qatar National Research Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409455","Security;machine learning;insulin pumps;deep learning;implantable medical devices","Sugar;Insulin pumps;Security;Wireless communication;Blood;Communication system security;Field programmable gate arrays","belief networks;blood;diseases;learning (artificial intelligence);medical computing;multilayer perceptrons;neural chips;patient monitoring;patient treatment;pattern classification;security of data;support vector machines","reliability estimation;genuine glucose measurements;blood glucose level control;Bayesian network;linear support vector machine;on-chip neural system network;low-power embedded frameworks;machine learning algorithms;real-time medical device security;neural networks-based multilayer perceptron model;wireless communication channel;implantable medical device;insulin pump;diabetic patients;secure diabetic treatment","","3","31","","","","","IEEE","IEEE Journals"
"Constrained Convolutional Neural Networks: A New Approach Towards General Purpose Image Manipulation Detection","B. Bayar; M. C. Stamm","Department of Electrical and Computer Engineering, Drexel University, Philadelphia, PA, USA; Department of Electrical and Computer Engineering, Drexel University, Philadelphia, PA, USA","IEEE Transactions on Information Forensics and Security","","2018","13","11","2691","2706","Identifying the authenticity and processing history of an image is an important task in multimedia forensics. By analyzing traces left by different image manipulations, researchers have been able to develop several algorithms capable of detecting targeted editing operations. While this approach has led to the development of several successful forensic algorithms, an important problem remains: creating forensic detectors for different image manipulations is a difficult and time consuming process. Furthermore, forensic analysts need general purpose forensic algorithms capable of detecting multiple different image manipulations. In this paper, we address both of these problems by proposing a new general purpose forensic approach using convolutional neural networks (CNNs). While CNNs are capable of learning classification features directly from data, in their existing form they tend to learn features representative of an image's content. To overcome this issue, we have developed a new type of CNN layer, called a constrained convolutional layer, that is able to jointly suppress an image's content and adaptively learn manipulation detection features. Through a series of experiments, we show that our proposed constrained CNN is able to learn manipulation detection features directly from data. Our experimental results demonstrate that our CNN can detect multiple different editing operations with up to 99.97% accuracy and outperform the existing state-of-the-art general purpose manipulation detector. Furthermore, our constrained CNN can still accurately detect image manipulations in realistic scenarios where there is a source camera model mismatch between the training and testing data.","","","10.1109/TIFS.2018.2825953","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8335799","Image forensics;deep learning;convolutional neural networks;deep convolutional features","Feature extraction;Forensics;Detectors;Computer architecture;Convolutional neural networks;Task analysis;Training","feature extraction;image classification;image forensics;learning (artificial intelligence);object detection;recurrent neural nets","convolutional neural networks;general purpose image manipulation detection;multimedia forensics;targeted editing operations;forensic detectors;forensic analysts;multiple different image manipulations;general purpose forensic approach;constrained convolutional layer;manipulation detection features;constrained CNN;multiple different editing operations","","17","48","","","","","IEEE","IEEE Journals"
"Person Re-Identification by Camera Correlation Aware Feature Augmentation","Y. Chen; X. Zhu; W. Zheng; J. Lai","School of Data and Computer Science, Sun Yat-Sen University, Guangzhou, China; School of Data and Computer Science, Sun Yat-Sen University, Guangzhou, China; School of Data and Computer Science, Sun Yat-Sen University, Guangzhou, China; School of Data and Computer Science, Sun Yat-Sen University, Guangzhou, China","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","2","392","408","The challenge of person re-identification (re-id) is to match individual images of the same person captured by different nonoverlapping camera views against significant and unknown cross-view feature distortion. While a large number of distance metric/ subspace learning models have been developed for re-id, the cross-view transformations they learned are view-generic and thus potentially less effective in quantifying the feature distortion inherent to each camera view. Learning view-specific feature transformations for re-id (i.e., view-specific re-id), an under-studied approach, becomes an alternative resort for this problem. In this work, we formulate a novel view-specific person re-identification framework from the feature augmentation point of view, called Camera coRrelation Aware Feature augmenTation (CRAFT). Specifically, CRAFT performs cross-view adaptation by automatically measuring camera correlation from cross-view visual data distribution and adaptively conducting feature augmentation to transform the original features into a new adaptive space. Through our augmentation framework, view-generic learning algorithms can be readily generalized to learn and optimize view-specific sub-models whilst simultaneously modelling view-generic discrimination information. Therefore, our framework not only inherits the strength of view-generic model learning but also provides an effective way to take into account view specific characteristics. Our CRAFT framework can be extended to jointly learn view-specific feature transformations for person re-id across a large network with more than two cameras, a largely under-investigated but realistic re-id setting. Additionally, we present a domain-generic deep person appearance representation which is designed particularly to be towards view invariant for facilitating cross-view adaptation by CRAFT. We conducted extensively comparative experiments to validate the superiority and advantages of our proposed framework over state-of-the-art competitors on contemporary challenging person re-id datasets.","","","10.1109/TPAMI.2017.2666805","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7849147","Person re-identification;adaptive feature augmentation;view-specific transformation","Cameras;Correlation;Training data;Adaptation models;Data models;Visualization;Reliability","feature extraction;image representation;image sensors;learning (artificial intelligence);object recognition","domain-generic deep person appearance representation;realistic re-id setting;CRAFT framework;view-generic model learning;simultaneously modelling view-generic discrimination information;view-generic learning algorithms;cross-view visual data distribution;CRAFT performs cross-view adaptation;called Camera coRrelation Aware Feature augmenTation;feature augmentation point;re-identification framework;view-specific person;view-specific re-id;learning view-specific feature transformations;camera view;cross-view transformations;distance metric/ subspace learning models;unknown cross-view feature distortion;significant cross-view feature distortion;different nonoverlapping camera","","33","93","","","","","IEEE","IEEE Journals"
"Open Data for Global Multimodal Land Use Classification: Outcome of the 2017 IEEE GRSS Data Fusion Contest","N. Yokoya; P. Ghamisi; J. Xia; S. Sukhanov; R. Heremans; I. Tankoyeu; B. Bechtel; B. Le Saux; G. Moser; D. Tuia","RIKEN Center for Advanced Intelligence Project, RIKEN, Tokyo, Japan; Department of Signal Processing in Earth Observation, Remote Sensing Technology Institute (IMF), German Aerospace Center (DLR), Wessling, Germany; Department of Advanced Interdisciplinary Studies, The University of Tokyo, Tokyo, Japan; AGT International, Darmstadt, Germany; AGT International, Darmstadt, Germany; AGT International, Darmstadt, Germany; Center for Earth System Research and Sustainability, Universität Hamburg, Hamburg, Germany; DTIS, ONERA, Université Paris Saclay, Palaiseau, France; Department of Electrical, Electronic, Telecommunications Engineering and Naval Architecture, University of Genoa, Genoa, Italy; Laboratory of Geo-Information Science and Remote Sensing, Wageningen University & Research, Wageningen, The Netherlands","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2018","11","5","1363","1377","In this paper, we present the scientific outcomes of the 2017 Data Fusion Contest organized by the Image Analysis and Data Fusion Technical Committee of the IEEE Geoscience and Remote Sensing Society. The 2017 Contest was aimed at addressing the problem of local climate zones classification based on a multitemporal and multimodal dataset, including image (Landsat 8 and Sentinel-2) and vector data (from OpenStreetMap). The competition, based on separate geographical locations for the training and testing of the proposed solution, aimed at models that were accurate (assessed by accuracy metrics on an undisclosed reference for the test cities), general (assessed by spreading the test cities across the globe), and computationally feasible (assessed by having a test phase of limited time). The techniques proposed by the participants to the Contest spanned across a rather broad range of topics, and of mixed ideas and methodologies deriving from computer vision and machine learning but also deeply rooted in the specificities of remote sensing. In particular, rigorous atmospheric correction, the use of multidate images, and the use of ensemble methods fusing results obtained from different data sources/time instants made the difference.","","","10.1109/JSTARS.2018.2799698","Cluster of Excellence “CliSAP”; University of Hamburg; Swiss National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8338367","Convolutional neural networks (CNNs);crowdsourcing;deep learning (DL);ensemble learning;image analysis and data fusion (IADF);multimodal;multiresolution;multisource;OpenStreetMap (OSM);random fields","Urban areas;Remote sensing;Earth;Training;Artificial satellites;Data integration;Image resolution","geophysical image processing;image classification;image fusion;land use;learning (artificial intelligence);remote sensing;terrain mapping","remote sensing;local climate zones classification;multidate images;global multimodal land use classification;geographical locations;data fusion contest;ensemble methods;OpenStreetMap;Landsat 8;Sentinel-2;computer vision;machine learning;AD 2017","","13","62","","","","","IEEE","IEEE Journals"
"Denoising Autoencoders for Laser-Based Scan Registration","A. Nicolai; G. A. Hollinger","Collaborative Robotics and Intelligent Systems Institute, Oregon State University, Corvallis, OR, USA; Collaborative Robotics and Intelligent Systems Institute, Oregon State University, Corvallis, OR, USA","IEEE Robotics and Automation Letters","","2018","3","4","4391","4398","In this letter, we build on recent advances in deep learning to improve SE(3) transformations, enabling more accurate motion estimation in mobile robots. We propose using denoising autoencoders (DAEs) to address the challenges presented by modern LIDARs. Our proposed approach is comprised of two stages: a novel pre-processing stage for robust feature identification and a scan matching stage for motion estimation. In the pre-processing stage, LIDAR data are projected into a two-dimensional (2-D) image format and a DAE is used to extract salient features. These features are used as a mask for the original data, which is then re-projected into full 3-D space. Scan matching is performed on the re-projected data to estimate motion in SE(3). We analyze the performance of our approach using the real-world data from the University of Michigan North Campus long-term vision and LIDAR dataset and test generalization on LIDAR data from the KITTI dataset. We show that our approach generalizes across domains, is capable of reducing the per-estimate error of standard iterative closest point (ICP) methods on average by 25.5% for the translational component and 57.53% for the rotational component, and is capable of reducing the computation time of state-of-the-art ICP methods by a factor of 7.94 on average while achieving competitive performance.","","","10.1109/LRA.2018.2867856","National Aeronautics and Space Administration; DWFritz Automation; Oregon Metals Initiative; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8451962","Autonomous vehicle navigation;learning and adaptive systems;localization","Feature extraction;Three-dimensional displays;Laser radar;Iterative closest point algorithm;Robustness;Standards;Machine learning","feature extraction;image denoising;image matching;image registration;iterative methods;learning (artificial intelligence);mobile robots;motion estimation;optical radar;pose estimation;robot vision","test generalization;LIDAR data;KITTI dataset;per-estimate error;standard iterative closest point methods;competitive performance;autoencoders;laser-based scan registration;deep learning;mobile robots;DAE;robust feature identification;scan matching stage;image format;salient features;University of Michigan North Campus long-term vision;preprocessing stage;motion estimation","","","37","","","","","IEEE","IEEE Journals"
"Estimation of Steering Angle and Collision Avoidance for Automated Driving Using Deep Mixture of Experts","V. John; A. Boyali; H. Tehrani; K. Ishimaru; M. Konishi; Z. Liu; S. Mita","Research Center of Smart Vehicles, Toyota Technological Institute, Nagoya, Japan; Ascent Robotics, Tokyo, Japan; Denso Corporation, Kariya, Japan; Nippon Soken, Nishio, Japan; Denso Corporation, Kariya, Japan; University of British Columbia (Okanagan), Kelowna, BC, Canada; Research Center of Smart Vehicles, Toyota Technological Institute, Nagoya, Japan","IEEE Transactions on Intelligent Vehicles","","2018","3","4","571","584","In this paper, a monocular camera-based method is proposed to estimate the steering angle in autonomous driving. A second-order particle filtering algorithm is used to estimate the steering angles. The filtering algorithm is modeled at the scene-level for varying driving patterns. For a given road scene, individual proposal and likelihood distributions are modeled with deep learning-based regression frameworks for normal driving and obstacle avoidance driving patterns, respectively, the proposal distribution is modeled using a novel long short-term memory-based mixture-of-expert; and the likelihood is modeled using a convolutional neural network. To estimate the driving pattern captured from the monocular camera, a long recurrent convolutional network is adopted and trained. By modeling the distribution at the scene-level for different driving patterns, we accurately model the particle filter distributions. Consequently, for autonomous driving, the steering angle is robustly estimated with few particles. The proposed framework is validated on multiple acquired sequences. A detailed comparative and parametric analysis of the algorithm is performed. The experimental results demonstrate the robustness and accuracy of our filtering algorithm for varying road scenes and driving behaviors.","","","10.1109/TIV.2018.2874555","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8485411","Autonomous systems;pattern analysis;multi-layer neural network","Trajectory;Autonomous systems;Road traffic;Collision avoidance;Robustness;Autonomous vehicles;Neural networks;Pattern recognition;Traffic control","cameras;collision avoidance;convolution;estimation theory;expert systems;feedforward neural nets;learning (artificial intelligence);mobile robots;particle filtering (numerical methods);recurrent neural nets;regression analysis;road traffic;statistical distributions;steering systems;traffic engineering computing","normal driving pattern;obstacle avoidance driving pattern;long short-term memory-based mixture-of-expert;likelihood distribution;steering angle estimation;driving behaviors;road scenes;particle filter distributions;long recurrent convolutional network;proposal distribution;deep learning-based regression frameworks;second-order particle filtering algorithm;autonomous driving;monocular camera-based method;automated driving;collision avoidance","","","44","","","","","IEEE","IEEE Journals"
"Indoor Person Identification Using a Low-Power FMCW Radar","B. Vandersmissen; N. Knudde; A. Jalalvand; I. Couckuyt; A. Bourdoux; W. De Neve; T. Dhaene","Department of Electronics and Information Systems, Ghent University–imec, Ghent, Belgium; Department of Information Technology, Ghent University–imec, Ghent, Belgium; Department of Electronics and Information Systems, Ghent University–imec, Ghent, Belgium; Department of Information Technology, Ghent University–imec, Ghent, Belgium; imec, Leuven, Belgium; Department of Electronics and Information Systems, Ghent University–imec, Ghent, Belgium; Department of Information Technology, Ghent University–imec, Ghent, Belgium","IEEE Transactions on Geoscience and Remote Sensing","","2018","56","7","3941","3952","Contemporary surveillance systems mainly use video cameras as their primary sensor. However, video cameras possess fundamental deficiencies, such as the inability to handle low-light environments, poor weather conditions, and concealing clothing. In contrast, radar devices are able to sense in pitch-dark environments and to see through walls. In this paper, we investigate the use of micro-Doppler (MD) signatures retrieved from a low-power radar device to identify a set of persons based on their gait characteristics. To that end, we propose a robust feature learning approach based on deep convolutional neural networks. Given that we aim at providing a solution for a real-world problem, people are allowed to walk around freely in two different rooms. In this setting, the IDentification with Radar data data set is constructed and published, consisting of 150 min of annotated MD data equally spread over five targets. Through experiments, we investigate the effectiveness of both the Doppler and time dimension, showing that our approach achieves a classification error rate of 24.70% on the validation set and 21.54% on the test set for the five targets used. When experimenting with larger time windows, we are able to further lower the error rate.","","","10.1109/TGRS.2018.2816812","Ghent University; imec; Fund for Scientific Research-Flanders (FWO-Flanders); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8333730","Convolutional neural network (CNN);feature learning;gait classification;indoor sensing;low-power radar;micro-Doppler (MD);person identification","Legged locomotion;Doppler effect;Doppler radar;Cameras;Robustness;Machine learning","CW radar;Doppler radar;feature extraction;FM radar;gait analysis;image classification;learning (artificial intelligence);neural nets;radar imaging;video surveillance","radar devices;pitch-dark environments;microDoppler signatures;low-power radar device;gait characteristics;robust feature learning approach;deep convolutional neural networks;annotated MD data;time dimension;indoor person identification;low-power FMCW Radar;contemporary surveillance systems;video cameras;primary sensor;low-light environments;concealing clothing;radar dataset;weather conditions;classification error rate;time 150.0 min","","11","22","","","","","IEEE","IEEE Journals"
"Domain Specific Learning for Sentiment Classification and Activity Recognition","H. Wang; Y. Xue; X. Zhen; X. Tu","School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China; School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China; School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China; School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China","IEEE Access","","2018","6","","53611","53619","A deep neural network, while avoiding its complex process of feature selection, requires sufficient training samples to learn those connection weights of adjacent layers. However, in many real applications, not enough training samples are available in all cases. This paper suggests a universal-todomain-specific learning method based on recurrent neural network for cross-domain sentiment classification and activity recognition. In the situation of having only a small amount of training samples that is in available, the structure of its network model can be adjusted flexibly according to the needs of a target domain classification or recognition. Where there are two points of our concern as follows: 1) the finetune and regular constraints can increase its training efficiency by updating in a small local area, namely, sharing these parameters between input and hidden layers with a target domain and 2) then, a linear output network moves on its implementing amelioration from subtlety as an exploration or exploitation in order to mitigate the phenomenon of over-fitting. Aiming at an actual situation, this domain-specific learning model with a slide window of instances and features is designed and implemented for a good long-short term memory. Finally, the two strategies are applied into IMDB reviews, Amazon product reviews, and human activities recognition collected by the built-in gyroscope sensors data, and the experimental results verify their validity.","","","10.1109/ACCESS.2018.2871349","National Natural Science Foundation of China; China Scholarship Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8468971","Personalized activity recognition;recurrent neural networks;sentiment classification","Training;Mathematical model;Activity recognition;Recurrent neural networks;Logic gates;Adaptation models;Analytical models","learning (artificial intelligence);pattern classification;recurrent neural nets;sentiment analysis","deep neural network;feature selection;recurrent neural network;cross-domain sentiment classification;linear output network;human activities recognition;universal-to-domain-specific learning method;long-short term memory","","","27","","","","","IEEE","IEEE Journals"
"Can We Speculate Running Application With Server Power Consumption Trace?","Y. Li; H. Hu; Y. Wen; J. Zhang","School of Computer Engineering, Nanyang Technological University, Singapore; School of Computer Engineering, Nanyang Technological University, Singapore; School of Computer Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, South China University of Technology, Guangzhou, China","IEEE Transactions on Cybernetics","","2018","48","5","1500","1512","In this paper, we propose to detect the running applications in a server by classifying the observed power consumption series for the purpose of data center energy consumption monitoring and analysis. Time series classification problem has been extensively studied with various distance measurements developed; also recently the deep learning-based sequence models have been proved to be promising. In this paper, we propose a novel distance measurement and build a time series classification algorithm hybridizing nearest neighbor and long short term memory (LSTM) neural network. More specifically, first we propose a new distance measurement termed as local time warping (LTW), which utilizes a user-specified index set for local warping, and is designed to be noncommutative and nondynamic programming. Second, we hybridize the 1-nearest neighbor (1NN)-LTW and LSTM together. In particular, we combine the prediction probability vector of 1NN-LTW and LSTM to determine the label of the test cases. Finally, using the power consumption data from a real data center, we show that the proposed LTW can improve the classification accuracy of dynamic time warping (DTW) from about 84% to 90%. Our experimental results prove that the proposed LTW is competitive on our data set compared with existed DTW variants and its noncommutative feature is indeed beneficial. We also test a linear version of LTW and find out that it can perform similar to state-of-the-art DTW-based method while it runs as fast as the linear runtime lower bound methods like LB_Keogh for our problem. With the hybrid algorithm, for the power series classification task we achieve an accuracy up to about 93%. Our research can inspire more studies on time series distance measurement and the hybrid of the deep learning models with other traditional models.","","","10.1109/TCYB.2017.2703941","Singapore EMA; Singapore IMDA; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7933202","Long short term memory (LSTM);recurrent neural network (RNN);time series classification;time warping","Time series analysis;Distance measurement;Servers;Power demand;Neural networks;Monitoring;Algorithm design and analysis","computer centres;learning (artificial intelligence);neural nets;pattern classification;power aware computing;power consumption;probability;time series","server power consumption trace;observed power consumption series;data center energy consumption monitoring;time series classification problem;deep learning-based sequence models;time series classification algorithm;long short term memory neural network;LSTM;nondynamic programming;neighbor-LTW;prediction probability vector;1NN-LTW;test cases;power consumption data;dynamic time warping;existed DTW variants;noncommutative feature;state-of-the-art DTW;linear runtime lower bound methods;power series classification task;time series distance measurement;deep learning models","","2","40","","","","","IEEE","IEEE Journals"
"Ultra-High-Efficiency Writing in Voltage-Control Spintronics Memory (VoCSM): The Most Promising Embedded Memory for Deep Learning","Y. Ohsawa; H. Yoda; N. Shimomura; S. Shirotori; S. Fujita; K. Koi; A. Buyandalai; S. Oikawa; M. Shimizu; Y. Kato; T. Inokuchi; H. Sugiyama; M. Ishikawa; K. Ikegami; S. Takaya; A. Kurobe","Corporate Research and Development Center, Toshiba Corporation, Kawasaki, Japan; Corporate Research and Development Center, Toshiba Corporation, Kawasaki, Japan; Corporate Research and Development Center, Toshiba Corporation, Kawasaki, Japan; Corporate Research and Development Center, Toshiba Corporation, Kawasaki, Japan; Corporate Research and Development Center, Toshiba Corporation, Kawasaki, Japan; Corporate Research and Development Center, Toshiba Corporation, Kawasaki, Japan; Corporate Research and Development Center, Toshiba Corporation, Kawasaki, Japan; Corporate Research and Development Center, Toshiba Corporation, Kawasaki, Japan; Corporate Research and Development Center, Toshiba Corporation, Kawasaki, Japan; Corporate Research and Development Center, Toshiba Corporation, Kawasaki, Japan; Corporate Research and Development Center, Toshiba Corporation, Kawasaki, Japan; Corporate Research and Development Center, Toshiba Corporation, Kawasaki, Japan; Department of Systems Innovation, Graduate School of Engineering Science, Osaka University, Toyonaka, Japan; Corporate Research and Development Center, Toshiba Corporation, Kawasaki, Japan; Corporate Research and Development Center, Toshiba Corporation, Kawasaki, Japan; Corporate Research and Development Center, Toshiba Corporation, Kawasaki, Japan","IEEE Journal of the Electron Devices Society","","2018","6","","1233","1238","Our new proposal of voltage-control spintronics memory (VoCSM) in which spin-orbit torque in conjunction with the voltage-control-magnetic-anisotropy effect works as the writing principle showed small switching current of  $37~\mu \text{A}$  for about 350  $K_{B}T$  switching energy. This indicates VoCSM’s writing efficiency is so high that VoCSM would be applicable for deep learning memories requiring ultra-low power consumption.","","","10.1109/JEDS.2018.2880752","Council for Science, Technology and Innovation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8531691","Magnetic memory;nonvolatile memory;magnetic tunneling;magnetic devices;learning (artificial intelligence);Nanopatterning","Electrodes;Integrated circuits;Writing;Spintronics;Etching;Switches","","","","","14","","","","","IEEE","IEEE Journals"
"Improvement of Generalization Ability of Deep CNN via Implicit Regularization in Two-Stage Training Process","Q. Zheng; M. Yang; J. Yang; Q. Zhang; X. Zhang","School of Information Science and Engineering, Shandong University, Jinan, China; School of Information Science and Engineering, Shandong University, Jinan, China; Department of Science, The University of British Columbia, Vancouver, BC, Canada; School of Information Science and Engineering, Shandong University, Jinan, China; School of Information Science and Engineering, Shandong University, Jinan, China","IEEE Access","","2018","6","","15844","15869","Optimization of deep learning is no longer an imminent problem, due to various gradient descent methods and the improvements of network structure, including activation functions, the connectivity style, and so on. Then the actual application depends on the generalization ability, which determines whether a network is effective. Regularization is an efficient way to improve the generalization ability of deep CNN, because it makes it possible to train more complex models while maintaining a lower overfitting. In this paper, we propose to optimize the feature boundary of deep CNN through a two-stage training method (pre-training process and implicit regularization training process) to reduce the overfitting problem. In the pre-training stage, we train a network model to extract the image representation for anomaly detection. In the implicit regularization training stage, we re-train the network based on the anomaly detection results to regularize the feature boundary and make it converge in the proper position. Experimental results on five image classification benchmarks show that the two-stage training method achieves a state-of-the-art performance and that it, in conjunction with more complicated anomaly detection algorithm, obtains better results. Finally, we use a variety of strategies to explore and analyze how implicit regularization plays a role in the two-stage training process. Furthermore, we explain how implicit regularization can be interpreted as data augmentation and model ensemble.","","","10.1109/ACCESS.2018.2810849","Shandong Provincial Natural Science Foundation; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8306949","Deep CNN;image classification;overfitting;generalization;anomaly detection;implicit regularization","Training;Anomaly detection;Feature extraction;Image representation;Production;Principal component analysis;Machine learning","","","","6","68","","","","","IEEE","IEEE Journals"
"On the Importance of Super-Gaussian Speech Priors for Machine-Learning Based Speech Enhancement","R. Rehr; T. Gerkmann","Signal Processing Group, Department of Informatics, University of Hamburg, Hamburg, Germany; Signal Processing Group, Department of Informatics, University of Hamburg, Hamburg, Germany","IEEE/ACM Transactions on Audio, Speech, and Language Processing","","2018","26","2","357","366","For enhancing noisy signals, machine-learning based single-channel speech enhancement schemes exploit prior knowledge about typical speech spectral structures. To ensure a good generalization and to meet requirements in terms of computational complexity and memory consumption, certain methods restrict themselves to learning speech spectral envelopes. We refer to these approaches as machine-learning spectral envelope (MLSE)-based approaches. In this paper, we show by means of theoretical and experimental analyses that for MLSE-based approaches, super-Gaussian priors allow for a reduction of noise between speech spectral harmonics which is not achievable using Gaussian estimators such as the Wiener filter. For the evaluation, we use a deep neural network based phoneme classifier and a low-rank nonnegative matrix factorization framework as examples of MLSE-based approaches. A listening experiment and instrumental measures confirm that while super-Gaussian priors yield only moderate improvements for classic enhancement schemes, for MLSE-based approaches super-Gaussian priors clearly make an important difference and significantly outperform Gaussian priors.","","","10.1109/TASLP.2017.2778151","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8121999","Super-Gaussian PDF;nonnegative matrix factorization;neural networks;speech enhancement","Speech;Speech enhancement;Noise measurement;Harmonic analysis;Speech recognition;Maximum likelihood estimation","learning (artificial intelligence);matrix decomposition;neural nets;speech enhancement;speech recognition;Wiener filters","super-Gaussian speech priors;single-channel speech enhancement schemes;speech spectral envelopes;machine-learning spectral envelope;MLSE-based approaches;speech spectral harmonics;classic enhancement schemes;speech spectral structures;Gaussian estimators;listening experiment;instrumental measures;deep neural network based phoneme classifier;low-rank nonnegative matrix factorization framework","","2","46","Traditional","","","","IEEE","IEEE Journals"
"DIDACTIC: A Data-Intelligent Digital-to-Analog Converter with a Trainable Integrated Circuit using Memristors","L. Danial; N. Wainstein; S. Kraus; S. Kvatinsky","Andrew and Erna Viterbi Faculty of Electrical Engineering, Technion–Israel Institute of Technology, Haifa, Israel; Andrew and Erna Viterbi Faculty of Electrical Engineering, Technion–Israel Institute of Technology, Haifa, Israel; PLSense Ltd., Yokneam, Israel; Andrew and Erna Viterbi Faculty of Electrical Engineering, Technion–Israel Institute of Technology, Haifa, Israel","IEEE Journal on Emerging and Selected Topics in Circuits and Systems","","2018","8","1","146","158","In an increasingly data-diverse world, in which data are interactively transferred at high rates, there is an ever-growing demand for high-precision data converters. In this paper, we propose a novel digital-to-analog converter (DAC) configuration that is calibrated using an artificial intelligence neural network technique. The proposed technique is demonstrated on an adaptive and self-calibrated binary-weighted DAC that can be configured on-chip in real time. We design a reconfigurable 4-bit DAC with a memristor-based neural network. This circuit uses an online supervised machine learning algorithm called “binary-weighted time-varying gradient descent.” This algorithm fits multiple full-scale voltage ranges and sampling frequencies by iterative synaptic adjustments, while inherently providing mismatch calibration and noise tolerance. Theoretical analysis, as well as simulation results, show the efficiency and robustness of the training algorithm in reconfiguration, self-calibration, and desensitization, leading to a significant improvement in DAC accuracy: 0.12 LSB in terms of integral non-linearity, 0.11 LSB in terms of differential non-linearity, and 3.63 bits in terms of effective number of bits. The findings constitute a promising milestone toward scalable data-driven converters using deep neural networks.","","","10.1109/JETCAS.2017.2780251","Israeli Planning and Budgeting Committee Fellowship; Viterbi Fellowship at the Technion Computer Engineering Center; EU COST Action IC1401; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8168325","Adaptive systems;calibration;converters;memristors;neuromorphic computing;reconfigurable architectures;supervised learning","Memristors;Training;Algorithm design and analysis;Machine learning algorithms;Resistance;Circuits and systems","calibration;digital-analogue conversion;iterative methods;learning (artificial intelligence);memristor circuits;neural chips","multiple full-scale voltage ranges;iterative synaptic adjustments;mismatch calibration;training algorithm;DAC accuracy;integral nonlinearity;deep neural networks;trainable integrated circuit;memristor;high-precision data converters;artificial intelligence neural network technique;online supervised machine learning algorithm;binary-weighted time-varying gradient descent;DIDACTIC;self-calibrated binary-weighted DAC;adaptive binary-weighted DAC;data-intelligent digital-to-analog converter configuration;sampling frequencies;noise tolerance;differential nonlinearity;data-driven converters;word length 3.63 bit;word length 4 bit","","7","37","","","","","IEEE","IEEE Journals"
"Deep Multi-Layer Perceptron Classifier for Behavior Analysis to Estimate Parkinson’s Disease Severity Using Smartphones","S. Wan; Y. Liang; Y. Zhang; M. Guizani","School of Information and Safety Engineering, Zhongnan University of Economics and Law, Wuhan, China; School of Information and Safety Engineering, Zhongnan University of Economics and Law, Wuhan, China; School of Information and Safety Engineering, Zhongnan University of Economics and Law, Wuhan, China; Electrical and Computer Engineering Department, University of Idaho, Moscow, ID, USA","IEEE Access","","2018","6","","36825","36833","Although the preclinical detection of Parkinson's disease (PD) has been explored, a practical, inexpensive, and overall screening diagnosis has yet to be made available. However, due to the large variability and complexity in progress of PD and the difficulties in gathering a single time-point measurement of a single sign, the goal of precision treatment and assessment severity would be impossible to achieve. Hence, the repeated monitoring and tracking of individuals during their daily living activities at different times would also be of great importance for treating this chronic disease. We propose a deep multi-layer perceptron (DMLP) classifier for behavior analysis to estimate the progression of PD using smartphones. This paper aims to identify severity in PD patients' actions by analyzing their speech and movement patterns, as measured with a smartphone accelerometer in their pocket at different times of the day. Popular machine learning classification algorithms, such as logistic regression, random forests, k-nearest neighbors, M5P, and DMLP, are applied on one dataset from the University of California Irvine and another dataset collected by the authors to classify each patient as being Parkinson positive or negative. We further measure the success of each method for their ability to correctly classify the patients into one of these categories. Of the experimental models, it is demonstrated that DMLP performs the best in both datasets.","","","10.1109/ACCESS.2018.2851382","National Natural Science Foundation of China; MOE (Ministry of Education in China) Project of Humanities and Social Sciences; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8405749","Parkinson’s disease;behavior analysis;DMLP;classification","Smart phones;Diseases;Legged locomotion;Monitoring;Biomedical measurement;Sensors;Accelerometers","accelerometers;diseases;learning (artificial intelligence);medical computing;multilayer perceptrons;patient diagnosis;pattern classification;regression analysis;smart phones","practical screening diagnosis;chronic disease;DMLP;PD patients;smartphone accelerometer;Parkinsons disease;deep multilayer perceptron classifier;machine learning classification algorithm;logistic regression;random forest;k-nearest neighbor;California Irvine","","9","47","","","","","IEEE","IEEE Journals"
"PCNN: Deep Convolutional Networks for Short-Term Traffic Congestion Prediction","M. Chen; X. Yu; Y. Liu","York University, Toronto, ON, Canada; York University, Toronto, ON, Canada; Wilfrid Laurier University, Waterloo, ON, Canada","IEEE Transactions on Intelligent Transportation Systems","","2018","19","11","3550","3559","Traffic problems have seriously affected people's life quality and urban development, and forecasting short-term traffic congestion is of great importance to both individuals and governments. However, understanding and modeling the traffic conditions can be extremely difficult, and our observations from real traffic data reveal that: 1) similar traffic congestion patterns exist in the neighboring time slots and on consecutive workdays and 2) the levels of traffic congestion have clear multiscale properties. To capture these characteristics, we propose a novel method named PCNN, which is based on a deep convolutional neural network, modeling periodic traffic data for short-term traffic congestion prediction. PCNN has two pivotal procedures: time series folding and multi-grained learning. It first temporally folds the time series and constructs a 2-D matrix as the network input, such that both the real-time traffic conditions and past traffic patterns are well considered; then, with a series of convolutions over the input matrix, it is able to model the local temporal dependency and multiscale traffic patterns. In particular, the global trend of congestion can be addressed at the macroscale, whereas more details and variations of the congestion can be captured at the microscale. Experimental results on a real-world urban traffic data set confirm that folding time series data into a 2-D matrix is effective and PCNN outperforms the baselines significantly for the task of short-term congestion prediction.","","","10.1109/TITS.2018.2835523","National Natural Science Foundation of China; NSERC Discovery Grants; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8392388","Traffic congestion prediction;periodic traffic data;convolutional neural network","Roads;Predictive models;Data models;Time series analysis;Forecasting;Market research;Solid modeling","convolution;feedforward neural nets;learning (artificial intelligence);road traffic;time series;traffic engineering computing","traffic congestion patterns;multigrained learning;2-D matrix;time series folding;periodic traffic data;deep convolutional neural network;short-term traffic congestion prediction;PCNN;folding time series data;real-world urban traffic data;multiscale traffic patterns;real-time traffic conditions","","6","29","","","","","IEEE","IEEE Journals"
"Bimodal Vein Data Mining via Cross-Selected-Domain Knowledge Transfer","J. Wang; G. Wang; M. Zhou","School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, China; School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, China; Shanghai Key Laboratory of Multidimensional Information Processing, East China Normal University, Shanghai, China","IEEE Transactions on Information Forensics and Security","","2018","13","3","733","744","Recent success in large-scale image recognition challenge (i.e., ImageNet) fully demonstrates the capability of deep neural network (DNN) in learning complex and semantic representation, and this also motivates the generation of transfer learning model, which fine-tunes state-of-the-art DNN models with other small-scale databases for better performance. Driven by such an idea, a task-specific DNN model fine-tuned from VGG-face is constructed for both gender and identity recognition with hand vein information. Unlike the traditional transfer learning models, which fine-tune directly from source to target, we leverage the coarse-to-fine scheme to train the task-specific models in a step-aware way, such that the inherent correlation between the neighboring databases could serve as initialization base to relieve the problem of over-fitting, which is inevitable with the small-scaled hand vein database, and also speed up the convergence. Besides, the task-driven network training idea, which involves joint optimization of linear regression classifier and network parameters, is also adopted during training of each model to obtain more discriminative representation for specified tasks. Instead of adopting the trained linear regression classifier for gender and identity classification, the large margin distribution machine (LDM) is introduced to ensure the discriminative and generalization performance of the model simultaneously, and it should be noted that before feeding the gender feature vector into the LDM, a supervised feature selection step is incorporated to improve the classification performance by discarding the redundant feature and highlighting the important ones for gender classification. Rigorous experiments using the lab-made database are conducted to demonstrate the effectiveness and feasibility of the proposed model. What is more, additional experiment with a subset of the PolyU database illustrates its generalization ability and robustness.","","","10.1109/TIFS.2017.2766039","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8080243","Hand vein information;gender classification;personal identification;transfer learning;coarse-to-fine;taskdriven;LDM;supervised feature selection","Veins;Feature extraction;Databases;Face;Training;Robustness","data mining;feature extraction;image recognition;image representation;learning (artificial intelligence);neural nets;pattern classification;regression analysis","gender classification;PolyU database;classification performance;supervised feature selection step;gender feature vector;generalization performance;discriminative performance;trained linear regression classifier;discriminative representation;network parameters;network training idea;hand vein database;neighboring databases;traditional transfer learning models;hand vein information;identity recognition;VGG-face;task-specific DNN model;small-scale databases;fine-tunes state-of-the-art DNN models;transfer learning model;semantic representation;deep neural network;large-scale image recognition challenge;cross-selected-domain knowledge transfer;bimodal vein data mining","","4","87","","","","","IEEE","IEEE Journals"
"Multi-scale Frequency Reconstruction for Guided Depth Map Super-resolution via Deep Residual Network","Y. Zuo; Q. Wu; Y. Fang; P. An; L. Huang; Z. Chen","School of Information Management, Jiangxi University of Finance and Economics, Nanchang, Jiangxi, China.; Faculty of Engineering and Information Technology, University of Technology Sydney, NSW, Australia.; School of Information Management, Jiangxi University of Finance and Economics, Nanchang, Jiangxi, China.; Faculty of Communication and Information Engineering, University of Shanghai University, Shanghai, China.; College of Physics and Information Engineering, Fuzhou University, Fuzhou, Fujian, China.; College of Physics and Information Engineering, Fuzhou University, Fuzhou, Fujian, China.","IEEE Transactions on Circuits and Systems for Video Technology","","2018","PP","99","1","1","The depth maps obtained by consumer-level sensors are always noisy in low-resolution (LR) domain. Existing methods for guided depth super-resolution (SR) which are based on pre-defined local and global models perform well in general cases (e.g., Joint Bilateral Filter and Markov Random Field). However, such model-based methods may fail describing the potential relationship between RGB-D image pairs. To solve this problem, this paper proposes a data-driven approach based on deep convolutional neural network with global and local residual learning. It progressively upsamples the LR depth map guided by high-resolution (HR) intensity image in multiple scales. A global residual learning is adopted to learn the difference between the ground truth and the coarsely upsampled depth map. And the local residual learning is introduced in each scaledependent reconstruction sub-network. This scheme can restore the depth structure from coarse to fine via multi-scale frequency synthesis. In addition, batch normalization layers are used to improve the performance of depth map denoising. Our method is evaluated in noise-free and noisy cases. A comprehensive comparison against 17 state-of-the-art methods is carried out. The experimental results show that the proposed method has faster convergence speed as well as the improved performances based on the qualitative and the quantitative evaluations.","","","10.1109/TCSVT.2018.2890271","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8598786","Depth Map Super-resolution (SR);Deep Convolutional Neual Network (DCNN);Depth Denoising;Residual Learning;Batch-normalization","Color;Image reconstruction;Image edge detection;Image resolution;Noise measurement;Dictionaries;Training","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Facial Expression Recognition with Identity and Emotion Joint Learning","M. Li; H. Xu; X. Huang; Z. Song; X. Liu; X. Li","Data Science Research Center, Duke Kunshan University, Kunshan, Jiangsu China (e-mail: ming.li369@dukekunshan.edu.cn); School of Data and Computer Science, Sun Yat-sen University, guangzhou, guangdong China (e-mail: 379548839@qq.com); School of Data and Computer Science, Sun Yat-sen University, guangzhou, guangdong China (e-mail: 767967354@qq.com); School of Preschool Education, Shandong Yingcai University, 381721 Jinan, Shandong China (e-mail: songzhanmei@126.com); School of Preschool Education, Shandong Yingcai University, 381721 Jinan, Shandong China (e-mail: liuxiaolin0531@qq.com); School of Preschool Education, Shangdong Yingcai University, Jinan, Shangdong China (e-mail: xinli.ece@duke.edu)","IEEE Transactions on Affective Computing","","2018","PP","99","1","1","Different subjects may express a specific expression in different ways due to inter-subject variabilities. In this work, besides training deep-learned facial expression feature (emotional feature), we also consider the influence of latent face identity feature such as the shape or appearance of face. We propose an identity and emotion joint learning approach with deep convolutional neural networks (CNNs) to enhance the performance of facial expression recognition (FER) tasks. First, we learn the emotion and identity features separately using two different CNNs with their corresponding training data. Second, we concatenate these two features together as a deep-learned Tandem Facial Expression (TFE) Feature and feed it to the subsequent fully connected layers to form a new model. Finally, we perform joint learning on the newly merged network using only the facial expression training data. Experimental results show that our proposed approach achieves 99.31% and 84.29% accuracy on the CK+ and the FER+ database, respectively, which outperforms the residual network baseline as well as many other state-of-the-art methods.","","","10.1109/TAFFC.2018.2880201","Natural Science Foundation of Guangzhou City; Six talent peaks project in Jiangsu Province; Science and Technology Program of Guangzhou City; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8528894","Facial expression recognition;Emotion recognition;Face recognition;Joint learning;Transfer learning","Face recognition;Face;Task analysis;Feature extraction;Convolution;Emotion recognition;Training data","","","","3","","","","","","IEEE","IEEE Early Access Articles"
"Action Recognition with Dynamic Image Networks","H. Bilen; B. Fernando; E. Gavves; A. Vedaldi","University of Edinburgh, Edinburgh, United Kingdom; ACRV, The Australian National University, ACT, Australia; University of Amsterdam, Amsterdam, WX, Netherlands; University of Oxford, Oxford, United Kingdom","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","12","2799","2813","We introduce the concept of dynamic image, a novel compact representation of videos useful for video analysis, particularly in combination with convolutional neural networks (CNNs). A dynamic image encodes temporal data such as RGB or optical flow videos by using the concept of `rank pooling'. The idea is to learn a ranking machine that captures the temporal evolution of the data and to use the parameters of the latter as a representation. We call the resulting representation dynamic image because it summarizes the video dynamics in addition to appearance. This powerful idea allows to convert any video to an image so that existing CNN models pre-trained with still images can be immediately extended to videos. We also present an efficient approximate rank pooling operator that runs two orders of magnitude faster than the standard ones with any loss in ranking performance and can be formulated as a CNN layer. To demonstrate the power of the representation, we introduce a novel four stream CNN architecture which can learn from RGB and optical flow frames as well as from their dynamic image representations. We show that the proposed network achieves state-of-the-art performance, 95.5 and 72.5 percent accuracy, in the UCF101 and HMDB51, respectively.","","","10.1109/TPAMI.2017.2769085","Engineering and Physical Sciences Research Council; ERC Starting Grant IDIU and the Australian Research Council Centre of Excellence for Robotic Vision; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094009","Human action classification;video classification;motion representation;deep learning;convolutional neural networks","Convolutional neural networks;Neural networks;Video sequences;Optical imaging;Streaming media;Image classification;Feature extraction;Deep learning","feedforward neural nets;image colour analysis;image motion analysis;image representation;object recognition;video coding","action recognition;dynamic image networks;video analysis;convolutional neural networks;temporal data;RGB;optical flow videos;ranking machine;video dynamics;optical flow frames;dynamic image representations;approximate rank pooling operator;CNN models;UCF101;HMDB51","","5","81","","","","","IEEE","IEEE Journals"
"A New Deep Generative Network for Unsupervised Remote Sensing Single-Image Super-Resolution","J. M. Haut; R. Fernandez-Beltran; M. E. Paoletti; J. Plaza; A. Plaza; F. Pla","Department of Technology of Computers and Communications, Hyperspectral Computing Laboratory, Escuela Politécnica, University of Extremadura, Cáceres, Spain; Institute of New Imaging Technologies, University Jaume I, Castellón de la Plana, Spain; Department of Technology of Computers and Communications, Hyperspectral Computing Laboratory, Escuela Politécnica, University of Extremadura, Cáceres, Spain; Department of Technology of Computers and Communications, Hyperspectral Computing Laboratory, Escuela Politécnica, University of Extremadura, Cáceres, Spain; Department of Technology of Computers and Communications, Hyperspectral Computing Laboratory, Escuela Politécnica, University of Extremadura, Cáceres, Spain; Institute of New Imaging Technologies, University Jaume I, Castellón de la Plana, Spain","IEEE Transactions on Geoscience and Remote Sensing","","2018","56","11","6792","6810","Super-resolution (SR) brings an excellent opportunity to improve a wide range of different remote sensing applications. SR techniques are concerned about increasing the image resolution while providing finer spatial details than those captured by the original acquisition instrument. Therefore, SR techniques are particularly useful to cope with the increasing demand remote sensing imaging applications requiring fine spatial resolution. Even though different machine learning paradigms have been successfully applied in SR, more research is required to improve the SR process without the need of external high-resolution (HR) training examples. This paper proposes a new convolutional generator model to super-resolve low-resolution (LR) remote sensing data from an unsupervised perspective. That is, the proposed generative network is able to initially learn relationships between the LR and HR domains throughout several convolutional, downsampling, batch normalization, and activation layers. Then, the data are symmetrically projected to the target resolution while guaranteeing a reconstruction constraint over the LR input image. An experimental comparison is conducted using 12 different unsupervised SR methods over different test images. Our experiments reveal the potential of the proposed approach to improve the resolution of remote sensing imagery.","","","10.1109/TGRS.2018.2843525","Ministerio de Educación (resolución de 26 de diciembre de 2014 y de 19 de noviembre de 2015, de la Secretaría de Estado de Educación, Formación Profesional y Universidades, por la que se convocan ayudas para la formación de profesorado universitario, de los subprogramas de Formación y de Movilidad incluidos en el Programa Estatal de Promoción del Talento y su Empleabilidad, en el marco del Plan Estatal de Investigación Científica y Técnica y de Innovación 2013–2016); Consejería de Educación y Empleo, Junta de Extremadura; Generalitat Valenciana; Spanish Ministry of Economy; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8400496","Convolutional neural networks (CNNs);remote sensing;super-resolution (SR)","Spatial resolution;Remote sensing;Image reconstruction;Data models;Imaging;Training","geophysical image processing;image reconstruction;image resolution;learning (artificial intelligence);remote sensing","high-resolution training examples;convolutional generator model;low-resolution remote sensing data;unsupervised perspective;target resolution;LR input image;remote sensing imagery;unsupervised remote sensing single-image super-resolution;SR techniques;image resolution;finer spatial details;original acquisition instrument;fine spatial resolution;SR process;test images;deep generative network;remote sensing imaging applications;machine learning paradigms;unsupervised SR methods","","12","94","","","","","IEEE","IEEE Journals"
"Denoised Senone I-Vectors for Robust Speaker Verification","Z. Tan; M. Mak; B. K. Mak; Y. Zhu","Hong Kong; Hong Kong; Hong Kong; Hong Kong","IEEE/ACM Transactions on Audio, Speech, and Language Processing","","2018","26","4","820","830","Recently, it has been shown that senone i-vectors, whose posteriors are produced by senone deep neural networks (DNNs), outperform the conventional Gaussian mixture model (GMM) i-vectors in both speaker and language recognition tasks. The success of senone i-vectors relies on the capability of the DNN to incorporate phonetic information into the i-vector extraction process. In this paper, we argue that to apply senone i-vectors in noisy environments, it is important to robustify the phonetically discriminative acoustic features and senone posteriors estimated by the DNN. To this end, we propose a deep architecture formed by stacking a deep belief network on top of a denoising autoencoder (DAE). After backpropagation fine-tuning, the network, referred to as denoising autoencoder-deep neural network (DAE-DNN), facilitates the extraction of robust phonetically-discriminitive bottleneck (BN) features and senone posteriors for i-vector extraction. We refer to the resulting i-vectors as denoised BN-based senone i-vectors. Results on NIST 2012 SRE show that senone i-vectors outperform the conventional GMM i-vectors. More interestingly, the BN features are not only phonetically discriminative, results suggest that they also contain sufficient speaker information to produce BN-based senone i-vectors that outperform the conventional senone i-vectors. This work also shows that DAE training is more beneficial to BN feature extraction than senone posterior estimation.","","","10.1109/TASLP.2018.2796843","The RGC of Hong Kong SAR; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8269399","Speaker verification;i-vectors;phonetically discriminative features;senone posteriors;deep learning;denoising autoencoders;noise robustness","Feature extraction;Speech;Noise reduction;Training;Robustness;Noise measurement;Speaker recognition","acoustic signal processing;backpropagation;belief networks;feature extraction;neural nets;signal denoising;speaker recognition","denoised senone i-vectors;senone deep neural networks;i-vector extraction process;phonetically discriminative acoustic features;senone posterior estimation;noisy environments;deep architecture;deep belief network;denoising autoencoder;backpropagation fine-tuning;Speaker Verification","","1","49","","","","","IEEE","IEEE Journals"
"Towards a Generalized Approach for Deep Neural Network Based Event Processing for the Internet of Multimedia Things","A. Aslam; E. Curry","Insight Centre for Data Analytics, National University of Ireland Galway, Galway, Ireland; Insight Centre for Data Analytics, National University of Ireland Galway, Galway, Ireland","IEEE Access","","2018","6","","25573","25587","Event processing systems serve as a middleware between the Internet of Things (IoT) and the application layer by allowing users to subscribe to events of interest. Due to the increase of multimedia IoT devices (i.e. traffic camera), the types of events created are shifting more toward unstructured (multimedia) data. Therefore, there is a growing demand for efficient utilization of effective processing of streams of both structured events (i.e. sensors) and unstructured multimedia events (i.e. images, video, and audio). However, current event processing engines have limited or no support for unstructured event types. In this paper, we described a generalized approach that can handle Internet of Multimedia Things (IoMT) events as a native event type in event processing engines with high efficiency. The proposed system extends event processing languages with the introduction of operators for multimedia analysis of unstructured events and leverages a deep convolutional neural network based event matcher for processing image events to extract features. Furthermore, we show that neural network based object detection models can be further optimized by leveraging subscription constraints to reduce time complexity while maintaining competitive accuracy. Our initial results demonstrate the feasibility of a generalized approach toward IoMT-based event processing. Application areas for generalized event processing include traffic management, security, parking, and supervision activities to enhance the quality of life within smart cities.","","","10.1109/ACCESS.2018.2823590","Science Foundation Ireland; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8331844","Internet of Multimedia Things;Smart Cities;Event-Based Systems;Internet of Things;Multimedia Stream Processing;Distributed Systems;Smart Environments","Multimedia communication;Streaming media;Sensors;Smart cities","feature extraction;feedforward neural nets;Internet of Things;learning (artificial intelligence);middleware;object detection;statistical analysis","IoMT-based event processing;Internet of Multimedia Things events;deep convolutional neural network based event matcher;unstructured multimedia events;structured events;multimedia IoT devices;deep neural network based event processing;generalized event processing;neural network based object detection models;image events;multimedia analysis;event processing languages","","2","42","","","","","IEEE","IEEE Journals"
"Automatic Recognition of fMRI-Derived Functional Networks Using 3-D Convolutional Neural Networks","Y. Zhao; Q. Dong; S. Zhang; W. Zhang; H. Chen; X. Jiang; L. Guo; X. Hu; J. Han; T. Liu","Cortical Architecture Imaging and Discovery Lab Department of Computer Science and Bioimaging Research CenterUniversity of Georgia; Cortical Architecture Imaging and Discovery Lab Department of Computer Science and Bioimaging Research CenterUniversity of Georgia; Cortical Architecture Imaging and Discovery Lab Department of Computer Science and Bioimaging Research CenterUniversity of Georgia; Cortical Architecture Imaging and Discovery Lab Department of Computer Science and Bioimaging Research CenterUniversity of Georgia; Cortical Architecture Imaging and Discovery Lab Department of Computer Science and Bioimaging Research CenterUniversity of Georgia; Cortical Architecture Imaging and Discovery Lab Department of Computer Science and Bioimaging Research CenterUniversity of Georgia; School of AutomationNorthwestern Polytechnical University; School of AutomationNorthwestern Polytechnical University; School of AutomationNorthwestern Polytechnical University; Cortical Architecture Imaging and Discovery Lab Department of Computer Science and Bioimaging Research Center, University of Georgia, Athens, GA, USA","IEEE Transactions on Biomedical Engineering","","2018","65","9","1975","1984","Current functional magnetic resonance imaging (fMRI) data modeling techniques, such as independent component analysis and sparse coding methods, can effectively reconstruct dozens or hundreds of concurrent interacting functional brain networks simultaneously from the whole brain fMRI signals. However, such reconstructed networks have no correspondences across different subjects. Thus, automatic, effective, and accurate classification and recognition of these large numbers of fMRI-derived functional brain networks are very important for subsequent steps of functional brain analysis in cognitive and clinical neuroscience applications. However, this task is still a challenging and open problem due to the tremendous variability of various types of functional brain networks and the presence of various sources of noises. In recognition of the fact that convolutional neural networks (CNN) has superior capability of representing spatial patterns with huge variability and dealing with large noises, in this paper, we design, apply, and evaluate a deep 3-D CNN framework for automatic, effective, and accurate classification and recognition of large number of functional brain networks reconstructed by sparse representation of whole-brain fMRI signals. Our extensive experimental results based on the Human Connectome Project fMRI data showed that the proposed deep 3-D CNN can effectively and robustly perform functional networks classification and recognition tasks, while maintaining a high tolerance for mistakenly labeled training instances. This study provides a new deep learning approach for modeling functional connectomes based on fMRI data.","","","10.1109/TBME.2017.2715281","National Institute of Health; National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7949139","fMRI;functional brain networks;deep learning;convolutional neural networks;recognition","Three-dimensional displays;Training;Dictionaries;Image reconstruction;Robustness;Sociology;Statistics","biomedical MRI;brain;image classification;independent component analysis;learning (artificial intelligence);medical image processing;neural nets;neurophysiology","3D convolutional neural networks;functional connectomes;deep 3D CNN framework;clinical neuroscience applications;reconstructed networks;independent component analysis;current functional magnetic resonance imaging data;fMRI-derived functional networks;automatic recognition;Human Connectome Project fMRI data;whole-brain fMRI signals;automatic classification;functional brain analysis;fMRI-derived functional brain networks","","6","43","","","","","IEEE","IEEE Journals"
"Applying Deep Learning for Improving Image Classification in Nuclear Fusion Devices","G. Farias; E. Fabregas; S. Dormido-Canto; J. Vega; S. Vergara; S. D. Bencomo; I. Pastor; A. Olmedo","Escuela de Ingeniería Eléctrica, Pontificia Universidad Católica de Valparaíso, Avenida Brasil 2147, Valparaíso, Chile; Departamento de Informática y Automática, Universidad Nacional de Educación a Distancia, Madrid, Spain; Departamento de Informática y Automática, Universidad Nacional de Educación a Distancia, Madrid, Spain; Laboratorio Nacional de Fusión, CIEMAT, Madrid, Spain; Escuela de Ingeniería Eléctrica, Pontificia Universidad Católica de Valparaíso, Avenida Brasil 2147, Valparaíso, Chile; Departamento de Informática y Automática, Universidad Nacional de Educación a Distancia, Madrid, Spain; Laboratorio Nacional de Fusión, CIEMAT, Madrid, Spain; Departamento de Informática y Automática, Universidad Nacional de Educación a Distancia, Madrid, Spain","IEEE Access","","2018","6","","72345","72356","Deep learning has become one of the most promising approaches in recent years. One of the main applications of deep learning is the automatic feature extraction with auto-encoders (AEs). Feature extraction, one of the most important stages in machine learning, that can reduce drastically the dimensionality of the problem, making easier any subsequent process such as classification. The main contribution of this research is to evaluate the use of AEs for automatic feature extraction in massive thermonuclear fusion databases. In order to show the performance of AEs in a practical way, the problem of image classification of the TJ-II Thomson Scattering diagnostic has been selected. The classification has been performed by the algorithm of support vector machines and conformal predictors. The results show that the use of AEs produces the predictions faster, with more reliable models, and with higher success rates in comparison to the performance without using the deep learning approach.","","","10.1109/ACCESS.2018.2881832","Chilean Ministry of Education; Spanish Ministry of Economy and Competitiveness; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8537905","Images classification;auto-encoder;future extraction;nuclear fusion","Feature extraction;Plasmas;Fusion reactors;Databases;Scattering;Heating systems","","","","","42","","","","","IEEE","IEEE Journals"
"Dropping Activation Outputs With Localized First-Layer Deep Network for Enhancing User Privacy and Data Security","H. Dong; C. Wu; Z. Wei; Y. Guo","Department of Computing, Imperial College London, London, U.K.; Department of Computing, Imperial College London, London, U.K.; Department of Computing, Imperial College London, London, U.K.; Department of Computing, Imperial College London, London, U.K.","IEEE Transactions on Information Forensics and Security","","2018","13","3","662","670","Deep learning methods can play a crucial role in anomaly detection, prediction, and supporting decision making for applications like personal health-care, pervasive body sensing, and so on. However, current architecture of deep networks suffers the privacy issue that users need to give out their data to the model (typically hosted in a server or a cluster on Cloud) for training or prediction. This problem is getting more severe for those sensitive health-care or medical data (e.g., fMRI or body sensors measures like EEG signals). In addition to this, there is also a security risk of leaking these data during the data transmission from user to the model (especially when it is through the Internet). Targeting at these issues, in this paper, we proposed a new architecture for deep network in which users do not reveal their original data to the model. In our method, feed-forward propagation and data encryption are combined into one process: we migrate the first layer of deep network to users' local devices and apply the activation functions locally, and then use the “dropping activation output” method to make the output non-invertible. The resulting approach is able to make model prediction without accessing users' sensitive raw data. The experiment conducted in this paper showed that our approach achieves the desirable privacy protection requirement and demonstrated several advantages over the traditional approach with encryption/decryption.","","","10.1109/TIFS.2017.2763126","OPTIMISE Portal; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8070331","Artificial neural networks;data privacy","Servers;Data models;Data privacy;Encryption;Training;Computer architecture","cryptography;data privacy;decision making;electroencephalography;Internet;learning (artificial intelligence);medical information systems;patient monitoring","body sensors measures;security risk;data transmission;dropping activation output method;desirable privacy protection requirement;localized first-layer deep network;user privacy;anomaly detection;personal health-care;pervasive body sensing;current architecture;privacy issue;sensitive health-care;medical data","","4","28","","","","","IEEE","IEEE Journals"
"Humanlike Behavior Generation in Urban Environment Based on Learning-Based Potentials With a Low-Cost Lane Graph","C. Guo; K. Kidono; R. Terashima; Y. Kojima","Toyota Central R&D Laboratories, Inc., Nagakute, Japan; Toyota Central R&D Laboratories, Inc., Nagakute, Japan; Toyota Central R&D Laboratories, Inc., Nagakute, Japan; Toyota Central R&D Laboratories, Inc., Nagakute, Japan","IEEE Transactions on Intelligent Vehicles","","2018","3","1","46","60","It is crucial to understand the surrounding cars with respect to the road context and interact with them harmoniously for the success of autonomous cars used in the mixed urban traffic. In this paper, a vision-based approach is proposed to implement the humanlike autonomous driving function along a predefined lane-level route in the complex urban environment with daily traffic. At first, the surrounding cars are located in the lane level by a deep neural network based detector with a low-cost lane graph. Subsequently, a Bayesian network is employed to classify the detected cars into six categories based on their states of operation, i.e., leader car, parked car, tail-end car, exiting car, merging car, and other car. Finally, a hybrid potential map, consisting of a trajectory-induction potential and a risk-prevention potential, is constructed for each of the cars according to their categories, which will be combined to be used for generating an appropriate behavior. Particularly, both of the trajectory-induction potentials and the risk-prevention potentials are learned from naturalistic driving data of the same situations in the daily urban traffic to encode the human driving skills and experiences. Therefore, the behavior generated based on the proposed learning-based potentials is close to a humanlike performance, which is important to achieve harmony in the mixed traffic. Experimental results in various typical but challenging urban traffic scenes have substantiated the effectiveness of the proposed system.","","","10.1109/TIV.2017.2788194","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8241707","Autonomous driving;ADAS;car detection;potential field;path planning;digital map","Automobiles;Roads;Image segmentation;Urban areas;Autonomous vehicles;Global Positioning System","automobiles;Bayes methods;belief networks;computer vision;graph theory;learning (artificial intelligence);neural nets;road traffic;road vehicles;traffic engineering computing","predefined lane-level route;complex urban environment;surrounding cars;lane level;low-cost lane graph;leader car;parked car;tail-end car;hybrid potential map;trajectory-induction potential;risk-prevention potential;daily urban traffic;mixed traffic;autonomous cars;mixed urban traffic;urban traffic scenes;human like autonomous driving function;learning-based potentials;vision-based approach;deep neural network based detector;Bayesian network;exiting car;merging car;naturalistic driving data;human driving skill driving","","2","46","","","","","IEEE","IEEE Journals"
"A Learning Framework for Size and Type Independent Transient Stability Prediction of Power System Using Twin Convolutional Support Vector Machine","A. Bashiri Mosavi; A. Amiri; H. Hosseini","Department of Computer Engineering, University of Zanjan, Zanjan, Iran; Department of Computer Engineering, University of Zanjan, Zanjan, Iran; Department of Electrical Engineering, University of Zanjan, Zanjan, Iran","IEEE Access","","2018","6","","69937","69947","Real-time transient stability assessment (TSA) of power systems is an important real world problem in electrical energy engineering and pattern recognition scope. The definition of most discriminative trajectory features and proper supervised trajectory-based classifier has remained a motivational challenge for scholars vis-à-vis real-time TSA. In addition, increase in the consumption of electrical energy along with constraints such as amortization of network equipment induces electric power system inadequacy risk. The retrieval of power system adequacy involves network expansion planning such as installing new power plants for the network. This policy affects the structure and electrical specification of the network significantly. Furthermore, due to sudden or the scheduled tripping of network equipment stemming from action of protection devices or maintenance procedures, the network must undergo shallow structural changes. The different level of changes in network specification is becoming a potential barrier for network analysis tools like real-time TSA platform. In fact, the lack of consideration of the incompatibility of TSA tool with expansion planning affects the performance of TSA learning model that is trained using the preexpansion network. However, this paradoxical problem can be solved by generalized learning for power system size & type independent (PSs&tInd) real-time TSA. For this purpose, first, we used a set of PSs&tInd trajectory features. Next, we presented a trajectory-based deep neuro classifier to eliminate kernel functions weaknesses plugged into the hyperplane-based classifier. Finally, experimental comparisons were conducted to assess the efficacy of the proposed framework. The results showed that the proposed technique offered high-generalization capacity on real-time TSA during network expansion.","","","10.1109/ACCESS.2018.2880273","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8540347","Transient stability assessment (TSA);size and type independent trajectory features (s&tIF);convolutional neural network (CNN)","Power system stability;Real-time systems;Stability analysis;Transient analysis;Thermal stability;Trajectory","convolutional neural nets;learning (artificial intelligence);pattern classification;power engineering computing;power system control;power system security;power system transient stability;support vector machines","twin convolutional support vector machine;real-time transient stability assessment;electrical energy engineering;pattern recognition scope;network equipment;electric power system inadequacy risk;network expansion planning;electrical specification;network specification;network analysis tools;TSA tool;TSA learning model;trajectory-based deep neuro classifier;hyperplane-based classifier;scholars vis-a-vis real-time TSA;supervised trajectory-based classifier;power system size and type independent real-time TSA;size and type independent transient stability prediction;electrical energy consumption;network equipment stemming;protection devices;PSs&tInd trajectory features;kernel functions","","4","37","","","","","IEEE","IEEE Journals"
"Deep-Learning-Based Earth Fault Detection Using Continuous Wavelet Transform and Convolutional Neural Network in Resonant Grounding Distribution Systems","M. Guo; X. Zeng; D. Chen; N. Yang","College of Electrical Engineering and Automation, Fuzhou University, Fuzhou, China; College of Electrical Engineering and Automation, Fuzhou University, Fuzhou, China; Department of Electrical Engineering, Yuan Ze University, Chung Li, Taiwan; Department of Electrical Engineering, Yuan Ze University, Chung Li, Taiwan","IEEE Sensors Journal","","2018","18","3","1291","1300","Feature extraction for fault signals is critical and difficult in all kinds of fault detection schemes. A novel simple and effective method of faulty feeder detection in resonant grounding distribution systems based on the continuous wavelet transform (CWT) and convolutional neural network (CNN) is presented in this paper. The time-frequency gray scale images are acquired by applying the CWT to the collected transient zero-sequence current signals of the faulty feeder and sound feeders. The features of the gray scale image will be extracted adaptively by the CNN, which is trained by a large number of gray scale images under various kinds of fault conditions and factors. The features extraction and the faulty feeder detection can be implemented by the trained CNN simultaneously. As a comparison, two faulty feeder detection methods based on artificial feature extraction and traditional machine learning are introduced. A practical resonant grounding distribution system is simulated in power systems computer aided design/electromagnetic transients including DC, the effectiveness and performance of the proposed faulty feeder detection method is compared and verified under different fault circumstances.","","","10.1109/JSEN.2017.2776238","National Natural Science Foundation of China through the Project of Research of Flexible and Adaptive Arc-suppression Method for Single-Phase Grounding Fault in Distribution Networks; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8116617","Distribution systems;feature extraction;faulty feeder detection;convolutional neural network (CNN);wavelet transform","Continuous wavelet transforms;Feature extraction;Transient analysis;Time-frequency analysis;Fault detection","earthing;fault diagnosis;fault location;feature extraction;learning (artificial intelligence);neural nets;power distribution faults;power distribution protection;power engineering computing;power system transients;wavelet transforms","earth fault detection;continuous wavelet transform;convolutional neural network;resonant grounding distribution systems;fault signals;fault detection schemes;CWT;time-frequency gray scale images;collected transient zero-sequence current signals;sound feeders;gray scale image;fault conditions;features extraction;trained CNN;faulty feeder detection method;artificial feature extraction;power systems computer;resonant grounding distribution system;fault actors;fault circumstances","","18","29","","","","","IEEE","IEEE Journals"
"Oil Spill Segmentation via Adversarial  $f$ -Divergence Learning","X. Yu; H. Zhang; C. Luo; H. Qi; P. Ren","College of Information and Control Engineering, China University of Petroleum (East China), Qingdao, China; College of Engineering, Mathematics, and Physical Sciences, University of Exeter, Exeter, U.K.; College of Engineering, Mathematics, and Physical Sciences, University of Exeter, Exeter, U.K.; College of Engineering, The University of Tennessee, Knoxville, TN, USA; College of Information and Control Engineering, China University of Petroleum (East China), Qingdao, China","IEEE Transactions on Geoscience and Remote Sensing","","2018","56","9","4973","4988","We develop an automatic oil spill segmentation method in terms of f-divergence minimization. We exploit f-divergence for measuring the disagreement between the distributions of ground-truth and generated oil spill segmentations. To render tractable optimization, we minimize the tight lower bound of the f-divergence by adversarial training a regressor and a generator, which are structured in different forms of deep neural networks separately. The generator aims at producing accurate oil spill segmentation, while the regressor characterizes discriminative distributions with respect to true and generated oil spill segmentations. It is the coplay between the generator net and the regressor net against each other that achieves a minimal of the maximum lower bound for the f-divergence. The adversarial strategy enhances the representational powers of both the generator and the regressor and avoids requesting large amounts of labeled data for training the deep network parameters. In addition, the trained generator net enables automatic oil spill detection that does not require manual initialization. Benefiting from the comprehensiveness of f-divergence for characterizing diversified distributions, our framework can accurately segment variously shaped oil spills in noisy synthetic aperture radar images. Experimental results validate the effectiveness of the proposed oil spill segmentation framework.","","","10.1109/TGRS.2018.2803038","National Natural Science Foundation of China; Qingdao Applied Fundamental Research; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8301576","Adversarial learning;f-divergence minimization;oil spill segmentation;synthetic aperture radar (SAR) image processing","Oils;Image segmentation;Synthetic aperture radar;Minimization;Training;Generators;Manuals","image segmentation;learning (artificial intelligence);neural nets;oil pollution;radar imaging;synthetic aperture radar","regressor net;trained generator net;automatic oil spill detection;oil spill segmentation framework;adversarial f-divergence learning;automatic oil spill segmentation method;f-divergence minimization;generated oil spill segmentations;adversarial training","","4","35","","","","","IEEE","IEEE Journals"
"Automatic Calcium Scoring in Low-Dose Chest CT Using Deep Neural Networks With Dilated Convolutions","N. Lessmann; B. van Ginneken; M. Zreik; P. A. de Jong; B. D. de Vos; M. A. Viergever; I. Išgum","Image Sciences Institute, University Medical Center Utrecht, Utrecht University, The Netherlands; Department of Radiology and Nuclear Medicine, Diagnostic Image Analysis Group, Radboud University Medical Center, Nijmegen, GA, The Netherlands; Image Sciences Institute, University Medical Center Utrecht, Utrecht University, The Netherlands; Department of Radiology, University Medical Center Utrecht, Utrecht University, CX, The Netherlands; Image Sciences Institute, University Medical Center Utrecht, Utrecht University, The Netherlands; Image Sciences Institute, University Medical Center Utrecht, Utrecht University, The Netherlands; Image Sciences Institute, University Medical Center Utrecht, Utrecht University, The Netherlands","IEEE Transactions on Medical Imaging","","2018","37","2","615","625","Heavy smokers undergoing screening with low-dose chest CT are affected by cardiovascular disease as much as by lung cancer. Low-dose chest CT scans acquired in screening enable quantification of atherosclerotic calcifications and thus enable identification of subjects at increased cardiovascular risk. This paper presents a method for automatic detection of coronary artery, thoracic aorta, and cardiac valve calcifications in low-dose chest CT using two consecutive convolutional neural networks. The first network identifies and labels potential calcifications according to their anatomical location and the second network identifies true calcifications among the detected candidates. This method was trained and evaluated on a set of 1744 CT scans from the National Lung Screening Trial. To determine whether any reconstruction or only images reconstructed with soft tissue filters can be used for calcification detection, we evaluated the method on soft and medium/sharp filter reconstructions separately. On soft filter reconstructions, the method achieved F1 scores of 0.89, 0.89, 0.67, and 0.55 for coronary artery, thoracic aorta, aortic valve, and mitral valve calcifications, respectively. On sharp filter reconstructions, the F1 scores were 0.84, 0.81, 0.64, and 0.66, respectively. Linearly weighted kappa coefficients for risk category assignment based on per subject coronary artery calcium were 0.91 and 0.90 for soft and sharp filter reconstructions, respectively. These results demonstrate that the presented method enables reliable automatic cardiovascular risk assessment in all low-dose chest CT scans acquired for lung cancer screening.","","","10.1109/TMI.2017.2769839","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094970","Calcium scoring;low-dose chest CT;lung cancer screening;deep learning;convolutional neural networks;dilated convolutions","Calcium;Computed tomography;Arteries;Lungs;Image reconstruction;Cancer;Valves","blood vessels;calcium;cardiovascular system;computerised tomography;diseases;image filtering;image reconstruction;lung;medical image processing;neural nets","low-dose chest CT;sharp filter reconstructions;cardiovascular risk;atherosclerotic calcifications;lung cancer;cardiovascular disease;heavy smokers;dilated convolutions;deep neural networks;automatic calcium scoring;Ca","Aged;Algorithms;Aortic Valve;Aortic Valve Stenosis;Calcinosis;Coronary Artery Disease;Coronary Vessels;Humans;Lung Neoplasms;Middle Aged;Neural Networks (Computer);Radiography, Thoracic;Tomography, X-Ray Computed","6","50","","","","","IEEE","IEEE Journals"
"A Reconfigurable Streaming Deep Convolutional Neural Network Accelerator for Internet of Things","L. Du; Y. Du; Y. Li; J. Su; Y. Kuan; C. Liu; M. F. Chang","High Speed Electronics Laboratory, University of California at Los Angeles, Los Angeles, CA, USA; High Speed Electronics Laboratory, University of California at Los Angeles, Los Angeles, CA, USA; Novumind Inc., Santa Clara, CA, USA; Kneron Inc., San Diego, CA, USA; National Chiao Tung University, Hsinchu, Taiwan; High Speed Electronics Laboratory, University of California at Los Angeles, Los Angeles, CA, USA; High Speed Electronics Laboratory, University of California at Los Angeles, Los Angeles, CA, USA","IEEE Transactions on Circuits and Systems I: Regular Papers","","2018","65","1","198","208","Convolutional neural network (CNN) offers significant accuracy in image detection. To implement image detection using CNN in the Internet of Things (IoT) devices, a streaming hardware accelerator is proposed. The proposed accelerator optimizes the energy efficiency by avoiding unnecessary data movement. With unique filter decomposition technique, the accelerator can support arbitrary convolution window size. In addition, max-pooling function can be computed in parallel with convolution by using separate pooling unit, thus achieving throughput improvement. A prototype accelerator was implemented in TSMC 65-nm technology with a core size of 5 mm2. The accelerator can support major CNNs and achieve 152GOPS peak throughput and 434GOPS/W energy efficiency at 350 mW, making it a promising hardware accelerator for intelligent IoT devices.","","","10.1109/TCSI.2017.2735490","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8011462","Convolution neural network;deep learning;hardware accelerator;IoT","Convolution;Neural networks;Computer architecture;Hardware;Engines;Artificial intelligence","convolution;feature extraction;feedforward neural nets;Internet of Things;object detection;reconfigurable architectures","Internet of Things;intelligent IoT devices;separate pooling unit;unique filter decomposition technique;unnecessary data movement;streaming hardware accelerator;image detection;CNN;reconfigurable streaming deep convolutional neural network accelerator","","17","20","","","","","IEEE","IEEE Journals"
"Automatic Extraction of Built-Up Areas From Panchromatic and Multispectral Remote Sensing Images Using Double-Stream Deep Convolutional Neural Networks","Y. Tan; S. Xiong; Y. Li","National Key Laboratory of Science & Technology on Multi-Spectral Information Processing, School of Automation, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science & Technology on Multi-Spectral Information Processing, School of Automation, Huazhong University of Science and Technology, Wuhan, China; Department of Photogrammetry, School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2018","11","11","3988","4004","As the central area of human activities, built-up area has been one of the most important objects that are recognized from a remote sensing image. Built-up area in different regions has characteristics as follows: the structure and texture of the built-up area are complex and diverse; the buildings have multitudinous materials; the vegetation distribution and background around the built-up area are changeable. The existing built-up area detection methods still face the challenge to achieve favorable precision and generalization ability. In this paper, a double-stream convolutional neural network (DSCNN) model is proposed to extract the built-up area automatically, which can combine the complementary cues of high-resolution panchromatic and multispectral image. Some postprocessing steps are adopted to make the results more reasonable. We manually annotated a large-scale dataset for training and testing DSCNN. Experiments demonstrate that the proposed method has a higher overall accuracy as well as better generalization ability compared to the state-of-the-art techniques.","","","10.1109/JSTARS.2018.2871046","National Natural Science Foundation of China; China Postdoctoral Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8477097","Built-up areas extraction;double-stream convolutional neural network (DSCNN);multispectral image;panchromatic image","Remote sensing;Indexes;Feature extraction;Vegetation mapping;Data mining;Buildings;Machine learning","feature extraction;feedforward neural nets;geophysical image processing;image classification;image resolution;image texture;learning (artificial intelligence);neural nets;object detection;remote sensing","DSCNN;double-stream convolutional neural network model;built-up area;remote sensing image;central area;double-stream deep convolutional neural networks;multispectral remote sensing images","","1","47","","","","","IEEE","IEEE Journals"
"Structurally-Sensitive Multi-Scale Deep Neural Network for Low-Dose CT Denoising","C. You; Q. Yang; H. Shan; L. Gjesteby; G. Li; S. Ju; Z. Zhang; Z. Zhao; Y. Zhang; W. Cong; G. Wang","Departments of Bioengineering and Electrical Engineering, Stanford University, Stanford, CA, USA; Department of Biomedical Engineering, Rensselaer Polytechnic Institute, Troy, NY, USA; Department of Biomedical Engineering, Rensselaer Polytechnic Institute, Troy, NY, USA; Department of Biomedical Engineering, Rensselaer Polytechnic Institute, Troy, NY, USA; Department of Biomedical Engineering, Rensselaer Polytechnic Institute, Troy, NY, USA; Department of Radiology, Jiangsu Key Laboratory of Molecular and Functional Imaging, Zhongda Hospital, Medical School, Southeast University, Nanjing, China; Department of Radiology, Wuxi No.2 People’s Hospital, Wuxi, China; Department of Radiology, Jiangsu Key Laboratory of Molecular and Functional Imaging, Zhongda Hospital, Medical School, Southeast University, Nanjing, China; College of Computer Science, Sichuan University, Chengdu, China; Department of Biomedical Engineering, Rensselaer Polytechnic Institute, Troy, NY, USA; Department of Biomedical Engineering, Rensselaer Polytechnic Institute, Troy, NY, USA","IEEE Access","","2018","6","","41839","41855","Computed tomography (CT) is a popular medical imaging modality and enjoys wide clinical applications. At the same time, the X-ray radiation dose associated with CT scannings raises a public concern due to its potential risks to the patients. Over the past years, major efforts have been dedicated to the development of low-dose CT (LDCT) methods. However, the radiation dose reduction compromises the signal-to-noise ratio, leading to strong noise and artifacts that down-grade the CT image quality. In this paper, we propose a novel 3-D noise reduction method, called structurally sensitive multi-scale generative adversarial net, to improve the LDCT image quality. Specifically, we incorporate 3-D volumetric information to improve the image quality. Also, different loss functions for training denoising models are investigated. Experiments show that the proposed method can effectively preserve the structural and textural information in reference to the normal-dose CT images and significantly suppress noise and artifacts. Qualitative visual assessments by three experienced radiologists demonstrate that the proposed method retrieves more information and outperforms competing methods.","","","10.1109/ACCESS.2018.2858196","National Natural Science Foundation of China; Department of Science and Technology of Sichuan Province; National Institutes of Health; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8416740","Machine leaning;low dose CT;image denoising;deep learning;loss function","Three-dimensional displays;Computed tomography;Noise reduction;Generators;Image quality;Loss measurement;Noise measurement","computerised tomography;diagnostic radiography;dosimetry;image denoising;image texture;medical image processing;neural nets","noise suppression;loss functions;structurally sensitive multiscale generative adversarial net;3D volumetric information;novel 3D noise reduction method;medical imaging modality;artifact suppression;CT scannings;X-ray radiation dose;wide clinical applications;computed tomography;low-dose CT denoising;structurally-sensitive multiscale deep neural network;normal-dose CT images;textural information;structural information;LDCT image quality;signal-to-noise ratio;radiation dose reduction","","3","62","","","","","IEEE","IEEE Journals"
"Deep Neural Networks for the Recognition and Classification of Heart Murmurs Using Neuromorphic Auditory Sensors","J. P. Dominguez-Morales; A. F. Jimenez-Fernandez; M. J. Dominguez-Morales; G. Jimenez-Moreno","Robotic and Technology of Computers Laboratory, Department of Architecture and Technology of Computers, University of Seville, Seville, Spain; Robotic and Technology of Computers Laboratory, Department of Architecture and Technology of Computers, University of Seville, Seville, Spain; Robotic and Technology of Computers Laboratory, Department of Architecture and Technology of Computers, University of Seville, Seville, Spain; Robotic and Technology of Computers Laboratory, Department of Architecture and Technology of Computers, University of Seville, Seville, Spain","IEEE Transactions on Biomedical Circuits and Systems","","2018","12","1","24","34","Auscultation is one of the most used techniques for detecting cardiovascular diseases, which is one of the main causes of death in the world. Heart murmurs are the most common abnormal finding when a patient visits the physician for auscultation. These heart sounds can either be innocent, which are harmless, or abnormal, which may be a sign of a more serious heart condition. However, the accuracy rate of primary care physicians and expert cardiologists when auscultating is not good enough to avoid most of both type-I (healthy patients are sent for echocardiogram) and type-II (pathological patients are sent home without medication or treatment) errors made. In this paper, the authors present a novel convolutional neural network based tool for classifying between healthy people and pathological patients using a neuromorphic auditory sensor for FPGA that is able to decompose the audio into frequency bands in real time. For this purpose, different networks have been trained with the heart murmur information contained in heart sound recordings obtained from nine different heart sound databases sourced from multiple research groups. These samples are segmented and preprocessed using the neuromorphic auditory sensor to decompose their audio information into frequency bands and, after that, sonogram images with the same size are generated. These images have been used to train and test different convolutional neural network architectures. The best results have been obtained with a modified version of the AlexNet model, achieving 97% accuracy (specificity: 95.12%, sensitivity: 93.20%, PhysioNet/CinC Challenge 2016 score: 0.9416). This tool could aid cardiologists and primary care physicians in the auscultation process, improving the decision making task and reducing type-I and type-II errors.","","","10.1109/TBCAS.2017.2751545","Spanish government; Formación de Personal Universitario Scholarship; Spanish Ministry of Education, Culture and Sport; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8048493","Audio processing;Caffe;convolutional neural networks;deep learning;heart murmur;neuromorphic sensor;pattern recognition","Heart;Sensors;Neuromorphics;Medical services;Field programmable gate arrays;Neural networks;Pathology","audio signal processing;biomedical ultrasonics;cardiology;diseases;field programmable gate arrays;medical signal processing;neural nets;signal classification","sonogram images;heart sound recordings;FPGA;neuromorphic auditory sensor;convolutional neural network;heart murmur classification;heart murmur recognition;deep neural networks","Adolescent;Adult;Child;Child, Preschool;Female;Heart Murmurs;Humans;Male;Neural Networks (Computer);Signal Processing, Computer-Assisted","12","44","","","","","IEEE","IEEE Journals"
"Deep probabilistic human pose estimation","I. Petrov; V. Shakhuro; A. Konushin","Moscow State University, Russia; Moscow State University, Russia; Moscow State University, Russia","IET Computer Vision","","2018","12","5","578","585","The authors consider the problem of human pose estimation using probabilistic convolutional neural networks. They explore ways to improve human pose estimation accuracy on standard pose estimation benchmarks MPII human pose and Leeds Sports Pose (LSP) datasets using frameworks for probabilistic deep learning. Such frameworks transform deterministic neural network into a probabilistic one and allow sampling of independent and equiprobable hypotheses (different outputs) for a given input. Overlapping body parts and body joints hidden under clothes or other obstacles make the problem of human pose estimation ambiguous. In this context to get accurate estimation of joints' position they use uncertainty in network's predictions, which is represented by variance of hypotheses, provided by a probabilistic convolutional neural network, and confidence is characterised by mean of them. Their work is based on current CNN cascades for pose estimation. They propose and evaluate three probabilistic convolutional neural networks built on top of deterministic ones with two probabilistic deep learning frameworks - DISCO networks and Bayesian SegNet. The authors evaluate their models on standard pose estimation benchmarks and show that proposed probabilistic models outperform base deterministic ones.","","","10.1049/iet-cvi.2017.0382","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8418324","","","learning (artificial intelligence);neural nets;pose estimation;probability","Bayesian SegNet;DISCO networks;CNN;deterministic neural network;leeds sports pose datasets;probabilistic convolutional neural networks;deep probabilistic human pose estimation","","","25","","","","","IET","IET Journals"
"Marginalized Denoising Dictionary Learning With Locality Constraint","S. Wang; Z. Ding; Y. Fu","Department of Electrical and Computer Engineering, Northeastern University, Boston, MA, USA; Department of Electrical and Computer Engineering, Northeastern University, Boston, MA, USA; Department of Electrical and Computer Engineering and the College of Computer and Information Science, Northeastern University, Boston, MA, USA","IEEE Transactions on Image Processing","","2018","27","1","500","510","Learning good representation for images is always a hot topic in machine learning and pattern recognition fields. Among the numerous algorithms, dictionary learning is a well-known strategy for effective feature extraction. Recently, more discriminative sub-dictionaries have been built by Fisher discriminative dictionary learning with specific class labels. Different types of constraints, such as sparsity, low rankness, and locality, are also exploited to make use of global and local information. On the other hand, as the basic building block of deep structure, the auto-encoder has demonstrated its promising performance in extracting new feature representation. To this end, we develop a unified feature learning framework by incorporating the marginalized denoising auto-encoder into a locality-constrained dictionary learning scheme, named marginalized denoising dictionary learning. Overall, we deploy low-rank constraint on each sub-dictionary and locality constraint instead of sparsity on coefficients, in order to learn a more concise and pure feature spaces meanwhile inheriting the discrimination from sub-dictionary learning. Finally, we evaluate our algorithm on several face and object data sets. Experimental results have demonstrated the effectiveness and efficiency of our proposed algorithm by comparing with several state-of-the-art methods.","","","10.1109/TIP.2017.2764622","NSF IIS Award; ONR Young Investigator Award; U.S. Army Research Office Award; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8076907","Marginalized denoising auto-encoder;locality constraint;dictionary learning","Machine learning;Noise reduction;Dictionaries;Encoding;Feature extraction;Training;Noise measurement","","","","4","46","","","","","IEEE","IEEE Journals"
"Wafer Map Defect Pattern Classification and Image Retrieval Using Convolutional Neural Network","T. Nakazawa; D. V. Kulkarni","Intel Corporation, Chandler, AZ, USA; Intel Corporation, Chandler, AZ, USA","IEEE Transactions on Semiconductor Manufacturing","","2018","31","2","309","314","Wafer maps provide important information for engineers in identifying root causes of die failures during semiconductor manufacturing processes. We present a method for wafer map defect pattern classification and image retrieval using convolutional neural networks (CNNs). Twenty eight thousand six hundred synthetic wafer maps for 22 defect classes are generated theoretically and used for CNN training, validation, and testing. The overall classification accuracy for the 6600 test dataset is 98.2%. One thousand one hundred and ninety one real wafer maps are used for CNN performance evaluation for the same model trained by synthetic wafer maps. We demonstrate that by using only synthetic data for network training, real wafer maps can be classified with high accuracy. For image retrieval, a binary code for each wafer map is generated from an output of a fully connected layer with sigmoid activation. A retrieval error rate is 0.36% for the test dataset and 3.7% for the real wafers. Image retrieval takes 0.13 s per wafer map from the 18 000 wafer map library.","","","10.1109/TSM.2018.2795466","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8263132","Deep learning;convolutional neural network;information retrieval;semiconductor defects","Image retrieval;Feature extraction;Convolutional codes;Pattern classification;Training","binary codes;failure analysis;feedforward neural nets;image classification;image coding;image retrieval;learning (artificial intelligence);manufacturing processes;production engineering computing;semiconductor technology","wafer map defect pattern classification;image retrieval;convolutional neural network;synthetic wafer maps;wafer map library;die failures;semiconductor manufacturing processes;CNN training;CNN performance evaluation;binary code;sigmoid activation;retrieval error rate;time 0.13 s","","17","10","","","","","IEEE","IEEE Journals"
"An End-to-End Compression Framework Based on Convolutional Neural Networks","F. Jiang; W. Tao; S. Liu; J. Ren; X. Guo; D. Zhao","School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; Microsoft Research Asia, Beijing, China; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China","IEEE Transactions on Circuits and Systems for Video Technology","","2018","28","10","3007","3018","Deep learning, e.g., convolutional neural networks (CNNs), has achieved great success in image processing and computer vision especially in high-level vision applications, such as recognition and understanding. However, it is rarely used to solve low-level vision problems such as image compression studied in this paper. Here, we move forward a step and propose a novel compression framework based on CNNs. To achieve high-quality image compression at low bit rates, two CNNs are seamlessly integrated into an end-to-end compression framework. The first CNN, named compact convolutional neural network (ComCNN), learns an optimal compact representation from an input image, which preserves the structural information and is then encoded using an image codec (e.g., JPEG, JPEG2000, or BPG). The second CNN, named reconstruction convolutional neural network (RecCNN), is used to reconstruct the decoded image with high quality in the decoding end. To make two CNNs effectively collaborate, we develop a unified end-to-end learning algorithm to simultaneously learn ComCNN and RecCNN, which facilitates the accurate reconstruction of the decoded image using RecCNN. Such a design also makes the proposed compression framework compatible with existing image coding standards. Experimental results validate that the proposed compression framework greatly outperforms several compression frameworks that use existing image coding standards with the state-of-the-art deblocking or denoising post-processing methods.","","","10.1109/TCSVT.2017.2734838","Major State Basic Research Development Program of China (973 Program); Harbin Institute of Technology; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7999241","Deep learning;compression framework;compact representation;convolutional neural networks (CNNs)","Image coding;Transform coding;Image reconstruction;Neural networks;Codecs;Convolutional codes;Quantization (signal)","computer vision;data compression;image coding;image reconstruction;image representation;learning (artificial intelligence);neural nets","end-to-end compression framework;CNNs;image processing;computer vision;high-level vision applications;low-level vision problems;novel compression framework;high-quality image compression;input image;image codec;compact convolutional neural network;unified end-to-end learning algorithm;reconstruction convolutional neural network","","18","42","","","","","IEEE","IEEE Journals"
"Ear verification under uncontrolled conditions with convolutional neural networks","Y. Zhang; Z. Mu; L. Yuan; C. Yu","School of Automation and Electrical Engineering, University of Science and Technology Beijing, People's Republic of China; School of Automation and Electrical Engineering, University of Science and Technology Beijing, People's Republic of China; School of Automation and Electrical Engineering, University of Science and Technology Beijing, People's Republic of China; Xi'an Musheng Electronic Technology Co., Ltd, People's Republic of China","IET Biometrics","","2018","7","3","185","198","The capabilities of biometric systems have recently made extraordinary leaps by the emergence of deep learning. However, due to the lack of enough training data, the applications of the deep neural network in the ear recognition filed have run into the bottleneck. Moreover, the effect of fine-tuning from some pre-trained models is far less than expected due to the diversity among different tasks. Therefore, the authors propose a large-scale ear database and explore the robust convolutional neural network (CNN) architecture for the ear feature representation. The images in this USTB-Helloear database were taken under uncontrolled conditions with illumination, pose variation and different level of ear occlusions. Then they fine-tuned and modified some deep models on the proposed database through the ear verification experiments. First, they replaced the last pooling layers by spatial pyramid pooling layers to fit arbitrary data size and obtain multi-level features. In the training phase, the CNNs were trained both under the supervision of the softmax loss and centre loss to obtain more compact and discriminative features to identify unseen ears. Finally, three CNNs with different scales of ear images were assembled as the multi-scale ear representations for ear verification. The experimental results demonstrate the effectiveness of the proposed modified CNN deep model.","","","10.1049/iet-bmt.2017.0176","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8340919","","","biometrics (access control);convolution;ear;feature extraction;feedforward neural nets;image recognition;image representation;learning (artificial intelligence)","CNN deep model;ear verification;convolutional neural network architecture;multiscale ear representations;unseen ears;discriminative features;softmax loss;multilevel features;arbitrary data size;spatial pyramid pooling layers;ear occlusions;USTB-Helloear database;ear feature representation;large-scale ear database;ear recognition;deep neural network;deep learning;biometric systems","","1","62","","","","","IET","IET Journals"
"Deep learning of multi-element abundances from high-resolution spectroscopic data","H. W. Leung; J. Bovy","Department of Astronomy and Astrophysics, University of Toronto, 50 St. George Street, Toronto, Ontario M5S 3H4, Canada, henrysky.leung@mail.utoronto.ca; Department of Astronomy and Astrophysics, University of Toronto, 50 St. George Street, Toronto, Ontario M5S 3H4, Canada; Dunlap Institute for Astronomy and Astrophysics, University of Toronto, 50 St. George Street, Toronto, Ontario M5S 3H4, Canada; Alfred P. Sloan Fellow","Monthly Notices of the Royal Astronomical Society","","2018","483","3","3255","3277","Deep learning with artificial neural networks is increasingly gaining attention because of its potential for data-driven astronomy. However, this methodology usually does not provide uncertainties and does not deal with incompleteness and noise in the training data. In this work, we design a neural network for high-resolution spectroscopic analysis using APO Galactic Evolution Experiment (APOGEE) data that mimics the methodology of standard spectroscopic analyses: stellar parameters are determined using the full wavelength range, but individual element abundances use censored portions of the spectrum. We train this network with a customized objective function that deals with incomplete and noisy training data and apply dropout variational inference to derive uncertainties on our predictions. We determine parameters and abundances for 18 individual elements at the ${\approx } 0.03\, \mathrm{dex}$ level, even at low signal-to-noise ratio. We demonstrate that the uncertainties returned by our method are a realistic estimate of the precision and they automatically blow up when inputs or outputs outside of the training set are encountered, thus shielding users from unwanted extrapolation. By using standard deep-learning tools for GPU acceleration, our method is extremely fast, allowing analysis of the entire APOGEE data set of ≈250 000 spectra in 10 min on a single, low-cost GPU. We release the stellar parameters and 18 individual-element abundances with associated uncertainty for the entire APOGEE DR14 data set. Simultaneously, we release astroNN, a well-tested, open-source PYTHON package developed for this work, but that is also designed to be a general package for deep learning in astronomy. astroNN is available at https://github.com/henrysky/astroNN with extensive documentation at http://astroNN.readthedocs.io.","","","10.1093/mnras/sty3217","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8668880","methods: data analysis;techniques: spectroscopic;stars: abundances;stars: fundamental parameters","","","","","","","","","","","OUP","OUP Journals"
"A Simple, Fast and Highly-Accurate Algorithm to Recover 3D Shape from 2D Landmarks on a Single Image","R. Zhao; Y. Wang; A. M. Martinez","Department of Electrical and Computer Engineering, Ohio State University, Columbus, OH; Department of Electrical and Computer Engineering, Ohio State University, Columbus, OH; Department of Electrical and Computer Engineering, Ohio State University, Columbus, OH","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","12","3059","3066","Three-dimensional shape reconstruction of 2D landmark points on a single image is a hallmark of human vision, but is a task that has been proven difficult for computer vision algorithms. We define a feed-forward deep neural network algorithm that can reconstruct 3D shapes from 2D landmark points almost perfectly (i.e., with extremely small reconstruction errors), even when these 2D landmarks are from a single image. Our experimental results show an improvement of up to two-fold over state-of-the-art computer vision algorithms; 3D shape reconstruction error (measured as the Procrustes distance between the reconstructed shape and the ground-truth) of human faces is $<.004$ , cars is .0022, human bodies is .022, and highly-deformable flags is .0004. Our algorithm was also a top performer at the 2016 3D Face Alignment in the Wild Challenge competition (done in conjunction with the European Conference on Computer Vision, ECCV) that required the reconstruction of 3D face shape from a single image. The derived algorithm can be trained in a couple hours and testing runs at more than 1,000 frames/s on an i7 desktop. We also present an innovative data augmentation approach that allows us to train the system efficiently with small number of samples. And the system is robust to noise (e.g., imprecise landmark points) and missing data (e.g., occluded or undetected landmark points).","","","10.1109/TPAMI.2017.2772922","National Institutes of Health; Human Frontier Science Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8105881","3D modeling and reconstruction;fine-grained reconstruction;3D shape from a single 2D image;deep learning","Three-dimensional displays;Two dimensional displays;Image reconstruction;Neural networks;Solid modeling;Training data;Deep learning","","","","1","41","","","","","IEEE","IEEE Journals"
"Learning to Classify Blockchain Peers According to Their Behavior Sequences","H. Tang; Y. Jiao; B. Huang; C. Lin; S. Goyal; B. Wang","Institute of Chinese Financial Studies, Southwestern University of Finance and Economics, Chengdu, China; School of Computing, National University of Singapore, Singapore; Department of Computer Science, Zhejiang University, Hangzhou, China; School of Computer and Information Engineering, Zhejiang Gongshang University, Hangzhou, China; School of Computing, National University of Singapore, Singapore; Department of Computer Science, Zhejiang University, Hangzhou, China","IEEE Access","","2018","6","","71208","71215","Blockchain technologies have the potential to establish novel financial service infrastructures and reshape numerous fields. A blockchain is essentially a distributed ledger maintained by a set of peers (i.e., trading nodes) that do not fully trust each other. A key challenge that blockchain faces is to precisely classify the blockchain peers into categories with respect to their behavior patterns, which will not only enable deeper insights into the blockchain network but also facilitate more effective maintenance of the various peers (in private chains). In this paper, we introduce and formulate the problem of behavior pattern classification in blockchain networks and propose a novel deep-learning-based method, termed PeerClassifier, to address the problem. To the best of our knowledge, we are the first to formally define the problem of peer behavior classification in blockchain networks. Moreover, we conduct extensive experiments to evaluate our proposed approach. Experimental results demonstrate that PeerClassifier is significantly more effective than the existing conventional methods.","","","10.1109/ACCESS.2018.2881431","National Key R&D Program of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8540828","Classification algorithms;computer applications;time series analysis","Peer-to-peer computing;Feature extraction;Neural networks;Jitter;History;Support vector machines","cryptocurrencies;distributed databases;financial data processing;learning (artificial intelligence);neural nets;pattern classification;peer-to-peer computing","behavior sequences;blockchain technologies;financial service infrastructures;reshape numerous fields;behavior patterns;blockchain network;behavior pattern classification;deep-learning-based method;peer behavior classification;blockchain peers","","","32","","","","","IEEE","IEEE Journals"
"Structure Prediction for Gland Segmentation With Hand-Crafted and Deep Convolutional Features","S. Manivannan; W. Li; J. Zhang; E. Trucco; S. J. McKenna","University of Dundee, Dundee, U.K.; University of Dundee, Dundee, U.K.; Computer Vision and Image Processing, School of Science and Engineering, University of Dundee, Dundee, U.K.; Computer Vision and Image Processing, School of Science and Engineering, University of Dundee, Dundee, U.K.; Computer Vision and Image Processing, School of Science and Engineering, University of Dundee, Dundee, U.K.","IEEE Transactions on Medical Imaging","","2018","37","1","210","221","We present a novel method to segment instances of glandular structures from colon histopathology images. We use a structure learning approach which represents local spatial configurations of class labels, capturing structural information normally ignored by sliding-window methods. This allows us to reveal different spatial structures of pixel labels (e.g., locations between adjacent glands, or far from glands), and to identify correctly neighboring glandular structures as separate instances. Exemplars of label structures are obtained via clustering and used to train support vector machine classifiers. The label structures predicted are then combined and post-processed to obtain segmentation maps. We combine hand-crafted, multi-scale image features with features computed by a deep convolutional network trained to map images to segmentation maps. We evaluate the proposed method on the public domain GlaS data set, which allows extensive comparisons with recent, alternative methods. Using the GlaS contest protocol, our method achieves the overall best performance.","","","10.1109/TMI.2017.2750210","U.K. Engineering and Physical Sciences Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8030141","Molecular and cellular imaging;gastrointestinal tract;segmentation","Glands;Image segmentation;Feature extraction;Support vector machines;Morphology;Training","image classification;image segmentation;medical image processing;pattern clustering;public domain software;support vector machines","structure prediction;gland segmentation;hand-crafted convolutional features;deep convolutional features;glandular structures;colon histopathology images;structure learning approach;local spatial configurations;sliding-window methods;pixel labels;neighboring glandular structures;train support vector machine classifiers;label structures;multiscale image features;deep convolutional network;public domain GlaS data set","Adenocarcinoma;Colon;Colorectal Neoplasms;Histocytochemistry;Humans;Image Processing, Computer-Assisted;Intestinal Mucosa;Molecular Imaging;Support Vector Machine","2","34","","","","","IEEE","IEEE Journals"
"A Stacked Sparse Autoencoder-Based Detector for Automatic Identification of Neuromagnetic High Frequency Oscillations in Epilepsy","J. Guo; K. Yang; H. Liu; C. Yin; J. Xiang; H. Li; R. Ji; Y. Gao","Department of Electrical Engineering and Computer Science, University of Cincinnati, Cincinnati, OH, USA; Department of Neurosurgery, Nanjing Brain Hospital, Nanjing, China; Department of Neurosurgery, Nanjing Brain Hospital, Nanjing, China; Department of Neurology, Xuanwu Hospital, Beijing, China; Department of Neurology Cincinnati Children’s Hospital Medical Center, MEG Center, Cincinnati, OH, USA; Department of Pediatrics, Cincinnati Children’s Hospital Medical Center, Cincinnati, OH, USA; School of Information Science and Engineering, Xiamen University, Xiamen, China; Key Laboratory for Information System Security, Beijing National Research Center for Information Science and Technology, Ministry of Education, School of Software, Tsinghua University, Beijing, China","IEEE Transactions on Medical Imaging","","2018","37","11","2474","2482","High-frequency oscillations (HFOs) are spontaneous magnetoencephalography (MEG) patterns that have been acknowledged as a putative biomarker to identify epileptic foci. Correct detection of HFOs in the MEG signals is crucial for the accurate and timely clinical evaluation. Since the visual examination of HFOs is time-consuming, error-prone, and with poor inter-reviewer reliability, an automatic HFOs detector is highly desirable in clinical practice. However, the existing approaches for HFOs detection may not be applicable for MEG signals with noisy background activity. Therefore, we employ the stacked sparse autoencoder (SSAE) and propose an SSAE-based MEG HFOs (SMO) detector to facilitate the clinical detection of HFOs. To the best of our knowledge, this is the first attempt to conduct HFOs detection in MEG using deep learning methods. After configuration optimization, our proposed SMO detector is outperformed other classic peer models by achieving 89.9% in accuracy, 88.2% in sensitivity, and 91.6% in specificity. Furthermore, we have tested the performance consistency of our model using various validation schemes. The distribution of performance metrics demonstrates that our model can achieve steady performance.","","","10.1109/TMI.2018.2836965","National Key Research and Development Program of China; National Institute of Neurological Disorders and Stroke; National Institutes of Health; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8359295","High-frequency oscillations;MEG;SSAE;brain;deep learning model;detector","Hafnium oxide;Detectors;Feature extraction;Machine learning;Surgery;Epilepsy;Head","electroencephalography;feature extraction;learning (artificial intelligence);magnetoencephalography;medical disorders;medical signal detection;medical signal processing;neurophysiology","SMO detector;clinical detection;SSAE-based MEG HFOs detector;HFOs detection;clinical practice;automatic HFOs detector;poor inter-reviewer reliability;time-consuming;timely clinical evaluation;accurate evaluation;MEG signals;correct detection;spontaneous magnetoencephalography patterns;high-frequency oscillations;neuromagnetic high frequency oscillations;automatic identification;stacked sparse autoencoder-based detector","","1","51","","","","","IEEE","IEEE Journals"
"Multi-scale features fusion from sparse LiDAR data and single image for depth completion","B. Wang; Y. Feng; H. Liu","National University of Defense Technology, People's Republic of China; National University of Defense Technology, People's Republic of China; National University of Defense Technology, People's Republic of China","Electronics Letters","","2018","54","24","1375","1377","Recently deep learning-based methods for dense depth completion from sparse depth data have shown superior performance than traditional techniques. However, sparse depth data lose the details of the scenes, for instance, the spatial and texture information. To overcome this problem, additional single image is introduced and a multi-scale features fusion scheme to learn more correlations of the two different data is proposed. Furthermore, sparse convolution operation to improve feature robustness for sparse depth data is exploited. Experiments demonstrate that the approach obviously improves the performance for depth completion and outperforms all the previous published methods. The authors believe their works also have the guidance significance for stereo images depth estimation fused with sparse LiDAR depth data.","","","10.1049/el.2018.6149","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8556216","","","convolution;feature extraction;image fusion;image texture;learning (artificial intelligence);optical radar;stereo image processing","multiscale features fusion scheme;sparse convolution operation;sparse depth data;stereo images depth estimation;sparse LiDAR depth data;deep learning-based methods;dense depth completion;single image;feature robustness","","1","","","","","","IET","IET Journals"
"A New Convolutional Neural Network-Based Data-Driven Fault Diagnosis Method","L. Wen; X. Li; L. Gao; Y. Zhang","Wuhan, China; Wuhan, China; Wuhan, China; Wuhan, China","IEEE Transactions on Industrial Electronics","","2018","65","7","5990","5998","Fault diagnosis is vital in manufacturing system, since early detections on the emerging problem can save invaluable time and cost. With the development of smart manufacturing, the data-driven fault diagnosis becomes a hot topic. However, the traditional data-driven fault diagnosis methods rely on the features extracted by experts. The feature extraction process is an exhausted work and greatly impacts the final result. Deep learning (DL) provides an effective way to extract the features of raw data automatically. Convolutional neural network (CNN) is an effective DL method. In this study, a new CNN based on LeNet-5 is proposed for fault diagnosis. Through a conversion method converting signals into two-dimensional (2-D) images, the proposed method can extract the features of the converted 2-D images and eliminate the effect of handcrafted features. The proposed method which is tested on three famous datasets, including motor bearing dataset, self-priming centrifugal pump dataset, and axial piston hydraulic pump dataset, has achieved prediction accuracy of 99.79%, 99.481%, and 100%, respectively. The results have been compared with other DL and traditional methods, including adaptive deep CNN, sparse filter, deep belief network, and support vector machine. The comparisons show that the proposed CNN-based data-driven fault diagnosis method has achieved significant improvements.","","","10.1109/TIE.2017.2774777","Natural Science Foundation of China (NSFC); China Postdoctoral Science Foundation; 111 Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8114247","Convolutional neural network (CNN);data-driven;fault diagnosis;image classification","Fault diagnosis;Feature extraction;Monitoring;Image classification;Time-domain analysis","belief networks;fault diagnosis;feature extraction;feedforward neural nets;hydraulic systems;intelligent manufacturing systems;learning (artificial intelligence);machine bearings;mechanical engineering computing;pistons;pumps;support vector machines","conversion method;data-driven fault diagnosis method;convolutional neural network;feature extraction process;raw data;effective DL method;manufacturing system;smart manufacturing;deep learning;LeNet-5;fault diagnosis;signal conversion;two-dimensional images;handcrafted features;motor bearing dataset;self-priming centrifugal pump dataset;axial piston hydraulic pump dataset;adaptive deep CNN;sparse filter;deep belief network;support vector machine","","55","43","","","","","IEEE","IEEE Journals"
"Embedding Structured Contour and Location Prior in Siamesed Fully Convolutional Networks for Road Detection","Q. Wang; J. Gao; Y. Yuan","School of Computer Science, Unmanned System Research Institute, and with the Center for OPTical IMagery Analysis and Learning (OPTIMAL), Northwestern Polytechnical University, Xi’an, China; School of Computer Science, Northwestern Polytechnical University, Xi’an, China; School of Computer Science, Northwestern Polytechnical University, Xi’an, China","IEEE Transactions on Intelligent Transportation Systems","","2018","19","1","230","241","Road detection from the perspective of moving vehicles is a challenging issue in autonomous driving. Recently, many deep learning methods spring up for this task, because they can extract high-level local features to find road regions from raw RGB data, such as convolutional neural networks and fully convolutional networks (FCNs). However, how to detect the boundary of road accurately is still an intractable problem. In this paper, we propose siamesed FCNs (named “s-FCN-loc”), which is able to consider RGB-channel images, semantic contours, and location priors simultaneously to segment the road region elaborately. To be specific, the s-FCN-loc has two streams to process the original RGB images and contour maps, respectively. At the same time, the location prior is directly appended to the siamesed FCN to promote the final detection performance. Our contributions are threefold: 1) An s-FCN-loc is proposed that learns more discriminative features of road boundaries than the original FCN to detect more accurate road regions. 2) Location prior is viewed as a type of feature map and directly appended to the final feature map in s-FCN-loc to promote the detection performance effectively, which is easier than other traditional methods, namely, different priors for different inputs (image patches). 3) The convergent speed of training s-FCN-loc model is 30% faster than the original FCN because of the guidance of highly structured contours. The proposed approach is evaluated on the KITTI road detection benchmark and one-class road detection data set, and achieves a competitive result with the state of the arts.","","","10.1109/TITS.2017.2749964","National Key Research and Development Program of China; National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; Open Research Fund of Key Laboratory of Spectral Imaging Technology, Chinese Academy of Sciences; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8058005","Road detection;siamesed fully convolutional networks;structured contour;location prior","Roads;Feature extraction;Semantics;Image edge detection;Image segmentation","feature extraction;image colour analysis;image segmentation;learning (artificial intelligence);neural nets;object detection","KITTI road detection benchmark;one-class road detection data;structured contour;siamesed fully convolutional networks;autonomous driving;high-level local features;raw RGB data;convolutional neural networks;siamesed FCN;RGB-channel images;semantic contours;original RGB images;contour maps;road boundaries;accurate road regions;image patches;s-FCN-loc feature map;deep learning methods;road detection;structured location;discriminative features","","52","42","","","","","IEEE","IEEE Journals"
"GapFlyt: Active Vision Based Minimalist Structure-Less Gap Detection For Quadrotor Flight","N. J. Sanket; C. D. Singh; K. Ganguly; C. Fermüller; Y. Aloimonos","University of Maryland Institute for Advanced Computer Studies, College Park, USA; University of Maryland Institute for Advanced Computer Studies, College Park, USA; University of Maryland Institute for Advanced Computer Studies, College Park, USA; University of Maryland Institute for Advanced Computer Studies, College Park, USA; University of Maryland Institute for Advanced Computer Studies, College Park, USA","IEEE Robotics and Automation Letters","","2018","3","4","2799","2806","Although quadrotors, and aerial robots in general, are inherently active agents, their perceptual capabilities in literature so far have been mostly passive in nature. Researchers and practitioners today use traditional computer vision algorithms with the aim of building a representation of general applicability: a 3-D reconstruction of the scene. Using this representation, planning tasks are constructed and accomplished to allow the quadrotor to demonstrate autonomous behavior. These methods are inefficient as they are not task driven and such methodologies are not utilized by flying insects and birds. Such agents have been solving the problem of navigation and complex control for ages without the need to build a 3-D map and are highly task driven. In this letter, we propose this framework of bioinspired perceptual design for quadrotors. We use this philosophy to design a minimalist sensorimotor framework for a quadrotor to fly through unknown gaps without an explicit 3-D reconstruction of the scene using only a monocular camera and onboard sensing. We successfully evaluate and demonstrate the proposed approach in many real-world experiments with different settings and window shapes, achieving a success rate of 85% at 2.5 ms-1 even with a minimum tolerance of just 5 cm. To best of our knowledge, this is the first letter that addresses the problem of gap detection of an unknown shape and location with a monocular camera and onboard sensing.","","","10.1109/LRA.2018.2843445","Brin Family Foundation; Northrop Grumman Corporation; National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8371216","Active vision;gap detection;quadrotor;visual servoing;deep learning in robotics and automation;optical flow;tracking;collision avoidance;computer vision for automation;aerial systems: perception and autonomy;visual tracking and visual-based navigation","Three-dimensional displays;Cameras;Adaptive optics;Task analysis;Optical imaging;Solid modeling;Sensors","active vision;autonomous aerial vehicles;cameras;helicopters;image representation;mobile robots;multi-agent systems;multi-robot systems;position control;robot vision;stereo image processing","active vision;quadrotor flight;aerial robots;3-D reconstruction;3-D map;bioinspired perceptual design;minimalist sensorimotor framework;active agents;computer vision;minimalist structure-less gap detection","","5","40","","","","","IEEE","IEEE Journals"
"How Well Do Change Sequences Predict Defects? Sequence Learning from Software Changes","M. Wen; R. Wu; S. C. Cheung","Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong, Hong Kong China (e-mail: mwenaa@cse.ust.hk); Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong, Hong Kong Hong Kong (e-mail: wurongxin@cse.ust.hk); Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Clear Water Bay, Kowloon Hong Kong (e-mail: scc@cse.ust.hk)","IEEE Transactions on Software Engineering","","2018","PP","99","1","1","Software defect prediction, which aims to identify defective modules, can assist developers in finding bugs and prioritizing limited quality assurance resources. Various features to build defect prediction models have been proposed and evaluated. Among them, process metrics are one important category. Yet, existing process metrics are mainly encoded manually from change histories and ignore the sequential information arising from the changes during software evolution. Unlike traditional process metrics used for existing defect prediction models, change sequences are mostly vectors of variable length. This makes it difficult to apply such sequences directly in prediction models that are driven by conventional classifiers. To resolve this challenge, we utilize Recurrent Neural Network (RNN), which is a deep learning technique, to encode features from sequence data automatically. In this paper, we propose a novel approach called Fences, which extracts six types of change sequences covering different aspects of software changes via fine-grained change analysis. It approaches defects prediction by mapping it to a sequence labeling problem solvable by RNN. Our evaluations on 10 open source projects show that Fences can predict defects with high performance. Fences also outperforms the state-of-the-art technique which learns semantic features automatically from static code via deep learning.","","","10.1109/TSE.2018.2876256","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8493303","Defect Prediction;Process Metrics;Sequence Learning","Measurement;Software;Predictive models;Semantics;History;Machine learning;Feature extraction","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Affective Computational Model to Extract Natural Affective States of Students With Asperger Syndrome (AS) in Computer-Based Learning Environment","A. Dawood; S. Turner; P. Perepa","Department of Computing, Faculty of Art, Science, and Technology, University of Northampton, Northampton, U.K.; Department of Computing, Faculty of Art, Science, and Technology, University of Northampton, Northampton, U.K.; Department of Special Education Needs and Inclusion, Faculty of Education and Humanities, University of Northampton, Northampton, U.K.","IEEE Access","","2018","6","","67026","67034","This paper was inspired by looking at the central role of emotion in the learning process, its impact on students’ performance; as well as the lack of affective computing models to detect and infer affective-cognitive states in real time for students with and without Asperger Syndrome (AS). This model overcomes gaps in other models that were designed for people with autism, which needed the use of sensors or physiological instrumentations to collect data. The model uses a webcam to capture students’ affective-cognitive states of confidence, uncertainty, engagement, anxiety, and boredom. These states have a dominant effect on the learning process. The model was trained and tested on a natural-spontaneous affective dataset for students with and without AS, which was collected for this purpose. The dataset was collected in an uncontrolled environment and included variations in culture, ethnicity, gender, facial and hairstyle, head movement, talking, glasses, illumination changes, and background variation. The model structure used deep learning (DL) techniques like convolutional neural network and long short-term memory. The DL is the-state-of-art tool that used to reduce data dimensionality and capturing non-linear complex features from simpler representations. The affective model provides reliable results with accuracy 90.06%. This model is the first model to detected affective states for adult students with AS without physiological or wearable instruments. For the first time, the occlusions in this model, like hand over face or head were considered an important indicator for affective states like boredom, anxiety, and uncertainty. These occlusions have been ignored in most other affective models. The essential information channels in this model are facial expressions, head movement, and eye gaze. The model can serve as an aided-technology for tutors to monitor and detect the behaviors of all students at the same time and help in predicting negative affective states during learning process.","","","10.1109/ACCESS.2018.2879619","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8522016","Affective model;affective-cognitive states;autism;Asperger Syndrome;AS;CNN;deep learning;LSTM","Autism;Computational modeling;Instruments;Tools;Face recognition;Physiology","","","","1","67","CCBY","","","","IEEE","IEEE Journals"
"Text-Independent Speaker Verification Based on Triplet Convolutional Neural Network Embeddings","C. Zhang; K. Koishida; J. H. L. Hansen","Center for Robust Speech Systems, Erik Jonsson School of Engineering and Computer Science, The University of Texas at Dallas, Richardson, TX, USA; Microsoft Corporation, Redmond, WA, USA; Center for Robust Speech Systems, Erik Jonsson School of Engineering and Computer Science, The University of Texas at Dallas, Richardson, TX, USA","IEEE/ACM Transactions on Audio, Speech, and Language Processing","","2018","26","9","1633","1644","The effectiveness of introducing deep neural networks into conventional speaker recognition pipelines has been broadly shown to benefit system performance. A novel text-independent speaker verification (SV) framework based on the triplet loss and a very deep convolutional neural network architecture (i.e., Inception-Resnet-v1) are investigated in this study, where a fixed-length speaker discriminative embedding is learned from sparse speech features and utilized as a feature representation for the SV tasks. A concise description of the neural network based speaker discriminative training with triplet loss is presented. An Euclidean distance similarity metric is applied in both network training and SV testing, which ensures the SV system to follow an end-to-end fashion. By replacing the final max/average pooling layer with a spatial pyramid pooling layer in the Inception-Resnet-v1 architecture, the fixed-length input constraint is relaxed and an obvious performance gain is achieved compared with the fixed-length input speaker embedding system. For datasets with more severe training/test condition mismatches, the probabilistic linear discriminant analysis (PLDA) back end is further introduced to replace the distance based scoring for the proposed speaker embedding system. Thus, we reconstruct the SV task with a neural network based front-end speaker embedding system and a PLDA that provides channel and noise variabilities compensation in the back end. Extensive experiments are conducted to provide useful hints that lead to a better testing performance. Comparison with the state-of-the-art SV frameworks on three public datasets (i.e., a prompt speech corpus, a conversational speech Switchboard corpus, and NIST SRE10 10 s-10 s condition) justifies the effectiveness of our proposed speaker embedding system.","","","10.1109/TASLP.2018.2831456","Air Force Research Laboratory; University of Texas at Dallas from the Distinguished University Chair in Telecommunications Engineering; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8352546","Speaker recognition;very deep convolutional neutral networks;i-vector;PLDA;triplet loss;spatial pyramid pooling","Training;Neural networks;NIST;Task analysis;Speech processing;Euclidean distance","feature extraction;feedforward neural nets;learning (artificial intelligence);speaker recognition;statistical analysis","performance gain;very deep convolutional neural network architecture;neural network based speaker discriminative training;SV testing;severe test condition mismatches;severe training condition mismatches;PLDA;channel variabilities compensation;noise variabilities compensation;sparse speech features;fixed-length speaker discriminative embedding;novel text-independent speaker verification framework;system performance;conventional speaker recognition pipelines;deep neural networks;triplet convolutional neural network embeddings;testing performance;front-end speaker;probabilistic linear discriminant analysis;fixed-length input speaker embedding system;fixed-length input constraint;Inception-Resnet-v1 architecture;spatial pyramid pooling layer;end-to-end fashion;SV system;network training;Euclidean distance similarity metric;triplet loss;SV task;feature representation","","8","50","","","","","IEEE","IEEE Journals"
"Image Superresolution Using Densely Connected Residual Networks","R. Wen; K. Fu; H. Sun; X. Sun; L. Wang","Key Laboratory of Technology in Geo-Spatial Information Processing and Application System, Institute of Electronics, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Technology in Geo-Spatial Information Processing and Application System, Institute of Electronics, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Technology in Geo-Spatial Information Processing and Application System, Institute of Electronics, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Technology in Geo-Spatial Information Processing and Application System, Institute of Electronics, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Technology in Geo-Spatial Information Processing and Application System, Institute of Electronics, Chinese Academy of Sciences, Beijing, China","IEEE Signal Processing Letters","","2018","25","10","1565","1569","Recently, convolutional neural networks (CNN) have achieved impressive breakthroughs in single image superresolution. In particular, an efficient nonlinear mapping by increasing the depth and width of the network can be learned between the low-resolution input image and the high-resolution target image. However, this will lead to a substantial increase in network parameters, requiring the massive amount of training data to prevent overfitting. Besides, most CNN-based methods ignore the full use of different levels of features and, therefore, achieve relatively low performance. In this letter, we propose a deep convolutional network named densely connected residual networks (DRNet). Our proposed DRNet can reach very deep and wide while requiring fewer parameters. The significant performance improvement of our model is mainly due to the integration of dense skip connection and residual learning. In this way, DRNet mitigates the problems of overfitting, vanishing gradient, and training instability during training very deep and wide networks. Moreover, it can improve the propagation and reuse of features by creating direct connections from the previous layers to the subsequent layers. We evaluate the proposed method using images from four benchmark datasets and set a new state of the art.","","","10.1109/LSP.2018.2861989","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8424499","Convolutional neural networks (CNN);densely connected residual networks (DRNet);dense skip connection;image superresolution;residual learning","Training;Image reconstruction;Convolution;Image resolution;Signal resolution;Feature extraction;Dictionaries","image resolution;learning (artificial intelligence);neural nets","densely connected residual networks;convolutional neural networks;single image superresolution;efficient nonlinear mapping;low-resolution input image;high-resolution target image;network parameters;CNN-based methods;deep convolutional network;DRNet;dense skip connection;residual learning;wide networks;training data;vanishing gradient;overfitting problem;training instability","","1","38","","","","","IEEE","IEEE Journals"
"Deep Feature Learning for Disease Risk Assessment Based on Convolutional Neural Network With Intra-Layer Recurrent Connection by Using Hospital Big Data","M. Usama; B. Ahmad; J. Wan; M. S. Hossain; M. F. Alhamid; M. A. Hossain","Embedded and Pervasive Computing Lab, School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China; Embedded and Pervasive Computing Lab, School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China; School of Mechanical and Automotive Engineering, South China University of Technology, Guangzhou, China; Department of Software Engineering, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia; Department of Software Engineering, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia; Department of Software Engineering, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia","IEEE Access","","2018","6","","67927","67939","This paper presents the analysis of real-life medical big data obtained from a hospital in central China from 2013 to 2015 for risk assessment of cerebral infarction disease. We propose a new recurrent convolutional neural network (RCNN)-based disease risk assessment multimodel by utilizing structured and unstructured text data from the hospital. In the proposed model, the convolutional layer becomes a bidirectional recurrent neural network by utilizing the intra-layer recurrent connection within the convolutional layer. Each neuron within convolutional layer receives feedforward and recurrent inputs from the previous unit and neighborhood, respectively. In addition to step-by-step recurrent operation, the region of context capture increases, thereby facilitating fine-grain feature extraction. Furthermore, we use a data parallelism approach over multimodel data during training and testing of the proposed model. Results show that the data parallelism approach leads to fast conversion speed. The RCNN-based model works differently from the traditional convolutional neural network and other typical methods. The proposed model exhibits a prediction accuracy of 96.02%, which is higher than those of typical existing methods.","","","10.1109/ACCESS.2018.2879158","Deanship of Scientific Research, King Saud University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8519726","Convolutional neural network;feature learning;medical big data;disease risk assessment","Diseases;Feature extraction;Risk management;Medical diagnostic imaging;Hospitals;Big Data","","","","2","81","","","","","IEEE","IEEE Journals"
"Places: A 10 Million Image Database for Scene Recognition","B. Zhou; A. Lapedriza; A. Khosla; A. Oliva; A. Torralba","Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA; Universitat Oberta de Catalunya, Barcelona, Spain; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","6","1452","1464","The rise of multi-million-item dataset initiatives has enabled data-hungry machine learning algorithms to reach near-human semantic classification performance at tasks such as visual object and scene recognition. Here we describe the Places Database, a repository of 10 million scene photographs, labeled with scene semantic categories, comprising a large and diverse list of the types of environments encountered in the world. Using the state-of-the-art Convolutional Neural Networks (CNNs), we provide scene classification CNNs (Places-CNNs) as baselines, that significantly outperform the previous approaches. Visualization of the CNNs trained on Places shows that object detectors emerge as an intermediate representation of scene classification. With its high-coverage and high-diversity of exemplars, the Places Database along with the Places-CNNs offer a novel resource to guide future progress on scene recognition problems.","","","10.1109/TPAMI.2017.2723009","US National Science Foundation; Basic Research Office of the Assistant Secretary of Defense for Research and Engineering; Office of Naval Research; MIT Big Data Initiative at CSAIL; Toyota Research Institute / MIT CSAIL Joint Research Center, Google, Xerox and Amazon Awards; NVIDIA Corporation; Facebook Fellowship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7968387","Scene classification;visual recognition;deep learning;deep feature;image dataset","Databases;Visualization;Sun;Image recognition;Semantics;Context;Training","feedforward neural nets;image classification;learning (artificial intelligence);object detection;object recognition;visual databases","near-human semantic classification performance;visual object;Places Database;scene semantic categories;diverse list;Convolutional Neural Networks;Places-CNNs;object detectors;scene recognition problems;multimillion-item dataset initiatives;data-hungry machine;scene photographs;image database;scene classification","","74","44","","","","","IEEE","IEEE Journals"
"Perceptually Aware Image Retargeting for Mobile Devices","Y. Zhou; L. Zhang; C. Zhang; P. Li; X. Li","Alibaba Research Center for Complexity Sciences, Hangzhou Normal University, Hangzhou, China; College of Computer Sciences, Zhejiang University, Zhejiang, China; Computer Science Department, University of Illinois at Urbana–Champaign, Champaign, IL, USA; School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China; State Key Laboratory of Transient Optics and Photonics, Center for OPTical IMagery Analysis and Learning, Xi’an Institute of Optics and Precision Mechanics, Chinese Academy of Sciences, Xi’an, China","IEEE Transactions on Image Processing","","2018","27","5","2301","2313","Retargeting aims at adapting an original high-resolution photograph/video to a low-resolution screen with an arbitrary aspect ratio. Conventional approaches are generally based on desktop PCs, since the computation might be intolerable for mobile platforms (especially when retargeting videos). Typically, only low-level visual features are exploited, and human visual perception is not well encoded. In this paper, we propose a novel retargeting framework that rapidly shrinks a photograph/video by leveraging human gaze behavior. Specifically, we first derive a geometry-preserving graph ranking algorithm, which efficiently selects a few salient object patches to mimic the human gaze shifting path (GSP) when viewing a scene. Afterward, an aggregation-based CNN is developed to hierarchically learn the deep representation for each GSP. Based on this, a probabilistic model is developed to learn the priors of the training photographs that are marked as aesthetically pleasing by professional photographers. We utilize the learned priors to efficiently shrink the corresponding GSP of a retargeted photograph/video to maximize its similarity to those from the training photographs. Extensive experiments have demonstrated that: 1) our method requires less than 35 ms to retarget a 1024×768 photograph (or a 1280 × 720 video frame) on popular iOS/Android devices, which is orders of magnitude faster than the conventional retargeting algorithms; 2) the retargeted photographs/videos produced by our method significantly outperform those of its competitors based on a paired-comparison-based user study; and 3) the learned GSPs are highly indicative of human visual attention according to the human eye tracking experiments.","","","10.1109/TIP.2017.2779272","Natural Science Foundation of Zhejiang Province; National Natural Science Foundation of China; National Natural Science Foundation of China; National University of Singapore (Suzhou) Research Institute, Suzhou, China; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8125759","Mobile platform;retarget;perceptual;gaze behavior;deep feature;probabilistic model","Visualization;Training;Adaptation models;Mobile communication;Videos;Probabilistic logic;Semantics","graph theory;image representation;image resolution;learning (artificial intelligence);mobile handsets;target tracking;visual perception","mobile platforms;human visual perception;geometry-preserving graph ranking algorithm;training photographs;professional photographers;retargeted photograph/video;retargeted photographs/videos;mobile devices;high-resolution photograph/video;human eye tracking;human gaze behavior;retargeting algorithms","","2","61","","","","","IEEE","IEEE Journals"
"Identifying Corresponding Patches in SAR and Optical Images With a Pseudo-Siamese CNN","L. H. Hughes; M. Schmitt; L. Mou; Y. Wang; X. X. Zhu","Signal Processing in Earth Observation, Technical University of Munich, Munich, Germany; Signal Processing in Earth Observation, Technical University of Munich, Munich, Germany; Signal Processing in Earth Observation, Technical University of Munich, Munich, Germany; Signal Processing in Earth Observation, Technical University of Munich, Munich, Germany; Signal Processing in Earth Observation, Technical University of Munich, Munich, Germany","IEEE Geoscience and Remote Sensing Letters","","2018","15","5","784","788","In this letter, we propose a pseudo-siamese convolutional neural network architecture that enables to solve the task of identifying corresponding patches in very high-resolution optical and synthetic aperture radar (SAR) remote sensing imagery. Using eight convolutional layers each in two parallel network streams, a fully connected layer for the fusion of the features learned in each stream, and a loss function based on binary cross entropy, we achieve a one-hot indication if two patches correspond or not. The network is trained and tested on an automatically generated data set that is based on a deterministic alignment of SAR and optical imagery via previously reconstructed and subsequently coregistered 3-D point clouds. The satellite images, from which the patches comprising our data set are extracted, show a complex urban scene containing many elevated objects (i.e., buildings), thus providing one of the most difficult experimental environments. The achieved results show that the network is able to predict corresponding patches with high accuracy, thus indicating great potential for further development toward a generalized multisensor key-point matching procedure.","","","10.1109/LGRS.2018.2799232","China Scholarship Council; European Research Council under the EU Horizon 2020 Research and Innovation Program; Helmholtz Association under the framework of the Young Investigators Group SiPEO; German Research Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8314449","Convolutional neural networks (CNNs);data fusion;deep learning;deep matching;image matching;optical imagery;synthetic aperture radar (SAR)","Optical imaging;Adaptive optics;Synthetic aperture radar;Optical sensors;Optical interferometry;Optical distortion;Optical fiber networks","feature extraction;image classification;image matching;image registration;image representation;learning (artificial intelligence);neural nets;object detection;radar imaging;remote sensing;synthetic aperture radar","optical images;pseudosiamese CNN;pseudosiamese convolutional neural network architecture;SAR;convolutional layers;parallel network streams;binary cross entropy;automatically generated data;optical imagery;satellite images","","13","13","","","","","IEEE","IEEE Journals"
"Combining the use of CNN classification and strength-driven compression for the robust identification of bacterial species on hyperspectral culture plate images","A. Signoroni; M. Savardi; M. Pezzoni; F. Guerrini; S. Arrigoni; G. Turra","Information Engineering Department, University of Brescia, Italy; Information Engineering Department, University of Brescia, Italy; Information Engineering Department, University of Brescia, Italy; Information Engineering Department, University of Brescia, Italy; Futura Science Park – Copan Italia S.p.A., Italy; Information Engineering Department, University of Brescia, Italy","IET Computer Vision","","2018","12","7","941","949","Huge streams of diagnostic images are expected to be produced daily in the emerging field of digital microbiology imaging because of the ongoing worldwide spread of Full Laboratory Automation systems. This is redefining the way microbiologists execute diagnostic tasks. In this context, the authors want to assess the suitability and effectiveness of a deep learning approach to solve the diagnostically relevant but visually challenging task of directly identifying pathogens on bacterial growing plates. In particular, starting from hyperspectral acquisitions in the VNIR range and spatial-spectral processing of cultured plates, they approach the identification problem as the classification of computed spectral signatures of the bacterial colonies. In a highly relevant clinical context (urinary tract infections) and on a database of acquired hyperspectral images, they designed and trained a convolutional neural network for pathogen identification, assessing its performance and comparing it against conventional classification solutions. At the same time, given the expected data flow and possible conservation and transmission needs, they are interested in evaluating the combined use of classification and lossy data compression. To this end, after selecting a suitable wavelet-based compression technology, they test coding strength-driven operating points looking for configurations able to provably prevent any classification performance degradation.","","","10.1049/iet-cvi.2018.5237","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8466247","","","biomedical optical imaging;microorganisms;medical image processing;image coding;data compression;image classification;feedforward neural nets;learning (artificial intelligence);wavelet transforms","CNN classification;strength-driven compression;robust bacterial species identification;hyperspectral culture plate images;diagnostic images;digital microbiology imaging;full microbiology laboratory automation systems;deep learning approach;pathogen identification;bacterial growing plates;hyperspectral acquisitions;VNIR range;spatial-spectral processing;computed spectral signature classification;bacterial colonies;urinary tract infections;clinical context;convolutional neural network;lossy data compression;wavelet-based compression technology;coding strength-driven operating points;classification performance degradation","","","59","","","","","IET","IET Journals"
"One-Shot Learning for Robust Material Classification Using Millimeter-Wave Radar System","J. Weiß; A. Santra","Infineon Technologies AG, Neubiberg, Germany; Infineon Technologies AG, Neubiberg, Germany","IEEE Sensors Letters","","2018","2","4","1","4","Wireless classification of different types of objects and materials has great potential in industrial and consumer applications. Different materials have a unique signature of electromagnetic signals that are reflected back to the radar sensor. The two main challenges are to handle instinctive interclass differences and large intraclass variations, as well as sensor variability arising, e.g., from different wafer lots. The limited amount of training data is the limitations for conventional deep learning approaches. We propose to address the issue of material classification in such consumer context using a Siamese network that uses the distance-based similarity metric to be small for same materials and large for different materials. We demonstrate our framework by classifying five variations of four materials using a short-range 60-GHz compact radar sensor achieving an overall accuracy of 99.23%.","","","10.1109/LSENS.2018.2878041","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8509596","Sensor signals processing;60-GHz mm-wave radar;human–machine interface;material classification;one-shot learning","Human computer interaction;Radar signal processing;Convolutional neural networks;Millimeter wave radar;Radar imaging;Target recognition","","","","1","16","","","","","IEEE","IEEE Journals"
"Multi-focus image fusion through DCNN and ELM","W. W. Kong; Y. Lei","Shaanxi Key Laboratory of Network Data Analysis and Intelligent Processing, China; Engineering University of CAPF, People's Republic of China","Electronics Letters","","2018","54","22","1282","1284","The purpose of researches on multi-focus image fusion is to obtain a composed image where the objects are all captured in focus. Compared with the source images, the new one is of richer information and much better visual performance. Deep convolutional neural network (DCNN) and extreme learning machine (ELM) are combined to be a novel model (DCELM) to deal with the issue of multi-focus image fusion. First, the source images are input into DCELM. Then, ELM is responsible for generating random weights between adjacent layers. Moreover, a convolution layer followed by a pooling one forms the basic unit of DCELM, which is used to get the feature maps of the source images from different perspectives. Finally, the above features are classified via ELM, and the information in focus from the source images can be fused into the final fused image. Experimental results demonstrate that the proposed fusion method well combines the better feature extraction ability of DCNN and much faster training speed of ELM, and its performance is superior to current state-of-the-art typical ones.","","","10.1049/el.2018.5415","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8509705","","","convolution;feature extraction;feedforward neural nets;image capture;image fusion;learning (artificial intelligence)","feature extraction;deep convolutional neural network;DCELM;extreme learning machine;ELM;multifocus image fusion","","","","","","","","IET","IET Journals"
"Smart parking sensors, technologies and applications for open parking lots: a review","V. Paidi; H. Fleyeh; J. Håkansson; R. G. Nyberg","School of Technology and Business Studies, Dalarna University, Sweden; School of Technology and Business Studies, Dalarna University, Sweden; School of Technology and Business Studies, Dalarna University, Sweden; School of Technology and Business Studies, Dalarna University, Sweden","IET Intelligent Transport Systems","","2018","12","8","735","741","Parking a vehicle in traffic dense environments often leads to excess time of driving in search for free space which leads to congestions and environmental pollution. Lack of guidance information to vacant parking spaces is one reason for inefficient parking behaviour. Smart parking sensors and technologies facilitate guidance of drivers to free parking spaces thereby improving parking efficiency. Currently, no such sensors or technologies is in use for open parking lot. This study reviews the literature on the usage of smart parking sensors, technologies, applications and evaluates their applicability to open parking lots. Magnetometers, ultrasonic sensors and machine vision were few of the widely used sensors and technologies on closed parking lots. However, this study suggests a combination of machine vision, convolutional neural network or multi-agent systems suitable for open parking lots due to less expenditure and resistance to varied environmental conditions. Few smart parking applications show drivers the location of common open parking lots. No application provided real-time parking occupancy information, which is a necessity to guide them along the shortest route to free space. To develop smart parking applications for open parking lots, further research is needed in the fields of deep learning and multi-agent systems.","","","10.1049/iet-its.2017.0406","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8461275","","","intelligent transportation systems;intelligent sensors;magnetometers;ultrasonic devices;computer vision;feedforward neural nets;multi-agent systems;learning (artificial intelligence);traffic information systems","deep learning;smart parking applications;real-time parking occupancy information;environmental conditions;multiagent systems;convolutional neural network;machine vision;machine vision;ultrasonic sensors;magnetometers;parking efficiency;guidance information;congestions;environmental pollution;traffic dense environments;open parking lot;smart parking sensors","","2","51","","","","","IET","IET Journals"
"Drawing and Recognizing Chinese Characters with Recurrent Neural Network","X. Zhang; F. Yin; Y. Zhang; C. Liu; Y. Bengio","NLPR, Institute of Automation, Chinese Academy of Sciences, Beijing, P.R. China; NLPR, Institute of Automation, Chinese Academy of Sciences, Beijing, P.R. China; NLPR, Institute of Automation, Chinese Academy of Sciences, Beijing, P.R. China; NLPR, Institute of Automation, Chinese Academy of Sciences, Beijing, P.R. China; MILA Lab, University of Montreal, Montreal, QC, Canada","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","4","849","862","Recent deep learning based approaches have achieved great success on handwriting recognition. Chinese characters are among the most widely adopted writing systems in the world. Previous research has mainly focused on recognizing handwritten Chinese characters. However, recognition is only one aspect for understanding a language, another challenging and interesting task is to teach a machine to automatically write (pictographic) Chinese characters. In this paper, we propose a framework by using the recurrent neural network (RNN) as both a discriminative model for recognizing Chinese characters and a generative model for drawing (generating) Chinese characters. To recognize Chinese characters, previous methods usually adopt the convolutional neural network (CNN) models which require transforming the online handwriting trajectory into image-like representations. Instead, our RNN based approach is an end-to-end system which directly deals with the sequential structure and does not require any domain-specific knowledge. With the RNN system (combining an LSTM and GRU), state-of-the-art performance can be achieved on the ICDAR-2013 competition database. Furthermore, under the RNN framework, a conditional generative model with character embedding is proposed for automatically drawing recognizable Chinese characters. The generated characters (in vector format) are human-readable and also can be recognized by the discriminative RNN model with high accuracy. Experimental results verify the effectiveness of using RNNs as both generative and discriminative models for the tasks of drawing and recognizing Chinese characters.","","","10.1109/TPAMI.2017.2695539","Strategic Priority Research Program of the Chinese Academy of Sciences; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7903730","Recurrent neural network;LSTM;GRU;discriminative model;generative model;handwriting","Character recognition;Writing;Recurrent neural networks;Handwriting recognition;Trajectory;Shape;Standards","feature extraction;handwriting recognition;handwritten character recognition;image classification;learning (artificial intelligence);recurrent neural nets","recurrent neural network;recognizable Chinese characters;Chinese character drawing;deep learning based approach;handwriting recognition;writing systems;pictographic Chinese characters;RNN;discriminative model;domain-specific knowledge;ICDAR-2013 competition database;conditional generative model;character embedding","","18","59","","","","","IEEE","IEEE Journals"
"Two-stream neural networks to detect manipulation of JPEG compressed images","H. -. Kim; J. -. Park; D. -. Kim; H. -. Lee","Korea Advanced Institute of Science and Technology, Republic of Korea; School of Computing, Korea Advanced Institute of Science and Technology, Republic of Korea; Korea Advanced Institute of Science and Technology, Republic of Korea; School of Computing, Korea Advanced Institute of Science and Technology, Republic of Korea","Electronics Letters","","2018","54","6","354","355","With the rapid spread of image editing software, anyone can easily create, distribute, and forge images. Although techniques to detect image forgery have been widely studied, current techniques have significant limitations, such as specific file formats, manipulations, or compression qualities. Although deep learning techniques have been introduced to detect various manipulations, such as blurring, median filtering, and Gaussian noise, these techniques are only suitable to detect forgeries of uncompressed images, and are difficult to apply in practice because most images are compressed for distribution. Therefore, a two-stream neural network approach for image forensics that is robust to compression is proposed. The two-stream neural network is based on constrained convolutional neural network and Markov characteristics to consider compression. Experimental results show that the proposed method overcomes current technique limitations.","","","10.1049/el.2017.4444","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8320123","","","data compression;image coding;image forensics;learning (artificial intelligence);neural nets","two-stream neural network approach;image forensics;constrained convolutional neural network;current technique limitations;-stream neural networks;rapid spread;image editing software;image forgery;current techniques;significant limitations;specific file formats;manipulations;compression qualities;deep learning techniques;median filtering;Gaussian noise;forgeries;uncompressed images","","","","","","","","IET","IET Journals"
"Masked AES PUF: a new PUF against hybrid SCA/MLAs","W. Yu; J. Chen","Old Dominion University, USA; University of Minnesota Twin Cities, USA","Electronics Letters","","2018","54","10","618","620","A masked advanced encryption standard (AES) physical unclonable function (PUF) architecture is proposed for hardware authentication against hybrid side-channel (SCA) and machine-learning attacks (MLAs). The random mismatches of the load capacitance of the masked substitution-boxes in the AES cryptographic circuit induced by the fabrication process are utilised for generating the critical-authentication data against SCAs. Moreover, a mask data is added to the input challenge data to mask the actual input data of the proposed PUF against MLAs. As demonstrated in the results, the masked AES PUF proposed shows a nearly 51.1% uniformity, 50.7% inter-Hamming distance, and 98.1% reliability. Furthermore, if a hybrid SCA/MLA is performed on the proposed PUF by combining the corresponding side-channel leakage with the deep neural network algorithm, the prediction rate of the output responses of the masked AES PUF is only 55.2% after 100,000 number of challenge-to-response pairs are used for training.","","","10.1049/el.2018.0735","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8358895","","","cryptography;learning (artificial intelligence);neural nets","masked AES PUF architecture;masked advanced encryption standard physical unclonable function;hardware authentication;hybrid side-channel attacks;SCA;machine-learning attacks;MLA;load capacitance;masked substitution-boxes;AES cryptographic circuit;fabrication process;critical-authentication data;mask data;input challenge data;actual input data;side-channel leakage;deep neural network algorithm;prediction rate;challenge-to-response pairs","","4","6","","","","","IET","IET Journals"
"RESC-net: reconstruction error as skip connection for stereo matching","Y. Feng; Z. Liang; H. Liu","National University of Defense Technology, People's Republic of China; National University of Defense Technology, People's Republic of China; National University of Defense Technology, People's Republic of China","Electronics Letters","","2018","54","23","1330","1332","Recently, the stereo matching task has been dramatically promoted by the deep learning methods. Specifically, the encoder–decoder framework with skip connection achieves outstanding performance over others. The skip connection scheme can bring detailed or in other words, residual information for the final prediction, thus improves the performance, which is successfully applied in many other pixel-wise prediction tasks, such as semantic segmentation, depth estimation and so on. In contrast to other tasks, the authors can explicitly obtain the residual information for stereo matching, which is achieved by back-warping the right image and calculating the reconstruction error. The reconstruction error is successfully used as unsupervised loss, but has not been explored for skip connection. In this Letter, the authors show that the reconstruction error in the feature space is very helpful to bring residual information for the final prediction. They validate the effectiveness of using reconstruction error for skip connection by conducting experiments on the KITTI 2015 and Scene Flow datasets. Experiments show that the proposed scheme can improve the performance by a notable margin and achieves the state-of-the-art performance with very fast processing time.","","","10.1049/el.2018.5905","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8645745","","","decoding;image matching;stereo image processing;image segmentation;learning (artificial intelligence);image sequences;feature extraction","reconstruction error;stereo matching task;deep learning methods;encoder–decoder framework;skip connection achieves outstanding performance;skip connection scheme;residual information;final prediction;pixel-wise prediction tasks","","","6","","","","","IET","IET Journals"
"Radar-ID: human identification based on radar micro-Doppler signatures using deep convolutional neural networks","P. Cao; W. Xia; M. Ye; J. Zhang; J. Zhou","Nanjing University of Aeronautics and Astronautics, People's Republic of China; Nanjing University of Aeronautics and Astronautics, People's Republic of China; Nanjing University of Aeronautics and Astronautics, People's Republic of China; Nanjing University of Aeronautics and Astronautics, People's Republic of China; Nanjing University of Aeronautics and Astronautics, People's Republic of China","IET Radar, Sonar & Navigation","","2018","12","7","729","734","Human identification is crucial in various applications, including terrorist attack preventing, criminal seeking, defence and so on. Traditional human identification methods are usually based on vision, biological features, radio-frequency identification cards and so on. In this study, the authors propose an identification method based on radar micro-Doppler signatures using deep convolutional neural networks (DCNNs) for the first time, which can identify human in non-contact, remote and no lighting status. They employ a K-band Doppler radar to acquire the raw signals due to its stationary clutter rejection and movement detection ability as well as its short wavelength which can generate larger Doppler shift. Then short-time Fourier transform is applied to the raw signals to characterise micro-Doppler signatures. They adopt the DCNNs to deal with the spectrograms for human identification problem. The DCNNs can learn the necessary features and classification conditions from raw micro-Doppler spectrograms without employing any explicit features. While the traditional supervised learning techniques relying on the extracted features require domain knowledge of each problem. It is shown that this method can achieve average accuracy ~97.1% for 4 people, 90.9% for 6 people, 89.1% for 8 people, 85.6% for 10 people, 77.4% for 12 people, 72.6% for 16 people and 68.9% for 20 people.","","","10.1049/iet-rsn.2017.0511","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8388798","","","Doppler radar;Doppler shift;feature extraction;Fourier transforms;image classification;learning (artificial intelligence);neural nets;pattern classification;radar imaging","radar-ID;radar microDoppler signatures;deep convolutional neural networks;biological features;radio-frequency identification cards;DCNNs;K-band Doppler radar;stationary clutter rejection;movement detection ability;larger Doppler shift;short-time Fourier transform;human identification problem;classification conditions;microDoppler spectrograms;human identification methods","","7","26","","","","","IET","IET Journals"
"Body Structure Aware Deep Crowd Counting","S. Huang; X. Li; Z. Zhang; F. Wu; S. Gao; R. Ji; J. Han","College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China; College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China; School of Information Science and Technology, ShanghaiTech University, Shanghai, China; School of Information Science and Engineering, Xiamen University, Xiamen, China; School of Automation, Northwestern Polytechnical University, Xi’an, China","IEEE Transactions on Image Processing","","2018","27","3","1049","1059","Crowd counting is a challenging task, mainly due to the severe occlusions among dense crowds. This paper aims to take a broader view to address crowd counting from the perspective of semantic modeling. In essence, crowd counting is a task of pedestrian semantic analysis involving three key factors: pedestrians, heads, and their context structure. The information of different body parts is an important cue to help us judge whether there exists a person at a certain position. Existing methods usually perform crowd counting from the perspective of directly modeling the visual properties of either the whole body or the heads only, without explicitly capturing the composite body-part semantic structure information that is crucial for crowd counting. In our approach, we first formulate the key factors of crowd counting as semantic scene models. Then, we convert the crowd counting problem into a multi-task learning problem, such that the semantic scene models are turned into different sub-tasks. Finally, the deep convolutional neural networks are used to learn the sub-tasks in a unified scheme. Our approach encodes the semantic nature of crowd counting and provides a novel solution in terms of pedestrian semantic analysis. In experiments, our approach outperforms the state-of-the-art methods on four benchmark crowd counting data sets. The semantic structure information is demonstrated to be an effective cue in scene of crowd counting.","","","10.1109/TIP.2017.2740160","NSFC; Fundamental Research Funds for Central Universities in China; Zhejiang Provincial Engineering Research Center on media data cloud processing and analysis technologies; ZJU Converging Media Computing Laboratory; Key Program of Zhejiang Province; National Basic Research Program of China; Alibaba-Zhejiang University Joint Institute of Frontier Technologies; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8010465","Crowd counting;pedestrian semantic analysis;visual context structure;convolutional neural networks","Semantics;Head;Visualization;Neural networks;Detectors;Estimation;Information science","learning (artificial intelligence);neural nets;object detection","body structure aware deep crowd counting;crowd counting problem;semantic scene models;composite body-part semantic structure information;pedestrian semantic analysis","","6","50","","","","","IEEE","IEEE Journals"
"Deep Age Estimation: From Classification to Ranking","S. Chen; C. Zhang; M. Dong","Department of Computer Science, Wayne State University, Detroit, MI, USA; Department of Mathematics, Wayne State University, Detroit, MI, USA; Department of Computer Science, Wayne State University, Detroit, MI, USA","IEEE Transactions on Multimedia","","2018","20","8","2209","2222","Human age is considered an important biometric trait for human identification or search. Recent research shows that the aging features deeply learned from large-scale data lead to significant performance improvement on facial image-based age estimation. However, age-related ordinal information is totally ignored in these approaches. In this paper, we propose a novel convolutional neural network (CNN)-based framework, ranking-CNN, for age estimation. Ranking-CNN contains a set of basic CNNs, each of which is trained with ordinal age labels. Then, their binary outputs are aggregated for the final age prediction. From a theoretical perspective, we obtain an approximation for the final ranking error, show that it is controlled by the maximum error produced among subranking problems, and thus find a new error bound, which provides helpful guidance for the training and analysis of deep rankers. Based on the new error bound, we theoretically give an explicit formula for the learning of ranking-CNN and demonstrate its convergence using the stochastic approximation method. Moreover, we rigorously prove that ranking-CNN, by considering ordinal relation between ages, is more likely to get smaller estimation errors when compared with multiclass classification approaches. Through extensive experiments, we show that ranking-CNN outperforms other state-of-the-art feature extractors and age estimators on benchmark datasets.","","","10.1109/TMM.2017.2786869","National Science Foundation; Ford Motor Company University Research Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239663","Age estimation;convolutional neural networks;ranking algorithms;error bound;convergence","Estimation;Aging;Feature extraction;Convergence;Support vector machines;Computer architecture","approximation theory;biometrics (access control);convergence;convolution;error analysis;face recognition;feature extraction;feedforward neural nets;image classification;learning (artificial intelligence);regression analysis;stochastic processes","human age;human identification;facial image-based age estimation;ranking-CNN;final age prediction;smaller estimation errors;deep age estimation;classification;feature extractors;stochastic approximation method;new error bond;biometric trait;convolutional neural network-based framework","","4","79","","","","","IEEE","IEEE Journals"
"Simultaneous bearing fault diagnosis and severity detection using a LAMSTAR network-based approach","M. He; D. He","University of Illinois at Chicago, USA; University of Illinois at Chicago, USA","IET Science, Measurement & Technology","","2018","12","7","893","901","Bearings are one of the most important components in many industrial machines. Effective bearing fault diagnosis and severity detection are critical for keeping the machines operate normally and safe. In this study, the problem of simultaneous bearing fault diagnosis and severity detection with deep learning is addressed. Existing solutions developed using deep learning rely on fault feature extraction using complicated signal processing techniques. They perform bearing fault diagnosis and severity detection separately and normally require extensive supervised fine tuning. This study presents an effective deep learning-based solution using a large memory storage and retrieval (LAMSTAR) neural network. The developed approach can automatically extract self-learned fault features and perform bearing fault diagnosis and severity detection simultaneously. The structure of the LAMSTAR network is determined by optimally selecting the sliding box size of the input time-frequency matrix. The effectiveness of the proposed approach is validated using data collected from rolling element bearing tests.","","","10.1049/iet-smt.2017.0528","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8474993","","","condition monitoring;fault diagnosis;feature extraction;learning (artificial intelligence);machine bearings;mechanical engineering computing;neural nets;rolling bearings;signal processing","LAMSTAR neural network;large memory storage and retrieval;input time-frequency matrix;bearing severity detection;deep learning;bearing fault diagnosis;self-learned fault features;memory storage;fault feature extraction;element bearing tests","","","23","","","","","IET","IET Journals"
"Lightweight Tag-Aware Personalized Recommendation on the Social Web Using Ontological Similarity","Z. Xu; O. Tifrea-Marciuska; T. Lukasiewicz; M. V. Martinez; G. I. Simari; C. Chen","Department of Computer Science, University of Oxford, Oxford, U.K.; Bloomberg, London, U.K.; Department of Computer Science, University of Oxford, Oxford, U.K.; Departamento de Ciencias e Ingenieria de la Computacion, Universidad Nacional del Sur (UNS), Bahia Blanca, Argentina; Departamento de Ciencias e Ingenieria de la Computacion, Universidad Nacional del Sur (UNS), Bahia Blanca, Argentina; China Academy of Electronics and Information Technology, Beijing, China","IEEE Access","","2018","6","","35590","35610","With the rapid growth of social tagging systems, many research efforts are being put into personalized search and recommendation using social tags (i.e., folksonomies). As users can freely choose their own vocabulary, social tags can be very ambiguous (for instance, due to the use of homonyms or synonyms). Machine learning techniques (such as clustering and deep neural networks) are usually applied to overcome this tag ambiguity problem. However, the machine-learning-based solutions always need very powerful computing facilities to train recommendation models from a large amount of data, so they are inappropriate to be used in lightweight recommender systems. In this paper, we propose an ontological similarity to tackle the tag ambiguity problem without the need of model training by using contextual information. The novelty of this ontological similarity is that it first leverages external domain ontologies to disambiguate tag information, and then semantically quantifies the relevance between user and item profiles according to the semantic similarity of the matching concepts of tags in the respective profiles. Our experiments show that the proposed ontological similarity is semantically more accurate than the state-of-the-art similarity metrics, and can thus be applied to improve the performance of content-based tag-aware personalized recommendation on the social web. Consequently, as a model-training-free solution, ontological similarity is a good disambiguation choice for lightweight recommender systems and a complement to machine-learning-based recommendation solutions.","","","10.1109/ACCESS.2018.2850762","Engineering and Physical Sciences Research Council; Engineering and Physical Sciences Research Council; Engineering and Physical Sciences Research Council; Google European Doctoral Fellowship; Yahoo Research Fellowship; Universidad Nacional del Sur; EU H2020 Research And Innovation Program for the project “MIREL” under the Marie Sklodowska-Curie; Office of Naval Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8396258","Folksonomies;ontological similarity;personalized recommendation;social tags","Recommender systems;Tagging;Ontologies;Semantics;Measurement;Computational modeling;Machine learning","information retrieval;learning (artificial intelligence);ontologies (artificial intelligence);recommender systems","similarity metrics;domain ontologies;machine-learning-based recommendation solutions;content-based tag-aware personalized recommendation;semantic similarity;tag information;lightweight recommender systems;recommendation models;machine-learning-based solutions;tag ambiguity problem;machine learning techniques;social tags;personalized search;social tagging systems;ontological similarity;social web;lightweight tag-aware personalized recommendation","","2","69","","","","","IEEE","IEEE Journals"
"A Neural Network-Based Ensemble Approach for Spam Detection in Twitter","S. Madisetty; M. S. Desarkar","Department of Computer Science and Engineering, IIT Hyderabad, Hyderabad, India; Department of Computer Science and Engineering, IIT Hyderabad, Hyderabad, India","IEEE Transactions on Computational Social Systems","","2018","5","4","973","984","As the social networking sites get more popular, spammers target these sites to spread spam posts. Twitter is one of the most popular online social networking sites where users communicate and interact on various topics. Most of the current spam filtering methods in Twitter focus on detecting the spammers and blocking them. However, spammers can create a new account and start posting new spam tweets again. So there is a need for robust spam detection techniques to detect the spam at tweet level. These types of techniques can prevent the spam in real time. To detect the spam at tweet level, often features are defined, and appropriate machine learning algorithms are applied in the literature. Recently, deep learning methods are showing fruitful results on several natural language processing tasks. We want to use the potential benefits of these two types of methods for our problem. Toward this, we propose an ensemble approach for spam detection at tweet level. We develop various deep learning models based on convolutional neural networks (CNNs). Five CNNs and one feature-based model are used in the ensemble. Each CNN uses different word embeddings (Glove, Word2vec) to train the model. The feature-based model uses content-based, user-based, and n-gram features. Our approach combines both deep learning and traditional feature-based models using a multilayer neural network which acts as a meta-classifier. We evaluate our method on two data sets, one data set is balanced, and another one is imbalanced. The experimental results show that our proposed method outperforms the existing methods.","","","10.1109/TCSS.2018.2878852","Visvesvaraya Ph.D. Scheme of Ministry of Electronics and Information Technology, Government of India; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8540077","Classification;social media;spam detection;Twitter","Twitter;Unsolicited electronic mail;Feature extraction;Convolutional neural networks;Social network services","convolutional neural nets;learning (artificial intelligence);natural language processing;pattern classification;social networking (online);unsolicited e-mail","multilayer neural network;deep learning models;convolutional neural networks;feature-based model;user-based features;online social networking sites;Twitter;spam detection;machine learning;n-gram features;CNN;natural language processing;neural network-based ensemble","","5","45","","","","","IEEE","IEEE Journals"
"Probe Efficient Feature Representation of Gapped K-mer Frequency Vectors from Sequences using Deep Neural Networks","Z. Cao; S. Zhang","Institute of Systems Science Academy of Mathematics and Systems Science Chinese Academy of Sciences, 74693 Beijing, Beijing China (e-mail: cz@amss.ac.cn); Academy of Mathematics and Systems Science, CAS, Beijing, Beijing China (e-mail: zsh@amss.ac.cn)","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2018","PP","99","1","1","Gapped k-mers frequency vectors (gkm-fv) has been presented for extracting sequence features. Coupled with support vector machine (gkm-SVM), gkm-fvs have been used to achieve effective sequence-based predictions. However, the huge computation of a large kernel matrix prevents it from using large amount of data. And it is unclear how to combine gkm-fvs with other data sources in the context of string kernel. On the other hand, the high dimensionality, colinearity and sparsity of gkm-fvs hinder the use of many traditional machine learning methods without a kernel trick. Therefore, we proposed a flexible and scalable framework gkm-DNN to achieve feature representation from high-dimensional gkm-fvs using deep neural networks (DNN). We first proposed a more concise version of gkm-fvs, which significantly reduce the dimension of gkm-fvs. Then we implemented an efficient method to calculate the gkm-fv of a given sequence at the first time. Finally, we adopted a DNN model with gkm-fvs as inputs to achieve efficient feature representation and a prediction task. Here, we took the transcription factor binding site prediction as an illustrative application and applied gkm-DNN onto 467 small and 69 big human ENCODE ChIP-seq datasets to demonstrate its performance and compared it with the state-of-the-art method gkm-SVM.","","","10.1109/TCBB.2018.2868071","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453009","Bioinformatics;machine learning;gapped k-mer;deep neural network;transcription factor binding site prediction","DNA;Bioinformatics;Kernel;Feature extraction;Support vector machines;Genomics;Task analysis","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Human in the Loop: Distributed Deep Model for Mobile Crowdsensing","L. Li; K. Ota; M. Dong","Department of Information and Electronic Engineering, Muroran Institute of Technology, Muroran, Japan; Department of Information and Electronic Engineering, Muroran Institute of Technology, Muroran, Japan; Department of Information and Electronic Engineering, Muroran Institute of Technology, Muroran, Japan","IEEE Internet of Things Journal","","2018","5","6","4957","4964","With the proliferation of mobile devices, crowdsensing has become an appealing technique to collect and process big data. Meanwhile, the rise of fifth generation wireless systems, especially the new cellular base stations with computing ability, brings about the revolutionary edge computing. Although many approaches regarding the mobile crowdsensing have emerged in the last few years, very few of them are focused on the combination of edge computing and crowdsensing. In this paper, we adopt the state-of-the-art edge computing method to solve the crowdsensing problem with the real-time sensing data, and more importantly, make human be in the loop again, in order to respect the users’ willing and privacy. A distributed deep learning model is adopted to extract features from the captured data, which is not only a compression process to reduce the communication cost, but an encryption procedure for safety protection. The proposed model enables the crowdsensing system to fully harness the computing capacity of edge nodes and devices, and obtain a strong data analysis ability to process the captured data. Simulations demonstrate that our approach is robust and efficient, and outperforms other strategies in several related tasks.","","","10.1109/JIOT.2018.2883318","Japan Society for the Promotion of Science; KDDI Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8543832","Big data;crowdsensing;deep learning;edge computing;human-driven","Edge computing;Servers;Task analysis;Computational modeling;Cloud computing;Intelligent sensors","","","","1","30","","","","","IEEE","IEEE Journals"
"Attention-Based Relation Extraction With Bidirectional Gated Recurrent Unit and Highway Network in the Analysis of Geological Data","X. Luo; W. Zhou; W. Wang; Y. Zhu; J. Deng","School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China; School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China; School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China; Key Laboratory of Geological Information Technology, Ministry of Land and Resources, Beijing, China; School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China","IEEE Access","","2018","6","","5705","5715","Attention-based deep learning model as a human-centered smart technology has become the state-of-the-art method in addressing relation extraction, while implementing natural language processing. How to effectively improve the computational performance of that model has always been a research focus in both academic and industrial communities. Generally, the structures of model would greatly affect the final results of relation extraction. In this article, a deep learning model with a novel structure is proposed. In our model, after incorporating the highway network into a bidirectional gated recurrent unit, the attention mechanism is additionally utilized in an effort to assign weights of key issues in the network structure. Here, the introduction of highway network could enable the proposed model to capture much more semantic information. Experiments on a popular benchmark data set are conducted, and the results demonstrate that the proposed model outperforms some existing relation extraction methods. Furthermore, the performance of our method is also tested in the analysis of geological data, where the relation extraction in Chinese geological field is addressed and a satisfactory display result is achieved.","","","10.1109/ACCESS.2017.2785229","Key Laboratory of Geological Information Technology, Ministry of Land and Resources; Fundamental Research Funds for the China Central Universities, University of Science and Technology Beijing; National Key Technologies Research and Development Program of China; National Natural Science Foundation of China; National Key Research and Development Program of China; University of Science and Technology Beijing–National Taipei University of Technology Joint Research Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8240917","Relation extraction;bidirectional gated recurrent unit (BGRU);highway network;attention;geological data","Feature extraction;Road transportation;Geology;Machine learning;Computational modeling;Data mining","data analysis;geology;geophysics computing;learning (artificial intelligence);natural language processing","deep learning model;human-centered smart technology;state-of-the-art method;natural language processing;highway network;bidirectional gated recurrent unit;attention mechanism;network structure;existing relation extraction methods;geological data analysis;attention-based relation extraction;semantic information;Chinese geological field","","8","41","","","","","IEEE","IEEE Journals"
"Optimizing Neural Network as Locomotion Controller With Motion Data","S. Guo; W. Jiang; X. Gao; M. Wang; M. Liao","School of Software, Xiamen University, Xiamen, China; School of Software, Xiamen University, Xiamen, China; School of Software, Xiamen University, Xiamen, China; College of Information Engineering, Northwest A&F University, Xianyang, China; School of Software, Xiamen University, Xiamen, China","IEEE Access","","2018","6","","26949","26957","This paper proposes a novel method of optimizing locomotion controller for virtual characters, which is constructed with the deep neural network and learned with the assistance of existing motion data. The learning is accomplished with a progressive reward function by starting from a simple reward function and gradually imposing advanced requirements on the gait pattern. A multi-critic model is proposed to address the dynamically changing reward function by evaluating the individual goal in a separate fashion. This strategy proves effective in avoiding the local minima that are likely to occur when a set of weighted reward functions are introduced at the beginning of the optimization. The results show that the integration of motion data not only ensures the consistency between the synthetic and original motions but also accelerates the learning of network parameters. We demonstrate the application of our method to a variety of virtual characters (cheetah, hopper, 2-D walker, and 3-D humanoid) performing various tasks (walking, running, jumping, and traversing at different velocities and across uneven terrains).","","","10.1109/ACCESS.2018.2834380","National Natural Science Foundation of China; National Key Technology Research and Development Program; China Postdoctoral Science Foundation; People Programme (Marie Curie Actions) of the EU FP7/2007-2013; Natural Science Foundation of Fujian Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8356026","Character animation;deep neural network;motion capture data","Neural networks;Task analysis;Optimization;Three-dimensional displays;Biological system modeling;Acceleration;Two dimensional displays","computer animation;learning (artificial intelligence);legged locomotion;motion control;neural nets;optimisation;virtual reality","virtual character animation;virtual character motion;learning;neural network optimization;weighted reward functions;multicritic model;progressive reward function;deep neural network;motion data;locomotion controller","","","24","","","","","IEEE","IEEE Journals"
"A Densely Connected End-to-End Neural Network for Multiscale and Multiscene SAR Ship Detection","J. Jiao; Y. Zhang; H. Sun; X. Yang; X. Gao; W. Hong; K. Fu; X. Sun","Key Laboratory of Technology in Geo-Spatial Information Processing and Application System, Institute of Electronics, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Technology in Geo-Spatial Information Processing and Application System, Institute of Electronics, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Technology in Geo-Spatial Information Processing and Application System, Institute of Electronics, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Technology in Geo-Spatial Information Processing and Application System, Institute of Electronics, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Technology in Geo-Spatial Information Processing and Application System, Institute of Electronics, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Technology in Geo-Spatial Information Processing and Application System, Institute of Electronics, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Technology in Geo-Spatial Information Processing and Application System, Institute of Electronics, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Technology in Geo-Spatial Information Processing and Application System, Institute of Electronics, Chinese Academy of Sciences, Beijing, China","IEEE Access","","2018","6","","20881","20892","Synthetic aperture radar (SAR) images have been widely used for ship monitoring. The traditional methods of SAR ship detection are difficult to detect small scale ships and avoid the interference of inshore complex background. Deep learning detection methods have shown great performance on various object detection tasks recently but using deep learning methods for SAR ship detection does not show an excellent performance it should have. One of the important reasons is that there is no effective model to handle the detection of multiscale ships in multiresolution SAR images. Another important reason is it is difficult to handle multiscene SAR ship detection including offshore and inshore, especially it cannot effectively distinguish between inshore complex background and ships. In this paper, we propose a densely connected multiscale neural network based on faster-RCNN framework to solve multiscale and multiscene SAR ship detection. Instead of using a single feature map to generate proposals, we densely connect one feature map to every other feature maps from top to down and generate proposals from each fused feature map. In addition, we propose a training strategy to reduce the weight of easy examples in the loss function, so that the training process more focus on the hard examples to reduce false alarm. Experiments on expanded public SAR ship detection dataset, verify the proposed method can achieve an excellent performance on multiscale SAR ship detection in multiscene.","","","10.1109/ACCESS.2018.2825376","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8334534","Ship detection;multiscale;neural network;synthetic aperture radar (SAR)","Marine vehicles;Feature extraction;Synthetic aperture radar;Proposals;Object detection;Machine learning;Image resolution","learning (artificial intelligence);object detection;radar imaging;recurrent neural nets;ships;synthetic aperture radar","densely connected multiscale neural network;multiscene SAR ship detection;expanded public SAR ship detection dataset;multiscale SAR ship detection;densely connected end-to-end neural network;synthetic aperture radar images;ship monitoring;inshore complex background;object detection tasks;multiresolution SAR images;deep learning detection methods;faster-RCNN framework;fused feature map","","17","38","","","","","IEEE","IEEE Journals"
"Training Simplification and Model Simplification for Deep Learning: A Minimal Effort Back Propagation Method","X. Sun; X. Ren; S. Ma; B. Wei; W. Li; J. Xu; H. Wang; Y. Zhang","Department of Computer Science, Peking University, Beijing, Beijing China (e-mail: xusun@pku.edu.cn); Department of Computer Science, Peking University, Beijing, Beijing China (e-mail: renxc@pku.edu.cn); Department of Computer Science, Peking University, Beijing, Beijing China (e-mail: shumingma@pku.edu.cn); Department of Computer Science, Peking University, Beijing, Beijing China (e-mail: weibz@pku.edu.cn); Department of Computer Science, Peking University, Beijing, Beijing China (e-mail: liweitj47@pku.edu.cn); Department of Computer Science, Peking University, Beijing, Beijing China (e-mail: jingjingxu@pku.edu.cn); Department of Computer Science, Peking University, Beijing, Beijing China (e-mail: wanghf@pku.edu.cn); Department of Computer Science, Peking University, Beijing, Beijing China (e-mail: zhangyi16@pku.edu.cn)","IEEE Transactions on Knowledge and Data Engineering","","2018","PP","99","1","1","We propose a simple yet effective technique to simplify the training and the resulting model of neural networks. In back propagation, only a small subset of the full gradient is computed to update the model parameters. The gradient vectors are sparsified in such a way that only the top-k elements (in terms of magnitude) are kept. As a result, only k rows or columns (depending on the layout) of the weight matrix are modified, leading to a linear reduction in the computational cost. Based on the sparsified gradients, we further simplify the model by eliminating the rows or columns that are seldom updated, which will reduce the computational cost both in the training and decoding, and potentially accelerate decoding in real-world applications. Surprisingly, experimental results demonstrate that most of time we only need to update fewer than 5% of the weights at each back propagation pass. More interestingly, the accuracy of the resulting models is actually improved rather than degraded, and a detailed analysis is given. The model simplification results show that we could adaptively simplify the model which could often be reduced by around 9x, without any loss on accuracy or even with improved accuracy.","","","10.1109/TKDE.2018.2883613","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8546786","neural network;back propagation;sparse learning;model pruning","Backpropagation;Computational modeling;Training;Adaptation models;Neurons;Computational efficiency;Decoding","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Novel Biologically Inspired Visual Cognition Model: Automatic Extraction of Semantics, Formation of Integrated Concepts, and Reselection Features for Ambiguity","P. Yin; H. Qiao; W. Wu; L. Qi; Y. Li; S. Zhong; B. Zhang","Institute of Applied Mathematics, Academy of Mathematics and Systems Science, Chinese Academy of Science, Beijing, China; University Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; University Chinese Academy of Sciences, Beijing, China; Institute of Applied Mathematics, Academy of Mathematics and Systems Science, Chinese Academy of Science, Beijing, China","IEEE Transactions on Cognitive and Developmental Systems","","2018","10","2","420","431","Techniques that integrate neuroscience and information science benefit both fields. Many related models have been proposed in computer vision; however, in general, the robustness and recognition precision are still key problems in object recognition models. In this paper, inspired by the process by which humans recognize objects and its biological mechanisms, a new integrated and dynamic framework is proposed that mimics the semantic extraction, concept formation and feature reselection found in human visual processing. The main contributions of the proposed model are as follows: 1) semantic feature extraction: local semantic features are learned from episodic features extracted from raw images using a deep neural network; 2) integrated concept formation: concepts are formed using the local semantic information and structural information is learned through a network; and 3) feature reselection: when ambiguity is detected during the recognition process, distinctive features based on the differences between the ambiguous candidates are reselected for recognition. Experimental results on four datasets show that-compared with other methods-the new proposed model is more robust and achieves higher precision for visual recognition, especially when the input samples are semantically ambiguous. Meanwhile, the introduced biological mechanisms further strengthen the interaction between neuroscience and information science.","","","10.1109/TCDS.2017.2749978","National Science Foundation of China; Strategic Priority Research Program of the CAS; National Key Research and Development Plan of China; National Natural Science Foundation of China; Development of Science and Technology of Guangdong Province Special Fund Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8027111","Biologically inspired model;object recognition;semantic learning;structural learning","Feature extraction;Semantics;Visualization;Biological system modeling;Data mining;Training;Neurons","computer vision;feature extraction;learning (artificial intelligence);neural nets;object recognition","visual cognition model;reselection features;neuroscience;computer vision;object recognition models;dynamic framework;feature reselection;human visual processing;local semantic features;episodic features;raw images;deep neural network;local semantic information;structural information;recognition process;visual recognition","","","58","","","","","IEEE","IEEE Journals"
"Fast Landmark Localization With 3D Component Reconstruction and CNN for Cross-Pose Recognition","G. Hsu; H. Shie; C. Hsieh; J. Chan","Artificial Vision Laboratory, National Taiwan University of Science and Technology, Taipei, Taiwan; Artificial Vision Laboratory, National Taiwan University of Science and Technology, Taipei, Taiwan; Artificial Vision Laboratory, National Taiwan University of Science and Technology, Taipei, Taiwan; Artificial Vision Laboratory, National Taiwan University of Science and Technology, Taipei, Taiwan","IEEE Transactions on Circuits and Systems for Video Technology","","2018","28","11","3194","3207","Two approaches are proposed for cross-pose face recognition, one is built on the handcrafted features extracted from the 3D reconstruction of facial components and the other is built on the learned features from a deep convolutional neural network (CNN). As both approaches rely on facial landmarks for alignment across large poses, we propose the Fast Hierarchical Model (FHM) for locating cross-pose facial landmarks in real time. Unlike most 3D approaches that consider holistic faces, the first proposed approach considers 3D facial components. It segments each 2D face in the gallery into components, reconstructs the 3D surface for each component, and recognizes a query face by component features. The core part of the CNN-based approach is a modified VGG network. We study the performance with different settings on the training set, including the synthesized data from 3D reconstruction, the real-life data from an in-the-wild database, and both types of data combined. The two recognition approaches and the FHM are evaluated in extensive experiments and compared with state-of-the-art methods to demonstrate their efficacy.","","","10.1109/TCSVT.2017.2748379","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8023997","Convolutional neural network;deep learning;face alignment;face recognition","Face;Three-dimensional displays;Feature extraction;Two dimensional displays;Image reconstruction;Face recognition;Detectors","face recognition;feature extraction;image reconstruction;image retrieval;image segmentation;learning (artificial intelligence);neural nets;pose estimation","3D reconstruction;2D face segmentation;query face recognition;3D facial components;fast landmark localization;handcrafted features;cross-pose face recognition;modified VGG network;CNN-based approach;component features;holistic faces;cross-pose facial landmarks;FHM;Fast Hierarchical Model;deep convolutional neural network;facial components","","1","59","","","","","IEEE","IEEE Journals"
"NIMA: Neural Image Assessment","H. Talebi; P. Milanfar","Google Research, Mountain View, CA, USA; Google Research, Mountain View, CA, USA","IEEE Transactions on Image Processing","","2018","27","8","3998","4011","Automatically learned quality assessment for images has recently become a hot topic due to its usefulness in a wide variety of applications, such as evaluating image capture pipelines, storage techniques, and sharing media. Despite the subjective nature of this problem, most existing methods only predict the mean opinion score provided by data sets, such as AVA and TID2013. Our approach differs from others in that we predict the distribution of human opinion scores using a convolutional neural network. Our architecture also has the advantage of being significantly simpler than other methods with comparable performance. Our proposed approach relies on the success (and retraining) of proven, state-of-the-art deep object recognition networks. Our resulting network can be used to not only score images reliably and with high correlation to human perception, but also to assist with adaptation and optimization of photo editing/enhancement algorithms in a photographic pipeline. All this is done without need for a “golden” reference image, consequently allowing for single-image, semantic- and perceptually-aware, no-reference quality assessment.","","","10.1109/TIP.2018.2831899","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8352823","Image quality assessment;no-reference quality assessment;deep learning","Standards;Quality assessment;Image quality;Distortion;Histograms;Training;Task analysis","feedforward neural nets;image enhancement;learning (artificial intelligence);object recognition;quality management","human perception;photographic pipeline;perceptually-aware quality assessment;single-image quality assessment;human opinion scores distribution;AVA;photo enhancement algorithm;photo editing algorithm;semantic-aware quality assessment;resulting network;deep object recognition networks;convolutional neural network;TID2013;data sets;mean opinion score;sharing media;storage techniques;image capture pipelines;neural image assessment;NIMA;no-reference quality assessment","","22","47","CCBY","","","","IEEE","IEEE Journals"
"Exploring Recurrent Neural Networks for On-Line Handwritten Signature Biometrics","R. Tolosana; R. Vera-Rodriguez; J. Fierrez; J. Ortega-Garcia","Biometrics and Data Pattern Analytics (BiDA) Lab-ATVS, Universidad Autonoma de Madrid, Madrid, Spain; Biometrics and Data Pattern Analytics (BiDA) Lab-ATVS, Universidad Autonoma de Madrid, Madrid, Spain; Biometrics and Data Pattern Analytics (BiDA) Lab-ATVS, Universidad Autonoma de Madrid, Madrid, Spain; Biometrics and Data Pattern Analytics (BiDA) Lab-ATVS, Universidad Autonoma de Madrid, Madrid, Spain","IEEE Access","","2018","6","","5128","5138","Systems based on deep neural networks have made a breakthrough in many different pattern recognition tasks. However, the use of these systems with traditional architectures seems not to work properly when the amount of training data is scarce. This is the case of the on-line signature verification task. In this paper, we propose a novel writer-independent on-line signature verification systems based on Recurrent Neural Networks (RNNs) with a Siamese architecture whose goal is to learn a dissimilarity metric from the pairs of signatures. To the best of our knowledge, this is the first time these recurrent Siamese networks are applied to the field of on-line signature verification, which provides our main motivation. We propose both Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU) systems with a Siamese architecture. In addition, a bidirectional scheme (which is able to access both past and future context) is considered for both LSTMand GRU-based systems. An exhaustive analysis of the system performance and also the time consumed during the training process for each recurrent Siamese network is carried out in order to compare the advantages and disadvantages for practical applications. For the experimental work, we use the BiosecurID database comprised of 400 users who contributed a total of 11,200 signatures in four separated acquisition sessions. Results achieved using our proposed recurrent Siamese networks have outperformed the state-of-the-art on-line signature verification systems using the same database.","","","10.1109/ACCESS.2018.2793966","Project; UAM-CecaBank Project; FPU Fellowship from Spanish MECD; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8259229","Biometrics;deep learning;on-line handwritten signature verification;recurrent neural networks;LSTM;GRU;DTW;BiosecurID","Computer architecture;Training;Biometrics (access control);Logic gates;Databases;Recurrent neural networks","handwriting recognition;image recognition;learning (artificial intelligence);recurrent neural nets","Siamese architecture;recurrent Siamese network;on-line signature verification systems;recurrent neural networks;on-line handwritten signature biometrics;deep neural networks;on-line signature verification task;pattern recognition tasks;GRU systems;gated recurrent unit systems;long short-term memory;LSTM","","17","36","","","","","IEEE","IEEE Journals"
"Residual LSTM Attention Network for Object Tracking","H. Kim; R. Park","Department of Electronic Engineering, School of Engineering, Sogang University, Seoul, South Korea; Department of Electronic Engineering, School of Engineering, Sogang University, Seoul, South Korea","IEEE Signal Processing Letters","","2018","25","7","1029","1033","In this letter, we propose an attention network for object tracking. To construct the proposed attention network for sequential data, we combine long-short term memory (LSTM) and a residual framework into a residual LSTM (RLSTM). The LSTM, which learns temporal correlation, is used for a temporal learning of object tracking. In the proposed RLSTM method, the residual framework, which achieves the highest accuracy in ImageNet large scale visual recognition competition (ILSVRC) 2016, learns the variations of spatial inputs and thus achieves the spatio-temporal attention of the target object. Also, a rule-based RLSTM learning is used for robust attention. Experimental results on large tracking benchmark datasets object tracking benchmark (OTB)-2013, OTB-100, and OTB-50 show that the proposed RLSTM tracker achieves the highest performance among existing trackers including the Siamese trackers, attention trackers, and correlation trackers, and also has comparable performance with the state-of-the-art deep trackers.","","","10.1109/LSP.2018.2835768","BK21 Plus Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8357947","Attention network;attention tracker;deep tracker;object tracking;residual long–short term memory (RLSTM);Siamese network;spatio-temporal attention;visual tracking","Target tracking;Object tracking;Feature extraction;Correlation;Robustness;Adaptation models;Task analysis","learning (artificial intelligence);object tracking","rule-based RLSTM learning;OTB-100;OTB-50;attention trackers;RLSTM tracker;tracking benchmark datasets object tracking benchmark-2013;robust attention;target object;spatio-temporal attention;ImageNet large scale visual recognition competition 2016;temporal learning;temporal correlation;residual framework;long-short term memory;residual LSTM attention network","","3","38","","","","","IEEE","IEEE Journals"
"Recurrent Broad Learning Systems for Time Series Prediction","M. Xu; M. Han; C. L. P. Chen; T. Qiu","Faculty of Electronic Information and Electrical Engineering, Dalian University of Technology, Dalian 116024, China.; Faculty of Electronic Information and Electrical Engineering, Dalian University of Technology, Dalian 116024, China (e-mail: minhan@dlut.edu.cn).; Department of Computer and Information Science, Faculty of Science and Technology, University of Macau, Macau 999078, China, and also with the Navigation College, Dalian Maritime University, Dalian 116026, China.; School of Computer Science and Technology, Tianjin University, Tianjin 300350, China.","IEEE Transactions on Cybernetics","","2018","PP","99","1","13","The broad learning system (BLS) is an emerging approach for effective and efficient modeling of complex systems. The inputs are transferred and placed in the feature nodes, and then sent into the enhancement nodes for nonlinear transformation. The structure of a BLS can be extended in a wide sense. Incremental learning algorithms are designed for fast learning in broad expansion. Based on the typical BLSs, a novel recurrent BLS (RBLS) is proposed in this paper. The nodes in the enhancement units of the BLS are recurrently connected, for the purpose of capturing the dynamic characteristics of a time series. A sparse autoencoder is used to extract the features from the input instead of the randomly initialized weights. In this way, the RBLS retains the merit of fast computing and fits for processing sequential data. Motivated by the idea of ``fine-tuning'' in deep learning, the weights in the RBLS can be updated by conjugate gradient methods if the prediction errors are large. We exhibit the merits of our proposed model on several chaotic time series. Experimental results substantiate the effectiveness of the RBLS. For chaotic benchmark datasets, the RBLS achieves very small errors, and for the real-world dataset, the performance is satisfactory.","","","10.1109/TCYB.2018.2863020","National Natural Science Foundation of China; Macau Science and Technology Development Fund FDCT; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8458240","Broad learning systems (BLSs);prediction;neural networks (NNs);time series","Artificial neural networks;Time series analysis;Learning systems;Zinc;Predictive models;Complex systems;Feedforward systems","","","","3","","","","","","IEEE","IEEE Early Access Articles"
"Heterogeneous Ensemble for Default Prediction of Peer-to-Peer Lending in China","W. Li; S. Ding; Y. Chen; S. Yang","School of Management, Hefei University of Technology, Hefei, China; School of Management, Hefei University of Technology, Hefei, China; School of Management, Hefei University of Technology, Hefei, China; School of Management, Hefei University of Technology, Hefei, China","IEEE Access","","2018","6","","54396","54406","As a novel financing method, peer-to-peer (P2P) lending has drawn extensive attention as it provides those financers who cannot participate in the traditional financial market with funds. In P2P lending marketplaces, one of the crucial challenges that P2P online lending platforms are facing is to accurately predict the default risk of each loan by tapping into default prediction models, thus effectively helping P2P lending companies avoid credit risks. That traditional credit risk prediction models fail to meet the demand of P2P lending companies for default risk prediction, which is because of the uneven distribution of credit data samples in the P2P lending marketplaces (i.e., the default sampled data are scarce). In this paper, we designed a multi-round ensemble learning model based on heterogeneous ensemble frameworks to predict default risk. In this model, an extreme gradient boosting (XGBoost) is initially used for ensemble learning, and the XGBoost, deep neural network, and logistic regression are then regarded as heterogeneous individual learners to undergo a linear weighted fusion. To verify the designed default risk prediction model, real credit data from a famous P2P online lending marketplace in China were used in a test. The results of the experiment indicate that this model can effectively increase the predictive accuracy compared with traditional machine learning models and ensemble learning models.","","","10.1109/ACCESS.2018.2810864","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8305471","Ensemble learning;default prediction;imbalanced data;P2P lending","Predictive models;Data models;Training;Classification algorithms;Boosting;Neural networks;Companies","credit transactions;financial data processing;learning (artificial intelligence);neural nets;peer-to-peer computing;regression analysis","XGBoost;linear weighted fusion;deep neural network;extreme gradient boosting;financing method;default risk prediction model;default risk prediction model;P2P online lending marketplace;ensemble learning models;predictive accuracy;heterogeneous ensemble frameworks;default sampled data;credit data samples;credit risks;P2P lending companies;P2P online lending platforms;P2P lending marketplaces;peer-to-peer lending","","5","44","","","","","IEEE","IEEE Journals"
"Towards Improved Design and Evaluation of Epileptic Seizure Predictors","I. Korshunova; P. Kindermans; J. Degrave; T. Verhoeven; B. H. Brinkmann; J. Dambre","Ghent University, Ghent, Belgium; Machine Learning GroupTechnische Universität Berlin; Ghent University; Ghent University; Mayo Systems Electrophysiology Laboratory, Departments of Neurology and Biomedical EngineeringMayo Clinic; Ghent University","IEEE Transactions on Biomedical Engineering","","2018","65","3","502","510","Objective: Key issues in the epilepsy seizure prediction research are (1) the reproducibility of results (2) the inability to compare multiple approaches directly. To overcome these problems, the seizure prediction challenge was organized on Kaggle.com. It aimed at establishing benchmarks on a dataset with predefined train, validation, and test sets. Our main objective is to analyze the competition format, and to propose improvements, which would facilitate a better comparison of algorithms. The second objective is to present a novel deep learning approach to seizure prediction and compare it to other commonly used methods using patient centered metrics. Methods: We used the competition's datasets to illustrate the effects of data contamination. Having better data partitions, we compared three types of models in terms of different objectives. Results: We found that correct selection of test samples is crucial when evaluating the performance of seizure forecasting models. Moreover, we showed that models, which achieve state-of-the-art performance with respect to commonly used AUC, sensitivity, and specificity metrics, may not yet be suitable for practical usage because of low precision scores. Conclusion: Correlation between validation and test datasets used in the competition limited its scientific value. Significance: Our findings provide guidelines which allow for a more objective evaluation of seizure prediction models.","","","10.1109/TBME.2017.2700086","Special Research Fund of Ghent University; Agency for Innovation by Science and Technology in Flanders; European Union's Horizon 2020; Marie Sklodowska-Curie; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7915772","Epilepsy;linear discriminant analysis;neural networks;support vector machines","Brain models;Electroencephalography;Epilepsy;Dogs;Prediction algorithms;Electrodes","learning (artificial intelligence);medical computing;medical disorders;neural nets;neurophysiology;support vector machines","epileptic seizure predictors;epilepsy seizure prediction research;test sets;competition format;deep learning approach;patient centered metrics;competition's datasets;data contamination;data partitions;seizure forecasting models;AUC;specificity metrics;sensitivity metrics","","4","41","","","","","IEEE","IEEE Journals"
"No-Reference Stereoimage Quality Assessment for Multimedia Analysis Towards Internet-of-Things","J. Yang; B. Jiang; H. Song; X. Yang; W. Lu; H. Liu","School of Electrical and Information Engineering, Tianjin University, Tianjin, China; School of Electrical and Information Engineering, Tianjin University, Tianjin, China; Department of Electrical, Computer, Software, and Systems Engineering, Embry-Riddle Aeronautical University, Daytona Beach, FL, USA; Department of Electrical and Computer Engineering, Missouri University of Science and Technology, Rolla, MO, USA; School of Electronic Engineering, Xidian University, Xi’an, China; School of Electrical and Information Engineering, Tianjin University, Tianjin, China","IEEE Access","","2018","6","","7631","7640","With continuous progress of Internet of Things, multimedia analysis in it has attracted more and more attention. Specially, stereoscopic display technology plays an important role in the multimedia analysis processing. In the Internet of Things system, the quality of stereoscopic image will be reduced in the transmission process. In this mode, it will have a great impact on multimedia analysis to judge whether the quality of stereoscopic image meets the requirements. In this paper, a new no-reference stereoscopic image quality assessment model for multimedia analysis towards Internet of Things is built, which is based on a deep learning model to learn from the class labels and image representations. In our framework, images are represented by natural scene statistics features that are extracted from discrete cosine transform domain, and a regression model is employed to shine upon the quality from the feature vector. The training process of the proposed model contains an unsupervised pretraining phase and a supervised fine-tuning phase, enabling it to generalize over the whole distortion types and severity. The proposed model greatly shows the correlation with subjective assessment as demonstrated by experiments on the LIVE 3-D Image Quality Database and IVC 3-D Image Quality Database.","","","10.1109/ACCESS.2018.2791560","National Natural Science Foundation of China; Natural Science Foundation of Tianjin; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8253458","Multimedia analysis;internet-of-things;stereoscopic image quality assessment;deep belief networks","Feature extraction;Image quality;Stereo image processing;Discrete cosine transforms;Multimedia communication;Visual systems;Neurons","discrete cosine transforms;feature extraction;image representation;multimedia computing;natural scenes;regression analysis;stereo image processing;unsupervised learning","multimedia analysis processing;no-reference stereoscopic image quality assessment model;LIVE 3-D Image Quality Database;supervised fine-tuning phase;unsupervised pretraining phase;feature vector;regression model;discrete cosine transform domain;feature extraction;natural scene statistics features;class labels;deep learning model;no-reference stereoimage quality assessment;Internet-of-Things;stereoscopic display technology;IVC 3-D Image Quality Database;image representations","","3","44","","","","","IEEE","IEEE Journals"
"Wearable Depth Camera: Monocular Depth Estimation via Sparse Optimization Under Weak Supervision","L. He; C. Chen; T. Zhang; H. Zhu; S. Wan","School of Electromechanical Engineering, Guangdong University of Technology, Guangzhou, China; School of Electromechanical Engineering, Guangdong University of Technology, Guangzhou, China; School of Electromechanical Engineering, Guangdong University of Technology, Guangzhou, China; School of Electromechanical Engineering, Guangdong University of Technology, Guangzhou, China; School of Information and Safety Engineering, Zhongnan University of Economics and Law, Wuhan, China","IEEE Access","","2018","6","","41337","41345","Depth estimation is essential for many human-object interaction tasks. Despite its advantages, traditional depth sensors, including Kinect or depth camera, are always not wearable-friendly due to several critical drawbacks, such as over-size or over-weight. Monocular camera, on the other hand, provides a promising solution with limited burden to users and attracts more and more attentions in the literature. In this paper, we propose a depth estimation method with monocular camera. Our main idea lies in the weak-supervised learning model of monocular depth estimation based on left and right consistency. To learn an accurate depth estimation, on our training step, we employ LiDAR data, which are generated by laser radar with very high depth accuracy, to semi-supervise the learning scheme. We train our network on ResNet and propose a new penalty function, which takes into account the LiDAR depth loss in training. Compared with several state-of-the-art monocular camera depth estimators, our proposed method obtains the highest depth accuracy.","","","10.1109/ACCESS.2018.2857703","National Natural Science Foundation of China; Leading Talents of Guangdong Province Program; Frontier and Key Technology Innovation Special Funds of Guangdong Province; Program of Foshan Innovation Team of Science and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8413080","Wearable devices;depth estimation;deep learning;weak supervision;sparse optimization","Estimation;Cameras;Task analysis;Laser radar;Computer vision;Optimization;Three-dimensional displays","cameras;feedforward neural nets;image colour analysis;image sensors;learning (artificial intelligence);object detection;optical radar","wearable depth camera;monocular depth estimation;weak supervision;human-object interaction tasks;depth estimation method;weak-supervised learning model;LiDAR depth loss;monocular camera depth estimators;sparse optimization;left consistency;right consistency;LiDAR data;penalty function;ResNet","","4","29","","","","","IEEE","IEEE Journals"
"A Light CNN for Deep Face Representation With Noisy Labels","X. Wu; R. He; Z. Sun; T. Tan","National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Information Forensics and Security","","2018","13","11","2884","2896","The volume of convolutional neural network (CNN) models proposed for face recognition has been continuously growing larger to better fit the large amount of training data. When training data are obtained from the Internet, the labels are likely to be ambiguous and inaccurate. This paper presents a Light CNN framework to learn a compact embedding on the large-scale face data with massive noisy labels. First, we introduce a variation of maxout activation, called max-feature-map (MFM), into each convolutional layer of CNN. Different from maxout activation that uses many feature maps to linearly approximate an arbitrary convex activation function, MFM does so via a competitive relationship. MFM can not only separate noisy and informative signals but also play the role of feature selection between two feature maps. Second, three networks are carefully designed to obtain better performance, meanwhile, reducing the number of parameters and computational costs. Finally, a semantic bootstrapping method is proposed to make the prediction of the networks more consistent with noisy labels. Experimental results show that the proposed framework can utilize large-scale noisy data to learn a Light model that is efficient in computational costs and storage spaces. The learned single network with a 256-D representation achieves state-of-the-art results on various face benchmarks without fine-tuning.","","","10.1109/TIFS.2018.2833032","State Key Development Program; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8353856","Convolutional neural network;face recognition","Noise measurement;Face;Neurons;Face recognition;Robustness;Training;Training data","convolution;face recognition;feature extraction;feedforward neural nets;image representation;learning (artificial intelligence)","compact embedding;large-scale face data;massive noisy labels;maxout activation;MFM;feature maps;noisy signals;informative signals;feature selection;large-scale noisy data;face benchmarks;deep face representation;convolutional neural network models;face recognition;max-feature-map;arbitrary convex activation function;light CNN framework;linearly approximation","","41","79","","","","","IEEE","IEEE Journals"
"Remote Sensing Image Fusion With Deep Convolutional Neural Network","Z. Shao; J. Cai","Mapping and Remote Sensing, State Key Laboratory for Information Engineering in Surveying, Wuhan University, Wuhan, China; Mapping and Remote Sensing, State Key Laboratory for Information Engineering in Surveying, Wuhan University, Wuhan, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2018","11","5","1656","1669","Remote sensing images with different spatial and spectral resolution, such as panchromatic (PAN) images and multispectral (MS) images, can be captured by many earth-observing satellites. Normally, PAN images possess high spatial resolution but low spectral resolution, while MS images have high spectral resolution with low spatial resolution. In order to integrate spatial and spectral information contained in the PAN and MS images, image fusion techniques are commonly adopted to generate remote sensing images at both high spatial and spectral resolution. In this study, based on the deep convolutional neural network, a remote sensing image fusion method that can adequately extract spectral and spatial features from source images is proposed. The major innovation of this study is that the proposed fusion method contains a two branches network with the deeper structure which can capture salient features of the MS and PAN images separately. Besides, the residual learning is adopted in our network to thoroughly study the relationship between the high- and low-resolution MS images. The proposed method mainly consists of two procedures. First, spatial and spectral features are respectively extracted from the MS and PAN images by convolutional layers with different depth. Second, the feature fusion procedure utilizes the extracted features from the former step to yield fused images. By evaluating the performance on the QuickBird and Gaofen-1 images, our proposed method provides better results compared with other classical methods.","","","10.1109/JSTARS.2018.2805923","National key R & D plan on strategic international scientific and technological innovation cooperation; Fundamental Research Funds for the Central Universities; Wuhan Chen Guang Project; Guangzhou science and technology project; Special Task of Technical Innovation in Hubei Province; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8314460","Deep convolutional neural network;multispectral image;panchromatic image;remote sensing image fusion","Remote sensing;Feature extraction;Image fusion;Spatial resolution;Transforms;Multiresolution analysis","convolution;feature extraction;feedforward neural nets;geophysical image processing;image classification;image fusion;image resolution;remote sensing","deep convolutional neural network;panchromatic images;multispectral images;PAN images;high spatial resolution;low spectral resolution;MS images;high spectral resolution;low spatial resolution;spatial information;spectral information;image fusion techniques;remote sensing images;remote sensing image fusion method;spectral features;spatial features;source images;low-resolution;feature fusion procedure;fused images;spatial resolution","","11","57","","","","","IEEE","IEEE Journals"
"Implementation and On-Orbit Testing Results of a Space Communications Cognitive Engine","T. M. Hackett; S. G. Bilén; P. V. R. Ferreira; A. M. Wyglinski; R. C. Reinhart; D. J. Mortensen","School of Electrical Engineering and Computer Science, Pennsylvania State University, University Park, PA, USA; School of Electrical Engineering and Computer Science, Pennsylvania State University, University Park, PA, USA; Department of Electrical Engineering and Computer Engineering, Worcester Polytechnic Institute, Worcester, MA, USA; Department of Electrical Engineering and Computer Engineering, Worcester Polytechnic Institute, Worcester, MA, USA; Space Communications and Navigation, NASA John H. Glenn Research Center, Cleveland, OH, USA; Space Communications and Navigation, NASA John H. Glenn Research Center, Cleveland, OH, USA","IEEE Transactions on Cognitive Communications and Networking","","2018","4","4","825","842","Cognitive algorithms for communications systems have been presented in literature, but very few have been integrated into a fielded system, especially space communications systems. In this paper, we describe the implementation of a multi-objective reinforcement-learning algorithm using deep artificial neural networks acting as a radio-resource-allocation controller. The developed software core is generic in nature and can be ported readily to another application. The cognitive engine algorithm implementation was characterized through a series of tests using both a ground-based system and a space-based system. The ground system comprised of engineering-model software-defined radios, commercial modems, and RF equipment emulating the targeted space-to-ground channel. The on-orbit communication system, including a space-based, remotely controlled transmitter, resides on the International Space Station and operates with a ground-based receiver at NASA Glenn Research Center. Through a series of on-orbit tests, the cognitive engine was tested in a highly dynamic channel and its performance is discussed and analyzed.","","","10.1109/TCCN.2018.2878202","NASA Space Technology Research Fellowship; Glenn Research Center; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8510837","Cognitive engine;neural networks;reinforcement learning;SCaN Testbed;space communications;machine learning","Artificial neural networks;Neural networks;Modulation;Encoding;Cognitive radio;Space communications;Machine learning;Reinforcement learning","","","","1","21","","","","","IEEE","IEEE Journals"
"Multilevel Building Detection Framework in Remote Sensing Images Based on Convolutional Neural Networks","Y. Liu; Z. Zhang; R. Zhong; D. Chen; Y. Ke; J. Peethambaran; C. Chen; L. Sun","Advanced Innovation Center for Imaging Technology, Capital Normal University, Beijing, China; Advanced Innovation Center for Imaging Technology, Capital Normal University, Beijing, China; Advanced Innovation Center for Imaging Technology, Capital Normal University, Beijing, China; College of Civil Engineering, Nanjing Forestry University, Nanjing, China; Advanced Innovation Center for Imaging Technology, Capital Normal University, Beijing, China; Department of Mathematics and Computing, Saint Mary's University, Halifax, NS, Canada; Guangdong Key Laboratory of Ocean Remote Sensing, South China Sea Institute of Oceanology Chinese Academy of Sciences, Guangzhou, China; Advanced Innovation Center for Imaging Technology, Capital Normal University, Beijing, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2018","11","10","3688","3700","In this paper, we propose a hierarchical building detection framework based on deep learning model, which focuses on accurately detecting buildings from remote sensing images. To this end, we first construct the generation model of the multilevel training samples using the Gaussian pyramid technique to learn the features of building objects at different scales and spatial resolutions. Then, the building region proposal networks are put forward to quickly extract candidate building regions, thereby increasing the efficiency of the building object detection. Based on the candidate building regions, we establish the multilevel building detection model using the convolutional neural networks (CNNs), from which the generic image features of each building region proposal are calculated. Finally, the obtained features are provided as inputs for training CNNs model, and the learned model is further applied to test images for the detection of unknown buildings. Various experiments using the Datasets I and II (in Section V-A) show that the proposed framework increases the mean average precision values of building detection by 3.63%, 3.85%, and 3.77%, compared with the state-of-the-art methods, i.e., Method IV. Besides, the proposed method is robust to the buildings having different spatial textures and types.","","","10.1109/JSTARS.2018.2866284","Open Fund of Twenty First Century Aerospace Technology Co., Ltd.; National Natural Science Foundation of China; Open Fund for Guangdong Key Laboratory of Ocean Remote Sensing (South China Sea Institute of Oceanology Chinese Academy of Sciences); Open Fund Key Laboratory for National Geography State Monitoring (National Administration of Surveying, Mapping, and Geoinformation); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8458225","Building detection;convolutional neural networks (CNNs);candidate building regions;multilevel framework;remote sensing images","Buildings;Remote sensing;Feature extraction;Object detection;Machine learning;Proposals;Training","buildings (structures);convolution;feature extraction;feedforward neural nets;geophysical image processing;image classification;image resolution;image segmentation;image texture;learning (artificial intelligence);object detection;remote sensing","remote sensing images;convolutional neural networks;hierarchical building detection framework;deep learning model;generation model;multilevel training samples;Gaussian pyramid technique;building region proposal networks;candidate building regions;building object detection;multilevel building detection model;generic image features;CNNs model;spatial resolutions;scales;mean average precision values;spatial textures;spatial types","","3","57","","","","","IEEE","IEEE Journals"
"Analysis of the 72-h Mortality of Emergency Room Septic Patients Based on a Deep Belief Network","J. Perng; I. Kao; Y. Chen; Y. Lai; C. Su; S. Hung; M. S. Lee; C. Kung","Department of Mechanical and Electro-Mechanical Engineering, National Sun Yat-sen University, Kaohsiung, Taiwan; Department of Mechanical and Electro-Mechanical Engineering, National Sun Yat-sen University, Kaohsiung, Taiwan; Department of Mechanical and Electro-Mechanical Engineering, National Sun Yat-sen University, Kaohsiung, Taiwan; Department of Mechanical and Electro-Mechanical Engineering, National Sun Yat-sen University, Kaohsiung, Taiwan; Department of Emergency Medicine, Kaohsiung Chang Gung Memorial Hospital, College of Medicine, Chang Gung University, Kaohsiung, Taiwan; Department of Emergency Medicine, Kaohsiung Chang Gung Memorial Hospital, College of Medicine, Chang Gung University, Kaohsiung, Taiwan; Department of Orthopedics, Kaohsiung Chang Gung Memorial Hospital, College of Medicine, Chang Gung University, Kaohsiung, Taiwan; Department of Emergency Medicine, Kaohsiung Chang Gung Memorial Hospital, College of Medicine, Chang Gung University, Kaohsiung, Taiwan","IEEE Access","","2018","6","","76820","76830","In this paper, a deep belief network (DBN) is proposed as an effective method to predict the mortality of patients within the first 72 h of visiting an emergency room (ER), i.e., 72-h mortality. Previously, physicians used the quick sequential organ failure assessment (qSOFA) and systemic inflammatory response syndrome (SIRS) to determine the survival probability of patients. Although such prediction methods are convenient, there is room for improvement in their accuracy. To demonstrate the effectiveness of our proposed method, original data from a hospital was used. A single-center retrospective study was performed regarding adult ER patients who were admitted between January 2007 and December 2013 with an infection. The qSOFA and SIRS scores were calculated using primary vital signs and laboratory data. A DBN was then used to predict patients’ survival rates and to choose 65 clinical variables as an input. Utilizing the DBN, the joint probability distribution of the 65 clinical variables was calculated, and valid solutions of the decreased features were achieved. Results indicate that the DBN can predict the 72-h mortality of ER septic patients more accurately than the qSOFA or SIRS. This paper aims to design an effective prediction system to assist clinicians in their diagnosis using a DBN for early risk stratification and intervention.","","","10.1109/ACCESS.2018.2884509","Kaohsiung Chang Gung Memorial Hospital; National Sun Yat-sen University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8558682","Deep belief network;mortality prediction;qSOFA;SIRS","Hospitals;Feature extraction;Blood pressure;Machine learning algorithms","","","","","53","","","","","IEEE","IEEE Journals"
"Action-Attending Graphic Neural Network","C. Li; Z. Cui; W. Zheng; C. Xu; R. Ji; J. Yang","Key Laboratory of Child Development and Learning Science, Ministry of Education, School of Biological Science and Medical Engineering, Southeast University, Nanjing, China; Key Laboratory of Intelligent Perception and Systems for High-Dimensional Information, Ministry of Education, School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; Key Laboratory of Child Development and Learning Science, Ministry of Education, School of Biological Science and Medical Engineering, Southeast University, Nanjing, China; Key Laboratory of Intelligent Perception and Systems for High-Dimensional Information, Ministry of Education, School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Information Science and Engineering, Xiamen University, Xiamen, China; Key Laboratory of Intelligent Perception and Systems for High-Dimensional Information, Ministry of Education, School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China","IEEE Transactions on Image Processing","","2018","27","7","3657","3670","The motion analysis of human skeletons is crucial for human action recognition, which is one of the most active topics in computer vision. In this paper, we propose a fully end-to-end action-attending graphic neural network (A2GNN) for skeleton-based action recognition, in which each irregular skeleton is structured as an undirected attribute graph. To extract high-level semantic representation from skeletons, we perform the local spectral graph filtering on the constructed attribute graphs like the standard image convolution operation. Considering not all joints are informative for action analysis, we design an action-attending layer to detect those salient action units by adaptively weighting skeletal joints. Herein, the filtering responses are parameterized into a weighting function irrelevant to the order of input nodes. To further encode continuous motion variations, the deep features learnt from skeletal graphs are gathered along consecutive temporal slices and then fed into a recurrent gated network. Finally, the spectral graph filtering, action-attending, and recurrent temporal encoding are integrated together to jointly train for the sake of robust action recognition as well as the intelligibility of human actions. To evaluate our A2GNN, we conduct extensive experiments on four benchmark skeleton-based action datasets, including the large-scale challenging NTU RGB+D dataset. The experimental results demonstrate that our network achieves the state-of-the-art performances.","","","10.1109/TIP.2018.2815744","National Basic Research Program of China; National Natural Science Foundation of China; Key Research and Development Program of Jiangsu Province, China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8315510","Human action recognition;skeleton-based action recognition;convolutional neural networks;attention mechanism","Feature extraction;Three-dimensional displays;Joints;Hidden Markov models;Dynamics;Neural networks","computer vision;feature extraction;feedforward neural nets;graph theory;image filtering;image motion analysis;image recognition;image representation;learning (artificial intelligence);object recognition","skeleton-based action datasets;action-attending graphic neural network;motion analysis;human skeletons;human action recognition;undirected attribute graph;high-level semantic representation;local spectral graph;constructed attribute graphs;action analysis;salient action units;skeletal graphs;recurrent gated network;spectral graph filtering;robust action recognition;A2GNN;recurrent temporal encoding;NTU RGB+D dataset;image convolution operation;filtering responses","","5","66","","","","","IEEE","IEEE Journals"
"A Cascaded Deep Convolutional Neural Network for Joint Segmentation and Genotype Prediction of Brainstem Gliomas","J. Liu; F. Chen; C. Pan; M. Zhu; X. Zhang; L. Zhang; H. Liao","Department of Biomedical EngineeringSchool of Medicine Tsinghua University; Department of Biomedical EngineeringSchool of Medicine Tsinghua University; Department of Neurosurgery/China National Clinical Research Center for Neurological Diseases Beijing Tiantan HospitalCapital Medical University; Department of Biomedical EngineeringSchool of Medicine Tsinghua University; Department of Biomedical EngineeringSchool of Medicine Tsinghua University; Department of Neurosurgery/China National Clinical Research Center for Neurological Diseases Beijing Tiantan HospitalCapital Medical University; Department of Biomedical Engineering, School of Medicine, Tsinghua University, Beijing, China","IEEE Transactions on Biomedical Engineering","","2018","65","9","1943","1952","Goal: Automatic segmentation of brainstem gliomas and prediction of genotype (H3 K27M) mutation status based on magnetic resonance (MR) images are crucial but challenging tasks for computer-aided diagnosis in neurosurgery. In this paper, we present a novel cascaded deep convolutional neural network (CNN) to address these two challenging tasks simultaneously. Methods: Our novel segmentation task contains two feature-fusion modules: the Gaussian-pyramid multiscale input features-fusion technique and the brainstem-region feature enhancement. The aim is to resolve very difficult problems in brainstem glioma segmentation. Our prediction model combines CNN features and support-vector-machine classifier to automatically predict genotypes without region-of-interest labeled-MR images and is learned jointly with the segmentation task. First, Gaussian-pyramid multiscale input feature fusion is added to our glioma-segmentation task to solve the problems of size variety and weak brainstem-gliomas boundaries. Second, the two feature-fusion modules provide both local and global contexts to retain higher frequency details for sharper tumor boundaries, handling the problem of the large variation of tumor shape, and volume resolution. Results and Conclusion: Experiments demonstrate that our cascaded CNN method achieves not only a good tumor segmentation result with a high Dice similarity coefficient of 77.03%, but also a competitive genotype prediction result with an average accuracy of 94.85% upon fivefold cross-validation.","","","10.1109/TBME.2018.2845706","Beijing Municipal Science and Technology Commission; National Basic Research Program of China (973 Program); National Natural Science Foundation of China; Natural Science Foundation of Beijing Municipality; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8375811","Convolutional neural networks;tumor segmentation;H3 K27M mutation prediction;Brainstem Gliomas","Tumors;Image segmentation;Task analysis;Brainstem;Brain modeling;Biomedical imaging;Feature extraction","biomedical MRI;convolution;feature extraction;image enhancement;image segmentation;learning (artificial intelligence);medical image processing;neural nets;support vector machines;tumours","cascaded deep convolutional neural network;brainstem gliomas;magnetic resonance images;computer-aided diagnosis;feature-fusion modules;Gaussian-pyramid multiscale input features-fusion technique;brainstem-region feature enhancement;brainstem glioma segmentation;prediction model;CNN features;region-of-interest labeled-MR images;glioma-segmentation task;weak brainstem-gliomas boundaries;cascaded CNN method;competitive genotype prediction result;automatic segmentation;segmentation task;genotype mutation status;tumor segmentation result;Dice similarity coefficient","","2","34","","","","","IEEE","IEEE Journals"
"Deep Convolution Neural Networks for Twitter Sentiment Analysis","Z. Jianqiang; G. Xiaolin; Z. Xuejun","School of Electronic and Information Engineering, Xi’an Jiaotong University, Xi’an, China; School of Electronic and Information Engineering, Xi’an Jiaotong University, Xi’an, China; Key Laboratory of Computer Network, Xi’an Jiaotong University, Xi’an, China","IEEE Access","","2018","6","","23253","23260","Twitter sentiment analysis technology provides the methods to survey public emotion about the events or products related to them. Most of the current researches are focusing on obtaining sentiment features by analyzing lexical and syntactic features. These features are expressed explicitly through sentiment words, emoticons, exclamation marks, and so on. In this paper, we introduce a word embeddings method obtained by unsupervised learning based on large twitter corpora, this method using latent contextual semantic relationships and co-occurrence statistical characteristics between words in tweets. These word embeddings are combined with n-grams features and word sentiment polarity score features to form a sentiment feature set of tweets. The feature set is integrated into a deep convolution neural network for training and predicting sentiment classification labels. We experimentally compare the performance of our model with the baseline model that is a word n-grams model on five Twitter data sets, the results indicate that our model performs better on the accuracy and F1-measure for twitter sentiment classification.","","","10.1109/ACCESS.2017.2776930","NSFC Projects; Science and Technology Project of Shaanxi Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8244338","Twitter;sentiment analysis;word embeddings;convolution neural network","Twitter;Neural networks;Convolution;Sentiment analysis;Terminology;Semantics","feedforward neural nets;neural nets;pattern classification;sentiment analysis;social networking (online);unsupervised learning","word n-grams model;Twitter data sets;sentiment features;lexical features;syntactic features;sentiment words;latent contextual semantic relationships;co-occurrence statistical characteristics;n-grams features;word sentiment polarity score features;sentiment feature set;deep convolution neural network;word embedding method;sentiment classification label prediction;Twitter sentiment classification;Twitter corpora","","18","46","","","","","IEEE","IEEE Journals"
"Solution to overcome the sparsity issue of annotated data in medical domain","A. K. Pujitha; J. Sivaswamy","Center for Visual Information Technology, IIIT Hyderabad, India; Center for Visual Information Technology, IIIT Hyderabad, India","CAAI Transactions on Intelligence Technology","","2018","3","3","153","160","Annotations are critical for machine learning and developing computer aided diagnosis (CAD) algorithms. Good performance of CAD is critical to their adoption, which generally rely on training with a wide variety of annotated data. However, a vast amount of medical data is either unlabeled or annotated only at the image-level. This poses a problem for exploring data driven approaches like deep learning for CAD. In this paper, we propose a novel crowdsourcing and synthetic image generation for training deep neural net-based lesion detection. The noisy nature of crowdsourced annotations is overcome by assigning a reliability factor for crowd subjects based on their performance and requiring region of interest markings from the crowd. A generative adversarial network-based solution is proposed to generate synthetic images with lesions to control the overall severity level of the disease. We demonstrate the reliability of the crowdsourced annotations and synthetic images by presenting a solution for training the deep neural network (DNN) with data drawn from a heterogeneous mixture of annotations. Experimental results obtained for hard exudate detection from retinal images show that training with refined crowdsourced data/synthetic images is effective as detection performance in terms of sensitivity improves by 25%/27% over training with just expert-markings.","","","10.1049/trit.2018.1010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8548699","","","learning (artificial intelligence);image colour analysis;neural nets;image classification;image segmentation;medical image processing;diseases","annotated data;medical domain;machine learning;developing computer;diagnosis algorithms;CAD;good performance;medical data;image level;data-driven approaches;deep learning;data augmentation;popular solution;synthetic image generation;crowdsourced annotations;interest markings;pixel-level markings;generative adversarial network-based solution;severity level;crowdsourced region;synthetically generated data;colour fundus images;processed/refined crowdsourced data/synthetic images;detection performance","","","27","","","","","IET","IET Journals"
"Optimization for Deep Convolutional Neural Networks: How Slim Can It Go?","S. D. Liang","Coppell High School, Coppell, TX 75019 USA, and also with the SkymontLabs LLC, Irving, TX 75063 USA (e-mail: stephendliang@gmail.com).","IEEE Transactions on Emerging Topics in Computational Intelligence","","2018","PP","99","1","9","The deep convolutional neural networks (CNN) have a vast amount of parameters, especially in the fully connected (FC) layers, which have become a bottleneck for real-time applications where processing latency is high due to computational cost. In this paper, we propose to optimize the FC layers in CNN via making it much slimmer. We make analysis of the statistical distribution of the weights in FC layer, and observe each column follows Gaussian distribution. Regression model analysis of the weights of FC layer based on Akaike information criteria and Bayesian information criterion demonstrates that they have Granger causality, which means the columns are correlated and they follow colored Gaussian distribution. Based on this distribution, we derive a CNN design and optimization theorem for FC layers from information theory point of view. The theorem provides two design criteria, rank and singular values. Further, we show that FC layer with weights of colored Gaussian is more efficient than that of white Gaussian. The optimization criteria is singular-values-based, so we apply singular value decomposition to find the maximal singular values and QR to identify the corresponding columns in FC layer. We evaluate our optimization approach to AlexNet and apply the slimmer CNN to ImageNet classification. Simulation results show our approach performs much better than random dropout. Specifically, with only around $\text{28}\text{\%}$ of weights, the AlexNet could perform as well as the original AlexNet in terms of top one error and top five error.","","","10.1109/TETCI.2018.2876573","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8513987","Deep learning;convolutional neural networks;optimization;information theory;Granger causality;statistical analysis","Optimization;Principal component analysis;Training;Gaussian distribution;Convolutional neural networks;Error analysis;Neurons","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Distributed Perception by Collaborative Robots","R. Hadidi; J. Cao; M. Woodward; M. S. Ryoo; H. Kim","Computer Science School and Electrical Engineering Department, Georgia Institute of Technology, GA, USA; Computer Science School and Electrical Engineering Department, Georgia Institute of Technology, GA, USA; Computer Science School and Electrical Engineering Department, Georgia Institute of Technology, GA, USA; EgoVid, Inc., Ulsan, South Korea; Computer Science School and Electrical Engineering Department, Georgia Institute of Technology, GA, USA","IEEE Robotics and Automation Letters","","2018","3","4","3709","3716","Recognition ability and, more broadly, machine learning techniques enable robots to perform complex tasks and allow them to function in diverse situations. In fact, robots can easily access an abundance of sensor data that are recorded in real time such as speech, image, and video. Since such data are time sensitive, processing them in real time is a necessity. Moreover, machine learning techniques are known to be computationally intensive and resource hungry. As a result, an individual resource-constrained robot, in terms of computation power and energy supply, is often unable to handle such heavy real-time computations alone. To overcome this obstacle, we propose a framework to harvest the aggregated computational power of several low-power robots for enabling efficient, dynamic, and real-time recognition. Our method adapts to the availability of computing devices at runtime and adjusts to the inherit dynamics of the network. Our framework can be applied to any distributed robot system. To demonstrate, with several Raspberry-Pi3-based robots (up to 12) each equipped with a camera, we implement a state-of-the-art action recognition model for videos and two recognition models for images. Our approach allows a group of multiple low-power robots to obtain a similar performance (in terms of the number of images or video frames processed per second) compared to a high-end embedded platform, Nvidia Tegra TX2.","","","10.1109/LRA.2018.2856261","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8411096","Deep learning in robotics and automation;distributed robot system","Robots;Task analysis;Real-time systems;Computational modeling;Parallel processing;Collaboration;Streaming media","distributed control;image recognition;learning (artificial intelligence);robot vision;video signal processing","resource-constrained robot;action recognition model;Raspberry-Pi3-based robots;distributed robot system;real-time recognition;low-power robots;machine learning techniques;collaborative robots;distributed perception","","4","47","","","","","IEEE","IEEE Journals"
"Minimizing Reconstruction Bias Hashing via Joint Projection Learning and Quantization","L. Duan; Y. Wu; Y. Huang; Z. Wang; J. Yuan; W. Gao","Institute of Digital Media, School of Electronics Engineering and Computer Science, Peking University, Beijing, China; PKU-NTU Joint Research Institute, Beijing, China; Institute of Digital Media, School of Electronics Engineering and Computer Science, Peking University, Beijing, China; Institute of Digital Media, School of Electronics Engineering and Computer Science, Peking University, Beijing, China; Department of Computer Science and Engineering, The State University of New York, Buffalo, NY, USA; Institute of Digital Media, School of Electronics Engineering and Computer Science, Peking University, Beijing, China","IEEE Transactions on Image Processing","","2018","27","6","3127","3141","Hashing, a widely studied solution to the approximate nearest neighbor search, aims to map data points in the high-dimensional Euclidean space to the low-dimensional Hamming space while preserving the similarity between original points. As directly learning binary codes can be NP-hard due to discrete constraints, a two-stage scheme, namely, “projection and quantization”, has already become a standard paradigm for learning similarity-preserving hash codes. However, most existing hashing methods typically separate these two stages and thus fail to investigate complementary effects of both stages. In this paper, we systematically study the relationship between “projection and quantization”, and propose a novel minimal reconstruction bias hashing (MRH) method to learn compact binary codes, in which the projection learning and quantization optimizing are jointly performed. By introducing a lower bound analysis, we design an effective ternary search algorithm to solve the corresponding optimization problem. Furthermore, we conduct some insightful discussions on the proposed MRH approach, including the theoretical proof, and computational complexity. Distinct from previous works, the MRH can adaptively adjust the projection dimensionality to balance the information loss between the projection and quantization. The proposed framework not only provides a unique perspective to view traditional hashing methods, but also evokes some other researches, e.g., guiding the design of the loss functions in deep networks. Extensive experiment results have shown that the proposed MRH significantly outperforms a variety of state-of-the-art methods over eight widely used benchmarks.","","","10.1109/TIP.2018.2818008","National Natural Science Foundation of China; National Key Research and Development Program of China; PKU-NTU Joint Research Institute through a donation from the Ng Teng Fong Charitable Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8320817","Bias hashing;quantization error;joint optimization;image retrieval","","binary codes;computational complexity;file organisation;Hamming codes;image reconstruction;image retrieval;learning (artificial intelligence);optimisation;search problems;theorem proving","optimization problem;hashing methods;bias hashing reconstruction;ternary search algorithm;joint optimization;image retrieval;minimal reconstruction bias hashing;MRH method;theoretical proof;computational complexity;projection dimensionality;MRH approach;compact binary codes;similarity-preserving hash codes;low-dimensional Hamming space;high-dimensional Euclidean space;approximate nearest neighbor search;quantization;joint projection learning","","2","66","","","","","IEEE","IEEE Journals"
"Body Joint Guided 3-D Deep Convolutional Descriptors for Action Recognition","C. Cao; Y. Zhang; C. Zhang; H. Lu","National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, Beijing, China; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Cybernetics","","2018","48","3","1095","1108","3-D convolutional neural networks (3-D CNNs) have been established as a powerful tool to simultaneously learn features from both spatial and temporal dimensions, which is suitable to be applied to video-based action recognition. In this paper, we propose not to directly use the activations of fully connected layers of a 3-D CNN as the video feature, but to use selective convolutional layer activations to form a discriminative descriptor for video. It pools the feature on the convolutional layers under the guidance of body joint positions. Two schemes of mapping body joints into convolutional feature maps for pooling are discussed. The body joint positions can be obtained from any off-the-shelf skeleton estimation algorithm. The helpfulness of the body joint guided feature pooling with inaccurate skeleton estimation is systematically evaluated. To make it end-to-end and do not rely on any sophisticated body joint detection algorithm, we further propose a two-stream bilinear model which can learn the guidance from the body joints and capture the spatio-temporal features simultaneously. In this model, the body joint guided feature pooling is conveniently formulated as a bilinear product operation. Experimental results on three real-world datasets demonstrate the effectiveness of body joint guided pooling which achieves promising performance.","","","10.1109/TCYB.2017.2756840","National Natural Science Foundation of China; Youth Innovation Promotion Association CAS; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8167329","Action recognition;body joints;convolutional networks;feature pooling;two-stream bilinear model","Feature extraction;Skeleton;Kernel;Estimation;Optical imaging;Convolution;Trajectory","convolution;feature extraction;image motion analysis;image recognition;image representation;learning (artificial intelligence);neural nets;pose estimation;video signal processing","spatiotemporal features;body joint guided 3-D deep convolutional descriptors;body joint guided pooling;sophisticated body joint detection algorithm;body joint guided feature pooling;convolutional feature maps;mapping body joints;body joint positions;convolutional layers;selective convolutional layer activations;video feature;fully connected layers;action recognition;3-D CNNs;3-D convolutional neural networks","","3","52","","","","","IEEE","IEEE Journals"
"Scenario Generation for Wind Power Using Improved Generative Adversarial Networks","C. Jiang; Y. Mao; Y. Chai; M. Yu; S. Tao","Key Laboratory of Complex System Safety and Control, Ministry of Education, College of Automation, Chongqing University, Chongqing, China; Key Laboratory of Complex System Safety and Control, Ministry of Education, College of Automation, Chongqing University, Chongqing, China; Key Laboratory of Complex System Safety and Control, Ministry of Education, College of Automation, Chongqing University, Chongqing, China; School of Instrument Science and Engineering, Southeast University, Nanjing, China; Key Laboratory of Complex System Safety and Control, Ministry of Education, College of Automation, Chongqing University, Chongqing, China","IEEE Access","","2018","6","","62193","62203","Wind power scenarios have a significant impact on stochastic optimization problems for power systems in which wind power is a significant component. Generative adversarial networks (GANs) are a powerful class of generative models, and can generate realistic scenarios for renewable power sources without the need for any modeling assumptions. However, the performance of GANs in generating scenarios can further be improved by modifying the way in which a Lipschitz constraint on discriminator network is imposed. Another critical problem of applying deep neural networks is overfitting, a phenomenon especially prone to appear on small training sets. In this paper, we propose an improved GAN for the generation of wind power scenarios. To improve the training speed, we use a gradient penalty term to enforce the Lipschitz constraint based on the output and input of the discriminator network. To improve the scenario quality, we further use a consistency term in the training procedure. Besides, the overfitting problem can be effectively alleviated by the enforced Lipschitz continuity. The proposed method is applied to actual time series data from the NREL wind integration data set. The experimental results demonstrate that our method outperforms the existing methods.","","","10.1109/ACCESS.2018.2875936","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8491271","Deep learning;generative adversarial networks;scenario generation;wind power","Wind power generation;Gallium nitride;Training;Production;Uncertainty;Wind forecasting;Autoregressive processes","learning (artificial intelligence);neural nets;optimisation;power engineering computing;stochastic processes;time series;wind power;wind power plants","scenario generation;improved generative adversarial networks;wind power scenarios;stochastic optimization problems;power systems;GANs;generative models;realistic scenarios;renewable power sources;Lipschitz constraint;discriminator network;deep neural networks;improved GAN;scenario quality;training procedure;enforced Lipschitz continuity;NREL wind integration data set","","","40","","","","","IEEE","IEEE Journals"
"Robust Traffic-Sign Detection and Classification Using Mobile LiDAR Data With Digital Images","H. Guan; W. Yan; Y. Yu; L. Zhong; D. Li","College of Geography and Remote Sensing, Nanjing University of Information Science and Technology, Nanjing, China; College of Geography and Remote Sensing, Nanjing University of Information Science and Technology, Nanjing, China; Faculty of Computer and Software Engineering, Huaiyin Institute of Technology, Huaian, China; College of Geography and Remote Sensing, Nanjing University of Information Science and Technology, Nanjing, China; State Key Laboratory of Information Engineering in Surveying, Mapping, and Remote Sensing, Wuhan University, Wuhan, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2018","11","5","1715","1724","This study aims at building a robust method for detecting and classifying traffic signs from mobile LiDAR point clouds and digital images. First, this method detects traffic signs from mobile LiDAR point clouds with regard to a prior knowledge of road width, pole height, reflectance, geometrical structure, and traffic-sign size. Then, traffic-sign images are segmented by projecting the detected traffic-sign points onto the digital images. Afterward, the segmented traffic-sign images are normalized for automatic classification with a given image size. Finally, a traffic-sign classifier is proposed based on a supervised Gaussian-Bernoulli deep Boltzmann machine model. We evaluated the proposed method using datasets acquired by a RIEGL VMX-450 system. The traffic-sign detection accuracy of 86.8% was achieved; through parameter sensitivity analysis, the overall performance of traffic-sign classification achieved a recognition rate of 93.3%. The computational performance showed that our method provides a promising solution to traffic-sign detection and classification using mobile LiDAR point clouds and digital images.","","","10.1109/JSTARS.2018.2810143","Natural Science Foundation of Jiangsu; National Natural Science Foundation of China; Natural Science Research in Colleges and Universities of Jiangsu; Science and Technology Project of Huaian City; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8325411","Digital images;deep learning;geometrical features;intensity;mobile LiDAR point clouds;traffic signs","Laser radar;Roads;Three-dimensional displays;Digital images;Shape;Image color analysis;Feature extraction","Boltzmann machines;feature extraction;Gaussian processes;image classification;image colour analysis;image segmentation;learning (artificial intelligence);object detection;optical radar;roads;sensitivity analysis;traffic engineering computing","traffic-sign classifier;supervised Gaussian-Bernoulli deep Boltzmann machine model;mobile LiDAR point clouds;digital images;mobile LiDAR data;robust method;traffic-sign size;traffic-sign images segmentation;road width;geometrical structure;pole height;RIEGL VMX-450 system;parameter sensitivity analysis;recognition rate","","5","38","","","","","IEEE","IEEE Journals"
"DNN-Based Source Enhancement to Increase Objective Sound Quality Assessment Score","Y. Koizumi; K. Niwa; Y. Hioka; K. Kobayashi; Y. Haneda","Nippon Telegraph and Telephone (NTT) Media Intelligence Laboratories, NTT Corporation, Tokyo, Japan; Nippon Telegraph and Telephone (NTT) Media Intelligence Laboratories, NTT Corporation, Tokyo, Japan; Department of Mechanical Engineering, University of Auckland, Auckland, New Zealand; Nippon Telegraph and Telephone (NTT) Media Intelligence Laboratories, NTT Corporation, Tokyo, Japan; Department of Informatics, The University of Electro-Communications, Tokyo, Japan","IEEE/ACM Transactions on Audio, Speech, and Language Processing","","2018","26","10","1780","1792","We propose a training method for deep neural network (DNN) based source enhancement to increase objective sound quality assessment (OSQA) scores such as the perceptual evaluation of speech quality. In many conventional studies, DNNs have been used as a mapping function to estimate time-frequency masks and trained to minimize an analytically tractable objective function such as the mean squared error (MSE). Since OSQA scores have been used widely for sound-quality evaluation, constructing DNNs to increase OSQA scores would be better than using the minimum MSE to create high-quality output signals. However, since most OSQA scores are not analytically tractable, i.e., they are black boxes, the gradient of the objective function cannot be calculated by simply applying backpropagation. To calculate the gradient of the OSQA-based objective function, we formulated a DNN optimization scheme on the basis of black-box optimization, which is used for training a computer that plays a game. For a black-box-optimization scheme, we adopt the policy gradient method for calculating the gradient on the basis of a sampling algorithm. To simulate output signals using the sampling algorithm, DNNs are used to estimate the probability density function of the output signals that maximize OSQA scores. The OSQA scores are calculated from the simulated output signals, and the DNNs are trained to increase the probability of generating the simulated output signals that achieve high OSQA scores. Through several experiments, we found that OSQA scores significantly increased by applying the proposed method, even though the MSE was not minimized.","","","10.1109/TASLP.2018.2842156","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8369109","Sound-source enhancement;time-frequency mask;deep learning;objective sound quality assessment (OSQA) score","Training;Linear programming;Optimization;Speech processing;Quality assessment;Time-frequency analysis;Estimation","backpropagation;gradient methods;learning (artificial intelligence);mean square error methods;neural nets;optimisation;probability;speech enhancement","objective sound quality assessment score;deep neural network based source enhancement;sound-quality evaluation;high-quality output signals;high OSQA scores;backpropagation;DNN optimization scheme;black-box-optimization scheme;policy gradient method","","8","58","","","","","IEEE","IEEE Journals"
"A Multimodal Classifier Generative Adversarial Network for Carry and Place Tasks From Ambiguous Language Instructions","A. Magassouba; K. Sugiura; H. Kawai","National Institute of Information and Communication Technology, Kyoto, Japan; National Institute of Information and Communication Technology, Kyoto, Japan; National Institute of Information and Communication Technology, Kyoto, Japan","IEEE Robotics and Automation Letters","","2018","3","4","3113","3120","This letter focuses on a multimodal language understanding method for carry-and-place tasks with domestic service robots. We address the case of ambiguous instructions, that is, when the target area is not specified. For instance “put away the milk and cereal” is a natural instruction where there is ambiguity regarding the target area, considering environments in daily life. Conventionally, this instruction can be disambiguated from a dialogue system, but at the cost of time and cumbersome interaction. Instead, we propose a multimodal approach, in which the instructions are disambiguated using the robot's state and environment context. We develop the Multi-Modal Classifier Generative Adversarial Network (MMC-GAN) to predict the likelihood of different target areas considering the robot's physical limitation and the target clutter. Our approach, MMC-GAN, significantly improves accuracy compared with baseline methods that use instructions only or simple deep neural networks.","","","10.1109/LRA.2018.2849607","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8392364","Deep learning in robotics and automation;domestic robots;robot audition","Task analysis;Robots;Gallium nitride;Linguistics;Visualization;Feature extraction;Generators","learning (artificial intelligence);mobile robots;natural language processing;neural nets;service robots;speech recognition","MMC-GAN;simple deep neural networks;multimodal Classifier Generative Adversarial Network;carry;multimodal language understanding method;domestic service robots;carry-and-place tasks","","3","23","","","","","IEEE","IEEE Journals"
"Model-Free Renewable Scenario Generation Using Generative Adversarial Networks","Y. Chen; Y. Wang; D. Kirschen; B. Zhang","Department of Electrical Engineering, University of Washington, Seattle, WA, USA; GEIRI North America, San Jose, CA, USA; Department of Electrical Engineering, University of Washington, Seattle, WA, USA; Department of Electrical Engineering, University of Washington, Seattle, WA, USA","IEEE Transactions on Power Systems","","2018","33","3","3265","3275","Scenario generation is an important step in the operation and planning of power systems with high renewable penetrations. In this work, we proposed a data-driven approach for scenario generation using generative adversarial networks, which is based on two interconnected deep neural networks. Compared with existing methods based on probabilistic models that are often hard to scale or sample from, our method is data-driven, and captures renewable energy production patterns in both temporal and spatial dimensions for a large number of correlated resources. For validation, we use wind and solar times-series data from NREL integration data sets. We demonstrate that the proposed method is able to generate realistic wind and photovoltaic power profiles with full diversity of behaviors. We also illustrate how to generate scenarios based on different conditions of interest by using labeled data during training. For example, scenarios can be conditioned on weather events (e.g., high wind day, intense ramp events, or large forecasts errors) or time of the year (e.g., solar generation for a day in July). Because of the feedforward nature of the neural networks, scenarios can be generated extremely efficiently without sophisticated sampling techniques.","","","10.1109/TPWRS.2018.2794541","Washington Clean Energy Institute; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8260947","Renewable integration;scenario generation;deep learning;generative models","Gallium nitride;Training;Autoregressive processes;Generators;Power generation;Probabilistic logic;Wind","feedforward neural nets;learning (artificial intelligence);photovoltaic power systems;power engineering computing;power generation planning;probability;solar power stations;time series;wind power plants","model-free renewable scenario generation;generative adversarial networks;high renewable penetrations;interconnected deep neural networks;probabilistic models;solar times-series data;NREL integration data sets;photovoltaic power profiles;solar generation;power system planning;renewable energy production patterns;data-driven approach;spatial dimensions;temporal dimensions;wind power profiles;feedforward neural networks;wind times-series data","","23","33","","","","","IEEE","IEEE Journals"
"Scene Classification Based on Multiscale Convolutional Neural Network","Y. Liu; Y. Zhong; Q. Qin","State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China","IEEE Transactions on Geoscience and Remote Sensing","","2018","56","12","7109","7121","With the large amount of high-spatial resolution images now available, scene classification aimed at obtaining high-level semantic concepts has drawn great attention. The convolutional neural networks (CNNs), which are typical deep learning methods, have widely been studied to automatically learn features for the images for scene classification. However, scene classification based on CNNs is still difficult due to the scale variation of the objects in remote sensing imagery. In this paper, a multiscale CNN (MCNN) framework is proposed to solve the problem. In MCNN, a network structure containing dual branches of a fixed-scale net (F-net) and a varied-scale net (V-net) is constructed and the parameters are shared by the F-net and V-net. The images and their rescaled images are fed into the F-net and V-net, respectively, allowing us to simultaneously train the shared network weights on multiscale images. Furthermore, to ensure that the features extracted from MCNN are scale invariant, a similarity measure layer is added to MCNN, which forces the two feature vectors extracted from the image and its corresponding rescaled image to be as close as possible in the training phase. To demonstrate the effectiveness of the proposed method, we compared the results obtained using three widely used remote sensing data sets: the UC Merced data set, the aerial image data set, and the google data set of SIRI-WHU. The results confirm that the proposed method performs significantly better than the other state-of-the-art scene classification methods.","","","10.1109/TGRS.2018.2848473","National Natural Science Foundation of China; National Key Research and Development Program of China; Natural Science Foundation of Hubei Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8421052","Convolutional neural networks (CNNs);multiscale;scene classification;similarity measure","Feature extraction;Remote sensing;Semantics;Convolutional neural networks;Training data;Machine learning;Object oriented modeling","convolution;feature extraction;feedforward neural nets;geophysical image processing;image classification;learning (artificial intelligence);remote sensing","multiscale convolutional neural network;high-spatial resolution images;high-level semantic concepts;CNNs;typical deep learning methods;scale variation;multiscale CNN framework;MCNN;network structure;fixed-scale net;varied-scale net;V-net;F-net;shared network weights;multiscale images;aerial image data;remote sensing data sets;scene classification methods;remote sensing imagery;images rescaling;SIRI-WHU","","8","65","","","","","IEEE","IEEE Journals"
"Learning to Weight for Text Classification","A. Moreo Fernandez; A. Esuli; F. Sebastiani","Networked Multimedia Information Systems Laboratory (NeMIS), Istituto di Scienza e Tecnologie dellInformazione, CNR, Pisa, Tuscany Italy (e-mail: alejandro.moreo@isti.cnr.it); ISTI, CNR, Pisa, Pisa Italy (e-mail: andrea.esuli@isti.cnr.it); Istituto di Scienza e Tecnologie dell'Informazione, Consiglio Nazionale delle Ricerche, Pisa, Tuscany Italy 56124 (e-mail: fabrizio.sebastiani@isti.cnr.it)","IEEE Transactions on Knowledge and Data Engineering","","2018","PP","99","1","1","In information retrieval (IR) and related tasks, term weighting approaches typically consider the frequency of the term in the document and in the collection in order to compute a score reflecting the importance of the term for the document. In tasks characterized by the presence of training data (such as text classification) it seems logical to design a term weighting function that leverages the distribution (as estimated from training data) of the term across the classes of interest. Although ""supervised term weighting"" approaches that use this intuition have been described before, they have failed to show consistent improvements. In this article we analyse the possible reasons for this failure, and call consolidated assumptions into question. Following this criticism, we propose a novel supervised term weighting approach that, instead of relying on any predefined formula, learns a term weighting function optimised on the training set of interest; we dub this approach Learning to Weight (LTW). The experiments that we have run on several well-known benchmarks, and using different learning methods, show that our method outperforms previous term weighting approaches in text classification.","","","10.1109/TKDE.2018.2883446","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8550687","Term weighting;Supervised term weighting;Text classification;Neural networks;Deep learning","Training data;Task analysis;Training;Neural networks;Feature extraction;Time-frequency analysis;Information retrieval","","","","","","","","","","IEEE","IEEE Early Access Articles"
"MIMO-FMCW Radar-Based Parking Monitoring Application With a Modified Convolutional Neural Network With Spatial Priors","J. Martínez García; D. Zoeke; M. Vossiek","Institute of Microwaves and Photonics (LHFT), University of Erlangen-Nuremberg, Erlangen, Germany; Siemens AG, Munich, Germany; Institute of Microwaves and Photonics (LHFT), University of Erlangen-Nuremberg, Erlangen, Germany","IEEE Access","","2018","6","","41391","41398","Radar imaging is a competitive option for smart city applications over optical approaches, as it raises no privacy concerns. The inherent difficulty of interpreting radar signals can be overcome using deep learning techniques to leverage the capabilities of monitoring sensors with a minimum of human intervention. In this paper, we use a modified convolutional neural network (CNN) for classifying radar images in order to detect vacant parking spaces with a 77-GHz imaging radar. Although training CNNs for radar-image classification is challenging due to poor generalization performance caused by the lack of labeled training data, the modified architecture takes into account the properties of the radar image in order to introduce prior information into the model and improve performance. A MIMO-FMCW radar is utilized to render a slant-range image of a parking scenario, and the image patches corresponding to each parking location are classified independently in the CNN. Since the radiation pattern of a MIMO array varies as a function of the scanning angle, the corresponding spatial coordinate of each patch is included as an additional feature in the upper layers of the network. This allows the model to combine local features from each patch with global scenario information in order to learn robust features that generalize properly to new scenarios. Several models are trained end to end with data from four different parking scenarios and evaluated in a 4-fold cross-validation scheme, and performance is improved when spatial prior information is included.","","","10.1109/ACCESS.2018.2857007","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8412486","Convolutional neural networks;MIMO radar;parking monitoring;smart cities","Radar imaging;Feature extraction;Sensors;Data models;Monitoring;Machine learning","CW radar;feature extraction;feedforward neural nets;FM radar;image classification;learning (artificial intelligence);millimetre wave radar;MIMO radar;radar detection;radar imaging;smart cities;traffic information systems","77-GHz imaging radar;radar-image classification;slant-range image;parking scenario;image patches;spatial prior information;MIMO-FMCW radar-based parking monitoring application;modified convolutional neural network;smart city applications;radar signals;CNN training;performance improvement;radiation pattern;MIMO array;4-fold cross-validation;deep learning;vacant parking space detection;frequency 77 GHz","","","23","","","","","IEEE","IEEE Journals"
"Webshell Traffic Detection With Character-Level Features Based on Deep Learning","H. Zhang; H. Guan; H. Yan; W. Li; Y. Yu; H. Zhou; X. Zeng","State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; National Computer Network Emergency Response Technical Team/Coordination Center of China, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China; School of Economics and Management, Beihang University, Beijing, China; National Computer Network Emergency Response Technical Team/Coordination Center of China, Beijing, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China","IEEE Access","","2018","6","","75268","75277","Webshell is a kind of backdoor programs based on Web services. Network-based detection could monitor the request and response traffic to find abnormal behaviors and detect the existence of Webshell. Some machine learning and deep learning methods have been used in this field, but the current methods need to be further explored in discovering new attacks and performance. In order to detect large-scale unknown Webshell events, we propose a Webshell traffic detection model combining the characteristics of convolutional neural network and long short-term memory network. At the same time, we propose a character-level traffic content feature transformation method. We apply the method in our proposed model and evaluate our approach on a Webshell detection testbed. The experiment result indicates that the model has a high precision rate and recall rate, and the generalization ability can be guaranteed.","","","10.1109/ACCESS.2018.2882517","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8540857","Webshell;character level;convolutional neural network;long short term memory","Trojan horses;Feature extraction;Uniform resource locators;Servers;Security;Choppers (circuits)","","","","","33","","","","","IEEE","IEEE Journals"
"YoTube: Searching Action Proposal Via Recurrent and Static Regression Networks","H. Zhu; R. Vial; S. Lu; X. Peng; H. Fu; Y. Tian; X. Cao","Institute for Infocomm Research, A*Star, Singapore; Mines ParisTech, Paris, France; School of Computer Science and Engineering, Nanyang Technological University, Singapore; College of Computer Science, Sichuan University, Chengdu, China; Institute for Infocomm Research, A*Star, Singapore; National Engineering Laboratory for Video Technology, School of EECS, Peking University, Beijing, China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China","IEEE Transactions on Image Processing","","2018","27","6","2609","2622","In this paper, we propose YoTube-a novel deep learning framework for generating action proposals in untrimmed videos, where each action proposal corresponds to a spatial-temporal tube that potentially locates one human action. Most of the existing works generate proposals by clustering low-level features or linking image proposals, which ignore the interplay between long-term temporal context and short-term cues. Different from these works, our method considers the interplay by designing a new recurrent YoTube detector and static YoTube detector. The recurrent YoTube detector sequentially regresses candidate bounding boxes using Recurrent Neural Network learned long-term temporal contexts. The static YoTube detector produces bounding boxes using rich appearance cues in every single frame. To fully exploit the complementary appearance, motion, and temporal context, we train the recurrent and static detector using RGB (Color) and flow information. Moreover, we fuse the corresponding outputs of the detectors to produce accurate and robust proposal boxes and obtain the final action proposals by linking the proposal boxes using dynamic programming with a novel path trimming method. Benefiting from the pipeline of our method, the untrimmed video could be effectively and efficiently handled. Extensive experiments on the challenging UCF-101, UCF-Sports, and JHMDB datasets show superior performance of the proposed method compared with the state of the arts.","","","10.1109/TIP.2018.2806279","National Nature Science Foundation of China; Fundamental Research Funds for the Central Universities; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8291617","Image sequence analysis;object detection;activity recognition","Proposals;Videos;Detectors;Feature extraction;Machine learning;Image recognition;Task analysis","dynamic programming;image classification;image motion analysis;learning (artificial intelligence);object detection;recurrent neural nets;regression analysis;video signal processing","recurrent regression networks;static regression networks;deep learning framework;untrimmed video;action proposal corresponds;spatial-temporal tube;human action;existing works;path trimming method;dynamic programming;image proposal linking;low-level features clustering;recurrent neural network;final action proposals;robust proposal boxes;accurate proposal boxes;rich appearance cues;static YoTube detector;recurrent YoTube detector;short-term cues;long-term temporal context","","18","66","","","","","IEEE","IEEE Journals"
"Learning Transformation-Invariant Representations for Image Recognition With Drop Transformation Networks","C. Fan; Y. Li; G. Wang; Y. Li","School of Electronic Engineering, Beijing University of Posts and Telecommunications, Beijing, China; School of Electronic Engineering, Beijing University of Posts and Telecommunications, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; School of Electronic Engineering, Beijing University of Posts and Telecommunications, Beijing, China","IEEE Access","","2018","6","","73357","73369","This paper proposes a drop transformation networks (DTNs), a novel framework of learning transformation-invariant representations of images with good flexibility and generalization ability. Convolutional neural networks are a powerful end-to-end learning framework that can learn hierarchies of representations. Although the invariance to translation of the representations can be introduced by the approach of stacking convolutional and max-pooling layers, the approach is not effective in tackling other geometric transformations such as rotation and scale. Rotation and scale invariance are usually obtained through data augmentation, but this requires larger model size and more training time. DTN formulates transformation-invariant representations through explicitly manipulating geometric transformations within it. DTN applies multiple random transformations to its inputs but keeps only one output according to the given dropout policy. In this way, the complex dependencies of the knowledge on transformations contained in training data can be alleviated, and therefore the generalization to transformations is improved. Another advantage of DTN is the flexibility. Under the proposed framework, data augmentation can be seen as a special case. We evaluate DTN on three benchmark data sets and show that it can provide better performance with smaller number of parameters compared to state-of-the-art methods.","","","10.1109/ACCESS.2018.2850965","National Natural Science Foundation of China; National Great Science Specific Project; Natural Science Foundation of Beijing Municipality; Beijing University of Posts and Telecommunications; Beijing Key Laboratory of Work Safety and Intelligent Monitoring; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8397162","Convolutional neural networks;deep learning;image representation;transformation-invariance","Microsoft Windows;Network architecture;Complexity theory;Image recognition;Transforms;Computer architecture;Stacking","","","","","42","","","","","IEEE","IEEE Journals"
"Vehicle Re-Identification by Deep Hidden Multi-View Inference","Y. Zhou; L. Liu; L. Shao","Inception Institute of Artificial Intelligence, Abu Dhabi, United Arab Emirates; Inception Institute of Artificial Intelligence, Abu Dhabi, United Arab Emirates; Inception Institute of Artificial Intelligence, Abu Dhabi, United Arab Emirates","IEEE Transactions on Image Processing","","2018","27","7","3275","3287","Vehicle re-identification (re-ID) is an area that has received far less attention in the computer vision community than the prevalent person re-ID. Possible reasons for this slow progress are the lack of appropriate research data and the special 3D structure of a vehicle. Previous works have generally focused on some specific views (e.g., front); but, these methods are less effective in realistic scenarios, where vehicles usually appear in arbitrary views to cameras. In this paper, we focus on the uncertainty of vehicle viewpoint in re-ID, proposing two end-to-end deep architectures: the Spatially Concatenated ConvNet and convolutional neural network (CNN)-LSTM bi-directional loop. Our models exploit the great advantages of the CNN and long short-term memory (LSTM) to learn transformations across different viewpoints of vehicles. Thus, a multi-view vehicle representation containing all viewpoints' information can be inferred from the only one input view, and then used for learning to measure distance. To verify our models, we also introduce a Toy Car RE-ID data set with images from multiple viewpoints of 200 vehicles. We evaluate our proposed methods on the Toy Car RE-ID data set and the public Multi-View Car, VehicleID, and VeRi data sets. Experimental results illustrate that our models achieve consistent improvements over the state-of-the-art vehicle re-ID approaches.","","","10.1109/TIP.2018.2819820","Createc, Cockermouth, U.K.; University of East Anglia, Norwich, U.K.; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8325486","Vehicle re-identification;multi-view;spatially concatenated ConvNet;CNN-LSTM bi-directional loop","Automobiles;Toy manufacturing industry;Feature extraction;Cameras;Task analysis;Measurement;Licenses","automobiles;computer vision;convolution;feedforward neural nets;image representation;inference mechanisms;traffic engineering computing","deep hidden MultiView inference;computer vision community;vehicle viewpoint;end-to-end deep architectures;Spatially Concatenated ConvNet;convolutional neural network-LSTM bi-directional loop;long short-term memory;multiview vehicle representation;Toy Car RE-ID data;public MultiView Car;VeRi data sets;person re-ID;3D structure;vehicle re-ID;Vehicle Re-Identification","","11","56","","","","","IEEE","IEEE Journals"
"Machine Health Monitoring Using Local Feature-Based Gated Recurrent Unit Networks","R. Zhao; D. Wang; R. Yan; K. Mao; F. Shen; J. Wang","School of Electrical and Electronic Engineering, Nanyang Technology University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technology University, Singapore; School of Instrument Science and Engineering, Southeast University, Nanjing, China; School of Electrical and Electronic Engineering, Nanyang Technology University, Singapore; School of Instrument Science and Engineering, Southeast University, Nanjing, China; Faculty of Mechanical Engineering, China University of Petroleum, Beijing, China","IEEE Transactions on Industrial Electronics","","2018","65","2","1539","1548","In modern industries, machine health monitoring systems (MHMS) have been applied wildly with the goal of realizing predictive maintenance including failures tracking, downtime reduction, and assets preservation. In the era of big machinery data, data-driven MHMS have achieved remarkable results in the detection of faults after the occurrence of certain failures (diagnosis) and prediction of the future working conditions and the remaining useful life (prognosis). The numerical representation for raw sensory data is the key stone for various successful MHMS. Conventional methods are the labor-extensive as they usually depend on handcrafted features, which require expert knowledge. Inspired by the success of deep learning methods that redefine representation learning from raw data, we propose local feature-based gated recurrent unit (LFGRU) networks. It is a hybrid approach that combines handcrafted feature design with automatic feature learning for machine health monitoring. First, features from windows of input time series are extracted. Then, an enhanced bidirectional GRU network is designed and applied on the generated sequence of local features to learn the representation. A supervised learning layer is finally trained to predict machine condition. Experiments on three machine health monitoring tasks: tool wear prediction, gearbox fault diagnosis, and incipient bearing fault detection verify the effectiveness and generalization of the proposed LFGRU.","","","10.1109/TIE.2017.2733438","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7997605","Fault diagnosis;feature engineering;gated recurrent unit (GRU);machine health monitoring (MHM);tool wear prediction","Feature extraction;Logic gates;Monitoring;Sensors;Data mining;Fault diagnosis;Computational modeling","condition monitoring;fault diagnosis;gears;learning (artificial intelligence);machinery;maintenance engineering;mechanical engineering computing;wear","recurrent unit networks;machine health monitoring systems;big machinery data;numerical representation;raw sensory data;deep learning methods;enhanced bidirectional GRU network;supervised learning layer;machine condition;tool wear prediction;gearbox fault diagnosis;incipient bearing fault detection;predictive maintenance;MHMS;feature-based gated recurrent unit","","41","33","Traditional","","","","IEEE","IEEE Journals"
"VPRS-Based Regional Decision Fusion of CNN and MRF Classifications for Very Fine Resolution Remotely Sensed Images","C. Zhang; I. Sargent; X. Pan; A. Gardiner; J. Hare; P. M. Atkinson","Lancaster Environment Centre, Lancaster University, Lancaster, U.K.; Ordnance Survey, Southampton, U.K.; School of Computer Technology and Engineering, Changchun Institute of Technology, Changchun, China; Ordnance Survey, Southampton, U.K.; Electronics and Computer Science, University of Southampton, Southampton, U.K.; Lancaster Environment Centre, Lancaster University, Lancaster, U.K.","IEEE Transactions on Geoscience and Remote Sensing","","2018","56","8","4507","4521","Recent advances in computer vision and pattern recognition have demonstrated the superiority of deep neural networks using spatial feature representation, such as convolutional neural networks (CNNs), for image classification. However, any classifier, regardless of its model structure (deep or shallow), involves prediction uncertainty when classifying spatially and spectrally complicated very fine spatial resolution (VFSR) imagery. We propose here to characterize the uncertainty distribution of CNN classification and integrate it into a regional decision fusion to increase classification accuracy. Specifically, a variable precision rough set (VPRS) model is proposed to quantify the uncertainty within CNN classifications of VFSR imagery and partition this uncertainty into positive regions (correct classifications) and nonpositive regions (uncertain or incorrect classifications). Those “more correct” areas were trusted by the CNN, whereas the uncertain areas were rectified by a multilayer perceptron (MLP)-based Markov random field (MLP-MRF) classifier to provide crisp and accurate boundary delineation. The proposed MRF-CNN fusion decision strategy exploited the complementary characteristics of the two classifiers based on VPRS uncertainty description and classification integration. The effectiveness of the MRF-CNN method was tested in both urban and rural areas of southern England as well as semantic labeling data sets. The MRF-CNN consistently outperformed the benchmark MLP, support vector machine, MLP-MRF, CNN, and the baseline methods. This paper provides a regional decision fusion framework within which to gain the advantages of model-based CNN, while overcoming the problem of losing effective resolution and uncertain prediction at object boundaries, which is especially pertinent for complex VFSR image classification.","","","10.1109/TGRS.2018.2822783","National Key Research and Development Program of China; Ordnance Survey and Lancaster University through the Ph.D. Studentship “Deep Learning in Massive Area, Multi-Scale Resolution Remotely Sensed Imagery”; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8345225","Convolutional neural network (CNN);Markov random field (MRF);regional fusion decision;rough set;uncertainty","Uncertainty;Remote sensing;Rough sets;Spatial resolution;Support vector machines;Machine learning","computer vision;convolution;feature extraction;geophysical image processing;image classification;image resolution;integration;Markov processes;multilayer perceptrons;prediction theory;remote sensing;rough set theory;support vector machines;uncertain systems","computer vision;pattern recognition;deep neural networks;spatial feature representation;convolutional neural networks;prediction uncertainty;uncertainty distribution;CNN classification;variable precision rough set model;partition;classification integration;complex VFSR image classification;MRF classifications;very fine spatial resolution imagery;multilayer perceptron based Markov random field classifier;VPRS based regional decision fusion;fine resolution remotely sensed images;Southern England;semantic labeling data sets;support vector machine","","4","61","","","","","IEEE","IEEE Journals"
"Replicating a Trading Strategy by Means of LSTM for Financial Industry Applications","L. Troiano; E. M. Villa; V. Loia","Department of Engineering, University of Sannio, Benevento, Italy; Department of Engineering, University of Sannio, Benevento, Italy; Department of Innovation Systems, University of Salerno, Fisciano, Italy","IEEE Transactions on Industrial Informatics","","2018","14","7","3226","3234","This paper investigates the possibility of learning a trading rule looking at the relationship between market indicators and decisions undertaken regarding entering or quitting a position. As means to achieve this objective, we employ a long short-term memory machine, due its capability to relate past and recent events. Our solution is a first step in the direction of building a model-free robot, based on deep learning, able to identify the logic that links the market mood given by technical indicators to the undertaken investment decisions. Although preliminary, experimental results show that the proposed solution is viable and promising.","","","10.1109/TII.2018.2811377","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8305636","Recurrent neural networks;robot Learning;stock markets","Computer architecture;Microprocessors;Logic gates;Robots;Time series analysis;Training;Mathematical model","financial management;formal logic;investment;learning (artificial intelligence);market opportunities;robots;stock markets","model-free robot;deep learning;market mood;trading strategy;LSTM;financial industry applications;trading rule;market indicators;short-term memory machine;investment decisions","","1","41","","","","","IEEE","IEEE Journals"
"Bearing Fault Diagnosis Using Fully-Connected Winner-Take-All Autoencoder","C. Li; W. Zhang; G. Peng; S. Liu","State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, China; State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, China; State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, China; Department of Computer Science, Harbin Institute of Technology, Harbin, China","IEEE Access","","2018","6","","6103","6115","Intelligent fault diagnosis of bearings has been a heated research topic in the prognosis and health management of rotary machinery systems, due to the increasing amount of available data collected by sensors. This has given rise to more and more business desire to apply data-driven methods for health monitoring of machines. In recent years, various deep learning algorithms have been adapted to this field, including multi-layer perceptrons, autoencoders, convolutional neural networks, and so on. Among these methods, autoencoder is of particular interest for us because of its simple structure and its ability to learn useful features from data in an unsupervised fashion. Previous studies have exploited the use of autoencoders, such as denoising autoencoder, sparsity aotoencoder, and so on, either with one layer or with several layers stacked together, and they have achieved success to certain extent. In this paper, a bearing fault diagnosis method based on fully-connected winner-take-all autoencoder is proposed. The model explicitly imposes lifetime sparsity on the encoded features by keeping only k% largest activations of each neuron across all samples in a mini-batch. A soft voting method is implemented to aggregate prediction results of signal segments sliced by a sliding window to increase accuracy and stability. A simulated data set is generated by adding white Gaussian noise to original signals to test the diagnosis performance under noisy environment. To evaluate the performance of the proposed method, we compare our methods with some state-of-the-art bearing fault diagnosis methods. The experiments result show that, with a simple two-layer network, the proposed method is not only capable of diagnosing with high precision under normal conditions, but also has better robustness to noise than some deeper and more complex models.","","","10.1109/ACCESS.2017.2717492","National High-Tech Research and Development Program of China (863 Program); National Natural Science Foundation of China; Self-Planned Task of the State Key Laboratory of Robotics and System; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7956142","Autoencoder;fault diagnosis;lifetime sparsity;signal processing;signal representations;supervised learning;vibrations","Fault diagnosis;Robustness;Noise reduction;Training;Feature extraction;Noise measurement;Robots","condition monitoring;fault diagnosis;Gaussian noise;learning (artificial intelligence);machine bearings;machinery;signal denoising;signal representation;vibrational signal processing","bearing fault diagnosis;winner-take-all autoencoder;unsupervised fashion;signal segments;Gaussian noise;vibration signals;two-layer network;diagnosis performance;soft voting method;fully-connected winner;bearing fault diagnosis method;deep learning algorithms;rotary machinery systems;health management;prognosis;bearings;intelligent fault diagnosis;autoencoder","","8","21","","","","","IEEE","IEEE Journals"
"Center-Point-Guided Proposal Generation for Detection of Small and Dense Buildings in Aerial Imagery","Z. Shu; X. Hu; J. Sun","School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; School of Resource and Environmental Sciences, Wuhan University, Wuhan, China","IEEE Geoscience and Remote Sensing Letters","","2018","15","7","1100","1104","For automatic building detection in aerial images, small and dense buildings make it a very challenging task. It is because small objects lack sufficient information, and dense building distribution makes the localization of the objects confusing. High-quality building proposals can certainly promote the detection performance. The key to the problem is adopting sufficiently proper size and location of bounding boxes to use the image information for the proposal generation. Based on machine learning with a deep convolutional neural network, this letter proposes a new pipeline of building proposal generation, which is an end-to-end process during training and testing. First, the proposed pipeline attempts to find possible object center points called point proposals. Subsequently, a location refinement module and an object scoring module are applied to the boxes generated from the point proposals with a series of sizes and aspect ratios to obtain the final object proposals. This center-point-guided location refinement and multibox scoring method effectively alleviates the small and dense object problems. Experiments in INRIA Aerial Image Labeling data set demonstrate the better performance of our approach than other state-of-the-art proposal methods. In addition, we add a normal classification branch based on our generated proposals to conduct experiments on detection task. Detection result outperforms the latest detection framework R-FCN equipped with ResNet-101 7% mean average precision at 0.7.","","","10.1109/LGRS.2018.2822760","National Key Research and Development Program of China; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8344558","Aerial imagery;building detection;deep convolutional network;dense buildings;object proposal;small buildings","Proposals;Feature extraction;Training;Testing;Windows;Microsoft Windows","buildings (structures);feedforward neural nets;geophysical image processing;learning (artificial intelligence);object detection;remote sensing","machine learning;object center points;INRIA aerial image labeling data set;multibox scoring method;center-point-guided location refinement;final object proposals;object scoring module;location refinement module;point proposals;end-to-end process;deep convolutional neural network;image information;bounding boxes;detection performance;high-quality building proposals;dense building distribution;aerial images;automatic building detection;aerial imagery;center-point-guided proposal generation;dense object problems;small object problems","","3","28","","","","","IEEE","IEEE Journals"
"Semantic Labeling Using a Low-Power Neuromorphic Platform","J. Tang; B. S. Mashford; A. J. Yepes","IBM Research Australia, Southbank, VIC, Australia; IBM Research Australia, Southbank, VIC, Australia; IBM Research Australia, Southbank, VIC, Australia","IEEE Geoscience and Remote Sensing Letters","","2018","15","8","1184","1188","Deep learning is a powerful technique for the analysis of remote sensing imagery. For applications that require real-time processing on mobile platforms, a low power consumption processing unit is advantageous. The human brain is remarkably powerful at image recognition tasks while operating at very low power consumption levels. Neuromorphic computing designs aim to achieve energy efficiency through the use of spiking neurons and low-precision synapses to perform data processing. We demonstrate here the classification of red, green, blue and depth and hyperspectral data sets using a neuromorphic processing unit (IBM TrueNorth Neurosynaptic System). The convolutional neural-network architecture of the classifier network has been adapted to fit the neuromorphic architecture. The results on overhead imagery and hyperspectral imagery data show that neuromorphic platforms can achieve the state-of-theart performance in semantic labeling with significantly (≈1000×) lower power consumption than traditional GPU-based solutions.","","","10.1109/LGRS.2018.2834522","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8374950","Brain-inspired computing;deep neural networks (DNNs);hyperspectral imaging;ISPRS 2-D semantic labeling;semantic labeling","Neurons;Labeling;Semantics;Training;Power demand;Hyperspectral imaging","convolution;feedforward neural nets;graphics processing units;hyperspectral imaging;image classification;learning (artificial intelligence);neural net architecture;power consumption;remote sensing","semantic labeling;deep learning;remote sensing imagery;mobile platforms;human brain;neuromorphic computing designs;neuromorphic processing unit;convolutional neural-network architecture;neuromorphic architecture;hyperspectral imagery data;image recognition;IBM TrueNorth neurosynaptic system;power consumption;spiking neurons;data processing;classifier network;GPU solutions","","","22","","","","","IEEE","IEEE Journals"
"Vision-Based Parking-Slot Detection: A DCNN-Based Approach and a Large-Scale Benchmark Dataset","L. Zhang; J. Huang; X. Li; L. Xiong","School of Software Engineering, Tongji University, Shanghai, China; School of Software Engineering, Tongji University, Shanghai, China; School of Software Engineering, Tongji University, Shanghai, China; Institute of Intelligent Vehicle, Tongji University, Shanghai, China","IEEE Transactions on Image Processing","","2018","27","11","5350","5364","In the automobile industry, recent years have witnessed a growing interest in developing self-parking systems. For such systems, how to accurately and efficiently detect and localize the parking slots defined by regular line segments near the vehicle is a key and still unresolved issue. In fact, kinds of unfavorable factors, such as the diversity of ground materials, changes in illumination conditions, and unpredictable shadows caused by nearby trees, make the vision-based parking-slot detection much harder than it looks. In this paper, we attempt to solve this issue to some extent and our contributions are twofold. First, we propose a novel deep convolutional neural network (DCNN)-based parking-slot detection approach, namely, DeepPS, which takes the surround-view image as the input. There are two key steps in DeepPS, identifying all the marking points on the input image and classifying local image patterns formed by pairs of marking points. We formulate both of them as learning problems, which can be solved naturally by modern DCNN models. Second, to facilitate the study of vision-based parking-slot detection, a large-scale labeled dataset is established. This dataset is the largest in this field, comprising 12 165 surround-view images collected from typical indoor and outdoor parking sites. For each image, the marking points and parking slots are carefully labeled. The efficacy and efficiency of DeepPS have been corroborated on our collected dataset. To make our results fully reproducible, all the relevant source codes and the dataset have been made publicly available at https://cslinzhang.github.io/deepps/.","","","10.1109/TIP.2018.2857407","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; Shanghai Automotive Industry Science and Technology Development Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8412601","Self-parking systems;parking-slot detection;deep convolutional neural networks","Feature extraction;Cameras;Convolutional neural networks;Detectors;Transforms;Space vehicles","computer vision;convolution;image classification;image segmentation;learning (artificial intelligence);neural nets;traffic engineering computing","marking points;vision-based parking-slot detection;surround-view image;typical indoor parking sites;outdoor parking sites;parking slots;DCNN-based approach;self-parking systems;deep convolutional neural network-based parking-slot detection approach;input image;large-scale benchmark dataset;DeepPS;local image pattern classification;learning problems;large-scale labeled dataset;indoor parking sites;source codes","","6","70","","","","","IEEE","IEEE Journals"
"Detect Globally, Label Locally: Learning Accurate 6-DOF Object Pose Estimation by Joint Segmentation and Coordinate Regression","A. Nigam; A. Penate-Sanchez; L. Agapito","Department of Computer Science, University College London, London, U.K.; Department of Computer Science, University College London, London, U.K.; Department of Computer Science, University College London, London, U.K.","IEEE Robotics and Automation Letters","","2018","3","4","3960","3967","Coordinate regression has established itself as one of the most successful current trends in model-based 6 degree of freedom (6-DOF) object pose estimation from a single image. The underlying idea is to train a system that can regress the three-dimensional coordinates of an object, given an input RGB or RGB-D image and known object geometry, followed by a robust procedure such as RANSAC to optimize the object pose. These coordinate regression based approaches exhibit state-of-the-art performance by using pixel-level cues to model the probability distribution of object parts within the image. However, they fail to capture global information at the object level to learn accurate foreground/background segmentation. In this letter, we show that combining global features for object segmentation and local features for coordinate regression results in pixel-accurate object boundary detections and consequently a substantial reduction in outliers and an increase in overall performance. We propose a deep architecture with an instance-level object segmentation network that exploits global image information for object/background segmentation and a pixel-level classification network for coordinate regression based on local features. We evaluate our approach on the standard ground-truth 6-DOF pose estimation benchmarks and show that our joint approach to accurate object segmentation and coordinate regression results in the state-of-the-art performance on both RGB and RGB-D 6-DOF pose estimation.","","","10.1109/LRA.2018.2858446","Second Hands project; EU Horizon 2020 Research and Innovation programme; EPSRC; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8417447","Object detection;segmentation and categorization;deep learning in robotics and automation","Three-dimensional displays;Pose estimation;Image segmentation;Labeling;Robustness;Object segmentation;Robots","image capture;image colour analysis;image segmentation;object detection;pose estimation;regression analysis","pose estimation;foreground/background segmentation;pixel-level classification network;object/background segmentation;instance-level object segmentation network;pixel-accurate object boundary detections","","1","33","","","","","IEEE","IEEE Journals"
"DSIP: A Scalable Inference Accelerator for Convolutional Neural Networks","J. Jo; S. Cha; D. Rho; I. Park","School of Electrical Engineering, KAIST, Daejeon, South Korea; School of Electrical Engineering, KAIST, Daejeon, South Korea; School of Electrical Engineering, KAIST, Daejeon, South Korea; School of Electrical Engineering, KAIST, Daejeon, South Korea","IEEE Journal of Solid-State Circuits","","2018","53","2","605","618","This paper presents a scalable inference accelerator called a deep-learning specific instruction-set processor (DSIP) to support various convolutional neural networks (CNNs). For CNNs requiring a large amount of computations and memory accesses, a programmable inference system called master-slave instruction set architecture (ISA) is newly proposed to achieve high flexibility, processing speed, and energy efficiency. The master is responsible for sending and receiving feature maps in order to deal with neural networks in a scalable way, and the slave performs CNN operations, such as multiply accumulate, max pooling, and activation functions, on the features received from the master. The master-slave ISA maximizes computation speed by overlapping the off-chip data transmission and the CNN operations, and reduces power consumption by performing the convolution incrementally to reuse input and partial-sum data as maximally as possible. An inference system can be configured by connecting multiple DSIPs in a form of either 1-D or 2-D chain structure in order to enhance computation speed further. To evaluate the proposed accelerator, a prototype chip is implemented and evaluated for AlexNet. Compared to the state-of-the-art accelerator, the DSIP-based system enhances the energy efficiency by 2.17×.×.","","","10.1109/JSSC.2017.2764045","Center for Integrated Smart Sensors; Ministry of Science and ICT as Global Frontier Project; IC Design Education Center; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8103908","Deep neural network;energy-efficient accelerator;heterogeneous instruction set architecture;object recognition;scalable architecture","Neural networks;Power demand;Convolution;Arrays;Registers;Instruction sets","feedforward neural nets;inference mechanisms;instruction sets;learning (artificial intelligence);storage management","memory accesses;programmable inference system;master-slave instruction set architecture;energy efficiency;feature maps;master-slave ISA;off-chip data transmission;partial-sum data;DSIP;scalable inference accelerator;convolutional neural networks;CNN operations;power consumption reduction;AlexNet;deep-learning specific instruction-set processor","","4","24","","","","","IEEE","IEEE Journals"
"Object Detection Based on Multi-Layer Convolution Feature Fusion and Online Hard Example Mining","J. Chu; Z. Guo; L. Leng","School of Software, Nanchang Hangkong University, Nanchang, China; School of Information Engineering, Nanchang Hangkong University, Nanchang, China; School of Software, Nanchang Hangkong University, Nanchang, China","IEEE Access","","2018","6","","19959","19967","Object detection is a significant issue in visual surveillance. Faster region-based convolutional neural network (R-CNN) is a typical object detection algorithm of deep learning; however, neither its generalization ability nor its detection accuracy of small object is high. In this paper, an effective object detection algorithm is proposed for the small and occluded objects, which is based on multi-layer convolution feature fusion (MCFF) and online hard example mining (OHEM). First, the candidate regions are generated with region proposal network optimized by MCFF. Then, an effective OHEM algorithm is employed to train the region-based ConvNet detector. The hard examples are automatically selected to improve training efficiency. The avoidance of invalid examples accelerates the convergence speed of the model training. The experiments are performed on KITTI data set in intelligent traffic scenario. The proposed method outperforms the popular methods, such as Faster R-CNN, Regionlets, in terms of the overall detection accuracy. Furthermore, our method is good at the detection of small and occluded objects.","","","10.1109/ACCESS.2018.2815149","National Natural Science Foundation of China; Key Research and Development Project of Jiangxi Province; Construction Project of Advantage Scientific and Technological Innovation Team; Application Innovation Program of Public Security Ministry; Science and Technology Research Project of Education Department of Jiangxi Province; Open Foundation of Key Laboratory of Jiangxi Province for Image Processing and Pattern Recognition; Ph.D. Starting Foundation of Nanchang Hangkong University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8314823","Deep leaning;multi-layer convolution feature fusion;object detection;online hard example mining;region proposal network","Object detection;Feature extraction;Convolution;Training;Automobiles;Microsoft Windows;Classification algorithms","convolution;feature extraction;feedforward neural nets;image fusion;learning (artificial intelligence);object detection;optimisation","multilayer convolution feature fusion;online hard example mining;convolutional neural network;small objects;occluded objects;MCFF;candidate regions;deep learning;OHEM algorithm;region proposal network optimization;object detection algorithm","","4","45","CCBY","","","","IEEE","IEEE Journals"
"3DmFV: Three-Dimensional Point Cloud Classification in Real-Time Using Convolutional Neural Networks","Y. Ben-Shabat; M. Lindenbaum; A. Fischer","Department of Mechanical Engineering, Techion—Israel Institute of Technology, Haifa, Israel; Department of Computer Science, Techion—Israel Institute of Technology, Haifa, Israel; Department of Mechanical Engineering, Techion—Israel Institute of Technology, Haifa, Israel","IEEE Robotics and Automation Letters","","2018","3","4","3145","3152","Modern robotic systems are often equipped with a direct three-dimensional (3-D) data acquisition device, e.g., LiDAR, which provides a rich 3-D point cloud representation of the surroundings. This representation is commonly used for obstacle avoidance and mapping. Here, we propose a new approach for using point clouds for another critical robotic capability, semantic understanding of the environment (i.e., object classification). Convolutional neural networks (CNNs), that perform extremely well for object classification in 2-D images, are not easily extendible to 3-D point clouds analysis. It is not straightforward due to point clouds' irregular format and a varying number of points. The common solution of transforming the point cloud data into a 3-D voxel grid needs to address severe accuracy versus memory size tradeoffs. In this letter, we propose a novel, intuitively interpretable, 3-D point cloud representation called 3-D modified Fisher vectors. Our representation is hybrid as it combines a coarse discrete grid structure with continuous generalized Fisher vectors. Using the grid enables us to design a new CNN architecture for real-time point cloud classification. In a series of performance analysis experiments, we demonstrate competitive results or even better than state of the art on challenging benchmark datasets while maintaining robustness to various data corruptions.","","","10.1109/LRA.2018.2850061","Ministry of Economy and Industry of Israel; Israel Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8394990","Deep learning in robotics and automation;recognition;computer vision for transportation;computer vision for other robotic applications","Three-dimensional displays;Real-time systems;Robots;Laser radar;Computational efficiency;Machine learning;Convolutional neural networks","data acquisition;feature extraction;feedforward neural nets;image classification;image representation;learning (artificial intelligence);mobile robots;neural net architecture;object detection;vectors","3-D point cloud representation;3-D modified Fisher vectors;real-time point cloud classification;3DmFV;three-dimensional point cloud classification;convolutional neural networks;modern robotic systems;point clouds;object classification;point cloud data;3-D voxel grid;CNN architecture;continuous generalized Fisher vectors;coarse discrete grid structure","","2","44","","","","","IEEE","IEEE Journals"
"Visual Kinship Recognition of Families in the Wild","J. P. Robinson; M. Shao; Y. Wu; H. Liu; T. Gillis; Y. Fu","Department of Electrical and Computer Engineering, Northeastern University, Boston, MA, USA; Department of Computer and Information Science, University of Massachusetts Dartmouth, Dartmouth, MA, USA; Department of Electrical and Computer Engineering, Northeastern University, Boston, MA, USA; Department of Electrical and Computer Engineering, Northeastern University, Boston, MA, USA; Department of Electrical and Computer Engineering, Northeastern University, Boston, MA, USA; Department of Electrical and Computer Engineering","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","11","2624","2637","We present the largest database for visual kinship recognition, Families In the Wild (FIW), with over 13,000 family photos of 1,000 family trees with 4-to-38 members. It took only a small team to build FIW with efficient labeling tools and work-flow. To extend FIW, we further improved upon this process with a novel semi-automatic labeling scheme that used annotated faces and unlabeled text metadata to discover labels, which were then used, along with existing FIW data, for the proposed clustering algorithm that generated label proposals for all newly added data-both processes are shared and compared in depth, showing great savings in time and human input required. Essentially, the clustering algorithm proposed is semi-supervised and uses labeled data to produce more accurate clusters. We statistically compare FIW to related datasets, which unarguably shows enormous gains in overall size and amount of information encapsulated in the labels. We benchmark two tasks, kinship verification and family classification, at scales incomparably larger than ever before. Pre-trained CNN models fine-tuned on FIW outscores other conventional methods and achieved state-of-the art on the renowned KinWild datasets. We also measure human performance on kinship recognition and compare to a fine-tuned CNN.","","","10.1109/TPAMI.2018.2826549","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8337841","Large-scale image dataset;kinship verification;family classification;semi-supervised clustering;deep learning","Labeling;Visualization;Machine learning;Benchmark testing;Databases;Task analysis;Face recognition","feature extraction;feedforward neural nets;learning (artificial intelligence);pattern clustering;text analysis","visual kinship recognition;work-flow;annotated faces;unlabeled text metadata;clustering algorithm;generated label proposals;kinship verification;family classification;family photos;family trees;labeling tools;semiautomatic labeling scheme;FIW data","","6","72","","","","","IEEE","IEEE Journals"
"Are Critical Success Factors Always Valid for Any Case? A Contextual Perspective","W. Alkarney; M. Albraithen","Information Systems Department, Al-Imam Muhammad Ibn Saud Islamic University, Riyadh, Saudi Arabia; Information Systems Department, Al-Imam Muhammad Ibn Saud Islamic University, Riyadh, Saudi Arabia","IEEE Access","","2018","6","","63496","63512","The critical success factor (CSF) concept systematically highlights the key areas which management should carefully consider in order to realize its performance goals. By understanding the CSFs for the implementation of a system, an organization can successfully determine the issues that critically affect the process, enabling it to eliminate or avoid any problems that might contribute to its failure. The purpose of this paper is to investigate whether the CSFs presented in the literature are always valid for any case. It reports an exploratory case study which adopted a qualitative methodology to achieve a deep understanding of the CSFs for learning management system (LMS) implementation in Saudi Arabia from the students' perspective. Having identified these CSFs, it compares them with those reported by other studies in the literature. The results indicate that such CSFs are not similar in all contexts. Studying the change in its context is in fact found to be significant and information system success is determined to be not a purely technical issue but a socio-technical one. Accordingly, the widely recognized CSFs are undeniably beneficial but not sufficient to ensure the success of LMS implementation.","","","10.1109/ACCESS.2018.2876792","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8496768","Change management;critical success factors;information system development;learning management system;socio-technical theory","Organizations;Electronic learning;Training;Information systems;Investment","information systems;learning management systems","information system success;LMS implementation;Saudi Arabia;learning management system;critical success factor","","","99","","","","","IEEE","IEEE Journals"
"Scene Classification via Triplet Networks","Y. Liu; C. Huang","School of Geography, South China Normal University, Guangzhou, China; College of Mathematics and Statistics, Shenzhen University, Shenzhen, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2018","11","1","220","237","Scene classification is a fundamental task for automatic remote sensing image understanding. In recent years, convolutional neural networks have become a hot research topic in the remote sensing community, and have made great achievements in scene classification. Deep convolutional networks are primarily trained in a supervised way, requiring huge volumes of labeled training samples. However, clearly labeled remote sensing data are usually limited. To address this issue, in this paper, we propose a novel scene classification method via triplet networks, which use weakly labeled images as network inputs. Besides, we initiate a theoretical study on the three existing loss functions for triplet networks, analyzing their different underlying mechanisms for dealing with “hard” and/or “easy” triplets during training. Furthermore, four new loss functions are constructed, aiming at laying more stress on “hard” triplets to improve classification accuracy. Extensive experiments have been conducted, and the experimental results show that triplet networks coupled with our proposed losses achieve a state-of-the-art performance in scene classification tasks.","","","10.1109/JSTARS.2017.2761800","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8086123","Deep learning;difference loss;ratio loss;scene classification;triplet networks","Remote sensing;Feature extraction;Training;Machine learning;Neural networks;Semantics","feedforward neural nets;geophysical image processing;image classification;remote sensing","scene classification tasks;network inputs;weakly labeled images;scene classification method;clearly labeled remote sensing data;labeled training samples;deep convolutional networks;remote sensing community;convolutional neural networks;automatic remote sensing image understanding;triplet networks","","8","70","","","","","IEEE","IEEE Journals"
"Cascaded Subpatch Networks for Effective CNNs","X. Jiang; Y. Pang; M. Sun; X. Li","School of Electrical and Information Enginnering, Tianjin University, Tianjin, China; School of Electrical and Information Enginnering, Tianjin University, Tianjin, China; School of Electrical and Information Enginnering, Tianjin University, Tianjin, China; Center for OPTical IMagery Analysis and Learning, State Key Laboratory of Transient Optics and Photonic, Xi’an Institute of Optics and Precision Mechanics, Chinese Academy of Sciences, Xi’an, China","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","7","2684","2694","Conventional convolutional neural networks use either a linear or a nonlinear filter to extract features from an image patch (region) of spatial size H × W (typically, H is small and is equal to W, e.g., H is 5 or 7). Generally, the size of the filter is equal to the size H x W of the input patch. We argue that the representational ability of equal-size strategy is not strong enough. To overcome the drawback, we propose to use subpatch filter whose spatial size hxw is smaller than H×W. The proposed subpatch filter consists of two subsequent filters. The first one is a linear filter of spatial size h x w and is aimed at extracting features from spatial domain. The second one is of spatial size 1 × 1 and is used for strengthening the connection between different input feature channels and for reducing the number of parameters. The subpatch filter convolves with the input patch and the resulting network is called a subpatch network. Taking the output of one subpatch network as input, we further repeat constructing subpatch networks until the output contains only one neuron in spatial domain. These subpatch networks form a new network called the cascaded subpatch network (CSNet). The feature layer generated by CSNet is called the csconv layer. For the whole input image, we construct a deep neural network by stacking a sequence of csconv layers. Experimental results on five benchmark data sets demonstrate the effectiveness and compactness of the proposed CSNet. For example, our CSNet reaches a test error of 5.68% on the CIFAR10 data set without model averaging. To the best of our knowledge, this is the best result ever obtained on the CIFAR10 data set.","","","10.1109/TNNLS.2017.2689098","National Basic Research Program of China 973 Program; National Natural Science Foundation of China; Research Fund of Hainan Tropical Ocean University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7927455","Cascaded subpatch networks (CSNet);convolutional neural network (CNN);feature extraction;subpatch filter","Feature extraction;Convolution;Biological neural networks;Stacking;Robustness;Visualization","feature extraction;neural nets;nonlinear filters","subpatch filter;linear filter;spatial size h x w;spatial domain;cascaded subpatch network;deep neural network;conventional convolutional neural networks;nonlinear filter;equal-size strategy;CSNet;csconv layer","","3","47","","","","","IEEE","IEEE Journals"
"Training DCNN by Combining Max-Margin, Max-Correlation Objectives, and Correntropy Loss for Multilabel Image Classification","W. Shi; Y. Gong; X. Tao; N. Zheng","Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China; Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China; Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China; Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","7","2896","2908","In this paper, we build a multilabel image classifier using a general deep convolutional neural network (DCNN). We propose a novel objective function that consists of three parts, i.e., max-margin objective, max-correlation objective, and correntropy loss. The max-margin objective explicitly enforces that the minimum score of positive labels must be larger than the maximum score of negative labels by a predefined margin, which not only improves accuracies of the multilabel classifier, but also eases the threshold determination. The max-correlation objective can make the DCNN model learn a latent semantic space, which maximizes the correlations between the feature vectors of the training samples and their corresponding ground-truth label vectors projected into this space. Instead of using the traditional softmax loss, we adopt the correntropy loss from the information theory field to minimize the training errors of the DCNN model. The proposed framework can be end-to-end trained. Comprehensive experimental evaluations on Pascal VOC 2007 and MIR Flickr 25K multilabel benchmark data sets with four DCNN models, i.e., AlexNet, VGG-16, GoogLeNet, and ResNet demonstrate that the proposed objective function can remarkably improve the performance accuracies of a DCNN model for the task of multilabel image classification.","","","10.1109/TNNLS.2017.2705222","National Basic Research Program of China (973 Program); National Natural Science Foundation of China; Huawei Technologies; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7947145","Correntropy loss;deep convolutional neural network (DCNN);max-correlation objective;max-margin objective;multilabel image classification","Training;Neural networks;Correlation;Semantics;Data models;Proposals","convolution;correlation methods;feature extraction;feedforward neural nets;image classification;image representation;image retrieval;object detection","max-correlation objective;correntropy loss;multilabel image classification;max-margin objective;DCNN model;MIR Flickr 25K multilabel benchmark data sets;deep convolutional neural network;ground-truth label vectors;softmax loss;information theory field;Pascal VOC 2007 dataset","","3","63","","","","","IEEE","IEEE Journals"
"Semisupervised Hyperspectral Image Classification Based on Generative Adversarial Networks","Y. Zhan; D. Hu; Y. Wang; X. Yu","College of Information Science and Technology, Beijing Normal University, Beijing, China; College of Information Science and Technology, Beijing Normal University, Beijing, China; Beijing Institute of Geology, Beijing, China.; College of Information Science and Technology, Beijing Normal University, Beijing, China","IEEE Geoscience and Remote Sensing Letters","","2018","15","2","212","216","Because the collection of ground-truth labels is difficult, expensive, and time-consuming, classifying hyperspectral images (HSIs) with few training samples is a challenging problem. In this letter, we propose a novel semisupervised algorithm for the classification of hyperspectral data by training a customized generative adversarial network (GAN) for hyperspectral data. The GAN constructs an adversarial game between a discriminator and a generator. The generator generates samples that are not distinguishable by the discriminator, and the discriminator determines whether or not a sample is composed of real data. We design a semisupervised framework for HSI data based on a 1-D GAN (HSGAN). This framework enables the automatic extraction of spectral features for HSI classification. When HSGAN is trained using unlabeled hyperspectral data, the generator can generate hyperspectral samples that are similar to the real data, while the discriminator contains the features, which can be used to classify hyperspectral data with only a small number of labeled samples. The performance of the HSGAN is evaluated on the Airborne Visible Infrared Imaging Spectrometer image data, and the results show that the proposed framework achieves very promising results with a small number of labeled samples.","","","10.1109/LGRS.2017.2780890","Ministry of Land and Resources for the Public Welfare Industry Research Special Funds; National Natural Science Foundation of China; Beijing Natural Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8241773","Deep learning;generative adversarial network (GAN);hyperspectral image (HSI) classification;remote sensing;semisupervised learning (SSL)","Gallium nitride;Training;Hyperspectral imaging;Data models;Generators;Feature extraction","hyperspectral imaging;image classification;infrared imaging;learning (artificial intelligence);remote sensing","hyperspectral image classification;generative adversarial networks;adversarial game;semisupervised framework;HSI data;HSGAN;HSI classification;Airborne Visible Infrared Imaging Spectrometer image data;semisupervised algorithm;hyperspectral data;1D GAN","","17","16","","","","","IEEE","IEEE Journals"
"Convolutional neural network-based multi-label classification of PCB defects","L. Zhang; Y. Jin; X. Yang; X. Li; X. Duan; Y. Sun; H. Liu","Minzu University of China, People's Republic of China; Peking University, Shenzhen Graduate School, People's Republic of China; University of Illinois Urbana-Champaign, USA; Peking University, Shenzhen Graduate School, People's Republic of China; Aalborg University, Denmark; Minzu University of China, People's Republic of China; Peking University, Shenzhen Graduate School, People's Republic of China","The Journal of Engineering","","2018","2018","16","1612","1616","Due to the rapid development of printed circuit board (PCB) design technology, inspection of PCB surface defects has become an increasingly critical issue. The classification of PCB defects facilitates the root causes of detects’ identification. As PCB defects may be intensive, the actual PCB classification should not be considered as a binary or multi-category problem. This type of problem is called multi-label classification problem. Recently, as one of the deep learning frameworks, a convolutional neural network (CNN) has a major breakthrough in many areas of image processing, especially in the image classification. This study proposes a multi-task CNN model to handle the multi-label learning problem by defining each label learning as a binary classification task. In this study, the multi-label learning is transformed into multiple binary classification tasks by customising the loss function. Extensive experiments demonstrate that the proposed method achieves great performance on the dataset of defects.","","","10.1049/joe.2018.8279","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8543724","","","printed circuits;image classification;learning (artificial intelligence);feedforward neural nets;convolution;electronic engineering computing;feature extraction;automatic optical inspection","convolutional neural network-based multilabel classification;PCB defects;printed circuit board design technology;image classification;multitask CNN model;multilabel learning problem;multiple binary classification tasks;multicategory problem;deep learning frameworks;PCB surface defects inspection","","","27","","","","","IET","IET Journals"
"Re$^3$: Re al-Time Recurrent Regression Networks for Visual Tracking of Generic Objects","D. Gordon; A. Farhadi; D. Fox","Paul G. Allen School of Computer Science, University of Washington, Seattle, WA, USA; Paul G. Allen School of Computer Science, University of Washington, Seattle, WA, USA; Paul G. Allen School of Computer Science, University of Washington, Seattle, WA, USA","IEEE Robotics and Automation Letters","","2018","3","2","788","795","Robust object tracking requires knowledge and understanding of the object being tracked: its appearance, its motion, and how it changes over time. A tracker must be able to modify its underlying model and adapt to new observations. We present Re3, a real-time deep object tracker capable of incorporating temporal information into its model. Rather than focusing on a limited set of objects or training a model at test-time to track a specific instance, we pretrain our generic tracker on a large variety of objects and efficiently update on the fly; Re3 simultaneously tracks and updates the appearance model with a single forward pass. This lightweight model is capable of tracking objects at 150 FPS while attaining competitive results on challenging benchmarks. We also show that our method handles temporary occlusion better than other comparable trackers using experiments that directly measure performance on sequences with occlusion.","","","10.1109/LRA.2018.2792152","National Science Foundation; Intel Science and Technology Center for Pervasive Computing; Allen Distinguished Investigator Award; Allen Institute for Artificial Intelligence; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8253805","Visual tracking;deep learning in robotics and automation;visual learning","Agriculture;Object tracking;Robots;Real-time systems;Streaming media;Target tracking","object tracking","recurrent regression networks;generic tracker;real-time deep object tracker;robust object tracking;visual tracking;comparable trackers;Re;FPS","","8","44","","","","","IEEE","IEEE Journals"
"EgoGesture: A New Dataset and Benchmark for Egocentric Hand Gesture Recognition","Y. Zhang; C. Cao; J. Cheng; H. Lu","National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences and University of Chinese Academy of Sciences, Beijing, China; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences and University of Chinese Academy of Sciences, Beijing, China; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences and University of Chinese Academy of Sciences, Beijing, China; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences and University of Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Multimedia","","2018","20","5","1038","1050","Gesture is a natural interface in human-computer interaction, especially interacting with wearable devices, such as VR/AR helmet and glasses. However, in the gesture recognition community, it lacks of suitable datasets for developing egocentric (first-person view) gesture recognition methods, in particular in the deep learning era. In this paper, we introduce a new benchmark dataset named EgoGesture with sufficient size, variation, and reality to be able to train deep neural networks. This dataset contains more than 24 000 gesture samples and 3 000 000 frames for both color and depth modalities from 50 distinct subjects. We design 83 different static and dynamic gestures focused on interaction with wearable devices and collect them from six diverse indoor and outdoor scenes, respectively, with variation in background and illumination. We also consider the scenario when people perform gestures while they are walking. The performances of several representative approaches are systematically evaluated on two tasks: gesture classification in segmented data and gesture spotting and recognition in continuous data. Our empirical study also provides an in-depth analysis on input modality selection and domain adaptation between different scenes.","","","10.1109/TMM.2018.2808769","National Natural Science Foundation of China; Youth Innovation Promotion Association of the Chinese Academy of Sciences; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8299578","Benchmark;dataset;egocentric vision;gesture recognition;first-person view","Gesture recognition;Cameras;Task analysis;Performance evaluation;Three-dimensional displays;Benchmark testing;Neural networks","gesture recognition;learning (artificial intelligence);neural nets","EgoGesture;deep neural networks;dynamic gestures;wearable devices;diverse indoor scenes;outdoor scenes;gesture classification;gesture spotting;egocentric hand gesture recognition;natural interface;human-computer interaction;gesture recognition community;deep learning era;benchmark dataset;gesture samples","","6","47","","","","","IEEE","IEEE Journals"
"Deeply vulnerable: a study of the robustness of face recognition to presentation attacks","A. Mohammadi; S. Bhattacharjee; S. Marcel","Idiap Research Institute, Switzerland; Idiap Research Institute, Switzerland; Idiap Research Institute, Switzerland","IET Biometrics","","2018","7","1","15","26","The vulnerability of deep-learning-based face-recognition (FR) methods, to presentation attacks (PA), is studied in this study. Recently, proposed FR methods based on deep neural networks (DNN) have been shown to outperform most other methods by a significant margin. In a trustworthy face-verification system, however, maximising recognition-performance alone is not sufficient - the system should also be capable of resisting various kinds of attacks, including PA. Previous experience has shown that the PA vulnerability of FR systems tends to increase with face-verification accuracy. Using several publicly available PA datasets, the authors show that DNN-based FR systems compensate for variability between bona fide and PA samples, and tend to score them similarly, which makes such FR systems extremely vulnerable to PAs. Experiments show the vulnerability of the studied DNN-based FR systems to be consistently higher than 90%, and often higher than 98%.","","","10.1049/iet-bmt.2017.0079","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8244397","","","face recognition;learning (artificial intelligence);neural nets","presentation attacks;deep-learning-based face-recognition method;FR methods;deep neural networks;DNN;trustworthy face-verification system;recognition-performance maximization;PA vulnerability","","7","44","","","","","IET","IET Journals"
"Energy-Efficient Neural Network Acceleration in the Presence of Bit-Level Memory Errors","S. Kim; P. Howe; T. Moreau; A. Alaghi; L. Ceze; V. S. Sathe","Department of Electrical Engineering, University of Washington, Seattle, WA, USA; Department of Electrical Engineering, University of Washington, Seattle, WA, USA; Paul G. Allen School of Computer Science and Engineering, University of Washington, Seattle, WA, USA; Paul G. Allen School of Computer Science and Engineering, University of Washington, Seattle, WA, USA; Paul G. Allen School of Computer Science and Engineering, University of Washington, Seattle, WA, USA; Department of Electrical Engineering, University of Washington, Seattle, WA, USA","IEEE Transactions on Circuits and Systems I: Regular Papers","","2018","65","12","4285","4298","As a result of the increasing demand for deep neural network (DNN)-based services, efforts to develop hardware accelerators for DNNs are growing rapidly. However, while highly efficient accelerators on convolutional DNNs (ConvDNNs) have been developed, less progress has been made with regards to fully-connected DNNs. Based on analysis of bit-level SRAM errors, we propose memory adaptive training with in-situ canaries (MATIC), a methodology that enables aggressive voltage scaling of accelerator weight memories to improve the energyefficiency of DNN accelerators. To enable accurate operation with voltage overscaling, MATIC combines characteristics of SRAM bit failures with the error resilience of neural networks in a memory-adaptive training (MAT) process. Furthermore, PVT-related voltage margins are eliminated using bit-cells from synaptic weights as in-situ canaries to track runtime environmental variation. Demonstrated on a low-power DNN accelerator fabricated in 65 nm CMOS, MATIC enables up to 3.3× energy reduction versus the nominal voltage, or 18.6× application error reduction. We also perform a simulation study that extends MAT to Conv-DNNs, and characterize the accuracy impact of bit failure statistics. Finally, we develop a weight refinement algorithm to improve the performance of MAT, and show that it improves absolute accuracy by 0.8-1.3% or reduces training time by 5-10×.","","","10.1109/TCSI.2018.2839613","National Science Foundation; C-FAR, one of the six SRC STARnet Centers through MARCO and DARPA; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8374828","Neural networks;deep learning;voltage scaling;SRAM;machine learning acceleration","Random access memory;Training;Neural networks;System-on-chip;Hardware;Neurons;Acceleration","CMOS integrated circuits;convolution;electronic engineering computing;feedforward neural nets;power aware computing;SRAM chips;statistics","deep neural network;energy-efficiency neural network acceleration;MAT process;bit-level memory errors;weight refinement algorithm;bit failure statistics;Conv-DNNs;low-power DNN accelerator;memory-adaptive training process;SRAM bit failures;voltage overscaling;DNN accelerators;accelerator weight memories;aggressive voltage scaling;MATIC;memory adaptive training;bit-level SRAM errors;convolutional DNNs;hardware accelerators","","4","48","","","","","IEEE","IEEE Journals"
"SRMC: A Multibit Memristor Crossbar for Self-Renewing Image Mask","L. Shang; S. Duan; L. Wang; T. Huang","Chongqing Key Laboratory of Nonlinear Circuits and Intelligent Information Processing, College of Electronic and Information Engineering, Southwest University, Chongqing, China; Chongqing Key Laboratory of Nonlinear Circuits and Intelligent Information Processing, Brain-Inspired Computing and Intelligent Control Key Laboratory, and National and Local Joint Engineering Laboratory of Intelligent Transmission and Control Technology, College of Electronic and Information Engineering, Chongqing Collaborative Innovation Center for Brain Science, Southwest University, Chongqing, China; Chongqing Key Laboratory of Nonlinear Circuits and Intelligent Information Processing, Brain-Inspired Computing and Intelligent Control Key Laboratory, and National and Local Joint Engineering Laboratory of Intelligent Transmission and Control Technology, College of Electronic and Information Engineering, Chongqing Collaborative Innovation Center for Brain Science, Southwest University, Chongqing, China; Department of Mathematics, Texas A&M University at Qatar, Doha, Qatar","IEEE Transactions on Very Large Scale Integration (VLSI) Systems","","2018","26","12","2830","2841","A recent surge of research on deep convolutional neural network (DCNN) has given a challenge on existing computation architecture which has the flows in speed and memory bottleneck. In the pretreatment of deep learning, mask operation is frequently used to remove noise or fetch information. However, under data-intensive conditions, applying mask frequently can put an extremely heavy memory/communication burden on computing system. An efficient substrate of DCNN for ameliorating mask operation is urgently needed. In this paper, we present a self-renewing mask circuit (SRMC) to alleviate/solve earlier problems. First, a new approach to apply mask is presented based on computation-in-memory architecture that implements high-performance processor and high-density memory in the same physical location. Second, we designed the peripheral circuit which can provide self-renewing function to further avoid the data exchange with an external space. As opposed to most other computational element, which calculates two 1-bit data, the proposed SRMC storage multibit value and calculate several of them parallel. The calculating ability of SRMC is significantly superior to those of computational element in general architectures. Moreover, mean filter and edge detector are implemented to illustrate the effectiveness and scalability of the proposed circuit. Finally, we discussed two possible methods to enhance the practicability of our scheme.","","","10.1109/TVLSI.2018.2844463","National Natural Science Foundation of China; Fundamental Science and Advanced Technology Research Foundation of Chongqing; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8430568","Computation-in-memory (CIM);image processing;mask operation;memristor crossbar","Memristors;Adders;Computer architecture;Spintronics;Resistance;Hardware;Critical current density (superconductivity)","convolution;edge detection;feedforward neural nets;learning (artificial intelligence);memory architecture;memristors","multibit memristor crossbar;deep convolutional neural network;DCNN;memory bottleneck;deep learning;mask operation;data-intensive conditions;mask circuit;computation-in-memory architecture;high-performance processor;high-density memory;peripheral circuit;data exchange;SRMC storage multibit value;general architectures;self-renewing image mask","","","62","","","","","IEEE","IEEE Journals"
"Deblurring retinal optical coherence tomography via a convolutional neural network with anisotropic and double convolution layer","J. Lian; S. Hou; X. Sui; F. Xu; Y. Zheng","Shandong University of Science and Technology, People's Republic of China; School of Information Science and Engineering, Shandong Normal University, People's Republic of China; School of Information Science and Engineering, Shandong Normal University, People's Republic of China; School of Electrical Engineering and Automation, Qilu University of Technology (Shandong Academy of Sciences), People's Republic of China; School of Information Science and Engineering, Shandong Normal University, People's Republic of China","IET Computer Vision","","2018","12","6","900","907","Various image pre-processing tasks in optical coherence tomography (OCT) systems involve reversing degradation effects (e.g. deblurring). Current deblurring research mainly focuses on how to build suitable degradation models using deconvolution operators. However, model-based solutions may not work well in many scenarios. To solve this problem, the authors propose a non-model architecture, called a deep convolutional neural network, to address parameter-free situations. The proposed solution employs a deep learning strategy to bridge the gap between traditional model-based methods and neural network architectures. Experiments on retinal OCT images demonstrate that the proposed approach achieves superior performance compared with the state-of-the-art model-based OCT deblurring methods.","","","10.1049/iet-cvi.2018.0016","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8435128","","","biomedical optical imaging;convolution;deconvolution;eye;image restoration;learning (artificial intelligence);medical image processing;neural nets;optical tomography","retinal optical coherence tomography;double convolution layer;image pre-processing tasks;optical coherence tomography systems;degradation effects;current deblurring research;suitable degradation models;deconvolution operators;model-based solutions;nonmodel architecture;deep convolutional neural network;parameter-free situations;deep learning strategy;traditional model;neural network architectures;retinal OCT images;state-of-the-art model;OCT deblurring methods","","","","","","","","IET","IET Journals"
"The Effects of Noisy Labels on Deep Convolutional Neural Networks for Music Tagging","K. Choi; G. Fazekas; K. Cho; M. Sandler","Centre for Digital Music, Electric Engineering and Computer Science, Queen Mary University of London, London, U.K.; Centre for Digital Music, Electric Engineering and Computer Science, Queen Mary University of London, London, U.K.; Center for Data Science, New York University, New York, NY, USA; Centre for Digital Music, Electric Engineering and Computer Science, Queen Mary University of London, London, U.K.","IEEE Transactions on Emerging Topics in Computational Intelligence","","2018","2","2","139","149","Deep neural networks (DNNs) have been successfully applied to music classification including music tagging. However, there are several open questions regarding the training, evaluation, and analysis of DNNs. In this paper, we investigate specific aspects of neural networks, the effects of noisy labels, to deepen our understanding of their properties. We analyze and (re-)validate a large music tagging dataset to investigate the reliability of training and evaluation. Using a trained network, we compute label vector similarities, which are compared to groundtruth similarity. The results highlight several important aspects of music tagging and neural networks. We show that networks can be effective despite relatively large error rates in groundtruth datasets, while conjecturing that label noise can be the cause of varying tag-wise performance differences. Finally, the analysis of our trained network provides valuable insight into the relationships between music tags. These results highlight the benefit of using data-driven methods to address automatic music tagging.","","","10.1109/TETCI.2017.2771298","Engineering and Physical Sciences Research Council; Wolfson Research Merit Award; Queen Mary University of London; eBay; TenCent; Facebook; Google; NVIDIA; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8323324","Music tagging;convolutional neural networks","Tagging;Training;Task analysis;Music;Neural networks;Instruments;Noise measurement","fuzzy neural nets;learning (artificial intelligence);music;pattern classification","noisy labels;deep convolutional neural networks;trained network;label vector similarities;label noise;tag-wise performance differences;music tags;automatic music tagging;DNN;music classification","","","39","CCBY","","","","IEEE","IEEE Journals"
"Entity Linking on Chinese Microblogs via Deep Neural Network","W. Zeng; J. Tang; X. Zhao","Science and Technology on Information Systems Engineering Laboratory, National University of Defense Technology, Changsha, China; Science and Technology on Information Systems Engineering Laboratory, National University of Defense Technology, Changsha, China; Science and Technology on Information Systems Engineering Laboratory, National University of Defense Technology, Changsha, China","IEEE Access","","2018","6","","25908","25920","Entity linking is the task of mapping mentions in text to target knowledge base, which is crucial to knowledge-base-related tasks such as knowledge fusion and knowledge base construction. Although English-oriented entity linking task has undergone continuing advancement, the entity linking systems targeted at Chinese language still suffer from lagged development. State-of-the-art Chinese entity linking systems devise multiple handcrafted features to measure similarity between mention and entity, whereas fail to mine semantic relations underneath the surface forms. In this paper, we propose to take the advantage of latent text features and generate representations of mention and entity via double-attention-based long short term memory network, which are further utilized to calculate mention-entity similarity. Furthermore, joint word and entity embedding training and well-designed candidate entities generation strategies are put forward to facilitate the implementation of neural network. The experimental results validate the superiority of our method Celan. Our proposal not only offers an improved deep neural network for generating mention and entity representation, but also enhances the performance of entity linking on Chinese microblogs.","","","10.1109/ACCESS.2018.2833153","NSFC; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354691","Entity linking;named entity disambiguation;neural network;Chinese microblogs","Joining processes;Internet;Knowledge based systems;Encyclopedias;Electronic publishing;Dictionaries","knowledge based systems;learning (artificial intelligence);natural language processing;neural nets;text analysis;Web sites;word processing","double-attention-based long short term memory network;text features;Chinese entity linking systems;deep neural network;entity representation;entity embedding training;joint word;mention-entity similarity;Chinese language;knowledge-base-related tasks;Chinese microblogs","","4","38","","","","","IEEE","IEEE Journals"
"Semantic Clustering-Based Deep Hypergraph Model for Online Reviews Semantic Classification in Cyber-Physical-Social Systems","X. Yuan; M. Sun; Z. Chen; J. Gao; P. Li","School of Software, Dalian University of Technology, Dalian, China; School of Software, Dalian University of Technology, Dalian, China; School of Software, Dalian University of Technology, Dalian, China; School of Software, Dalian University of Technology, Dalian, China; School of Software, Dalian University of Technology, Dalian, China","IEEE Access","","2018","6","","17942","17951","Sentiment classification of online reviews is playing an increasingly important role for both consumers and businesses in cyber-physical-social systems. However, existing works ignore the semantic correlation among different reviews, causing the ineffectiveness for sentiment classification. In this paper, a word embedding clustering-based deep hypergraph model (ECDHG) is proposed for the sentiment analysis of online reviews. The ECDHG introduces external knowledge by employing the pre-training word embeddings to express reviews. Then, semantic units are detected under the supervision of semantic cliques discovered by an improved hierarchical fast clustering algorithm. Convolutional neural networks are connected to extract the high-order textual and semantic features of reviews. Finally, the hypergraph can be constructed based on high-order relations of samples for the sentiment classification of reviews. Experiments are performed on five-domain data sets including movie, book, DVD, kitchen, and electronic to assess the performance of the proposed model compared with other seven models. The results validate that our model outperforms the compared methods in classification accuracy.","","","10.1109/ACCESS.2018.2813419","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; Dalian University of Technology Fundamental Research Fund; Doctoral Scientific Research Foundation of Liaoning Province; Key Laboratory of Vibration and the Control of Aero-Propulsion System, Ministry of Education, Northeastern University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8314135","CNNs;hypergraph;sentiment classification;online reviews;short text","Semantics;Clustering algorithms;Feature extraction;Sentiment analysis;Classification algorithms;Business;Dictionaries","data mining;graph theory;learning (artificial intelligence);pattern classification;pattern clustering;text analysis","semantic clustering;deep hypergraph model;online reviews semantic classification;cyber-physical-social systems;sentiment classification;semantic correlation;word embedding clustering;ECDHG;sentiment analysis;semantic units;semantic cliques;semantic features;classification accuracy;hierarchical fast clustering algorithm","","2","31","","","","","IEEE","IEEE Journals"
"DeepTrain: A Programmable Embedded Platform for Training Deep Neural Networks","D. Kim; T. Na; S. Yalamanchili; S. Mukhopadhyay","Department of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; Department of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; Department of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; Department of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","","2018","37","11","2360","2370","This paper presents, DeepTrain, an embedded platform for high-performance and energy-efficient training of deep neural network (DNN). The key architectural concept of DeepTrain is to develop a spatially homogeneous computing (and memory) fabric with temporally heterogeneous programmable data flows to optimize memory mapping and data reuse during different phases of training operation.The DeepTrain is demonstrated as an in-memory accelerator integrated in the logic layer of a 3-D memory module. A programming model and supporting architecture utilizes the flexible data flow to efficiently accelerate training of various types of DNNs. The cycle level simulation and synthesized design in 15 nm FinFET shows power efficiency of 500 GFLOPS/W, and almost similar throughput for a wide range of DNNs, including convolutional, recurrent, and mixed (CNN+RNN) networks.","","","10.1109/TCAD.2018.2858358","National Science Foundation; Office of Naval Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8418347","Accelerator architectures;computer architecture","Training;Random access memory;Kernel;Convolution;Computer architecture;Programming;Data models","convolution;coprocessors;digital signal processing chips;embedded systems;energy conservation;feedforward neural nets;learning (artificial intelligence);logic design;memory architecture;MOSFET;optimisation;recurrent neural nets","DeepTrain;programmable embedded platform;training deep neural networks;energy-efficient training;key architectural concept;spatially homogeneous computing;temporally heterogeneous programmable data;memory mapping;data reuse;training operation;in-memory accelerator;3-D memory module;programming model;supporting architecture;power efficiency;high-performance training;DNN;logic layer;flexible data flow;cycle level simulation;design synthesis;convolutional neural networks;recurrent neural networks;mixed neural networks;CNN+RNN network","","4","33","","","","","IEEE","IEEE Journals"
"Auto-Tuning CNNs for Coarse-Grained Reconfigurable Array-Based Accelerators","I. Bae; B. Harris; H. Min; B. Egger","Department of Computer Science and Engineering, Seoul National University, Seoul, South Korea; Department of Computer Science and Engineering, Seoul National University, Seoul, South Korea; Department of Computer Science and Engineering, Seoul National University, Seoul, South Korea; Department of Computer Science and Engineering, Seoul National University, Seoul, South Korea","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","","2018","37","11","2301","2310","As more and more deep learning tasks are pushed to mobile devices, accelerators for running these networks efficiently gain in importance. We show a that an existing class of general purpose accelerators, modulo-scheduled coarse-grained reconfigurable array (CGRA) processors typically used to accelerate multimedia workloads, can be a viable alternative to dedicated deep neural network processing hardware. To this end, an auto-tuning compiler is presented that maps convolutional neural networks (CNNs) efficiently on such architectures. The auto-tuner analyzes the structure of the CNN and the features of the CGRA, then explores the large optimization space to generate code that allows for an efficient mapping of the network. Evaluated with various CNNs, the auto-tuned code achieves an 11-fold speedup over the initial mapping. Comparing the energy per interference, the CGRA outperforms other general-purpose accelerators and an ARMv8 processor by a significant margin.","","","10.1109/TCAD.2018.2857278","National Research Foundation of Korea; Basic Science Research Program of NRF through the Ministry of Science, ICT and Future Planning; Samsung; Seoul National University; ITC at Seoul National University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8412597","Automatic code optimization;coarse-grained reconfigurable array (CGRA);convolutional neural network (CNN) accelerator","Optimization;Program processors;Computer architecture;Convolution;Kernel;Hardware;Convolutional codes","convolution;feedforward neural nets;learning (artificial intelligence);parallel processing;program compilers","deep learning tasks;mobile devices;general purpose accelerators;modulo-scheduled coarse-grained reconfigurable array processors;auto-tuning compiler;convolutional neural networks;CNN auto-tuning;deep neural network processing hardware","","1","33","","","","","IEEE","IEEE Journals"
"Online Multimodal Multiexpert Learning for Social Event Tracking","S. Qian; T. Zhang; C. Xu","National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Multimedia","","2018","20","10","2733","2748","In this paper, we aim to automatically identify and track the interesting social event from vast amounts of social media data. However, there are two existing challenges: 1) how to model multimodal social event data over time and visualize the topic evolution and 2) how to alleviate the tracking drift problem to boost social event tracking accuracy. We propose a novel online multimodal multiexpert learning algorithm for social event tracking. Compared with existing methods, the proposed model has several advantages: First, it has a nonparametric online multimodal tracking module, which is able to not only automatically learn the number of topics from data over time, but also exploit the multimodal property of the social event. Second, it adopts a novel multiexpert minimization restoration scheme and allows the tracked model to evolve backwards to undo undesirable model updates, which helps alleviate the model drift problem of social event tracking. Third, it is able to not only effectively track the multimodal social event, but also automatically exploit the topic evolution of the social event for a deep understanding with multimodal topics. To evaluate the proposed model, we collect a real-world dataset for research on social event tracking with multimodality information. We have conducted extensive experiments, and both qualitative and quantitative evaluation results have demonstrated the effectiveness of the proposed model.","","","10.1109/TMM.2018.2815785","National Natural Science Foundation of China; Key Research Program of Frontier Sciences, CAS; Beijing Natural Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8316909","Social event tracking;topic evolution;multi-modality;topic model;social media","Data models;Social network services;Analytical models;Image restoration;Minimization;Google;Voting","image restoration;learning (artificial intelligence);object tracking;social networking (online)","multimodal social event data;tracking drift problem;social event tracking accuracy;nonparametric online multimodal tracking module;online multimodal multiexpert learning;social media data;multiexpert minimization restoration scheme","","1","53","","","","","IEEE","IEEE Journals"
"Depth Estimation of Video Sequences With Perceptual Losses","A. Wang; Z. Fang; Y. Gao; X. Jiang; S. Ma","School of Electronic and Electrical Engineering, Shanghai University of Engineering Science, Shanghai, China; School of Electronic and Electrical Engineering, Shanghai University of Engineering Science, Shanghai, China; School of Electronic and Electrical Engineering, Shanghai University of Engineering Science, Shanghai, China; School of Electronic and Electrical Engineering, Shanghai University of Engineering Science, Shanghai, China; Department of Electrical Engineering and Computer Science, Peking University, Beijing, China","IEEE Access","","2018","6","","30536","30546","3-D vision plays an important role in intelligent perception of robot, while it requires extra 3-D sensors. Depth estimation from monocular videos provides an alternative mechanism to recover the 3-D information. In this paper, we propose an unsupervised learning framework that uses the perceptual loss for depth estimation. Depth and pose networks are first trained to estimate the depth and the camera motion of the video sequence, respectively. With the estimated depth and pose of the original frame, the adjacent frame can be reconstructed. The pixel-wise differences between the constructed frame and the original frame are used as per-pixel loss. Meanwhile, reconstructed views and original views can be used to extract advanced features from a pre-trained network to define and optimize perceptual loss functions to assess the quality of reconstructions. We combine the respective advantages of these two methods and present an approach of generating a depth map by training the feed-forward network with per-pixel loss function and perceptual loss function. The experimental results show that our method can significantly improve the estimation accuracy of depth map.","","","10.1109/ACCESS.2018.2846546","National Natural Science Foundation of China; International Cooperation Project of Jiangxi Province; Collaborative Innovation Center for Economic Crime Investigation and Prevention Technology of Jiangxi Province; Local Colleges Faculty Construction of Shanghai MSTC; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8382156","Depth estimation;perceptual losses;unsupervised;deep learning","Estimation;Cameras;Feature extraction;Neural networks;Image reconstruction;Training;Three-dimensional displays","feature extraction;image motion analysis;image reconstruction;image sequences;stereo image processing;unsupervised learning;video signal processing","depth map;per-pixel loss function;perceptual loss function;depth estimation;video sequence;monocular videos;3-D information;unsupervised learning framework","","2","37","","","","","IEEE","IEEE Journals"
"Stacked Nonnegative Sparse Autoencoders for Robust Hyperspectral Unmixing","Y. Su; A. Marinoni; J. Li; J. Plaza; P. Gamba","Guangdong Provincial Key Laboratory of Urbanization and Geo-simulation, Center of Integrated Geographic Information Analysis, School of Geography and Planning, Sun Yat-sen University, Guangzhou, China; Dipartimento di Ingegneria Industriale e dell’Informazione, Università degli Studi di Pavia, Pavia, Italy; Guangdong Provincial Key Laboratory of Urbanization and Geo-simulation, Center of Integrated Geographic Information Analysis, School of Geography and Planning, Sun Yat-sen University, Guangzhou, China; Department of Technology of Computers and Communications, Hyperspectral Computing Laboratory, Escuela Politécnica, University of Extremadura, Cáceres, Spain; Dipartimento di Ingegneria Industriale e dell’Informazione, Università degli Studi di Pavia, Pavia, Italy","IEEE Geoscience and Remote Sensing Letters","","2018","15","9","1427","1431","As an unsupervised learning tool, autoencoder has been widely applied in many fields. In this letter, we propose a new robust unmixing algorithm that is based on stacked nonnegative sparse autoencoders (NNSAEs) for hyperspectral data with outliers and low signal-to-noise ratio. The proposed stacked autoencoders network contains two main steps. In the first step, a series of NNSAE is used to detect the outliers in the data. In the second step, a final autoencoder is performed for unmixing to achieve the endmember signatures and abundance fractions. By taking advantage from nonnegative sparse autoencoding, the proposed approach can well tackle problems with outliers and low noise-signal ratio. The effectiveness of the proposed method is evaluated on both synthetic and real hyperspectral data. In comparison with other unmixing methods, the proposed approach demonstrates competitive performance.","","","10.1109/LGRS.2018.2841400","National Natural Science Foundation of China; National Key Research and Development Program of China; Natural Science Foundation of Guangdong Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8387431","Deep learning;hyperspectral remote sensing;nonnegative sparse autoencoder (NNSAE);unmixing","Hyperspectral imaging;Artificial neural networks;Neurons;Training;Anomaly detection;Signal to noise ratio","geophysical image processing;hyperspectral imaging;signal processing;statistical analysis;unsupervised learning","stacked nonnegative sparse autoencoders;unsupervised learning tool;robust unmixing algorithm;hyperspectral data;outliers;low signal-to-noise ratio;stacked autoencoders network;low noise-signal ratio;robust hyperspectral unmixing;NNSAE;endmember signatures;abundance fractions;hyperspectral images;geophysical applications","","5","13","","","","","IEEE","IEEE Journals"
"Stream Processing Dual-Track CGRA for Object Inference","X. Fan; D. Wu; W. Cao; W. Luk; L. Wang","State Key Laboratory of Application Specific Integrated Circuit and System, Fudan University, Shanghai, China; State Key Laboratory of Application Specific Integrated Circuit and System, Fudan University, Shanghai, China; State Key Laboratory of Application Specific Integrated Circuit and System, Fudan University, Shanghai, China; Department of Computing, Imperial College London, London, U.K.; State Key Laboratory of Application Specific Integrated Circuit and System, Fudan University, Shanghai, China","IEEE Transactions on Very Large Scale Integration (VLSI) Systems","","2018","26","6","1098","1111","With the development of machine learning technology, the exploration of energy-efficient and flexible architectures for object inference algorithms is of growing interest in recent years. However, not many publications concentrate on a coarsegrained reconfigurable architecture (CGRA) for object inference algorithms. This paper provides a stream processing, dual-track programming CGRA-based approach to address the inherent computing characteristics of algorithms in object inference. Based on the proposed approach, an architecture called stream dual-track CGRA (SDT-CGRA) is presented as an implementation prototype. To evaluate the performance, the SDT-CGRA is realized in Verilog HDL and implemented in Semiconductor Manufacturing International Corporation 55-nm process, with the footprint of 5.19 mm2 at 450 MHz. Seven object inference algorithms, including convolutional neural network (CNN), k-means, principal component analysis (PCA), spatial pyramid matching (SPM), linear support vector machine (SVM), Softmax, and Joint Bayesian, are selected as benchmarks. The experimental results show that the SDT-CGRA can gain on average 343.8 times and 17.7 times higher energy efficiency for Softmax, PCA, and CNN, 621.0 times and 1261.8 times higher energy efficiency for k-means, SPM, linear-SVM, and Joint-Bayesian algorithms when compared with the Intel Xeon E5-2637 CPU and the Nvidia TitanX graphics processing unit. When compared with the state-of-the-art solutions of AlexNet on field-programmable gate array and CGRA, the proposed SDT-CGRA can achieve a 1.78 times increase in energy efficiency and a 13 times speedup, respectively.","","","10.1109/TVLSI.2018.2797600","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8290568","Acceleration;coarse-grained reconfigurable architecture (CGRA);deep learning;domain-specific computing;object inference","Computer architecture;Inference algorithms;Acceleration;Algorithm design and analysis;Kernel;Feature extraction;Signal processing algorithms","convolution;feedforward neural nets;hardware description languages;learning (artificial intelligence);parallel programming;principal component analysis;reconfigurable architectures;support vector machines","flexible architectures;coarsegrained reconfigurable architecture;SDT-CGRA;Joint-Bayesian algorithms;Nvidia TitanX graphics processing unit;Semiconductor Manufacturing International Corporation;energy efficiency;object inference algorithms;machine learning;stream processing dual-track programming CGRA;Verilog HDL;convolutional neural network;k-means;principal component analysis;spatial pyramid matching;linear support vector machine;Softmax;Joint Bayesian algorithms","","1","47","","","","","IEEE","IEEE Journals"
"H-DenseUNet: Hybrid Densely Connected UNet for Liver and Tumor Segmentation From CT Volumes","X. Li; H. Chen; X. Qi; Q. Dou; C. Fu; P. Heng","Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong","IEEE Transactions on Medical Imaging","","2018","37","12","2663","2674","Liver cancer is one of the leading causes of cancer death. To assist doctors in hepatocellular carcinoma diagnosis and treatment planning, an accurate and automatic liver and tumor segmentation method is highly demanded in the clinical practice. Recently, fully convolutional neural networks (FCNs), including 2-D and 3-D FCNs, serve as the backbone in many volumetric image segmentation. However, 2-D convolutions cannot fully leverage the spatial information along the third dimension while 3-D convolutions suffer from high computational cost and GPU memory consumption. To address these issues, we propose a novel hybrid densely connected UNet (H-DenseUNet), which consists of a 2-D DenseUNet for efficiently extracting intra-slice features and a 3-D counterpart for hierarchically aggregating volumetric contexts under the spirit of the auto-context algorithm for liver and tumor segmentation. We formulate the learning process of the H-DenseUNet in an end-to-end manner, where the intra-slice representations and inter-slice features can be jointly optimized through a hybrid feature fusion layer. We extensively evaluated our method on the data set of the MICCAI 2017 Liver Tumor Segmentation Challenge and 3DIRCADb data set. Our method outperformed other state-of-the-arts on the segmentation results of tumors and achieved very competitive performance for liver segmentation even with a single model.","","","10.1109/TMI.2018.2845918","Research Grants Council of the Hong Kong Special Administrative Region; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8379359","CT;liver tumor segmentation;deep learning;hybrid features","Liver;Three-dimensional displays;Two dimensional displays;Image segmentation;Feature extraction;Lesions","cancer;computerised tomography;convolution;feedforward neural nets;graphics processing units;image segmentation;learning (artificial intelligence);liver;medical image processing;patient diagnosis;patient treatment;tumours","liver segmentation;H-DenseUNet;hybrid densely connected UNet;CT volumes;hepatocellular carcinoma diagnosis;treatment planning;tumor segmentation method;fully convolutional neural networks;FCNs;GPU memory consumption;2-D DenseUNet;intra-slice features;end-to-end manner;inter-slice features;liver cancer;image segmentation;feature fusion layer;backbone;learning process","","27","59","","","","","IEEE","IEEE Journals"
"Classification of Whole Mammogram and Tomosynthesis Images Using Deep Convolutional Neural Networks","X. Zhang; Y. Zhang; E. Y. Han; N. Jacobs; Q. Han; X. Wang; J. Liu","Department of Computer Science, University of Kentucky, Lexington, KY, USA; Department of Computer Science, University of Kentucky, Lexington, KY, USA; Paul Laurence Dunbar High School, Lexington, KY, USA; Department of Computer Science, University of Kentucky, Lexington, KY, USA; Department of Radiology, University of Kentucky, Lexington, KY, USA; Department of Radiology, University of Kentucky, Lexington, KY, USA; Department of Computer Science, University of Kentucky, Lexington, KY, USA","IEEE Transactions on NanoBioscience","","2018","17","3","237","242","Mammography is the most popular technology used for the early detection of breast cancer. Manual classification of mammogram images is a hard task because of the variability of the tumor. It yields a noteworthy number of patients being called back to perform biopsies, ensuring no missing diagnosis. The convolutional neural network (CNN) has succeeded in a lot of image classification challenges during the recent years. In this paper, we proposed an approach of mammogram and tomosynthesis classification based on CNNs. We had acquired more than 3000 mammograms and tomosynthesis data with approval from an institutional review board at the University of Kentucky. Different models of CNNs were built to classify both the 2-D mammograms and 3-D tomosynthesis, and every classifier was assessed with respect to truth-values generated by histology results from the biopsy and two-year negative mammogram follow-up confirmed by expert radiologists. Our outcomes demonstrated that CNN-based models we had built and optimized utilizing transfer learning and data augmentation have good potential for automatic breast cancer detection based on the mammograms and tomosynthesis data.","","","10.1109/TNB.2018.2845103","National Science Foundation; American Cancer Society; National Institutes of Health; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8374855","Mammogram;tomosynthesis;convolutional neural network;classification","Mammography;Convolutional neural networks;Breast cancer;Training;Three-dimensional displays;Tumors","cancer;diagnostic radiography;feature extraction;image classification;learning (artificial intelligence);mammography;medical image processing;neural nets;tumours","CNN-based models;automatic breast cancer detection;tomosynthesis data;deep convolutional neural networks;mammogram images;convolutional neural network;image classification challenges;tomosynthesis classification;2D mammograms;3D tomosynthesis","Breast Neoplasms;Female;Humans;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Mammography;Neural Networks (Computer);Tomography","1","29","","","","","IEEE","IEEE Journals"
"Device-Free Non-Privacy Invasive Classification of Elderly Travel Patterns in a Smart House Using PIR Sensors and DCNN","M. Gochoo; T. Tan; V. Velusamy; S. Liu; D. Bayanduuren; S. Huang","Department of Electronic Engineering, National Taipei University of Technology, Taipei, Taiwan; Department of Electrical Engineering, National Taipei University of Technology, Taipei, Taiwan; Department of Electrical and Electronic Engineering, Manchester Metropolitan University, Manchester, U.K.; Department of Information Engineering, Chaoyang University of Technology, Taichung, Taiwan; School of Information and Communication Technology, Mongolian University of Science and Technology, Ulaanbaatar, Mongolia; Department of Electronic Engineering, National Taipei University of Technology, Taipei, Taiwan","IEEE Sensors Journal","","2018","18","1","390","400","Single resident life style is increasing among the elderly due to the issues of elderly care cost and privacy invasion. However, the single life style cannot be maintained if they have dementia. Thus, the early detection of dementia is crucial. Systems with wearable devices or cameras are not preferred choice for the long-term monitoring. Main intention of this paper is to propose deep convolutional neural network (DCNN) classifier for indoor travel patterns of elderly people living alone using open data set collected by device-free non-privacy invasive binary (passive infrared) sensor data. Travel patterns are classified as direct, pacing, lapping, or random according to Martino-Saltzman (MS) model. MS travel pattern is highly related with person's cognitive state, and thus can be used to detect early stage of dementia. We have utilized an open data set that was presented by Center for Advanced Studies in Adaptive Systems project, Washington State University. The data set was collected by monitoring a cognitively normal elderly person by wireless passive infrared sensors for 21 months. First, 117 320 travel episodes are extracted from the data set and classified by MS travel pattern classifier algorithm for the ground truth. Later, 12 000 episodes (3000 for each pattern) were randomly selected from the total episodes to compose training and testing data set. Finally, DCNN performance was compared with seven other classical machine-learning classifiers. The random forest and DCNN yielded the best classification accuracies of 94.48% and 97.84%, respectively. Thus, the proposed DCNN classifier can be used to infer dementia through travel pattern matching.","","","10.1109/JSEN.2017.2771287","Ministry of Science and Technology of Taiwan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8101507","Non-privacy invasive;deep learning;device-free;assistive technology;smart house;travel pattern;elder care","Sensors;Lapping;Senior citizens;Dementia;Training;Monitoring;Biomedical monitoring","computerised instrumentation;geriatrics;infrared detectors;intelligent sensors;neural nets;pattern classification;wireless sensor networks","device-free nonprivacy invasive classification;smart house;PIR sensor;DCNN;elderly care cost;privacy invasion;dementia detection;wearable device;camera;deep convolutional neural network;indoor travel pattern classification;device-free nonprivacy invasive binary sensor data;Martino-Saltzman model;Center for Advanced Studies in Adaptive Systems project;Washington State University;cognitively normal elderly person monitoring;wireless passive infrared sensor data;MS travel pattern classifier algorithm;classical machine-learning classifier;travel pattern matching;time 21 month","","2","33","","","","","IEEE","IEEE Journals"
"PERSON—Personalized Expert Recommendation System for Optimized Nutrition","C. Chen; M. Karvela; M. Sohbati; T. Shinawatra; C. Toumazou","Centre for Bio-Inspired Technology and the Department of Electrical and Electronic Engineering, Imperial College London, London, U.K.; DNAnudge, London, U.K.; Centre for Bio-Inspired Technology and the Department of Electrical and Electronic Engineering, Imperial College London, London, U.K.; DNAnudge, London, U.K.; Centre for Bio-Inspired Technology and the Department of Electrical and Electronic Engineering, Imperial College London, London, U.K.","IEEE Transactions on Biomedical Circuits and Systems","","2018","12","1","151","160","The rise of personalized diets is due to the emergence of nutrigenetics and genetic tests services. However, the recommendation system is far from mature to provide personalized food suggestion to consumers for daily usage. The main barrier of connecting genetic information to personalized diets is the complexity of data and the scalability of the applied systems. Aiming to cross such barriers and provide direct applications, a personalized expert recommendation system for optimized nutrition is introduced in this paper, which performs direct to consumer personalized grocery product filtering and recommendation. Deep learning neural network model is applied to achieve automatic product categorization. The ability of scaling with unknown new data is achieved through the generalized representation of word embedding. Furthermore, the categorized products are filtered with a model based on individual genetic data with associated phenotypic information and a case study with databases from three different sources is carried out to confirm the system.","","","10.1109/TBCAS.2017.2760504","DNAnudge Ltd; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8089390","Expert system;recommendation system;personalized diets;deep learning;grocery decisions;neural networks;genetic algorithm","Logic gates;Genetics;Data models;Recurrent neural networks;Genetic algorithms;Biological neural networks","expert systems;food products;genetic algorithms;neural nets","phenotypic information;word embedding;automatic product categorization;deep learning neural network model;personalized grocery product filtering;optimized nutrition;personalized expert recommendation system;PERSON","Decision Making, Computer-Assisted;Humans;Models, Theoretical;Neural Networks (Computer);Nutrition Assessment;Precision Medicine","","37","","","","","IEEE","IEEE Journals"
"Fast Object Detection at Constrained Energy","J. Liu; Y. Huang; J. Peng; J. Yao; L. Wang","Beijing, 100190, China; Beijing, 100190, China; Beijing, 100190, China; Beijing, 100190, China; Beijing, 100190, China","IEEE Transactions on Emerging Topics in Computing","","2018","6","3","409","416","Visual computing, e.g., automatic object detection, in mobile devices attracts more and more attention recently, in which fast models at constrained energy cost is a critical problem. In this paper, we introduce our work on designing models based on deep learning for 200 classes object detection in mobile devices, as well as exploring trade-off between accuracy and energy cost. In particular, we investigate several methods of extracting object proposals and integrate them into the fast-RCNN framework for object detection. Extensive experiments are conducted using the Jetson TK1 SOC platform and the Alienware-15 laptop, including detailed parameters evaluation with respect to accuracy, energy cost and speed. From these experiments, we conclude how to obtain good balance between accuracy and energy cost, which might provide guidance to design effective and efficient object detection models on mobile devices.","","","10.1109/TETC.2016.2577538","National Basic Research Program of China (973 Program); National Natural Science Foundation of China; Huawei Technologies Co., Ltd.; Strategic Priority Research Program of the CAS; Youth Innovation Promotion Association CAS; SAMSUNG GRO Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7486110","Object detection;constrained energy;fast-RCNN","Object detection;Proposals;Graphics processing units;Mobile handsets;Feature extraction;Machine learning;Portable computers","convolution;learning (artificial intelligence);mobile computing;neural nets;object detection;system-on-chip","RCNN framework;object detection models;visual computing;parameters evaluation;Jetson TK1 SOC platform;object proposals;deep learning;constrained energy cost;mobile devices;automatic object detection","","","46","","","","","IEEE","IEEE Journals"
"A novel design framework for smart operating robot in power system","Q. Wang; X. Yang; Z. Huang; S. Ma; Q. Li; D. W. Gao; F. Wang","State Grid Tianjin Electric Power Company, Tianjin 300010, China; State Grid Tianjin Electric Power Company, Tianjin 300010, China; State Grid Tianjin Electric Power Company, Tianjin 300010, China; State Grid Tianjin Electric Power Research Institute, Tianjin 300384, China; University of Denver, Denver, Colorado 80210, USA; University of Denver, Denver, Colorado 80210, USA; Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China","IEEE/CAA Journal of Automatica Sinica","","2018","5","2","531","538","This paper proposes the concept and framework of smart operating system based on the artificial intelligence (AI) techniques. The demands and the potential applications of AI technologies in power system control centers is discussed in the beginning of the paper. The discussion is based on the results of a field study in the Tianjin Power System Control Center in China. According to the study, one problem in power systems is that the power system analysis system in the control center is not fast and powerful enough to help the operators in time to deal with the incidents in the power system. Another issue in current power system control center is that the operation tickets are compiled manually by the operators, so that it is less efficient and human errors cannot be avoided. Based on these problems, a framework of the smart operating robot is proposed in this paper, which includes an intelligent power system analysis system and a smart operation ticket compiling system to solve the two problems in power system control centers. The proposed framework is mainly based on the AI techniques, especially the neural network with deep learning, since it is faster and more capable of dealing with the highly nonlinear and complex power system.","","","10.1109/JAS.2017.7510838","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8283978","","Power system stability;Machine learning;Robots;Maintenance engineering;Power system control","control engineering computing;intelligent robots;learning (artificial intelligence);neural nets;power engineering computing;power system control","deep learning;neural network;China;AI techniques;smart operation ticket compiling system;intelligent power system analysis system;Tianjin Power System Control Center;power system control centers;artificial intelligence techniques;smart operating system;smart operating robot","","1","","","","","","IEEE","IEEE Journals"
"Deep Learning of Complex Batch Process Data and Its Application on Quality Prediction","K. Wang; B. Gopaluni; J. Chen; Z. Song","Control Science and Engineering, Institute of Industrial Process Control, Hangzhou, Zhejiang China 310027 (e-mail: 11432023@zju.edu.cn); Chemical and Biological Engineering, University of British Columbia, Vancouver, British Columbia Canada V6T1Z3 (e-mail: bhushan.gopaluni@ubc.ca); Department of Chemical Engineering, Chung-Yuan Christian University, Chung-Li Taiwan 320 (e-mail: jason@wavenet.cycu.edu.tw); Control Science and Engineering, Institute of Industrial Process Control, Hangzhou, Zhejiang China 310027 (e-mail: zhsong@iipc.zju.edu.cn)","IEEE Transactions on Industrial Informatics","","2018","PP","99","1","1","Batch process quality prediction is an important application in the chemical industry. The complexity of batch processes is characterized by multiphase, nonlinearity, dynamics and uneven durations, so modeling of batch processes is very difficult. Moreover, there are other challenges in quality prediction. As the process trajectories over the whole running duration make contributions to the final targets, the prediction issue embraces tremendously high-dimensional inputs but very low-dimensional outputs. That is, the prediction suffers from a severe dimensional imbalance between inputs and outputs. To conquer these difficulties, this paper proposes a new deep learning-based framework for complex features and quality prediction. The long short-term memory is used to extract quality-relevant hidden features from a long-time sequence in each phase, significantly reducing the predictor dimensions. And these features from different phases are further integrated and compressed by a stacked auto-encoder. A practical industrial example testifies to the efficacy of the proposed framework.","","","10.1109/TII.2018.2880968","Ministry of Science and Technology, Taiwan; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8544024","batch process;quality prediction;long short-term memory;stacked auto-encoder","Batch production systems;Feature extraction;Predictive models;Trajectory;Sensors;Correlation","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Towards Generic Modelling of Viewer Interest Using Facial Expression and Heart Rate Features","P. R. Chakraborty; D. W. Tjondronegoro; L. Zhang; V. Chandran","IT Discipline, School of Business and Tourism, Southern Cross University, Bilinga, QLD, Australia; IT Discipline, School of Business and Tourism, Southern Cross University, Bilinga, QLD, Australia; School of Engineering and Technology, Central Queensland University, Brisbane, QLD, Australia; School of Electrical Engineering and Computer Science, Queensland University of Technology, Brisbane, QLD, Australia","IEEE Access","","2018","6","","62490","62502","Automatic detection of viewer interest while watching video contents can enable multimedia applications, such as online video streaming, to recommend contents in real time. However, there is yet a generic model for detecting viewer interest that is independent of subject and content while using noninvasive sensors in near-natural settings. This paper is the first attempt at solving this issue by investigating the feasibility of a generic model for detecting viewer interest based on facial expression and heart rate features. The proposed model adopts deep learning features, which are trained and tested using multisubjects' data across different video stimuli domains. The experimental results show that the generic model can reach a similar accuracy to a domain-specific model.","","","10.1109/ACCESS.2018.2874892","Queensland University of Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8487037","Facial expression;heart rate;heart rate variability;viewer interest","Motion pictures;Feature extraction;Heart rate;Sports;Streaming media;Machine learning;Histograms","behavioural sciences computing;face recognition;feature extraction;learning (artificial intelligence);multimedia communication;signal classification;video signal processing;video streaming","viewer interest;video contents;online video streaming;generic model;facial expression;heart rate features;domain-specific model;video stimuli domains;deep learning features","","","53","","","","","IEEE","IEEE Journals"
"Correlation-Preserving Photo Collage","L. Liu; H. Zhang; G. Jing; Y. Guo; Z. Chen; W. Wang","Department of Computer Science, The University of Hong Kong, Hong Kong, P.R. China; National Key Lab for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, P.R. China; Department of Computer Science, The University of Hong Kong, Hong Kong, P.R. China; National Key Lab for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, P.R. China; Department of Computer Science, Xiamen University, Xiamen, P.R. China; Department of Computer Science, The University of Hong Kong, Hong Kong, P.R. China","IEEE Transactions on Visualization and Computer Graphics","","2018","24","6","1956","1968","A new method is presented for producing photo collages that preserve content correlation of photos. We use deep learning techniques to find correlation among given photos to facilitate their embedding on the canvas, and develop an efficient combinatorial optimization technique to make correlated photos stay close to each other. To make efficient use of canvas space, our method first extracts salient regions of photos and packs only these salient regions. We allow the salient regions to have arbitrary shapes, therefore yielding informative, yet more compact collages than by other similar collage methods based on salient regions. We present extensive experimental results, user study results, and comparisons against the state-of-the-art methods to show the superiority of our method.","","","10.1109/TVCG.2017.2703853","National Natural Science Foundation of China; NSF of Jiangsu Province; National Natural Science Foundation of China; Research Grant Council of Hong Kong; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7927420","Photo collage;image saliency;irregular shaped packing;image classification","Correlation;Shape;Optimization;Semantics;Machine learning;Computer science;Feature extraction","combinatorial mathematics;correlation methods;feature extraction;learning (artificial intelligence);optimisation","correlation-preserving photo collage;deep learning techniques;canvas space;salient regions;combinatorial optimization technique;photos content correlation","","","30","","","","","IEEE","IEEE Journals"
"Preserving-Texture Generative Adversarial Networks for Fast Multi-Weighted MRI","T. Chen; X. Song; C. Wang","School of Computer Science and Communication Engineering, Jiangsu University, Zhenjiang, China; School of Computer Science and Communication Engineering, Jiangsu University, Zhenjiang, China; School of Computer Science and Communication Engineering, Jiangsu University, Zhenjiang, China","IEEE Access","","2018","6","","71048","71059","Traditional magnetic resonance imaging (MRI) acquires three contrasts of T1, T2, and proton density (PD), but only one contrast can be highlighted in an imaging process, which not only restricts the reference standard for disease but also increases the discomfort and medical expenses of the patients due to requiring two different weighted MRI. In order to solve such a problem, we proposed a method based on deep learning technology to provide two MRI contrasts after one signal acquisition. In this paper, a new model (PTGAN) based on generative adversarial networks is devised to convert T2-weighted MRI images into PD-weighted MRI images. In addition, we have devised four different network structures as the reference model of PTGAN, by which the different brain dissection MRI images, different noise MRI images, knee cartilage MRI images, and pathological MRI images from different body parts are used to test PTGAN. The research results show that the proposed PTGAN can effectively preserve the structure and texture and improve resolution in the conversion. Moreover, each T2-weighted MRI conversion takes only about 4 ms and can provide more information for disease diagnosis through different image contrasts.","","","10.1109/ACCESS.2018.2877932","National Natural Science Foundation of China; National Key Research and Development Program of China; Jiangsu Provincial Science and Technology Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8513818","T₂-weighted MRI;PD-weighted MRI;deep learning;generative adversarial networks (GAN);fast conversion;accurate diagnosis;preserve texture","Magnetic resonance imaging;Generative adversarial networks;Gallium nitride;Generators;Magnetization;Training;Mathematical model","biomedical MRI;brain;diseases;image segmentation;image texture;medical image processing","fast multiweighted MRI;proton density;deep learning technology;MRI contrasts;PTGAN;PD-weighted MRI images;reference model;knee cartilage MRI images;pathological MRI images;MRI conversion;magnetic resonance imaging;image contrasts;brain dissection MRI images;preserving-texture generative adversarial networks;signal acquisition;disease diagnosis","","1","48","","","","","IEEE","IEEE Journals"
"Effect of Word Sense Disambiguation on Neural Machine Translation: A Case Study in Korean","Q. Nguyen; A. Vo; J. Shin; C. Ock","Department of IT Convergence, University of Ulsan, Ulsan, South Korea; Department of IT Convergence, University of Ulsan, Ulsan, South Korea; Department of IT Convergence, University of Ulsan, Ulsan, South Korea; Department of IT Convergence, University of Ulsan, Ulsan, South Korea","IEEE Access","","2018","6","","38512","38523","With the advent of robust deep learning, neural machine translation (NMT) has achieved great progress and recently become the dominant paradigm in machine translation (MT). However, it is still confronted with the challenge of word ambiguities that force NMT to choose among several translation candidates that represent different senses of an input word. This research presents a case study using Korean word sense disambiguation (WSD) to improve NMT performance. First, we constructed a Korean lexical semantic network (LSN) as a large-scale lexical semantic knowledge base. Then, based on the Korean LSN, we built a Korean WSD preprocessor that can annotate the correct sense of Korean words in the training corpus. Finally, we conducted a series of translation experiments using Korean-English, Korean-French, Korean-Spanish, and Korean-Japanese language pairs. The experimental results show that our Korean WSD system can significantly improve the translation quality of NMT in terms of the BLEU, TER, and DLRATIO metrics. On average, it improved the precision by 2.94 BLEU points and improved translation error prevention by 4.04 TER points and 4.51 DLRATIO points for all the language pairs.","","","10.1109/ACCESS.2018.2851281","National Research Foundation of Korea; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8399736","Lexical semantic network;neural machine translation;word sense disambiguation","Semantics;Feeds;Standards;Robustness;Machine learning;Knowledge based systems;Training","language translation;learning (artificial intelligence);natural language processing;neural nets;statistical analysis","robust deep learning;neural machine translation;great progress;word ambiguities;force NMT;translation candidates;different senses;input word;Korean word sense disambiguation;NMT performance;Korean lexical semantic network;large-scale lexical semantic knowledge base;Korean LSN;Korean WSD preprocessor;correct sense;translation experiments;Korean-Japanese language pairs;Korean WSD system;translation quality;improved translation error prevention;Korean-Spanish language pairs;Korean-French language pairs;Korean-English language pairs;BLEU metrics;TER metrics;DLRATIO metrics","","3","50","","","","","IEEE","IEEE Journals"
"Automatic Pearl Classification Machine Based on a Multistream Convolutional Neural Network","Q. Xuan; B. Fang; Y. Liu; J. Wang; J. Zhang; Y. Zheng; G. Bao","College of Information Engineering, Zhejiang University of Technology, Hangzhou, China; College of Information Engineering, Zhejiang University of Technology, Hangzhou, China; College of Mechanical Engineering, Zhejiang University of Technology, Hangzhou, China; College of Information Engineering, Zhejiang University of Technology, Hangzhou, China; College of Information Engineering, Zhejiang University of Technology, Hangzhou, China; College of Information Engineering, Zhejiang University of Technology, Hangzhou, China; College of Mechanical Engineering, Zhejiang University of Technology, Hangzhou, China","IEEE Transactions on Industrial Electronics","","2018","65","8","6538","6547","In this paper, we design an automatic pearl classification machine, composed of four parts: feeding mechanism, delivering mechanism, vision-based detection device, and classification mechanism. Pearls can be delivered to the detection device one by one, where multiview images of each pearl can be collected. A novel multistream convolutional neural network (MS-CNN) is developed to cope with these multiview images, with each stream processing an image of particular viewing angle and different streams sharing part of weights to fuse high-order features without losing too much diversity. Using the machine, we collect 52 500 multiview images for 10 500 pearls, i.e., each pearl has five images of top, left, right, main, and rear views. These pearls were labeled by the experienced professionals in advance, and grouped into two classes with rough rules and seven classes with fine rules. Experimental results show that, compared with the support vector machine and backpropagation neural network, our MS-CNN behaves much better in both classification tasks, obtaining 92.14% and 91.24% accuracies. Moreover, the visualization of activations of convolutional kernels suggests that MS-CNN, imitating the manual process, can indeed recognize relatively complex features. These results indicate the potential value of our machine in the pearl industry.","","","10.1109/TIE.2017.2784394","National Natural Science Foundation of China; NSFC-Zhejiang Joint Fund for the Integration of Industrialization and Informatization; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8219720","Convolutional neural network (CNN);deep learning;fine-grained classification;machine learning;pearl classification machine;textural feature","Streaming media;Feature extraction;Containers;Shape;Visualization;Machine learning","aquaculture;backpropagation;computer vision;feature extraction;image classification;neural nets;support vector machines","multiview images;multistream convolutional neural network;pearl industry;classification tasks;backpropagation neural network;support vector machine;MS-CNN;classification mechanism;detection device;automatic pearl classification machine","","8","34","","","","","IEEE","IEEE Journals"
"Motion-Based Object Segmentation Based on Dense RGB-D Scene Flow","L. Shao; P. Shah; V. Dwaracherla; J. Bohg","Stanford University, Stanford, USA; Stanford University, Stanford, USA; Stanford University, Stanford, USA; Stanford University, Stanford, USA","IEEE Robotics and Automation Letters","","2018","3","4","3797","3804","Given two consecutive RGB-D images, we propose a model that estimates a dense three-dimensional (3D) motion field, also known as scene flow. We take advantage of the fact that in robot manipulation scenarios, scenes often consist of a set of rigidly moving objects. Our model jointly estimates the following: First, the segmentation of the scene into an unknown but finite number of objects, second, the motion trajectories of these objects, and finally, the object scene flow. We employ an hourglass, deep neural network architecture. In the encoding stage, the RGB and depth images undergo spatial compression and correlation. In the decoding stage, the model outputs three images containing a per-pixel estimate of the corresponding object center as well as object translation and rotation. This forms the basis for inferring the object segmentation and final object scene flow. To evaluate our model, we generated a new and challenging, large scale, synthetic dataset that is specifically targeted at robotic manipulation: It contains a large number of scenes with a very diverse set of simultaneously moving 3D objects and is recorded with a simulated, static RGB-D camera. In quantitative experiments, we show that we outperform state-of-the-art scene flow and motion-segmentation methods on this data set. In qualitative experiments, we show how our learned model transfers to challenging real-world scenes, visually generating better results than existing methods.","","","10.1109/LRA.2018.2856525","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8411477","RGB-D perception;object detection;segmentation and categorization;deep learning in robotics and automation","Three-dimensional displays;Motion segmentation;Object segmentation;Estimation;Image segmentation;Trajectory","cameras;image colour analysis;image motion analysis;image segmentation;image sequences;object detection;object recognition","motion-based object segmentation;three-dimensional motion field;robot manipulation scenarios;motion trajectories;deep neural network architecture;encoding stage;depth images;spatial compression;decoding stage;per-pixel estimate;corresponding object center;object translation;final object scene flow;robotic manipulation;simulated RGB-D camera;static RGB-D camera;state-of-the-art scene flow;motion-segmentation methods;learned model transfers;challenging real-world scenes;finite number;spatial correlation;object rotation;dense RGB-D scene flow;consecutive RGB-D images","","","37","","","","","IEEE","IEEE Journals"
"Leveraging Expert Feature Knowledge for Predicting Image Aesthetics","M. Kucer; A. C. Loui; D. W. Messinger","Chester F. Carlson Center for Imaging Science, Rochester Institute of Technology, Rochester, NY, USA; Kodak Alaris, Inc., Rochester, NY, USA; Chester F. Carlson Center for Imaging Science, Rochester Institute of Technology, Rochester, NY, USA","IEEE Transactions on Image Processing","","2018","27","10","5100","5112","The ability to rank the images based on their appearance finds many real-world applications, such as image retrieval or image album creation. Despite the recent dominance of deep learning methods in computer vision which often result in superior performance, they are not always the methods of choice because they lack interpretability. In this paper, we investigate the possibility of improving the image aesthetic inference of the convolutional neural networks with hand-designed features that rely on domain expertise in various fields. We perform a comparison of hand-crafted feature sets in their ability to predict fine-grained aesthetics scores on two image aesthetics data sets. We observe that even feature sets published earlier are able to compete with more recently published algorithms and, by combining the algorithms, a significant improvement in predicting image aesthetics is possible. By using a tree-based learner, we perform the feature elimination to understand the best performing features overall and across different image categories. Only roughly 15% and 8% of the features are needed to achieve full performance in predicting a fine-grained aesthetic score and binary classification, respectively. By combining the hand-crafted features with metafeatures that predict the quality of an image based on convolutional neural network features, the model performs better than a baseline VGG16 model. One can, however, achieve more significant improvement in both aesthetics score prediction and binary classification by fusing the hand-crafted features and the penultimate layer activations. Our experiments indicate an improvement up to 2.2% achieving current state-of-the-art binary classification accuracy on the aesthetic visual analysis data set when the hand-designed features are fused with activations from VGG16 and ResNet50 networks.","","","10.1109/TIP.2018.2845100","Kodak Alaris; RIT; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8374927","Computational aesthetics;image aesthetics;hand-crafted;aesthetic quality assessment","Feature extraction;Image color analysis;Prediction algorithms;Machine learning;Convolutional neural networks;Photography;Computer architecture","computer vision;convolution;feature extraction;feedforward neural nets;image classification;image retrieval;learning (artificial intelligence)","aesthetic visual analysis data;image retrieval;deep learning methods;image aesthetic inference;convolutional neural networks;hand-crafted feature sets;fine-grained aesthetics scores;image aesthetics data sets;tree-based learner;feature elimination;image album creation;computer vision;interpretability;binary classification;metafeatures;VGG16 model;penultimate layer activations;ResNet50 networks;image aesthetics prediction","","5","47","","","","","IEEE","IEEE Journals"
"Cross-Media Similarity Evaluation for Web Image Retrieval in the Wild","J. Dong; X. Li; D. Xu","College of Computer Science and Technology, Zhejiang University, Hangzhou, China; Key Laboratory of Data Engineering and Knowledge Engineering, School of Information, Renmin University of China, Beijing, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China","IEEE Transactions on Multimedia","","2018","20","9","2371","2384","In order to retrieve unlabeled images by textual queries, cross-media similarity computation is a key ingredient. Although novel methods are continuously introduced, little has been done to evaluate these methods together with large-scale query log analysis. Consequently, how far have these methods brought us in answering real-user queries is unclear. Given baseline methods that use relatively simple text/image matching, how much progress have advanced models made is also unclear. This paper takes a pragmatic approach to answering the two questions. Queries are automatically categorized according to the proposed query visualness measure and later connected to the evaluation of multiple cross-media similarity models on three test sets. Such a connection reveals that the success of the state of the art is mainly attributed to their good performance on visual-oriented queries, which account for only a small part of real-user queries. To quantify the current progress, we propose a simple text2image method, representing a novel query by a set of images selected from large-scale query log. Consequently, computing cross-media similarity between the query and a given image boils down to comparing the visual similarity between the given image and the selected images. Image retrieval experiments on the challenging Clickture dataset show that the proposed text2image is a strong baseline, comparing favorably to recent deep learning alternatives.","","","10.1109/TMM.2018.2796248","National Natural Science Foundation of China; Key Scientific Research Base for Digital Conservation of Cave Temples (Zhejiang University), State Administration for Cultural Heritage; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8265097","Web image retrieval;real-user query;cross-media similarity computation","Image retrieval;Visualization;Computational modeling;Benchmark testing;Search engines;Machine learning;Correlation","image matching;image retrieval;learning (artificial intelligence);query processing;search engines","cross-media similarity evaluation;web image retrieval;textual queries;large-scale query log analysis;pragmatic approach;query visualness measure;visual-oriented queries;real-user queries answering;deep learning;text2image method;text matching;unlabeled images retrieval;image matching;baseline methods","","","69","","","","","IEEE","IEEE Journals"
"Image-Matching Based Identification of Store Signage Using Web-Crawled Information","C. Liao; W. Wang; K. Sakurada; N. Kawaguchi","Graduate School of Engineering, Nagoya University, Nagoya, Japan; National Institute of Advanced Industrial Science and Technology, Tokyo, Japan; National Institute of Advanced Industrial Science and Technology, Tokyo, Japan; Graduate School of Engineering, Nagoya University, Nagoya, Japan","IEEE Access","","2018","6","","45590","45605","We address automatic matching of street images with relevant web resources to enable the identification of store signage in street images. Identification methods for signage usually involve image matching, which attempts to match query images to other similar viewings using pre-labeled copies from a target data set. Manual target data set, such as a fingerprinting database can ensure high-quality data but collected data must be fed manually, which significantly adds costs. Utilizing web-crawled information is a way for automatic data set generation at lower cost, however, imbalanced and noisy data can adversely affect identification accuracy. Our work aims to resolve these issues. We propose a signage identifier in Web-crawled information - SIWI. The SIWI includes a web image data set construction method, which can self-generate high-quality data sets through automated web-mining, including data filtering and pruning strategies, which effectively reduce the identification error caused by noise, imbalance, and insufficient data. Furthermore, by applying a Hybrid Image Matching method that combines the deep learning approach with the feature point matching to signage identification without Optical Character Recognition, it can handle arbitrary signage designs. Because there is no specialized training involved, the same process should also work for any other locations without manual adjustment. An experimental result achieves 91% accuracy in a real-life application, which confirms its effectiveness.","","","10.1109/ACCESS.2018.2865490","JSPS KAKENHI; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8439069","Web mining;data set generation;image matching;store signage identification","Image matching;Optical character recognition software;Engines;Training;Visualization;Machine learning;Character recognition","data mining;feature extraction;image matching;information filtering;Internet;learning (artificial intelligence);optical character recognition","noisy data;data filtering;identification error;arbitrary signage designs;query images;Web resources;Web-crawled information;image-matching based identification;hybrid image matching method;street images automatic matching;store signage identification;signage identifier in Web-crawled information;SIWI;Web image data set construction method;automated Web-mining;data pruning strategies;feature point matching;optical character recognition;deep learning approach","","","37","","","","","IEEE","IEEE Journals"
"Cascaded Segmentation-Detection Networks for Text-Based Traffic Sign Detection","Y. Zhu; M. Liao; M. Yang; W. Liu","School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China","IEEE Transactions on Intelligent Transportation Systems","","2018","19","1","209","219","In this paper, we propose a novel text-based traffic sign detection framework with two deep learning components. More precisely, we apply a fully convolutional network to segment candidate traffic sign areas providing candidate regions of interest (RoI), followed by a fast neural network to detect texts on the extracted RoI. The proposed method makes full use of the characteristics of traffic signs to improve the efficiency and accuracy of text detection. On one hand, the proposed two-stage detection method reduces the search area of text detection and removes texts outside traffic signs. On the other hand, it solves the problem of multi-scales for the text detection part to a large extent. Extensive experimental results show that the proposed method achieves the state-of-the-art results on the publicly available traffic sign data set: Traffic Guide Panel data set. In addition, we collect a data set of text-based traffic signs including Chinese and English traffic signs. Our method also performs well on this data set, which demonstrates that the proposed method is general in detecting traffic signs of different languages.","","","10.1109/TITS.2017.2768827","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239744","Text detection;text-based traffic sign detection;fully convolutional network;textboxes;object detection","Text recognition;Character recognition;Detectors;Machine learning;Assistive technology","feature extraction;image colour analysis;image segmentation;learning (artificial intelligence);neural nets;object detection;text detection;traffic engineering computing","cascaded segmentation-detection networks;traffic sign detection framework;fully convolutional network;fast neural network;two-stage detection method;text detection part;publicly available traffic sign data;text-based traffic signs;candidate traffic sign areas;deep learning components;traffic guide panel data;Chinese traffic signs;English traffic signs","","6","61","","","","","IEEE","IEEE Journals"
"Decoding Asynchronous Reaching in Electroencephalography Using Stacked Autoencoders","D. Pei; M. Burns; R. Chandramouli; R. Vinjamuri","Department of Biomedical Engineering, Sensorimotor Control Laboratory, Stevens Institute of Technology, Hoboken, NJ, USA; Department of Biomedical Engineering, Sensorimotor Control Laboratory, Stevens Institute of Technology, Hoboken, NJ, USA; Department of Biomedical Engineering, Sensorimotor Control Laboratory, Stevens Institute of Technology, Hoboken, NJ, USA; Department of Biomedical Engineering, Sensorimotor Control Laboratory, Stevens Institute of Technology, Hoboken, NJ, USA","IEEE Access","","2018","6","","52889","52898","Electroencephalography (EEG)-based brain-computer interfaces (BCIs) that decode cortical activity in reaching and grasping movements can enable natural upper limb motor control. In this paper, we studied the performance of stacked autoencoders in decoding asynchronous reaching movements in the dominant upper limb using EEG. Five individuals without any motor disabilities performed three self-paced reaching tasks while the endpoints of the arm movements were recorded with a motion tracker. Power spectral densities of the relevant cortical signals were extracted among eight bandwidths in the range of 1-45Hz to train a stacked autoencoder. For comparison, convolutional neural network (CNN) and traditional linear decoding using principal component analysis (PCA) for feature selection and linear discriminant analysis (LDA) for classification were also used. An average classification accuracy of 79±5.5% (best up to 88±6%) was achieved from all subjects on wide frequency band (1-45Hz) in offline analysis with stacked autoencoders while average classification accuracies of 68±9.1% (best up to 74±9.1%) with PCA-LDA and 49±13.8% (best up to 56±7.2%) with CNN were achieved. The simultaneous dimensionality reduction and feature extraction capabilities of stacked autoencoders can have significant advantages in BCI applications.","","","10.1109/ACCESS.2018.2869687","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8466111","Electroencephalography;arm reaching movement;stacked autoencoders;machine learning;deep learning;classification;principal component analysis;linear discriminant analysis","Electroencephalography;Decoding;Task analysis;Tracking;Feature extraction;Principal component analysis;Machine learning","biomechanics;brain-computer interfaces;electroencephalography;feature extraction;handicapped aids;medical signal processing;neural nets;neurophysiology;principal component analysis","average classification accuracy;stacked autoencoder;electroencephalography-based brain-computer interfaces;decode cortical activity;reaching grasping movements;natural upper limb motor control;asynchronous reaching movements;dominant upper limb;arm movements;relevant cortical signals;traditional linear decoding;frequency 1.0 Hz to 45.0 Hz","","4","38","","","","","IEEE","IEEE Journals"
"Deep Audio-visual Speech Recognition","T. Afouras; J. S. Chung; A. Senior; O. Vinyals; A. Zisserman","Engineering Science, University of Oxford, Oxford, Oxfordshire United Kingdom of Great Britain and Northern Ireland (e-mail: afourast@robots.ox.ac.uk); Engineering Science, University of Oxford, Oxford, Oxfordshire United Kingdom of Great Britain and Northern Ireland (e-mail: joon@robots.ox.ac.uk); Deepmind, Google Inc, 93176 Mountain View, California United States (e-mail: andrewsenior@google.com); Deepmind, Google Inc, 93176 Mountain View, California United States (e-mail: vinyals@google.com); Engineering Science, University of Oxford, Oxford, Oxford United Kingdom of Great Britain and Northern Ireland (e-mail: az@robots.ox.ac.uk)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","PP","99","1","1","The goal of this work is to recognise phrases and sentences being spoken by a talking face, with or without the audio. Unlike previous works that have focussed on recognising a limited number of words or phrases, we tackle lip reading as an open-world problem -- unconstrained natural language sentences, and in the wild videos. Our key contributions are: (1) we compare two models for lip reading, one using a CTC loss, and the other using a sequence-to-sequence loss. Both models are built on top of the transformer self-attention architecture; (2) we investigate to what extent lip reading is complementary to audio speech recognition, especially when the audio signal is noisy; (3) we introduce and publicly release two new datasets for audio-visual speech recognition: LRS2-BBC, consisting of thousands of natural sentences from British television; and LRS3-TED, consisting of hundreds of hours of TED and TEDx talks obtained from YouTube. The models that we train surpass the performance of all previous work on lip reading benchmark datasets by a significant margin.","","","10.1109/TPAMI.2018.2889052","Engineering and Physical Sciences Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8585066","Lip Reading;Audio Visual Speech Recognition;Deep Learning","Hidden Markov models;Lips;Speech recognition;Visualization;Videos;Feeds;Training","","","","5","","","","","","IEEE","IEEE Early Access Articles"
"Integration of Image Feature and Word Relevance: Toward Automatic Image Annotation in Cyber-Physical-Social Systems","Z. Ning; G. Zhou; Z. Chen; Q. Li","Key Laboratory for Ubiquitous Network and Service Software of Liaoning Province, School of Software, Dalian University of Technology, Dalian, China; Key Laboratory for Ubiquitous Network and Service Software of Liaoning Province, School of Software, Dalian University of Technology, Dalian, China; Key Laboratory for Ubiquitous Network and Service Software of Liaoning Province, School of Software, Dalian University of Technology, Dalian, China; Key Laboratory for Ubiquitous Network and Service Software of Liaoning Province, School of Software, Dalian University of Technology, Dalian, China","IEEE Access","","2018","6","","44190","44198","Image annotation is challenging due to the explosive increase of image data in cyber-physical-social systems. Because of the semantic gap between images and corresponding labels, it has attracted extensive attentions in recent years. However, most existing research neglects the imbalanced distribution of different classes and the internal relevance of image labels. Besides, the weak image labeling affects the annotation performance to some extent. To address these issues, we propose a learning model for image annotation through integrating deep features and label relevance of images. Specifically, we first employ a convolutional neural-network approach to extract the deep features of images and utilize the synthetic minority oversampling technique to deal with the problem of class imbalance. Furthermore, we exploit the correlations, including symbiotic and semantic relationships of labels, to compute the relevance of label sets. Then, we incorporate this relevance into one classifier to reconstruct the complete label sets, and learn the mapping from image features to the reconstructed label sets by the other classifier. In addition, a joint convex loss function is proposed, which combines the two classifiers via co-regularization and compels them to be consistent. We evaluate the proposed method on two benchmark data sets. The experimental results demonstrate that our method outperforms several state-of-the-art solutions.","","","10.1109/ACCESS.2018.2864332","National Natural Science Foundation of China; National Key Research and Development Plan; Fundamental Research Funds for the Central University; Nanjing University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8429928","Image annotation;label relevance;deep feature;cyber-physical-social systems","Image annotation;Semantics;Hidden Markov models;Visualization;Kernel;Correlation;Task analysis","image classification;image reconstruction;learning (artificial intelligence);neural nets","image feature;word relevance;cyber-physical-social systems;image data;internal relevance;image labels;deep features;label relevance;complete label sets;reconstructed label sets;automatic image annotation;convolutional neural-network approach","","3","36","","","","","IEEE","IEEE Journals"
"Denoising adversarial autoencoders: classifying skin lesions using limited labelled training data","A. Creswell; A. Pouplin; A. A. Bharath","BICV, Bioengineering, Imperial College, UK; BICV, Bioengineering, Imperial College, UK; BICV, Bioengineering, Imperial College, UK","IET Computer Vision","","2018","12","8","1105","1111","The authors propose a novel deep learning model for classifying medical images in the setting where there is a large amount of unlabelled medical data available, but the amount of labelled data is limited. They consider the specific case of classifying skin lesions as either benign or malignant. In this setting, the authors' proposed approach - the semi-supervised, denoising adversarial autoencoder - is able to utilise vast amounts of unlabelled data to learn a representation for skin lesions, and small amounts of labelled data to assign class labels based on the learned representation. They perform an ablation study to analyse the contributions of both the adversarial and denoising components and compare their work with state-of-the-art results. They find that their model yields superior classification performance, especially when evaluating their model at high sensitivity values.","","","10.1049/iet-cvi.2018.5243","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8555958","","","feature extraction;image classification;learning (artificial intelligence);medical image processing;pattern classification;skin","model yields superior classification performance;denoising components;learned representation;class labels;unlabelled data;vast amounts;specific case;labelled data;unlabelled medical data;classifying medical images;deep learning model;labelled training data;skin lesions;adversarial autoencoder","","","14","","","","","IET","IET Journals"
"Anatomically Constrained Neural Networks (ACNNs): Application to Cardiac Image Enhancement and Segmentation","O. Oktay; E. Ferrante; K. Kamnitsas; M. Heinrich; W. Bai; J. Caballero; S. A. Cook; A. de Marvao; T. Dawes; D. P. O‘Regan; B. Kainz; B. Glocker; D. Rueckert","Biomedical Image Analysis Group, Imperial College London, London, U.K.; Biomedical Image Analysis Group, Imperial College London, London, U.K.; Biomedical Image Analysis Group, Imperial College London, London, U.K.; Institute of Medical Informatics, University of Lübeck, Lübeck, Germany.; Biomedical Image Analysis Group, Imperial College London, London, U.K.; Biomedical Image Analysis Group, Imperial College London, London, U.K.; MRC Clinical Sciences Centre, London, U.K.; MRC Clinical Sciences Centre, London, U.K.; MRC Clinical Sciences Centre, London, U.K.; MRC Clinical Sciences Centre, London, U.K.; Biomedical Image Analysis Group, Imperial College London, London, U.K.; Biomedical Image Analysis Group, Imperial College London, London, U.K.; Biomedical Image Analysis Group, Imperial College London, London, U.K.","IEEE Transactions on Medical Imaging","","2018","37","2","384","395","Incorporation of prior knowledge about organ shape and location is key to improve performance of image analysis approaches. In particular, priors can be useful in cases where images are corrupted and contain artefacts due to limitations in image acquisition. The highly constrained nature of anatomical objects can be well captured with learning-based techniques. However, in most recent and promising techniques such as CNN-based segmentation it is not obvious how to incorporate such prior knowledge. State-of-the-art methods operate as pixel-wise classifiers where the training objectives do not incorporate the structure and inter-dependencies of the output. To overcome this limitation, we propose a generic training strategy that incorporates anatomical prior knowledge into CNNs through a new regularisation model, which is trained end-to-end. The new framework encourages models to follow the global anatomical properties of the underlying anatomy (e.g. shape, label structure) via learnt non-linear representations of the shape. We show that the proposed approach can be easily adapted to different analysis tasks (e.g. image enhancement, segmentation) and improve the prediction accuracy of the state-of-the-art models. The applicability of our approach is shown on multi-modal cardiac data sets and public benchmarks. In addition, we demonstrate how the learnt deep models of 3-D shapes can be interpreted and used as biomarkers for classification of cardiac pathologies.","","","10.1109/TMI.2017.2743464","EPSRC Program; British Heart Foundation, U.K.; National Institute for Health Research (NIHR) Biomedical Research Centre-based at Imperial College Healthcare NHS Trust; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8051114","Shape prior;convolutional neural network;medical image segmentation;image super-resolution","Image segmentation;Shape;Biomedical imaging;Computational modeling;Image resolution;Artificial neural networks;Motion segmentation","biomedical MRI;cardiology;image enhancement;image segmentation;learning (artificial intelligence);medical image processing;neural nets","cardiac pathologies;3-D shapes;learnt deep models;multimodal cardiac data sets;state-of-the-art models;different analysis tasks;learnt nonlinear representations;global anatomical properties;trained end-to-end;regularisation model;anatomical prior knowledge;generic training strategy;pixel-wise classifiers;state-of-the-art methods;recent promising techniques;anatomical objects;image acquisition;image analysis approaches;organ shape;incorporation;cardiac image enhancement;ACNNs;anatomically constrained neural networks","Algorithms;Cardiac Imaging Techniques;Cardiomyopathies;Databases, Factual;Heart;Humans;Imaging, Three-Dimensional;Magnetic Resonance Imaging;Neural Networks (Computer)","27","49","CCBY","","","","IEEE","IEEE Journals"
"Visually Interpretable Representation Learning for Depression Recognition from Facial Images","X. Zhou; K. Jin; Y. Shang; G. Guo","School of Automation, Beijing University of Posts and Telecommunications, China (e-mail: xiuzhuang.zhou@cnu.edu.cn); Department of Computer Science, Capital Normal University, Beijing, Beijing China (e-mail: jinkai@cnu.edu.cn); Department of Computer Science, Capital Normal University, Beijing, Beijing China (e-mail: syy.cnu@gmail.com); CSEE, West Virginia University, Morgantown, West Virginia United States 26506 (e-mail: Guodong.Guo@mail.wvu.edu)","IEEE Transactions on Affective Computing","","2018","PP","99","1","1","Recent evidence in mental health assessment have demonstrated that facial appearance could be highly indicative of depressive disorder. While previous methods based on the facial analysis promise to advance clinical diagnosis of depressive disorder in a more efficient and objective manner, challenges in visual representation of complex depression pattern prevent widespread practice of automated depression diagnosis. In this paper, we present a deep regression network termed DepressNet to learn a depression representation with visual explanation. Specifically, a deep convolutional neural network equipped with a global average pooling layer is first trained with facial depression data, which allows for identifying salient regions of input image in terms of its severity score based on the generated depression activation map (DAM). We then propose a multi-region DepressNet, with which multiple local deep regression models for different face regions are jointly leaned and their responses are fused to improve the overall recognition performance. We evaluate our method on two benchmark datasets, and the results show that our method significantly boosts state-of-the-art performance of the visual-based depression recognition. Most importantly, the DAM induced by our learned deep model may help reveal the visual depression pattern on faces and understand the insights of automated depression diagnosis.","","","10.1109/TAFFC.2018.2828819","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8344107","Depression recognition;face recognition;deep convolutional neural network;depression activation map","Visualization;Feature extraction;Videos;Face recognition;Face;Computer architecture;Image recognition","","","","7","","","","","","IEEE","IEEE Early Access Articles"
"Application behaviors Driven Self-Organizing Network (SON) for 4G LTE networks","Y. Ouyang; Z. Li; L. Su; W. Lu; Z. Lin","Verizon Inc, 5943 Basking Ridge, New Jersey United States (e-mail: Ye.Ouyang@VerizonWireless.com); Verizon Inc, 5943 Basking Ridge, New Jersey United States 07920-1097 (e-mail: Thomas.Li@VerizonWireless.com); Verizon Inc, 5943 Basking Ridge, New Jersey United States (e-mail: su.le@VerizonWireless.com); Verizon Inc, 5943 Basking Ridge, New Jersey United States (e-mail: Wenyuan.Lu@VerizonWireless.com); Verizon Wireless, Basking Ridge, New Jersey United States (e-mail: Zhenyi.lin@VerizonWireless.com)","IEEE Transactions on Network Science and Engineering","","2018","PP","99","1","1","Self-Organizing Networks (SON) is an automation technology in the wireless industry implemented to simplify the planning, deployment, operation, optimization, and healing of networks. However, legacy SON functions are targeted at network automation and network optimization through certain optimization rules and policies which are globally applied in the entire networks. Therefore, scalable and targeted optimization is not supported in these existing SON solutions. Furthermore, such existing SON schemes are driven by performance optimization rather than ultimately improving user Quality of Experience (QoE). The impact of application characteristics on network performance and further on QoE are also not considered in SON defined by 3GPP. This paper presents an application characteristics-driven SON system (APP-SON) to optimize 4G/5G network performance and user Quality of Experience. APP-SON leverages a scalable big data platform for targeted optimization through profiling cell application characteristics with an incremental manner in temporal space. A Hungarian Algorithm Assisted Clustering (HAAC) algorithm and a deep learning-assisted regression algorithm are developed to profile the cell application characteristics and find the targeted KPIs to be optimized for each cell in a network. A similarity-based parameter-tuning algorithm is designed to tune the corresponding engineering parameters to optimize the targeted KPIs which further improve the QoE. Experimental results demonstrated that the APP-SON system can precisely profile cell traffic and application characteristics to find the targeted KPIs for optimization. APP-SON can also automatically tune the corresponding engineering parameters to improve corresponding KPIs, ultimately improving QoE. APP-SON has been successfully implemented in production and applied in a tier-1 operator's 4G network. As a universal SON solution, it will be smoothly transitioned and applied in 5G networks for this operator.","","","10.1109/TNSE.2018.2877353","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8502107","SON;Self-Optimization;Big Data;Machine Learning;Deep Learning;Ensemble Learning;Clustering","Computer architecture;Optimization;Clustering algorithms;Microprocessors;Quality of experience;Long Term Evolution;Planning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Learning Face Image Quality From Human Assessments","L. Best-Rowden; A. K. Jain","Department of Computer Science and Engineering, Michigan State University, East Lansing, MI, USA; Department of Computer Science and Engineering, Michigan State University, East Lansing, MI, USA","IEEE Transactions on Information Forensics and Security","","2018","13","12","3064","3077","Face image quality can be defined as a measure of the utility of a face image to automatic face recognition. In this paper, we propose (and compare) two methods for learning face image quality based on target face quality values from: 1) human assessments of face image quality (matcher-independent) and 2) quality values computed from similarity scores (matcher-dependent). A support vector regression model trained on face features extracted using a deep convolutional neural network (ConvNet) is used to predict the quality of a face image. The proposed methods are evaluated on two unconstrained face image databases, Labeled Faces in the Wild and IARPA Janus Benchmark-A (IJB-A), which both contain facial variations encompassing a multitude of quality factors. Evaluation of the proposed automatic face image quality measures shows we are able to reduce the false non-match rate at 1% false match rate by at least 13% for two face matchers (a commercial off-the-shelf matcher and a ConvNet matcher) by using the proposed face quality to select subsets of face images and video frames for matching templates (i.e., multiple faces per subject) in the IJB-A protocol. To the best of our knowledge, this is the first work to utilize human assessments of face image quality in designing a predictor of unconstrained face quality that is shown to be effective in cross-database evaluation.","","","10.1109/TIFS.2018.2799585","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8272466","Face image quality;face recognition;biometric quality;crowdsourcing;unconstrained face images","Face;Face recognition;Image quality;Databases;Image recognition;Lighting;Prediction algorithms","face recognition;feature extraction;feedforward neural nets;image matching;learning (artificial intelligence);protocols;regression analysis;support vector machines;video signal processing","multiple faces;human assessments;unconstrained face quality;automatic face recognition;target face quality values;unconstrained face image databases;automatic face image quality;face matchers;labeled faces;support vector regression model;face feature extraction;deep convolutional neural network;ConvNet;IARPA Janus benchmark-A;IJB-A;false nonmatch rate;video frames;matching templates;cross-database evaluation","","1","53","","","","","IEEE","IEEE Journals"
"Legal Decision Support: Exploring Big Data Analytics Approach to Modeling Pharma Patent Validity Cases","V. Raghupathi; Y. Zhou; W. Raghupathi","Koppelman School of Business, Brooklyn College, The City University of New York, New York, NY, USA; Gabelli School of Business, Fordham University, New York, NY, USA; Gabelli School of Business, Fordham University, New York, NY, USA","IEEE Access","","2018","6","","41518","41528","This exploratory research examines the potential for applying a big data analytic framework to the modeling and analysis of cases in pharmaceutical patent validity brought before the U.S. Court of Appeals of the Federal Circuit. We start with two specific goals: one, to identify the key issues or reasons the Court uses to makes validity decisions and, two, to attempt to predict outcomes for new cases. The ultimate goal is to support legal decision-making with automation. The legal domain is a challenging one to tackle. However, current advances in analytic technologies and models hold the promise of success. Our application of Hadoop MapReduce in conjunction with a number of algorithms, such as clustering, classification, word count, word co-occurrence, and row similarity, is encouraging, in that the results are robust enough to suggest these approaches have promise and are worth pursuing. By utilizing larger case data sets and sample sizes and by using deep machine learning models in text analytics, more breakthroughs can be achieved to provide decision support to the legal domain. From an economic standpoint, the potential for litigation cost reduction is another objective of our study. Synergies are obtained in applying lessons to the computational field and vice versa, leading to acceleration in our understanding.","","","10.1109/ACCESS.2018.2859052","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8418375","Big data analytics;Hadoop MapReduce;legal decision making;machine learning;pharma patent validity","Patents;Law;Drugs;Technological innovation;Decision making","Big Data;data analysis;law administration;learning (artificial intelligence);patents","legal decision-making;legal domain;analytic technologies;word count;word co-occurrence;deep machine learning models;text analytics;legal decision support;big data analytics approach;big data analytic framework;US Court of Appeals of the Federal Circuit;pharmaceutical patent validity case","","1","67","","","","","IEEE","IEEE Journals"
"Noncontact Sleep Stage Estimation Using a CW Doppler Radar","H. Hong; L. Zhang; C. Gu; Y. Li; G. Zhou; X. Zhu","School of Electronic and Optical Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Electronic and Optical Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Electronic and Optical Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Electronic and Optical Engineering, Nanjing University of Science and Technology, Nanjing, China; Jinling Hospital, Nanjing, China; School of Electronic and Optical Engineering, Nanjing University of Science and Technology, Nanjing, China","IEEE Journal on Emerging and Selected Topics in Circuits and Systems","","2018","8","2","260","270","Sleep stage estimation is crucial to the evaluation of sleep quality and is a proven biometric in diagnosing cardiovascular diseases. In this paper, we design a continuous wave (CW) Doppler radar to accurately measure sleep-related signals, including respiration, heartbeat, and body movement. Body movement index, respiration per minute (RPM), variance of RPM, amplitude difference accumulation (ADA) of respiration, rapid eye movement parameter, sample entropy, heartbeat per minute (HPM), variance of HPM, ADA of heartbeat, deep parameter, and time feature have been extracted and fed into different machine learning classifiers. A total of 11 all night polysomnography recordings from 13 healthy examinees were used to validate the proposed CW Doppler radar system and the ability to detect sleep stage information from it. Comparative studies and statistical results have shown that the subspace K-nearest neighbor algorithm outperforms the other classifiers with the highest accuracy of up to 86.6%. With the Relief F algorithm, features have been ranked, and the selected feature subsets have been preliminary tested to identify the optimal feature subset. Meanwhile, comparative analysis of our classification performance under different sleep stage patterns with prior works has been carried out to show the significant improvements over state-of-the-art solutions. These results suggest that the proposed scheme is suitable for long-term sleep monitoring.","","","10.1109/JETCAS.2017.2789278","National Natural Science Foundation of China; National Key Technology Support Program; Natural Science Foundation of Jiangsu Province; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8245788","Sleep stage;Doppler radar;noncontact;machine learning;polysomnography;sleep monitoring","Sleep;Doppler radar;Estimation;Heart beat;Monitoring;Feature extraction","cardiovascular system;CW radar;diseases;Doppler radar;entropy;eye;feature extraction;feature selection;learning (artificial intelligence);medical signal processing;nearest neighbour methods;patient diagnosis;patient monitoring;pneumodynamics;signal classification;sleep","noncontact sleep stage estimation;sleep quality;continuous wave Doppler radar;sleep-related signals;body movement index;RPM;amplitude difference accumulation;ADA;rapid eye movement parameter;sample entropy;HPM;deep parameter;CW Doppler radar system;sleep stage information;subspace K-nearest neighbor algorithm;selected feature subsets;optimal feature subset;long-term sleep monitoring;cardiovascular disease diagnosis;respiration per minute;heartbeat per minute;time feature extraction;machine learning classifiers;all-night polysomnography recordings;sleep stage patterns;Relief F algorithm","","11","51","","","","","IEEE","IEEE Journals"
"A Multi-Functional In-Memory Inference Processor Using a Standard 6T SRAM Array","M. Kang; S. K. Gonugondla; A. Patil; N. R. Shanbhag","Coordinated Science Laboratory, University of Illinois at Urbana–Champaign, Champaign, IL, USA; Coordinated Science Laboratory, University of Illinois at Urbana–Champaign, Champaign, IL, USA; Coordinated Science Laboratory, University of Illinois at Urbana–Champaign, Champaign, IL, USA; Coordinated Science Laboratory, University of Illinois at Urbana–Champaign, Champaign, IL, USA","IEEE Journal of Solid-State Circuits","","2018","53","2","642","655","A multi-functional in-memory inference processor integrated circuit (IC) in a 65-nm CMOS process is presented. The prototype employs a deep in-memory architecture (DIMA), which enhances both energy efficiency and throughput over conventional digital architectures via simultaneous access of multiple rows of a standard 6T bitcell array (BCA) per precharge, and embedding column pitch-matched low-swing analog processing at the BCA periphery. In doing so, DIMA exploits the synergy between the dataflow of machine learning (ML) algorithms and the SRAM architecture to reduce the dominant energy cost due to data movement. The prototype IC incorporates a 16-kB SRAM array and supports four commonly used ML algorithms-the support vector machine, template matching, k-nearest neighbor, and the matched filter. Silicon measured results demonstrate simultaneous gains (dot product mode) in energy efficiency of 10× and in throughput of 5.3× leading to a 53× reduction in the energy-delay product with negligible (≤1%) degradation in the decision-making accuracy, compared with the conventional 8-b fixed-point single-function digital implementations.","","","10.1109/JSSC.2017.2782087","Systems on Nanoscale Information fabriCs (SONIC), one of the six SRC STARnet Centers, sponsored by SRC and DARPA; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8246704","Accelerator;analog processing;associative memory;in-memory processing;inference;machine learning (ML)","Integrated circuits;Random access memory;Prototypes;Computer architecture;Standards;Throughput;Inference algorithms","CMOS memory circuits;inference mechanisms;learning (artificial intelligence);memory architecture;SRAM chips","template matching;deep in-memory architecture;support vector machine;CMOS process;energy-delay product;k-nearest neighbor;data movement;SRAM architecture;machine learning algorithms;BCA periphery;low-swing analog processing;standard 6T bitcell array;conventional digital architectures;energy efficiency;DIMA;in-memory inference processor integrated circuit;standard 6T SRAM array","","22","39","","","","","IEEE","IEEE Journals"
"QoE Assessment of Encrypted YouTube Adaptive Streaming for Energy Saving in Smart Cities","W. Pan; G. Cheng","School of Cybersecurity, Southeast University, Nanjing, China; School of Cybersecurity, Southeast University, Nanjing, China","IEEE Access","","2018","6","","25142","25156","Video streaming has become one of the most prevalent mobile applications and uses a substantial portion of the traffic on mobile networks today. With the limited bandwidth of mobile networks, understanding the user perception of the quality (i.e., Quality of Experience or QoE) of video streaming services is thus paramount for content providers and content-delivery network providers to flexibly configure network bandwidth, video servers, routing devices, and other network resources to save energy in smart cities. Although various video QoE assessment approaches have been proposed using different key performance indicators (KPIs), they all essentially relate to a common parameter: bitrate. However, because YouTube has adopted hyper text transfer protocol over secure socket layer (HTTPS) as its adaptive video streaming method to better protect user privacy and network security, bitrate can no longer be obtained from encrypted video traffic via typical deep packet inspection. In this paper, we address this challenge by proposing a machine-learning-based bitrate estimation (MBE) approach to parse bitrate information from IP packet level measurements. First, we filter HTTPS YouTube traffic based on the previously established video server IP according to the data packet googlevideo field. Then, we identify the transmission mode according to the traffic characteristics of several previous packets. Next, we identify the bitrates and resolutions of HTTP Live Streaming and Dynamic Adaptive Streaming over HTTP modes according to the characteristics of video chunks. Finally, for evaluating the effectiveness of MBE, we have chosen the video Mean Opinion Score (vMOS) proposed by a leading telecom vendor as the QoE assessment framework, and have conducted comprehensive experiments to study the impact of bitrate estimation accuracy on its KPIs for the HTTPS YouTube video streaming service. Experimental results show that MBE is a feasible and highly effective QoE evaluation approach to flexibly configure network resources in smart cities.","","","10.1109/ACCESS.2018.2811416","Fundamental Research Funds for the Central Universities; National High Technology Research and Development Program (863 Program) of China; Jiangsu Future Networks Innovation Institute: Prospective Research Project on Future Networks; Six talent peaks of high level Talents Project of Jiangsu province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8310894","Hyper text transfer protocol over secure socket layer (HTTPS) YouTube;QoE assessment;adaptive streaming;machine learning;smart city","Streaming media;Quality of experience;YouTube;Bit rate;Cryptography;Adaptive systems;Smart cities","cryptography;hypermedia;IP networks;learning (artificial intelligence);quality of experience;smart cities;social networking (online);telecommunication traffic;transport protocols;video servers;video streaming","content-delivery network providers;video servers;smart cities;video QoE assessment approaches;secure socket layer;user privacy;network security;MBE;IP packet level measurements;data packet googlevideo field;HTTPS YouTube video streaming service;vMOS;video mean opinion score;machine-learning-based bitrate estimation approach;HTTPS YouTube traffic characteristics;encrypted YouTube adaptive video streaming service;QoE evaluation approach;HTTP live streaming;video server IP;video traffic encryption;mobile network applications;dynamic adaptive streaming;deep packet inspection;hypertext transfer protocol;KPI","","3","52","","","","","IEEE","IEEE Journals"
"HearthBot: An Autonomous Agent Based on Fuzzy ART Adaptive Neural Networks for the Digital Collectible Card Game HearthStone","A. R. da Silva; L. F. W. Goes","Department of Computer Science, Pontificia Universidade Catolica de Minas Gerais, Belo Horizonte, Brazil; Department of Computer Science, Pontificia Universidade Catolica de Minas Gerais, Belo Horizonte, Brazil","IEEE Transactions on Games","","2018","10","2","170","181","Digital collectible card games, as partially observable games based on alternating turns, such as HearthStone, have been the most played card games in recent years, where the main challenge is the creation of strategies capable of subdue the enemy's moves. From the artificial intelligence perspective, the space of possible strategies is large and dynamic due to the number of cards and actions combinations and also to randomness, which makes the design of efficient autonomous agents a hard problem. This paper presents HearthBot, an autonomous agent that plays HearthStone through an adaptive neural network inspired in the fuzzy adaptive resonance associative map and adaptive resonance theory map. This paper also proposes a new mechanism to categorize and predict information to overcome the overgeneralization problem from those networks. Furthermore, the proposed solution was implemented as a parallel adaptive neural network for a graphics processing unit that achieves a performance compatible with the ones obtained for deep learning methods. HearthBot win rate was evaluated in two experiments playing against a Monte Carlo tree search heuristic with competitive decks on a HearthStone simulator called Metastone. Results show that the proposed solution allows HearthBot to obtain an average win rate performance of 80% against known decks and 70% against unknown decks.","","","10.1109/TCIAIG.2017.2743347","Coordenação de Aperfeiçoamento de Pessoal de Nível Superior; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8015141","Autonomous agent;adaptive resonance associative map (ARAM);adaptive resonance theory map (ARTMAP);fusion architecture for learning cognition and navigation (FALCON);fuzzy adaptive neural networks;HearthStone;neural networks","Games;Adaptive systems;Neural networks;Autonomous agents;Subspace constraints;Avatars;Adaptation models","ART neural nets;computer games;fuzzy neural nets;learning (artificial intelligence);Monte Carlo methods;tree searching","autonomous agent;fuzzy adaptive resonance associative map;parallel adaptive neural network;HearthStone simulator;fuzzy ART adaptive neural networks;digital collectible card games;played card games;artificial intelligence;HearthBot;deep learning;Monte Carlo tree search;Metastone","","2","35","","","","","IEEE","IEEE Journals"
"Whole Brain fMRI Pattern Analysis Based on Tensor Neural Network","X. Xu; Q. Wu; S. Wang; J. Liu; J. Sun; A. Cichocki","School of Information Science and Engineering, Shandong University, Jinan, China; School of Information Science and Engineering, Shandong University, Jinan, China; School of Information Science and Engineering, Shandong University, Jinan, China; School of Information Science and Engineering, Shandong University, Jinan, China; School of Information Science and Engineering, Shandong Normal University, Jinan, China; Skolkovo Institute of Science and Technology, Moscow, Russia","IEEE Access","","2018","6","","29297","29305","Functional magnetic resonance imaging (fMRI) has increasingly come to dominate brain mapping research, as it provides a dynamic view of brain matter. Feature selection or extraction methods play an important role in the successful application of machine learning techniques to classifying fMRI data by appropriately reducing the dimensionality of the data. While whole-brain fMRI data contains large numbers of voxels, the curse of dimensionality problem may limit the feature selection/extraction and classification performance of traditional methods. In this paper, we propose a novel framework based on a tensor neural network (TensorNet) to extract the essential and discriminative features from the whole-brain fMRI data. The tensor train model was employed to construct a simple and shallow neural network and compress a large number of network weight parameters. The proposed framework can avoid the curse of dimensionality problem, and allow us to extract effective patterns from the whole-brain fMRI data. Furthermore, it reveals a new perspective for analyzing complex fMRI data with a large numbers of voxels, through compressing the number of parameters in a neural network. Experimental results confirmed that our proposed classification framework based on TensorNet outperforms traditional methods based on an SVM classifier for multi-class fMRI data.","","","10.1109/ACCESS.2018.2815770","Shandong University; Shandong Province; Shandong Province; Natural Science Foundation of Shandong Province; Shandong Province; Ministry of Education and Science of the Russian Federation; Polish National Science Center; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8319500","Tensor neural network;tensor train;medical image analysis;feature selection/exaction;deep learning;fMRI","Tensile stress;Functional magnetic resonance imaging;Feature extraction;Biological neural networks;Data mining;Machine learning;Principal component analysis","biomedical MRI;brain;feature extraction;feature selection;image classification;medical image processing;neural nets;neurophysiology;tensors","tensor neural network;functional magnetic resonance imaging;brain mapping research;brain matter;whole-brain fMRI data;dimensionality problem;classification performance;shallow neural network;complex fMRI data;multiclass fMRI data;feature extraction methods;feature selection;whole brain fMRI pattern analysis;machine learning techniques;TensorNet;tensor train model;network weight parameters","","3","34","","","","","IEEE","IEEE Journals"
"Spoofing Detection in Automatic Speaker Verification Systems Using DNN Classifiers and Dynamic Acoustic Features","H. Yu; Z. Tan; Z. Ma; R. Martin; J. Guo","Pattern Recognition and Intelligent System Laboratory, School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China; Department of Electronic Systems, Aalborg University, Aalborg, Denmark; Pattern Recognition and Intelligent System Laboratory, School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China; Institute of Communication Acoustics, Ruhr-Universität, Bochum, Germany; Pattern Recognition and Intelligent System Laboratory, School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","10","4633","4644","With the development of speech synthesis technology, automatic speaker verification (ASV) systems have encountered the serious challenge of spoofing attacks. In order to improve the security of ASV systems, many antispoofing countermeasures have been developed. In the front-end domain, much research has been conducted on finding effective features which can distinguish spoofed speech from genuine speech and the published results show that dynamic acoustic features work more effectively than static ones. In the back-end domain, Gaussian mixture model (GMM) and deep neural networks (DNNs) are the two most popular types of classifiers used for spoofing detection. The log-likelihood ratios (LLRs) generated by the difference of human and spoofing log-likelihoods are used as spoofing detection scores. In this paper, we train a five-layer DNN spoofing detection classifier using dynamic acoustic features and propose a novel, simple scoring method only using human log-likelihoods (HLLs) for spoofing detection. We mathematically prove that the new HLL scoring method is more suitable for the spoofing detection task than the classical LLR scoring method, especially when the spoofing speech is very similar to the human speech. We extensively investigate the performance of five different dynamic filter bank-based cepstral features and constant Q cepstral coefficients (CQCC) in conjunction with the DNN-HLL method. The experimental results show that, compared to the GMM-LLR method, the DNN-HLL method is able to significantly improve the spoofing detection accuracy. Compared with the CQCC-based GMM-LLR baseline, the proposed DNN-HLL model reduces the average equal error rate of all attack types to 0.045%, thus exceeding the performance of previously published approaches for the ASVspoof 2015 Challenge task. Fusing the CQCC-based DNN-HLL spoofing detection system with ASV systems, the false acceptance rate on spoofing attacks can be reduced significantly.","","","10.1109/TNNLS.2017.2771947","National Natural Science Foundation of China; Beijing National Science Foundation; Beijing Nova Program; Chinese 111 program of Advanced Intelligence, OCTAVE-Objective Control for TAlker VErification; European Commission; German Science Foundation within the framework of the Research Unit FOR2457 “Acoustic Sensor Networks.”; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8128906","Constant Q cepstral coefficients (CQCC);deep neural networks (DNNs) classifier;human log-likelihood (HLL);log-likelihood ratios (LLRs);speaker verification;spoofing detection","Feature extraction;Speech;Mel frequency cepstral coefficient;Time-frequency analysis","cepstral analysis;channel bank filters;Gaussian processes;neural nets;pattern classification;security of data;speaker recognition;speech synthesis","dynamic acoustic features;speech synthesis technology;automatic speaker verification systems;deep neural networks;log-likelihood ratios;human log-likelihoods;spoofing log-likelihoods;spoofing detection scores;HLL scoring method;spoofing detection task;DNN-HLL method;GMM-LLR method;CQCC-based GMM-LLR baseline;CQCC-based DNN-HLL spoofing detection system;DNN classifiers;Gaussian mixture model;GMM;DNNs;LLR scoring method;dynamic filter bank-based cepstral features;constant q cepstral coefficients;asv systems","","14","48","","","","","IEEE","IEEE Journals"
"Support vector machine approach to fall recognition based on simplified expression of human skeleton action and fast detection of start key frame using torso angle","W. Min; L. Yao; Z. Lin; L. Liu","School of Information Engineering, Nanchang University, People's Republic of China; School of Information Engineering, Nanchang University, People's Republic of China; School of Information Engineering, Nanchang University, People's Republic of China; School of Information Engineering, Nanchang University, People's Republic of China","IET Computer Vision","","2018","12","8","1133","1140","Falls sustained by subjects can have severe consequences, especially for elderly persons living alone. A fall detection method for indoor environments based on the Kinect sensor and analysis of three-dimensional skeleton joints information is proposed. Compared with state-of-the-art methods, the authors' method provides two major improvements. First, possible fall activity is quantified and represented by a one-dimensional float array with only 32 items, followed by fall recognition using a support vector machine (SVM). Unlike typical deep learning methods, the input parameters of their method are dramatically reduced. Hence, videos are trained and recognised by an SVM with a low time cost. Second, the torso angle is imported to detect the start key frame of a possible fall, which is much more efficient than using a sliding window. Their approach is evaluated on the telecommunication systems team (TST) fall detection dataset v2. The results show that their approach achieves an accuracy of 92.05%, better than other typical methods. According to the characters of machine learning, when more samples are imported, their method is expected to achieve a higher accuracy and stronger capability of fall-like discrimination. It can be used in real-time video surveillance because of its time efficiency and robustness.","","","10.1049/iet-cvi.2018.5324","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8555960","","","geriatrics;image recognition;image sensors;learning (artificial intelligence);object detection;support vector machines;video signal processing;video surveillance","support vector machine approach;fall recognition;human skeleton action;start key frame fast detection;torso angle;elderly persons;fall detection method;indoor environments;Kinect sensor;three-dimensional skeleton joint information analysis;one-dimensional float array;SVM;deep learning methods;low time cost;sliding window;TST fall detection dataset v2;machine learning;fall-like discrimination;real-time video surveillance","","1","30","","","","","IET","IET Journals"
"Structure-Preserving Guided Retinal Image Filtering and Its Application for Optic Disk Analysis","J. Cheng; Z. Li; Z. Gu; H. Fu; D. W. K. Wong; J. Liu","Cixi Institute of Biomedical Engineering, Chinese Academy of Sciences, Ningbo, China; Institute for Infocomm Research, Agency for Science, Technology and Research, Singapore; Cixi Institute of Biomedical Engineering, Chinese Academy of Sciences, Ningbo, China; Ocular Imaging (iMED) Department, Institute for Infocomm Research, Agency for Science, Technology and Research, Singapore; Ocular Imaging (iMED) Department, Institute for Infocomm Research, Agency for Science, Technology and Research, Singapore; Cixi Institute of Biomedical Engineering, Chinese Academy of Sciences, Ningbo, China","IEEE Transactions on Medical Imaging","","2018","37","11","2536","2546","Retinal fundus photographs have been used in the diagnosis of many ocular diseases such as glaucoma, pathological myopia, age-related macular degeneration, and diabetic retinopathy. With the development of computer science, computer aided diagnosis has been developed to process and analyze the retinal images automatically. One of the challenges in the analysis is that the quality of the retinal image is often degraded. For example, a cataract in human lens will attenuate the retinal image, just as a cloudy camera lens which reduces the quality of a photograph. It often obscures the details in the retinal images and posts challenges in retinal image processing and analyzing tasks. In this paper, we approximate the degradation of the retinal images as a combination of human-lens attenuation and scattering. A novel structure-preserving guided retinal image filtering (SGRIF) is then proposed to restore images based on the attenuation and scattering model. The proposed SGRIF consists of a step of global structure transferring and a step of global edge-preserving smoothing. Our results show that the proposed SGRIF method is able to improve the contrast of retinal images, measured by histogram flatness measure, histogram spread, and variability of local luminosity. In addition, we further explored the benefits of SGRIF for subsequent retinal image processing and analyzing tasks. In the two applications of deep learning-based optic cup segmentation and sparse learning-based cup-to-disk ratio (CDR) computation, our results show that we are able to achieve more accurate optic cup segmentation and CDR measurements from images processed by SGRIF.","","","10.1109/TMI.2018.2838550","Chinese Academy of Sciences; Ningbo 3315 Innovation Team; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8361495","Retinal image processing;segmentation;computer aided diagnosis","Retina;Optical imaging;Optical scattering;Image segmentation;Biomedical optical imaging;Optical attenuators;Lenses","biomedical optical imaging;diseases;eye;image colour analysis;image segmentation;learning (artificial intelligence);medical image processing;vision defects","retinal image filtering;retinal fundus photographs;subsequent retinal image processing;structure-preserving guided retinal image filtering;optic disk analysis;SGRIF method;global structure transferring;histogram flatness measure;histogram spread;local luminosity variability;deep learning-based optic cup segmentation;sparse learning-based cup-to-disk ratio computation;images processing","","","46","","","","","IEEE","IEEE Journals"
"Face Feature Extraction: A Complete Review","H. Wang; J. Hu; W. Deng","Beijing University of Posts and Telecommunications, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China","IEEE Access","","2018","6","","6001","6039","Feature extraction is vital for face recognition. In this paper, we focus on the general feature extraction framework for robust face recognition. We collect about 300 papers regarding face feature extraction. While some works apply handcrafted features, other works employ statistical learning methods. We believe that a general framework for face feature extraction consists of four major components: filtering, encoding, spatial pooling, and holistic representation. We analyze each component in detail. Each component could be applied in a task with multiple levels. Then, we provide a brief review of deep learning networks, which can be seen as a hierarchical extension of the framework above. Finally, we provide a detailed performance comparison of various features on LFW and FERET face database.","","","10.1109/ACCESS.2017.2784842","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8225635","Face recognition;feature extraction;filtering;feature encoding;feature aggregation","Feature extraction;Face recognition;Face;Histograms;Robustness;Encoding;Quantization (signal)","face recognition;feature extraction;image filtering;image representation;learning (artificial intelligence);statistical analysis","face feature extraction;statistical learning methods;deep learning networks;holistic representation;spatial pooling;encoding;filtering;feature extraction framework;face recognition","","2","293","","","","","IEEE","IEEE Journals"
"GDMN: Group Decision-Making Network for Person Re-Identification","Y. Liu; H. Sheng; Y. Zheng; N. Chen; W. Ke; Z. Xiong","State Key Laboratory of Software Development Environment, School of Computer Science and Engineering, Beihang University, Beijing, China; State Key Laboratory of Software Development Environment, School of Computer Science and Engineering, Beihang University, Beijing, China; State Key Laboratory of Software Development Environment, School of Computer Science and Engineering, Beihang University, Beijing, China; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, China; School of Public Administration, Macao Polytechnic Institute, Macau, China; State Key Laboratory of Software Development Environment, School of Computer Science and Engineering, Beihang University, Beijing, China","IEEE Access","","2018","6","","64169","64181","Person re-identification (re-ID) is a widely studied yet still challenging problem in computer vision. It aims to match images of the same pedestrian captured from different cameras. Recently, deep learning has been widely used for feature extraction and distance metric learning in re-ID. However, most of them only consider a certain aspect of the input data and thus will make certain mistakes during the testing process. In this paper, group decision-making (GDM) theory is introduced for comprehensive decision. Furthermore, a novel GDM network (GDMN) is proposed which consists of two sub-networks. First, proposal generation network can generate proposals based on baseline networks for the following decisionmaking process. Then, decision evaluation network evaluates all the proposals and makes the comprehensive decision. The proposed GDMN can analyze the merits and drawbacks of existing methods and make a better decision. The experimental results on public re-ID benchmarks show that our approach significantly improves the performance of the baseline methods and achieves competitive results compared with other state-of-the-art methods.","","","10.1109/ACCESS.2018.2877841","National Key Research and Development Program of China; National Natural Science Foundation of China; Macao Science and Technology Development Fund; Open Fund of the State Key Laboratory of Software Development Environment; Project of Experimental Verification of the Basic Commonness and Key Technical Standards of the Industrial Internet Network Architecture; Technology Innovation Fund of China Electronic Technology Group Corporation; HAWKEYE Group; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8506353","Convolutional neural networks;group decision-making;person re-identification","Decision making;Measurement;Feature extraction;Image color analysis;Bagging;Laboratories","computer vision;convolutional neural nets;decision making;feature extraction;image matching;learning (artificial intelligence)","GDMN;group decision-making network;person re-identification;computer vision;deep learning;feature extraction;distance metric learning;group decision-making theory;proposal generation network;decision evaluation network;decision making process;GDM network;image matching;convolutional neural network","","2","66","","","","","IEEE","IEEE Journals"
"Mixed Neural Network Approach for Temporal Sleep Stage Classification","H. Dong; A. Supratak; W. Pan; C. Wu; P. M. Matthews; Y. Guo","Department of Computing, Imperial College London, London, U.K.; Department of Computing, Imperial College London, London, U.K.; Department of Computing, Imperial College London, London, U.K.; Department of Computing, Imperial College London, London, U.K.; Department of Medicine, Division of Brain Sciences, Imperial College London, London, U.K.; Department of Computing, Imperial College London, London, U.K.","IEEE Transactions on Neural Systems and Rehabilitation Engineering","","2018","26","2","324","333","This paper proposes a practical approach to addressing limitations posed by using of single-channel electroencephalography (EEG) for sleep stage classification. EEG-based characterizations of sleep stage progression contribute the diagnosis and monitoring of the many pathologies of sleep. Several prior reports explored ways of automating the analysis of sleep EEG and of reducing the complexity of the data needed for reliable discrimination of sleep stages at lower cost in the home. However, these reports have involved recordings from electrodes placed on the cranial vertex or occiput, which are both uncomfortable and difficult to position. Previous studies of sleep stage scoring that used only frontal electrodes with a hierarchical decision tree motivated this paper, in which we have taken advantage of rectifier neural network for detecting hierarchical features and long short-term memory network for sequential data learning to optimize classification performance with single-channel recordings. After exploring alternative electrode placements, we found a comfortable configuration of a single-channel EEG on the forehead and have shown that it can be integrated with additional electrodes for simultaneous recording of the electro-oculogram. Evaluation of data from 62 people (with 494 hours sleep) demonstrated better performance of our analytical algorithm than is available from existing approaches with vertex or occipital electrode placements. Use of this recording configuration with neural network deconvolution promises to make clinically indicated home sleep studies practical.","","","10.1109/TNSRE.2017.2733220","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7995122","Sleep stage classification;electroencephalography;EEG signal;deep learning;long short-term memory","Sleep;Electroencephalography;Electrodes;Feature extraction;Electrooculography;Standards","biomedical electrodes;decision trees;electroencephalography;medical signal processing;neural nets;neurophysiology;patient monitoring;signal classification;sleep","single-channel EEG;home sleep studies;decision tree;sleep stage classification;neural network deconvolution;short-term memory network;rectifier neural network;frontal electrodes;cranial vertex;sleep EEG;sleep stage progression;single-channel electroencephalography;mixed neural network approach;time 494.0 hour","Algorithms;Electrodes;Electroencephalography;Electrooculography;Equipment Design;Forehead;Humans;Machine Learning;Memory, Short-Term;Neural Networks (Computer);Reference Standards;Reproducibility of Results;Sleep Stages","18","36","","","","","IEEE","IEEE Journals"
"An Accurate and Efficient Device-Free Localization Approach Based on Sparse Coding in Subspace","H. Huang; H. Zhao; X. Li; S. Ding; L. Zhao; Z. Li","School of Computer Science and Engineering, The University of Aizu, Aizuwakamatsu, Japan; School of Computer Science and Engineering, The University of Aizu, Aizuwakamatsu, Japan; School of Computer Science and Engineering, The University of Aizu, Aizuwakamatsu, Japan; School of Computer Science and Engineering, The University of Aizu, Aizuwakamatsu, Japan; School of Computer Science and Engineering, The University of Aizu, Aizuwakamatsu, Japan; School of Automation, Guangdong Key Laboratory of IoT Information Technology, Guangdong University of Technology, Guangzhou, China","IEEE Access","","2018","6","","61782","61799","In practical device-free localization (DFL) applications, for enlarging the monitoring area and improving localization accuracy, too many nodes need to be deployed, which results in a large volume of DFL data with high dimensions. This arises a key problem of seeking an accurate and efficient approach for DFL. In order to address this problem, this paper regards DFL as a problem of sparse-representation-based classification; builds a sparse model; and then proposes two sparse-coding-based algorithms. The first algorithm, sparse coding via the iterative shrinkage-thresholding algorithm (SC-ISTA), is efficient for handling high-dimensional data. And then, subspace techniques are further utilized, followed by performing sparse coding in the low-dimensional signal subspace, which leads to the second algorithm termed subspace-based SC-ISTA (SSC-ISTA). Experiments with the real-world data set are conducted for single-target and multi-target localization, and three typical machine learning algorithms, deep learning based on auto encoder, K-nearest neighbor, and orthogonal matching pursuit, are compared. Experimental results show that both SC-ISTA and SSC-ISTA can achieve high localization accuracies of 100% and are robust to noisy data when SNR is greater than 10 dB, and the time costs for sparse coding of SC-ISTA and SSC-ISTA are 2.1 × 10-3 s and 2.1 × 10-4 s respectively, which indicates that the proposed algorithms outperform the other three ones.","","","10.1109/ACCESS.2018.2876034","Japan Society for the Promotion of Science; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8496740","Device-free localization;wireless sensor networks;multi-targets;sparse coding;subspace;iterative shrinkage-thresholding algorithm","Encoding;Matching pursuit algorithms;Monitoring;Wireless sensor networks;Target tracking;Wireless communication;Iterative algorithms","encoding;iterative methods;learning (artificial intelligence);nearest neighbour methods;neural nets;signal classification;telecommunication computing;wireless sensor networks","SSC-ISTA;sparse coding;sparse-representation-based classification;sparse model;iterative shrinkage-thresholding algorithm;subspace techniques;wireless sensor networks;orthogonal matching pursuit;K-nearest neighbor;deep learning;machine learning;DFL;device-free localization;multitarget localization","","7","54","","","","","IEEE","IEEE Journals"
"Greedy Annotation of Remote Sensing Image Scenes Based on Automatic Aggregation via Hierarchical Similarity Diffusion","Y. Li; D. Ye","School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China","IEEE Access","","2018","6","","57376","57388","As a basic and key problem in the remote sensing community, remote sensing image scene understanding (RSISU) has attracted increasing research interest. In recent years, deep learning has revolutionized RSISU. However, the great success of deep learning strongly depends on the availability of a largescale data set with explicit labels. Although remote sensing image scene data sets have been publicly released for a limited number of remote sensing image types, data sets of many types of remote sensing images are still not available, which limits the applicability of deep learning. Generally, exhaustively labeling remote sensing image scene data sets via manual labor is time consuming, and it becomes impossible when the data set volume is very large. Hence, it is necessary to develop an intelligent annotation approach to efficiently and accurately label these data sets. Based on a prior assumption of consistency, namely, the assumption that samples within the same cluster are likely to have the same label, this paper proposes a novel annotation method for remote sensing image scene data sets called automatic aggregation via hierarchical similarity diffusion (AA-HSD). More specifically, each remote sensing image scene is represented by multiple features. To make full use of these complementary features, this paper proposes a new hierarchical similarity diffusion method for robustly measuring the similarity matrix of the scenes in the data set. Based on this similarity matrix, the scenes are automatically aggregated into clusters. Instead of annotating the data set scene by scene, as in the traditional manual annotation solution, we annotate the data set cluster by cluster, which dramatically increases the annotation speed while achieving a very high accuracy. Extensive experiments on two public remote sensing image scene data sets demonstrate the validity of our proposed AA-HSD method, which outperforms all competing baselines.","","","10.1109/ACCESS.2018.2873761","National Natural Science Foundation of China; China Postdoctoral Science Foundation; Natural Science Foundation of Hubei Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8481337","Remote sensing image scene understanding (RSISU);efficient and accurate image scene dataset annotation;automatic aggregation;hierarchical similarity diffusion","Remote sensing;Feature extraction;Manuals;Diffusion processes;Computational modeling;Task analysis","feature extraction;geophysical image processing;image classification;image representation;image segmentation;learning (artificial intelligence);object detection;remote sensing","AA-HSD method;remote sensing image scene understanding;public remote sensing image scene data sets;data set cluster;remote sensing image types;deep learning;remote sensing community;hierarchical similarity diffusion;data set volume;RSISU;greedy annotation;automatic aggregation","","3","60","","","","","IEEE","IEEE Journals"
"Sparsing Deep Neural Network Using Semi-Discrete Matrix Decomposition","X. Fu; P. Zuo; J. Zhai; R. Wang; H. Yang; D. Qian","School of Computer Science and Engineering, Beihang University, Beijing, China; School of Computer Science and Engineering, Beihang University, Beijing, China; Information Engineering Institute, Communication University of China, Beijing, China; School of Computer Science and Engineering, Beihang University, Beijing, China; School of Computer Science and Engineering, Beihang University, Beijing, China; School of Computer Science and Engineering, Beihang University, Beijing, China","IEEE Access","","2018","6","","58673","58681","Deep learning has gained a lot of successes in various areas, including computer vision, natural language process, and robot control. Convolution neural network (CNN) is the most commonly used model in deep neural networks. Despite their effectiveness on feature abstraction, CNNs need powerful computation even in the inference stage, which becomes a major obstacle in their deployment in embedded and mobile devices. In order to solve this problem, we 1) propose to make decomposition on convolution layers and full connected layers in CNNs with naïve semi-discrete matrix decomposition (SDD), which achieves the low-rank decomposition and parameters sparse at the same time; and 2) we propose a layer-merging scheme which merges two out of all the three result matrices, which can avoid the explode of the intermediate data come with the naïve semi-discrete matrix decomposition; 3) we propose a progressive training strategy to speed up the converging. We implement this optimized method in image classification and object detection networks. Under the loss of network accuracy by 1%, we achieve significant running time and model size reduction. The full-connected layer of the LeNet network achieves$7\times $speedup in the inference stage. In the Faster-Rcnn, the weight parameters are reduced by the factor of$5.85\times $, and it can have a speedup by the factor of$1.75\times $.","","","10.1109/ACCESS.2018.2872560","National Key R&D Program of China; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8478113","Deep neural network;sparsity;matrix decomposition;memory footprints","Convolution;Matrix decomposition;Kernel;Biological neural networks;Sparse matrices;Solid modeling","","","","","18","","","","","IEEE","IEEE Journals"
"Global Temporal Representation Based CNNs for Infrared Action Recognition","Y. Liu; Z. Lu; J. Li; T. Yang; C. Yao","School of Telecommunications Engineering, Xidian University, Xi’an, China; School of Telecommunications Engineering, Xidian University, Xi’an, China; School of Telecommunications Engineering, Xidian University, Xi’an, China; SAIIP, School of Computer Science, Northwestern Polytechnical University, Xi’an, China; School of Automation, Northwestern Polytechnical University, Xi’an, China","IEEE Signal Processing Letters","","2018","25","6","848","852","Infrared human action recognition has many advantages, i.e., it is insensitive to illumination change, appearance variability, and shadows. Existing methods for infrared action recognition are either based on spatial or local temporal information, however, the global temporal information, which can better describe the movements of body parts across the whole video, is not considered. In this letter, we propose a novel global temporal representation named optical-flow stacked difference image (OFSDI) and extract robust and discriminative feature from the infrared action data by considering the local, global, and spatial temporal information together. Due to the small size of the infrared action dataset, we first apply convolutional neural networks on local, spatial, and global temporal stream respectively to obtain efficient convolutional feature maps from the raw data rather than train a classifier directly. Then these convolutional feature maps are aggregated into effective descriptors named three-stream trajectory-pooled deep-convolutional descriptors by trajectory-constrained pooling. Furthermore, we improve the robustness of these features by using the locality-constrained linear coding (LLC) method. With these features, a linear support vector machine (SVM) is adopted to classify the action data in our scheme. We conduct the experiments on infrared action recognition datasets InfAR and NTU RGB+D. The experimental results show that the proposed approach outperforms the representative state-of-the-art handcrafted features and deep learning features based methods for the infrared action recognition.","","","10.1109/LSP.2018.2823910","China Postdoctoral Science Foundation funded project; Fundamental Research Funds for the Central Universities; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8332532","Convolutional neural networks (CNN);deep learning;global temporal information;infrared action recognition","Optical imaging;Feature extraction;Streaming media;Machine learning;Optical signal processing;Computer architecture;Trajectory","convolution;feature extraction;feedforward neural nets;image classification;image motion analysis;image representation;image sequences;infrared imaging;support vector machines","robust feature extraction;discriminative feature extraction;global temporal representation;linear support vector machine;locality-constrained linear coding;CNNs;optical-flow stacked difference image;action data classification;convolutional feature maps;infrared action dataset;global temporal information;local temporal information;spatial information;infrared human action recognition","","1","29","","","","","IEEE","IEEE Journals"
"Focal Onset Seizure Prediction Using Convolutional Networks","H. Khan; L. Marcuse; M. Fields; K. Swann; B. Yener","Department of Computer Science, Rensselaer Polytechnic Institute, Troy, NY, USA; Mount Sinai Epilepsy CenterMount Sinai Hospital; Mount Sinai Epilepsy CenterMount Sinai Hospital; Department of Computer ScienceRensselaer Polytechnic Institute; Department of Computer ScienceRensselaer Polytechnic Institute","IEEE Transactions on Biomedical Engineering","","2018","65","9","2109","2118","Objective: This paper investigates the hypothesis that focal seizures can be predicted using scalp electroencephalogram (EEG) data. Our first aim is to learn features that distinguish between the interictal and preictal regions. The second aim is to define a prediction horizon in which the prediction is as accurate and as early as possible, clearly two competing objectives. Methods: Convolutional filters on the wavelet transformation of the EEG signal are used to define and learn quantitative signatures for each period: interictal, preictal, and ictal. The optimal seizure prediction horizon is also learned from the data as opposed to making an a priori assumption. Results: Computational solutions to the optimization problem indicate a 10-min seizure prediction horizon. This result is verified by measuring Kullback-Leibler divergence on the distributions of the automatically extracted features. Conclusion: The results on the EEG database of 204 recordings demonstrate that (i) the preictal phase transition occurs approximately ten minutes before seizure onset, and (ii) the prediction results on the test set are promising, with a sensitivity of 87.8% and a low false prediction rate of 0.142 FP/h. Our results significantly outperform a random predictor and other seizure prediction algorithms. Significance: We demonstrate that a robust set of features can be learned from scalp EEG that characterize the preictal state of focal seizures.","","","10.1109/TBME.2017.2785401","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239676","Automatic feature extraction;convolutional neural networks;deep learning;focal seizures;preictal period;scalp EEG;seizure prediction","Electroencephalography;Feature extraction;Scalp;Wavelet transforms;Brain modeling;Tensile stress;Convolution","diseases;electroencephalography;feature extraction;learning (artificial intelligence);medical signal processing;neurophysiology;wavelet transforms","convolutional networks;interictal regions;convolutional filters;EEG data;EEG signal;EEG database;wavelet transformation;preictal regions;scalp electroencephalogram data;focal onset seizure prediction;focal seizures;preictal state;seizure prediction algorithms;preictal phase transition;Kullback-Leibler divergence;optimization problem;optimal seizure prediction horizon","","5","51","","","","","IEEE","IEEE Journals"
"Deep Contextual Stroke Pooling for Scene Character Recognition","Z. Zhang; H. Wang; S. Liu; B. Xiao","Tianjin Key Laboratory of Wireless Mobile Communications and Power Transmission, Tianjin Normal University, Tianjin, China; Tianjin Key Laboratory of Wireless Mobile Communications and Power Transmission, Tianjin Normal University, Tianjin, China; Tianjin Key Laboratory of Wireless Mobile Communications and Power Transmission, Tianjin Normal University, Tianjin, China; State Key Laboratory of Management and Intelligent Control of Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China","IEEE Access","","2018","6","","16454","16463","Characters, as a kind of symbols carrying rich semantic information, are composed of strokes arranged in a certain structure and are of great significance in our daily life. In this paper, we are concerned with the problem of scene character recognition, and study the problem from the perspective of feature representation. We propose a novel pooling method termed deep contextual stroke pooling (DCSP) for scene character recognition. The proposed DCSP discovers the most prominent stroke information by using stroke detectors and captures the spatial context of discriminative strokes by learning contextual factor. Specifically, we first utilize the convolutional summing map in one convolutional layer to select discriminative strokes and use the convolutional activation features of discriminative strokes to train stroke detectors. Then, we propose the contextual factor to represent the co-occurrence probability of the stroke and its location. Finally, in the response regions, we incorporate the contextual factor into the detector scores and obtain the deep contextual confidence vectors of scene characters. Extensive experiments are conducted on three databases, i.e., ICDAR2003, Chars74k, and SVHN, and the experimental results demonstrate that our method achieves higher accuracies than the state-of-the-art methods.","","","10.1109/ACCESS.2018.2817342","National Natural Science Foundation of China; Natural Science Foundation of Tianjin; Open Projects Program of the National Laboratory of Pattern Recognition; China Scholarship Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8319969","Scene character recognition;deep contextual stroke pooling;contextual factor","Character recognition;Text recognition;Feature extraction;Detectors;Training;Optical character recognition software;Histograms","","","","4","35","","","","","IEEE","IEEE Journals"
"Intraspectrum Discrimination and Interspectrum Correlation Analysis Deep Network for Multispectral Face Recognition","F. Wu; X. Jing; X. Dong; R. Hu; D. Yue; L. Wang; Y. Ji; R. Wang; G. Chen","College of Automation, Nanjing University of Posts and Telecommunications, Nanjing 210003, China.; School of Computer, Wuhan University, Wuhan 430072, China, and also with the College of Automation, Nanjing University of Posts and Telecommunications, Nanjing 210003, China (e-mail: jingxy_2000@126.com).; College of Automation, Nanjing University of Posts and Telecommunications, Nanjing 210003, China.; School of Computer, Wuhan University, Wuhan 430072, China.; College of Automation, Nanjing University of Posts and Telecommunications, Nanjing 210003, China.; School of Computer, Wuhan University, Wuhan 430072, China.; College of Computer, Nanjing University of Posts and Telecommunications, Nanjing 210003, China.; College of Computer, Nanjing University of Posts and Telecommunications, Nanjing 210003, China.; College of Computer, Nanjing University of Posts and Telecommunications, Nanjing 210003, China.","IEEE Transactions on Cybernetics","","2018","PP","99","1","14","Multispectral images contain rich recognition information since the multispectral camera can reveal information that is not visible to the human eye or to the conventional RGB camera. Due to this characteristic of multispectral images, multispectral face recognition has attracted lots of research interest. Although some multispectral face recognition methods have been presented in the last decade, how to fully and effectively explore the intraspectrum discriminant information and the useful interspectrum correlation information in multispectral face images for recognition has not been well studied. To boost the performance of multispectral face recognition, we propose an intraspectrum discrimination and interspectrum correlation analysis deep network (IDICN) approach. Multiple spectra are divided into several spectrum-sets, with each containing a group of spectra within a small spectral range. The IDICN network contains a set of spectrum-set-specific deep convolutional neural networks attempting to extract spectrum-set-specific features, followed by a spectrum pooling layer, whose target is to select a group of spectra with favorable discriminative abilities adaptively. IDICN jointly learns the nonlinear representations of the selected spectra, such that the intraspectrum Fisher loss and the interspectrum discriminant correlation are minimized. Experiments on the well-known Hong Kong Polytechnic University, Carnegie Mellon University, and the University of Western Australia multispectral face datasets demonstrate the superior performance of the proposed approach over several state-of-the-art methods.","","","10.1109/TCYB.2018.2876591","National Natural Science Foundation of China; National Post Doctoral Program for Innovative Talents; NSFC Key Project of General Technology Fundamental Research United Fund; National Key Research and Development Program of China; Natural Science Foundation of Jiangsu Province; Key Research and Development Program of Jiangsu Province; Natural Science Foundation Outstanding Youth Fund of Jiangsu Province; Natural Science Fund for Colleges and Universities in Jiangsu Province; Scientific Research Staring Foundation for Introduced Talents in NJUPT NUPTSF; 1311 Project of NJUPT; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8525134","Deep convolutional neural networks (DCNNs);intraspectrum discriminant information exploration;multispectral face recognition;spectra selection;useful interspectrum correlation information exploration","Face recognition;Feature extraction;Face;Correlation;Image recognition;Cameras;Focusing","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Text Recovery via Deep CNN-BiLSTM Recognition and Bayesian Inference","L. Jiao; H. Wu; H. Wang; R. Bie","College of Information Science and Technology, Beijing Normal University, Beijing, China; College of Information Science and Technology, Beijing Normal University, Beijing, China; College of Information Science and Technology, Beijing Normal University, Beijing, China; College of Information Science and Technology, Beijing Normal University, Beijing, China","IEEE Access","","2018","6","","76416","76428","Image inpainting is an essential process of semantically filling the missing holes in a corrupt image. However, concurrent methods cannot semantically recover some self-described objects, such as a text instance. In this paper, we focus on the recovery of a missing character in a detected corrupt text instance on an image and propose a procedure to semantically recover the text. Specifically, the corrupt text instance is first recognized with a pre-trained CNN-BiLSTM architecture and the missing character is inferred by the statistical Bayesian posterior probability. The horizontal coordinate of the missing character is estimated by the image histogram. The obtained candidate character and possible position enable the synthesis of the corrupt image and the latent character, and the text information, meanwhile, is semantically recovered. Experiments and corresponding results demonstrate that our procedure is able to predict the missing character and synthesize the images of the corrupt context and the candidate character; besides, it can be employed in the recovery of natural text images.","","","10.1109/ACCESS.2018.2882592","Fundamental Research Funds for the Central Universities; National Natural Science Foundation of China; BNU Graduate Students’ Platform for Innovation & Entrepreneurship Training Program; SRF for ROCS, SEM; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8542673","Computer vision;image inpainting;text recovery","Text recognition;Image restoration;Feature extraction;Bayes methods;Semantics;Art;Recurrent neural networks","Bayes methods;belief networks;convolutional neural nets;image restoration;image texture;inference mechanisms;learning (artificial intelligence);object detection;text detection","missing character;pre-trained CNN-BiLSTM architecture;statistical Bayesian posterior probability;image histogram;candidate character;corrupt image;latent character;text information;corrupt context;natural text images;text recovery;deep CNN-BiLSTM recognition;Bayesian inference;image inpainting;missing holes;corrupt text instance","","1","64","","","","","IEEE","IEEE Journals"
"Keyphrase Generation Based on Deep Seq2seq Model","Y. Zhang; W. Xiao","Science and Technology on Information System Engineering Laboratory, National University of Defense Technology, Changsha, China; Science and Technology on Information System Engineering Laboratory, National University of Defense Technology, Changsha, China","IEEE Access","","2018","6","","46047","46057","Keyphrase can provide highly summative information which can help us improve information utilization efficiency in the era of information overload. Though previous researches about keyphrase generation have provided some workable solutions, they generate keyphrase by ranking and selecting meaningful words from the source text. These approaches belong to an extractive method, by which they cannot effectively use semantic meaning of the source text, and are unable to generate keyphrases which do not appear in the source text. So we propose a sequence-to-sequence framework with attention mechanism, copy mechanism, and coverage mechanism, which can effectively deal with the above-mentioned drawbacks. The experimental results on five data sets reveal that our proposed model can achieve a better performance than the traditional extraction approaches and can also generate absent keyphrases which do not appear in the source text.","","","10.1109/ACCESS.2018.2865589","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8438457","Abstraction;seq2seq;attention mechanism;copy mechanism;coverage mechanism","Task analysis;Semantics;Decoding;Correlation;Logic gates;Recurrent neural networks;Machine learning algorithms","feature extraction;information retrieval;text analysis","deep seq2seq model;information utilization efficiency;information overload;keyphrase generation;sequence-to-sequence framework;attention mechanism;copy mechanism;coverage mechanism","","2","35","","","","","IEEE","IEEE Journals"
"High-Performance Mixed-Signal Neurocomputing With Nanoscale Floating-Gate Memory Cell Arrays","F. Merrikh-Bayat; X. Guo; M. Klachko; M. Prezioso; K. K. Likharev; D. B. Strukov","Electrical Engineering Department, University of California, Santa Barbara, CA, USA; Electrical Engineering Department, University of California, Santa Barbara, CA, USA; Electrical Engineering Department, University of California, Santa Barbara, CA, USA; Electrical Engineering Department, University of California, Santa Barbara, CA, USA; Department of Physics and Astronomy, Stony Brook University, Stony Brook, NY, USA; Electrical Engineering Department, University of California, Santa Barbara, CA, USA","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","10","4782","4790","Potential advantages of analog- and mixed-signal nanoelectronic circuits, based on floating-gate devices with adjustable conductance, for neuromorphic computing had been realized long time ago. However, practical realizations of this approach suffered from using rudimentary floating-gate cells of relatively large area. Here, we report a prototype 28 × 28 binary-input, ten-output, three-layer neuromorphic network based on arrays of highly optimized embedded nonvolatile floating-gate cells, redesigned from a commercial 180-nm nor flash memory. All active blocks of the circuit, including 101 780 floating-gate cells, have a total area below 1 mm2. The network has shown a 94.7% classification fidelity on the common Modified National Institute of Standards and Technology benchmark, close to the 96.2% obtained in simulation. The classification of one pattern takes a sub-1-μs time and a sub-20-nJ energy-both numbers much better than in the best reported digital implementations of the same task. Estimates show that a straightforward optimization of the hardware and its transfer to the already available 55nm technology may increase this advantage to more than 102× in speed and 104× in energy efficiency.","","","10.1109/TNNLS.2017.2778940","Defense Advanced Research Projects Agency; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8237202","Deep learning;floating-gate memory cells;multilayer perceptron;neuromorphic networks;pattern classification","Computer architecture;Neuromorphics;Microprocessors;Logic gates;Nonvolatile memory;Neurons;Benchmark testing","flash memories;nanoelectronics;neural chips;random-access storage","high-performance mixed-signal neurocomputing;nanoscale floating-gate memory cell arrays;mixed-signal nanoelectronic circuits;floating-gate devices;neuromorphic computing;three-layer neuromorphic network;highly optimized embedded nonvolatile floating-gate cells;nor flash memory;Modified National Institute of Standards and Technology benchmark;analog-signal nanoelectronic circuits;size 55.0 nm;size 180 nm","","10","33","","","","","IEEE","IEEE Journals"
"Deep Neural Networks for Exploration of Transcriptome of Adult Mouse Brain","Y. Li; H. Huang; H. Chen; T. Liu","Computer Science, the University of Georgia, Athens, GA Georgia (e-mail: lyj@uga.edu); School of Automation, Northwestern Polytechnical University, 26487 Xi'an, Shaanxi China (e-mail: hh07999@uga.edu); Computer Science, the University of Georgia, Athens, Georgia United States 30605 (e-mail: cojoc.chen@gmail.com); Computer Science, University of Georgia, Athens, Georgia United States (e-mail: tliu@cs.uga.edu)","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2018","PP","99","1","1","Transcriptome in brain plays a crucial role in understanding the cortical organization and the development of brain structure and function. Two challenges, the incomplete data and the high dimensionality of transcriptome, remain unsolved. Here we present a novel training scheme that successfully adapts the U-net architecture to the problem of volume recovery. By analogy to denoising autoencoder, we hide a portion of each training sample so that the network can learn to recover missing voxels from the context. Then on the completed volumes, we show that restricted Boltzmann Machines (RBMs) can be used to infer co-occurrences among voxels, providing foundations for dividing the cortex into discrete subregions. As we stack multiple RBMs to form a deep belief network (DBN), we progressively map the high-dimensional raw input into abstract representations and create a hierarchy of transcriptome architecture. A coarse to fine organization emerges from the network layers. This organization incidentally corresponds to the anatomical structures, suggesting a close link between structures and the genetic underpinnings. Thus, we demonstrate a new way of learning transcriptome-based hierarchical organization using RBM and DBN.","","","10.1109/TCBB.2018.2864262","Division of Information and Intelligent Systems; Division of Behavioral and Cognitive Sciences; Foundation for the National Institutes of Health; Division of Biological Infrastructure; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8428473","deep belief network;fully convolutional neural network;Restricted Boltzmann Machines;transcriptome architecture","Training;Brain;Neural networks;Organizations;Computer architecture;Measurement;Bioinformatics","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Ristretto: A Framework for Empirical Study of Resource-Efficient Inference in Convolutional Neural Networks","P. Gysel; J. Pimentel; M. Motamedi; S. Ghiasi","Electrical and Computer Engineering Department, Laboratory for Embedded and Programmable Systems, University of California at Davis, Davis, CA, USA; Electrical and Computer Engineering Department, VLSI Computation Laboratory, University of California at Davis, Davis, CA, USA; Electrical and Computer Engineering Department, Laboratory for Embedded and Programmable Systems, University of California at Davis, Davis, CA, USA; Electrical and Computer Engineering Department, Laboratory for Embedded and Programmable Systems, University of California at Davis, Davis, CA, USA","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","11","5784","5789","Convolutional neural networks (CNNs) have led to remarkable progress in a number of key pattern recognition tasks, such as visual scene understanding and speech recognition, that potentially enable numerous applications. Consequently, there is a significant need to deploy trained CNNs to resource-constrained embedded systems. Inference using pretrained modern deep CNNs, however, requires significant system resources, including computation, energy, and memory space. To enable efficient implementation of trained CNNs, a viable approach is to approximate the network with an implementation-friendly model with only negligible degradation in classification accuracy. We present Ristretto, a CNN approximation framework that enables empirical investigation of the tradeoff between various number representation and word width choices and the classification accuracy of the model. Specifically, Ristretto analyzes a given CNN with respect to numerical range required to represent weights, activations, and intermediate results of convolutional and fully connected layers, and subsequently, it simulates the impact of reduced word width or lower precision arithmetic operators on the model accuracy. Moreover, Ristretto can fine-tune a quantized network to further improve its classification accuracy under a given number representation and word width configuration. Given a maximum classification accuracy degradation tolerance of 1%, we use Ristretto to demonstrate that three ImageNet networks can be condensed to use 8-bit dynamic fixed point for network weights and activations. Ristretto is available as a popular open-source software project1 and has already been viewed over 1000 times on Github as of the submission of this brief.","","","10.1109/TNNLS.2018.2808319","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8318896","Arithmetic precision;convolutional neural network (CNN);efficient inference;number representation","Energy dissipation;Neural networks;Dynamic range;Embedded systems;Training;Quantization (signal);Learning systems","approximation theory;convolution;embedded systems;feedforward neural nets;image classification;inference mechanisms;mathematical operators;public domain software;speech recognition","resource-efficient inference;convolutional neural networks;speech recognition;embedded systems;CNN approximation framework;Ristretto analyzes;convolutional connected layers;quantized network;word width configuration;ImageNet networks;pattern recognition tasks;visual scene;deep CNNs;system resources;number representation;classification accuracy degradation tolerance;arithmetic operators;dynamic fixed point;open-source software project;Github","","16","18","","","","","IEEE","IEEE Journals"
"Learning Building Extraction in Aerial Scenes with Convolutional Networks","J. Yuan","Computational Sciences Engineering Division, Oak Ridge National Laboratory, Oak Ridge, TN","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","11","2793","2798","Extracting buildings from aerial scene images is an important task with many applications. However, this task is highly difficult to automate due to extremely large variations of building appearances, and still heavily relies on manual work. To attack this problem, we design a deep convolutional network with a simple structure that integrates activation from multiple layers for pixel-wise prediction, and introduce the signed distance function of building boundaries to represent output, which has an enhanced representation power. To train the network, we leverage abundant building footprint data from geographic information systems (GIS) to generate large amounts of labeled data. The trained model achieves a superior performance on datasets that are significantly larger and more complex than those used in prior work, demonstrating that the proposed method provides a promising and scalable solution for automating this labor-intensive task.","","","10.1109/TPAMI.2017.2750680","National Geospatial-Intelligence Agency; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8031068","Convolutional network;building extraction;GIS map;remote sensing","Buildings;Training;Interpolation;Convolution;Remote sensing;Image resolution;Feature extraction","feature extraction;geographic information systems;geophysical image processing;image segmentation;learning (artificial intelligence);neural nets","building extraction;aerial scenes;convolutional networks;aerial scene images;building appearances;deep convolutional network;pixel-wise prediction;signed distance function;enhanced representation power;geographic information systems","","6","23","","","","","IEEE","IEEE Journals"
"A Self-Adaptive Bell–LaPadula Model Based on Model Training With Historical Access Logs","Z. Tang; X. Ding; Y. Zhong; L. Yang; K. Li","College of Information Science and Engineering, Hunan University, Changsha, China; College of Information Science and Engineering, Hunan University, Changsha, China; College of Information Science and Engineering, Hunan University, Changsha, China; College of Computer and Communication Engineering, Changsha University of Science and Technology, Hunan, China; College of Information Science and Engineering, Hunan University, Changsha, China","IEEE Transactions on Information Forensics and Security","","2018","13","8","2047","2061","In currently popular access control models, the security policies and regulations never change in the running system process once they are identified, which makes it possible for attackers to find the vulnerabilities in a system, resulting in the lack of ability to perceive the system security status and risks in a dynamic manner and exposing the system to such risks. By introducing the maximum entropy (MaxENT) models into the rule optimization for the Bell-LaPadula (BLP) model, this paper proposes an improved BLP model with the self-learning function: MaxENT-BLP. This model first formalizes the security properties, system states, transformational rules, and a constraint model based on the states transition of the MaxENT. After handling the historical system access logs as the original data sets, this model extracts the user requests, current states, and decisions to act as the feature vectors. Second, we use k -fold cross validation to divide all vectors into a training set and a testing set. In this paper, the model training process is based on the Broyden-Fletcher-Goldfarb-Shanno algorithm. And this model contains a strategy update algorithm to adjust the access control rules dynamically according to the access and decision records in a system. Third, we prove that MaxENT-BLP is secure through theoretical analysis. By estimating the precision, recall, and F1-score, the experiments show the availability and accuracy of this model. Finally, this paper provides the process of model training based on deep learning and discussions regarding adversarial samples from the malware classifiers. We demonstrate that MaxENT-BLP is an appropriate choice and has the ability to help running information systems to avoid more risks and losses.","","","10.1109/TIFS.2018.2807793","National Natural Science Foundation of China; National Key Research and Development Program of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8295130","Adversarial sample;BLP;machine learning;mandatory access control;maximum entropy model;rule optimization","Hidden Markov models;Training;Access control;Data models;Feature extraction;Machine learning","authorisation;entropy;invasive software;learning (artificial intelligence);optimisation","historical access;security policies;regulations;running system process;system security status;maximum entropy models;rule optimization;improved BLP model;MaxENT-BLP;security properties;system states;transformational rules;constraint model;states transition;historical system access;training set;Broyden-Fletcher-Goldfarb-Shanno algorithm;access control rules;decision records;running information systems;training process;self-adaptive Bell-LaPadula model;access control models;precision;recall;F1-score","","","37","","","","","IEEE","IEEE Journals"
"QoE-driven big data management in pervasive edge computing environment","Q. Meng; K. Wang; X. He; M. Guo","Jiangsu Engineering Research Center of Communication and Network Technology, Nanjing University of Posts and Telecommunications, Nanjing 210003, China; Jiangsu High Technology Research Key Laboratory for Wireless Sensor Networks, Nanjing University of Posts and Telecommunications, Nanjing 210003, and the Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai 200240, China; Jiangsu Engineering Research Center of Communication and Network Technology, Nanjing University of Posts and Telecommunications, Nanjing 210003, China; Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai 200240, China","Big Data Mining and Analytics","","2018","1","3","222","233","In the age of big data, services in the pervasive edge environment are expected to offer end-users better Quality-of-Experience (QoE) than that in a normal edge environment. However, the combined impact of the storage, delivery, and sensors used in various types of edge devices in this environment is producing volumes of high-dimensional big data that are increasingly pervasive and redundant. Therefore, enhancing the QoE has become a major challenge in high-dimensional big data in the pervasive edge computing environment. In this paper, to achieve high QoE, we propose a QoE model for evaluating the qualities of services in the pervasive edge computing environment. The QoE is related to the accuracy of high-dimensional big data and the transmission rate of this accurate data. To realize high accuracy of high-dimensional big data and the transmission of accurate data through out the pervasive edge computing environment, in this study we focused on the following two aspects. First, we formulate the issue as a high-dimensional big data management problem and test different transmission rates to acquire the best QoE. Then, with respect to accuracy, we propose a Tensor-Fast Convolutional Neural Network (TF-CNN) algorithm based on deep learning, which is suitable for high-dimensional big data analysis in the pervasive edge computing environment. Our simulation results reveal that our proposed algorithm can achieve high QoE performance.","","","10.26599/BDMA.2018.9020020","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8361574","Quality-of-Experience (QoE); high-dimensional big data management; deep learning; pervasive edge","Big Data;Quality of experience;Edge computing;Quality of service;Computational modeling;Training;Streaming media","Big Data;feedforward neural nets;learning (artificial intelligence);ubiquitous computing","quality-of-experience;high-dimensional Big Data management problem;QoE-driven Big Data management;high-QoE performance;tensor-fast convolutional neural network;TF-CNN;normal edge environment;pervasive edge environment;pervasive edge computing environment","","","","","","","","TUP","TUP Journals"
"Spatio-Temporal Saliency Networks for Dynamic Saliency Prediction","C. Bak; A. Kocak; E. Erdem; A. Erdem","Department of Computer Engineering, Hacettepe University, Ankara, Turkey; Department of Computer Engineering, Hacettepe University, Ankara, Turkey; Department of Computer Engineering, Hacettepe University, Ankara, Turkey; Department of Computer Engineering, Hacettepe University, Ankara, Turkey","IEEE Transactions on Multimedia","","2018","20","7","1688","1698","Computational saliency models for still images have gained significant popularity in recent years. Saliency prediction from videos, on the other hand, has received relatively little interest from the community. Motivated by this, in this paper, we study the use of deep learning for dynamic saliency prediction and propose the so-called spatio-temporal saliency networks. The key to our models is the architecture of two-stream networks where we investigate different fusion mechanisms to integrate spatial and temporal information. We evaluate our models on the dynamic images and eye movements and University of Central Florida-Sports datasets and present highly competitive results against the existing state-of-the-art models. We also carry out some experiments on a number of still images from the MIT300 dataset by exploiting the optical flow maps predicted from these images. Our results show that considering inherent motion information in this way can be helpful for static saliency estimation.","","","10.1109/TMM.2017.2777665","TUBITAK Career Development Award; Hacettepe BAP; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8119879","Dynamic saliency;deep learning","Videos;Feature extraction;Predictive models;Computational modeling;Visualization;Dynamics","image motion analysis;learning (artificial intelligence)","dynamic images;static saliency estimation;spatio-temporal saliency networks;dynamic saliency prediction;computational saliency models;two-stream networks;spatial information;temporal information;University of Central Florida-Sports datasets;eye movements","","7","66","","","","","IEEE","IEEE Journals"
"Specific Emitter Identification via Convolutional Neural Networks","L. Ding; S. Wang; F. Wang; W. Zhang","School of Electronic Science and Engineering, National University of Defense Technology, Changsha, China; School of Electronic Science and Engineering, National University of Defense Technology, Changsha, China; State Key Laboratory of Rail Traffic Control and Safety, Beijing Jiaotong University, Beijing, China; School of Electronic Science and Engineering, National University of Defense Technology, Changsha, China","IEEE Communications Letters","","2018","22","12","2591","2594","Specific emitter identification (SEI) is a technique that distinguishes between unique emitters using the external feature measurements from their transmit signals, primarily radio frequency fingerprints. The SEI has been widely adopted for military and civilian spectrum management applications. We propose a deep-learning-based SEI approach that uses the features of the received steady-state signals. In particular, the bispectrum of the received signal is calculated as a unique feature. Then, we use a supervised dimensionality reduction method to significantly reduce the dimensions of the bispectrum. Finally, a convolutional neural network is adopted to identify specific emitters using the compressed bispectrum. This approach essentially extracts overall feature information hidden in the original signals, which can then be used to improve identification performance. Results from both the simulations and the software radio experiments are provided. A signal acquisition system is designed to collect steady-state signals from multiple universal software radio peripherals. Both the simulations and the experiments validate our conclusion that the proposed approach outperforms other existing schemes in the literature.","","","10.1109/LCOMM.2018.2871465","Fundamental Research Funds for the Central Universities; National Natural Science Foundation of China; Natural Science Foundation of Beijing Municipality; State Key Laboratory of Rail Traffic Control and Safety; Key Laboratory of Universal Wireless Communications (BUPT), Ministry of Education, P. R. China; Beijing Municipal Science and Technology Commission; National Key Research and Development Program; Nokia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8469100","Bispectrum;convolutional neural network;deep learning;specific emitter identification;USRP","Feature extraction;Identification;Convolutional neural networks;Steady-state;Transient analysis;Dimensionality reduction;Computational modeling","convolution;feature extraction;feedforward neural nets;learning (artificial intelligence);signal processing;software radio;spectral analysis;telecommunication computing","compressed bispectrum;feature information;signal acquisition system;steady-state signals;specific emitter identification;external feature measurements;transmit signals;radio frequency fingerprints;military spectrum management applications;civilian spectrum management applications;SEI approach;supervised dimensionality reduction method;convolutional neural networks;software radio peripherals","","5","20","","","","","IEEE","IEEE Journals"
"Predicting Visual Features From Text for Image and Video Caption Retrieval","J. Dong; X. Li; C. G. M. Snoek","College of Computer Science and Technology, Zhejiang University, Hangzhou, China; Key Lab of Data Engineering and Knowledge Engineering, School of Information, Renmin University of China, Beijing, China; Informatics Institute, University of Amsterdam, Amsterdam, XH, The Netherlands","IEEE Transactions on Multimedia","","2018","20","12","3377","3388","This paper strives to find amidst a set of sentences the one best describing the content of a given image or video. Different from existing works, which rely on a joint subspace for their image and video caption retrieval, we propose to do so in a visual space exclusively. Apart from this conceptual novelty, we contribute Word2VisualVec , a deep neural network architecture that learns to predict a visual feature representation from textual input. Example captions are encoded into a textual embedding based on multiscale sentence vectorization and further transferred into a deep visual feature of choice via a simple multilayer perceptron. We further generalize Word2VisualVec for video caption retrieval, by predicting from text both three-dimensional convolutional neural network features as well as a visual-audio representation. Experiments on Flickr8k, Flickr30k, the Microsoft Video Description dataset, and the very recent NIST TrecVid challenge for video caption retrieval detail Word2VisualVec's properties, its benefit over textual embeddings, the potential for multimodal query composition, and its state-of-the-art results.","","","10.1109/TMM.2018.2832602","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; Research Funds of Renmin University of China; STW STORY project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8353472","Image and video caption retrieval","Visualization;Feature extraction;Natural languages;Convolutional neural networks;Machine learning;Encoding","convolution;feature extraction;image annotation;image representation;learning (artificial intelligence);multilayer perceptrons;text analysis;video retrieval;video signal processing","video caption retrieval;visual space;deep neural network architecture;visual feature representation;textual embedding;three-dimensional convolutional neural network features;visual-audio representation;Microsoft Video Description dataset;NIST TrecVid;multilayer perceptron;multimodal query composition;Word2VisualVecs properties","","6","72","","","","","IEEE","IEEE Journals"
"CNNs-Based RGB-D Saliency Detection via Cross-View Transfer and Multiview Fusion","J. Han; H. Chen; N. Liu; C. Yan; X. Li","School of Automation, Northwestern Polytechnical University, Xi’an, China; School of Automation, Northwestern Polytechnical University, Xi’an, China; School of Automation, Northwestern Polytechnical University, Xi’an, China; Institute of Information and Control, Hangzhou Dianzi University, Hangzhou, China; Center for Optical Imagery Analysis and Learning, State Key Laboratory of Transient Optics and Photonics, Xi’an Institute of Optics and Precision Mechanics, Chinese Academy of Sciences, Xi’an, China","IEEE Transactions on Cybernetics","","2018","48","11","3171","3183","Salient object detection from RGB-D images aims to utilize both the depth view and RGB view to automatically localize objects of human interest in the scene. Although a few earlier efforts have been devoted to the study of this paper in recent years, two major challenges still remain: 1) how to leverage the depth view effectively to model the depth-induced saliency and 2) how to implement an optimal combination of the RGB view and depth view, which can make full use of complementary information among them. To address these two challenges, this paper proposes a novel framework based on convolutional neural networks (CNNs), which transfers the structure of the RGB-based deep neural network to be applicable for depth view and fuses the deep representations of both views automatically to obtain the final saliency map. In the proposed framework, the first challenge is modeled as a cross-view transfer problem and addressed by using the task-relevant initialization and adding deep supervision in hidden layer. The second challenge is addressed by a multiview CNN fusion model through a combination layer connecting the representation layers of RGB view and depth view. Comprehensive experiments on four benchmark datasets demonstrate the significant and consistent improvements of the proposed approach over other state-of-the-art methods.","","","10.1109/TCYB.2017.2761775","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8091125","Convolutional neural networks (CNNs);cross-view transfer;multiview fusion;RGB-D;salient object detection","Object detection;Image color analysis;Adaptation models;Fuses;Biological neural networks;Computer vision","feedforward neural nets;image colour analysis;image fusion;image representation;object detection","RGB-D images;depth view;RGB view;depth-induced saliency;cross-view transfer problem;deep neural network;RGB-D saliency detection;salient object detection;convolutional neural networks;deep representation fusion;task-relevant initialization;multiview CNN fusion model","Attention;Humans;Image Processing, Computer-Assisted;Models, Neurological;Neural Networks (Computer)","21","55","","","","","IEEE","IEEE Journals"
"An Embarrassingly Simple Approach to Visual Domain Adaptation","H. Lu; C. Shen; Z. Cao; Y. Xiao; A. van den Hengel","National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, School of Automation, Huazhong University of Science and Technology, Wuhan, China; Australian Centre for Visual Technologies, School of Computer Science, The University of Adelaide, Adelaide, SA, Australia; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, School of Automation, Huazhong University of Science and Technology, Wuhan, China; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, School of Automation, Huazhong University of Science and Technology, Wuhan, China; Australian Centre for Visual Technologies, School of Computer Science, The University of Adelaide, Adelaide, SA, Australia","IEEE Transactions on Image Processing","","2018","27","7","3403","3417","We show that it is possible to achieve high-quality domain adaptation without explicit adaptation. The nature of the classification problem means that when samples from the same class in different domains are sufficiently close, and samples from differing classes are separated by large enough margins, there is a high probability that each will be classified correctly. Inspired by this, we propose an embarrassingly simple yet effective approach to domain adaptation-only the class mean is used to learn class-specific linear projections. Learning these projections is naturally cast into a linear-discriminant-analysis-like framework, which gives an efficient, closed form solution. Furthermore, to enable to application of this approach to unsupervised learning, an iterative validation strategy is developed to infer target labels. Extensive experiments on cross-domain visual recognition demonstrate that, even with the simplest formulation, our approach outperforms existing non-deep adaptation methods and exhibits classification performance comparable with that of modern deep adaptation methods. An analysis of potential issues effecting the practical application of the method is also described, including robustness, convergence, and the impact of small sample sizes.","","","10.1109/TIP.2018.2819503","National High-tech R&D Program of China (863 Program); National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8325317","Domain adaptation;convolutional neural networks;linear discriminant analysis;cross-domain object recognition;scene classification","Visualization;Robustness;Adaptation models;Closed-form solutions;Iterative methods;Training data;Training","feature extraction;pattern classification;probability;unsupervised learning","linear-discriminant-analysis-like framework;classification performance;efficient form solution;class-specific linear projections;class mean;embarrassingly simple yet effective approach;differing classes;classification problem;explicit adaptation;high-quality domain adaptation;visual domain adaptation;sample sizes;modern deep adaptation methods;cross-domain visual recognition;iterative validation strategy;unsupervised learning;closed form solution","","7","51","","","","","IEEE","IEEE Journals"
"Universal Golomb–Rice Coding Parameter Estimation Using Deep Belief Networks for Hyperspectral Image Compression","Z. Jiang; W. D. Pan; H. Shen","Department of Electrical and Computer Engineering, University of Alabama in Huntsville, Huntsville, AL, USA; Department of Electrical and Computer Engineering, University of Alabama in Huntsville, Huntsville, AL, USA; Bank of America Corporation, New York, NY, USA","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2018","11","10","3830","3840","For efficient compression of hyperspectral images, we propose a universal Golomb-Rice coding parameter estimation method using deep belief network, which does not rely on any assumption on the distribution of the input data. We formulate the problem of selecting the best coding parameter for a given input sequence as a supervised pattern classification problem. Simulations on the synthesized data and five hyperspectral image datasets show that we can achieve significantly more accurate estimation of the coding parameters, which can translate to slightly higher compression than three state-of-the-art methods. More extensive simulations on additional images from the 2006 AVIRIS datasets show that the proposed method achieved overall compression bitrates comparable with other estimation methods, as well as the sample-adaptive entropy coder employed by the Consultative Committee for Space Data Systems standard for multispectral and hyperspectral data compression. Regarding computational feasibility, we show how to use transferable deep belief networks to speed up training by about five times. We also show that inferring the best coding parameters using a trained deep belief network offers computational advantages over the brute-force search method. As an extension, we propose a novel side-information free codec, where the intersequence correlations can be learned by a differently trained network based on the current sequence to predict reasonably good parameters for coding the next sequence. As another extension, we introduce a variable feature combination architecture, where problem specific heuristics such as the sample means can be incorporated to further improve the estimation accuracy.","","","10.1109/JSTARS.2018.2864921","University of Alabama in Huntsville; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8443992","Data compression;image coding;neural network applications;pattern classification;remote sensing","Image coding;Hyperspectral imaging;Parameter estimation;Encoding;Estimation;Histograms","belief networks;data compression;hyperspectral imaging;image classification;image coding;parameter estimation;spectral analysis","multispectral data compression;hyperspectral data compression;trained deep belief network;brute-force search method;hyperspectral image compression;supervised pattern classification problem;synthesized data;hyperspectral image datasets;input sequence;golomb-rice coding parameter estimation method;coding parameters;sample-adaptive entropy coder;space data systems standard;computational feasibility;side-information free codec;AVIRIS datasets","","","33","","","","","IEEE","IEEE Journals"
"Sequential Video VLAD: Training the Aggregation Locally and Temporally","Y. Xu; Y. Han; R. Hong; Q. Tian","School of Computer Science and Technology, Tianjin University, Tianjin, China; School of Computer Science and Technology, Tianjin University, Tianjin, China; School of Computer and Information, Hefei University of Technology, Hefei, China; Department of Computer Science, The University of Texas at San Antonio, San Antonio, TX, USA","IEEE Transactions on Image Processing","","2018","27","10","4933","4944","As characterizing videos simultaneously from spatial and temporal cues has been shown crucial for the video analysis, the combination of convolutional neural networks and recurrent neural networks, i.e., recurrent convolution networks (RCNs), should be a native framework for learning the spatio-temporal video features. In this paper, we develop a novel sequential vector of locally aggregated descriptor (VLAD) layer, named SeqVLAD, to combine a trainable VLAD encoding process and the RCNs architecture into a whole framework. In particular, sequential convolutional feature maps extracted from successive video frames are fed into the RCNs to learn soft spatio-temporal assignment parameters, so as to aggregate not only detailed spatial information in separate video frames but also fine motion information in successive video frames. Moreover, we improve the gated recurrent unit (GRU) of RCNs by sharing the input-to-hidden parameters and propose an improved GRU-RCN architecture named shared GRU-RCN (SGRU-RCN). Thus, our SGRU-RCN has a fewer parameters and a less possibility of overfitting. In experiments, we evaluate SeqVLAD with the tasks of video captioning and video action recognition. Experimental results on Microsoft Research Video Description Corpus, Montreal Video Annotation Dataset, UCF101, and HMDB51 demonstrate the effectiveness and good performance of our method.","","","10.1109/TIP.2018.2846664","National Natural Science Foundation of China; Natural Science Foundation of Tianjin City; Army Research Office; Faculty Research Gift Awards by the NEC Laboratories of America and Blippar; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8382330","Video representation;deep learning;recurrent convolution networks;video captioning;action recognition","Image coding;Visualization;Convolution;Feature extraction;Aggregates;Recurrent neural networks;Task analysis","feature extraction;feedforward neural nets;image motion analysis;image representation;image sequences;learning (artificial intelligence);neural net architecture;recurrent neural nets;video signal processing","spatial cues;temporal cues;video analysis;convolutional neural networks;recurrent neural networks;native framework;spatio-temporal video features;locally aggregated descriptor layer;trainable VLAD encoding process;sequential convolutional feature maps;successive video frames;soft spatio-temporal assignment parameters;separate video frames;fine motion information;gated recurrent unit;input-to-hidden parameters;GRU-RCN architecture;SGRU-RCN;video captioning;video action recognition;Microsoft Research Video Description Corpus;Montreal Video Annotation Dataset;feature maps;sequential video VLAD;sequential vector;SeqVLAD;RCN architecture","","12","68","","","","","IEEE","IEEE Journals"
"Annotated Plant Pathology Databases for Image-Based Detection and Recognition of Diseases","J. Garcia Arnal Barbedo; L. Vieira Koenigkan; B. Almeida Halfeld-Vieira; R. Veras Costa; K. Lima Nechet; C. Vieira Godoy; M. Lobo Junior; F. Rodrigues Alves Patricio; V. Talamini; L. Gonzaga Chitarra; S. Alves Santos Oliveira; A. K. Nakasone Ishida; J. M. Cunha Fernandes; T. Teixeira Santos; F. Rossi Cavalcanti; D. Terao; F. Angelotti","NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA","IEEE Latin America Transactions","","2018","16","6","1749","1757","Over the last few years, considerable effort has been spent by Embrapa in the construction of a plant disease database representative enough for the development of effective methods for automatic plant disease detection and recognition. In October of 2016, this database, called PDDB, had 2326 images of 171 diseases and other disorders affecting 21 plant species. PDDB size, although considerable, is not enough to allow the use of powerful techniques such as deep learning. In order to increase its size, each image was subdivided according to certain criteria, increasing the number of images to 46,513. Both the original (PDDB) and subdivided (XDB) databases are now being made freely available for academic research purposes, thus supporting new studies and contributing to speed up the advances in the area. Both collections are expected to grow continuously in order to expand their reach. PDDB and XDB can be accessed in the link https://www.digipathos-rep.cnptia.embrapa.br/.","","","10.1109/TLA.2018.8444395","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8444395","database;deep learning;image processing;Plant pathology","Databases;Diseases;Machine learning;IEEE transactions;Pathology;Smart phones;Image recognition","","","","2","","","","","","IEEE","IEEE Journals"
"Tensor-Based Classification Models for Hyperspectral Data Analysis","K. Makantasis; A. D. Doulamis; N. D. Doulamis; A. Nikitakis","KIOS Research and Innovation Center of Excellence, Nicosia, Cyprus; National Technical University of Athens, Athens, Greece; National Technical University of Athens, Athens, Greece; Althexis Solutions Ltd., Nicosia, Cyprus","IEEE Transactions on Geoscience and Remote Sensing","","2018","56","12","6884","6898","In this paper, we present tensor-based linear and nonlinear models for hyperspectral data classification and analysis. By exploiting the principles of tensor algebra, we introduce new classification architectures, the weight parameters of which satisfy the rank-1 canonical decomposition property. Then, we propose learning algorithms to train both linear and nonlinear classifiers. The advantages of the proposed classification approach are that: 1) it significantly reduces the number of weight parameters required to train the model (and thus the respective number of training samples); 2) it provides a physical interpretation of model coefficients on the classification output; and 3) it retains the spatial and spectral coherency of the input samples. The linear tensor-based model exploits the principles of logistic regression, assuming the rank-1 canonical decomposition property among its weights. For the nonlinear classifier, we propose a modification of a feedforward neural network (FNN), called rank-1 FNN, since its weights satisfy again the rank-1 canonical decomposition property. An appropriate learning algorithm is also proposed to train the network. Experimental results and comparisons with state-of-the-art classification methods, either linear (e.g., linear support vector machine) or nonlinear (e.g., deep learning), indicate the outperformance of the proposed scheme, especially in the cases where a small number of training samples is available.","","","10.1109/TGRS.2018.2845450","European Union through the H2020 STOP-IT Project, Strategic, Tactical, Operational Protection of Water Infrastructure Against Cyber-Physical Threats; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8408516","Dimensionality reduction;hyperspectral data analysis;nonlinear modeling;rank-1 feedforward neural networks (FNNs);tensor-based classification","Tensile stress;Hyperspectral imaging;Data models;Machine learning;Data analysis;Analytical models","data analysis;feedforward neural nets;learning (artificial intelligence);pattern classification;regression analysis;tensors","weight parameters;rank-1 canonical decomposition property;nonlinear classifier;linear support vector machine;tensor-based classification models;hyperspectral data analysis;FNN;learning algorithm;logistic regression;feedforward neural network","","6","39","","","","","IEEE","IEEE Journals"
"Deep Learning and Visualization for Identifying Malware Families","G. Sun; Q. Qian","School of Computer Engineering & Science, Shanghai University, 34747 Shanghai, Shanghai China (e-mail: asongsxx@foxmail.com); School of Computer Engineering & Science, Shanghai University, Shanghai, ShangHai China (e-mail: qqian@shu.edu.cn)","IEEE Transactions on Dependable and Secure Computing","","2018","PP","99","1","1","The growing threat of malware is becoming more and more difficult to ignore. In this paper, a malware feature images generation method is used to combine the static analysis of malicious code with the methods of recurrent neural networks (RNN) and convolutional neural networks (CNN). By using RNN, our method considers not only the malware original opcode information but also the association between the original code and the timing characteristics. Furthermore, using RNN,itreducesthetrainingdependenceoncategorylabelsofmalware. Then, we use minhash to generate feature images from the fusion of the original codes and the predictive codes from the RNN. Finally, we train a CNN to classify feature images. When we trained very few samples (the proportion of the sample size of training dataset to validation dataset was 1:30), we obtained accuracy over 92%. When we adjust the proportion to 3:1, the accuracy exceeds 99.5%. As shown in confusion matrices, our method obtains a good result, where the worst false positive rate of all the malware families is 0.0147 and the average false positive rate is 0.0058.","","","10.1109/TDSC.2018.2884928","Natural Science Foundation of Shanghai; Shanghai Municipal Science and Technology Commission; National Key Research and Development Program of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8565880","Malware family identification;Malware feature image;Recurrent neural network;Convolutional neural network","Malware;Recurrent neural networks;Feature extraction;Static analysis;Training","","","","3","","","","","","IEEE","IEEE Early Access Articles"
"Deep Semisupervised Zero-Shot Learning with Maximum Mean Discrepancy","L. Zhang; J. Liu; M. Luo; X. Chang; Q. Zheng","MOEKLINNS Lab, Department of Computer Science and Technology, Xi'an Jiaotong University, 710049, Chinazhanglingling@stu.xjtu.edu.cn; MOEKLINNS Lab, Department of Computer Science and Technology, Xi'an Jiaotong University, 710049, Chinaliukeen@mail.xjtu.edu.cn; MOEKLINNS Lab, Department of Computer Science and Technology, Xi'an Jiaotong University, 710049, Chinaminnluo@mail.xjtu.edu.cn; Centre for Quantum Computation and Intelligent Systems, University of Technology Sydney, Ultimo NSW 2007, Australiacxj273@gmail.com; MOEKLINNS Lab, Department of Computer Science and Technology, Xi'an Jiaotong University, 710049, Chinaqhzheng@mail.xjtu.edu.cn","Neural Computation","","2018","30","5","1426","1447","Due to the difficulty of collecting labeled images for hundreds of thousands of visual categories, zero-shot learning, where unseen categories do not have any labeled images in training stage, has attracted more attention. In the past, many studies focused on transferring knowledge from seen to unseen categories by projecting all category labels into a semantic space. However, the label embeddings could not adequately express the semantics of categories. Furthermore, the common semantics of seen and unseen instances cannot be captured accurately because the distribution of these instances may be quite different. For these issues, we propose a novel deep semisupervised method by jointly considering the heterogeneity gap between different modalities and the correlation among unimodal instances. This method replaces the original labels with the corresponding textual descriptions to better capture the category semantics. This method also overcomes the problem of distribution difference by minimizing the maximum mean discrepancy between seen and unseen instance distributions. Extensive experimental results on two benchmark data sets, CU200-Birds and Oxford Flowers-102, indicate that our method achieves significant improvements over previous methods.","","","10.1162/neco_a_01071","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8353106","","","","","","","","Traditional","","","","MITP",""
"Context Adaptive Neural Network Based Acoustic Models for Rapid Adaptation","M. Delcroix; K. Kinoshita; A. Ogawa; C. Huemmer; T. Nakatani","NTT Communication Science Laboratories, NTT Corporation, Kyoto, Japan; NTT Communication Science Laboratories, NTT Corporation, Kyoto, Japan; NTT Communication Science Laboratories, NTT Corporation, Kyoto, Japan; Chair of Multimedia Communications and Signal Processing, Friedrich-Alexander University Erlangen-Nuremberg, Erlangen, Germany; NTT Communication Science Laboratories, NTT Corporation, Kyoto, Japan","IEEE/ACM Transactions on Audio, Speech, and Language Processing","","2018","26","5","895","908","The adaptation of automatic speech recognition systems to a speaker or an environment is important if we are to achieve high speech recognition performance ubiquitously. Recently, deep neural network (DNN) based acoustic models have been made adaptive to speakers or environments by the addition of an auxiliary feature representing the acoustic context information such as speaker or noise characteristics to the network input. The addition of such auxiliary features to the input realizes only the adaptation of the bias term of the input layer. In this paper, we introduce “context adaptive neural networks,” which are an alternative approach for exploiting auxiliary features that can achieve adaptation of all the parameters of a layer including the linear transformation matrices and the bias terms. A context adaptive neural network is a neural network with one of its layers factorized into sublayers, each associated with an acoustic context class representing a class of speakers or noise conditions. The output of the factorized layer is obtained as a weighted sum of the contributions of all of the sublayers. The weighting coefficients, or context class weights, are derived from the auxiliary features, by transforming them through an auxiliary network. The auxiliary network and the main network can be trained jointly, which enables the context classes that optimize the training criterion to be learned automatically. We perform experiments on three tasks, i.e., two speaker adaptation experiments using DNN models with medium-sized (Wall Street Journal) and large (Continuous Spontaneous Japanese) training datasets, and one environmental adaptation of a convolutional neural network based acoustic model with CHiME3 data. These experiments confirm the potential of the proposed approach in various settings.","","","10.1109/TASLP.2018.2798821","JSPS KAKENHI; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8270663","Acoustic modeling;acoustic model adaptation;deep neural network;adaptive training;auxiliary feature","Adaptation models;Hidden Markov models;Acoustics;Training;Speech;Neural networks;Training data","feedforward neural nets;learning (artificial intelligence);speech recognition","context adaptive neural network;acoustic model;rapid adaptation;deep neural network;auxiliary feature;acoustic context information;network input;acoustic context class;context class weights;auxiliary network;speaker adaptation experiments;environmental adaptation;convolutional neural network;CHiME3 data;speech recognition performance","","2","66","","","","","IEEE","IEEE Journals"
"Depth Super-Resolution on RGB-D Video Sequences With Large Displacement 3D Motion","Y. Wang; J. Zhang; Z. Liu; Q. Wu; Z. Zhang; Y. Jia","School of Electrical and Data Engineering, University of Technology Sydney, Ultimo, NSW, Australia; School of Electrical and Data Engineering, University of Technology Sydney, Ultimo, NSW, Australia; Multimedia, Interaction, and Communication Group, Microsoft Research, Redmond, WA, USA; School of Electrical and Data Engineering, University of Technology Sydney, Ultimo, NSW, Australia; Multimedia, Interaction, and Communication Group, Microsoft Research, Redmond, WA, USA; Beijing Laboratory of Intelligent Information Technology, Beijing Institute of Technology, Beijing, China","IEEE Transactions on Image Processing","","2018","27","7","3571","3585","To enhance the resolution and accuracy of depth data, some video-based depth super-resolution methods have been proposed, which utilizes its neighboring depth images in the temporal domain. They often consist of two main stages: motion compensation of temporally neighboring depth images and fusion of compensated depth images. However, large displacement 3D motion often leads to compensation error, and the compensation error is further introduced into the fusion. A video-based depth super-resolution method with novel motion compensation and fusion approaches is proposed in this paper. We claim that 3D nearest neighboring field (NNF) is a better choice than using positions with true motion displacement for depth enhancements. To handle large displacement 3D motion, the compensation stage utilized 3D NNF instead of true motion used in the previous methods. Next, the fusion approach is modeled as a regression problem to predict the super-resolution result efficiently for each depth image by using its compensated depth images. A new deep convolutional neural network architecture is designed for fusion, which is able to employ a large amount of video data for learning the complicated regression function. We comprehensively evaluate our method on various RGB-D video sequences to show its superior performance.","","","10.1109/TIP.2018.2820809","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8327836","Depth super-resolution;RGB-D video sequences;large displacement 3D motion;3D nearest neighboring field;deep convolutional neural network","Three-dimensional displays;Image resolution;Data structures;Boolean functions;Motion compensation;Optical imaging;Video sequences","convolution;feedforward neural nets;image colour analysis;image fusion;image resolution;image sequences;learning (artificial intelligence);motion compensation;regression analysis;video signal processing","motion compensation;temporally neighboring depth images;compensated depth images;compensation error;fusion approach;3D nearest neighboring field;motion displacement;depth enhancements;compensation stage;video data;depth superresolution method;3D NNF;regression problem;deep convolutional neural network architecture","","","46","","","","","IEEE","IEEE Journals"
"Landlord's equal cards force generation algorithm","S. Li; S. Li; M. Ding","Beijing Information Science & Technology University, People's Republic of China; Beijing Information Science & Technology University, People's Republic of China; Beijing Information Science & Technology University, People's Republic of China","The Journal of Engineering","","2018","2018","16","1590","1594","In recent years, deep learning has developed rapidly and gradually infiltrated into various fields. As a rookie, generation-based confrontation networks based on deep learning show excellent characteristics in many aspects. This study presents two innovative ideas, the same card force and generation cards algorithm. The generation of the equivalent cards force based on the generation of confrontation networks is studied. For the same period of time in the regular game, players will be issued different types of cards with similar card force, so as to distinguish the player level, the theory of the equal force is proposed. Based on the average and variance of scores obtained after the completion of a game, the cards are divided into ten different types of cards. On this basis, the use of generating a counterfeit network Generative Adversarial Nets generates a large number of cards of the equal card force. In the actual game, a network model is generated to generate a large number of game cards with the same force and distributed to different table numbers, so that the points scored by the landlords in different matches can have the characteristics of mutual appraisal.","","","10.1049/joe.2018.8289","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8543699","","","computerised instrumentation;learning (artificial intelligence);computer games;game theory","similar card force;equal force;counterfeit network Generative Adversarial Nets;equal card force;game cards;landlord;deep learning;generation-based confrontation networks;generation cards algorithm;equivalent cards force","","","15","","","","","IET","IET Journals"
"End-to-End Feature Integration for Correlation Filter Tracking With Channel Attention","D. Li; G. Wen; Y. Kuai; F. Porikli","College of Electronic Science, National University of Defense Technology, Changsha, China; College of Electronic Science, National University of Defense Technology, Changsha, China; College of Electronic Science, National University of Defense Technology, Changsha, China; Research School of Engineering, Australian National University, Canberra, Australia","IEEE Signal Processing Letters","","2018","25","12","1815","1819","Recently, the performance advancement of discriminative correlation filter (DCF) based trackers is predominantly driven by the use of deep convolutional features. As convolutional features from multiple layers capture different target information, existing works integrate hierarchical convolutional features to enhance target representation. However, these works separate feature integration from DCF learning and hardly benefit from end-to-end training. In this letter, we incorporates feature integration and DCF learning in a unified convolutional neural network. This network reformulates feature integration as a differential module that concatenates features from the shallow and deep layers. A channel attention mechanism is introduced to adaptively impose channel-wise weight on the integrated features. Experimental results on OTB100 and UAV123 demonstrate that our method achieves significant performance improvement while running in real-time.","","","10.1109/LSP.2018.2877008","National Natural Science Foundation of China; Australian Research Council's Discovery Projects; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8502094","Correlation filters;feature integration;channel attention","Convolutional neural networks;Feature extraction;Correlation;Target tracking;Information filters;Network architecture","computer vision;convolution;correlation methods;feature extraction;feedforward neural nets;image filtering;image representation;learning (artificial intelligence);object tracking","end-to-end feature integration;correlation filter tracking;discriminative correlation filter based trackers;deep convolutional features;multiple layers capture different target information;hierarchical convolutional features;target representation;DCF learning;unified convolutional neural network;channel attention mechanism;channel-wise weight;DCF based trackers;target information;feature concatenation;visual tracking","","2","26","","","","","IEEE","IEEE Journals"
"Real-Time Action Recognition With Deeply Transferred Motion Vector CNNs","B. Zhang; L. Wang; Z. Wang; Y. Qiao; H. Wang","Department of Computer Science and Technology, The Key Laboratory of Embedded System and Service Computing, Ministry of Education, Tongji University, Shanghai, China; Computer Vision Laboratory, ETH Zurich, Zurich, Switzerland; Computational Vision Group, University of California at Irvine, Irvine, CA, USA; Guangdong Provincial Key Laboratory of Computer Vision and Virtual Reality Technology, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Department of Computer Science and Technology, Key Laboratory of Embedded System and Service Computing, Ministry of Education, Tongji University, Shanghai, China","IEEE Transactions on Image Processing","","2018","27","5","2326","2339","The two-stream CNNs prove very successful for video-based action recognition. However, the classical two-stream CNNs are time costly, mainly due to the bottleneck of calculating optical flows (OFs). In this paper, we propose a two-stream-based real-time action recognition approach by using motion vector (MV) to replace OF. MVs are encoded in video stream and can be extracted directly without extra calculation. However, directly training CNN with MVs degrades accuracy severely due to the noise and the lack of fine details in MVs. In order to relieve this problem, we propose four training strategies which leverage the knowledge learned from OF CNN to enhance the accuracy of MV CNN. Our insight is that MV and OF share inherent similar structures which allow us to transfer knowledge from one domain to another. To fully utilize the knowledge learned in OF domain, we develop deeply transferred MV CNN. Experimental results on various datasets show the effectiveness of our training strategies. Our approach is significantly faster than OF based approaches and achieves processing speed of 390.7 frames per second, surpassing real-time requirement. We release our model and code to facilitate further research.","","","10.1109/TIP.2018.2791180","National Natural Science Foundation of China; Shenzhen Basic Research Program; External Cooperation Program of BIC Chinese Academy of Sciences; Shanghai Engineering Research Center of Industrial Vision Perception and Intelligent Computing; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8249882","Action recognition;motion vector;knowledge transfer;real-time processing;deep learning","Optical imaging;Feature extraction;Real-time systems;Machine learning;Streaming media;Image recognition;Training","convolution;feature extraction;feedforward neural nets;image motion analysis;image sequences;video signal processing;video streaming","real-time requirement;deeply transferred motion vector CNNs;two-stream CNNs;optical flows;video stream;video-based action recognition;two-stream-based real-time action recognition;deeply transferred MV CNN","","4","51","","","","","IEEE","IEEE Journals"
"Recognition of Visually Perceived Compositional Human Actions by Multiple Spatio-Temporal Scales Recurrent Neural Networks","H. Lee; M. Jung; J. Tani","School of Computing, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Department of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Cognitive Neurorobotics Research Unit, Okinawa Institute of Science and Technology, Kunigami-gun, Japan","IEEE Transactions on Cognitive and Developmental Systems","","2018","10","4","1058","1069","We investigate a deep learning model for action recognition that simultaneously extracts spatio-temporal information from a raw RGB input data. The proposed multiple spatio-temporal scales recurrent neural network (MSTRNN) model is derived by combining multiple timescale recurrent dynamics with a conventional convolutional neural network model. The architecture of the proposed model imposes both spatial and temporal constraints simultaneously on its neural activities. The constraints vary, with multiple scales in different layers. As suggested by the principle of upward and downward causation, it is assumed that the network can develop a functional hierarchy using its constraints during training. To evaluate and observe the characteristics of the proposed model, we use three human action datasets consisting of different primitive actions and different compositionality levels. The performance capabilities of the MSTRNN model on these datasets are compared with those of other representative deep learning models used in the field. The results show that the MSTRNN outperforms baseline models while using fewer parameters. The characteristics of the proposed model are observed by analyzing its internal representation properties. The analysis clarifies how the spatio-temporal constraints of the MSTRNN model aid in how it extracts critical spatio-temporal information relevant to its given tasks.","","","10.1109/TCDS.2017.2768422","National Research Foundation of Korea; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8090898","Action recognition;convolutional neural network (CNN);dynamic vision processing;recurrent neural network;symbol grounding","Feature extraction;Convolutional codes;Training;Visualization;Spatiotemporal phenomena;Biological neural networks;Recurrent neural networks","convolution;feature extraction;feedforward neural nets;gesture recognition;image motion analysis;image representation;learning (artificial intelligence);recurrent neural nets;spatiotemporal phenomena","multiple spatio-temporal scales recurrent neural network model;multiple timescale recurrent dynamics;conventional convolutional neural network model;neural activities;human action datasets;different compositionality levels;spatio-temporal constraints;MSTRNN model aid;critical spatio-temporal information;deep learning model;action recognition;spatio-temporal information extraction;RGB input data;visually perceived compositional human action recognition","","1","42","","","","","IEEE","IEEE Journals"
"3D Randomized Connection Network With Graph-Based Label Inference","S. Bao; P. Wang; T. C. W. Mok; A. C. S. Chung","Department of Computer Science and Engineering, Lo Kwee-Seong Medical Image Analysis Laboratory, The Hong Kong University of Science and Technology, Hong Kong; Department of Computer Science and Engineering, Lo Kwee-Seong Medical Image Analysis Laboratory, The Hong Kong University of Science and Technology, Hong Kong; Department of Computer Science and Engineering, Lo Kwee-Seong Medical Image Analysis Laboratory, The Hong Kong University of Science and Technology, Hong Kong; Department of Computer Science and Engineering, Lo Kwee-Seong Medical Image Analysis Laboratory, The Hong Kong University of Science and Technology, Hong Kong","IEEE Transactions on Image Processing","","2018","27","8","3883","3892","In this paper, a novel 3D deep learning network is proposed for brain magnetic resonance image segmentation with randomized connection, which can decrease the dependency between layers and increase the network capacity. The convolutional long-short term memory and the 3D convolution are employed as network units to capture the long-term and short-term 3D properties, respectively. To assemble these two kinds of spatial-temporal information and refine the deep learning outcomes, we further introduce an efficient graph-based node selection and label inference method. Experiments have been carried out on two publicly available databases and results demonstrate that the proposed method can obtain competitive performances as compared with the other state-of-the-art methods.","","","10.1109/TIP.2018.2829263","Hong Kong Research Grants Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8345227","Segmentation;brain;magnetic resonance imaging","Convolution;Three-dimensional displays;Two dimensional displays;Image segmentation;Logic gates;Kernel;Image analysis","biomedical MRI;feedforward neural nets;graph theory;image segmentation;inference mechanisms;learning (artificial intelligence);medical image processing;neurophysiology","network capacity;network units;spatial-temporal information;inference method;brain magnetic resonance image segmentation;3D deep learning network;3D randomized connection network;graph-based label inference;convolutional long-short term memory;3D convolution;long-term 3D properties;short-term 3D properties;publicly available databases","","","30","","","","","IEEE","IEEE Journals"
"Dense and Sparse Labeling With Multidimensional Features for Saliency Detection","Y. Yuan; C. Li; J. Kim; W. Cai; D. D. Feng","Biomedical and Multimedia Information Technology Research Group, School of Information Technologies, The University of Sydney, Darlington, NSW, Australia; Biomedical and Multimedia Information Technology Research Group, School of Information Technologies, The University of Sydney, Darlington, NSW, Australia; Biomedical and Multimedia Information Technology Research Group, School of Information Technologies, The University of Sydney, Darlington, NSW, Australia; Biomedical and Multimedia Information Technology Research Group, School of Information Technologies, The University of Sydney, Darlington, NSW, Australia; Biomedical and Multimedia Information Technology Research Group, The University of Sydney, Darlington, NSW, Australia","IEEE Transactions on Circuits and Systems for Video Technology","","2018","28","5","1130","1143","Conventional low-level feature-based saliency detection methods tend to use nonrobust prior knowledge and do not perform well in complex or low-contrast images. In this paper, to address these issues in existing methods, we propose a novel deep neural network (DNN)-based dense and sparse labeling (DSL) framework for saliency detection. DSL consists of three major steps, namely, dense labeling (DL), sparse labeling (SL), and deep convolutional (DC) network. The DL and SL steps conduct initial saliency estimations with macro object contours and low-level image features, respectively, which effectively approximate the location of the salient object and generate accurate guidance channels for the DC step; the DC step, on the other hand, takes in the results of DL and SL, establishes a six-channeled input data structure (including local superpixel information), and conducts accurate final saliency classification. Our DSL framework exploits the saliency estimation guidance from both macro object contours and local low-level features, as well as utilizing the DNN for high-level saliency feature extraction. Extensive experiments are conducted on six well-recognized public data sets against 16 state-of-the-art saliency detection methods, including ten conventional feature-based methods and six learning-based methods. The results demonstrate the superior performance of DSL on various challenging cases in terms of both accuracy and robustness.","","","10.1109/TCSVT.2016.2646720","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7802636","Deep neural network (DNN);dense labeling (DL);low-level feature;macro object contour;saliency detection;sparse labeling (SL)","Labeling;Feature extraction;DSL;Estimation;Image color analysis;Neural networks;Channel estimation","feature extraction;image classification;neural nets;object detection","multidimensional features;deep neural network;DNN;deep convolutional network;low-level image features;six-channeled input data structure;DSL framework;saliency estimation guidance;high-level saliency feature extraction;saliency detection methods;dense and sparse labeling framework;dense labeling;saliency classification","","3","74","","","","","IEEE","IEEE Journals"
"An Automatic Cardiac Arrhythmia Classification System With Wearable Electrocardiogram","Y. Xia; H. Zhang; L. Xu; Z. Gao; H. Zhang; H. Liu; S. Li","Chinese Academy of Sciences, Shenzhen Institutes of Advanced Technology, Shenzhen, China; School of Information Engineering, Guangdong Medical University, Dongguan, China; Department of Cardiology, General Hospital of Guangzhou Military Command of PLA, Guangzhou, China; Chinese Academy of Sciences, Shenzhen Institutes of Advanced Technology, Shenzhen, China; Chinese Academy of Sciences, Shenzhen Institutes of Advanced Technology, Shenzhen, China; Department of Optical Engineering, State Key Laboratory of Modern Optical Instrumentation, Zhejiang University, Hangzhou, China; Western University, London, Canada","IEEE Access","","2018","6","","16529","16538","This paper presents an automatic wearable electrocardiogram (ECG) classification and monitoring system with stacked denoising autoencoder (SDAE). We use a wearable device with wireless sensors to obtain the ECG data, and send these ECG data to a computer with Bluetooth 4.2. Then, these ECG data are classified by the automatic cardiac arrhythmia classification system. First, the ECG feature representation is learned by the SDAE with sparsity constraint. Then, the softmax regression is used to classify the ECG beats. In the fine-tuning phase, an active learning is added to improve the performance. In the active learning phase, we use the method that relies on the deep neural networks posterior probabilities to associate confidence measures to select the most informative samples. Breaking-ties and modified breaking-ties methods are used to select the most informative samples. We validate the proposed method on the well-known MIT-BIH arrhythmia database and ECG data obtained from the wearable device. We follow the recommendations of the Association for the Advancement of Medical Instrumentation for class labeling and results presentation. The results show that the classification performance of our proposed approach outperforms the most of the state-of-the-art methods.","","","10.1109/ACCESS.2018.2807700","National Key Research and Development Program of China; Shenzhen Dual Chain Funding; National Natural Science Foundation of China; Science and Technology Planning Project of Guangdong Province; Guangzhou Science and Technology Planning Project; Shenzhen Innovation Funding; China Postdoctoral Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8300311","Stacked denoising autoencoder;wearable device;active learning;breaking-ties;modified breaking-ties","Electrocardiography;Biomedical monitoring;Feature extraction;Databases;Support vector machines;Noise reduction;Neural networks","electrocardiography;learning (artificial intelligence);medical signal processing;neural nets;signal classification","modified breaking-ties methods;breaking-ties method;class labeling;Association for the Advancement of Medical Instrumentation;monitoring system;wearable electrocardiogram;classification performance;active learning phase;ECG beats;SDAE;ECG feature representation;automatic cardiac arrhythmia classification system;ECG data;wearable device","","8","38","","","","","IEEE","IEEE Journals"
"DNN-Supported Speech Enhancement With Cepstral Estimation of Both Excitation and Envelope","S. Elshamy; N. Madhu; W. Tirry; T. Fingscheidt","Institute for Communications Technology, Technische Universität Braunschweig, Braunschweig, Germany; NXP Software, Leuven, Belgium; NXP Software, Leuven, Belgium; Institute for Communications Technology, Technische Universität Braunschweig, Braunschweig, Germany","IEEE/ACM Transactions on Audio, Speech, and Language Processing","","2018","26","12","2460","2474","In this paper, we propose and compare various techniques for the estimation of clean spectral envelopes in noisy conditions. The source-filter model of human speech production is employed in combination with a hidden Markov model and/or a deep neural network approach to estimate clean envelope-representing coefficients in the cepstral domain. The cepstral estimators for speech spectral envelope-based noise reduction are both evaluated alone and also in combination with the recently introduced cepstral excitation manipulation (CEM) technique for a priori SNR estimation in a noise reduction framework. Relative to the classical MMSE short time spectral amplitude estimator, we obtain more than 2 dB higher noise attenuation, and relative to our recent CEM technique still 0.5 dB more, in both cases maintaining the quality of the speech component and obtaining considerable SNR improvement.","","","10.1109/TASLP.2018.2867947","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8452964","${a\; priori}$SNR;speech enhancement","Hidden Markov models;Cepstral analysis;Deep learning;Signal to noise ratio;Speech enhancement;Noise reduction","filtering theory;hidden Markov models;least mean squares methods;neural nets;spectral analysis;speech enhancement","human speech production;hidden Markov model;deep neural network approach;clean envelope-representing coefficients;cepstral domain;speech spectral envelope-based noise reduction;a priori SNR estimation;noise reduction framework;classical MMSE short time spectral amplitude estimator;speech component;DNN-supported speech enhancement;clean spectral envelopes;noisy conditions;source-filter model;noise attenuation;cepstral excitation manipulation technique;CEM technique","","6","54","","","","","IEEE","IEEE Journals"
"Video-Based Depression Level Analysis by Encoding Deep Spatiotemporal Features","M. A. Jazaery; G. Guo","Computer Science and Electrical Engineering, West Virginia University College of Engineering and Mineral Resources, 195919 Morgantown, West Virginia United States (e-mail: moaljazaery@mix.wvu.edu); CSEE, West Virginia University, Morgantown, West Virginia United States 26506 (e-mail: Guodong.Guo@mail.wvu.edu)","IEEE Transactions on Affective Computing","","2018","PP","99","1","1","As a serious mood disorder problem, depression causes severe symptoms that affect how people feel, think, and handle daily activities, such as sleeping, eating, or working. In this paper, a novel framework is proposed to estimate the Beck Depression Inventory II (BDI-II) values from video data, which uses a 3D convolutional neural network to automatically learn the spatiotemporal features at two different face scales. Then, a Recurrent Neural Network (RNN) is used to learn further from the sequence of the spatiotemporal information. This formulation, called RNN-C3D, can model the local and global spatiotemporal information from consecutive face expressions, in order to predict the depression levels. Experiments on the AVEC2013 and AVEC2014 depression datasets show that our proposed approach is promising, when compared to the state-of-the- art visual-based depression analysis methods.","","","10.1109/TAFFC.2018.2870884","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8466881","Automated Visual-based depression analysis;nonverbal behavior;3D convolutional Neural Network (C3D);Recurrent Neural Network (RNN)","Face;Visualization;Spatiotemporal phenomena;Recurrent neural networks;Feature extraction;Three-dimensional displays;Analytical models","","","","3","","","","","","IEEE","IEEE Early Access Articles"
"View-Based 3-D Model Retrieval: A Benchmark","A. Liu; W. Nie; Y. Gao; Y. Su","School of Electrical and Information Engineering, Tianjin University, Tianjin, China; School of Electrical and Information Engineering, Tianjin University, Tianjin, China; School of Software and TNList, Tsinghua University, Beijing, China; School of Electrical and Information Engineering, Tianjin University, Tianjin, China","IEEE Transactions on Cybernetics","","2018","48","3","916","928","View-based 3-D model retrieval is one of the most important techniques in numerous applications of computer vision. While many methods have been proposed in recent years, to the best of our knowledge, there is no benchmark to evaluate the state-of-the-art methods. To tackle this problem, we systematically investigate and evaluate the related methods by: 1) proposing a clique graph-based method and 2) reimplementing six representative methods. Moreover, we concurrently evaluate both hand-crafted visual features and deep features on four popular datasets (NTU60, NTU216, PSB, and ETH) and one challenging real-world multiview model dataset (MV-RED) prepared by our group with various evaluation criteria to understand how these algorithms perform. By quantitatively analyzing the performances, we discover the graph matching-based method with deep features, especially the clique graph matching algorithm with convolutional neural networks features, can usually outperform the others. We further discuss the future research directions in this field.","","","10.1109/TCYB.2017.2664503","National Natural Science Foundation of China; Tianjin Research Program of Application Foundation and Advanced Technology; China Scholarship Council; Elite Scholar Program of Tianjin University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7857115","3-D model retrieval;benchmark;deep learning;graph matching","Solid modeling;Computational modeling;Mathematical model;Adaptation models;Visualization;Shape;Feature extraction","computer vision;convolution;feature extraction;graph theory;image matching;image representation;image retrieval;neural nets;stereo image processing","view-based 3D model retrieval;real-world multiview model dataset;MV-RED;computer vision;convolutional neural networks features;clique graph matching algorithm;NTU216;NTU60;deep features;visual features;representative methods","","6","72","","","","","IEEE","IEEE Journals"
"Predicting Occupancy Distributions of Walking Humans With Convolutional Neural Networks","J. Doellinger; M. Spies; W. Burgard","Bosch Center for Artificial Intelligence, Renningen, Germany; Bosch Center for Artificial Intelligence, Renningen, Germany; Department of Computer Science, University of Freiburg, Freiburg, Germany","IEEE Robotics and Automation Letters","","2018","3","3","1522","1528","As robots are increasingly entering human environments, many subtleties of socially compliant navigation are still unsolved. To behave in a socially compliant way, robots need to have an understanding of the natural motion paths of humans in the shared environment. Humans intuitively follow social norms, which allows them to navigate smoothly even in crowded environments. For example, when humans enter a previously unseen building, they are still able to infer from their surroundings where humans would typically walk and use this information to obviate interference. In this letter, we propose an approach to learn such a predictive method. A robot could use this information to find nondisturbing waiting positions, avoid crowded areas, or clean heavily frequented areas more often. We propose the use of convolutional neural networks to predict average occupancy maps of walking humans even in environments where no human trajectory data are available. In experiments, we show that our method transfers from simulation to real-world data and performs better than several baseline methods. We demonstrate the applicability on a real robot to find good waiting positions near narrow passages as well as a planner, which avoids areas where human interference is likely.","","","10.1109/LRA.2018.2800780","Bosch Center for Artificial Intelligence; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8278198","Deep learning in robotics and automation;semantic scene understanding;social human-robot interaction","Legged locomotion;Trajectory;Hidden Markov models;Agriculture;Convolutional neural networks;Data models","control engineering computing;feedforward neural nets;learning (artificial intelligence);mobile robots;neurocontrollers;path planning","convolutional neural networks;robots;human environments;socially compliant navigation;shared environment;social norms;crowded environments;human trajectory data;human interference;walking humans;occupancy distribution prediction","","2","24","","","","","IEEE","IEEE Journals"
"Multi-Resident Activity Recognition in a Smart Home Using RGB Activity Image and DCNN","T. Tan; M. Gochoo; S. Huang; Y. Liu; S. Liu; Y. Huang","Department of Electrical Engineering, National Taipei University of Technology, Taipei, Taiwan; Department of Electronic Engineering, National Taipei University of Technology, Taipei, Taiwan; Department of Electronic Engineering, National Taipei University of Technology, Taipei, Taiwan; Department of Mechanical Engineering, National Taipei University of Technology, Taipei, Taiwan; Department of Information Engineering, Chaoyang University of Technology, Taichung, Taiwan; Department of Information and Communications, Chaoyang University of Technology, Taichung, Taiwan","IEEE Sensors Journal","","2018","18","23","9718","9727","In the last decade, unobtrusive (device-free and non-privacy invasive) recognition of activities of daily living for an individual in a smart home has been studied by many researchers. However, the unobtrusive recognition of multi-resident activities in a smart home is hardly studied. We propose a novel RGB activity image-based DCNN classifier for the unobtrusive recognition of the multi-resident activities (Bed_to_Toilet, Bed, Breakfast, Lunch, Leave_home, Laundry, Dinner, Night_wandering, R2_work, and R1_medicine) using Cairo open data set provided by the CASAS Project. The open data set is collected by environmental sensors (PIR and temperature sensors) in Cairo testbed, while an adult couple with a dog was living for 55 days. The data set is preprocessed with activity segmentation, sliding window, and RGB activity image conversion steps. The experimental results demonstrate that our classifier has the highest total accuracy of 95.2% among the previously developed machine learning classifiers that employed the same data set. Moreover, the proposed RGB activity image was proven to be helpful for increasing the recognition rate. Therefore, we conclude that the proposed DCNN classifier is a useful tool for the unobtrusive recognition of the multi-resident activity in a home.","","","10.1109/JSEN.2018.2866806","Ministry of Science and Technology, Taiwan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8444711","Unobtrusive;convolutional neural networks;deep learning;activity recognition;wandering detection","Temperature sensors;Image segmentation;Activity recognition;Intelligent sensors;Training;Smart homes","home automation;image classification;learning (artificial intelligence);medical computing;sensors;ubiquitous computing","multiresident activity recognition;smart home;unobtrusive recognition;RGB activity image-based DCNN classifier;Cairo open data;open data set;activity segmentation;RGB activity image conversion steps;recognition rate;CASAS Project","","3","46","","","","","IEEE","IEEE Journals"
"Rotation Invariant Local Binary Convolution Neural Networks","X. Zhang; Y. Xie; J. Chen; L. Wu; Q. Ye; L. Liu","College of Information System and Management, National University of Defense Technology, Changsha, China; College of Information System and Management, National University of Defense Technology, Changsha, China; Center for Machine Vision and Signal Analysis, University of Oulu, Oulu, Finland; Space Engineering University, Beijing, China; University of Chinese Academy of Sciences, Beijing, China; College of Information System and Management, National University of Defense Technology, Changsha, China","IEEE Access","","2018","6","","18420","18430","Convolutional neural networks (CNNs) have achieved unprecedented successes in computer vision fields, but they remain challenged by the problem about how to effectively process the orientation transformation of objects with fewer parameters. In this paper, we propose a new convolutional module, local binary orientation module (LBoM), which takes advantages of both local binary convolutional and active rotating filters to effectively deal with the rotation variations with fewer parameters. LBoM can be naturally inserted to popular CNN models and upgrade them to be rotation invariant local binary CNNs (RI-LBCNNs). RI-LBCNNs can be learned with off-the-shelf optimization approaches in an end-to-end manner and fulfill image classification tasks. Extensive experiments on four benchmarks show that RI-LBCNNs can perform image classification with fewer network parameters and significantly outperform the baseline LBCNN when processing images with large rotation variations.","","","10.1109/ACCESS.2018.2818887","National Natural Science Foundation of China; Natural Science Foundation of Hunan Province; Hunan Provincial Natural Science Fund for Distinguished Young Scholars; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8323369","Deep learning;rotation invariance;convolutional neural network;local binary filter","Convolution;Computer architecture;Convolutional neural networks;Image coding;Feature extraction;Computer vision","computer vision;feedforward neural nets;image classification;learning (artificial intelligence)","rotation invariant local binary convolution neural networks;computer vision fields;convolutional module;local binary orientation module;LBoM;local binary convolutional rotating filters;active rotating filters;rotation variations;rotation invariant local binary CNNs;RI-LBCNNs;image classification","","2","48","","","","","IEEE","IEEE Journals"
"Scenario-Based Insider Threat Detection From Cyber Activities","P. Chattopadhyay; L. Wang; Y. Tan","Department of Computer Science and Engineering, IIT (BHU) Varanasi, Varanasi, India; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore","IEEE Transactions on Computational Social Systems","","2018","5","3","660","675","An insider threat scenario refers to the outcome of a set of malicious activities caused by intentional or unintentional misuse of the organization's systems, networks, data, and resources. Prevention of insider threat is difficult, since trusted partners of the organization are involved in it, who have authorized access to these confidential/sensitive resources. The state-of-the-art research on insider threat detection mostly focuses on developing unsupervised behavioral anomaly detection techniques with the objective of finding out anomalousness or abnormal changes in user behavior over time. However, an anomalous activity is not necessarily malicious that can lead to an insider threat scenario. As an improvement to the existing approaches, we propose a technique for insider threat detection from time-series classification of user activities. Initially, a set of single-day features is computed from the user activity logs. A time-series feature vector is next constructed from the statistics of each single-day feature over a period of time. The label of each time-series feature vector (whether malicious or nonmalicious) is extracted from the ground truth. To classify the imbalanced ground-truth insider threat data consisting of only a small number of malicious instances, we employ a cost-sensitive data adjustment technique that undersamples the nonmalicious class instances randomly. As a classifier, we employ a two-layered deep autoencoder neural network and compare its performance with other popularly used classifiers: random forest and multilayer perceptron. Encouraging results are obtained by evaluating our approach using the CMU Insider Threat Data, which is the only publicly available insider threat data set consisting of about 14-GB web-browsing logs, along with logon, device connection, file transfer, and e-mail log files. We observe that both deep autoencoder and random forest classifiers classify the dataadjusted time-series feature set with high precision, recall, and f-score. Although multilayer perceptron has a high recall, it suffers from a lower precision and f-score compared to the other two classifiers.","","","10.1109/TCSS.2018.2857473","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8444978","Cost-sensitive learning;imbalanced data;insider threat;time-series classification","Organizations;Anomaly detection;Electronic mail;Feature extraction;Forestry;Web pages;Thumb","multilayer perceptrons;pattern classification;security of data;time series;unsupervised learning","cyber activities;malicious activities;unsupervised behavioral anomaly detection techniques;anomalous activity;time-series classification;time-series feature vector;imbalanced ground-truth insider threat data;cost-sensitive data adjustment technique;CMU Insider Threat Data;scenario-based insider threat detection;user activity logs;two-layered deep autoencoder neural network;random forest;multilayer perceptron;data adjusted time-series feature set","","4","67","","","","","IEEE","IEEE Journals"
"Fusion-based holistic road scene understanding","W. Huang; F. Zhang; A. Xu; H. Chen; P. Li","Electric Power Research Institute, People's Republic of China; Electric Power Research Institute, People's Republic of China; Electric Power Research Institute, People's Republic of China; Electric Power Research Institute, People's Republic of China; Electric Power Research Institute, People's Republic of China","The Journal of Engineering","","2018","2018","16","1623","1628","This study addresses the problem of holistic road scene understanding based on the integration of visual and range data. To achieve the grand goal, the authors propose an approach that jointly tackles object-level image segmentation and semantic region labelling within a conditional random field (CRF) framework. Specifically, the authors first generate semantic object hypotheses by clustering 3D points, learning their prior appearance models, and using a deep learning method for reasoning their semantic categories. The learned priors, together with spatial and geometric contexts, are incorporated in CRF. With this formulation, visual and range data are fused thoroughly, and moreover, the coupled segmentation and semantic labelling problem can be inferred via graph cuts. The authors’ approach is validated on the challenging KITTI dataset that contains diverse complicated road scenarios. Both quantitative and qualitative evaluations demonstrate its effectiveness.","","","10.1049/joe.2018.8319","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8543739","","","learning (artificial intelligence);image segmentation;image fusion;random processes;pattern clustering","fusion-based holistic road scene understanding;object-level image segmentation;conditional random field framework;semantic object hypotheses;deep learning method;CRF framework;semantic region labelling problem;3D point clustering;KITTI dataset","","","33","","","","","IET","IET Journals"
"Cross-Scene Counting Based on Domain Adaptation-Extreme Learning Machine","B. Yang; J. Cao; N. Wang; Y. Zhang; G. Cui","Department of Information Science and Engineering, Changzhou University, Changzhou, China; Department of Information Science and Engineering, Changzhou University, Changzhou, China; Department of Information Science and Engineering, Ocean University of China, Qingdao, China; Department of Information Science and Engineering, Changzhou University, Changzhou, China; Department of Information Science and Engineering, Changzhou University, Changzhou, China","IEEE Access","","2018","6","","17029","17038","Cross-scene counting is difficult if only limited training samples are available in the new scene. In this paper, a cross-scene counting model is learned with information transferred from other scenes. Counting is achieved through regression, which maps the features of crowds to their counts. Hand-crafted features are extracted from segmented crowd foregrounds obtained through block robust principal component analysis. Samples of existing scenes (source domain) are adaptively transferred into the new scene (target domain) through domain adaptation. Then, a counting model based on domain adaptation-extreme learning machine (DA-ELM) is efficiently learned via iterative optimization with training samples of both domains. Quantitative analysis indicates that the DA-ELM can count the crowds of a new scene with only a half of the training samples compared with counting without domain adaptation. Contrastive evaluations based on three benchmarking data sets are implemented with several state-of-the-art domain adaptation approaches, including hand-crafted feature-based and deep neural network-based approaches. Results reveal the effectiveness of DA-ELM in transferring information through embedding domain adaptation into an ELM framework.","","","10.1109/ACCESS.2018.2800688","National Natural Science Foundation of China; Natural Science Foundation of Jiangsu Province; Key Laboratory for New Technology Application of Road Conveyance of Jiangsu Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8278167","Crowd counting;domain adaptation;extreme learning machine;iterative optimization","Feature extraction;Adaptation models;Training;Robustness;Distortion;Optimization;Motion segmentation","","","","2","37","","","","","IEEE","IEEE Journals"
"THINKER - Entity Linking System for Turkish Language","M. Kalender; E. E. Korkmaz","Department of Computer Engineering, Yeditepe University, Istanbul, Turkey; Department of Computer Engineering, Yeditepe University, Istanbul, Turkey","IEEE Transactions on Knowledge and Data Engineering","","2018","30","2","367","380","Entity linking is one of the problems to be handled in order to process natural language and to enrich the existing unstructured text with metadata. The generation of assignments between knowledge base entities and lexical units is called entity linking. Although a number of systems have been proposed for linking entity mentions in various languages, there is currently no publicly available entity linking system specific to the Turkish language. This paper presents a novel entity linking system-THINKER - for linking Turkish content with entities defined in the Turkish dictionary (tdk.gov.tr) or Turkish Wikipedia (tr.wikipedia.org). Specifically, we first propose a novel machine learning based entity detection algorithm for the Turkish language. Then, we propose a collective disambiguation algorithm which utilizes a set of metrics for the linking task and, which is optimized using a genetic algorithm. The effectiveness of THINKER is validated empirically over generated data sets. The experimental results show that THINKER outperformed the state-of-the-art cross-lingual and multilingual entity linking systems in the literature. High entity linking performance (74.81 percent F1 score) is achieved by extending previous methods with some features specific to Turkish language and by developing a novel method that can learn better representations of entity embeddings.","","","10.1109/TKDE.2017.2761743","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8063926","Entity linking;entity disambiguation;deep neural networks;knowledge base;embeddings","Knowledge based systems;Encyclopedias;Electronic publishing;Internet;Neural networks","feature extraction;genetic algorithms;knowledge based systems;learning (artificial intelligence);natural language processing;text analysis","Turkish Wikipedia;entity detection algorithm;Turkish language;multilingual entity;entity embeddings;knowledge base entities;Turkish dictionary;natural language processing;entity linking system;THINKER;collective disambiguation algorithm;genetic algorithm;machine learning","","","44","","","","","IEEE","IEEE Journals"
"A Driving Fingerprint Map Method of Driving Characteristic Representation for Driver Identification","H. Cai; Z. Hu; Z. Chen; D. Zhu","Intelligent Transportation Systems Research Center, Wuhan University of Technology, Wuhan, China; Intelligent Transportation Systems Research Center, Wuhan University of Technology, Wuhan, China; Intelligent Transportation Systems Research Center, Wuhan University of Technology, Wuhan, China; Intelligent Transportation Systems Research Center, Wuhan University of Technology, Wuhan, China","IEEE Access","","2018","6","","71012","71019","Safety and comfortability are important indicators to evaluate the performance of driver assistant systems (ADAS) and intelligent vehicle (IV) systems. Driver identification or driving characteristic learning is needed to achieve the comfortability function for ADAS or IV systems. The effectiveness of driver identification or driving characteristic learning is directly affected by driving characteristic representation method. This paper develops a new concept of the driving fingerprint map to represent driving characteristics. First, the driving scenes are classified using the ensemble learning method. Then, the feature selection method known as conditional mutual information maximization is used to select the representative features for describing driving characteristics. Finally, the sliding time window is applied to generate the driving fingerprint map based on the selected driving features. To verify the performance of the proposed driving fingerprint map method, a real vehicle experiment is conducted to obtain the test dataset. The driver identification results that used the original driving features and the proposed driving fingerprint map based on the deep convolutional neural network, support vector machine, and extreme learning machine are compared. The results show that the driving fingerprint map method can effectively describe driving characteristics.","","","10.1109/ACCESS.2018.2881722","Major Project of Technological Innovation in Hubei Province; National Natural Science Foundation of China; Science-Technology Funds for Overseas Chinese Talents of Hubei Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8537901","Intelligent transportation system;driving behavior;driving fingerprint map;driver identification;intelligent vehicle","Vehicles;Fingerprint recognition;Microsoft Windows;Classification algorithms;Windows;Feature extraction;Mutual information","convolutional neural nets;driver information systems;learning (artificial intelligence);pattern classification;support vector machines","driving fingerprint map method;driving characteristic learning;characteristic representation method;driving characteristics;driving scenes;ensemble learning method;feature selection method;selected driving features;driver identification results;original driving features","","","24","","","","","IEEE","IEEE Journals"
"A Novel Fault Diagnostic Approach for DC-DC Converters Based on CSA-DBN","Q. Sun; Y. Wang; Y. Jiang","College of Automation Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of Automation Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of Automation Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, China","IEEE Access","","2018","6","","6273","6285","Effective fault diagnosis for mission-critical and safety-critical systems has been an essential and mandatory technique to reduce failure rate and prevent unscheduled shutdown. In this paper, to realize fault diagnosis for a closed-loop single-ended primary inductance converter, a novel optimization deep belief network (DBN) is presented. First, wavelet packet decomposition is adopted to extract the energy values from the voltage signals of four circuit nodes, as the fault feature vectors. Then, a four-layer DBN architecture including input and output layers is developed. Meanwhile, the number of neurons in the two hidden layers is selected by the crow search algorithm (CSA) with training samples. Not only the hard faults such as open-circuit faults and short-circuit faults but also the soft faults such as the component degradation of power MOSFET, inductor, diode, and capacitor are considered in this study. Finally, these fault modes are isolated by CSA-DBN. Compared with the back-propagation neural network and support vector machine fault diagnosis methods, both simulation and experimental results show that the proposed method has a higher classification accuracy that proves its effectiveness and superiority to the other methods.","","","10.1109/ACCESS.2017.2786458","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities and Funding of Jiangsu Innovation Program for Graduate Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8240905","Crow search algorithm;dc-dc power converter;deep belief network;fault diagnosis;feature extraction;wavelet packets","Circuit faults;Fault diagnosis;Neurons;Capacitors;DC-DC power converters;Support vector machines","belief networks;DC-DC power convertors;electronic engineering computing;fault diagnosis;learning (artificial intelligence);neural nets;power MOSFET;support vector machines;wavelet transforms","short-circuit faults;soft faults;fault modes;CSA-DBN;back-propagation neural network;support vector machine fault diagnosis methods;DC-DC converters;power MOSFET;fault diagnostic approach;open-circuit faults;hard faults;training samples;crow search algorithm;fault feature vectors;circuit nodes;voltage signals;energy values;wavelet packet decomposition;novel optimization deep belief network;primary inductance converter;unscheduled shutdown;mandatory technique;safety-critical systems","","7","24","","","","","IEEE","IEEE Journals"
"Spatial Pyramid Pooling of Selective Convolutional Features for Vein Recognition","J. Wang; Z. Pan; G. Wang; M. Li; Y. Li","School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, China; School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, China; School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, China; School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, China; School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, China","IEEE Access","","2018","6","","28563","28572","Deep neural network (DNN) has demonstrated astounding performance in large-scale image recognition task, and pre-trained DNN models trained for one task have also been applied to domains different from their original purposes. Following such an idea, a novel hand-dorsa vein recognition model is constructed by adopting DNN pre-trained on a large-scale database as a universal feature descriptor. Unlike most of these studies which adopt activations of the fully connected layer of DNN as the image representation, we adopt convolutional activations as the region representation. However, not local features of all regions are equally important for final classification. Thus, to solve this issue, a novel selective convolutional feature model based on spatial weighting is proposed to acquire more robust and discriminative feature representation. In specific, a spatial weighting scheme is applied on the convolutional activations to weigh the importance of local features at different regions for classification, which further enhances the discriminability of feature representation. Besides, to take full advantage of the spatial information of the convolutional activations, spatial pyramid pooling is introduced to obtain feature representation with rich spatial information. The final image representation is formed by concatenating the local features of different level of the spatial pyramid. Series rigorous experiments on the lab-made database are conducted to evidence the effectiveness and feasibility of the proposed model. What is more, an additional experiment with subset of PolyU database illustrates its generalization ability and robustness.","","","10.1109/ACCESS.2018.2839720","Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8362924","Deep neural network;hand-dorsa vein recognition;selective convolutional features;spatial weighting;spatial pyramid pooling","Veins;Task analysis;Feature extraction;Databases;Robustness;Image recognition;Image representation","convolution;feature extraction;image classification;image representation;learning (artificial intelligence);neural nets;vein recognition","spatial pyramid pooling;selective convolutional features;deep neural network;pre-trained DNN models;hand-dorsa vein recognition model;large-scale database;universal feature descriptor;spatial weighting scheme;large-scale image recognition;image representation;PolyU database","","4","63","","","","","IEEE","IEEE Journals"
"Personalized Classifier for Food Image Recognition","S. Horiguchi; S. Amano; M. Ogawa; K. Aizawa","Department of Information and Communication Engineering, University of Tokyo, Tokyo, Japan; Department of Information and Communication Engineering, University of Tokyo, Tokyo, Japan; foo.log, Inc., Tokyo, Japan; Department of Information and Communication Engineering, University of Tokyo, Tokyo, Japan","IEEE Transactions on Multimedia","","2018","20","10","2836","2848","Currently, food image recognition tasks are evaluated against fixed datasets. However, in real-world conditions, there are cases in which the number of samples in each class continues to increase and samples from novel classes appear. In particular, dynamic datasets in which each individual user creates samples and continues the updating process often has content that varies considerably between different users, and the number of samples per person is very limited. A single classifier common to all users cannot handle such dynamic data. Bridging the gap between the laboratory environment and the real world has not yet been accomplished on a large scale. Personalizing a classifier incrementally for each user is a promising way to do this. In this paper, we address the personalization problem, which involves adapting to the user's domain incrementally using a very limited number of samples. We propose a simple yet effective personalization framework, which is a combination of the nearest class mean classifier and the 1-nearest neighbor classifier based on deep features. To conduct realistic experiments, we made use of a new dataset of daily food images collected by a food-logging application. Experimental results show that our proposed method significantly outperforms existing methods.","","","10.1109/TMM.2018.2814339","JST CREST; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8316919","Incremental learning;domain adaptation, one-shot learning;personalization;food image classification;deep feature","Image recognition;Training;Task analysis;Support vector machines;Feature extraction;Estimation;Laboratories","feature extraction;food technology;image classification;image recognition","class mean classifier;personalization framework;1-nearest neighbor classifier;food image recognition tasks;personalized classifier;food-logging application;personalization problem;laboratory environment;dynamic data","","1","57","","","","","IEEE","IEEE Journals"
"Collaborative Deconvolutional Neural Networks for Joint Depth Estimation and Semantic Segmentation","J. Liu; Y. Wang; Y. Li; J. Fu; J. Li; H. Lu","National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; University of Science and Technology, Beijing, China; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","11","5655","5666","Semantic segmentation and single-view depth estimation are two fundamental problems in computer vision. They exploit the semantic and geometric properties of images, respectively, and are thus complementary in scene understanding. In this paper, we propose a collaborative deconvolutional neural network (C-DCNN) to jointly model these two problems for mutual promotion. The C-DCNN consists of two DCNNs, of which each is for one task. The DCNNs provide a finer resolution reconstruction method and are pretrained with hierarchical supervision. The feature maps from these two DCNNs are integrated via a pointwise bilinear layer, which fuses the semantic and depth information and produces higher order features. Then, the integrated features are fed into two sibling classification layers to simultaneously learn for semantic segmentation and depth estimation. In this way, we combine the semantic and depth features in a unified deep network and jointly train them to benefit each other. Specifically, during network training, we process depth estimation as a classification problem where a soft mapping strategy is proposed to map the continuous depth values into discrete probability distributions and the cross entropy loss is used. Besides, a fully connected conditional random field is also used as postprocessing to further improve the performance of semantic segmentation, where the proximity relations of pixels on position, intensity, and depth are jointly considered. We evaluate our approach on two challenging benchmarks: NYU Depth V2 and SUN RGB-D. It is demonstrated that our approach effectively utilizes these two kinds of information and achieves state-of-the-art results on both the semantic segmentation and depth estimation tasks.","","","10.1109/TNNLS.2017.2787781","National Natural Science Foundation of China; Fundamental Research Funds for Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8320527","Deconvolutional neural network (DCNN);depth estimation;fully connected conditional random field (CRF);pointwise bilinear layer;semantic segmentation;soft mapping strategy","Semantics;Estimation;Task analysis;Image segmentation;Labeling;Neural networks;Image resolution","computer vision;deconvolution;entropy;feedforward neural nets;image colour analysis;image reconstruction;image resolution;image segmentation;image sensors;learning (artificial intelligence);probability;random processes","semantic segmentation;NYU Depth;depth estimation tasks;collaborative deconvolutional neural network;joint Depth estimation;single-view depth estimation;DCNNs;semantic depth;continuous depth","","3","45","","","","","IEEE","IEEE Journals"
"Single Image Rain Removal via a Simplified Residual Dense Network","H. Xia; R. Zhuge; H. Li; S. Song; F. Jiang; M. Xu","College of Electronics Engineering, Guangxi Normal University, Guilin, China; College of Electronics Engineering, Guangxi Normal University, Guilin, China; College of Electronics Engineering, Guangxi Normal University, Guilin, China; College of Electronics Engineering, Guangxi Normal University, Guilin, China; College of Electronics Engineering, Guangxi Normal University, Guilin, China; Faculty of Engineering and IT, University of Technology Sydney, Ultimo, NSW, Australia","IEEE Access","","2018","6","","66522","66535","The single-image rain removal problem has attracted tremendous interests within the deep learning domains. Although deep learning based de-raining methods outperform many conventional methods, there are still unresolved issues in regards to improving the performance. In this paper, we propose a simplified residual dense network (SRDN) to improve the de-raining performance and cut down the computation time. Inspired by the image processing domain knowledge that a rainy image can be decomposed into a base (low-pass) layer and a detail (high-pass) layer, we train our network by directly learning the residual between the detail layer of rainy images and the detail layer of clean images. It can both significantly reduce the mapping range from input to output and easily employ the image enhancement operation to handle the heavy rain with hazy looks. Instead of designing a deeper network structure to increase the learning ability of network, we propose a simplified dense block to explore more effective information between layers and, hence, reduce the computation time of network. Experiments on both synthetic and real-world images demonstrate that our SRDN network can achieve competitive results in comparison with the benchmarked and conventional approaches for single-image rain removal.","","","10.1109/ACCESS.2018.2879330","National Natural Science Foundation of China; Opening Project of Guangxi Colleges and Universities Key Laboratory of Robot & Welding, Guilin University of Aerospace Technology; Research Fund of Guangxi Key Lab of Intelligent Integrated Automation; Project of Science and Technology of Jiangxi Province; Guangxi 100 Youth Talent Program; Guilin University of Electronic Technology; Guangxi Key Lab of Multi-Source Information Mining and Security; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8520865","Rain removal;deep learning;SRDN","Rain;Task analysis;Image enhancement;Generative adversarial networks;Aerospace engineering","","","","","37","","","","","IEEE","IEEE Journals"
"Identity Adaptation for Person Re-Identification","Q. Ke; M. Bennamoun; H. Rahmani; S. An; F. Sohel; F. Boussaid","School of Computer Science and Software Engineering, The University of Western Australia, Crawley, Australia; School of Computer Science and Software Engineering, The University of Western Australia, Crawley, Australia; School of Computing and Communications, Lancaster University, Lancashire, England; School of Electrical Engineering, Computing and Mathematical Sciences, Curtin University, Bentley, Australia; School of Engineering and Information Technology, Murdoch University, Murdoch, Australia; School of Electrical, Electronic and Computer Engineering, The University of Western Australia, Crawley, Australia","IEEE Access","","2018","6","","48147","48155","Person re-identification (re-ID), which aims to identify the same individual from a gallery collected with different cameras, has attracted increasing attention in the multimedia retrieval community. Current deep learning methods for person re-ID focus on learning classification models on training identities to obtain an ID-discriminative embedding (IDE) extractor, which is used to extract features from testing images for re-ID. The IDE features of the testing identities might not be discriminative due to that the training identities are different from the testing identities. In this paper, we introduce a new ID-adaptation network (ID-AdaptNet), which aims to improve the discriminative power of the IDE features of the testing identities for better person re-ID. The main idea of the ID-AdaptNet is to transform the IDE features to a common discriminative latent space, where the representations of the “seen”training identities are enforced to adapt to those of the “unseen”training identities. More specifically, the ID-AdaptNet is trained by simultaneously minimizing the classification cross-entropy and the discrepancy between the “seen”and the “unseen”training identities in the hidden space. To calculate the discrepancy, we represent their probability distributions as moment sequences and calculate their distance using their central moments. We further propose a stacking ID-AdaptNet that jointly trains multiple ID-AdaptNets with a regularization method for better re-ID. Experiments show that the ID-AdaptNet and stacking ID-AdaptNet effectively improve the discriminative power of IDE features.","","","10.1109/ACCESS.2018.2867898","Australian Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8452946","Person re-identification;ID adaptation;moment matching","Training;Testing;Feature extraction;Image color analysis;Stacking;Australia;Task analysis","entropy;feature extraction;image classification;learning (artificial intelligence);probability","multimedia retrieval;unseen training identities;seen training identities;discriminative latent space;probability distributions;classification cross-entropy;feature extraction;deep learning methods;stacking ID-AdaptNet;ID-adaptation network;testing identities;IDE features;ID-discriminative embedding extractor;person re-identification;identity adaptation","","","49","","","","","IEEE","IEEE Journals"
"Extensive exploration of comprehensive vehicle attributes using D-CNN with weighted multi-attribute strategy","Z. Yan; Y. Feng; C. Cheng; J. Fu; X. Zhou; J. Yuan","Chongqing Institute of Green and Intelligent Technology, People's Republic of China; Chongqing Institute of Green and Intelligent Technology, People's Republic of China; Chongqing Institute of Green and Intelligent Technology, People's Republic of China; Chongqing Institute of Green and Intelligent Technology, People's Republic of China; Chongqing Institute of Green and Intelligent Technology, People's Republic of China; Chongqing Institute of Green and Intelligent Technology, People's Republic of China","IET Intelligent Transport Systems","","2018","12","3","186","193","As a classical machine learning method, multi-task learning (MTL) has been widely applied in computer vision technology. Due to deep convolutional neural network (D-CNN) having strong ability of feature representation, the combination of MTL and D-CNN has attracted much attention from researchers recently. However, this kind of combination has rarely been explored in the field of vehicle analysis. The authors propose a D-CNN enhanced with weighted multi-attribute strategy for extensive exploration of comprehensive vehicle attributes over surveillance images. Specifically, regarding to recognising vehicle model and make/manufacturer, several related attributes as auxiliary tasks are incorporated in the training process of D-CNN structure. The proposed strategy focuses more on the main task compared with traditional MTL methods, which has assigned different weights for the main task and auxiliary tasks rather than treating all involved tasks equally. To the extent of their knowledge, this is the first report relating to the combination of D-CNN and weighted MTL for exploration of comprehensive vehicle attributes. The following experiments will show that the proposed approach outperforms the state-of-the-art method for the vehicle recognition and improves the accuracy rate by about 10% for the analysis of other vehicle attributes on the recently public CompCars dataset.","","","10.1049/iet-its.2017.0066","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8307026","","","feedforward neural nets;learning (artificial intelligence);object recognition","comprehensive vehicle attributes;D-CNN;weighted multiattribute strategy;deep convolutional neural network;surveillance images;vehicle model recognition;manufacturer recognition;CompCars vehicle dataset;multitask learning;MTL methods;make recognition","","","51","","","","","IET","IET Journals"
"An Overview of Lead and Accompaniment Separation in Music","Z. Rafii; A. Liutkus; F. Stöter; S. I. Mimilakis; D. FitzGerald; B. Pardo","Gracenote, Emeryville, CA, USA; Inria and LIRMM, University of Montpellier, Montpellier, France; Inria and LIRMM, University of Montpellier, Montpellier, France; Fraunhofer IDMT, Ilmenau, Germany; Cork School of Music, Cork Institute of Technology, Cork, U.K.; Northwestern University, Evanston, IL, USA","IEEE/ACM Transactions on Audio, Speech, and Language Processing","","2018","26","8","1307","1335","Popular music is often composed of an accompaniment and a lead component, the latter typically consisting of vocals. Filtering such mixtures to extract one or both components has many applications, such as automatic karaoke and remixing. This particular case of source separation yields very specific challenges and opportunities, including the particular complexity of musical structures, but also relevant prior knowledge coming from acoustics, musicology or sound engineering. Due to both its importance in applications and its challenging difficulty, lead and accompaniment separation has been a popular topic in signal processing for decades. In this article, we provide a comprehensive review of this research topic, organizing the different approaches according to whether they are model-based or data-centered. For model-based methods, we organize them according to whether they concentrate on the lead signal, the accompaniment, or both. For data-centered approaches, we discuss the particular difficulty of obtaining data for learning lead separation systems, and then review recent approaches, notably those based on deep learning. Finally, we discuss the delicate problem of evaluating the quality of music separation through adequate metrics and present the results of the largest evaluation, to-date, of lead and accompaniment separation systems. In conjunction with the above, a comprehensive list of references is provided, along with relevant pointers to available implementations and repositories.","","","10.1109/TASLP.2018.2825440","Research Programme KAMoulox; ANR; French State Agency for Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8336997","Source separation;music;accompaniment;lead;overview","Speech;Lead;Speech processing;Spectrogram;Music;Time-frequency analysis;Source separation","audio signal processing;learning (artificial intelligence);music;source separation","accompaniment separation;popular music;lead component;automatic karaoke;remixing;source separation yields;particular complexity;musical structures;relevant prior knowledge;musicology;popular topic;model-based methods;lead signal;data-centered approaches;particular difficulty;lead separation systems;music separation;deep learning","","9","364","","","","","IEEE","IEEE Journals"
"Multichannel Fully Convolutional Network for Coronary Artery Segmentation in X-Ray Angiograms","J. Fan; J. Yang; Y. Wang; S. Yang; D. Ai; Y. Huang; H. Song; A. Hao; Y. Wang","Beijing Engineering Research Center of Mixed Reality and Advanced Display, School of Optics and Electronics, Beijing Institute of Technology, Beijing, China; Beijing Engineering Research Center of Mixed Reality and Advanced Display, School of Optics and Electronics, Beijing Institute of Technology, Beijing, China; Beijing Engineering Research Center of Mixed Reality and Advanced Display, School of Optics and Electronics, Beijing Institute of Technology, Beijing, China; Beijing Engineering Research Center of Mixed Reality and Advanced Display, School of Optics and Electronics, Beijing Institute of Technology, Beijing, China; Beijing Engineering Research Center of Mixed Reality and Advanced Display, School of Optics and Electronics, Beijing Institute of Technology, Beijing, China; Beijing Engineering Research Center of Mixed Reality and Advanced Display, School of Optics and Electronics, Beijing Institute of Technology, Beijing, China; School of Software, Beijing Institute of Technology, Beijing, China; State Key Laboratory of Virtual Technology and Systems, Beihang University, Beijing, China; Beijing Engineering Research Center of Mixed Reality and Advanced Display, School of Optics and Electronics, Beijing Institute of Technology, Beijing, China","IEEE Access","","2018","6","","44635","44643","Accurate segmentation of coronary arteries in X-ray angiograms is an important step for the quantitative study of coronary artery disease. However, accurate segmentation is a challenging task because coronary arteries are thin tubular structures with relatively low contrast and the presence of artifacts. In this paper, a novel deep-learning-based method is proposed to automatically segment the coronary artery from angiograms by using multichannel fully convolutional networks. Since the artifacts appear in both live images (after the injection of contrast material) and mask images (before the injection of contrast material) and the blood vessels appear only in live images, we take the mask images into consideration to distinguish real blood vessel structures from artifacts. Therefore, both live images and mask images are used as multichannel inputs to provide enhanced vascular structure information. The hierarchical features are then automatically learned to characterize the spatial associations between vessel and background and are further used to achieve the final segmentation. In addition, a dense matching between the live image and mask image is processed for a precise initial alignment. The experimental results demonstrate that our method is effective and robust for coronary artery segmentation, compared with several state-of-the-art methods.","","","10.1109/ACCESS.2018.2864592","National Basic Research Program of China (973 Program); National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8432384","Coronary artery;fully convolutional network;dense matching;U-net","Image segmentation;Arteries;Motion segmentation;Biomedical imaging;Solid modeling;Training","angiocardiography;blood vessels;diagnostic radiography;diseases;image enhancement;image segmentation;learning (artificial intelligence);medical image processing","dense matching;blood vessel structures;contrast material;deep-learning-based method;coronary artery disease;X-ray angiograms;multichannel fully convolutional network;coronary artery segmentation;live image","","2","30","","","","","IEEE","IEEE Journals"
"Integrating Different Levels of Automation: Lessons From Winning the Amazon Robotics Challenge 2016","C. H. Corbato; M. Bharatheesha; J. van Egmond; J. Ju; M. Wisse","TU Delft Robotics Institute, Delft University of Technology, Delft, The Netherlands; TU Delft Robotics Institute, Delft University of Technology, Delft, The Netherlands; TU Delft Robotics Institute, Delft University of Technology, Delft, The Netherlands; TU Delft Robotics Institute, Delft University of Technology, Delft, The Netherlands; TU Delft Robotics Institute, Delft University of Technology, Delft, The Netherlands","IEEE Transactions on Industrial Informatics","","2018","14","11","4916","4926","This paper describes Team Delft's robot winning the Amazon Robotics Challenge 2016. The competition involves automating pick and place operations in semistructured environments, specifically the shelves in an Amazon warehouse. Team Delft's entry demonstrated that the current robot technology can already address most of the challenges in product handling: object recognition, grasping, motion, or task planning; under broad yet bounded conditions. The system combines an industrial robot arm, 3-D cameras and a custom gripper. The robot's software is based on the robot operating system to implement solutions based on deep learning and other state-of-the-art artificial intelligence techniques, and to integrate them with off-the-shelf components. From the experience developing the robotic system, it was concluded that: 1) the specific task conditions should guide the selection of the solution for each capability required; 2) understanding the characteristics of the individual solutions and the assumptions they embed is critical to integrate a performing system from them; and 3) this characterization can be based on “levels of robot automation.” This paper proposes automation levels based on the usage of information at design or runtime to drive the robot's behavior, and uses them to discuss Team Delft's design solution and the lessons learned from this robot development experience.","","","10.1109/TII.2018.2800744","European Union's Seventh Framework Programme; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8304784","Grasping;manipulators;motion planning;object recognition;robot control","Service robots;Task analysis;Automation;Robot sensing systems;Grasping;Runtime","cameras;control engineering computing;grippers;industrial manipulators;learning (artificial intelligence);mobile robots;motion control;object recognition;robot vision","place operations;Amazon warehouse;Team Delft's entry;industrial robot arm;robot operating system;robot automation;Team Delft's design solution;robot development experience;Team Delft's robot;pick operations;Amazon robotics challenge;object recognition;grasping;motion planning;task planning;cameras;custom gripper;robots software;deep learning;artificial intelligence techniques;off-the-shelf components;robots behavior","","1","32","CCBY","","","","IEEE","IEEE Journals"
"Combining Convolutional Neural Network and Distance Distribution Matrix for Identification of Congestive Heart Failure","Y. Li; Y. Zhang; L. Zhao; Y. Zhang; C. Liu; L. Zhang; L. Zhang; Z. Li; B. Wang; E. Ng; J. Li; Z. He","State Key Laboratory of Bioelectronics, Jiangsu Key Laboratory of Remote Measurement and Control, School of Instrument Science and Engineering, Southeast University, Nanjing, China; Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; School of Control Science and Engineering, Shandong University, Jinan, China; Lenovo Research, Beijing, China; State Key Laboratory of Bioelectronics, Jiangsu Key Laboratory of Remote Measurement and Control, School of Instrument Science and Engineering, Southeast University, Nanjing, China; Computational Intelligence Group, Northumbria University, Newcastle upon Tyne, U.K.; Lenovo Research, Beijing, China; Lenovo Research, Beijing, China; Medical Big Data Center, Chinese PLA General Hospital, Beijing, China; School of Mechanical and Aerospace Engineering, College of Engineering, Nanyang Technological University, Singapore; State Key Laboratory of Bioelectronics, Jiangsu Key Laboratory of Remote Measurement and Control, School of Instrument Science and Engineering, Southeast University, Nanjing, China; Lenovo Research, Beijing, China","IEEE Access","","2018","6","","39734","39744","Congestive heart failure (CHF) is a serious pathophysiological condition with high morbidity and mortality, which is hard to predict and diagnose in early age. Artificial intelligence and deep learning combining with cardiac rhythms and physiological time series provide a potential to help in solving it. In this paper, we proposed a novel method that combines a convolutional neural network (CNN) and a distance distribution matrix (DDM) in entropy calculation to classify CHF patients from normal subjects, and demonstrated the effectiveness of this combination. Specifically, three entropy methods were used to generate the distribution matrixes from a 300-point RR interval (i.e., the time interval between the successive cardiac cycles) time series, which are Sample entropy, fuzzy local measure entropy, and fuzzy global measure entropy. Then, three high representative CNN models, i.e., AlexNet, DenseNet, and SE_Inception_v4 were chosen to learn the pattern of the data distributions hidden in the generated distribution matrixes. All data used in our experiments were gathered from the MIT-BIH RR Interval Databases (http://www.physionet.org). A total of 29 CHF patients and 54 normal sinus rhythm subjects were included in this paper. The results showed that the combination of FuzzyGMEn-generated DDM and Inception_v4 model yielded the highest accuracy of 81.85% out of all proposed combinations.","","","10.1109/ACCESS.2018.2855420","National Natural Science Foundation of China; Key Research and Development Programs of Jiangsu Province; Fundamental Research Funds for the Central Universities; Southeast-Lenovo Wearable Heart-Sleep-Emotion Intelligent Monitoring Lab; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8410564","Congestive heart failure (CHF);convolutional neural network (CNN);distance distribution matrix (DDM);heart rate variability (HRV);entropy","Entropy;Heart rate variability;Databases;Time series analysis;Electrocardiography;Feature extraction","diseases;electrocardiography;learning (artificial intelligence);medical signal processing;neural nets;signal classification;signal sampling;time series","artificial intelligence;deep learning;cardiac rhythms;physiological time series;entropy calculation;entropy methods;successive cardiac cycles;Sample entropy;fuzzy local measure entropy;fuzzy global measure entropy;high representative CNN models;data distributions;generated distribution matrixes;MIT-BIH RR Interval Databases;FuzzyGMEn-generated DDM;serious pathophysiological condition;congestive heart failure;distance distribution matrix;convolutional neural network","","2","35","","","","","IEEE","IEEE Journals"
"FOV Expansion of Bioinspired Multiband Polarimetric Imagers With Convolutional Neural Networks","Y. Zhao; M. Wang; G. Yang; J. C. Chan","School of Automation, Northwestern Polytechnical University, Xi'an, China; School of Automation, Northwestern Polytechnical University, Xi'an, China; Shanghai Aerospace Control Technology Institute, Shanghai, China; Department of Electronics and Informatics, Vrije Universiteit Brussel, Belgium","IEEE Photonics Journal","","2018","10","1","1","14","Spectral and polarimetric contents of the light reflected from an object contain useful information on material type and surface characteristics of the object. Jointly exploiting spatial, spectral, and polarimetric information helps detect camouflage targets. Motivated by the vision mechanism of some known aquatic insects, we construct a bioinspired multiband polarimetric imaging system using a camera array, which simultaneously captures multiple images of different spectral bands and polarimetric angles. But the disparity between the fixed positions of each component camera leads to the loss of information in the boundary region and a reduction in the field of view (FOV). In order to overcome the limits, this paper presents a deep learning method for FOV expansion, incorporating the gradient prior of the image into a nine-dimensional convolutional neural network's framework to learn end-to-end mapping between the incomplete images and the FOV-expanded images. With FOV expansion, the proposed model recovers significant missing information. For the problem of insufficient training data, we construct the training dataset and propose the corresponding training methods to achieve good convergence of the network. We also provide some experimental results to validate its state-of-the-art performance of FOV expansion.","","","10.1109/JPHOT.2017.2783039","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8194739","Bio-inspired vision;multiband polarization imaging;convolutional neural networks;FOV expansion.","Cameras;Image reconstruction;Training;Feature extraction;Biomedical imaging;Band-pass filters","biomimetics;cameras;image sensors;learning (artificial intelligence);neural nets;optical engineering computing;polarimetry","FOV-expanded images;nine-dimensional convolutional neural network;deep learning method;camera array;bioinspired multiband polarimetric imaging system;aquatic insects;vision mechanism;camouflage target detection;polarimetric information;spectral information;spatial information;convolutional neural networks;bioinspired multiband polarimetric imagers;FOV expansion","","2","21","","","","","IEEE","IEEE Journals"
"Computer Graphics Identification Combining Convolutional and Recurrent Neural Networks","P. He; X. Jiang; T. Sun; H. Li","School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore","IEEE Signal Processing Letters","","2018","25","9","1369","1373","In this letter, a deep-learning-based pipeline is proposed to distinguish photographics (PGs) from computer-graphics (CGs) combining convolutional neural network (CNN) and recurrent neural network (RNN). In the preprocessing stage, the color space transformation and the Schmid filter bank are utilized to extract chrominance and luminance components, which suppress the irrelevant information of various image contents for the CG identification task. Then, a dual-path CNN architecture is designed to learn joint feature representations of local patches for exploiting their color and texture characteristics. To extract the global artifact, the directed acyclic graph RNN is applied to model the spatial dependence of local patterns. Finally, the output score of RNN is used to identify the input sample. The CG/PG dataset is constructed by collecting samples from the Internet. Experimental results show that the proposed framework can outperform state-of-the-art methods on identification ability of CGs, especially for images with low resolution.","","","10.1109/LSP.2018.2855566","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8410682","Computer-graphics (CGs);convolutional neural network (CNN);recurrent neural network (RNN)","Image color analysis;Feature extraction;Convolution;Rendering (computer graphics);Forensics;Training","directed graphs;feature extraction;image classification;image colour analysis;image representation;image texture;learning (artificial intelligence);recurrent neural nets","dual-path CNN architecture;joint feature representations;local patches;texture characteristics;directed acyclic graph RNN;local patterns;CG/PG dataset;identification ability;CGs;computer graphics identification;convolutional networks;recurrent neural networks;deep-learning-based pipeline;photographics;computer-graphics;convolutional neural network;recurrent neural network;preprocessing stage;color space transformation;Schmid filter bank;chrominance;luminance components;irrelevant information;image contents;CG identification task","","1","39","","","","","IEEE","IEEE Journals"
"Intelligent Fault Diagnosis Under Varying Working Conditions Based on Domain Adaptive Convolutional Neural Networks","B. Zhang; W. Li; X. Li; S. Ng","School of Computer Science and Technology, China University of Mining and Technology, Xuzhou, China; School of Mechanical and Electrical Engineering, China University of Mining and Technology, Xuzhou, China; Institute for Infocomm Research, A*STAR, Singapore; Institute of Data Science, National University of Singapore, Singapore","IEEE Access","","2018","6","","66367","66384","Traditional intelligent fault diagnosis works well when the labeled training data (source domain) and unlabeled testing data (target domain) are drawn from the same distribution. However, in many real-world applications, the working conditions can vary between training and testing time. In this paper, we address the issues of intelligent fault diagnosis when the data at training and testing time do not come from the same distribution as a domain adaptation problem using domain adaptive convolutional neural networks (DACNN). Our proposed DACNN consists of three parts: a source feature extractor, a target feature extractor, and a label classifier. We adopt a two-stage training process to obtain strong fault-discriminative and domain-invariant capacity. First, we obtain fault-discriminative features by pre-training the source feature extractor with labeled source training examples to minimize the label classifier error. Then, in the domain adaptive fine-tuning stage, we train the target feature extractor to minimize the squared maximum mean discrepancy between the output of the source and target feature extractor, such that the instances sampled from the source and target domains have similar distributions after the mapping. Furthermore, to enable training efficiency in domain adaptation, the layers between the source and target feature extractors in our DACNN are partially untied during the training stage. Experiments on the bearing and gearbox fault data showed that DACNN can achieve high fault diagnosis precision and recall under different working conditions, outperforming other intelligent fault diagnosis methods. We also demonstrate the ability to visualize the learned features and the networks to better understand the reasons behind the remarkable performance of our proposed model.","","","10.1109/ACCESS.2018.2878491","National Basic Research Program of China (973 Program); Natural Science Foundation of Jiangsu Province; China Postdoctoral Science Foundation; Jiangsu Planned Projects for Postdoctoral Research Funds; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8513748","Convolutional neural networks;domain adaptation;deep learning;intelligent fault diagnosis;transfer learning","Employee welfare;Feature extraction;Fault diagnosis;Training;Testing;Adaptation models;Vibrations","","","","4","43","CCBY","","","","IEEE","IEEE Journals"
"Robust Covariance Representations With Large Margin Dimensionality Reduction for Visual Classification","Q. Sun; J. Zhang; P. Zhu; Q. Wang; P. Li","Key Laboratory of Advanced Design and Intelligent Computing, Ministry of Education, Dalian University, Dalian, China; Key Laboratory of Advanced Design and Intelligent Computing, Ministry of Education, Dalian University, Dalian, China; School of Computer Science and Technology, Tianjin University, Tianjin, China; School of Information and Communication Engineering, Dalian University of Technology, Dalian, China; School of Information and Communication Engineering, Dalian University of Technology, Dalian, China","IEEE Access","","2018","6","","5531","5537","Inspired by the breakthrough performance of deep convolutional neural networks (CNNs) and the effectiveness of covariance representations, the combination of covariances with activations of deep CNNs has great potential in representing visual concepts. However, such method lies in two challenges: 1) robust estimation of covariance in the case of high dimension and small sample size and 2) high computational and storage costs caused by high-dimensional covariance representations. To tackle the above challenges, this paper proposes a novel robust covariance representation with large-margin dimensionality reduction for visual classification. First, we introduce two regularized maximum likelihood estimators to perform the robust estimation of covariance in the case of high dimension and small sample size, which can greatly improve the modeling ability of covariances. Then, we present a large-margin dimensionality reduction method for high-dimensional covariance representations. It does not only significantly reduce the dimension of robust covariance representations with considering their Riemannian geometry structure, but also can further enhance their discriminability. Experiments are conducted on three kinds of visual classification tasks, and the results show that our proposed method is superior to its counterparts and achieves the state-of-the-art performance.","","","10.1109/ACCESS.2018.2797419","National Natural Science Foundation of China; Liaoning Provincial Natural Science Foundation; High-level Talent Innovation Support Program of Dalian City; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8268085","Robust covariances;regularized MLE;large margin dimensionality reduction;visual classification","Covariance matrices;Robustness;Maximum likelihood estimation;Dimensionality reduction;Visualization;Feature extraction;Manifolds","convolution;covariance matrices;estimation theory;feedforward neural nets;geometry;image classification;image representation;learning (artificial intelligence);maximum likelihood estimation","robust covariance representations;deep convolutional neural networks;deep CNNs;visual concepts;high-dimensional covariance representations;novel robust covariance representation;regularized maximum likelihood estimators;large-margin dimensionality reduction method;visual classification tasks;visual classification;visual concept representation","","","37","","","","","IEEE","IEEE Journals"
"Urdu Optical Character Recognition Systems: Present Contributions and Future Directions","N. H. Khan; A. Adnan","Department of Computer Science, Institute of Management Sciences, Peshawar, Pakistan; Department of Computer Science, Institute of Management Sciences, Peshawar, Pakistan","IEEE Access","","2018","6","","46019","46046","This paper gives an across-the-board comprehensive review and survey of the most prominent studies in the field of Urdu optical character recognition (OCR). This paper introduces the OCR technology and presents a historical review of the OCR systems, providing comparisons between the English, Arabic, and Urdu systems. Detailed background and literature have also been provided for Urdu script, discussing the script's past, OCR categories, and phases. This paper further reports all state-of-the-art studies for different phases, namely, image acquisition, pre-processing, segmentation, feature extraction, classification/recognition, and post-processing for an Urdu OCR system. In the segmentation section, the analytical and holistic approaches for Urdu text have been emphasized. In the feature extraction section, a comparison has been provided between the feature learning and feature engineering approaches. Deep learning and traditional machine learning approaches have been discussed. The Urdu numeral recognition systems have also been deliberated concisely. The research paper concludes by identifying some open problems and suggesting some future directions.","","","10.1109/ACCESS.2018.2865532","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8438450","Cursive;optical character recognition;Urdu text recognition","Optical character recognition software;Character recognition;Writing;History;Optical imaging;Feature extraction;Text recognition","feature extraction;image classification;image segmentation;learning (artificial intelligence);natural language processing;optical character recognition;text analysis","OCR technology;historical review;OCR systems;Urdu script;OCR categories;Urdu OCR system;segmentation section;analytical approaches;holistic approaches;Urdu text;feature extraction section;feature learning;Urdu numeral recognition systems;Urdu optical character recognition systems;machine learning approaches","","3","104","","","","","IEEE","IEEE Journals"
"Pushing the Limits of Deep CNNs for Pedestrian Detection","Q. Hu; P. Wang; C. Shen; A. van den Hengel; F. Porikli","The University of Adelaide, Adelaide, SA, Australia; The University of Adelaide, Adelaide, SA, Australia; The University of Adelaide, Adelaide, SA, Australia; The University of Adelaide, Adelaide, SA, Australia; Data61, Canberra, ACT, Australia","IEEE Transactions on Circuits and Systems for Video Technology","","2018","28","6","1358","1368","Compared with other applications in computer vision, convolutional neural networks (CNNs) have underperformed on pedestrian detection. A breakthrough was made very recently using sophisticated deep CNN (DCNN) models, with a number of handcrafted features or explicit occlusion handling mechanism. In this paper, we show that by reusing the convolutional feature maps of a DCNN model as image features to train an ensemble of boosted decision models, we are able to achieve the best reported accuracy without using specially designed learning algorithms. We empirically identify and disclose important implementation details. We also show that pixel labeling may be simply combined with a detector to boost the detection performance. By adding complementary handcrafted features such as optical flow, the DCNN-based detector can be further improved. We advance the state-of-the-art results by lowering the log-average miss rate from 11.7% to 8.9% on the Caltech data set and from 11.2% to 8.6% on the Inria data set. We also achieve a comparable result to state-of-the-art approaches on the KITTI data set.","","","10.1109/TCSVT.2017.2648850","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7807316","Convolutional feature map (CFM);ensemble model;pedestrian detection","Feature extraction;Detectors;Training;Labeling;Object detection;Proposals;Australia","computer vision;feature extraction;feedforward neural nets;image sequences;object detection;pedestrians;traffic engineering computing","pedestrian detection;computer vision;convolutional neural networks;explicit occlusion handling mechanism;convolutional feature maps;DCNN model;image features;boosted decision models;detection performance;complementary handcrafted features;deep CNN models","","9","50","","","","","IEEE","IEEE Journals"
"A Multiscale and Multidepth Convolutional Neural Network for Remote Sensing Imagery Pan-Sharpening","Q. Yuan; Y. Wei; X. Meng; H. Shen; L. Zhang","School of Geodesy and Geomatics and the Collaborative Innovation Center of Geospatial Technology, Wuhan University, Wuhan, China; Mapping and Remote Sensing, State Key Laboratory of Information Engineering in Surveying, Wuhan University, Wuhan, China; Electrical Engineering and Computer Science, Ningbo University, Ningbo, China; School of Resource and Environmental Science and the Collaborative Innovation Center of Geospatial Technology, Wuhan University, Wuhan, China; Mapping and Remote Sensing, State Key Laboratory of Information Engineering in Surveying, Collaborative Innovation Center of Geospatial Technology, Wuhan University, Wuhan, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2018","11","3","978","989","Pan-sharpening is a fundamental and significant task in the field of remote sensing imagery processing, in which high-resolution spatial details from panchromatic images are employed to enhance the spatial resolution of multispectral (MS) images. As the transformation from low spatial resolution MS image to high-resolution MS image is complex and highly nonlinear, inspired by the powerful representation for nonlinear relationships of deep neural networks, we introduce multiscale feature extraction and residual learning into the basic convolutional neural network (CNN) architecture and propose the multiscale and multidepth CNN for the pan-sharpening of remote sensing imagery. Both the quantitative assessment results and the visual assessment confirm that the proposed network yields high-resolution MS images that are superior to the images produced by the compared state-of-the-art methods.","","","10.1109/JSTARS.2018.2794888","National Key Research and Development Program of China; National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; Natural Science Foundation of Hubei Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8281501","Convolutional neural network (CNN);multiscale feature learning;pan-sharpening;remote sensing","Remote sensing;Machine learning;Feature extraction;Spatial resolution;Convolutional neural networks;Task analysis","correlation methods;feature extraction;feedforward neural nets;geophysical image processing;image classification;image enhancement;image filtering;image resolution;neural net architecture;remote sensing","convolutional neural network architecture;deep neural networks;nonlinear relationships;high-resolution MS image;low spatial resolution MS image;multispectral images;panchromatic images;high-resolution spatial details;remote sensing imagery processing;remote sensing imagery pan-sharpening;multidepth CNN;multiscale CNN;multiscale feature extraction","","21","55","","","","","IEEE","IEEE Journals"
"Image denoising method based on a deep convolution neural network","F. Zhang; N. Cai; J. Wu; G. Cen; H. Wang; X. Chen","Guangdong University of Technology, People's Republic of China; Guangdong University of Technology, People's Republic of China; Guangdong University of Technology, People's Republic of China; Guangdong University of Technology, People's Republic of China; Guangdong University of Technology, People's Republic of China; Guangdong University of Technology, People's Republic of China","IET Image Processing","","2018","12","4","485","493","Image denoising is still a challenging problem in image processing. The authors propose a novel image denoising method based on a deep convolution neural network (DCNN). Different from other learning-based methods, the authors design a DCNN to achieve the noise image. Thus, the latent clear image can be achieved by separating the noise image from the contaminated image. At the training stage, the gradient clipping scheme is employed to prevent gradient explosions and enables the network to converge quickly. Experimental results demonstrate that the proposed denoising method can achieve a better performance compared with the state-of-the-art denoising methods. Also, the results indicate that the denoising method has the ability of suppressing different noises with different noise levels by means of one single denoising model.","","","10.1049/iet-ipr.2017.0389","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8320125","","","convergence of numerical methods;feedforward neural nets;gradient methods;image denoising","image denoising method;deep convolution neural network;DCNN;contaminated image;latent clear image;training stage;gradient clipping scheme;noise levels;single denoising model","","3","","","","","","IET","IET Journals"
"Natural image illuminant estimation via deep non-negative matrix factorisation","X. Liu; G. Zhong; J. Dong","Shandong University of Science and Technology, People's Republic of China; Ocean University of China, People's Republic of China; Ocean University of China, People's Republic of China","IET Image Processing","","2018","12","1","121","125","The influence of environmental light sources affects the colour cast in natural images. In computer vision, biased colours have a significant influence on object recognition and classification. Illuminant estimation aims to eliminate these effects and obtain the image in canonical white light. In this study, the authors propose a deep non-negative matrix factorisation (DeepNMF) method to estimate the illuminant of colour-biased images. DeepNMF deeply factorises the input matrix into multiple layers, separating the image into patches and reshaping each channel of the patch as an [R,G,B] matrix. Based on the diagonal model, they assume that the final layer is the estimated illuminant of each patch. Mean pooling is then used to estimate the illuminant of the overall image. The angular error is used as a metric to test the authors' method on three commonly used colour constancy datasets. The results show that the proposed method is comparable to state-of-the-art methods, although it is simpler to implement. As the proposed method uses a single image as input, it does not require a learning process.","","","10.1049/iet-ipr.2016.1058","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8249687","","","computer vision;image classification;image colour analysis;matrix decomposition","natural image illuminant estimation;deep nonnegative matrix factorisation;environmental light sources;colour cast;computer vision;biased colours;object recognition;object classification;canonical white light;deepNMF method;colour-biased images;input matrix;diagonal model;mean pooling;angular error;colour constancy dataset","","","43","","","","","IET","IET Journals"
"Co-Robust-ADMM-Net: Joint ADMM Framework and DNN for Robust Sparse Composite Regularization","Y. Li; X. Cheng; G. Gui","College of Electronic and Optical Engineering and College of Microelectronics, Nanjing University of Posts and Telecommunications, Nanjing, China; College of Electronic and Optical Engineering and College of Microelectronics, Nanjing University of Posts and Telecommunications, Nanjing, China; College of Telecommunication and Information Engineering, Nanjing University of Posts and Telecommunications, Nanjing, China","IEEE Access","","2018","6","","47943","47952","Symmetric α-stable (SαS) noise is a typical form of impulsive noise often generated in signal measurement and transmission systems. The problem of reconstructing an image from a small number of under-sampled data corrupted by impulsive noise is called robust compressive sensing (CS). In this paper, to effectively suppress the outliers and accurately reconstruct the image from compressive measured data in the presence of SαS noise, a novel composite robust alternating direction method of multiplier network-based CS algorithm is proposed. Specifically, we first employ the L1-norm as the estimator to depress the influence of SαS noise, and then the ADMM framework is employed to address the resulting optimization problem. Moreover, a smoothing strategy is adopted to address the L1-norm based non-smooth optimization problem. To exploit more prior knowledge and image features, a robust composite regularization model is proposed for training by the deep neural network (DNN). In the training phase, the DNN can be utilized to train the samples for the optimal parameters, the optimal shrinkage function and the optimal transform domain, which can be reserved as the network. In the reconstruction process, the obtained network can be employed for improving the reconstruction performance. Experiments show that our proposed algorithm can obtain higher reconstruction Peak signal-to-noise ratio than the existing state-of-the-art robust CS methods.","","","10.1109/ACCESS.2018.2867435","National Natural Science Foundation of China; Jiangsu Specially Appointed Professor; Innovation and Entrepreneurship of Jiangsu High-level Talent; NUPTSF; Nanjing University of Posts and Telecommunications; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8449267","Symmetric$\alpha $-stable noise;compressive sensing;composite regularization model;alternating direction method of multipliers;deep neural network","Optimization;Robustness;Image reconstruction;Transforms;Machine learning;Training;Convex functions","biomedical MRI;compressed sensing;impulse noise;iterative methods;medical image processing;neural nets;optimisation","joint ADMM framework;DNN;robust sparse composite regularization;α-stable noise;impulsive noise;signal measurement;under-sampled data;robust compressive sensing;compressive measured data;SαS noise;novel composite robust alternating direction method;multiplier network-based CS algorithm;smoothing strategy;nonsmooth optimization problem;robust composite regularization model;deep neural network;optimal shrinkage function;optimal transform domain;reconstruction process;robust CS methods","","28","27","","","","","IEEE","IEEE Journals"
"Optimized Hierarchical Cascaded Processing","K. Goetschalckx; B. Moons; S. Lauwereins; M. Andraud; M. Verhelst","Department of Electrical Engineering, ESAT/MICAS, KU Leuven, Leuven, Belgium; Department of Electrical Engineering, ESAT/MICAS, KU Leuven, Leuven, Belgium; Department of Electrical Engineering, ESAT/MICAS, KU Leuven, Leuven, Belgium; Department of Electrical Engineering, ESAT/MICAS, KU Leuven, Leuven, Belgium; Department of Electrical Engineering, ESAT/MICAS, KU Leuven, Leuven, Belgium","IEEE Journal on Emerging and Selected Topics in Circuits and Systems","","2018","8","4","884","894","Recently, there has been an increasing demand for advanced classification capabilities embedded on wearable battery constrained devices, such as smartphones or watches. Achieving such functionality with a tight power and energy budget has proven a real challenge, specifically for large-scale neural network-based applications. Previously, cascaded systems have been proposed to minimize energy consumption for such applications, either through using a single wake-up stage, or by using a linear- or tree based cascade of consecutive classifiers that allow early termination. In this paper, we expand upon these concepts by generalizing cascades to hierarchical cascaded processing, where a hierarchy of increasingly complex classifiers, each designed and trained for a specific subtask is used. This hierarchical approach significantly outperforms the wake-up based approach by up to 2 orders of magnitude in energy consumption at iso-accuracy, specifically in systems with sparse input data such as speech recognition and visual object detection. This paper presents a general design framework for such systems and illustrates how to optimize them toward minimum energy consumption. The text further proposes a roofline model for cascaded systems, derives system level trade-offs and proves the approaches validity through a visual classification case-study.","","","10.1109/JETCAS.2018.2839347","FWO projects; Agentschap voor Innovatie door Wetenschap en Technologie; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8361800","Hierarchical cascaded processing;hierarchical systems;cascaded systems;deep learning;object recognition;ubiquitous computing;hierarchical cascaded processing","Energy consumption;Task analysis;Complexity theory;Classification;Batteries;Circuits and systems;Neural networks","cascade systems;learning (artificial intelligence);multiprocessing systems;neural nets;object detection;optimisation;pattern classification;power aware computing;speech recognition;trees (mathematics);wearable computers","advanced classification capabilities;wearable battery constrained devices;smartphones;energy budget;large-scale neural network-based applications;cascaded systems;single wake-up stage;tree based cascade;consecutive classifiers;early termination;hierarchical cascaded processing;increasingly complex classifiers;wake-up based approach;general design framework;minimum energy consumption;system level trade-offs;visual classification case-study","","","20","","","","","IEEE","IEEE Journals"
"A Multimodal Anomaly Detector for Robot-Assisted Feeding Using an LSTM-Based Variational Autoencoder","D. Park; Y. Hoshi; C. C. Kemp","Healthcare Robotics Lab, Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA; Healthcare Robotics Lab, Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA; Healthcare Robotics Lab, Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA","IEEE Robotics and Automation Letters","","2018","3","3","1544","1551","The detection of anomalous executions is valuable for reducing potential hazards in assistive manipulation. Multimodal sensory signals can be helpful for detecting a wide range of anomalies. However, the fusion of high-dimensional and heterogeneous modalities is a challenging problem for model-based anomaly detection. We introduce a long short-term memory-based variational autoencoder (LSTM-VAE) that fuses signals and reconstructs their expected distribution by introducing a progress-based varying prior. Our LSTM-VAE-based detector reports an anomaly when a reconstruction-based anomaly score is higher than a state-based threshold. For evaluations with 1555 robot-assisted feeding executions, including 12 representative types of anomalies, our detector had a higher area under the receiver operating characteristic curve of 0.8710 than 5 other baseline detectors from the literature. We also show the variational autoencoding and state-based thresholding are effective in detecting anomalies from 17 raw sensory signals without significant feature engineering effort.","","","10.1109/LRA.2018.2801475","NSF; NIDILRR; Google Faculty Research Award; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8279425","Failure detection and recovery;deep learning in robotics and automation;assistive robots","Robot sensing systems;Anomaly detection;Hidden Markov models;Detectors;Decoding;Gaussian distribution","assisted living;handicapped aids;learning (artificial intelligence);manipulators;medical robotics;neural nets;sensor fusion;service robots;signal representation;variational techniques","anomalous executions;potential hazards;assistive manipulation;multimodal sensory signals;high-dimensional modalities;heterogeneous modalities;anomaly detection;short-term memory;variational autoencoder;LSTM-VAE;anomaly score;feeding executions;variational autoencoding;multimodal anomaly detector;signal fusion;baseline detectors;raw sensory signals;long short-term memory-based variational autoencoder;1555 robot-assisted feeding execution;receiver operating characteristic curve;state-based thresholding","","12","36","","","","","IEEE","IEEE Journals"
"Power- and Endurance-Aware Neural Network Training in NVM-Based Platforms","F. Meng; Y. Xue; C. Yang","Department of Electrical and Computer Engineering, University of Delaware, Newark, DE, USA; Department of Electrical and Computer Engineering, University of Delaware, Newark, DE, USA; Department of Electrical and Computer Engineering, University of Delaware, Newark, DE, USA","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","","2018","37","11","2709","2719","Neural networks (NNs) have become the go-to tool for solving many real-world recognition and classification tasks with massive and complex data sets. These networks require large data sets for training, which is usually performed on GPUs and CPUs in either a cloud or edge computing setting. No matter where the training is performed, it is subject to tight power/energy and data storage/transfer constraints. While these issues can be mitigated by replacing SRAM/DRAM with nonvolatile memories (NVMs) which offer near-zero leakage power and high scalability, the massive weight updates performed during training shorten NVM endurance and engender high write energy. In this paper, an NVM-friendly NN training approach is proposed. Weight update is redesigned to reduce bit flips in NVM cells. Moreover, two techniques, namely, filter exchange and bitwise rotation, are proposed to respectively balance writes to different weights and to different bits of one weight. The proposed techniques are integrated and evaluated in Caffe. Experimental results show significant power savings and endurance improvements, while maintaining high inference accuracy.","","","10.1109/TCAD.2018.2858360","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8493526","Deep learning;neural network (NN) training;nonvolatile memory (NVM)","Training;Nonvolatile memory;Artificial neural networks;Optimization;Approximation algorithms;Training data","cloud computing;distributed processing;DRAM chips;graphics processing units;learning (artificial intelligence);microprocessor chips;neural nets;power aware computing;SRAM chips","nonvolatile memories;NVM-friendly NN training approach;NVM cells;endurance-aware neural network training;massive data sets;complex data sets;power savings;cloud computing;power aware neural network training;GPUs;CPUs;edge computing;SRAM-DRAM;bit flips","","","32","","","","","IEEE","IEEE Journals"
"Convolutional Neural Networks Based Fire Detection in Surveillance Videos","K. Muhammad; J. Ahmad; I. Mehmood; S. Rho; S. W. Baik","Intelligent Media Laboratory, Digital Contents Research Institute, Sejong University, Seoul, South Korea; Intelligent Media Laboratory, Digital Contents Research Institute, Sejong University, Seoul, South Korea; Department of Computer Science and Engineering, Sejong University, Seoul, South Korea; Department of Media Software, Sungkyul University, Anyang, South Korea; Intelligent Media Laboratory, Digital Contents Research Institute, Sejong University, Seoul, South Korea","IEEE Access","","2018","6","","18174","18183","The recent advances in embedded processing have enabled the vision based systems to detect fire during surveillance using convolutional neural networks (CNNs). However, such methods generally need more computational time and memory, restricting its implementation in surveillance networks. In this research paper, we propose a cost-effective fire detection CNN architecture for surveillance videos. The model is inspired from GoogleNet architecture, considering its reasonable computational complexity and suitability for the intended problem compared to other computationally expensive networks such as AlexNet. To balance the efficiency and accuracy, the model is fine-tuned considering the nature of the target problem and fire data. Experimental results on benchmark fire datasets reveal the effectiveness of the proposed framework and validate its suitability for fire detection in CCTV surveillance systems compared to state-of-the-art methods.","","","10.1109/ACCESS.2018.2812835","National Research Foundation of Korea (NRF); Korea government (MSIP); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8307064","Fire detection;image classification;real-world applications;deep learning;CCTV video analysis","Fires;Surveillance;Computer architecture;Videos;Color;Feature extraction;Convolution","closed circuit television;computational complexity;computer vision;learning (artificial intelligence);neural nets;object detection;video surveillance","AlexNet;vision based systems;CCTV surveillance systems;benchmark fire datasets;computationally expensive networks;reasonable computational complexity;GoogleNet architecture;cost-effective fire detection CNN architecture;surveillance networks;memory;computational time;embedded processing;surveillance videos;convolutional neural networks","","26","37","","","","","IEEE","IEEE Journals"
"Hybrid LSTM/MaxEnt Networks for Arabic Syntactic Diacritics Restoration","Y. Hifny","University of Helwan, Cairo, Egypt","IEEE Signal Processing Letters","","2018","25","10","1515","1519","Restoring syntactic diacritics is an essential task for Arabic text-to-speech systems. Syntactic diacritic mark is defined as the last diacritic mark of the stem of a whitespace delimited word. It is usually assigned based on the syntax of the Arabic language. In this paper, we formulate the problem as a tagging problem and propose the use of long short-term memory (LSTM) networks to assign the syntactic diacritics for a sentence of Arabic words. These LSTM networks were augmented with sparse direct connections between the input and output layers of the tagger (i.e., maximum entropy (MaxEnt) connections). On the Arabic tree bank task, this hybrid LSTM/MaxEnt approach achieves competitive results to the state-of-the-art systems.","","","10.1109/LSP.2018.2865098","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8433889","Arabic syntactic diacritics restoration;deep learning;long short-term memory (LSTM) networks","Syntactics;Tagging;Feature extraction;Logic gates;Hidden Markov models;Computer aided software engineering;Recurrent neural networks","entropy;learning (artificial intelligence);maximum entropy methods;natural language processing;neural nets;speech synthesis;text analysis","hybrid LSTM/MaxEnt networks;Arabic text-to-speech systems;syntactic diacritic mark;whitespace delimited word;tagging problem;Arabic words;Arabic tree bank task;Arabic language syntax;long short-term memory networks;Arabic syntactic diacritic restoration;maximum entropy connections","","1","38","","","","","IEEE","IEEE Journals"
"Too Far to See? Not Really!—Pedestrian Detection With Scale-Aware Localization Policy","X. Zhang; L. Cheng; B. Li; H. Hu","Beijing Key Laboratory of Digital Media, School of Computer Science and Engineering, and the State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing, China; Bioinformatics Institute, A*STAR, Singapore; Beijing Key Laboratory of Digital Media, School of Computer Science and Engineering, and the State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing, China; Beijing Key Laboratory of Digital Media, School of Computer Science and Engineering, and the State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing, China","IEEE Transactions on Image Processing","","2018","27","8","3703","3715","A major bottleneck of pedestrian detection lies on the sharp performance deterioration in the presence of small-size pedestrians that are relatively far from the camera. Motivated by the observation that pedestrians of disparate spatial scales exhibit distinct visual appearances, we propose in this paper an active pedestrian detector that explicitly operates over multiple-layer neuronal representations of the input still image. More specifically, convolutional neural nets, such as ResNet and faster R-CNNs, are exploited to provide a rich and discriminative hierarchy of feature representations, as well as initial pedestrian proposals. Here each pedestrian observation of distinct size could be best characterized in terms of the ResNet feature representation at a certain layer of the hierarchy. Meanwhile, initial pedestrian proposals are attained by the faster R-CNNs techniques, i.e., region proposal network and follow-up region of interesting pooling layer employed right after the specific ResNet convolutional layer of interest, to produce joint predictions on the bounding-box proposals' locations and categories (i.e., pedestrian or not). This is engaged as an input to our active detector, where for each initial pedestrian proposal, a sequence of coordinate transformation actions is carried out to determine its proper x-y 2D location and the layer of feature representation, or eventually terminated as being background. Empirically our approach is demonstrated to produce overall lower detection errors on widely used benchmarks, and it works particularly well with far-scale pedestrians. For example, compared with 60.51% log-average miss rate of the state-of-the-art MS-CNN for far-scale pedestrians (those below 80 pixels in bounding-box height) of the Caltech benchmark, the miss rate of our approach is 41.85%, with a notable reduction of 18.66%.","","","10.1109/TIP.2018.2818018","National Key Research and Development Program of China; National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; A*STAR JCO; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8328854","Localization policy;sequence of coordinate transformations;deep reinforcement learning;multiple-layer neuronal representations;pedestrian object proposals","Proposals;Benchmark testing;Detectors;Feature extraction;Cameras;Visualization;Task analysis","feature extraction;image classification;image representation;learning (artificial intelligence);neural nets;object detection;pedestrians;traffic engineering computing","scale-aware localization policy;small-size pedestrians;disparate spatial scales;multiple-layer neuronal representations;pedestrian observation;ResNet feature representation;region proposal network;specific ResNet convolutional layer;bounding-box proposals;far-scale pedestrians;pooling layer;active pedestrian detector","","4","54","","","","","IEEE","IEEE Journals"
"When Vehicles See Pedestrians With Phones: A Multicue Framework for Recognizing Phone-Based Activities of Pedestrians","A. Rangesh; M. M. Trivedi","Laboratory for Intelligent and Safe Automobiles, University of California, San Diego, San Diego, CA, USA; Laboratory for Intelligent and Safe Automobiles, University of California, San Diego, San Diego, CA, USA","IEEE Transactions on Intelligent Vehicles","","2018","3","2","218","227","The intelligent vehicle community has devoted considerable efforts to model driver behavior, and in particular, to detect and overcome driver distraction in an effort to reduce accidents caused by driver negligence. However, as the domain increasingly shifts toward autonomous and semiautonomous solutions, the driver is no longer integral to the decision-making process, indicating a need to refocus efforts elsewhere. To this end, we propose to study pedestrian distraction instead. In particular, we focus on detecting pedestrians who are engaged in secondary activities involving their cellphones and similar hand-held multimedia devices from a purely vision-based standpoint. To achieve this objective, we propose a pipeline incorporating articulated human pose estimation, followed by a soft object label transfer from an ensemble of exemplar support vector machines trained on the nearest neighbors in pose feature space. We additionally incorporate head gaze features and prior pose information to carry out cellphone related pedestrian activity recognition. Finally, we offer a method to reliably track the articulated pose of a pedestrian through a sequence of images using a particle filter with a Gaussian process dynamical model, which can then be used to estimate sequentially varying activity scores at a very low computational cost. The entire framework is fast (especially for sequential data) and accurate, and easily extensible to include other secondary activities and sources of distraction.","","","10.1109/TIV.2018.2804170","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8286931","Articulated pose tracking;computer vision;deep learning;exemplar support vector machines (SVMs);highly autonomous vehicles;panoramic surround behavior analysis;pedestrian activity recognition","Legged locomotion;Intelligent vehicles;Pose estimation;Injuries;Head;Activity recognition","computer vision;driver information systems;feature extraction;Gaussian processes;image classification;learning (artificial intelligence);object detection;object recognition;object tracking;particle filtering (numerical methods);pedestrians;pose estimation;road safety;support vector machines","exemplar support vector machines;cellphone related pedestrian activity recognition;Gaussian process dynamical model;activity scores;secondary activities;phone;multicue framework;intelligent vehicle community;driver behavior;driver distraction;driver negligence;autonomous solutions;semiautonomous solutions;decision-making process;pedestrian distraction;human pose estimation;soft object label transfer;head gaze features","","","32","","","","","IEEE","IEEE Journals"
"A Model Combining Stacked Auto Encoder and Back Propagation Algorithm for Short-Term Wind Power Forecasting","R. Jiao; X. Huang; X. Ma; L. Han; W. Tian","School of Control and Computer Engineering, North China Electric Power University, Beijing, China; School of Control and Computer Engineering, North China Electric Power University, Beijing, China; School of Control and Computer Engineering, North China Electric Power University, Beijing, China; School of Control and Computer Engineering, North China Electric Power University, Beijing, China; Electrical and Computer Engineering Department, Illinois Institute of Technology, Chicago, IL, USA","IEEE Access","","2018","6","","17851","17858","Recently, many countries have spent great efforts on wind power generation. Although there have been many methods in the field of wind power forecasting, the persistence statistics model based on historical data is still being challenged due to the randomness and uncontrollability in wind power. Hence, a more accurate and effective wind power forecasting method is still required. In this paper, a new forecasting method is proposed by combining stacked auto-encoders (SAE) and the back propagation (BP) algorithm. First, an SAE with three hidden layers is designed to extract the characteristics from the reference data sequence, and the subsequent loss function is used in the pre-training process to obtain the optimal initial connection weights of the deep network. Second, after adding one output layer to the stacked auto encoders, the BP algorithm is used to fine tune the weights of the whole network. To achieve the best network architecture, the particle swarm optimization is adopted to decide the number of neurons of the hidden layer and the learning rate of each auto encoder. Experimental results show that, for short-term wind power forecasting, the proposed method achieves more stable and effective performance than the existing BP neural network and support vector machines. The improvement in accuracy is 12% on average under different time steps.","","","10.1109/ACCESS.2018.2818108","Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8322127","Machine learning;particle swarm optimization;stacked auto-encoders;wind energy;wind power forecasting","Forecasting;Predictive models;Wind power generation;Neurons;Feature extraction;Training;Wavelet analysis","backpropagation;learning (artificial intelligence);load forecasting;neural nets;particle swarm optimisation;power engineering computing;support vector machines;wind power plants","short-term wind power forecasting;wind power generation;persistence statistics model;back propagation algorithm;BP algorithm;stacked auto encoder;wind power forecasting method;learning rate","","11","30","","","","","IEEE","IEEE Journals"
"Simultaneous Face Detection and Pose Estimation Using Convolutional Neural Network Cascade","H. Wu; K. Zhang; G. Tian","School of Control Science and Engineering, Shandong University, Jinan, China; School of Control Science and Engineering, Shandong University, Jinan, China; School of Control Science and Engineering, Shandong University, Jinan, China","IEEE Access","","2018","6","","49563","49575","Recent studies show that convolutional neural networks (CNNs) has made a series of breakthroughs in the two tasks of face detection and pose estimation, respectively. There are two CNN frameworks for solving these two integrated tasks simultaneously. One is to use face detection network to detect faces firstly, and then use pose estimation network to estimate each face's pose; the other is to use region proposal algorithm to generate many candidate regions that may contain faces, and then use a single deep multi-task CNN to process these regions for simultaneous face detection and pose estimation. The former's problem is pose estimation's performance is affected by face detection network because two networks are separate. The latter generates lots of candidate regions, which will bring huge computation cost to CNN and can't achieve real-time. To solve the above existing problems, we propose a multi-task CNN cascade framework that integrates these two tasks. We show that multi-task learning of face detection and head pose estimation helps to extract more representative features. We exploit CNN feature fusion strategy to further improve head pose estimation's performance. We evaluate face detection on FDDB benchmark, and evaluate pose estimation on AFW benchmark. Our method achieves comparative result compared with state-of-the-art in these two tasks and can achieve real-time performance.","","","10.1109/ACCESS.2018.2869465","National Natural Science Foundation of China; Natural Science Foundation of Shandong Province; Shandong Major Research Plan Project; Taishan Scholars Program of Shandong Province; Spring City Industry Leading Talent Support Program of Jinan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8458127","Face detection;pose estimation;CNN cascade;multi-task learning;feature fusion","Face detection;Pose estimation;Face;Task analysis;Real-time systems;Feature extraction","convolution;face recognition;feature extraction;feedforward neural nets;learning (artificial intelligence);pose estimation","convolutional neural network cascade;convolutional neural networks;face detection network;pose estimation network;region proposal algorithm;multitask learning;head pose estimation;face detection;feature extraction;FDDB benchmark;multitask CNN cascade","","5","64","","","","","IEEE","IEEE Journals"
"PROVID: Progressive and Multimodal Vehicle Reidentification for Large-Scale Urban Surveillance","X. Liu; W. Liu; T. Mei; H. Ma","Beijing Key Laboratory of Intelligent Telecommunication Software and Multimedia, Beijing University of Posts and Telecommunications, Beijing, China; Beijing Key Laboratory of Intelligent Telecommunication Software and Multimedia, Beijing University of Posts and Telecommunications, Beijing, China; Microsoft Research Asia, Beijing, China; Beijing Key Laboratory of Intelligent Telecommunication Software and Multimedia, Beijing University of Posts and Telecommunications, Beijing, China","IEEE Transactions on Multimedia","","2018","20","3","645","658","Compared with person reidentification, which has attracted concentrated attention, vehicle reidentification is an important yet frontier problem in video surveillance and has been neglected by the multimedia and vision communities. Since most existing approaches mainly consider the general vehicle appearance for reidentification while overlooking the distinct vehicle identifier, such as the license plate number, they attain suboptimal performance. In this paper, we propose PROVID, a PROgressive Vehicle re-IDentification framework based on deep neural networks. In particular, our framework not only utilizes the multimodality data in large-scale video surveillance, such as visual features, license plates, camera locations, and contextual information, but also considers vehicle reidentification in two progressive procedures: coarse-to-fine search in the feature domain, and near-to-distant search in the physical space. Furthermore, to evaluate our progressive search framework and facilitate related research, we construct the VeRi dataset, which is the most comprehensive dataset from real-world surveillance videos. It not only provides large numbers of vehicles with varied labels and sufficient cross-camera recurrences but also contains license plate numbers and contextual information. Extensive experiments on the VeRi dataset demonstrate both the accuracy and efficiency of our progressive vehicle reidentification framework.","","","10.1109/TMM.2017.2751966","National Key Research and Development Plan; Funds for Creative Research Groups of China; National Natural Science Foundation of China; Beijing Training Project for the Leading Talents in S&T; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8036238","Progressive search;vehicle re-identification;deep learning;license plate verification;contextual information","Licenses;Cameras;Image color analysis;Spatiotemporal phenomena;Multimedia communication;Video surveillance","computer vision;feature extraction;image recognition;image representation;neural nets;object detection;video surveillance","progressive search framework;license plate number;contextual information;progressive vehicle reidentification framework;PROVID;large-scale urban surveillance;distinct vehicle identifier;large-scale video surveillance;multimodal data;deep neural networks;camera locations;coarse-to-fine search;feature domain;near-to-distant search;physical space;VeRi dataset;vision features","","19","42","","","","","IEEE","IEEE Journals"
"Ultrasound Image Enhancement Using Structure Oriented Adversarial Network","D. Mishra; S. Chaudhury; M. Sarkar; A. S. Soin","Department of Electrical Engineering, Indian Institute of Technology Delhi, New Delhi, India; Department of Electrical Engineering, Indian Institute of Technology Delhi, New Delhi, India; Department of Electrical Engineering, Indian Institute of Technology Delhi, New Delhi, India; Medanta Hospital, Gurugram, India","IEEE Signal Processing Letters","","2018","25","9","1349","1353","In this letter, we aim to develop a deep adversarial despeckling approach to enhance the quality of ultrasound images. Most of the existing approaches target a complete removal of speckle, which produces oversmooth outputs and results in loss of structural details. In contrast, the proposed approach reduces the speckle extent without altering the structural and qualitative attributes of the ultrasound images. A despeckling residual neural network (DRNN) is trained with an adversarial loss imposed by a discriminator. The discriminator tries to differentiate between the despeckled images generated by the DRNN and the set of high-quality images. Further to prevent the developed network from oversmoothing, a structural loss term is used along with the adversarial loss. Experimental evaluations show that the proposed DRNN outperforms the state-of-the-art despeckling approaches in terms of the structural similarity index measure, peak signal to noise ratio, edge preservation index, and speckle region's signal to noise ratio.","","","10.1109/LSP.2018.2858147","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8417930","Deep learning;generative adversarial network (GAN);ultrasound image;speckle","Speckle;Training;Gallium nitride;Convolutional codes;Convolution;Generators;Probes","biomedical ultrasonics;image denoising;image enhancement;medical image processing;neural nets;speckle","ultrasound image enhancement;deep adversarial despeckling approach;speckle extent;structural attributes;qualitative attributes;despeckling residual neural network;DRNN;adversarial loss;despeckled images;high-quality images;structural loss term;structure oriented adversarial network","","2","41","","","","","IEEE","IEEE Journals"
"Capturing Drivers’ Lane Changing Behaviors on Operational Level by Data Driven Methods","L. Huang; H. Guo; R. Zhang; H. Wang; J. Wu","School of Civil Engineering and Transportation, South China University of Technology, Guangzhou, China; School of Civil Engineering and Transportation, South China University of Technology, Guangzhou, China; School of Intelligent Systems Engineering, Sun Yat-sen University, Guangzhou, China; School of Civil Engineering and Transportation, South China University of Technology, Guangzhou, China; Department of Civil Engineering, Tsinghua University, Beijing, China","IEEE Access","","2018","6","","57497","57506","With the development of autonomous vehicles, advanced driver-assistance systems, and vehicular social networks, the requirement for vehicle trajectory prediction in lane changing is higher. Here, we propose a neural-network-based operational level lane-changing model using data-driven methods. First, we determine the inputs of the lane-changing model by analyzing the influence factors of the lanechanging behavioral model under the framework of the social force theory. The main influencing factors include the temporal destination, the historical trajectories of the lane-changing vehicle, and the relative distance between the surrounding vehicles in our lane-changing model. Our lane-changing model is built by deep neural networks (DNNs). Then, we determine the suitable network structure and other parameters by empirical data for the DNN. Finally, tests on empirical lane-changing trajectory data sets show that the operational level lane-changing model built by DNN is promising.","","","10.1109/ACCESS.2018.2873942","Guangdong Science and Technology Department; National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; Fundamental Research Funds for Guangdong Communication Polytechnic; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8481492","Lane change;simulation;deep learning;neural network;recurrent neural network (RNN);social force;vehicular social networks (VSN)","Trajectory;Analytical models;Vehicles;Data models;Numerical models;Neural networks","driver information systems;neural nets;road traffic;road vehicles;social networking (online);traffic engineering computing","data driven methods;autonomous vehicles;advanced driver-assistance systems;vehicular social networks;vehicle trajectory prediction;data-driven methods;lane-changing vehicle;lane changing behavioral model;operational level lane changing model;social force theory;deep neural networks;DNN","","2","44","CCBY","","","","IEEE","IEEE Journals"
"Fully Convolutional Networks for Semantic Segmentation of Very High Resolution Remotely Sensed Images Combined With DSM","W. Sun; R. Wang","Department of Geomatics Engineering, University of Calgary, Calgary, AB, Canada; Department of Geomatics Engineering, University of Calgary, Calgary, AB, Canada","IEEE Geoscience and Remote Sensing Letters","","2018","15","3","474","478","Recently, approaches based on fully convolutional networks (FCN) have achieved state-of-the-art performance in the semantic segmentation of very high resolution (VHR) remotely sensed images. One central issue in this method is the loss of detailed information due to downsampling operations in FCN. To solve this problem, we introduce the maximum fusion strategy that effectively combines semantic information from deep layers and detailed information from shallow layers. Furthermore, this letter develops a powerful backend to enhance the result of FCN by leveraging the digital surface model, which provides height information for VHR images. The proposed semantic segmentation scheme has achieved an overall accuracy of 90.6% on the ISPRS Vaihingen benchmark.","","","10.1109/LGRS.2018.2795531","Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8281008","Fully convolutional networks (FCN);deep learning;semantic segmentation;remote sensing;very high resolution (VHR)","Semantics;Image segmentation;Remote sensing;Color;Image resolution;Convolution;Benchmark testing","geophysical image processing;image classification;image resolution;image segmentation;remote sensing","fully convolutional networks;state-of-the-art performance;downsampling operations;maximum fusion strategy;semantic information;deep layers;height information;VHR images;semantic segmentation scheme;high resolution remotely sensed images;shallow layers","","6","19","","","","","IEEE","IEEE Journals"
"CREAM: CNN-REgularized ADMM Framework for Compressive-Sensed Image Reconstruction","C. Zhao; J. Zhang; R. Wang; W. Gao","School of Electronic and Computer Engineering, Peking University Shenzhen Graduate School, Shenzhen, China; School of Electronic and Computer Engineering, Peking University Shenzhen Graduate School, Shenzhen, China; School of Electronic and Computer Engineering, Peking University Shenzhen Graduate School, Shenzhen, China; School of Electronics Engineering and Computer Science, Peking University, Beijing, China","IEEE Access","","2018","6","","76838","76853","Compressive sensing (CS) has drawn an enormous amount of attention in recent years due to its sub-Nyquist sampling rate and low-complexity requirement at the encoder. However, it turns out that the decoder in lieu of the encoder suffers from heavy computation in order to decently recover the signal from its CS measurements. With the aim of developing a fast yet accurate algorithm, in this paper, we propose to leverage a deep convolutional neural network (CNN) prior model to the constrained CS reconstruction formulation and solve it via the alternating direction method of multipliers (ADMM). The proposed CNN-REgularized ADMM framework, dubbed CREAM, is able to recover image signals from CS measurements effectively and efficiently. On the one hand, the developed constrained CS formulation by CREAM enables fewer regularization parameters and less computational complexity compared with traditional unconstrained CS formulation by ADMM. On the other hand, rather than training a neural network from scratch, an off-theshelf CNN model is directly incorporated into CREAM even without the effort of fine tuning, in which CNN has exhibited its desirable reconstruction performance and low computational complexity. Hereby, powerful GPU can be utilized to speed up the reconstruction. Experiments demonstrate that our proposed method for CS reconstruction of natural images surpasses state-of-the-art CS models by a significant margin in speed and performance.","","","10.1109/ACCESS.2018.2882990","National Postdoctoral Program for Innovative Talents; Natural Science Foundation of Guangdong Province; Shenzhen Peacock Plan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8543575","Compressive sensing;deep learning;alternate direction method of multipliers (ADMM);convolutional neural network (CNN);image reconstruction","Convex functions;Image reconstruction;Computational modeling;Adaptation models;Compressed sensing;Computational complexity","compressed sensing;computational complexity;convolutional neural nets;image reconstruction;image sampling","sub-Nyquist sampling rate;low-complexity requirement;CS measurements;deep convolutional neural network;constrained CS reconstruction formulation;alternating direction method;image signals;compressive-sensed image reconstruction;CREAM;CNN model;computational complexity;natural images;CNN-regularized ADMM framework;unconstrained CS formulation","","","47","","","","","IEEE","IEEE Journals"
"Phonetic Temporal Neural Model for Language Identification","Z. Tang; D. Wang; Y. Chen; L. Li; A. Abel","Institute of Computer Applications, University of Chinese Academy of Sciences, Chinese Academy of Sciences, Beijing, China; Tsinghua National Laboratory for Information Science and Technology and the Center for Speech and Language Technologies, Tsinghua University, Beijing, China; Tsinghua National Laboratory for Information Science and Technology and the Center for Speech and Language Technologies, Tsinghua University, Beijing, China; Tsinghua National Laboratory for Information Science and Technology and the Center for Speech and Language Technologies, Tsinghua University, Beijing, China; Department of Computer Science and Software Engineering, Xi’an Jiaotong-Liverpool University, Suzhou, China","IEEE/ACM Transactions on Audio, Speech, and Language Processing","","2018","26","1","134","144","Deep neural models, particularly the long short-term memory recurrent neural network (LSTM-RNN) model, have shown great potential for language identification (LID). However, the use of phonetic information has been largely overlooked by most existing neural LID methods, although this information has been used very successfully in conventional phonetic LID systems. We present a phonetic temporal neural model for LID, which is an LSTM-RNN LID system that accepts phonetic features produced by a phone-discriminative DNN as the input, rather than raw acoustic features. This new model is similar to traditional phonetic LID methods, but the phonetic knowledge here is much richer: It is at the frame level and involves compacted information of all phones. Our experiments conducted on the Babel database and the AP16-OLR database demonstrate that the temporal phonetic neural approach is very effective, and significantly outperforms existing acoustic neural models. It also outperforms the conventional i-vector approach on short utterances and in noisy conditions.","","","10.1109/TASLP.2017.2764271","National Natural Science Foundation of China; National Basic Research Program (973 Program) of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8070977","Language identification;deep neural networks;multi-task learning","Speech;Acoustics;Hidden Markov models;Probabilistic logic;Recurrent neural networks;Speech processing","recurrent neural nets;speech processing","phonetic temporal neural model;language identification;deep neural models;short-term memory recurrent neural network model;phonetic information;conventional phonetic LID systems;LSTM-RNN LID system;phonetic features;traditional phonetic LID methods;phonetic knowledge;temporal phonetic neural approach;acoustic neural models;neural LID methods","","4","45","Traditional","","","","IEEE","IEEE Journals"
"Accelerating Convolutional Neural Network With FFT on Embedded Hardware","T. Abtahi; C. Shea; A. Kulkarni; T. Mohsenin","Department of Computer Science & Electrical Engineering, University of Maryland at Baltimore County, Baltimore, MD, USA; Department of Computer Science & Electrical Engineering, University of Maryland at Baltimore County, Baltimore, MD, USA; Department of Computer Science & Electrical Engineering, University of Maryland at Baltimore County, Baltimore, MD, USA; Department of Computer Science & Electrical Engineering, University of Maryland at Baltimore County, Baltimore, MD, USA","IEEE Transactions on Very Large Scale Integration (VLSI) Systems","","2018","26","9","1737","1749","Fueled by ImageNet Large Scale Visual Recognition Challenge and Common Objects in Context competitions, the convolutional neural network (CNN) has become important in computer vision and natural language processing. However, state-of-the-art CNNs are computationally memory-intensive, thus energy-efficient implementation on the embedded platform is challenging. Recently, VGGNet and ResNet showed that deep neural networks with more convolution layers and a few fully connected layers can achieve lower error rates, thus reducing the complexity of convolution layers is of utmost importance. In this paper, we evaluate three variations of convolutions, including direct convolution (Direct-Conv), fast Fourier transform (FFT)based convolution (FFT-Conv), and FFT overlap and add convolution (FFT-OVA-Conv) in terms of computation complexity and memory storage requirements for popular CNN networks in embedded hardware. We implemented these three techniques for ResNet-20 with the CIFAR-10 data set on a low-power domain-specific many-core architecture called power-efficient nanoclusters (PENCs), NVIDIA Jetson TX1 graphics processing unit (GPU), ARM Cortex A53 CPU, and SPARse Convolutional NETwork (SPARCNet) accelerator on Zynq 7020 FPGA to explore the tradeoff between software and hardware implementation, domain-specific logic and instructions, as well as various parallelism across different architectures. Results are evaluated and compared with respect to throughput per layer, energy consumption, and execution time for the three methods. SPARCNet deployed on Zynq FPGA achieved 42-ms runtime with 135-mJ energy consumption with a 10.8-MB/s throughput per layer using FFT-Conv for ResNet-20. Using built-in FFT instruction in PENC, the FFT-OVA-Conv performs 2.9 × and 1.65 × faster and achieves 6.8 × and 2.5 × higher throughput per watt than Direct-Conv and FFT-Conv. In ARM A53 CPU, FFT-OVA-Conv achieves 3.36 × and 1.38 × improvement in execution time and 2.72 × and 1.32 × higher throughput than DirectConv and FFT-Conv. In TX1 GPU, FFT-Conv is 1.9 × faster, 2.2 × more energy-efficient, and achieves 5.6 × higher throughput per layer than Direct-Conv. PENC is 10916 × and 1.8 × faster and 5053 × and 4.3 × more energy-efficient and achieves 7.5 × and 1.2 × higher throughput per layer than ARM A53 CPU and TX1 GPU, respectively.","","","10.1109/TVLSI.2018.2825145","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8392465","Convolutional neural network (CNN);deep learning;domain-specific many-core accelerator;energy-efficient;FFT overlap and add;field-programmable gate array (FPGA);graphics processing unit (GPU)","Convolution;Graphics processing units;Computer architecture;Throughput;Hardware;Field programmable gate arrays;Neurons","computer vision;convolution;fast Fourier transforms;feedforward neural nets;field programmable gate arrays;graphics processing units;multiprocessing systems","FFT-Conv;Direct-Conv;embedded hardware;energy-efficient implementation;deep neural networks;convolution layers;fully connected layers;direct convolution;computation complexity;ResNet-20;NVIDIA Jetson TX1 graphics processing unit;SPARse Convolutional NETwork accelerator;Zynq 7020 FPGA;FFT instruction;DirectConv;convolutional neural network acceleration;CNN networks;fast Fourier transform based convolution;FFT overlap-and-add convolution;CIFAR-10 data set;low-power domain-specific many-core architecture;power-efficient nanoclusters;PENC;GPU;ARM Cortex A53 CPU;FFT-OVA-Conv;ImageNet Large Scale Visual Recognition Challenge and Common Objects;computer vision;natural language processing;VGGNet","","6","44","","","","","IEEE","IEEE Journals"
"Dense Convolutional Binary-Tree Networks for Lung Nodule Classification","Y. Liu; P. Hao; P. Zhang; X. Xu; J. Wu; W. Chen","State Key Laboratory of CAD and CG, Zhejiang University, Hangzhou, China; School of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China; School of Economics and Management, Tongji University, Shanghai, China; Thoracic Surgery of Shanghai Pulmonary Hospital, Tongji University, Shanghai, China; Real Doctor AI Research Centre, Zhejiang University, Hangzhou, China; State Key Laboratory of CAD and CG, Zhejiang University, Hangzhou, China","IEEE Access","","2018","6","","49080","49088","This paper investigates the problem of benign or malignant diagnosis of pulmonary nodule with original thoracic computed tomography images, and presents a novel end-to-end deep learning architecture named dense convolutional binary-tree network (DenseBTNet). Besides introducing center-crop operation into the DenseNet, the DenseBTNet splits isolated transition layers of the DenseNet and merges them with dense blocks, then adjusts feature-maps transition mode to compact the model. The DenseBTNet has several compelling advantages: 1) the DenseBTNet not only preserves densely connected mechanism of the DenseNet to extract features of lung nodules in different level, but also further reinforces this mechanism to a level of dense blocks and enriches multi-scale features and 2) The DenseBTNet owns high parameter-efficiency and is lightweight in the scale of parameters as well. Experimental results show that the DenseBTNet largely boosts the performance of the DenseNet and achieves higher accuracies on the task of lung nodule classification in comparison with state-of-the-art approaches.","","","10.1109/ACCESS.2018.2865544","National Natural Science Foundation of China; Natural Science Foundation of Zhejiang Province; Ministry of Education of the People's Republic of China; Zhejiang University; Shen Kang’s three year action plan; Real Doctor AI Research Center, Zhejiang University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8451868","Lung nodule classification;computed tomography (CT) imaging;densely connected convolutional networks","Lung;Computed tomography;Task analysis;Feature extraction;Agriculture;Support vector machines;Convolution","computerised tomography;convolution;feature extraction;feedforward neural nets;image classification;learning (artificial intelligence);lung;medical image processing;trees (mathematics)","dense convolutional binary-tree networks;lung nodule classification;benign diagnosis;malignant diagnosis;pulmonary nodule;original thoracic computed tomography images;end-to-end deep learning architecture;DenseBTNet;center-crop operation;transition layers;dense blocks;feature-maps transition mode;densely connected mechanism;feature extraction;multi-scale features;multiscale features","","5","27","","","","","IEEE","IEEE Journals"
"Manufacturing Execution System Specific Data Analysis-Use Case With a Cobot","D. Mitrea; L. Tamas","Computer Science Department, Technical University of Cluj-Napoca, Cluj-Napoca, Romania; Computer Science Department, Technical University of Cluj-Napoca, Cluj-Napoca, Romania","IEEE Access","","2018","6","","50245","50259","The purpose of this research is to analyze and upgrade the performances of the Baxter intelligent robot, through data mining methods. The case study belongs to the robotics domain, being integrated in the context of manufacturing execution systems and product lifecycle management, aiming to overcome the lack of vertical integration inside a company. The explored data comprises the parameters registered during the activities of the Baxter intelligent robot, as, for example, the movement of the left or right arm. First, the state of the art concerning the data mining methods is presented, and then the solution is detailed by describing the data mining techniques. The final purpose was that of improving the speed and robustness of the robot in the production. Specific techniques and sometimes their combinations are experimented and assessed, in order to perform root cause analysis, then powerful classifiers and metaclassifiers, as well as deep learning methods, in optimum configuration, are analyzed for prediction. The experimental results are described and discussed in details, then the conclusions and further development possibilities are formulated. Based on the experiments, important relationships among the robot parameters were discovered, the obtained accuracy for predicting the target variables being always above 96%.","","","10.1109/ACCESS.2018.2869346","Ministerul Educației și Cercetării Științifice; Hungarian Research Fund; Magyar Tudományos Akadémia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8457197","Intelligent manufacturing systems;data mining;prediction models;intelligent robots;industry applications","Data mining;Robots;Manufacturing;Production;Optimization;Data analysis;Predictive maintenance","control engineering computing;data analysis;data mining;industrial robots;intelligent robots;learning (artificial intelligence);manufacturing systems;product life cycle management;production engineering computing","Baxter intelligent robot;data mining methods;Cobot;data analysis;manufacturing execution system;robot parameters;deep learning methods;root cause analysis;data mining techniques;product lifecycle management","","","34","","","","","IEEE","IEEE Journals"
"Artificial Intelligence for Detecting Media Piracy","M. Stolikj; D. Jarnikov; A. Wajs","NA; NA; NA","SMPTE Motion Imaging Journal","","2018","127","6","22","27","Pay TV has evolved from a walled garden, set-top box model to include online services. Although there are numerous operator and consumer benefits that result from this shift, it also opens up tremendous piracy threats that are a nightmare to control. The sheer volume of information being shared in a more open environment means that manpower alone is insufficient to process and detect threats effectively. As artificial intelligence (AI) technology develops in the media space, its application in security must focus on more than closing gaps and locking down assets. Security threats must be spotted and managed faster and more efficiently, before a security instance even occurs. In this paper, we explain how to leverage AI to fight piracy by using content monitoring solutions that search and identify pirated content on the internet. At the core of this technology is an AI-powered computer vision system that identifies the original source of distributed content based on the visual information present in the image (e.g., broadcaster logo). We cover practical issues around building such a system, including its workflow, training, and performance.In this paper, we explain how to leverage AI to fight piracy by using content monitoring solutions that search and identify pirated content on the internet.","","","10.5594/JMI.2018.2827181","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8395449","Artificial intelligence;deep learning;logo recognition;media","","","","","","16","","","","","SMPTE","SMPTE Journals"
"Relation Classification via LSTMs Based on Sequence and Tree Structure","Y. Dai; W. Guo; X. Chen; Z. Zhang","College of Mathematics and Computer Sciences, Fuzhou University, Fuzhou, China; College of Mathematics and Computer Sciences, Fuzhou University, Fuzhou, China; College of Mathematics and Computer Sciences, Fuzhou University, Fuzhou, China; College of Mathematics and Computer Sciences, Fuzhou University, Fuzhou, China","IEEE Access","","2018","6","","64927","64937","The goal of relation classification is to recognize the relationship between two marked entities in a sentence. It is a crucial constituent in natural language processing. Up till the present moment, most previous neural network models for this task either focus on using the handcrafted syntactic features or learning semantic representations of raw word sequences, they have no capacity for encoding the whole sentence representation including syntax and semantic information. In general, information of syntax and semantics can both have significant effect on classifying relation. Based on this idea, we propose a novel two-channel neural network architecture with attention mechanism in the paper to handle this task. First, we employ bidirectional sequence long short-term memory (LSTM) channel to capture the semantic information and acquire syntactic knowledge by utilizing tree structure LSTM channel. Second, sentence-level attention mechanism for word sequences is used to determine which parts of the sentence are most influential component. Eventually, we conduct experiments on two real-world datasets: the Wikipedia and the SemEval2010 Task8 dataset. The experimental results on datasets demonstrate that our method can make better use of the information contained in sentences and achieves impressive improvements on relation classification as compared with the existing methods.","","","10.1109/ACCESS.2018.2877934","National Key R&D Program of China; Guiding Project of Fujian Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8509590","Relation classification;deep neural network;two channels architecture;attention mechanism;tree structure LSTM","Syntactics;Neural networks;Semantics;Task analysis;Feature extraction;Natural language processing;Tools","learning (artificial intelligence);natural language processing;natural languages;neural nets;pattern classification;text analysis;trees (mathematics)","learning semantic representations;raw word sequences;sentence representation including syntax;semantic information;classifying relation;two-channel neural network architecture;bidirectional sequence;syntactic knowledge;LSTM channel;sentence-level attention mechanism;SemEval2010 Task8 dataset;relation classification;tree structure;marked entities;crucial constituent;natural language processing;previous neural network models;handcrafted syntactic features","","1","49","","","","","IEEE","IEEE Journals"
"A Neural Architecture for Bayesian Compressive Sensing Over the Simplex via Laplace Techniques","S. Limmer; S. Stańczak","Network-Information Theory Group, Technical University of Berlin, Berlin, Germany; Wireless Communications and Networks Department, Fraunhofer Heinrich Hertz Institute, Berlin, Germany","IEEE Transactions on Signal Processing","","2018","66","22","6002","6015","This paper presents a theoretical and conceptual framework to design neural architectures for Bayesian compressive sensing of simplex-constrained sparse stochastic vectors. First, we recast the problem of MMSE estimation (w.r.t. a pre-defined uniform input distribution over the simplex) as the problem of computing the centroid of a polytope that is equal to the intersection of the simplex and an affine subspace determined by compressive measurements. Then, we use multidimensional Laplace techniques to obtain a closed-form solution to this computation problem, and we show how to map this solution to a neural architecture comprising threshold functions, rectified linear (ReLU) and rectified polynomial activation functions. In the proposed architecture, the number of layers is equal to the number of measurements that allows for faster solutions in the low-measurement regime when compared to the integration by domain decomposition or Monte Carlo approximation. We also show by simulation that the proposed solution is robust to small model mismatches; furthermore, the proposed architecture yields superior approximations with less parameters when compared to a standard ReLU architecture in a supervised learning setting.","","","10.1109/TSP.2018.2873548","Deutsche Forschungsgemeinschaft; German Ministry of Research and Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8478823","Sparse recovery;bayesian compressed sensing;neural architectures;deep neural networks;convex geometry","Computer architecture;Bayes methods;Standards;Neural networks;Compressed sensing;Approximation algorithms;Iterative methods","Bayes methods;compressed sensing;Laplace equations;learning (artificial intelligence);neural nets;stochastic processes;vectors","supervised learning;polytope centroid;model mismatch;rectified polynomial activation functions;rectified linear function;threshold functions;neural architecture;uniform input distribution;computation problem;closed-form solution;multidimensional Laplace techniques;compressive measurements;affine subspace;MMSE estimation;simplex-constrained sparse stochastic vectors;Bayesian compressive sensing","","1","49","","","","","IEEE","IEEE Journals"
"Cloud and cloud shadow detection using multilevel feature fused segmentation network","Z. Yan; M. Yan; H. Sun; K. Fu; J. Hong; J. Sun; Y. Zhang; X. Sun","School of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences, Beijing, China; Key Laboratory of Technology in Geo-Spatial Information Processing and Application System, Institute of Electronics, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Technology in Geo-Spatial Information Processing and Application System, Institute of Electronics, Chinese Academy of Sciences, Beijing, China; School of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences, Beijing, China; Key Laboratory of Technology in Geo-Spatial Information Processing and Application System, Institute of Electronics, Chinese Academy of Sciences, Beijing, China; School of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences, Beijing, China; Key Laboratory of Technology in Geo-Spatial Information Processing and Application System, Institute of Electronics, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Technology in Geo-Spatial Information Processing and Application System, Institute of Electronics, Chinese Academy of Sciences, Beijing, China","IEEE Geoscience and Remote Sensing Letters","","2018","15","10","1600","1604","Cloud and cloud shadow detection in remote sensing imagery is important for its wide range of applications. Traditionally, the detection is usually based on the manually designed thresholds from multiband, which is complicated and of multistage. To simplify the process of cloud and cloud shadow detection and improve the performance, we propose a multilevel feature fused segmentation network (MFFSNet), which can be trained end-to-end without any hand-tuned parameters. Specifically, a fully convolutional network is proposed for cloud and cloud shadow features learning. Then, we utilize a novel pyramid pooling module to extract contextual relation between cloud and shadow. Furthermore, a special multilevel feature fused structure is designed to combine semantic information with spatial information from different levels, so that we can better handle the multiscale objects and produce detailed segmentation boundaries. Experiments show that the MFFSNet outperforms the state-of-the-art methods and achieves high accuracies of 98.69% and 98.92% for cloud and cloud shadow detection.","","","10.1109/LGRS.2018.2846802","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8401847","Cloud detection;cloud shadow;deep convolutional network;multilevel feature fusion","Clouds;Feature extraction;Task analysis;Image segmentation;Semantics;Remote sensing","feature extraction;geophysical image processing;image segmentation;learning (artificial intelligence);remote sensing","cloud shadow detection;multilevel feature;MFFSNet;multilevel feature fused segmentation network;cloud shadow feature learning","","6","19","","","","","IEEE","IEEE Journals"
"Full-GRU Natural Language Video Description for Service Robotics Applications","S. Cascianelli; G. Costante; T. A. Ciarfuglia; P. Valigi; M. L. Fravolini","Department of Engineering, University of Perugia, Perugia, Italy; Department of Engineering, University of Perugia, Perugia, Italy; Department of Engineering, University of Perugia, Perugia, Italy; Department of Engineering, University of Perugia, Perugia, Italy; Department of Engineering, University of Perugia, Perugia, Italy","IEEE Robotics and Automation Letters","","2018","3","2","841","848","Enabling effective human-robot interaction is crucial for any service robotics application. In this context, a fundamental aspect is the development of a user-friendly human-robot interface, such as a natural language interface. In this letter, we investigate the robot side of the interface, in particular the ability to generate natural language descriptions for the scene it observes. We achieve this capability via a deep recurrent neural network architecture completely based on the gated recurrent unit paradigm. The robot is able to generate complete sentences describing the scene, dealing with the hierarchical nature of the temporal information contained in image sequences. The proposed approach has fewer parameters than previous state-of-the-art architectures, thus it is faster to train and smaller in memory occupancy. These benefits do not affect the prediction performance. In fact, we show that our method outperforms or is comparable to previous approaches in terms of quantitative metrics and qualitative evaluation when tested on benchmark publicly available datasets and on a new dataset we introduce in this letter.","","","10.1109/LRA.2018.2793345","NVIDIA Corporation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8258893","Cognitive human-robot interaction;visual learning","Robots;Computer architecture;Natural languages;Video sequences;Logic gates;Encoding;Feature extraction","human-robot interaction;image sequences;learning (artificial intelligence);mobile robots;natural language interfaces;neural net architecture;recurrent neural nets;robot vision;service robots;video signal processing","natural language interface;deep recurrent neural network architecture;gated recurrent unit paradigm;qualitative evaluation;quantitative metrics;image sequences;temporal information;user-friendly human-robot interface;human-robot interaction;service robotic application;full-GRU natural language video description","","3","28","","","","","IEEE","IEEE Journals"
"Efficient Detection of Soft Concatenation Mapping","H. LIU; J. Xiao; H. Tan; Q. Luo; J. Zhao; L. M. Ni","Business Intelligence Lab, Baidu Research, National Engineering Laboratory of Deep Learning Technology and Application, Beijing, China; Services Computing Technology and System Lab, School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, Hubei, China; Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Clear Water Bay, Hong Kong, China; Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Clear Water Bay, Hong Kong, China; UnionPay Inc., Shanghai, China; University of Macau, Avenida da Universidade, Taipa, Macau, China","IEEE Transactions on Knowledge and Data Engineering","","2018","30","11","2106","2119","In modern big data warehouse systems, we observe a common phenomenon that a column of data values can be derived from one or several other columns by transforming and concatenating these columns. We call this relationship between columns a Soft Concatenation Mapping (SCM). SCMs imply significant redundancy in the schema or data, and therefore can be exploited for data integration or data compression. In this paper, we formalize the problem of SCM detection and prove it is NP-hard. We then propose efficient approximate algorithms to detect all SCMs or an optimal set of SCMs in a table. Our experiments on both real-world and synthetic datasets show promising results.","","","10.1109/TKDE.2018.2812822","National Key Basic Research and Development Program of China (973); University of Macau; NSFC; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8307189","Big data management;data profiling;soft concatenation mapping","Data warehouses;Redundancy;Data integration;Data compression;Approximation algorithms;Electronic mail;Task analysis","approximation theory;Big Data;data compression;data integration;data warehouses","efficient approximate algorithms;soft concatenation mapping;modern big data warehouse systems;data values;data integration;SCM detection;data compression","","1","38","","","","","IEEE","IEEE Journals"
"A Limb-Based Graphical Model for Human Pose Estimation","G. Liang; X. Lan; J. Wang; J. Wang; N. Zheng","Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China; Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China; Institute for Deep Learning, Baidu, Sunnyvale, CA, USA; Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China; Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University, Xi’an, China","IEEE Transactions on Systems, Man, and Cybernetics: Systems","","2018","48","7","1080","1092","Modeling the relationship among human joints is one of the most important components in human pose estimation. Most of previous methods define this relationship as a geometric constraint on the relative locations of two neighboring joints. In this constraint, the local appearance of the region connecting two neighboring joints is ignored. However, discarding this image appearance leads to some severe problems, such as double-counting and localization failure when the human pose is rare in the training dataset. Moreover, this image appearance, called human limb, plays an important role in human pose estimation in human visual system. Due to these reasons, we propose to solve a new task: human limb detection, which aims at detecting and representing this local image appearance. We combine this task with human joint localization as a unified framework. After getting the initial detections, we design a two-steps graphical model to capture the spatial relationship among human joints and limbs in a coarse to fine way. We evaluate the proposed method on two widely used datasets for human pose estimation: 1) frame labeled in cinema and 2) leeds sports pose datasets. The experiments results show the effectiveness of our method.","","","10.1109/TSMC.2016.2639788","National Key Research and Development Program of China; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7803546","Convolutional neural network (ConvNet);graphical model;human pose estimation;limbs detection","Pose estimation;Graphical models;Shape;Feature extraction;Elbow;Joining processes;Visual systems","object detection;pose estimation","human limb detection;local image appearance;human joint localization;two-steps graphical model;human pose estimation;localization failure;human visual system;training dataset;double-counting failure;limb-based graphical model","","4","50","","","","","IEEE","IEEE Journals"
"A Deep Structure of Person Re-Identification Using Multi-Level Gaussian Models","D. K. Vishwakarma; S. Upadhyay","Department of Information Technology, Delhi Technological University, New Delhi, India; NA","IEEE Transactions on Multi-Scale Computing Systems","","2018","4","4","513","521","Person re-identification is being widely used in the forensic, and security and surveillance system these days. However, it is still a challenging task in a real life scenario. Hence, in this work, a new feature descriptor model has been proposed using a multilayer framework of the Gaussian distribution model on pixel features, which include color moments, color space values, gradient information, and Schmid filter responses. An image of a person usually consists of distinct body regions, usually with differentiable clothing followed by local colors and texture patterns. Thus, the image is evaluated locally by dividing the image into overlapping regions. Each region is further fragmented into a set of local Gaussians on small patches. A global Gaussian encodes these local Gaussians for each region, creating a multi-level structure. Hence, the global picture of a person is described by local level information present in it, which is often ignored. Also, we have analyzed the efficiency of some existing metric learning methods on this descriptor. The performance of the descriptor is evaluated on four publicly available challenging datasets and the highest accuracy achieved on these datasets are compared with similar state-of-the-art works. It clearly demonstrates the superior performance of the proposed descriptor.","","","10.1109/TMSCS.2018.2870592","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8469037","Feature extraction;feature fusion;image matching;image recognition;metric learning;person re-identification","Image recognition;Feature extraction;Gabor filters;Information filters;Identification of persons;Image matching","","","","1","56","","","","","IEEE","IEEE Journals"
"Pedestrian Detection via Body Part Semantic and Contextual Information With DNN","S. Wang; J. Cheng; H. Liu; F. Wang; H. Zhou","School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China","IEEE Transactions on Multimedia","","2018","20","11","3148","3159","Pedestrian detection has achieved great improve-ments in recent years, while complex occlusion handling and high-accurate localization are still the most important problems. To take advantage of the body part semantic information and the contextual information for pedestrian detection, we propose the part and context network (PCN) in this paper. A PCN is composed of three branches: the basic branch; the part branch; and the context branch. It specially utilizes two branches to detect the pedestrians through the body part semantic information and the contextual information, respectively. In the part branch, the semantic information of body parts can communicate with each other via long short-term memory (LSTM). In the context branch, we adopt a local competition mechanism (maxout) for adaptive context scale selection. By combining the outputs of all branches, we develop a strong complementary pedestrian detector with a lower miss rate and higher localization accuracy, especially for the occlusion pedestrian. The combination of the body part semantic information and the contextual information in pedestrian detection is fully explored in this paper. Comprehensive evaluations on three challenging pedestrian detection datasets (i.e., Caltech, INRIA and KITTI) well demonstrate the effectiveness of our proposed PCN. Code for PCN is publicly available on GitHub https://github.com/sunnyxiaohu/pcn_pedestrian.","","","10.1109/TMM.2018.2829602","National Natural Science Foundation of China; State Key Laboratory of Synthetical Automation for Process Industries; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8345752","Pedestrian detection;deep learning;occlusion handling;adaptive context selection","Semantics;Detectors;Feature extraction;Machine learning;Object detection;Proposals;Bidirectional control","neural nets;object detection;pedestrians;traffic engineering computing","part branch;context branch;body part semantic information;contextual information;pedestrian detection datasets;complementary pedestrian detector;DNN;part and context network;PCN;long short-term memory;local competition mechanism;adaptive context scale selection;higher localization accuracy;LSTM","","2","59","","","","","IEEE","IEEE Journals"
"Automatic Arrival Time Detection for Earthquakes Based on Stacked Denoising Autoencoder","O. M. Saad; K. Inoue; A. Shalaby; L. Samy; M. S. Sayed","Department of Electronics and Communications Engineering, Egypt-Japan University of Science and Technology, Alexandria, Egypt; Department of I&E Visionaries, Kyushu University, Fukuoka, Japan; Department of Computer Science, Faculty of Computers and Informatics, Benha University, Benha, Egypt; National Research Institute of Astronomy and Geophysics, Helwan, Egypt; Department of Electronics and Communications Engineering, Egypt-Japan University of Science and Technology, Alexandria, Egypt","IEEE Geoscience and Remote Sensing Letters","","2018","15","11","1687","1691","The accurate detection of P-wave arrival time is imperative for determining the hypocenter location of an earthquake. However, precise detection of onset time becomes more difficult when the signal-to-noise ratio (SNR) of the seismic data is low, such as during microearthquakes. In this letter, a stacked denoising autoencoder (SDAE) is proposed to smooth the background noise. The SDAE acts as a denoising filter for the seismic data. In the proposed algorithm, the SDAE is utilized to reduce background noise such that the onset time becomes more clear and sharp. Afterward, a hard decision with one threshold is used to detect the onset time of the event. The proposed algorithm is evaluated on both synthetic and field seismic data. As a result, the proposed algorithm outperforms the short-time average/long-time average and the Akaike information criterion algorithms. The proposed algorithm accurately picks the onset time of 94.1% for 407 field seismic waveforms with a standard deviation error of 0.10 s. In addition, the results indicate that the proposed algorithm can pick arrival times accurately for weak SNR seismic data with SNR higher than -14 dB.","","","10.1109/LGRS.2018.2861218","Egypt-Japan University of Science and Technology; Egyptian Ministry of Higher Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8437146","Deep learning;P-wave arrival time of earthquakes;stacked denoising autoencoder (SDAE)","Noise measurement;Feature extraction;Machine learning;Decoding;Earthquakes;Noise reduction;Signal to noise ratio","earthquakes;geophysical techniques;seismic waves;seismology","automatic arrival time detection;earthquake;stacked denoising autoencoder;accurate detection;P-wave arrival time;precise detection;onset time;signal-to-noise ratio;SDAE;background noise;denoising filter;synthetic field seismic data;short-time average/long-time average;Akaike information criterion algorithms;weak SNR seismic data;seismic waveforms;hypocenter location;time 0.1 s;noise figure -14.0 dB","","2","17","","","","","IEEE","IEEE Journals"
"Scribble-Supervised Segmentation of Aerial Building Footprints Using Adversarial Learning","W. Wu; H. Qi; Z. Rong; L. Liu; H. Su","State Key Laboratory of Industrial Control Technology, Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, china; Department of Engineering Science, University of Oxford, Oxford, U.K.; State Key Laboratory of Industrial Control Technology, Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, china; Daniel J. Epstein Department of Industrial and Systems Engineering, University of Southern California, Los Angeles, CA, USA; State Key Laboratory of Industrial Control Technology, Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, china","IEEE Access","","2018","6","","58898","58911","Aerial image segmentation usually requires a large amount of pixel-level masks in order to achieve quality performance. Obtaining these annotations can be both costly and time-consuming, limiting the amount of data available for training. In this paper, we present an approach for learning to segment aerial building footprints in the absence of fully annotated label masks. Instead, we exploit cheap and efficient scribble annotations to supervise deep convolutional neural networks for segmentation. Our proposed model is based on an adversarial architecture that jointly trains two networks to produce building footprint segmentations that resemble synthetic label masks. We present competitive segmentation results on the Massachusetts Buildings data set by using only scribble supervision signals. Further experiments show that our method effectively alleviates building instance separation issue and displays strong robustness towards different scribble instance levels. We believe our cost-effective approach has the potential to be adapted for other aerial image interpretation tasks.","","","10.1109/ACCESS.2018.2874544","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8485295","Aerial image;generative adversarial network;image segmentation;weak supervision","Image segmentation;Buildings;Training;Task analysis;Semantics;Machine learning;Generators","","","","","61","","","","","IEEE","IEEE Journals"
"Temporal Bag-of-Features Learning for Predicting Mid Price Movements Using High Frequency Limit Order Book Data","N. Passalis; A. Tefas; J. Kanniainen; M. Gabbouj; A. Iosifidis","Department of Informatics Aristotle University of Thessaloniki, 54124, Thessaloniki, Greece (e-mail: passalis@csd.auth.gr).; Department of Informatics Aristotle University of Thessaloniki, 54124, Thessaloniki, Greece (e-mail: tefas@aiia.csd.auth.gr).; Laboratory of Industrial and Information Management, Tampere University of Technology, 33720, Tampere, Finland (e-mail: juho.kanniainen@tut.fi).; Laboratory of Signal Processing, Tampere University of Technology, 33720, Tampere, Finland (e-mail: moncef.gabbouj@tut.fi).; Department of Engineering, Electrical and Computer Engineering, Aarhus University, 8000, Aarhus, Denmark (e-mail: alexandros.iosifidis@eng.au.dk).","IEEE Transactions on Emerging Topics in Computational Intelligence","","2018","PP","99","1","12","Time-series forecasting has various applications in a wide range of domains, e.g., forecasting stock markets using limit order book data. Limit order book data provide much richer information about the behavior of stocks than its price alone, but also bear several challenges, such as dealing with multiple price depths and processing very large amounts of data of high dimensionality, velocity, and variety. A well-known approach for efficiently handling large amounts of high-dimensional data is the bag-of-features (BoF) model. However, the BoF method was designed to handle multimedia data such as images. In this paper, a novel temporal-aware neural BoF model is proposed tailored to the needs of time-series forecasting using high frequency limit order book data. Two separate sets of radial basis function and accumulation layers are used in the temporal BoF to capture both the short-term behavior and the long-term dynamics of time series. This allows for modeling complex temporal phenomena that occur in time-series data and further increase the forecasting ability of the model. Any other neural layer, such as feature transformation layers, or classifiers, such as multilayer perceptrons, can be combined with the proposed deep learning approach, which can be trained end-to-end using the back-propagation algorithm. The effectiveness of the proposed method is validated using a large-scale limit order book dataset, containing over 4.5 million limit orders, and it is demonstrated that it greatly outperforms all the other evaluated methods.","","","10.1109/TETCI.2018.2872598","EU Research and Innovation Programme Horizon 2020; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8487014","Limit order book;neural networks;bag-of-features","Feature extraction;Forecasting;Data models;Machine learning;Predictive models;Task analysis;Hidden Markov models","","","","4","","","","","","IEEE","IEEE Early Access Articles"
"Long-Distance Object Recognition With Image Super Resolution: A Comparative Study","X. Yang; W. Wu; K. Liu; P. W. Kim; A. K. Sangaiah; G. Jeon","College of Electronics and Information Engineering, University of Sichuan, Chengdu, china; College of Electronics and Information Engineering, University of Sichuan, Chengdu, china; School of Electrical Engineering and Information, University of Sichuan, Chengdu, China; Department of Korean Language Education, Incheon National University, Incheon, South Korea; School of Computing Science and Engineering, Vellore Institute of Technology, Vellore, India; Department of Embedded Systems Engineering, Incheon National University, Incheon, South Korea","IEEE Access","","2018","6","","13429","13438","Monitor systems are ubiquitously deployed in public areas. However, monitor systems face a major challenge regarding long-distance object recognition. Super-resolution constitutes a popular choice to address this challenge. Since super-resolution methods are used in many applications, it is necessary to understand these methods and make a comparative study of them. In this paper, we perform a comparative study on six super-resolution methods over two recognition algorithms. The paper evaluates super-resolution performance based on recognition accuracy, and serves as a summary assessment of image super-resolution algorithms.","","","10.1109/ACCESS.2018.2799861","National Natural Science Foundation of China; National Research Foundation of Korea; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8274945","Super-resolution;sparse representation;deep learning;convolutional neural networks","Image resolution;Dictionaries;Image reconstruction;Signal resolution;Monitoring;Image recognition;Machine learning","image resolution;object recognition","long-distance object recognition;monitor systems;super-resolution methods;recognition algorithms;super-resolution performance;image super-resolution algorithms","","5","25","","","","","IEEE","IEEE Journals"
"$BitCoding$: Network Traffic Classification Through Encoded Bit Level Signatures","N. Hubballi; M. Swarnkar","Discipline of Computer Science and Engineering, IIT Indore, Indore, India; Discipline of Computer Science and Engineering, IIT Indore, Indore, India","IEEE/ACM Transactions on Networking","","2018","26","5","2334","2346","With many network protocols using obfuscation techniques to hide their identity, robust methods of traffic classification are required. In traditional deep-packet-inspection (DPI) methods, application specific signatures are generated with byte-level data from payload. Increasingly new data formats are being used to encode the application protocols with bit-level information which render the byte-level signatures ineffective. In this paper, we describe BitCoding a bit-level DPI-based signature generation technique. BitCoding uses only a small number of initial bits from a flow and identify invariant bits as signature. Subsequently, these bit signatures are encoded and transformed into a newly defined state transition machine transition constrained counting automata. While short signatures are efficient for processing, this will increase the chances of collision and cross signature matching with increase in number of signatures (applications). We describe a method for signature similarity detection using a variant of Hamming distance and propose to increase the length of signatures for a subset of protocols to avoid overlaps. We perform extensive experiments with three different data sets consisting of 537 380 flows with a packet count of 3 445 969 and show that, BitCoding has very good detection performance across different types of protocols (text, binary, and proprietary) making it protocol-type agnostic. Further, to understand the portability of signatures generated we perform cross evaluation, i.e., signatures generated from one site are used for testing with data from other sites to conclude that it will lead to a small compromise in detection performance.","","","10.1109/TNET.2018.2868816","SERB, Government of India; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8465696","Traffic classification;DPI;bit-level signatures","Protocols;Payloads;Machine learning algorithms;Quality of service;Robustness;Machine learning;IEEE transactions","computer network security;digital signatures;protocols","cross signature matching;BitCoding;network traffic classification;encoded bit level signatures;network protocols;bit-level information;byte-level signatures;bit-level DPI-based signature generation technique;state transition machine transition;traffic classification;deep-packet-inspection methods;Hamming distance","","","33","","","","","IEEE","IEEE Journals"
"Multi-Center Brain Imaging Classification Using a Novel 3D CNN Approach","L. Yuan; X. Wei; H. Shen; L. Zeng; D. Hu","College of Artificial Intelligence, National University of Defense Technology, Changsha, China; College of Artificial Intelligence, National University of Defense Technology, Changsha, China; College of Artificial Intelligence, National University of Defense Technology, Changsha, China; College of Artificial Intelligence, National University of Defense Technology, Changsha, China; College of Artificial Intelligence, National University of Defense Technology, Changsha, China","IEEE Access","","2018","6","","49925","49934","With the development of brain imaging technology, increasing amounts of magnetic resonance imaging data are being acquired, and traditional computational analysis methods based on single sites and small samples are facing substantial challenges. Deep learning technology, which is born via artificial intelligence, has shown the powerful ability to solve the classification problem based on big data in many studies, while it has not been widely used in brain imaging classification. Herein, we utilized our proposed novel 3-D deep adding neural network to classify 6008 samples from the largest data sets in the brain imaging field collected from more than 61 centers. The proposed method utilizes multiple convolutional layers to extract gradient information in different orientations and combines spatial information at two scales via the adding operation. High accuracy (over 92.5%) was obtained with a standard fivefold cross-validation strategy, demonstrating that the proposed method can effectively handle big data classifications from multiple centers. Compared with some traditional classification methods and some deep learning architectures, the proposed method was more accurate, demonstrating its stronger power to classify data from multiple centers. Our cross-site classification results prove that the proposed method is robust when training on a data set and testing on another data set. To the best of our knowledge, this paper is the first to classify neuroimaging data on such a large scale from multiple centers with such high accuracy. With its improved performance in classification and transferable program codes, the proposed method can potentially be used in intelligent medical treatment strategies and clinical practices based on mobile terminal.","","","10.1109/ACCESS.2018.2868813","National Natural Science Foundation of China; Fok Ying Tung Education Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8454727","Artificial intelligence;artificial neural networks;image classification;machine learning;magnetic resonance imaging","Magnetic resonance imaging;Three-dimensional displays;Neuroimaging;Machine learning;Brain modeling;Image segmentation","Big Data;biomedical MRI;brain;convolution;diseases;feedforward neural nets;gradient methods;image classification;medical image processing;stereo image processing","neuroimaging data;multicenter brain imaging classification;magnetic resonance imaging data;artificial intelligence;brain imaging field;multiple convolutional layers;gradient information;standard fivefold cross-validation strategy;big data classifications;3D CNN;cross-site classification;computational analysis methods","","4","41","","","","","IEEE","IEEE Journals"
"Human Action Recognition Based on Integrating Body Pose, Part Shape, and Motion","H. El-Ghaish; M. E. Hussein; A. Shoukry; R. Onai","Department of Computer Science and Engineering, Egypt-Japan University of Science and Technology, New Borg El-Arab City, Alexandria, Egypt; Information Sciences Institute, Viterbi School of Engineering, University of Southern California, Arlington, VA, USA; Department of Computer Science and Engineering, Egypt-Japan University of Science and Technology, New Borg El-Arab City, Alexandria, Egypt; Department of Computer Science and Engineering, Waseda University, Tokyo, Japan","IEEE Access","","2018","6","","49040","49055","Human action recognition is a challenging problem, especially in the presence of multiple actors in the scene and/or viewpoint variations. In this paper, three modalities, namely, 3-D skeletons, body part images, and motion history image (MHI), are integrated into a hybrid deep learning architecture for human action recognition. The three modalities capture the main aspects of an action: body pose, part shape, and body motion. Although the 3-D skeleton modality captures the actor's pose, it lacks information about the shape of the body parts as well as the shape of manipulated objects. This is the reason for including both the body-part images and the MHI as additional modalities. The deployed architecture combines convolution neural networks (CNNs), long short-term memory (LSTM), and a fine-tuned pre-trained architecture into a hybrid one. It is called MCLP: multi-modal CNN + LSTM + VGG16 pre-trained on ImageNet. The MCLP consists of three sub-models: CL1D (for CNN1D + LSTM), CL2D (for CNN2D + LSTM), and CMHI (CNN2D for MHI), which simultaneously extract the spatial and temporal patterns in the three modalities. The decisions of these three sub-models are fused by a late multiply fusion module, which proved to yield better accuracy than averaging or maximizing fusion methods. The proposed combined model and its submodels have been evaluated both individually and collectively on four public data sets: UTkinect Action3D, SBU Interaction, Florence3-D Action, and NTU RGB+D. Our recognition rates outperform the state-ofthe-art rates on all the evaluated data sets.","","","10.1109/ACCESS.2018.2868319","Ministry of Higher Education (MoHE) of Egypt through the Ph.D. Scholarship in Egypt-Japan University of Science and Technology (E-JUST); Computer Science and Engineering Department, Cyber Physical System (CPS) Laboratory; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453782","Human action recognition;spatial and temporal features;convolution neural networks (CNN);long short-term memory (LSTM);CNN-LSTM;motion history images (MHI)","Skeleton;Feature extraction;Three-dimensional displays;Data mining;Shape;Solid modeling;Hidden Markov models","convolution;feedforward neural nets;image capture;image motion analysis;image sequences;learning (artificial intelligence);object recognition;pose estimation","human action recognition;integrating body pose;part shape;motion history image;MHI;hybrid deep learning architecture;modalities capture;body motion;body-part images;fine-tuned pre-trained architecture;recognition rates;evaluated data sets;temporal pattern;spatial pattern;convolution neural networks;LSTM;multimodal CNN;skeleton modality","","2","56","","","","","IEEE","IEEE Journals"
"DynaSLAM: Tracking, Mapping, and Inpainting in Dynamic Scenes","B. Bescos; J. M. Fácil; J. Civera; J. Neira","Instituto de Investigación en Ingeniería de Aragón (I3A), Universidad de Zaragoza, Zaragoza, Spain; Instituto de Investigación en Ingeniería de Aragón (I3A), Universidad de Zaragoza, Zaragoza, Spain; Instituto de Investigación en Ingeniería de Aragón (I3A), Universidad de Zaragoza, Zaragoza, Spain; Instituto de Investigación en Ingeniería de Aragón (I3A), Universidad de Zaragoza, Zaragoza, Spain","IEEE Robotics and Automation Letters","","2018","3","4","4076","4083","The assumption of scene rigidity is typical in SLAM algorithms. Such a strong assumption limits the use of most visual SLAM systems in populated real-world environments, which are the target of several relevant applications like service robotics or autonomous vehicles. In this letter we present DynaSLAM, a visual SLAM system that, building on ORB-SLAM2, adds the capabilities of dynamic object detection and background inpainting. DynaSLAM is robust in dynamic scenarios for monocular, stereo, and RGB-D configurations. We are capable of detecting the moving objects either by multiview geometry, deep learning, or both. Having a static map of the scene allows inpainting the frame background that has been occluded by such dynamic objects. We evaluate our system in public monocular, stereo, and RGB-D datasets. We study the impact of several accuracy/speed trade-offs to assess the limits of the proposed methodology. DynaSLAM outperforms the accuracy of standard visual SLAM baselines in highly dynamic scenarios. And it also estimates a map of the static parts of the scene, which is a must for long-term applications in real-world environments.","","","10.1109/LRA.2018.2860039","NVIDIA through the donation of a Titan X GPU; Spanish Ministry of Economy and Competitiveness; Aragón regional government; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8421015","SLAM;visual-based navigation;localization","Vehicle dynamics;Simultaneous localization and mapping;Heuristic algorithms;Image segmentation;Cameras;Visualization;Geometry","image colour analysis;image restoration;learning (artificial intelligence);mobile robots;object detection;service robots;SLAM (robots);stereo image processing","deep learning;multiview geometry;monocular datasets;stereo datasets;RGB-D datasets;frame background inpainting;scene rigidity;static map;dynamic object detection;ORB-SLAM2;DynaSLAM;autonomous vehicles;service robotics;visual SLAM system;SLAM algorithms","","9","24","","","","","IEEE","IEEE Journals"
"Multi-layer fusion techniques using a CNN for multispectral pedestrian detection","Y. Chen; H. Xie; H. Shin","Hanyang University, Republic of Korea; Hanyang University, Republic of Korea; Hanyang University, Republic of Korea","IET Computer Vision","","2018","12","8","1179","1187","In this study, a novel multi-layer fused convolution neural network (MLF-CNN) is proposed for detecting pedestrians under adverse illumination conditions. Currently, most existing pedestrian detectors are very likely to be stuck under adverse illumination circumstances such as shadows, overexposure, or nighttime. To detect pedestrians under such conditions, the authors apply deep learning for effective fusion of the visible and thermal information in multispectral images. The MLF-CNN consists of a proposal generation stage and a detection stage. In the first stage, they design an MLF region proposal network and propose to use summation fusion method for integration of the two convolutional layers. This combination can detect pedestrians in different scales, even in adverse illumination. Furthermore, instead of extracting features from a single layer, they extract features from three feature maps and match the scale using the fused ROI pooling layers. This new multiple-layer fusion technique can significantly reduce the detection miss rate. Extensive evaluations of several challenging datasets well demonstrate that their approach achieves state-of-the-art performance. For example, their method performs 28.62% better than the baseline method and 11.35% better than the well-known faster R-CNN halfway fusion method in detection accuracy on KAIST multispectral pedestrian dataset.","","","10.1049/iet-cvi.2018.5315","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8555956","","","feature extraction;feedforward neural nets;image fusion;image matching;learning (artificial intelligence);object detection;pedestrians","multilayer fusion techniques;CNN;multispectral pedestrian detection;multilayer fused convolution neural network;pedestrian detectors;adverse illumination circumstances;shadows;overexposure;nighttime;deep learning;visible information;thermal information;MLF region proposal network;summation fusion method;convolutional layers;adverse illumination;feature extraction;feature maps;scale matching;fused ROI pooling layers;detection miss rate reduction;KAIST multispectral pedestrian dataset","","1","33","","","","","IET","IET Journals"
"Robustness of Reflection Symmetry Detection Methods on Visual Stresses in Human Perception Perspective","I. R. Atadjanov; S. Lee","Department of Computer Science and Engineering, Kyung Hee University, Yongin, South Korea; Department of Computer Science and Engineering, Kyung Hee University, Yongin, South Korea","IEEE Access","","2018","6","","63712","63725","Symmetry is one of the most frequently observed fundamental regularities in the visual characteristic of real-world objects. The human brain has been trained to respond quickly to symmetry patterns, organizing them as salient clues for the unique description of objects. Recently, automatic symmetry detection methods have been widely introduced in computer vision and graphics fields for 2-D and 3-D object data, including reflection, translation, and rotation symmetry patterns. Researchers have invented features inspired by a human vision system and have adopted deep learning approaches. On the other side, traditional performance evaluations have been conducted on a unified test data set containing random degrees of diverse visual challenges. However, they ignore observing the insight of usability and practicality of the methods in higher level tasks, such as object recognition. In this paper, we carefully organize the visual stress data set for reflection symmetry detection evaluation proposing a novel evaluation framework. The state-of-the-art reflection symmetry detection methods are re-evaluated and analyzed in human perception perspective.","","","10.1109/ACCESS.2018.2876882","Ministry of Science and ICT, South Korea, through the Information Technology Research Center Support Program supervised by the Institute for Information and communications Technology Promotion; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8511044","Reflection symmetry;performance evaluation;human symmetry perception;visual stresses;psychophysics","Visualization;Stress;Task analysis;Object recognition;Robustness;Computational modeling;Shape","computer vision;learning (artificial intelligence)","human perception perspective;frequently observed fundamental regularities;human brain;automatic symmetry detection methods;3D object data;performance evaluations;visual stress characteristics;deep learning approaches;reflection symmetry detection evaluation;object recognition;unified test data set;human vision system;rotation symmetry patterns;graphics fields;computer vision","","","73","","","","","IEEE","IEEE Journals"
"SAR Automatic Target Recognition Using Joint Low-Rank and Sparse Multiview Denoising","Y. Huang; G. Liao; Z. Zhang; Y. Xiang; J. Li; A. Nehorai","National Laboratory of Radar Signal Processing, Xidian University, Xi’an, China; National Laboratory of Radar Signal Processing, Xidian University, Xi’an, China; Preston M. Green Department of Electrical and Systems Engineering, Washington University in St. Louis, St. Louis, MO, USA; Preston M. Green Department of Electrical and Systems Engineering, Washington University in St. Louis, St. Louis, MO, USA; National Laboratory of Radar Signal Processing, Xidian University, Xi’an, China; Preston M. Green Department of Electrical and Systems Engineering, Washington University in St. Louis, St. Louis, MO, USA","IEEE Geoscience and Remote Sensing Letters","","2018","15","10","1570","1574","In recent years, many researchers have focused on the automatic target recognition problem for high-resolution synthetic aperture radar (SAR) systems. Most have directly employed the training data as the dictionary, which introduces error from speckle noise. In this letter, a joint low-rank and sparse multiview denoising (JLSMD) dictionary is generated, which combines multiview training samples for denoising. To extract the dictionary, we fully consider the low-rank property of multiview target images and the sparsity of speckle noise for SAR systems. The designed dictionary is more accurate than the training data in representing the target. With the help of the proposed JLSMD dictionary, we develop three algorithms based on the sparse representation classification and the support vector machine approach. We carry out experiments on the moving and stationary target acquisition and recognition public data set to evaluate the excellent performance of the proposed methods against several state-of-the-art methods, including deep learning methods.","","","10.1109/LGRS.2018.2851146","National Natural Science Foundation of China; National Key Research and Development Program of China; Key Research and Development Program of Shaanxi Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8412510","Joint low-rank and sparse multiview denoising (JLSMD);sparse representation classification (SRC);support vector machine (SVM);synthetic aperture radar automatic target recognition (SAR ATR)","Dictionaries;Speckle;Synthetic aperture radar;Support vector machines;Testing;Training;Training data","data analysis;image classification;image denoising;image representation;learning (artificial intelligence);radar computing;radar imaging;radar target recognition;support vector machines;synthetic aperture radar","deep learning method;sparse multiview denoising;high-resolution synthetic aperture radar systems;automatic target recognition problem;joint low-rank;SAR automatic target recognition;recognition public data;stationary target acquisition;sparse representation classification;JLSMD dictionary;training data;SAR systems;speckle noise;multiview target images;low-rank property;multiview training samples","","3","19","","","","","IEEE","IEEE Journals"
"Exploiting ConvNet Diversity for Flooding Identification","K. Nogueira; S. G. Fadel; Í. C. Dourado; R. de O. Werneck; J. A. V. Muñoz; O. A. B. Penatti; R. T. Calumby; L. T. Li; J. A. dos Santos; R. d. S. Torres","Department of Computer Science, Federal University of Minas Gerais, Belo Horizonte, Brazil; Institute of Computing, University of Campinas, Campinas, Brazil; Institute of Computing, University of Campinas, Campinas, Brazil; Institute of Computing, University of Campinas, Campinas, Brazil; Institute of Computing, University of Campinas, Campinas, Brazil; Samsung Research and Development Institute Brazil, Campinas, Brazil; Department of Exact Sciences, State University of Feira de Santana, Feira de Santana, Brazil; Institute of Computing, University of Campinas, Campinas, Brazil; Department of Computer Science, Federal University of Minas Gerais, Belo Horizonte, Brazil; Institute of Computing, University of Campinas, Campinas, Brazil","IEEE Geoscience and Remote Sensing Letters","","2018","15","9","1446","1450","Flooding is the world's most costly type of natural disaster in terms of both economic losses and human causalities. A first and essential procedure toward flood monitoring is based on identifying the area most vulnerable to flooding, which gives authorities relevant regions to focus. In this letter, we propose several methods to perform flooding identification in high-resolution remote sensing images using deep learning. Specifically, some proposed techniques are based upon unique networks, such as dilated and deconvolutional ones, whereas others were conceived to exploit diversity of distinct networks in order to extract the maximum performance of each classifier. The evaluation of the proposed methods was conducted in a high-resolution remote sensing data set. Results show that the proposed algorithms outperformed the state-of-the-art baselines, providing improvements ranging from 1% to 4% in terms of the Jaccard Index.","","","10.1109/LGRS.2018.2845549","Fundação de Amparo à Pesquisa do Estado de São Paulo; Fundação de Amparo à Pesquisa do Estado de Minas Gerais; Conselho Nacional de Desenvolvimento Científico e Tecnológico; Coordenação de Aperfeiçoamento de Pessoal de Nível Superior; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8398414","Flooding identification;inundation;MediaEval;natural disaster;remote sensing;satellites","Remote sensing;Satellites;Task analysis;Image resolution;Support vector machines;Training;Monitoring","disasters;floods;geophysical image processing;image classification;image resolution;learning (artificial intelligence);remote sensing","flooding identification;natural disaster;economic losses;human causalities;flood monitoring;high-resolution remote sensing images;ConvNet diversity;deep learning","","6","19","","","","","IEEE","IEEE Journals"
"Code Acceleration Using Memristor-Based Approximate Matrix Multiplier: Application to Convolutional Neural Networks","M. Nourazar; V. Rashtchi; A. Azarpeyvand; F. Merrikh-Bayat","Department of Electrical and Computer Engineering, University of Zanjan, Zanjan, Iran; Department of Electrical and Computer Engineering, University of Zanjan, Zanjan, Iran; Department of Electrical and Computer Engineering, University of Zanjan, Zanjan, Iran; Department of Electrical and Computer Engineering, University of Zanjan, Zanjan, Iran","IEEE Transactions on Very Large Scale Integration (VLSI) Systems","","2018","26","12","2684","2695","In this paper, we demonstrate the feasibility of building a memristor-based approximate accelerator to be used in cooperation with general-purpose ×86 processors. First, an integrated full system simulator is developed for simultaneous simulation of any multicrossbar architecture as an accelerator for ×86 processors, which is performed by coupling a cycle accurate Marss ×86 processor simulator with the Ngspice mixed-level/mixed-signal circuit simulator. Then, a novel mixedsignal memristor-based architecture is presented for multiplying floating-point signed complex numbers. The presented multiplier is extended for accelerating convolutional neural networks and finally, it is tightly integrated with the pipeline of a generic ×86 processor. To validate the accelerator, first it is utilized for multiplying different matrices that vary in size and distribution. Then, it is used as an accelerator for accelerating the tiny-dnn, an open-source C++ implementation of deep learning neural networks. The memristor-based accelerator provides more than 100× speedup and energy saving for a 64 × 64 matrixmatrix multiplication, with an accuracy of 90%. Using the accelerated tiny-dnn for the MNIST database classification more than 10× speedup and energy saving along with 95.51% pattern recognition accuracy is achieved.","","","10.1109/TVLSI.2018.2837908","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8374046","Analog accelerator;approximate computing;convolutional neural network (CNN);matrix multiplier;memristor crossbar","Memristors;Program processors;Computer architecture;Acceleration;Approximate computing;Hardware;Neural networks","approximation theory;circuit simulation;feedforward neural nets;floating point arithmetic;learning (artificial intelligence);matrix multiplication;memristors;microprocessor chips;pattern recognition","convolutional neural networks;memristor-based approximate accelerator;integrated full system simulator;simultaneous simulation;multicrossbar architecture;cycle accurate Marss ×86 processor simulator;novel mixedsignal memristor-based architecture;multiplying floating-point signed complex numbers;generic ×86 processor;deep learning neural networks;memristor-based accelerator;code acceleration;memristor-based approximate matrix multiplier;Ngspice mixed-level-mixed-signal circuit simulator","","1","49","","","","","IEEE","IEEE Journals"
"Detection of Vehicles in Multisensor Data via Multibranch Convolutional Neural Networks","H. Schilling; D. Bulatov; R. Niessner; W. Middelmann; U. Soergel","Department of Scene Analysis, Fraunhofer Institute of Optronics, System Technologies and Image Exploitation (IOSB), Karlsruhe, Germany; Department of Scene Analysis, Fraunhofer Institute of Optronics, System Technologies and Image Exploitation (IOSB), Karlsruhe, Germany; Department of Scene Analysis, Fraunhofer Institute of Optronics, System Technologies and Image Exploitation (IOSB), Karlsruhe, Germany; Department of Scene Analysis, Fraunhofer Institute of Optronics, System Technologies and Image Exploitation (IOSB), Karlsruhe, Germany; Institute for Photogrammetry, University of Stuttgart, Stuttgart, Germany","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2018","11","11","4299","4316","Convolutional neural networks, or CNNs, raised the bar for most computer vision problems and have an increasing impact in remote sensing. However, since they usually contain multiple pooling layers, detection of exact borders of small objects at their original resolution remains yet a challenging topic. Additionally, efforts are being made to reduce the amount of training data. In this paper, we investigate the potential of fully convolutional neural networks (FCNs) for individual vehicle detection in combined elevation and optical data using relatively few training samples. By the proposed multibranch CNN, we combine object recognition within a deep learning framework with the object segmentation at a high resolution, for which two CNN branches are employed. Data fusion is accomplished with a pseudo-Siamese approach. The pixelwise classification likelihood, also referred to as heatmap, is harmoniously postprocessed by a vectorization module, which is based on the minimum bounding rectangle (MBR) extraction and allows for delineation of groups of vehicles. Two methods were developed in which MBRs are supported either by pairs of parallel lines or by region growing. Our approach allows efficient training with few training samples, while delivering high-quality detection results and good computational performance. In our detailed evaluation, we investigate the benefits of data fusion and compare our approach to other state-of-the-art networks. Different datasets were used, containing optical images and elevation data, derived either from airborne laser scanning or from photogrammetric reconstruction. The obtained results are very promising with F1 scores up to 97%.","","","10.1109/JSTARS.2018.2825099","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8365098","Convolution;image classification;neural networks;object detection;remote sensing;vehicles","Feature extraction;Remote sensing;Optical sensors;Optical imaging;Three-dimensional displays;Task analysis;Training","computer vision;convolution;feature extraction;feedforward neural nets;image classification;image resolution;image segmentation;learning (artificial intelligence);object detection;object recognition;photogrammetry;remote sensing;sensor fusion","vehicle detection;FCNs;object recognition;heatmap;vectorization module;MBR;delineation;airborne laser scanning;photogrammetric reconstruction;optical images;minimum bounding rectangle extraction;pixelwise classification likelihood;pseudoSiamese approach;data fusion;high resolution;object segmentation;deep learning framework;multibranch CNN;fully convolutional neural networks;multiple pooling layers;remote sensing;computer vision problems;multibranch convolutional neural networks;multisensor data","","2","71","","","","","IEEE","IEEE Journals"
"Fast and Lightweight Object Detection Network: Detection and Recognition on Resource Constrained Devices","B. A. Godinho de Oliveira; F. Magalhães Freitas Ferreira; C. A. P. d. S. Martins","Pontifícia Universidade Católica de Minas Gerais, Belo Horizonte, Brasil; Pontifícia Universidade Católica de Minas Gerais, Belo Horizonte, Brasil; Pontifícia Universidade Católica de Minas Gerais, Belo Horizonte, Brasil","IEEE Access","","2018","6","","8714","8724","The intrinsic ability of humans to rapidly detect, differentiate, and classify objects allows us to make quick decisions in regards to what we see. Several appliances can make use of fast and lightweight automated object detection for images or videos. Throughout the last five years, the technology industry has constantly introduced computational and hardware solutions, such as devices with impressive processing and storage capabilities. However, object detection methods usually require either high processing power or large storage availability, making it hard for resource constrained devices to perform the detection in real-time without a connection to a powerful server. The model presented in this paper requires only 95 megabytes of storage and took 113 ms in average per image running on a laptop CPU, making it suitable for standalone devices that can be used on the go.","","","10.1109/ACCESS.2018.2801813","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8281079","Computer vision;deep learning;machine learning;object detection","Training;Object detection;Feature extraction;Biological neural networks;Microsoft Windows;Object recognition;Task analysis","object detection","technology industry;resource constrained devices;standalone devices;fast object detection;lightweight automated object detection;object detection methods;memory size 95.0 MByte;time 113.0 ms","","3","57","","","","","IEEE","IEEE Journals"
"Multi-Task Vehicle Detection With Region-of-Interest Voting","W. Chu; Y. Liu; C. Shen; D. Cai; X. Hua","Alibaba, Hangzhou, China; Alibaba, Hangzhou, China; Alibaba, Hangzhou, China; State Key Laboratory of CAD&CG, College of Computer Science, Zhejiang University, Hangzhou, China; Alibaba Group, Hangzhou, China","IEEE Transactions on Image Processing","","2018","27","1","432","441","Vehicle detection is a challenging problem in autonomous driving systems, due to its large structural and appearance variations. In this paper, we propose a novel vehicle detection scheme based on multi-task deep convolutional neural networks (CNNs) and region-of-interest (RoI) voting. In the design of CNN architecture, we enrich the supervised information with subcategory, region overlap, bounding-box regression, and category of each training RoI as a multi-task learning framework. This design allows the CNN model to share visual knowledge among different vehicle attributes simultaneously, and thus, detection robustness can be effectively improved. In addition, most existing methods consider each RoI independently, ignoring the clues from its neighboring RoIs. In our approach, we utilize the CNN model to predict the offset direction of each RoI boundary toward the corresponding ground truth. Then, each RoI can vote those suitable adjacent bounding boxes, which are consistent with this additional information. The voting results are combined with the score of each RoI itself to find a more accurate location from a large number of candidates. Experimental results on the real-world computer vision benchmarks KITTI and the PASCAL2007 vehicle data set show that our approach achieves superior performance in vehicle detection compared with other existing published works.","","","10.1109/TIP.2017.2762591","National Basic Research Program of China (973 Program); National Youth Top-notch Talent Support Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8066331","Vehicle detection;CNN;multi-task;region-of-interest","Vehicle detection;Proposals;Three-dimensional displays;Feature extraction;Object detection;Solid modeling","computer vision;feedforward neural nets;learning (artificial intelligence);object detection;regression analysis;road vehicles;traffic engineering computing","KITTI;real-world computer vision benchmarks;offset direction prediction;neighboring RoI;visual knowledge sharing;multitask deep convolutional neural networks;appearance variations;structural variations;vehicle attributes;PASCAL2007 vehicle data;voting results;suitable adjacent bounding boxes;RoI boundary;detection robustness;CNN model;multitask learning framework;multitask vehicle detection;region-of-interest voting;autonomous driving systems;novel vehicle detection scheme;CNN architecture;supervised information;region overlap;bounding-box regression;training RoI","","11","65","","","","","IEEE","IEEE Journals"
"Analog Circuit Incipient Fault Diagnosis Method Using DBN Based Features Extraction","C. Zhang; Y. He; L. Yuan; S. Xiang","School of Physics and Electronic Engineering, Anqing Normal University, Anqing, China; School of Electrical Engineering, Wuhan University, Wuhan, China; School of Electrical Engineering and Automation, Hefei University of Technology, Hefei, China; School of Electrical Engineering and Automation, Hefei University of Technology, Hefei, China","IEEE Access","","2018","6","","23053","23064","Correct identifying analog circuit incipient faults is useful to the circuit's health monitoring, and yet it is very hard. In this paper, an analog circuit incipient fault diagnosis method using deep belief network (DBN) based features extraction is presented. In the diagnosis scheme, time responses of analog circuits are measured, and then features are extracted by using the DBN method. Meanwhile, the learning rates of DBN are produced by using quantum-behaved particle swarm optimization (QPSO) algorithm, which is beneficial to optimizing the structure parameters of DBN. Afterward, a support vector machine (SVM) based incipient fault diagnosis model is constructed on basis of the extracted features to classify incipient faulty components, where the regularization parameter and width factor of SVM are yielded by using the QPSO algorithm. Sallen-Key bandpass filter and four-op-amp biquad high pass filter incipient fault diagnosis simulations are conducted to demonstrate the proposed diagnosis method, and comparisons verify that the proposed diagnosis method can produce higher diagnosis accuracy than other typical analog circuit fault diagnosis methods.","","","10.1109/ACCESS.2018.2823765","National Natural Science Foundation of China; State Key Program of National Natural Science Foundation of China; National Key Research and Development Plan “Important Scientific Instruments and Equipment Development”; Equipment Research Project in Advance; Anhui Provincial Natural Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8332927","Analog circuits;incipient fault diagnosis;DBN;SVM;QPSO","Feature extraction;Fault diagnosis;Analog circuits;Circuit faults;Support vector machines;Data mining;Electrical engineering","analogue circuits;band-pass filters;belief networks;electronic engineering computing;fault diagnosis;feature extraction;high-pass filters;learning (artificial intelligence);particle swarm optimisation;support vector machines","Sallen-Key bandpass filter;QPSO algorithm;support vector machine;quantum-behaved particle swarm optimization;learning rates;deep belief network based features extraction;DBN based features;analog circuit incipient fault diagnosis method;four-op-amp biquad high pass filter incipient fault diagnosis simulations;incipient faulty components;incipient fault diagnosis model;DBN method","","9","36","","","","","IEEE","IEEE Journals"
"Deep Radiomic Analysis of MRI Related to Alzheimer’s Disease","A. Chaddad; C. Desrosiers; T. Niazi","Department of Automated Manufacturing Engineering, University of Quebec, Montreal, QC, Canada; Department of Software and IT Engineering, Ecole de Technologie Supérieure, University of Quebec, Montreal, QC, Canada; Department of Radiation Oncology, McGill University, Montreal, QC, Canada","IEEE Access","","2018","6","","58213","58221","Alzheimer's disease (AD) is the most common form of dementia, causing progressive impairment of memory and cognitive functions. Radiomic features obtained from brain MRI have shown a great potential as non-invasive biomarkers for this disease; however, their usefulness has not yet been explored for individual brain regions. In this paper, we hypothesize that distinct regions are affected differently by AD and, thus, that shape or texture changes occurring in separate regions can be expressed by different radiomic features. Moreover, to improve the classification of AD and healthy control (HC) subjects, we propose novel features based on the entropy of the convolution neural network (CNN) feature maps. The proposed approach is evaluated comprehensively using the Open Access Series of Imaging Studies database. Our experiments assess the significance of 45 different radiomic features from individual subcortical regions, via the Wilcoxon test. We also use the random forest classifier to identify the subcortical regions that best differentiate AD patients from HC subjects. Our analysis identified the features derived from several subcortical regions that show significant differences between AD and HC (corrected p <; 0.01). Specifically, we found correlation and volume features from the hippocampus (AUC = 81.19% - 84.09%) and amygdala (AUC = 79.70% - 80.27%) regions to have the greatest discriminative power. Furthermore, the proposed entropy features derived from CNN layers yielded the highest classification AUC of 92.58%, compared to 84.45% for the combined radiomic features of all subcortical. These results suggest that the proposed CNN entropy features could be used as an effective biomarker for AD.","","","10.1109/ACCESS.2018.2871977","McGill University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8495001","Alzheimer’s;radiomics;classification","Feature extraction;Magnetic resonance imaging;Entropy;Dementia;Hippocampus;Three-dimensional displays","biomedical MRI;brain;cognition;diseases;entropy;feature extraction;image classification;image texture;learning (artificial intelligence);medical image processing;neural nets;neurophysiology","radiomic analysis;brain MRI;noninvasive biomarkers;individual brain regions;distinct regions;separate regions;healthy control subjects;individual subcortical regions;HC subjects;volume features;combined radiomic features;CNN entropy features;Alzheimer disease;radiomic features","","4","82","","","","","IEEE","IEEE Journals"
"Dynamic Summarization of Videos Based on Descriptors in Space-Time Video Volumes and Sparse Autoencoder","J. Mohan; M. S. Nair","Department of Computer Science, University of Kerala, Thiruvananthapuram, India; Department of Computer Science, Cochin University of Science and Technology, Kochi, India","IEEE Access","","2018","6","","59768","59778","This paper addresses the problem of generating meaningful summaries from unedited user videos. A framework based on spatiotemporal and high-level features is proposed in this paper to detect the key-shots after segmenting the videos into shots based on motion magnitude. To encode the time-varying characteristics of a video, we explore the local phase quantization feature descriptor from three orthogonal planes (LPQ-TOP). The sparse autoencoder (SAE), an instance of deep learning strategy, is used for the extraction of high-level features from LPQ-TOP descriptors to represent the shots carrying key-contents of videos efficiently. The Chebyshev distance between the feature vectors of the consecutive shots are calculated and thresholded using the mean value of the distance score as the threshold value. The optimal subset of shots with distance score greater than the threshold value is used to generate a high-quality video summary. The method is evaluated using SumMe data set. The summaries thus generated are of better quality than those produced by the other state of the art techniques. The effectiveness of the method is further evaluated by comparing with the human-created summaries in the ground truth.","","","10.1109/ACCESS.2018.2872685","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8476548","Video Summarization;shot segmentation;LPQ-TOP;sparse autoencoders;Chebyshev distance","Videos;Feature extraction;Motion segmentation;Histograms;Quantization (signal);Spatiotemporal phenomena;Chebyshev approximation","feature extraction;image segmentation;learning (artificial intelligence);video retrieval;video signal processing","dynamic summarization;space-time video volumes;sparse autoencoder;meaningful summaries;unedited user videos;high-level features;time-varying characteristics;local phase quantization feature descriptor;deep learning strategy;key-contents;Chebyshev distance;feature vectors;consecutive shots;distance score;threshold value;high-quality video summary","","1","35","","","","","IEEE","IEEE Journals"
"Data-Driven Lightweight Interest Point Selection for Large-Scale Visual Search","F. Gao; X. Zhang; Y. Huang; Y. Luo; X. Li; L. Duan","School of Electronics Engineering and Computer Science, Institute of Digital Media, Peking University, Beijing, China; Ming Hsieh Department of Electrical Engineering, University of Southern California, Los Angeles, CA, USA; School of Electronics Engineering and Computer Science, Institute of Digital Media, Peking University, Beijing, China; School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Electronics Engineering and Computer Science, Institute of Network Computing and Information Systems, Peking University, Beijing, China; School of Electronics Engineering and Computer Science, Institute of Digital Media, Peking University, Beijing, China","IEEE Transactions on Multimedia","","2018","20","10","2774","2787","With the explosive increase of images and videos, visual analysis has become an essential technique in dealing with the big visual data, which utilizes the visual feature descriptors to search or recognize the images or frames with target objects or events. Subject to the constraints of resources (e.g., memory, bandwidth, storage, etc.), interest point selection is crucial to generate robust compact descriptors for high-efficiency visual analysis by selecting and aggregating the most discriminative local feature descriptors, which has been demonstrated in the state-of-the-art low bit rate visual search works. In this paper, we propose a data-driven lightweight interest point selection approach to significantly improve the performance of visual search, while ameliorating the efficiency of extracting feature descriptors. Comprehensive experimental results over benchmarks have shown that the proposed interest point selection algorithm has significantly improved image matching and retrieval performance in the completed MPEG Compact Descriptors for Visual Search (CDVS) standard as well as the emerging MPEG Compact Descriptors for Video Analytics (CDVA) standard, say 20% mAP gain by data-driven selection against random selection of interest points. In particular, the presented data-driven interest point selection has been adopted by MPEG-CDVS and MPEG-CDVA as a normative technique to improve the aggregation of handcrafted features, which has contributed to the combination of handcrafted features and deep learning (CNN) features as well.","","","10.1109/TMM.2018.2818012","National Natural Science Foundation of China; National Basic Research Program of China (973 Program); PKU-NTU Joint Research Institute (JRI); Ng Teng Fong Charitable Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8320818","Visual search;interest point selection;compact descriptors;regression;classification;feature selection;MPEG-CDVS;MPEG-CDVA","Visualization;Transform coding;Redundancy;Proposals;Encoding;Visual databases","data analysis;feature extraction;feature selection;image matching;image retrieval;learning (artificial intelligence)","discriminative local feature descriptors;data-driven lightweight interest point selection approach;image matching;Visual Search standard;Video Analytics standard;data-driven selection;random selection;handcrafted features;big visual data;visual feature descriptors;target objects;target events;compact descriptors;visual analysis;MPEG Compact Descriptors for Video Analytics;visual search;bit rate visual search works;feature descriptors;MPEG Compact Descriptors for Visual Search;deep learning;MPEG-CDVS;MPEG-CDVA","","2","52","","","","","IEEE","IEEE Journals"
"Generalized Haar Filter-Based Object Detection for Car Sharing Services","K. Lu; J. Li; L. Zhou; X. Hu; X. An; H. He","College of Mechatronics and Automation, National University of Defense Technology, Changsha, China; College of Mechatronics and Automation, National University of Defense Technology, Changsha, China; College of Mechatronics and Automation, National University of Defense Technology, Changsha, China; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; College of Mechatronics and Automation, National University of Defense Technology, Changsha, China; College of Mechatronics and Automation, National University of Defense Technology, Changsha, China","IEEE Transactions on Automation Science and Engineering","","2018","15","4","1448","1458","Object detection is important in car sharing services. Accuracy, efficiency, and low memory consumption are desirable for object detection in car sharing services. This paper presents a network system that satisfies all these requirements. Our approach first divides the object detection task into multiple simpler local regression tasks. Then, we propose the generalized Haar filter-based convolutional neural network to reduce the consumption of memory and computing resource. To achieve real-time performance, we introduce a sparse window generation strategy to reduce the number of input image patches without sacrificing accuracy. We perform experiments on both vehicle and pedestrian data sets. Experimental results demonstrate that our approach can accurately detect objects under challenging conditions. Note to Practitioners-Object detection is an important part of intelligent vehicle technologies, which play an important role in car sharing services. Object detection provides metadata for collision avoidance, self-driving systems, and driver-assistance systems, which can result in better safety and consumer experiences in car sharing services. Although deep learning has achieved an excellent performance in object detection, they consume a large amount of storage and computing resource, which makes them difficult to be deployed for car sharing services. This paper suggests a novel approach which is based on the generalized Haar filter and the local regression strategy. Our approach is accurate, efficient, and light. The experimental results verify the effectiveness of the proposed approach in car sharing services.","","","10.1109/TASE.2018.2830655","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8360162","Car sharing;convolutional neural network (CNN);Haar filter;object detection;traffic scene","Object detection;Sharing economy;Task analysis;Memory management;Feature extraction;Real-time systems;Convolutional neaural networks","collision avoidance;convolution;driver information systems;feedforward neural nets;Haar transforms;intelligent transportation systems;learning (artificial intelligence);object detection;pedestrians;regression analysis;traffic engineering computing","car sharing services;object detection task;generalized Haar filter-based convolutional neural network;generalized Haar filter-based object detection;local regression tasks;pedestrian data sets;intelligent vehicle technologies;self-driving systems;collision avoidance;driver-assistance systems;deep learning","","1","46","","","","","IEEE","IEEE Journals"
"Energy Efficient Neural Computing: A Study of Cross-Layer Approximations","S. S. Sarwar; G. Srinivasan; B. Han; P. Wijesinghe; A. Jaiswal; P. Panda; A. Raghunathan; K. Roy","Department of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA; Department of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA; Department of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA; Department of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA; Department of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA; Department of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA; Department of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA; Department of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA","IEEE Journal on Emerging and Selected Topics in Circuits and Systems","","2018","8","4","796","809","Deep neural networks (DNNs) have emerged as the state-of-the-art technique in a wide range of machine learning tasks for analytics and computer vision in the next generation of embedded (mobile, IoT, and wearable) devices. Despite their success, they suffer from high energy requirements. In recent years, the inherent error resiliency of DNNs has been exploited by introducing approximations at either the algorithmic or the hardware levels (individually) to obtain energy savings while incurring tolerable accuracy degradation. However, there is a need for investigating the overall energy-accuracy trade-offs arising from the introduction of approximations at different levels in complex DNNs. We perform a comprehensive analysis to determine the effectiveness of cross-layer approximations for the energy-efficient realization of large-scale DNNs. The approximations considered are as follows: 1) use of lower complexity networks (containing lesser number of layers and/or neurons per layer); 2) pruning of synaptic weights; 3) approximate multiplication operation in the neuronal multiply-and-accumulate computation; and 4) approximate write/read operations to/from the synaptic memory. Our experiments on recognition benchmarks (MNIST and CIFAR10) show that cross-layer approximation provides substantial improvements in energy efficiency for different accuracy/quality requirements. Furthermore, we propose a synergistic framework for combining the approximation techniques to achieve maximal energy benefits from approximate DNNs.","","","10.1109/JETCAS.2018.2835809","Center for Brain-inspired Computing, one of six centers in JUMP; Semiconductor Research Corporation; National Science Foundation; Intel Corporation; Vannevar Bush Faculty Fellowship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8358698","Alphabet set multiplier (ASM);energy efficiency;network complexity;pruning;shallow network;hybrid 8T-6T SRAM;neural computing","Neurons;Artificial neural networks;Biological neural networks;Hardware;Approximation algorithms;Complexity theory;Synapses","approximation theory;learning (artificial intelligence);neural nets;optimisation;power aware computing","complex DNNs;cross-layer approximation;energy-efficient realization;large-scale DNNs;multiply- accumulate computation;energy efficiency;approximation techniques;maximal energy benefits;approximate DNNs;energy efficient neural computing;deep neural networks;machine learning tasks;computer vision;high energy requirements;energy savings;tolerable accuracy degradation;energy-accuracy trade-offs;quality requirements;complexity networks","","4","35","","","","","IEEE","IEEE Journals"
"Detection and Classification of Acoustic Scenes and Events: Outcome of the DCASE 2016 Challenge","A. Mesaros; T. Heittola; E. Benetos; P. Foster; M. Lagrange; T. Virtanen; M. D. Plumbley","Department of Signal Processing, Tampere University of Technology, Tampere, Finland; Department of Signal Processing, Tampere University of Technology, Tampere, Finland; Centre for Digital Music, Queen Mary University of London, London, U.K.; Centre for Digital Music, Queen Mary University of London, London, U.K.; ADTSI, IRCCYN, Ecole Centrale de Nantes, Nantes, France; Department of Signal Processing, Tampere University of Technology, Tampere, Finland; ADTSI, IRCCYN, Ecole Centrale de Nantes, Nantes, France","IEEE/ACM Transactions on Audio, Speech, and Language Processing","","2018","26","2","379","393","Public evaluation campaigns and datasets promote active development in target research areas, allowing direct comparison of algorithms. The second edition of the challenge on detection and classification of acoustic scenes and events (DCASE 2016) has offered such an opportunity for development of the state-of-the-art methods, and succeeded in drawing together a large number of participants from academic and industrial backgrounds. In this paper, we report on the tasks and outcomes of the DCASE 2016 challenge. The challenge comprised four tasks: acoustic scene classification, sound event detection in synthetic audio, sound event detection in real-life audio, and domestic audio tagging. We present each task in detail and analyze the submitted systems in terms of design and performance. We observe the emergence of deep learning as the most popular classification method, replacing the traditional approaches based on Gaussian mixture models and support vector machines. By contrast, feature representations have not changed substantially throughout the years, as mel frequency-based representations predominate in all tasks. The datasets created for and used in DCASE 2016 are publicly available and are a valuable resource for further research.","","","10.1109/TASLP.2017.2778423","European Research Council; U.K. RAEng Research Fellowship; U.K. Engineering and Physical Sciences Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8123864","Acoustic scene classification;audio datasets;pattern recognition;sound event detection","Acoustics;Event detection;Speech;Speech processing;Tagging;Hidden Markov models","acoustic signal processing;audio signal processing;feature extraction;learning (artificial intelligence);signal classification","acoustic scene classification;sound event detection;synthetic audio;classification method;deep learning;Gaussian mixture models;support vector machines;acoustic scenes;public evaluation campaigns;DCASE 2016 challenge;domestic audio tagging","","34","64","Traditional","","","","IEEE","IEEE Journals"
"A Review of Automatic Drum Transcription","C. Wu; C. Dittmar; C. Southall; R. Vogl; G. Widmer; J. Hockman; M. Müller; A. Lerch","Center for Music Technology, Georgia Institute of Technology, Atlanta, GA, USA; International Audio Laboratories Erlangen, Erlangen, Germany; Digital Media Technology Lab, Birmingham City University, Birmingham, U.K.; Department of Computational Perception, Johannes Kepler University Linz, Linz, Austria; Department of Computational Perception, Johannes Kepler University Linz, Linz, Austria; Digital Media Technology Lab, Birmingham City University, Birmingham, U.K.; International Audio Laboratories Erlangen, Erlangen, Germany; Center for Music Technology, Georgia Institute of Technology, Atlanta, GA, USA","IEEE/ACM Transactions on Audio, Speech, and Language Processing","","2018","26","9","1457","1483","In Western popular music, drums and percussion are an important means to emphasize and shape the rhythm, often defining the musical style. If computers were able to analyze the drum part in recorded music, it would enable a variety of rhythm-related music processing tasks. Especially the detection and classification of drum sound events by computational methods is considered to be an important and challenging research problem in the broader field of music information retrieval. Over the last two decades, several authors have attempted to tackle this problem under the umbrella term automatic drum transcription (ADT). This paper presents a comprehensive review of ADT research, including a thorough discussion of the task-specific challenges, categorization of existing techniques, and evaluation of several state-of-the-art systems. To provide more insights on the practice of ADT systems, we focus on two families of ADT techniques, namely methods based on non-negative matrix factorization and recurrent neural networks. We explain the methods' technical details and drum-specific variations and evaluate these approaches on publicly available data sets with a consistent experimental setup. Finally, the open issues and underexplored areas in ADT research are identified and discussed, providing future directions in this field.","","","10.1109/TASLP.2018.2830113","Austrian FFG; German Research Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8350302","Music information retrieval;automatic music transcription;automatic drum transcription;machine learning;matrix factorization;deep learning","Instruments;Task analysis;Speech processing;Spectrogram;Transient analysis;Rhythm","information retrieval;matrix decomposition;music;pattern classification;recurrent neural nets","nonnegative matrix factorization;drum-specific variations;ADT research;Western popular music;percussion;musical style;drum part;recorded music;rhythm-related music processing tasks;classification;drum sound events;computational methods;music information retrieval;umbrella term automatic drum transcription;task-specific challenges;state-of-the-art systems;ADT systems;ADT techniques","","3","108","","","","","IEEE","IEEE Journals"
"Nonintrusive Speech Intelligibility Prediction Using Convolutional Neural Networks","A. H. Andersen; J. M. de Haan; Z. Tan; J. Jensen","Oticon A/S, Smørum, Denmark; Oticon A/S, Smørum, Denmark; Aalborg University, Aalborg øst, Denmark; Oticon A/S, Smørum, Denmark","IEEE/ACM Transactions on Audio, Speech, and Language Processing","","2018","26","10","1925","1939","Speech Intelligibility Prediction (SIP) algorithms are becoming popular tools within the development and operation of speech processing devices and algorithms. However, many SIP algorithms require knowledge of the underlying clean speech; a signal that is often not available in real-world applications. This has led to increased interest in nonintrusive SIP algorithms, which do not require clean speech to make predictions. In this paper, we investigate the use of Convolutional Neural Networks (CNNs) for nonintrusive SIP. To do so, we utilize a CNN architecture that shows similarities to existing SIP algorithms, in terms of computational structure, and which allows for easy and meaningful visualization and interpretation of trained weights. We evaluate this architecture using a large dataset obtained by combining datasets from the literature. The proposed method shows high prediction performance when compared with four existing intrusive and nonintrusive SIP algorithms. This demonstrates the potential of deep learning for speech intelligibility prediction.","","","10.1109/TASLP.2018.2847459","Oticon Fonden; Danish Innovation Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8401691","Nonintrusive speech intelligibility prediction;convolutional neural networks","Prediction algorithms;Signal processing algorithms;Noise measurement;Speech processing;Artificial intelligence;Convolutional neural networks;Auditory system","convolution;learning (artificial intelligence);neural nets;speech intelligibility;speech processing","nonintrusive SIP algorithms;deep learning;computational structure;speech processing algorithms;speech processing devices;nonintrusive speech intelligibility prediction;convolutional neural networks","","","73","","","","","IEEE","IEEE Journals"
"Interactive Text2Pickup Networks for Natural Language-Based Human–Robot Collaboration","H. Ahn; S. Choi; N. Kim; G. Cha; S. Oh","Department of Electrical and Computer Engineering and ASRI, Seoul National University, Seoul, South Korea; Kakao Brain, Seongnam, South Korea; Department of Electrical and Computer Engineering and ASRI, Seoul National University, Seoul, South Korea; Department of Electrical and Computer Engineering and ASRI, Seoul National University, Seoul, South Korea; Department of Electrical and Computer Engineering and ASRI, Seoul National University, Seoul, South Korea","IEEE Robotics and Automation Letters","","2018","3","4","3308","3315","In this letter, we propose the Interactive Text2Pickup (IT2P) network for human-robot collaboration that enables an effective interaction with a human user despite the ambiguity in user's commands. We focus on the task where a robot is expected to pick up an object instructed by a human, and to interact with the human when the given instruction is vague. The proposed network understands the command from the human user and estimates the position of the desired object first. To handle the inherent ambiguity in human language commands, a suitable question which can resolve the ambiguity is generated. The user's answer to the question is combined with the initial command and given back to the network, resulting in more accurate estimation. The experiment results show that given unambiguous commands, the proposed method can estimate the position of the requested object with an accuracy of 98.49% based on the test dataset. Given ambiguous language commands, we show that the accuracy of the pick up task increases by 1.94 times after incorporating the information obtained from the interaction.","","","10.1109/LRA.2018.2852786","Basic Science Research Program; National Research Foundation of Korea; Ministry of Science and ICT; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8403299","Deep learning in robotics;learning and adaptive systems;social human-robot interaction","Heating systems;Robots;Task analysis;Uncertainty;Collaboration;Estimation;Training","human-robot interaction;natural language processing","IT2P network;human language commands;ambiguous language commands;natural language-based human-robot collaboration;Interactive Text2Pickup networks","","","16","","","","","IEEE","IEEE Journals"
"Occlusion-robust object tracking based on the confidence of online selected hierarchical features","M. Liu; C. Jin; B. Yang; X. Cui; H. Kim","Inha University, Republic of Korea; Inha University, Republic of Korea; Inha University, Republic of Korea; Inha University, Republic of Korea; Inha University, Republic of Korea","IET Image Processing","","2018","12","11","2023","2029","In recent years, convolutional neural networks (CNNs) have been widely used for visual object tracking, especially in combination with correlation filters (CFs). However, the increasing complex CNN models introduce more useless information, which may decrease the tracking performance. This study proposes an online feature map selection method to remove noisy and irrelevant feature maps from different convolutional layers of CNN, which can reduce computation redundancy and improve tracking accuracy. Furthermore, a novel appearance model update strategy, which exploits the feedback from the peak value of response maps, is developed to avoid model corruption. Finally, an extensive evaluation of the proposed method was conducted over OTB-2013 and OTB-2015 datasets, and compared with different kinds of trackers, including deep learning-based trackers and CF-based trackers. The results demonstrate that the proposed method achieves a highly satisfactory performance.","","","10.1049/iet-ipr.2018.5454","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8502736","","","feature extraction;learning (artificial intelligence);neural nets;object detection;object tracking","CNN;computation redundancy;tracking accuracy;appearance model update strategy;model corruption;OTB-2015 datasets;deep learning-based trackers;CF-based trackers;occlusion-robust object tracking;online selected hierarchical features;convolutional neural networks;visual object tracking;correlation filters;useless information;tracking performance;feature map selection method;convolutional layers","","1","34","","","","","IET","IET Journals"
"Automatic Timed Up-and-Go Sub-Task Segmentation for Parkinson’s Disease Patients Using Video-Based Activity Classification","T. Li; J. Chen; C. Hu; Y. Ma; Z. Wu; W. Wan; Y. Huang; F. Jia; C. Gong; S. Wan; L. Li","Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; School of Aerospace Engineering, Man-Machine-Environment Engineering Institute, Tsinghua University, Beijing, China; Tsinghua University Yuquan Hospital, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; School of Aerospace Engineering, Man-Machine-Environment Engineering Institute, Tsinghua University, Beijing, China; School of Aerospace Engineering, Man-Machine-Environment Engineering Institute, Tsinghua University, Beijing, China; School of Aerospace Engineering, Man-Machine-Environment Engineering Institute, Tsinghua University, Beijing, China; National Engineering Laboratory for Neuromodulation, Precision Medicine and Healthcare Research Center, Center of Epilepsy, School of Aerospace Engineering, Man-Machine-Environment Engineering Institute, Beijing Institute for Brain Disorders, Tsinghua-Berkeley Shenzhen Institute, Tsinghua University, Beijing, China","IEEE Transactions on Neural Systems and Rehabilitation Engineering","","2018","26","11","2189","2199","The timed up-and-go (TUG) test has been widely accepted as a standard assessment for measuring the basic functional mobility of patients with Parkinson's disease. Several basic mobility sub-tasks “Sit,” “Sit-to-Stand,” “Walk,” “Turn,” “Walk-Back,” and “Sit-Back” are included in a TUG test. It has been shown that the time costs of these sub-tasks are useful clinical parameters for the assessment of Parkinson's disease. Several automatic methods have been proposed to segment and time these sub-tasks in a TUG test. However, these methods usually require either well-controlled environments for the TUG video recording or information from special devices, such as wearable inertial sensors, ambient sensors, or depth cameras. In this paper, an automatic TUG sub-task segmentation method using video-based activity classification is proposed and validated in a study with 24 Parkinson's disease patients. Videos used in this paper are recorded in semi-controlled environments with various backgrounds. The state-of-the-art deep learning-base 2-D human pose estimation technologies are used for feature extraction. A support vector machine and a long short-term memory network are then used for the activity classification and the subtask segmentation. Our method can be used to automatically acquire clinical parameters for the assessment of Parkinson's disease using TUG videos-only, leading to the possibility of remote monitoring of the patients' condition.","","","10.1109/TNSRE.2018.2875738","National Natural Science Foundation of China; National Key Research and Development Program of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8490862","Timed up-and-go;Parkinson’s disease;human pose estimation;sub-task segmentation","Cameras;Parkinson's disease;Video sequences;Wearable sensors;Two dimensional displays;Hospitals","diseases;feature extraction;image classification;image segmentation;learning (artificial intelligence);medical image processing;neurophysiology;pose estimation;support vector machines;video signal processing","video-based activity classification;TUG test;Parkinson's disease patients;deep learning;automatic timed up-and-go sub-task segmentation;automatic TUG sub-task segmentation;patients mobility;Sit-to-Stand;Walk-Back;Sit-Back;Turn;TUG video recording;2-D human pose estimation technologies;feature extraction;support vector machine;long short-term memory network;activity classification","","1","29","","","","","IEEE","IEEE Journals"
"Combining 2D and 3D features to improve road detection based on stereo cameras","G. Cai; S. Su; W. He; Y. Wu; S. Li","Jimei University, People's Republic of China; Xiamen University, People's Republic of China; Xiamen University, People's Republic of China; Jimei University, People's Republic of China; Xiamen University, People's Republic of China","IET Computer Vision","","2018","12","6","834","843","Road detection is a fundamental component of autonomous driving systems since it provides valid space and candidate regions of objects for driving decision. The core of road detection methods is extracting effective and discriminative features. Since two-dimensional (2D) and 3D features are complementary, the authors propose a robust multi-feature combination and optimisation framework for stereo image pairs, called Feature++. First, several 2D and 3D features such as Gabor and plane are, respectively, extracted after the generation of 2D super-pixel and a 3D depth image from stereo matching. Second, the combined features are fed into a three-layer shallow neural network classifier to decide whether a super-pixel is road region or not. Finally, the classified results are further refined using fully connected conditional random field (CRF), taking the content information into consideration. We extensively evaluate the performance of four 2D features, four 3D features, and their combinations. Experiments conducted on the KITTI ROAD benchmark show that (i) the combinations of 2D and 3D features greatly improve the road detection performance and (ii) using CRF as a refinement step is necessary. Overall, their proposed `Feature + +' method outperforms most manually designed features, and is comparable with state-of-the-art methods that are based on deep learning methods.","","","10.1049/iet-cvi.2017.0266","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8435138","","","feature extraction;image resolution;learning (artificial intelligence);neural nets;object detection;pattern classification;stereo image processing;traffic engineering computing","3D features;2D features;road detection;stereo cameras;autonomous driving systems;driving decision;discriminative features;effective features;robust multifeature combination;optimisation framework;stereo image pairs;Feature++;Gabor;2D super-pixel;3D depth image;three-layer shallow neural network classifier;conditional random field;CRF;KITTI ROAD benchmark;deep learning methods;source code","","","","","","","","IET","IET Journals"
"Radar emitter classification based on unidimensional convolutional neural network","J. Sun; G. Xu; W. Ren; Z. Yan","University of Chinese Academy of Sciences, People's Republic of China; Institute of Electronics, Chinese Academy of Sciences, People's Republic of China; Institute of Electronics, Chinese Academy of Sciences, People's Republic of China; University of Chinese Academy of Sciences, People's Republic of China","IET Radar, Sonar & Navigation","","2018","12","8","862","867","Radar emitter classification (REC) is an essential part of electronic warfare (EW) systems. In REC tasks, after deinterleaving, the intercepted radar signals are classified into specific radar types. With new radar types arising and the electromagnetism environment getting complicated, REC has become a big data problem. Meanwhile, there exist inconsistent features among samples. These two problems can affect the performance of classification. In this work, first, the authors designed a novel encoding method to deal with the inconsistent features. High-dimension sequences of equal length are generated as new features. Then a deep learning model named unidimensional convolutional neural network (U-CNN) is proposed to classify the encoded high-dimension sequences with big data. A large and complex radar emitter's dataset is used to evaluate the performance of the U-CNN model with the encoding method. Experiments show that the authors' proposal gains an improvement of 2-3% in accuracy compared with the state-of-the-art methods, while the time consumed for identifying 45,509 emitters is only 1.95 s using a GPU. Specifically, for 12 indistinguishable radars, the classification accuracy is improved about 15%.","","","10.1049/iet-rsn.2017.0547","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8418258","","","Big Data;electrical engineering computing;electromagnetism;electronic warfare;learning (artificial intelligence);neural nets;radar signal processing;sequences;signal classification","U-CNN model;deep learning model;high-dimension equal length sequence;encoding method;big data problem;electromagnetism environment;radar signal classification;EW system;electronic warfare system;REC;unidimensional convolutional neural network;radar emitter classification","","2","22","","","","","IET","IET Journals"
"Smart Campus Care and Guiding With Dedicated Video Footprinting Through Internet of Things Technologies","L. Chen; T. Chen; D. Chen; J. Liu; M. Tsai","Department of Information Engineering and Computer Science, Feng Chia University, Taichung, Taiwan; Department of Information Engineering and Computer Science, Feng Chia University, Taichung, Taiwan; Department of Information Engineering and Computer Science, Feng Chia University, Taichung, Taiwan; Department of Information Engineering and Computer Science, Feng Chia University, Taichung, Taiwan; Department of Electronic Engineering, National United University, Miaoli, Taiwan","IEEE Access","","2018","6","","43956","43966","In this paper, we propose a smart campus care and guiding framework with deep learning-based face recognition, called DeepGuiding, for students through Internet of Things technologies. The DeepGuiding framework can construct the dedicated video trajectory of a campus student, where the recorded video for each student can be automatically classified to achieve efficient footprint review as necessary. In addition, DeepGuiding can provide time-efficient indoor and outdoor guiding in a campus to quickly reach places, meet friends, and find students. To the best of our knowledge, DeepGuiding is the first campus care and guiding system which provides the following features: 1) it achieves the seamless outdoor and indoor navigation between buildings in a campus; 2) it keeps additional construction cost low by utilizing existing surveillance cameras in a campus; and 3) it reduces the total searching time for finding a specific event/target in a campus by alleviating time-consuming labor overhead to review a huge amount of video data. An Android-based prototype using iBeacon indoor localization and global positioning system outdoor positioning with surveillance cameras is implemented to verify the feasibility and superiority of our DeepGuiding framework. The Experimental results show that DeepGuiding outperforms existing face recognition methods and can achieve high recognition accuracy for students not close to surveillance cameras.","","","10.1109/ACCESS.2018.2856251","Ministry of Science and Technology, Taiwan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8411423","Face detection;face recognition;indoor positioning;Internet of Things;mobile device","Face recognition;Face;Surveillance;Cameras;Neurons;Global Positioning System;Servers","face recognition;Global Positioning System;learning (artificial intelligence);mobile computing;smart phones;video cameras;video surveillance","indoor navigation;total searching time;video data;surveillance cameras;DeepGuiding framework;smart campus care;dedicated video footprinting;deep learning-based face recognition;dedicated video trajectory;campus student;time-efficient indoor;outdoor guiding;guiding system;seamless outdoor navigation;Internet of Things technologies;Global Positioning System outdoor positioning;footprint review","","2","26","","","","","IEEE","IEEE Journals"
"Training and testing object detectors with virtual images","Y. Tian; X. Li; K. Wang; F. Wang","Department of Automation, University of Science and Technology of China, Hefei 230027, China, and also with the State Key Laboratory for Management and Control of Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China; School of Automation, Beijing Institute of Technology, Beijing 100081, China; State Key Laboratory for Management and Control of Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China, and also with Qingdao Academy of Intelligent Industries, Qingdao 266000, China; State Key Laboratory for Management and Control of Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China, and also with the Research Center for Computational Experiments and Parallel Systems Technology, National University of Defense Technology, Changsha 410073, China","IEEE/CAA Journal of Automatica Sinica","","2018","5","2","539","546","In the area of computer vision, deep learning has produced a variety of state-of-the-art models that rely on massive labeled data. However, collecting and annotating images from the real world is too demanding in terms of labor and money investments, and is usually inflexible to build datasets with specific characteristics, such as small area of objects and high occlusion level. Under the framework of Parallel Vision, this paper presents a purposeful way to design artificial scenes and automatically generate virtual images with precise annotations. A virtual dataset named ParallelEye is built, which can be used for several computer vision tasks. Then, by training the DPM U+0028 Deformable parts model U+0029 and Faster R-CNN detectors, we prove that the performance of models can be significantly improved by combining ParallelEye with publicly available real-world datasets during the training phase. In addition, we investigate the potential of testing the trained models from a specific aspect using intentionally designed virtual datasets, in order to discover the flaws of trained models. From the experimental results, we conclude that our virtual dataset is viable to train and test the object detectors.","","","10.1109/JAS.2017.7510841","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8283979","","Detectors;Cameras;Training;Testing;Computer vision;Computational modeling;Automobiles","computer vision;feedforward neural nets;learning (artificial intelligence);object detection","Parallel Vision;artificial scenes;virtual images;virtual dataset;ParallelEye;computer vision tasks;DPM U+0028 Deformable parts model U+0029;Faster R-CNN detectors;real-world datasets;training phase;deep learning;massive labeled data;high occlusion level;object detector testing;object detector training","","4","","","","","","IEEE","IEEE Journals"
"Real-Time Stereo Vision System: A Multi-Block Matching on GPU","Q. Chang; T. Maruyama","Graduate School of Systems and Information Engineering, University of Tsukuba, Tsukuba, Japan; Graduate School of Systems and Information Engineering, University of Tsukuba, Tsukuba, Japan","IEEE Access","","2018","6","","42030","42046","Real-time stereo vision is attractive in many areas such as outdoor mapping and navigation. As a popular accelerator in the image processing field, GPU is widely used for the studies of the stereo vision algorithms. Recently, many stereo vision systems on GPU have achieved low error rate, as a result of the development of deep learning. However, their processing speed is normally far from the real-time requirement. In this paper, we propose a real-time stereo vision system on GPU for the high-resolution images. This system also maintains a low error rate compared with other fast systems. In our approach, the image is resized to reduce the computational complexity and to realize the real-time processing. The low error rate is kept by using the cost aggregation with multiple blocks, secondary matching and sub-pixel estimation. Its processing speed is 41 fps for 2888×1920 pixels images when the maximum disparity is 760.","","","10.1109/ACCESS.2018.2859445","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8419688","Stereo vision;GPU;multi-block;real-time","Graphics processing units;Real-time systems;Stereo vision;Image resolution;Error analysis;Computational complexity;Acceleration","computational complexity;computer vision;graphics processing units;image matching;learning (artificial intelligence);stereo image processing","real-time stereo vision system;multiblock matching;GPU;image processing field;stereo vision algorithms;low error rate;processing speed;real-time processing;outdoor mapping;outdoor navigation;deep learning development;high-resolution images;subpixel estimation;cost aggregation;secondary matching;computational complexity","","2","55","CCBY","","","","IEEE","IEEE Journals"
"Mitigating Asymmetric Nonlinear Weight Update Effects in Hardware Neural Network Based on Analog Resistive Synapse","C. Chang; P. Chen; T. Chou; I. Wang; B. Hudec; C. Chang; C. Tsai; T. Chang; T. Hou","Department of Electronics Engineering and Institute of Electronics, National Chiao Tung University, Hsinchu, Taiwan; Department of Electronics Engineering and Institute of Electronics, National Chiao Tung University, Hsinchu, Taiwan; Department of Electronics Engineering and Institute of Electronics, National Chiao Tung University, Hsinchu, Taiwan; Department of Electronics Engineering and Institute of Electronics, National Chiao Tung University, Hsinchu, Taiwan; Department of Electronics Engineering and Institute of Electronics, National Chiao Tung University, Hsinchu, Taiwan; Department of Electronics Engineering and Institute of Electronics, National Chiao Tung University, Hsinchu, Taiwan; Department of Electronics Engineering and Institute of Electronics, National Chiao Tung University, Hsinchu, Taiwan; Department of Electronics Engineering and Institute of Electronics, National Chiao Tung University, Hsinchu, Taiwan; Department of Electronics Engineering and Institute of Electronics, National Chiao Tung University, Hsinchu, Taiwan","IEEE Journal on Emerging and Selected Topics in Circuits and Systems","","2018","8","1","116","124","Asymmetric nonlinear weight update is considered as one of the major obstacles for realizing hardware neural networks based on analog resistive synapses, because it significantly compromises the online training capability. This paper provides new solutions to this critical issue through co-optimization with the hardware-applicable deep-learning algorithms. New insights on engineering activation functions and a threshold weight update scheme effectively suppress the undesirable training noise induced by inaccurate weight update. We successfully trained a two-layer perceptron network online and improved the classification accuracy of MNIST handwritten digit data set to 87.8%/94.8% by using 6-/8-b analog synapses, respectively, with extremely high asymmetric nonlinearity.","","","10.1109/JETCAS.2017.2771529","Ministry of Science and Technology of Taiwan; Research of Excellence Program; Taiwan Semiconductor Manufacturing Company; NCTU-UCB I-RiCE Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8101463","Neuromorphic computing;RRAM;synapse;multilayer perceptron","Neurons;Training;Biological neural networks;Hardware;Circuits and systems;Multilayer perceptrons","learning (artificial intelligence);multilayer perceptrons;neural chips","activation functions;asymmetric nonlinearity;asymmetric nonlinear weight update effect mitigation;hardware neural network;two-layer perceptron network;threshold weight;deep-learning algorithms;online training capability;analog resistive synapse","","7","29","","","","","IEEE","IEEE Journals"
"Person Re-Identification Based on Heterogeneous Part-Based Deep Network in Camera Networks","Z. Zhang; M. Huang","Tianjin Key Laboratory of Wireless Mobile Communications and Power Transmission, and College of Electronic and Communication Engineering, Tianjin Normal University, Tianjin 300387, China (e-mail: zhong.zhang8848@gmail.com).; Tianjin Key Laboratory of Wireless Mobile Communications and Power Transmission, and College of Electronic and Communication Engineering, Tianjin Normal University, Tianjin 300387, China (e-mail: meiyanhuang7295@gmail.com).","IEEE Transactions on Emerging Topics in Computational Intelligence","","2018","PP","99","1","10","In this paper, we propose a new deep learning model named heterogeneous part-based deep network for person re-identification in camera networks, which simultaneously learns the alignment and discrimination for parts of pedestrian images. Concretely, several parts are obtained through the uniform partition on the convolutional layer for each pedestrian image. Then, we present part-aligned distances to perform alignment by searching the shortest local distances between image parts in a certain range. Meanwhile, we utilize the batch hard triplet loss and cross-entropy loss to learn more discriminative part-based features in different aspects. Experiments are conducted on three challenging datasets, Market-1501, CUHK03, and DukeMTMC-reID, and we achieve 94.0%, 64.3%, and 83.6% rank-1 accuracy and 81.2%, 58.2%, and 68.0% mAP, outperforming the state-of-the-art methods by a large margin.","","","10.1109/TETCI.2018.2883348","National Natural Science Foundation of China; Natural Science Foundation of Tianjin City; Tianjin Normal University; National Laboratory of Pattern Recognition; China Scholarship Council; Tianjin Higher Education Creative Team Funds Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8574024","Camera networks;person re-identification;part-based features","Feature extraction;Cameras;Measurement;Computational modeling;Computational intelligence;Pose estimation","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A New Anchor-Labeling Method For Oriented Text Detection Using Dense Detection Framework","C. Yan; K. Wu; C. Zhang","Department of Automation, Tsinghua University, Beijing, China; Department of Automation, Tsinghua University, Beijing, China; Department of Automation, Tsinghua University, Beijing, China","IEEE Signal Processing Letters","","2018","25","9","1295","1299","This letter proposes a new method for dense scene text detection anchor box labeling using single-shot multibox detection (SSD) as the base framework and VGG16 as the backbone, enhanced for scene text detection. This method can be further generalized to other detection tasks with various aspect ratios. We argue that the IoU criterion used by the dense object detection framework may have low recall ratios in extreme aspect ratio cases and oriented objects, and we propose a new criterion of the anchor-labeling method for these kinds of objects. The result shows that this method has better performance on public datasets compared with the previous labeling methods.","","","10.1109/LSP.2018.2852954","National Natural Science Foundation of China; Natural Science Foundation of Beijing Municipality; NSFC and the German Research Foundation (DFG) in Project Crossmodal Learning; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8403317","Deep neural network (DNN);geometry transformation;text detection","Labeling;Task analysis;Feature extraction;Machine learning;Neural networks;Training;Object detection","object detection;text analysis;text detection","detection tasks;aspect ratios;dense object detection framework;low recall ratios;extreme aspect ratio cases;oriented objects;new anchor-labeling method;oriented text detection;dense detection framework;dense scene text detection anchor box labeling;single-shot multibox detection;base framework;VGG16","","","39","","","","","IEEE","IEEE Journals"
"Integration Convolutional Neural Network for Person Re-Identification in Camera Networks","Z. Zhang; T. Si; S. Liu","Tianjin Key Laboratory of Wireless Mobile Communications and Power Transmission, Tianjin Normal University, Tianjin, China; Tianjin Key Laboratory of Wireless Mobile Communications and Power Transmission, Tianjin Normal University, Tianjin, China; Tianjin Key Laboratory of Wireless Mobile Communications and Power Transmission, Tianjin Normal University, Tianjin, China","IEEE Access","","2018","6","","36887","36896","In this paper, we propose a novel deep model named integration convolutional neural network (ICNN) for person re-identification in camera networks, which jointly learns global and local features in a unified framework. To this end, the proposed ICNN simultaneously applies two kinds of loss functions. Specifically, we propose the soft triplet loss to learn global features which automatically adjusts the margin threshold within one batch. The soft triplet loss could alleviate the difficult in tuning parameters and therefore learns discriminative global features. In order to avoid the part misalignment problem, we learn latent local features by conducting local horizontal average pooling on the convolutional maps. Afterward, we implement the identification task on each local feature. We concatenate global and local features using a weighted strategy to present the pedestrian images. We evaluate the proposed ICNN on three large-scale databases. Our method achieves rank-1 accuracy of 92.13% on Market 1501, 61.4% onCUHK03 and 85.3% on DukeMTMC-reID, and the results outperform the state-of-the-art methods.","","","10.1109/ACCESS.2018.2852712","National Natural Science Foundation of China; Natural Science Foundation of Tianjin City; Tianjin Normal University; Open Projects Program of National Laboratory of Pattern Recognition; China Scholarship Council; Tianjin Higher Education Creative Team Funds Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8402217","Camera networks;person re-identification;convolutional neural network","Feature extraction;Task analysis;Cameras;Convolutional neural networks;Loss measurement;Machine learning;Databases","cameras;convolution;feature extraction;feedforward neural nets;learning (artificial intelligence);visual databases","large scale databases;pedestrian images;misalignment problem;tuning parameters;margin threshold;unified framework;person re identification;soft triplet loss;camera networks;integration convolutional neural network;ICNN;local horizontal average pooling;latent local features","","7","65","","","","","IEEE","IEEE Journals"
"Face recognition with compressed Fisher vector on multiscale convolutional features","W. Deng; H. Wang","Pattern Recognition and Intelligent Systems Lab, Beijing University of Posts and Telecommunications, People's Republic of China; Pattern Recognition and Intelligent Systems Lab, Beijing University of Posts and Telecommunications, People's Republic of China","IET Biometrics","","2018","7","5","447","453","Representations generated by Fisher vector (FV) have shown decent performances on many facial image datasets. However, discriminative information could be masked by noise if the authors directly sum all local responses with respect to the learned dictionary. Further, the high dimension of FV prohibits its practical use. To mitigate these problems, the authors propose a new framework called joint compressed Fisher vector (JCFV), which generate task-specific data representation by jointly encoding multiscale deep convolutional activations. Firstly, they feed into the deep network facial images cropped with cascaded sub-windows and resized into various scales. Next, they select discriminative convolutional features to form a dictionary. Then, they aggregate multiscale features with respect to the dictionary by calculating a re-weighted first-order statistics. JCFV halves the dimension of FV, and they could further compress the dimension with several combinations of subspace methods. They prove the effectiveness of their JCFV descriptor with comprehensive experiments on FERET, AR, LFW and FRGC 2.0 Experiment 4.","","","10.1049/iet-bmt.2017.0194","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8440873","","","data compression;face recognition;feature selection;neural nets;statistical analysis","JCFV descriptor;subspace methods;re-weighted first-order statistics;multiscale feature aggregation;discriminative convolutional feature selection;cascaded sub-windows;deep network facial images;multiscale deep convolutional activation encoding;task-specific data representation;JCFV;joint compressed Fisher vector;learned dictionary;discriminative information;facial image datasets;multiscale convolutional features;face recognition","","","","","","","","IET","IET Journals"
"Interpolating Seismic Data With Conditional Generative Adversarial Networks","D. A. B. Oliveira; R. S. Ferreira; R. Silva; E. Vital Brazil","IBM Research, Rio de Janeiro, Brazil; IBM Research, Rio de Janeiro, Brazil; IBM Research, Rio de Janeiro, Brazil; IBM Research, Rio de Janeiro, Brazil","IEEE Geoscience and Remote Sensing Letters","","2018","15","12","1952","1956","Having dense and regularly sampled data is becoming increasingly important in seismic processing. However, due to physical or financial constraints, seismic data sets can be often undersampled. Occasionally, these data sets may also present bad or dead traces the geoscientist must deal with. Many works have tackled this problem using prestack data and can be classified in three main categories: wave-equation, domain transform, and prediction-error-filter methods. In this letter, we assess the performance of a conditional generative adversarial network for the interpolation problem in poststack seismic data sets. To the best of our knowledge, this is the first work to evaluate a deep learning approach in this context. Quantitative and qualitative evaluations of our experiments indicate that deep networks may present an interesting alternative to classical methods.","","","10.1109/LGRS.2018.2866199","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8465958","Geoscience;geophysical image processing;multilayer neural network","Training;Generators;Interpolation;Gallium nitride;Testing;Transforms;Decoding","geophysical techniques;seismic waves;seismology","conditional generative adversarial network;dense sampled data;regularly sampled data;seismic processing;physical constraints;financial constraints;bad traces;dead traces;prestack data;prediction-error-filter methods;interpolation problem;poststack seismic data sets;deep networks;wave-equation;domain transform;deep learning approach","","","22","","","","","IEEE","IEEE Journals"
"Leveraging Content Sensitiveness and User Trustworthiness to Recommend Fine-Grained Privacy Settings for Social Image Sharing","J. Yu; Z. Kuang; B. Zhang; W. Zhang; D. Lin; J. Fan","School of Computer Science, Hangzhou Dianzi University, Hangzhou, China; School of Computer Science, Hangzhou Dianzi University, Hangzhou, China; UNC-Charlotte, Charlotte, NC, USA; UNC-Charlotte, Charlotte, NC, USA; Department of Computer Science, Missouri University of Science and Technology, Rolla, MO, USA; Department of Computer Science, UNC-Charlotte, Charlotte, NC, USA","IEEE Transactions on Information Forensics and Security","","2018","13","5","1317","1332","To configure successful privacy settings for social image sharing, two issues are inseparable: 1) content sensitiveness of the images being shared; and 2) trustworthiness of the users being granted to see the images. This paper aims to consider these two inseparable issues simultaneously to recommend fine-grained privacy settings for social image sharing. For achieving more compact representation of image content sensitiveness (privacy), two approaches are developed: 1) a deep network is adapted to extract 1024-D discriminative deep features; and 2) a deep multiple instance learning algorithm is adopted to identify 280 privacy-sensitive object classes and events. Second, users on the social network are clustered into a set of representative social groups to generate a discriminative dictionary for user trustworthiness characterization. Finally, both the image content sensitiveness and the user trustworthiness are integrated to train a tree classifier to recommend fine-grained privacy settings for social image sharing. Our experimental studies have demonstrated both the efficiency and the effectiveness of our proposed algorithms.","","","10.1109/TIFS.2017.2787986","National Science Foundation; NSFC; NSFC; NSFC; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8249924","Privacy setting recommendation;image content sensitiveness;user trustworthiness;deep multiple instance learning;tree classifier;social image sharing","Privacy;Feature extraction;Visualization;Computer science;Electronic mail;Social network services","data privacy;feature extraction;image classification;image representation;social networking (online);trees (mathematics);trusted computing","privacy-sensitive object classes;image content sensitiveness;social image sharing;fine-grained privacy settings","","15","71","","","","","IEEE","IEEE Journals"
"A Multi-Modal, Discriminative and Spatially Invariant CNN for RGB-D Object Labeling","U. Asif; M. Bennamoun; F. A. Sohel","IBM Research, Melbourne, Vic, Australia; University of Western Australia, Crawley, WA, Australia; Murdoch University, Murdoch, WA, Australia","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","9","2051","2065","While deep convolutional neural networks have shown a remarkable success in image classification, the problems of inter-class similarities, intra-class variances, the effective combination of multi-modal data, and the spatial variability in images of objects remain to be major challenges. To address these problems, this paper proposes a novel framework to learn a discriminative and spatially invariant classification model for object and indoor scene recognition using multi-modal RGB-D imagery. This is achieved through three postulates: 1) spatial invariance-this is achieved by combining a spatial transformer network with a deep convolutional neural network to learn features which are invariant to spatial translations, rotations, and scale changes, 2) high discriminative capability-this is achieved by introducing Fisher encoding within the CNN architecture to learn features which have small inter-class similarities and large intra-class compactness, and 3) multi-modal hierarchical fusion-this is achieved through the regularization of semantic segmentation to a multi-modal CNN architecture, where class probabilities are estimated at different hierarchical levels (i.e., imageand pixel-levels), and fused into a Conditional Random Field (CRF)-based inference hypothesis, the optimization of which produces consistent class labels in RGB-D images. Extensive experimental evaluations on RGB-D object and scene datasets, and live video streams (acquired from Kinect) show that our framework produces superior object and scene classification results compared to the state-of-the-art methods.","","","10.1109/TPAMI.2017.2747134","Australian Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8022892","RGB-D object recognition;3D scene labeling;semantic segmentation","Three-dimensional displays;Labeling;Solid modeling;Proposals;Semantics;Image reconstruction;Computational modeling","feature extraction;feedforward neural nets;image classification;image coding;image colour analysis;image segmentation;image sensors;learning (artificial intelligence);probability;video streaming","spatially invariant CNN;deep convolutional neural network;image classification;multimodal data;spatial variability;discriminative classification model;spatially invariant classification model;indoor scene recognition;multimodal RGB-D imagery;spatial transformer network;spatial translations;high discriminative capability-this;multimodal hierarchical fusion-this;multimodal CNN architecture;class probabilities;RGB-D images;scene classification results;intraclass variances;intraclass compactness;interclass similarities;conditional random field-based inference hypothesis","","4","45","","","","","IEEE","IEEE Journals"
"Learning Multiviewpoint Context-Aware Representation for RGB-D Scene Classification","Y. Zheng; H. Ye; L. Wang; J. Pu","Shanghai Advanced Research Institute, Chinese Academy of Sciences, Shanghai, China; Shanghai Advanced Research Institute, Chinese Academy of Sciences, Shanghai, China; Shanghai Advanced Research Institute, Chinese Academy of Sciences, Shanghai, China; School of Computer Science and Software Engineering, East China Normal University, Shanghai, China","IEEE Signal Processing Letters","","2018","25","1","30","34","Effective visual representation plays an important role in the scene classification systems. While many existing methods are focused on the generic descriptors extracted from the RGB color channels, we argue the importance of depth context, since scenes are composed with spatial variability and depth is an essential component in understanding the geometry. In this letter, we present a novel depth representation for RGB-D scene classification based on a specific designed convolutional neural network (CNN). Contrast to previous deep models that transfer from pretrained RGB CNN models, we harness model by using the multiviewpoint depth image augmentation to overcome the data scarcity problem. The proposed CNN framework contains the dilated convolutions to expand the receptive field and a subsequent spatial pooling to aggregate multiscale contextual information. The combination of contextual design and multiviewpoint depth images are important toward a more compact representation, compared to directly using original depth images or off-the-shelf networks. Through extensive experiments on SUN RGB-D dataset, we demonstrate that the representation outperforms recent state of the arts, and combining it with standard CNN-based RGB features can lead to further improvements.","","","10.1109/LSP.2017.2764489","National Natural Science Foundation of China; Science and Technology Commission of Shanghai Municipality; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8074737","Context-aware representation;multiviewpoint depth images;RGB-D images;scene classification","Image color analysis;Data models;Geometry;Convolution;Three-dimensional displays;Training","feature extraction;image classification;image colour analysis;image representation;learning (artificial intelligence);neural nets","multiviewpoint context-aware representation;RGB-D scene classification;scene classification systems;RGB color channels;depth context;spatial variability;depth representation;pretrained RGB CNN models;multiviewpoint depth image augmentation;subsequent spatial pooling;multiviewpoint depth images;visual representation;convolutional neural network;SUN RGB-D dataset;data scarcity problem;dilated convolutions;multiscale contextual information;contextual design;CNN-based RGB features","","2","35","Traditional","","","","IEEE","IEEE Journals"
"Saliency Detection via Absorbing Markov Chain With Learnt Transition Probability","L. Zhang; J. Ai; B. Jiang; H. Lu; X. Li","School of Information and Communication Engineering, Dalian University of Technology, Dalian, China; School of Information and Communication Engineering, Dalian University of Technology, Dalian, China; AutoNavi Software Company, Ltd., Beijing, China; School of Information and Communication Engineering, Dalian University of Technology, Dalian, China; School of Information and Communication Engineering, Dalian University of Technology, Dalian, China","IEEE Transactions on Image Processing","","2018","27","2","987","998","In this paper, we propose a bottom-up saliency model based on absorbing Markov chain (AMC). First, a sparsely connected graph is constructed to capture the local context information of each node. All image boundary nodes and other nodes are, respectively, treated as the absorbing nodes and transient nodes in the absorbing Markov chain. Then, the expected number of times from each transient node to all other transient nodes can be used to represent the saliency value of this node. The absorbed time depends on the weights on the path and their spatial coordinates, which are completely encoded in the transition probability matrix. Considering the importance of this matrix, we adopt different hierarchies of deep features extracted from fully convolutional networks and learn a transition probability matrix, which is called learnt transition probability matrix. Although the performance is significantly promoted, salient objects are not uniformly highlighted very well. To solve this problem, an angular embedding technique is investigated to refine the saliency results. Based on pairwise local orderings, which are produced by the saliency maps of AMC and boundary maps, we rearrange the global orderings (saliency value) of all nodes. Extensive experiments demonstrate that the proposed algorithm outperforms the state-of-the-art methods on six publicly available benchmark data sets.","","","10.1109/TIP.2017.2766787","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8085143","Salient object detection;absorbing Markov chain;transition probability matrix;angular embedding","Markov processes;Transient analysis;Feature extraction;Object detection;Computational modeling;Sparse matrices;Image segmentation","convolution;feature extraction;graph theory;Markov processes;matrix algebra;object detection;probability","saliency detection;absorbing Markov chain;image boundary nodes;absorbing nodes;transient node;learnt transition probability matrix;saliency maps;bottom-up saliency model;sparsely connected graph;feature extraction;fully convolutional networks;angular embedding technique;pairwise local orderings;boundary maps;salient object detection","","7","61","","","","","IEEE","IEEE Journals"
"Scalable FPGA Accelerator for Deep Convolutional Neural Networks with Stochastic Streaming","M. Alawad; m. lin","Health Data Sciences Institute, Oak Ridge National Laboratory, Oak Ridge, TN, USA; Department of Electrical and Computer Engineering, University of Central Florida, Orlando, FL, USA","IEEE Transactions on Multi-Scale Computing Systems","","2018","4","4","888","899","FPGA-based heterogeneous computing platform, due to its extreme logic reconfigurability, emerges to be a strong contender as computing fabric in modern AI. As a result, various FPGA-based accelerators for deep CNN—the key driver of modern AI—have been proposed due to their advantages of high performance, reconfigurability, and fast development round, etc. In general, the consensus among researchers is that, although FPGA-based accelerator can achieve much higher energy efficiency, its raw computing performance lags behind when compared with GPUs with similar logic density. In this paper, we develop an alternative methodology to efficiently implement CNNs with FPGAs that outperform GPUs in terms of both power consumption and performance. Our key idea is to design a scalable hardware architecture and circuit design for large-scale CNNs that leverages a stochastic-based computing principle. Specifically, there are three major performance advantages. First, all key components of our deep learning CNN are designed and implemented to compute stochastically, thus achieving excellent computing performance and energy efficiency. Second, because our proposed CNN architecture enables a stream-mode computing, all of its stages can process even the partial results from preceding stages, therefore not incurring unnecessary latency due to data dependency. Finally, our FPGA-based deep CNN also provides a superior hardware scalability when compared with conventional FPGA implementations by reducing the bandwidth requirement between layers. The results show that our proposed CNN architecture significantly outperforms all previous FPGA-based deep CNN implementation approaches. It achieves 1.58x more GOPS, 6.42x more GOPS/Slice, and 10.92x more GOPS/W when compared with state-of-the-art CNN architecture. The top-5 accuracy of stochastic VGG-16 CNN is 86.77 percent with 18.91 fps frame rate.","","","10.1109/TMSCS.2018.2886266","ARO DURIP; NSF BRIGE; NSF CCF; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8573843","Convolutional neural network;FPGA;stochastic computing","Field programmable gate arrays;Computer networks;Convolutional neural networks;Stochastic processes;Memory management","","","","1","39","","","","","IEEE","IEEE Journals"
"Patch strategy for deep face recognition","Y. Zhang; K. Shang; J. Wang; N. Li; M. M. Y. Zhang","Tianjin University, People's Republic of China; Tianjin University, People's Republic of China; School of Mathematics, Tianjin University, People's Republic of China; Tianjin University, People's Republic of China; LPMC Nankai University, People's Republic of China","IET Image Processing","","2018","12","5","819","825","Convolutional neural network (CNN) has proven to be a highly efficient approach to face recognition. In this study, the authors introduce a new layer to embed the patch strategy in convolutional architectures to improve the effectiveness of face representation. Meanwhile, a multi-branch CNN is constructed to learn features of each cropped patch by the patch strategy and then fuses all the patch features together to form the entire face representation. Compared with the traditional patch methods, their approach has the advantage that no extra space is needed to store the facial patches since the images are cropped online. Moreover, due to the end-to-end training, this approach makes a better use of the interactions between global and local features in the model. Two baseline CNNs (i.e. AlexNet and ResNet) are used to analyse the effectiveness of their method. Experiments show that the proposed system achieves comparable performance with other state-of-the-art methods on the labelled faces in the wild and YouTube face verification tasks. To ensure the reproducibility, the publicly available training set CASIA-WebFace is used.","","","10.1049/iet-ipr.2017.1085","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8347038","","","face recognition;feature extraction;feedforward neural nets;image fusion;image representation","CASIA-WebFace publicly available training set;YouTube face verification tasks;ResNet;AlexNet;baseline CNN;local features;global features;end-to-end training;patch feature fusion;multibranch CNN;face representation;convolutional architectures;convolutional neural network;deep face recognition;patch strategy","","1","32","","","","","IET","IET Journals"
"Stable Forecasting of Environmental Time Series via Long Short Term Memory Recurrent Neural Network","K. Kim; D. Kim; J. Noh; M. Kim","Computer Science and Engineering Department, Konkuk University, Seoul, South Korea; Fisheries Science Institute, Chonnam National University, Yeosu, South Korea; Computer Science and Engineering Department, Seoul National University, Seoul, South Korea; Seocho R&D Center, LG Electronics, Seoul, South Korea","IEEE Access","","2018","6","","75216","75228","In a recent decade, deep neural networks have been applied for many research areas after achieving dramatic improvements of accuracy in solving complex problems in vision and computational linguistics area. However, some problems, such as environmental modeling, are still limited to benefit from the deep networks because of its difficulty in collecting sufficient data of learning process. In this paper, aside from the accuracy issue, we raise another property-stability-of the deep networks useful for even such data-limited problems, especially in time-series modeling. Recurrent neural networks with memory cell structures, a deep network, can be deemed as a more robust network structure for long-term forecasting under coarse data observation and associated uncertainties, including missing values and sampling/measurement errors. The stability in forecasting is induced from balancing impact of inputs over all time steps in the networks. To analyze this property in various problem conditions, we adapt the recurrent networks with memory structure to environmental time-series problems, such as forecasting water pollution, air pollution, and ozone alarm. In the results, the recurrent networks with memory showed better performance of forecasting in non-stationary environment and long-term time lags.","","","10.1109/ACCESS.2018.2884827","Konkuk University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8558483","Environmental forecasting;recurrent neural network;long short term memory;stability","Forecasting;Logic gates;Recurrent neural networks;Predictive models;Biological system modeling;Stability analysis","computational linguistics;environmental science computing;learning (artificial intelligence);recurrent neural nets;time series","memory structure;environmental time-series problems;recurrent networks;long-term time;stable forecasting;environmental time series;long short term memory recurrent neural network;deep neural networks;complex problems;computational linguistics area;environmental modeling;time-series modeling;recurrent neural networks;memory cell structures;robust network structure;long-term forecasting;coarse data observation;associated uncertainties;problem conditions;data-limited problems;property stability","","1","44","","","","","IEEE","IEEE Journals"
"Opinion–Aspect Relations in Cognizing Customer Feelings via Reviews","A. Vo; Q. Nguyen; C. Ock","Department of IT Convergence, University of Ulsan, Ulsan, South Korea; Department of IT Convergence, University of Ulsan, Ulsan, South Korea; Department of IT Convergence, University of Ulsan, Ulsan, South Korea","IEEE Access","","2018","6","","5415","5426","Determining a consensus opinion on a product sold online is no longer easy, because assessments have become more and more numerous on the Internet. To address this problem, researchers have used various approaches, such as looking for feelings expressed in the documents and exploring the appearance and syntax of reviews. Aspect-based evaluation is the most important aspect of opinion mining, and researchers are becoming more interested in product aspect extraction; however, more complex algorithms are needed to address this issue precisely with large data sets. This paper introduces a method to extract and summarize product aspects and corresponding opinions from a large number of product reviews in a specific domain. We maximize the accuracy and usefulness of the review summaries by leveraging knowledge about product aspect extraction and providing both an appropriate level of detail and rich representation capabilities. The results show that the proposed system achieves F1-scores of 0.714 for camera reviews and 0.774 for laptop reviews.","","","10.1109/ACCESS.2018.2797224","ICT R&D Program of MSIP/IITP(Development of Core Technology for Context -aware Deep-Symbolic Hybrid Learning and Construction of Language Resources); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8268123","Aspect-based;expert system;knowledge acquisition;sentiment analysis;text mining","Sentiment analysis;Feature extraction;Data mining;Task analysis;Hidden Markov models;Syntactics;Supervised learning","customer satisfaction;data mining;expert systems;Internet;knowledge acquisition;sentiment analysis","consensus opinion;opinion mining;product aspect extraction;product aspects;product reviews;review summaries;camera reviews;laptop reviews;opinion-aspect relations;customer feelings;knowledge acquisition;expert system;sentiment analysis","","3","62","","","","","IEEE","IEEE Journals"
"Indoor Floor Plan Construction Through Sensing Data Collected From Smartphones","Z. Peng; S. Gao; B. Xiao; G. Wei; S. Guo; Y. Yang","Department of Computing, Hong Kong Polytechnic University, Hong Kong; Department of Computing, Hong Kong Polytechnic University, Hong Kong; Department of Computing, Hong Kong Polytechnic University, Hong Kong; School of Computer Science and Information Engineering, Zhejiang Gongshang University, Hangzhou, China; College of Electronic and Information Engineering, Southwest University, Chongqing, China; Department of Electrical and Computer Engineering, Stony Brook University, Stony Brook, NY, USA","IEEE Internet of Things Journal","","2018","5","6","4351","4364","With the development of sensing technology, smartphones can provide various kinds of data, including inertial sensing data, WiFi data, depth data, and images. These data make it possible to construct accurate indoor floor plans that are the critical foundations of flourishing indoor location-based services for smartphone. However, even with the popular crowdsourcing approach, the wide construction of indoor floor plans has not yet to be realized due to the intensive time consumption. In this paper, we utilize deep learning techniques to build PlanSketcher, a system that enables one user to construct fine-grained and facility-labeled indoor floor plans accurately. First, the proposed system extracts novel integrated features to recognize diverse landmarks. Second, traverse-independent hallway topologies are constructed based on the sensing data, depth data, and images through the proposed hallway construction algorithms. Finally, PlanSketcher constructs the room shape and labels recognized facilities in their corresponding positions to generate a complete indoor floor plan. Because PlanSketcher exploits different kinds of data collected from smartphones with new feature extraction method, it can obtain accurate indoor floor plan topology and facility labels. We implement PlanSketcher and conduct extensive experiments in three large indoor settings. The evaluation results show that the 90th percentile accuracy of positions and orientations of facilities are 1 m–2.5 m and 4°–6°, while 85%–95% facilities are recognized and labeled precisely.","","","10.1109/JIOT.2018.2863688","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8428421","Energy consumption;facility label;indoor floor plan construction;sensing data;smartphone","Smart phones;Sensors;Internet of Things;Wireless fidelity;Cameras;Deep learning;Feature extraction","","","","1","28","","","","","IEEE","IEEE Journals"
"Using Unlabeled Data to Discover Bivariate Causality with Deep Restricted Boltzmann Machines","N. Sokolovska; O. Permiakova; K. Forslund; J. Zucker","UPMC, 27068 Paris, Ile de France France 75252 (e-mail: nataliya.sokolovska@upmc.fr); Grenoble, Auvergne-Rhône-Alpes France (e-mail: Olga.Permiakova@cea.fr); European Molecular Biology Laboratory, 9471 Heidelberg, Baden-Wurttemberg Germany 69117 (e-mail: forslund@embl.de); UMI 209 UMMISCO Modèlisation Math et Info des Systémes Complexes, Univ. Paris 6/IRD, Bondy, idf France (e-mail: Jean-Daniel.Zucker@ird.fr)","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2018","PP","99","1","1","An important question in microbiology is whether treatment causes changes in gut flora, and whether it also affects metabolism. The reconstruction of causal relations purely from non-temporal observational data is challenging. We address the problem of causal inference in a bivariate case, where the joint distribution of two variables is observed. In this contribution, we introduce a novel method of causality discovering which is based on the widely used assumption that if X causes Y, then P(X) and P(Y|X) are independent. We propose to explore a semi-supervised approach where P(Y|X) and P(X) are estimated from labeled and unlabeled data respectively, whereas the marginal probability is estimated potentially from much more unlabeled data than the conditional distribution. We illustrate by experiments on several benchmarks of biological network reconstruction that the proposed approach is very competitive in terms of computational time and accuracy compared to the state-of-the-art methods. Finally, we apply the proposed method to an original medical task where we study whether drugs confound human metagenome.","","","10.1109/TCBB.2018.2879504","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8521579","Causal inference;semi-supervised learning;probabilistic models;metagenomic data","Correlation;Drugs;Estimation;Benchmark testing;Biology;Medical diagnostic imaging;Task analysis","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Domain Adversarial for Acoustic Emotion Recognition","M. Abdelwahab; C. Busso","Department of Electrical and Computer Engineering, The University of Texas at Dallas, Richardson, TX, USA; Department of Electrical and Computer Engineering, The University of Texas at Dallas, Richardson, TX, USA","IEEE/ACM Transactions on Audio, Speech, and Language Processing","","2018","26","12","2423","2435","The performance of speech emotion recognition is affected by the differences in data distributions between train (source domain) and test (target domain) sets used to build and evaluate the models. This is a common problem, as multiple studies have shown that the performance of emotional classifiers drops when they are exposed to data that do not match the distribution used to build the emotion classifiers. The difference in data distributions becomes very clear when the training and testing data come from different domains, causing a large performance gap between development and testing performance. Due to the high cost of annotating new data and the abundance of unlabeled data, it is crucial to extract as much useful information as possible from the available unlabeled data. This study looks into the use of adversarial multitask training to extract a common representation between train and test domains. The primary task is to predict emotional-attribute-based descriptors for arousal, valence, or dominance. The secondary task is to learn a common representation, where the train and test domains cannot be distinguished. By using a gradient reversal layer, the gradients coming from the domain classifier are used to bring the source and target domain representations closer. We show that exploiting unlabeled data consistently leads to better emotion recognition performance across all emotional dimensions. We visualize the effect of adversarial training on the feature representation across the proposed deep learning architecture. The analysis shows that the data representations for the train and test domains converge as the data are passed to deeper layers of the network. We also evaluate the difference in performance when we use a shallow neural network versus a deep neural network and the effect of the number of shared layers used by the task and domain classifiers.","","","10.1109/TASLP.2018.2867099","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8445653","Speech emotion recognition;adversarial training;unlabeled adaptation of acoustic emotional models","Emotion recognition;Training;Speech recognition;Data models;Testing;Speech processing","acoustic signal processing;emotion recognition;gradient methods;image classification;image representation;learning (artificial intelligence);neural nets;speech recognition","domain adversarial;acoustic emotion recognition;speech emotion recognition;data distributions;source domain;testing data;performance gap;testing performance;adversarial multitask training;test domains;domain classifier;target domain representations;emotion recognition performance;emotional dimensions;adversarial training;data representations;emotional classifiers;unlabeled data;emotional-attribute-based descriptor prediction;data annotation;gradient reversal layer;shallow neural network;deep neural network","","10","51","","","","","IEEE","IEEE Journals"
"A Novel CNN-based Poisson Solver for Fluid Simulation","X. Xiao; Y. Zhou; H. Wang; X. Yang","School of Software, Shanghai Jiao Tong University, 12474 Shanghai, Shanghai China 200240 (e-mail: xiaoxiangyun@sjtu.edu.cn); School of software, Shanghai Jiao Tong University, 12474 Shanghai, Shanghai China (e-mail: zhouyq@sjtu.edu.cn); School of Software, Shanghai Jiao Tong University, 12474 Shanghai, Shanghai China (e-mail: wanghehv@sjtu.edu.cn); School of Software, Shanghai Jiao Tong University, 12474 Shanghai, Shanghai China (e-mail: yangxubo@sjtu.edu.cn)","IEEE Transactions on Visualization and Computer Graphics","","2018","PP","99","1","1","Solving a large-scale Poisson system is computationally expensive for most of the Eulerian fluid simulation applications. We propose a novel machine learning-based approach to accelerate this process. At the heart of our approach is a deep convolutional neural network (CNN), with the capability of predicting the solution (pressure) of a Poisson system given the discretization structure and the intermediate velocities as input. Our system consists of four main components, namely, a deep neural network to solve the large linear equations, a geometric structure to describe the spatial hierarchies of the input vector, a Principal Component Analysis (PCA) process to reduce the dimension of input in training, and a novel loss function to control the incompressibility constraint. We have demonstrated the efficacy of our approach by simulating a variety of high-resolution smoke and liquid phenomena. In particular, we have shown that our approach accelerates the projection step in a conventional Eulerian fluid simulator by two orders of magnitude. In addition, we have also demonstrated the generality of our approach by producing a diversity of animations deviating from the original datasets.","","","10.1109/TVCG.2018.2873375","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8478400","linear equation;Poisson solver;machine learning;deep convolutional neural network","Mathematical model;Poisson equations;Sparse matrices;Linear systems;Computational modeling;Acceleration;Artificial neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Automatic Segmentation of Acute Ischemic Stroke From DWI Using 3-D Fully Convolutional DenseNets","R. Zhang; L. Zhao; W. Lou; J. M. Abrigo; V. C. T. Mok; W. C. W. Chu; D. Wang; L. Shi","Department of Medicine and Therapeutics, The Chinese University of Hong Kong, Hong Kong; Department of Medicine and Therapeutics, The Chinese University of Hong Kong, Hong Kong; Department of Medicine and Therapeutics, The Chinese University of Hong Kong, Hong Kong; Department of Imaging and Interventional Radiology, The Chinese University of Hong Kong, Hong Kong; Department of Medicine and Therapeutics, The Chinese University of Hong Kong, Hong Kong; Department of Imaging and Interventional Radiology, The Chinese University of Hong Kong, Hong Kong; Department of Imaging and Interventional Radiology, The Chinese University of Hong Kong, Hong Kong; Department of Imaging and Interventional Radiology, The Chinese University of Hong Kong, Hong Kong","IEEE Transactions on Medical Imaging","","2018","37","9","2149","2160","Acute ischemic stroke is recognized as a common cerebral vascular disease in aging people. Accurate diagnosis and timely treatment can effectively improve the blood supply of the ischemic area and reduce the risk of disability or even death. Understanding the location and size of infarcts plays a critical role in the diagnosis decision. However, manual localization and quantification of stroke lesions are laborious and time-consuming. In this paper, we propose a novel automatic method to segment acute ischemic stroke from diffusion weighted images (DWIs) using deep 3-D convolutional neural networks (CNNs). Our method can efficiently utilize 3-D contextual information and automatically learn very discriminative features in an end-to-end and data-driven way. To relieve the difficulty of training very deep 3-D CNN, we equip our network with dense connectivity to enable the unimpeded propagation of information and gradients throughout the network. We train our model with Dice objective function to combat the severe class imbalance problem in data. A DWI data set containing 242 subjects (90 for training, 62 for validation, and 90 for testing) with various types of acute ischemic stroke was constructed to evaluate our method. Our model achieved high performance on various metrics (Dice similarity coefficient: 79.13%, lesionwise precision: 92.67%, and lesionwise F1 score: 89.25%), outperforming the other state-of-the-art CNN methods by a large margin. We also evaluated the model on ISLES2015-SSIS data set and achieved very competitive performance, which further demonstrated its generalization capacity. The proposed method is fast and accurate, demonstrating a good potential in clinical routines.","","","10.1109/TMI.2018.2821244","Research Grants Council, University Grants Committee; Innovation and Technology Commission; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8328863","Acute ischemic stroke segmentation;DWI;3D convolutional neural networks;deep learning","Three-dimensional displays;Lesions;Image segmentation;Biomedical imaging;Two dimensional displays;Solid modeling;Training","brain;convolution;diseases;feedforward neural nets;image segmentation;medical image processing","3-D convolutional neural networks;3-D contextual information;DWI data set;automatic segmentation;3-D fully convolutional DenseNets;common cerebral vascular disease;stroke lesions;acute ischemic stroke;Dice objective function;diffusion weighted images","","5","40","","","","","IEEE","IEEE Journals"
"IORN: An Effective Remote Sensing Image Scene Classification Framework","J. Wang; W. Liu; L. Ma; H. Chen; L. Chen","Beijing Key Laboratory of Embedded Real-time Information Processing Technology, Beijing Institute of Technology, Beijing, China; Beijing Key Laboratory of Embedded Real-time Information Processing Technology, Beijing Institute of Technology, Beijing, China; School of Information Engineering, Zhengzhou University, Zhengzhou, China; Beijing Key Laboratory of Embedded Real-time Information Processing Technology, Beijing Institute of Technology, Beijing, China; Beijing Key Laboratory of Embedded Real-time Information Processing Technology, Beijing Institute of Technology, Beijing, China","IEEE Geoscience and Remote Sensing Letters","","2018","15","11","1695","1699","In recent times, many efforts have been made to improve remote sensing image scene classification, especially using popular deep convolutional neural networks. However, most of these methods do not consider the specific scene orientation of the remote sensing images. In this letter, we propose the improved oriented response network (IORN), which is based on the ORN, to handle the orientation problem in remote sensing image scene classification. We propose average active rotating filters (A-ARFs) in the IORN. While IORNs are being trained, A-ARFs are updated by a method that is different from the ARFs of the ORN, without additional computations. This change helps IORN improve its ability to encode orientation information and speeds up optimization during training. We also propose Squeeze-ORAlign (S-ORAlign) by adding a squeeze layer to ORAlign of ORN. With the squeeze layer, S-ORAlign can address large-scale images, unlike ORAlign. An ablation study and comparison experiments are designed on a public remote sensing image scene classification data set. The experimental results demonstrate the effectiveness and better performance of the proposed model over that of other state-of-the-art models.","","","10.1109/LGRS.2018.2859024","Chang Jiang Scholars Program; Hundred Leading Talent Project of Beijing Science and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8434220","Convolutional neural network;oriented response network (ORN);remote sensing image scene classification","Remote sensing;Training;Convolutional neural networks;Indexes;Convolution;Data models;Encoding","convolution;feature extraction;feedforward neural nets;geophysical image processing;image classification;image representation;learning (artificial intelligence);optimisation;remote sensing","IORN;effective remote sensing image scene classification framework;specific scene orientation;improved oriented response network;ORN;orientation problem;average active rotating filters;orientation information;S-ORAlign;squeeze layer;large-scale images;deep convolutional neural networks;A-ARFs;speeds up optimization;unsupervised learning;squeeze-ORAlign","","3","25","","","","","IEEE","IEEE Journals"
"Machine Learning-Based Prototyping of Graphical User Interfaces for Mobile Apps","K. P. Moran; C. Bernal-Cárdenas; M. Curcio; R. Bonett; D. Poshyvanyk","Computer Science, College of William & Mary, Williamsburg, Virginia United States 23185 (e-mail: kpmoran@cs.wm.edu); Computer Science, College of William and Mary, 8604 Williamsburg, Virginia United States (e-mail: cebernal@cs.wm.edu); Computer Science, College of William & Mary, Williamsburg, Virginia United States (e-mail: mjcurcio@email.wm.edu); Computer Science, College of William & Mary, Williamsburg, Virginia United States (e-mail: rfbonett@email.wm.edu); Computer Science, William and Mary, Williamsburg, Virginia United States 23188 (e-mail: denys@cs.wm.edu)","IEEE Transactions on Software Engineering","","2018","PP","99","1","1","It is common practice for developers of user-facing software to transform a mock-up of a graphical user interface (GUI) into code. This process takes place both at an application's inception and in an evolutionary context as GUI changes keep pace with evolving features. Unfortunately, this practice is challenging and time-consuming. In this paper, we present an approach that automates this process by enabling accurate prototyping of GUIs via three tasks: detection, classification, and assembly. First, logical components of a GUI are detected from a mock-up artifact using either computer vision techniques or mock-up metadata. Then, software repository mining, automated dynamic analysis, and deep convolutional neural networks are utilized to accurately classify GUI-components into domain-specific types (e.g., toggle-button). Finally, a data-driven, K-nearest-neighbors algorithm generates a suitable hierarchical GUI structure from which a prototype application can be automatically assembled. We implemented this approach for Android in a system called ReDraw. Our evaluation illustrates that ReDraw achieves an average GUI-component classification accuracy of 91% and assembles prototype applications that closely mirror target mock-ups in terms of visual affinity while exhibiting reasonable code structure. Interviews with industrial practitioners illustrate ReDraw's potential to improve real development workflows.","","","10.1109/TSE.2018.2844788","Division of Computing and Communication Foundations; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8374985","GUI;CNN;Mobile;Prototyping;Machine-Learning;Mining Software Repositories","Graphical user interfaces;Software;Task analysis;Prototypes;Metadata;Androids;Humanoid robots","","","","5","","","","","","IEEE","IEEE Early Access Articles"
"WaterGAN: Unsupervised Generative Network to Enable Real-Time Color Correction of Monocular Underwater Images","J. Li; K. A. Skinner; R. M. Eustice; M. Johnson-Roberson","Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI, USA; Robotics Program, University of Michigan, Ann Arbor, MI, USA; Department of Naval Architecture and Marine Engineering, University of Michigan, Ann Arbor, MI, USA; Department of Naval Architecture and Marine Engineering, University of Michigan, Ann Arbor, MI, USA","IEEE Robotics and Automation Letters","","2018","3","1","387","394","This letter reports on WaterGAN, a generative adversarial network (GAN) for generating realistic underwater images from in-air image and depth pairings in an unsupervised pipeline used for color correction of monocular underwater images. Cameras onboard autonomous and remotely operated vehicles can capture high-resolution images to map the seafloor; however, underwater image formation is subject to the complex process of light propagation through the water column. The raw images retrieved are characteristically different than images taken in air due to effects, such as absorption and scattering, which cause attenuation of light at different rates for different wavelengths. While this physical process is well described theoretically, the model depends on many parameters intrinsic to the water column as well as the structure of the scene. These factors make recovery of these parameters difficult without simplifying assumptions or field calibration; hence, restoration of underwater images is a nontrivial problem. Deep learning has demonstrated great success in modeling complex nonlinear systems but requires a large amount of training data, which is difficult to compile in deep sea environments. Using WaterGAN, we generate a large training dataset of corresponding depth, in-air color images, and realistic underwater images. These data serve as input to a two-stage network for color correction of monocular underwater images. Our proposed pipeline is validated with testing on real data collected from both a pure water test tank and from underwater surveys collected in the field. Source code, sample datasets, and pretrained models are made publicly available.","","","10.1109/LRA.2017.2730363","National Science Foundation; Office of Naval Research; National Oceanic and Atmospheric Administration; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7995024","Marine robotics;visual learning","Image color analysis;Attenuation;Image restoration;Generators;Gallium nitride;Pipelines;Training","calibration;feature extraction;image colour analysis;image retrieval;image sensors;learning (artificial intelligence)","in-air color images;raw images;underwater image formation;high-resolution images;depth pairings;in-air image;realistic underwater images;generative adversarial network;monocular underwater images;real-time color correction;unsupervised generative network;WaterGAN;underwater surveys","","2","26","Traditional","","","","IEEE","IEEE Journals"
"Anomaly Detection for HTTP Using Convolutional Autoencoders","S. Park; M. Kim; S. Lee","Department of Electrical and Electronics Engineering, Kangwon National University, Chuncheon, South Korea; Penta Security Systems Inc., Seoul, South Korea; Penta Security Systems Inc., Seoul, South Korea","IEEE Access","","2018","6","","70884","70901","Hypertext transfer protocol (HTTP) intrusion has long been a major issue in network security. Anomaly detection methods for detecting such intrusions have been shown to be highly effective, as they learn patterns from the characteristics of normal HTTP messages and search for deviations to detect anomalous messages. Various anomaly detection schemes have been proposed using deep learning algorithms, which require a set of input features to represent an HTTP message. However, heuristically selected input features result in limited performance owing to their lack of understanding of HTTP messages. Recently, it has been shown that documents can be successfully classified by binary images transformed from documents at the character level as the input features for a convolutional neural network (CNN). Thus, document classification is possible without any prior knowledge of words, syntactics, or semantics. This motivates us to mitigate the issue of heuristically selected features in anomaly detection, as HTTP messages also consist of characters. In this paper, we propose an anomaly detection technique for HTTP messages by using a convolutional autoencoder (CAE) with character-level binary image transformation. The CAE consists of an encoder and a decoder with CNN structures that are symmetrical to each other. Furthermore, when an image that has been transformed from a message is submitted to the CAE, it tries to produce a similar image. Toward this end, the CAE is trained to minimize the binary cross entropy (BCE) between the input and output images for normal messages. After adequate training, the proposed scheme can detect an anomalous message if its BCE is larger than a prespecified threshold value. Experimental results show that the proposed scheme outperforms conventional machine learning schemes, such as a one-class support vector machine and an isolation forest, which use heuristically selected input features. In addition, it is shown that improved performance can be achieved by using a deeper CAE structure and a new decision variable, namely binary cross varentropy, instead of BCE. Finally, to investigate the validity of the characterlevel image transformation, we employ a character embedding in the image transformation, which requires additional computational load but achieves negligible performance improvement.","","","10.1109/ACCESS.2018.2881003","Institute for Information and communications Technology Promotion; Korea Government (MSIT), Developing Intelligent Attack Protection Technologies via Network Analysis based on Machine Learning; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8532358","Anomaly detection;HTTP;convolutional autoencoder;CAE;character-level convolutional network;binary cross entropy;binary cross varentropy;entropy;varentropy","Feature extraction;Anomaly detection;Decoding;Support vector machines;Protocols;Entropy","computer network security;convolutional neural nets;entropy;hypermedia;image coding;Internet;learning (artificial intelligence);support vector machines;transport protocols","anomalous message;anomaly detection schemes;HTTP message;heuristically selected input features;convolutional neural network;heuristically selected features;anomaly detection technique;convolutional autoencoder;CAE;character-level binary image transformation;hypertext transfer protocol intrusion;anomaly detection methods;binary cross entropy;BCE;CNN;character embedding;HTTP intrusion","","","48","","","","","IEEE","IEEE Journals"
"Evolution, Current Challenges, and Future Possibilities in ECG Biometrics","J. Ribeiro Pinto; J. S. Cardoso; A. Lourenço","Faculdade de Engenharia da Universidade do Porto, Porto, Portugal; Faculdade de Engenharia da Universidade do Porto, Porto, Portugal; CardioID Technologies LDA, Lisbon, Portugal","IEEE Access","","2018","6","","34746","34776","Face and fingerprint are, currently, the most thoroughly explored biometric traits, promising reliable recognition in diverse applications. Commercial products using these traits for biometric identification or authentication are increasingly widespread, from smartphones to border control. However, increasingly smart techniques to counterfeit such traits raise the need for traits that are less vulnerable to stealthy trait measurement or spoofing attacks. This has sparked interest on the electrocardiogram (ECG), most commonly associated with medical diagnosis, whose hidden nature and inherent liveness information make it highly resistant to attacks. In the last years, the topic of ECG-based biometrics has quickly evolved toward the commercial applications, mainly by addressing the reduced acceptability and comfort by proposing new off-the-person, wearable, and seamless acquisition settings. Furthermore, researchers have recently started to address the issues of spoofing prevention and data security in ECG biometrics, as well as the potential of deep learning methodologies to enhance the recognition accuracy and robustness. In this paper, we conduct a deep review and discussion of 93 state-of-the-art publications on their proposed methods, signal datasets, and publicly available ECG collections. The extracted knowledge is used to present the fundamentals and the evolution of ECG biometrics, describe the current state of the art, and draw conclusions on prior art approaches and current challenges. With this paper, we aim to delve into the current opportunities as well as inspire and guide future research in ECG biometrics.","","","10.1109/ACCESS.2018.2849870","North Portugal Regional Operational Programme through the NanoSTIMA: Macro-to-Nano Human Sensing: Towards Integrated Multimodal Health Monitoring and Analytics/NORTE-01-0145-FEDER-00001 Project; European Regional Development Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8392675","Acquisition;authentication;biometrics;biosensors;classification algorithms;electrocardiography;feature extraction;identification of persons;machine learning;off-the-person;seamless;signal processing","Biometrics (access control);Electrocardiography;Heart rate;Feature extraction;Electrodes;Blood","biometrics (access control);electrocardiography;learning (artificial intelligence);medical signal processing;signal classification","biometric identification;stealthy trait measurement;ECG-based biometrics;publicly available ECG collections;biometric traits;electrocardiogram","","9","161","","","","","IEEE","IEEE Journals"
"Quantized CNN: A Unified Approach to Accelerate and Compress Convolutional Networks","J. Cheng; J. Wu; C. Leng; Y. Wang; Q. Hu","Institute of Automation, Chinese Academy of Sciences, Beijing, China; Institute of Automation, Chinese Academy of Sciences, Beijing, China; Institute of Automation, Chinese Academy of Sciences, Beijing, China; Institute of Automation, Chinese Academy of Sciences, Beijing, China; Institute of Automation, Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","10","4730","4743","We are witnessing an explosive development and widespread application of deep neural networks (DNNs) in various fields. However, DNN models, especially a convolutional neural network (CNN), usually involve massive parameters and are computationally expensive, making them extremely dependent on high-performance hardware. This prohibits their further extensions, e.g., applications on mobile devices. In this paper, we present a quantized CNN, a unified approach to accelerate and compress convolutional networks. Guided by minimizing the approximation error of individual layer's response, both fully connected and convolutional layers are carefully quantized. The inference computation can be effectively carried out on the quantized network, with much lower memory and storage consumption. Quantitative evaluation on two publicly available benchmarks demonstrates the promising performance of our approach: with comparable classification accuracy, it achieves 4 to 6× acceleration and 15 to 20× compression. With our method, accurate image classification can even be directly carried out on mobile devices within 1 s.","","","10.1109/TNNLS.2017.2774288","National Natural Science Foundation of China; Beijing Municipal Commission of Education; Fund of Hubei Key Laboratory of Transportation Internet of Things; Fund of Jiangsu Key Laboratory of Big Data Analysis Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8171208","Acceleration and compression;convolutional neural network (CNN);mobile devices;product quantization","Convolutional codes;Acceleration;Quantization (signal);Computational modeling;Mobile handsets;Training;Tensile stress","convolution;feedforward neural nets;image classification","convolutional layers;fully connected layers;high-performance hardware;convolutional neural network;DNN models;deep neural networks;widespread application;convolutional networks;unified approach;quantized CNN;mobile devices;quantized network;inference computation","","5","59","","","","","IEEE","IEEE Journals"
"Modeling and Analysis of Beta Oscillations in the Basal Ganglia","C. Liu; J. Wang; H. Li; C. Fietkiewicz; K. A. Loparo","School of Electrical and Information Engineering, Tianjin University, Tianjin, China; School of Electrical and Information Engineering, Tianjin University, Tianjin, China; School of Automation and Electrical Engineering, Tianjin University of Technology and Educations, Tianjin, China; Department of Electrical Engineering and Computer Science, Case Western Reserve University, Cleveland, Ohio, USA; Department of Electrical Engineering and Computer Science, Case Western Reserve University, Cleveland, Ohio, USA","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","5","1864","1875","Enhanced beta (12-30 Hz) oscillatory activity in the basal ganglia (BG) is a prominent feature of the Parkinsonian state in animal models and in patients with Parkinson's disease. Increased beta oscillations are associated with severe dopaminergic striatal depletion. However, the mechanisms underlying these pathological beta oscillations remain elusive. Inspired by the experimental observation that only subsets of neurons within each nucleus in the BG exhibit oscillatory activities, a computational model of the BG-thalamus neuronal network is proposed, which is characterized by subdivided nuclei within the BG. Using different currents externally applied to the neurons within a given nucleus, neurons behave according to one of the two subgroups, named “-N” and “-P,” where “-N” and “-P” denote the normal and the Parkinsonian states, respectively. The ratio of “-P” to “-N” neurons indicates the degree of the Parkinsonian state. Simulation results show that if “-P” neurons have a high degree of connectivity in the subthalamic nucleus (STN), they will have a significant downstream effect on the generation of beta oscillations in the globus pallidus. Interestingly, however, the generation of beta oscillations in the STN is independent of the selection of the “-P” neurons in the external segment of the globus pallidus (GPe), despite the reciprocal structure between STN and GPe. This computational model may pave the way to revealing the mechanism of such pathological behaviors in a realistic way that can replicate experimental observations. The simulation results suggest that the STN is more suitable than GPe as a deep brain stimulation target.","","","10.1109/TNNLS.2017.2688426","National Natural Science Foundation of China; Hong Kong Scholars Programs; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7898504","Basal ganglia (BG);beta oscillations;Izhikevich model;parkinsonian state;relay reliability","Neurons;Oscillators;Pathology;Computational modeling;Brain models;Mathematical model","bioelectric potentials;biomedical electrodes;brain;diseases;neurophysiology;patient treatment","basal ganglia;enhanced beta;Parkinsonian state;animal models;increased beta oscillations;severe dopaminergic striatal depletion;pathological beta oscillations;experimental observation;BG exhibit oscillatory activities;computational model;BG-thalamus neuronal network;STN;-P neurons;deep brain stimulation target;reciprocal structure;globus pallidus;pathological behaviors;frequency 12.0 Hz to 30.0 Hz","","","50","","","","","IEEE","IEEE Journals"
"Defense Against Advanced Persistent Threats in Dynamic Cloud Storage: A Colonel Blotto Game Approach","M. Min; L. Xiao; C. Xie; M. Hajimirsadeghi; N. B. Mandayam","Department of Communication Engineering, Xiamen University, Xiamen, China; Department of Communication Engineering, Xiamen University, Xiamen, China; Department of Communication Engineering, Xiamen University, Xiamen, China; Department of Electrical and Computer Engineering, Wireless Information Network Laboratory, Rutgers University, New Brunswick, NJ, USA; Department of Electrical and Computer Engineering, Wireless Information Network Laboratory, Rutgers University, New Brunswick, NJ, USA","IEEE Internet of Things Journal","","2018","5","6","4250","4261","Advanced persistent threat (APT) attackers apply multiple sophisticated methods to continuously and stealthily steal information from the targeted cloud storage systems and can even induce the storage system to apply a specific defense strategy and attack it accordingly. In this paper, the interactions between an APT attacker and a defender allocating their central processing units (CPUs) over multiple storage devices in a cloud storage system are formulated as a Colonel Blotto game. The Nash equilibria of the CPU allocation game are derived for both symmetric and asymmetric CPUs between the APT attacker and the defender to evaluate how the limited CPU resources, the data storage size and the number of storage devices impact the expected data protection level and the utility of the cloud storage system. A CPU allocation scheme based on “hotbooting” policy hill-climbing that exploits the experiences in similar scenarios to initialize the quality values to accelerate the learning speed is proposed for the defender to achieve the optimal APT defense performance in the dynamic game without being aware of the APT attack model and the data storage model. A hotbooting deep  ${Q}$ -network-based CPU allocation scheme further improves the APT detection performance for the case with a large number of CPUs and storage devices. Simulation results show that our proposed reinforcement learning-based CPU allocation can improve both the data protection level and the utility of the cloud storage system compared with the  ${Q}$ -learning-based CPU allocation against APTs.","","","10.1109/JIOT.2018.2844878","National Natural Science Foundation of China; Southeast University; National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8374881","Advanced persistent threats (APTs);central processing unit (CPU) allocation;cloud security;Colonel Blotto game (CBG);data protection level;reinforcement learning (RL)","Computer security;Resource management;Cloud computing;Central Processing Unit;Data protection;Internet of Things;Reinforcement learning","","","","5","39","","","","","IEEE","IEEE Journals"
"S-CNN: Subcategory-Aware Convolutional Networks for Object Detection","T. Chen; S. Lu; J. Fan","Visual Computing Department, Agency for Science Technology and Research, Singapore; Nanyang Technological University, Singapore; Satellite Department, Agency for Science, Technology and Research, Singapore","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","10","2522","2528","The marriage between the deep convolutional neural network (CNN) and region proposals has made breakthroughs for object detection in recent years. While the discriminative object features are learned via a deep CNN for classification, the large intra-class variation and deformation still limit the performance of the CNN based object detection. We propose a subcategory-aware CNN (S-CNN) to solve the object intra-class variation problem. In the proposed technique, the training samples are first grouped into multiple subcategories automatically through a novel instance sharing maximum margin clustering process. A multi-component Aggregated Channel Feature (ACF) detector is then trained to produce more latent training samples, where each ACF component corresponds to one clustered subcategory. The produced latent samples together with their subcategory labels are further fed into a CNN classifier to filter out false proposals for object detection. An iterative learning algorithm is designed for the joint optimization of image subcategorization, multi-component ACF detector, and subcategory-aware CNN classifier. Experiments on INRIA Person dataset, Pascal VOC 2007 dataset and MS COCO dataset show that the proposed technique clearly outperforms the state-of-the-art methods for generic object detection.","","","10.1109/TPAMI.2017.2756936","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8051100","Subcategory;object detection;convolutional neural network;ACF detector;subcategory-aware CNN","Detectors;Training;Object detection;Proposals;Feature extraction;Robustness;Deformable models","convolution;feature extraction;feedforward neural nets;image classification;iterative methods;learning (artificial intelligence);object detection;optimisation;pattern clustering","optimization;iterative learning algorithm;multicomponent aggregated channel feature detector;generic object detection;subcategory-aware CNN classifier;multicomponent ACF detector;clustered subcategory;subcategory-aware convolutional networks;S-CNN","","6","36","","","","","IEEE","IEEE Journals"
"Unsupervised Domain Adaptation for Face Anti-Spoofing","H. Li; W. Li; H. Cao; S. Wang; F. Huang; A. C. Kot","School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; Computer Vision Laboratory, ETH Zürich, Zürich, Switzerland; Ernst & Young Advisory Pte Ltd., Singapore; Department of Computer Science, City University of Hong Kong, Hong Kong; Tencent Youtu Laboratory, Shanghai, China; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore","IEEE Transactions on Information Forensics and Security","","2018","13","7","1794","1809","Face anti-spoofing (a.k.a. presentation attack detection) has recently emerged as an active topic with great significance for both academia and industry due to the rapidly increasing demand in user authentication on mobile phones, PCs, tablets, and so on. Recently, numerous face spoofing detection schemes have been proposed based on the assumption that training and testing samples are in the same domain in terms of the feature space and marginal probability distribution. However, due to unlimited variations of the dominant conditions (illumination, facial appearance, camera quality, and so on) in face acquisition, such single domain methods lack generalization capability, which further prevents them from being applied in practical applications. In light of this, we introduce an unsupervised domain adaptation face anti-spoofing scheme to address the real-world scenario that learns the classifier for the target domain based on training samples in a different source domain. In particular, an embedding function is first imposed based on source and target domain data, which maps the data to a new space where the distribution similarity can be measured. Subsequently, the Maximum Mean Discrepancy between the latent features in source and target domains is minimized such that a more generalized classifier can be learned. State-of-the-art representations including both hand-crafted and deep neural network learned features are further adopted into the framework to quest the capability of them in domain adaptation. Moreover, we introduce a new database for face spoofing detection, which contains more than 4000 face samples with a large variety of spoofing types, capture devices, illuminations, and so on. Extensive experiments on existing benchmark databases and the new database verify that the proposed approach can gain significantly better generalization capability in cross-domain scenarios by providing consistently better anti-spoofing performance.","","","10.1109/TIFS.2018.2801312","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8279564","Face anti-spoofing;domain adaptation;maximum mean discrepancy","Face;Feature extraction;Cameras;Databases;Distortion;Testing;Lighting","face recognition;feature extraction;image representation;learning (artificial intelligence);neural nets","face antispoofing;unsupervised domain adaptation;probability distribution;face spoofing detection;attack detection;deep neural network;single domain methods;face acquisition;anti-spoofing performance;cross-domain scenarios;spoofing types;target domains","","8","75","","","","","IEEE","IEEE Journals"
"Estimation of Perceptual Surface Property Using Deep Networks With Attention Models","H. Cho; Y. S. Baek; Y. Kwak; S. Yang","School of Electrical and Computer Engineering, Ulsan National Institute of Science and Technology, Ulsan, South Korea; School of Design and Human Engineering, Ulsan National Institute of Science and Technology, Ulsan, South Korea; School of Design and Human Engineering, Ulsan National Institute of Science and Technology, Ulsan, South Korea; School of Electrical and Computer Engineering, Ulsan National Institute of Science and Technology, Ulsan, South Korea","IEEE Access","","2018","6","","72173","72178","How we perceive property of surfaces with distinct geometry and reflectance under various illumination conditions is not fully understood. One widely studied approach to understanding perceptual surface property is to derive statistics from images of surfaces with the goal of constructing models that can estimate surface property attributes. This paper presents machine-learning-based methods to estimate the lightness and glossiness of surfaces. Instead of deriving image statistics and building estimation models on top of them, we use deep networks to estimate the perceptual surface property directly from surface images. We adopt the attention models in our networks to allow the networks to estimate the surface property based on features in certain parts of images. This approach can rule out image variations due to geometry, reflectance, and illumination when making the estimations. The networks are trained with perceptual lightness and glossiness data obtained from psychophysical experiments. The trained deep networks provide accurate estimations of the surface property that correlate well with human perception. The network performances are compared with various image statistics derived for the estimation of perceptual surface property.","","","10.1109/ACCESS.2018.2880983","National Research Foundation of Korea; Ulsan National Institute of Science and Technology Outstanding Basic Research Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8532439","Appearance model;neural network;perceptual surface property","Lighting;Geometry;Observers;Three-dimensional displays;Visualization;Image color analysis","","","","","25","","","","","IEEE","IEEE Journals"
"Deep Physiological Affect Network for the Recognition of Human Emotions","B. H. Kim; S. Jo","Computer Science, KAIST, Daejeon, Daejeon Korea (the Republic of) (e-mail: bhyung@cs.kaist.ac.kr); Computer Science, Korea Advanced Institute of Science and Technology, Daejeon, Daejeon Korea (the Republic of) (e-mail: shjo@kaist.ac.kr)","IEEE Transactions on Affective Computing","","2018","PP","99","1","1","Here we present a robust physiological model for the recognition of human emotions, called Deep Physiological Affect Network. This model is based on a convolutional long short-term memory (ConvLSTM) network and a new temporal margin-based loss function. Formulating the emotion recognition problem as a spectral-temporal sequence classification problem of bipolar EEG signals underlying brain lateralization and photoplethysmogram signals, the proposed model improves the performance of emotion recognition. Specifically, the new loss function allows the model to be more confident as it observes more of specific feelings while training ConvLSTM models. The function is designed to result in penalties for the violation of such confidence. Our experiments on a public dataset show that our deep physiological learning technology significantly increases the recognition rate of state-of-the-art techniques by 15.96% increase in accuracy. An extensive analysis of the relationship between participants' emotion ratings and physiological changes in brain lateralization function during the experiment is also presented.","","","10.1109/TAFFC.2018.2790939","Institute for Information communications Technology Promotion IITP grant funded by the Korea government MSIT; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8249871","Emotion Recognition;Affective Computing;Physiological Signals;EEG;PPG;Convolutional;LSTM;Emotional Lateralization;Inter-hemispheric Asymmetry;Valence;Arousal","Emotion recognition;Physiology;Brain modeling;Electroencephalography;Biomedical monitoring;Convolution;Sensors","","","","4","","","","","","IEEE","IEEE Early Access Articles"
"Improving Acoustic Models in TORGO Dysarthric Speech Database","N. M. Joy; S. Umesh","Department of Electrical Engineering, Indian Institute of Technology–Madras, Chennai, India; Department of Electrical Engineering, Indian Institute of Technology–Madras, Chennai, India","IEEE Transactions on Neural Systems and Rehabilitation Engineering","","2018","26","3","637","645","Assistive speech-based technologies can improve the quality of life for people affected with dysarthria, a motor speech disorder. In this paper, we explore multiple ways to improve Gaussian mixture model and deep neural network (DNN) based hidden Markov model (HMM) automatic speech recognition systems for TORGO dysarthric speech database. This work shows significant improvements over the previous attempts in building such systems in TORGO. We trained speaker-specific acoustic models by tuning various acoustic model parameters, using speaker normalized cepstral features and building complex DNN-HMM models with dropout and sequence-discrimination strategies. The DNN-HMM models for severe and severe-moderate dysarthric speakers were further improved by leveraging specific information from dysarthric speech to DNN models trained on audio files from both dysarthric and normal speech, using generalized distillation framework. To the best of our knowledge, this paper presents the best recognition accuracies for TORGO database till date.","","","10.1109/TNSRE.2018.2802914","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8283503","Dysarthria;multitask;distillation;acoustic model;DNN","Speech;Hidden Markov models;Acoustics;Databases;Speech recognition;Data models;Training","acoustic signal processing;audio databases;Gaussian processes;hidden Markov models;mixture models;neural nets;speaker recognition","TORGO dysarthric speech database;assistive speech-based technologies;motor speech disorder;Gaussian mixture model;deep neural network;Markov model automatic speech recognition systems;trained speaker-specific acoustic models;acoustic model parameters;speaker normalized cepstral features;DNN-HMM models;severe-moderate dysarthric speakers;normal speech;sequence-discrimination strategies;generalized distillation;recognition accuracies","Adult;Communication Aids for Disabled;Databases, Factual;Dysarthria;Equipment Design;Female;Humans;Machine Learning;Male;Markov Chains;Models, Statistical;Normal Distribution;Self-Help Devices;Speech Disorders;Speech Production Measurement;Speech Recognition Software","2","55","","","","","IEEE","IEEE Journals"
"Application of Cloud Model in Rock Burst Prediction and Performance Comparison with Three Machine Learning Algorithms","Y. Lin; K. Zhou; J. Li","School of Resources and Safety Engineering, Central South University, Changsha, China; School of Resources and Safety Engineering, Central South University, Changsha, China; School of Resources and Safety Engineering, Central South University, Changsha, China","IEEE Access","","2018","6","","30958","30968","Rock burst is a common disaster in deep underground rock mass engineering excavation. In this paper, a cloud model (CM) is applied to classify and assess rock bursts. Some main factors that influence rock bursts include the uniaxial compressive strength (σc), the tensile strength (σt), the tangential stress (σθ), the rock brittleness coefficient (σc/σt), the stress coefficient (σθ/σc), and the elastic energy index (Wet), which are chosen to establish the evaluation index system. The weights of these indicators are obtained by the rough set method based on 246 sets of domestic and foreign rock burst samples. The 246 samples are classified by normalizing the data and establishing an RS-CM. The 10-fold cross validation was used to obtain higher generalization ability of models. The classification results of the RS-CM are compared with those of the Bayes, KNN, and RF methods. The results show that the RS-CM exhibits higher values of accuracy, Kappa, and three within-class classification metrics (recall, precision, and the F-measure) than the Bayes, KNN, and RF methods. Hence, the RS-CM, which is characterized by high discriminatory ability and simplicity, is a reasonable and appropriate approach to rock burst classification and prediction. Finally, the sensitivity of six indexes was investigated to take scientific and reasonable measures to prevent or reduce the occurrence of rock bursts.","","","10.1109/ACCESS.2018.2839754","National Natural Science Foundation of China; Central South University; Central South University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8370631","Cloud model;rough set;normalization;performance comparison;rock burst","Rocks;Indexes;Stress;Predictive models;Uncertainty;Gaussian distribution;Entropy","brittleness;compressive strength;geotechnical engineering;pattern classification;rocks;rough set theory;structural engineering;tensile strength","cloud model;rock burst prediction;deep underground rock mass engineering excavation;uniaxial compressive strength;rock brittleness coefficient;domestic rock burst samples;foreign rock burst samples;RS-CM;burst classification;within-class classification metrics;recall metric;precision metric;F-measure","","4","43","","","","","IEEE","IEEE Journals"
"CS-CNN: Enabling Robust and Efficient Convolutional Neural Networks Inference for Internet-of-Things Applications","Y. Shen; T. Han; Q. Yang; X. Yang; Y. Wang; F. Li; H. Wen","College of Computer Science and Technology, Harbin Engineering University, Harbin, China; College of Computer Science and Technology, Harbin Engineering University, Harbin, China; College of Computer Science and Technology, Harbin Engineering University, Harbin, China; College of Textile and Light Industry, Inner Mongolia University of Technology, Hohhot, China; College of Computer Science and Technology, Harbin Engineering University, Harbin, China; School of Computer Science and Technology, Shandong University, Qingdao, China; Department of Computer Science, University of Warwick, Coventry, U.K.","IEEE Access","","2018","6","","13439","13448","Recent advances have shown that convolutional neural networks (CNNs) perform excellent in the tasks of image classification and face recognition when the size of data sets is sufficiently large, i.e., over hundreds of thousands training images. Nevertheless, when public data sets are not suitable for training the model for new application scenarios, it is painful to obtain sufficient training examples, especially when the samples have to be labeled manually. Besides, training and inference using CNNs requires significant resources of energy, computation, and memory usage. Therefore, implanting deep CNN models trained and executed on high performance GPU clusters to resource constrained devices, i.e., Internet of Things (IoT) devices, which have permeated into every aspect of modern life, is not appropriate and impractical. Compression technology is an important and popularly used tool to accelerate the training and inference of the CNN models. In this paper, we aim for a step forward in this area: we propose a new compressed CNN model termed CS-CNN for image classification by incorporating the theory of compressive sensing at the input layer of the CNN models to both reduce the resources consumption (evaluated as computation time in this paper) and a required number of training samples. According to our extensive evaluations on the multiple public data sets for deep learning tasks, e.g., MINST and CIFAR-10, using different metrics, we illustrate that the CS-CNN is able to speed up the process of training and inference by a factor of magnitude. Meanwhile, it achieves higher classification accuracy compared with the traditional large CNN models when the size of training database is small.","","","10.1109/ACCESS.2018.2810264","National Natural Science Foundation of China; Natural Science Foundation of Heilongjiang Province; Fundamental Research Funds for the Central Universities; China Postdoctoral Science Foundation; Heilongjiang Postdoctoral Fund; Shandong Provincial Natural Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8304540","Convolutional neural network;compressive sensing;singular value decomposition;IoT;image classification","Training;Compressed sensing;Matrix decomposition;Feature extraction;Convolution;Computational modeling;Computer architecture","face recognition;feedforward neural nets;image classification;Internet of Things;learning (artificial intelligence)","multiple public data sets;compressed CNN model;high performance GPU clusters;deep CNN models;sufficient training examples;image classification;Internet-of-Things applications;efficient convolutional neural networks inference;robust networks inference;CS-CNN","","5","60","","","","","IEEE","IEEE Journals"
"T-CNN: Tubelets With Convolutional Neural Networks for Object Detection From Videos","K. Kang; H. Li; J. Yan; X. Zeng; B. Yang; T. Xiao; C. Zhang; Z. Wang; R. Wang; X. Wang; W. Ouyang","The Chinese University of Hong Kong, Hong Kong; The Chinese University of Hong Kong, Hong Kong; SenseTime Group Ltd., Beijing, China; SenseTime Group Ltd., Beijing, China; Computer Science Department, University of Toronto, Toronto, ON, Canada; The Chinese University of Hong Kong, Hong Kong; Shanghai Jiao Tong University, Shanghai, China; The Chinese University of Hong Kong, Hong Kong; The Chinese University of Hong Kong, Hong Kong; The Chinese University of Hong Kong, Hong Kong; The Chinese University of Hong Kong, Hong Kong","IEEE Transactions on Circuits and Systems for Video Technology","","2018","28","10","2896","2907","The state-of-the-art performance for object detection has been significantly improved over the past two years. Besides the introduction of powerful deep neural networks, such as GoogleNet and VGG, novel object detection frameworks, such as R-CNN and its successors, Fast R-CNN, and Faster R-CNN, play an essential role in improving the state of the art. Despite their effectiveness on still images, those frameworks are not specifically designed for object detection from videos. Temporal and contextual information of videos are not fully investigated and utilized. In this paper, we propose a deep learning framework that incorporates temporal and contextual information from tubelets obtained in videos, which dramatically improves the baseline performance of existing still-image detection frameworks when they are applied to videos. It is called T-CNN, i.e., tubelets with convolutional neural networks. The proposed framework won newly introduced an object-detection-from-video task with provided data in the ImageNet Large-Scale Visual Recognition Challenge 2015. Code is publicly available at https://github.com/myfavouritekk/T-CNN.","","","10.1109/TCSVT.2017.2736553","SenseTime Group Ltd.; General Research Fund through the Research Grants Council of Hong Kong; Hong Kong Innovation and Technology Support Programme; China Postdoctoral Science Foundation; National Natural Science Foundation of China; Office of Naval Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8003302","Object detection;neural networks;computer vision","Videos;Object detection;Proposals;Neural networks;Training;Convolutional codes;Target tracking","convolution;feedforward neural nets;learning (artificial intelligence);object detection;video signal processing","videos;tubelets;still-image detection frameworks;convolutional neural networks;fast R-CNN;deep neural networks;object detection frameworks;T-CNN;GoogleNet;VGG","","18","51","","","","","IEEE","IEEE Journals"
"Realization of a Power-Efficient Transmitter Based on Integrated Artificial Neural Network","D. Kong; S. Hu; Y. Wu; J. Wang; C. Xiong; Q. Yu; Z. Shi; Z. Liu; T. Chen; Y. Yin; S. Hosaka; Y. Liu","State Key Laboratory of Electronic Thin Films and Integrated Devices, University of Electronic Science and Technology of China, Chengdu, China; State Key Laboratory of Electronic Thin Films and Integrated Devices, University of Electronic Science and Technology of China, Chengdu, China; State Key Laboratory of Electronic Thin Films and Integrated Devices, University of Electronic Science and Technology of China, Chengdu, China; State Key Laboratory of Electronic Thin Films and Integrated Devices, University of Electronic Science and Technology of China, Chengdu, China; State Key Laboratory of Electronic Thin Films and Integrated Devices, University of Electronic Science and Technology of China, Chengdu, China; State Key Laboratory of Electronic Thin Films and Integrated Devices, University of Electronic Science and Technology of China, Chengdu, China; Deep Creatic Technologies Ltd., Chengdu, China; School of Materials and Energy, Guangdong University of Technology, Guangzhou, China; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; Graduate School of Engineering, Gunma University, Kiryu, Japan; Graduate School of Engineering, Gunma University, Kiryu, Japan; State Key Laboratory of Electronic Thin Films and Integrated Devices, University of Electronic Science and Technology of China, Chengdu, China","IEEE Access","","2018","6","","68773","68781","In wireless devices, a transmitter normally consumes most of power due to its power amplifier (PA), especially in the applications such as radar, base station, and mobile phone. It is highly desirable to design a transmitter that can emit signals smartly, i.e., the power emission is exactly based on the emitting distance required and the target. Such a design can save huge amount of power as there are almost countless wireless devices in use currently. In this paper, an intelligent radio-frequency transmitter integrated with artificial neural network (ANN) is implemented. The intelligent transmitter consists of an ANN module, a frequency generation module, and a switch-mode PA. The integrated three-layered fully connected ANN can be offline trained to smartly classify input data according to the required power and assign the transmission channel. Furthermore, with the integrated ANN, the average power consumption of the PA is reduced to 34.3 mW, which is 46.5 % lower than PA without the ANN. With the intelligent transmitter, wireless devices can save a large amount of energy in their operations.","","","10.1109/ACCESS.2018.2880033","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8529190","Radio transmitters;radiofrequency amplifiers;energy efficiency;power control;frequency control;classification algorithms;machine learning","Radio transmitters;Receivers;Registers;Radio frequency;Neural networks;Wireless communication","neural nets;power amplifiers;power consumption;radio transmitters","power-efficient transmitter;integrated artificial neural network;power amplifier;base station;mobile phone;power emission;countless wireless devices;intelligent radio-frequency transmitter;ANN module;frequency generation module;switch-mode PA;integrated ANN;power consumption;transmission channel","","1","37","","","","","IEEE","IEEE Journals"
"ERFNet: Efficient Residual Factorized ConvNet for Real-Time Semantic Segmentation","E. Romera; J. M. Álvarez; L. M. Bergasa; R. Arroyo","Department of Electronics, University of Alcalá, Alcalá de Henares, Spain; CSIRO-Data61, Canberra, Australia; Department of Electronics, University of Alcalá, Alcalá de Henares, Spain; Department of Electronics, University of Alcalá, Alcalá de Henares, Spain","IEEE Transactions on Intelligent Transportation Systems","","2018","19","1","263","272","Semantic segmentation is a challenging task that addresses most of the perception needs of intelligent vehicles (IVs) in an unified way. Deep neural networks excel at this task, as they can be trained end-to-end to accurately classify multiple object categories in an image at pixel level. However, a good tradeoff between high quality and computational resources is yet not present in the state-of-the-art semantic segmentation approaches, limiting their application in real vehicles. In this paper, we propose a deep architecture that is able to run in real time while providing accurate semantic segmentation. The core of our architecture is a novel layer that uses residual connections and factorized convolutions in order to remain efficient while retaining remarkable accuracy. Our approach is able to run at over 83 FPS in a single Titan X, and 7 FPS in a Jetson TX1 (embedded device). A comprehensive set of experiments on the publicly available Cityscapes data set demonstrates that our system achieves an accuracy that is similar to the state of the art, while being orders of magnitude faster to compute than other architectures that achieve top precision. The resulting tradeoff makes our model an ideal approach for scene understanding in IV applications. The code is publicly available at: https://github.com/Eromera/erfnet.","","","10.1109/TITS.2017.2750080","Spanish MINECO through the SmartElderlyCar Project; RoboCity2030-III-CM Project (Robótica aplicada a la mejora de la calidad de vida de los ciudadanos. Fase III; S2013/MIT-2748); Programas de actividades I+D (CAM); EU Structural Funds; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8063438","Intelligent vehicles;scene understanding;real-time;semantic segmentation;deep learning;residual layers","Computer architecture;Semantics;Image segmentation;Real-time systems;Kernel;Two dimensional displays","convolution;image classification;image resolution;image segmentation;intelligent transportation systems;neural nets","intelligent vehicles;Jetson TX1;ERFNet;Cityscapes data;neural networks;semantic segmentation;efficient residual factorized ConvNet","","59","38","","","","","IEEE","IEEE Journals"
"Deformable Convolutional Neural Networks for Hyperspectral Image Classification","J. Zhu; L. Fang; P. Ghamisi","College of Electrical and Information Engineering, Hunan University, Changsha, China; College of Electrical and Information Engineering, Hunan University, Changsha, China; German Aerospace Center (DLR), Remote Sensing Technology Institute (IMF), Wessling, Germany","IEEE Geoscience and Remote Sensing Letters","","2018","15","8","1254","1258","Convolutional neural networks (CNNs) have recently been demonstrated to be a powerful tool for hyperspectral image (HSI) classification, since they adopt deep convolutional layers whose kernels can effectively extract high-level spatial-spectral features. However, sampling locations of traditional convolutional kernels are fixed and cannot be changed according to complex spatial structures in HSIs. In addition, the typical pooling layers (e.g., average or maximum operations) in CNNs are also fixed and cannot be learned for feature downsampling in an adaptive manner. In this letter, a novel deformable CNN-based HSI classification method is proposed, which is called deformable HSI classification networks (DHCNet). The proposed network, DHCNet, introduces the deformable convolutional sampling locations, whose size and shape can be adaptively adjusted according to HSIs' complex spatial contexts. Specifically, to create the deformable sampling locations, 2-D offsets are first calculated for each pixel of input images. The sampling locations of each pixel with calculated offsets can cover the locations of other neighboring pixels with similar characteristics. With the deformable sampling locations, deformable feature images are then created by compressing neighboring similar structural information of each pixel into fixed grids. Therefore, applying the regular convolutions on the deformable feature images can reflect complex structures more effectively. Moreover, instead of adopting the pooling layers, the strided convolution is further introduced on the feature images, which can be learned for feature downsampling according to spatial contexts. Experimental results on two real HSI data sets demonstrate that DHCNet can obtain better classification performance than can several well-known classification methods.","","","10.1109/LGRS.2018.2830403","National Natural Science Foundation of China; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8361481","Convolutional neural networks (CNNs);deformable convolution;hyperspectral image (HSI) classification;spatial–spectral feature extraction","Feature extraction;Kernel;Training;Convolutional codes;Convolutional neural networks;Shape;Support vector machines","feature extraction;feedforward neural nets;geophysical image processing;hyperspectral imaging;image classification;image sampling;learning (artificial intelligence);remote sensing","deformable convolutional neural networks;hyperspectral image classification;deep convolutional layers whose kernels;high-level spatial-spectral features;traditional convolutional kernels;complex spatial structures;typical pooling layers;average operations;maximum operations;feature downsampling;novel deformable CNN-based HSI classification method;deformable HSI classification networks;DHCNet;deformable convolutional sampling locations;HSIs' complex spatial contexts;deformable sampling locations;input images;neighboring pixels;deformable feature images;neighboring similar structural information;fixed grids;complex structures;strided convolution;HSI data sets;classification performance;well-known classification methods;CNN","","20","22","","","","","IEEE","IEEE Journals"
"Consecutive Convolutional Activations for Scene Character Recognition","Z. Zhang; H. Wang; S. Liu; B. Xiao","Tianjin Key Laboratory of Wireless Mobile Communications and Power Transmission, Tianjin Normal University, Tianjin, China; Tianjin Key Laboratory of Wireless Mobile Communications and Power Transmission, Tianjin Normal University, Tianjin, China; Tianjin Key Laboratory of Wireless Mobile Communications and Power Transmission, Tianjin Normal University, Tianjin, China; The State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China","IEEE Access","","2018","6","","35734","35742","Driven by the rapid growth of communication technologies and the wide applications of intelligent mobile terminals, the scene character recognition has become a significant yet very challenging task in people's lives. In this paper, we design a novel feature representation scheme termed consecutive convolutional activations (CCA) for character recognition in natural scenes. The proposed CCA could integrate both the low-level and the high-level patterns into the global decision by learning character representations from several successive convolutional layers. Concretely, one shallow convolutional layer is first selected for extracting the convolutional activation features, and then, the next consecutive deep convolutional layers are utilized to learn weight matrices for these convolutional activation features. Finally, the Fisher vectors are employed to encode the CCA features so as to obtain the image-level representations. Extensive experiments are conducted on two English scene character databases (ICDAR2003 and Chars74K) and one Chinese scene character database (“Pan+ChiPhoto”), and the experimental data indicate that the proposed method achieves a superior performance than the previous algorithms.","","","10.1109/ACCESS.2018.2848930","National Natural Science Foundation of China; Natural Science Foundation of Tianjin City; Tianjin Normal University; Open Projects Program of National Laboratory of Pattern Recognition; China Scholarship Council; Tianjin Higher Education Creative Team Funds Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8388201","Consecutive convolutional activations;convolutional neural network;scene character recognition","Character recognition;Feature extraction;Convolutional codes;Databases;Optical character recognition software;Detectors;Training","character recognition;feature extraction;image classification;image representation;learning (artificial intelligence);natural scenes;neural nets","CCA features;image-level representations;English scene character databases;Chinese scene character database;consecutive convolutional activations;scene character recognition;intelligent mobile terminals;novel feature representation scheme;successive convolutional layers;shallow convolutional layer;consecutive deep convolutional layers","","1","48","","","","","IEEE","IEEE Journals"
"Content-Oriented User Modeling for Personalized Response Ranking in Chatbots","B. Liu; Z. Xu; C. Sun; B. Wang; X. Wang; D. F. Wong; M. Zhang","School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; Tricorn (Beijing) Technology Company, Ltd., Beijing, China; Shenzhen Graduate School, Harbin Institute of Technology, Shenzhen, China; Department of Computer and Information Science, University of Macau, Macau, China; Research Center for Human Language Technology, School of Computer Science and Technology, Soochow University, Suzhou, China","IEEE/ACM Transactions on Audio, Speech, and Language Processing","","2018","26","1","122","133","Automatic chatbots (also known as chat-agents) have attracted much attention from both researching and industrial fields. Generally, the semantic relevance between users' queries and the corresponding responses is considered as the essential element for conversation modeling in both generation and ranking based chat systems. By contrast, it is a nontrivial task to adopt the users' information, such as preference, social role, etc., into conversational models reasonably, while users' profiles play a significant role in the procedure of conversations by providing the implicit contexts. This paper aims to address the personalized response ranking task by incorporating user profiles into the conversation model. In our approach, users' personalized representations are latently learned from the contents posted by them via a two-branch neural network. After that, a deep neural network architecture is further presented to learn the fusion representation of posts, responses, and personal information. In this way, the proposed model could understand conversations from the users' perspective; hence, the more appropriate responses are selected for a specified person. The experimental results on two datasets from social network services demonstrate that our approach is hopeful to represent users' personal information implicitly based on user generated contents, and it is promising to perform as an important component in chatbots to select the personalized responses for each user.","","","10.1109/TASLP.2017.2763243","National Natural Science Foundation of China; National High Technology Research and Development Program (863 Program) of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8068225","User modeling;personalization;response ranking;conversational model;personalized chatbot","Semantics;Context modeling;Neural networks;Social network services;Electronic mail;Buildings","Internet;learning (artificial intelligence);neural net architecture;sensor fusion;social networking (online);user modelling","automatic chatbots;chat-agents;industrial fields;semantic relevance;nontrivial task;social role;conversational models;personalized response ranking task;user profiles;conversation model;two-branch neural network;deep neural network architecture;personal information;social network services;user generated contents;personalized responses;content-oriented user modeling","","2","48","Traditional","","","","IEEE","IEEE Journals"
"Service Orchestration of Optimizing Continuous Features in Industrial Surveillance Using Big Data Based Fog-Enabled Internet of Things","S. Din; A. Paul; A. Ahmad; B. B. Gupta; S. Rho","School of Computer Science and Engineering, Kyungpook National University, Daegu, South Korea; School of Computer Science and Engineering, Kyungpook National University, Daegu, South Korea; Department of Computer Science, Bahria University, Islamabad, Pakistan; Department of Computer Engineering, NIT Kurukshetra, Kurukshetra, India; Department of Media Software, Sungkyul University, Anyang, South Korea","IEEE Access","","2018","6","","21582","21591","Video-based surveillance pedestrian detection is playing a key role in emerging technologies, such as Internet of Things and Big Data for use in smart industries and cities. In pedestrian detection, factors, such as lighting, object collisions, backgrounds, clothes, and occlusion cause complications because of inconsistent classification. To address these problems, enhancements in feature extraction are required. These features should arise from multiple variations of pedestrians. Well-known features used for pedestrian detection involve histogram of gradients, scale-invariant feature transform, and Haar built to represent boundary level classifications. Occlusion feature extraction supports identification of regions involving pedestrian detection. Classifiers, such as support vector machine and random forests are also used to classify pedestrians. All these feature extraction and pedestrian detection methods are now being automated using deep learning methods known as convolutional neural networks (CNNs). A model is trained by providing positive and negative image data sets, and larger data sets provide more accurate results when a CNN-based approach is used. Additionally, Extensible Markup Language cascading is used for detecting faces from detected pedestrian.","","","10.1109/ACCESS.2018.2800758","Next Generation Information Computing Development Program through the National Research Foundation of Korea funded by the Korea Government (MSIT); Brain Korea 21 Plus project (SW Human Resource Development Program for Supporting Smart Life) funded by Ministry of Education, School of Computer Science and Engineering, Kyungpook National University, Korea; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8278202","Pedestrian detection;facial detection;convolutional neural network;surveillance model","Data models;XML;Feature extraction;Machine learning;Surveillance;Resource description framework","Big Data;feature extraction;feedforward neural nets;image classification;Internet of Things;learning (artificial intelligence);object detection;pedestrians;support vector machines;video surveillance","service orchestration;industrial surveillance;surveillance pedestrian detection;smart industries;scale-invariant feature;boundary level classifications;occlusion feature extraction;pedestrian detection methods;positive image data sets;negative image data sets;larger data sets;continuous feature optimization;Big Data based fog-enabled Internet of Things","","1","17","","","","","IEEE","IEEE Journals"
"Multisource Remote Sensing Data Classification Based on Convolutional Neural Network","X. Xu; W. Li; Q. Ran; Q. Du; L. Gao; B. Zhang","College of Information Science and Technology, Beijing University of Chemical Technology, Beijing, China; College of Information Science and Technology, Beijing University of Chemical Technology, Beijing, China; College of Information Science and Technology, Beijing University of Chemical Technology, Beijing, China; Department of Electrical and Computer Engineering, Mississippi State University, Starkville, MS, USA; Chinese Academy of Sciences, Institute of Remote Sensing and Digital Earth, Beijing, China; Chinese Academy of Sciences, Institute of Remote Sensing and Digital Earth, Beijing, China","IEEE Transactions on Geoscience and Remote Sensing","","2018","56","2","937","949","As a list of remotely sensed data sources is available, how to efficiently exploit useful information from multisource data for better Earth observation becomes an interesting but challenging problem. In this paper, the classification fusion of hyperspectral imagery (HSI) and data from other multiple sensors, such as light detection and ranging (LiDAR) data, is investigated with the state-of-the-art deep learning, named the two-branch convolution neural network (CNN). More specific, a two-tunnel CNN framework is first developed to extract spectral-spatial features from HSI; besides, the CNN with cascade block is designed for feature extraction from LiDAR or high-resolution visual image. In the feature fusion stage, the spatial and spectral features of HSI are first integrated in a dual-tunnel branch, and then combined with other data features extracted from a cascade network. Experimental results based on several multisource data demonstrate the proposed two-branch CNN that can achieve more excellent classification performance than some existing methods.","","","10.1109/TGRS.2017.2756851","National Natural Science Foundation of China; Higher Education and High-Quality and World-Class Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8068943","Convolutional neural network (CNN);data fusion;deep learning;feature extraction;hyperspectral imagery (HSI)","Feature extraction;Laser radar;Remote sensing;Convolution;Data mining;Support vector machines;Neural networks","convolution;feature extraction;feedforward neural nets;geophysical image processing;hyperspectral imaging;image fusion;image resolution;optical radar;remote sensing","light detection and ranging data;high-resolution visual image;feature extraction;spectral-spatial features;Earth observation;remotely sensed data sources;convolutional neural network;multisource remote sensing data classification","","28","60","","","","","IEEE","IEEE Journals"
"Towards Robust Human-Robot Collaborative Manufacturing: Multimodal Fusion","H. Liu; T. Fang; T. Zhou; L. Wang","Department of Production Engineering, KTH Royal Institute of Technology, Stockholm, Sweden; Department of Software and Computer Systems, KTH Royal Institute of Technology, Stockholm, Sweden; Department of Software and Computer Systems, KTH Royal Institute of Technology, Stockholm, Sweden; Department of Production Engineering, KTH Royal Institute of Technology, Stockholm, Sweden","IEEE Access","","2018","6","","74762","74771","Intuitive and robust multimodal robot control is the key toward human–robot collaboration (HRC) for manufacturing systems. Multimodal robot control methods were introduced in previous studies. The methods allow human operators to control robot intuitively without programming brand-specific code. However, most of the multimodal robot control methods are unreliable because the feature representations are not shared across multiple modalities. To target this problem, a deep learning-based multimodal fusion architecture is proposed in this paper for robust multimodal HRC manufacturing systems. The proposed architecture consists of three modalities: speech command, hand motion, and body motion. Three unimodal models are first trained to extract features, which are further fused for representation sharing. Experiments show that the proposed multimodal fusion model outperforms the three unimodal models. This paper indicates a great potential to apply the proposed multimodal fusion architecture to robust HRC manufacturing systems.","","","10.1109/ACCESS.2018.2884793","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8558584","Deep learning;human-robot collaboration;multimodal fusion;intelligent manufacturing systems","Speech recognition;Hidden Markov models;Service robots;Manufacturing systems;Task analysis","","","","","65","","","","","IEEE","IEEE Journals"
"Digital Signal Modulation Classification With Data Augmentation Using Generative Adversarial Nets in Cognitive Radio Networks","B. Tang; Y. Tu; Z. Zhang; Y. Lin","College of Shipbuilding Engineering, Harbin Engineering University, Harbin, China; College of Information and Communication Engineering, Harbin Engineering University, Harbin, China; College of Air Traffic Management, Civil Aviation University of China, Tianjin, China; College of Information and Communication Engineering, Harbin Engineering University, Harbin, China","IEEE Access","","2018","6","","15713","15722","Automated modulation classification plays a very important part in cognitive radio networks. Deep learning is also a powerful tool that we could not overlook its potential in addressing signal modulation recognition problem. In our last work, we propose a new data conversion algorithm in order to gain a better classification accuracy of communication signal modulation, but we still believe that the convolution neural network (CNN) can work better. However, its application to signal modulation recognition is often hampered by insufficient data and overfitting. Here, we propose a smart approach to programmatic data augmentation method by using the auxiliary classifier generative adversarial networks (ACGANs). The famous CNN model, AlexNet, has been utilized to be the classifier and ACGAN to be the generator, which will enlarge our data set. In order to alleviate the common issues in the traditional generative adversarial nets training, such as discriminator overfitting, generator disconverge, and mode collapse, we apply several training tricks in our training. With the result on original data set as our baseline, we will evaluate our result on enlarged data set to validate the ACGAN’s performance. The result shows that we can gain 0.1~6% increase in the classification accuracy in the ACGAN-based data set.","","","10.1109/ACCESS.2018.2815741","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8319926","Cognitive radio;modulation recognition;pattern recognition;classification algorithms;deep learning;convolutional networks;generative adversarial net","Constellation diagram;Training;Gallium nitride;Phase shift keying;Image color analysis;Signal to noise ratio","","","","22","28","","","","","IEEE","IEEE Journals"
"P2SNet: Can an Image Match a Video for Person Re-Identification in an End-to-End Way?","G. Wang; J. Lai; X. Xie","School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China","IEEE Transactions on Circuits and Systems for Video Technology","","2018","28","10","2777","2787","We address a new person re-identification problem, in which our goal is to directly match image-based scenarios with video-based ones. This differs significantly from the conventional person re-identification problem, which aims to match two image-based scenarios (and it is assumed that the available video frames have been manually selected to form the image-based scenarios). To solve this more challenging and realistic problem without the implicit assumption of manual selection, we propose an end-to-end matching framework called a point-to-set network (P2SNet), which consists of: 1) a k-nearest neighbor triplet module, which functions as a “denoiser” by letting the network sequentially focus on the available frames, while ignoring the other useless frames in a video and 2) a novel deep neural network that uses videos and images as input to jointly learn the feature representations and a point-to-set distance metric in a unified way. Our P2SNet is evaluated on three new image-to-video person re-identification data sets, i-LIDS-VID-P2S, PRID2011-P2S, and MARS-P2S, which are modified from i-LIDS-VID, PRID 2011, and MARS, respectively. The experimental results demonstrate the superior performance of our model over the other state-of-the-art methods.","","","10.1109/TCSVT.2017.2748698","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8025424","Person re-identification;image-to-video matching;kNN-triplet;deep learning","Feature extraction;Measurement;Face recognition;Neural networks;Cameras;Sun;Robustness","feature extraction;image classification;image matching;image representation;neural nets;video signal processing","person re-identification problem;i-LIDS-VID-P2S;end-to-end way;image match;MARS-P2S;PRID2011-P2S;image-to-video person re-identification data sets;P2SNet;point-to-set network;end-to-end matching framework;image-based scenarios;available video frames","","4","33","","","","","IEEE","IEEE Journals"
"Forecasting Solar Power Using Long-Short Term Memory and Convolutional Neural Networks","W. Lee; K. Kim; J. Park; J. Kim; Y. Kim","Department of Computer Science, Hanyang University, Ansan, South Korea; Department of Computer Science, Hanyang University, Ansan, South Korea; Department of Computer Science, Hanyang University, Ansan, South Korea; Department of Computer Science, Hanyang University, Ansan, South Korea; Department of Computer Science, Hanyang University, Ansan, South Korea","IEEE Access","","2018","6","","73068","73080","As solar photovoltaic (PV) generation becomes cost-effective, solar power comes into its own as the alternative energy with the potential to make up a larger share of growing energy needs. Consequently, operations and maintenance cost now have a large impact on the profit of managing power modules, and the energy market participants need to estimate the solar power in short or long terms of future. In this paper, we propose a solar power forecasting technique by utilizing convolutional neural networks and long–short-term memory networks recently developed for analyzing time series data in the deep learning communities. Considering that weather information may not be always available for the location where PV modules are installed and sensors are often damaged, we empirically confirm that the proposed method predicts the solar power well with roughly estimated weather data obtained from national weather centers as well as it works robustly without sophisticatedly preprocessed input to remove outliers.","","","10.1109/ACCESS.2018.2883330","Korea Institute of Energy Technology Evaluation and Planning; National Research Foundation of Korea; National Research Foundation of Korea; Hanyang University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8543793","Solar power forecasting;deep learning;convolutional neural networks;long-short term memory","Forecasting;Predictive models;Autoregressive processes;Power generation;Weather forecasting","","","","","49","","","","","IEEE","IEEE Journals"
"Twitter100k: A Real-World Dataset for Weakly Supervised Cross-Media Retrieval","Y. Hu; L. Zheng; Y. Yang; Y. Huang","Tsinghua National Laboratory for Information Science and Technology, Department of Electronic Engineering, Tsinghua University, Beijing, China; Center of Artificial Intelligence, University of Technology Sydney, Ultimo, Australia; Center of Artificial Intelligence, University of Technology Sydney, Ultimo, Australia; Tsinghua National Laboratory for Information Science and Technology, Department of Electronic Engineering, Tsinghua University, Beijing, China","IEEE Transactions on Multimedia","","2018","20","4","927","938","This paper contributes a new large-scale dataset for weakly supervised cross-media retrieval, named Twitter100k. Current datasets, such as Wikipedia, NUS Wide, and Flickr30k, have two major limitations. First, these datasets are lacking in content diversity, i.e., only some predefined classes are covered. Second, texts in these datasets are written in well-organized language, leading to inconsistency with realistic applications. To overcome these drawbacks, the proposed Twitter100k dataset is characterized by two aspects: it has 100 000 image-text pairs randomly crawled from Twitter, and thus, has no constraint in the image categories; and text in Twitter100k is written in informal language by the users. Since strongly supervised methods leverage the class labels that may be missing in practice, this paper focuses on weakly supervised learning for cross-media retrieval, in which only text-image pairs are exploited during training. We extensively benchmark the performance of four subspace learning methods and three variants of the correspondence AutoEncoder, along with various text features on Wikipedia, Flickr30k, and Twitter100k. As a minor contribution, we also design a deep neural network to learn cross-modal embeddings for Twitter100k. Inspired by the characteristic of Twitter100k, we propose a method to integrate optical character recognition into cross-media retrieval. The experiment results show that the proposed method improves the baseline performance.","","","10.1109/TMM.2017.2760101","Key Program of the National Natural Science Foundation of China; Tsinghua Fudaoyuan Research Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8061031","Cross-media retrieval;Twitter100k dataset;weakly supervised method;text-image embeddings","Internet;Encyclopedias;Electronic publishing;Optical character recognition software;Visualization;Training","image retrieval;learning (artificial intelligence)","real-world dataset;weakly supervised cross-media retrieval;large-scale dataset;Flickr30k;weakly supervised learning;text-image pairs;Twitter100k;image-text pairs","","6","67","","","","","IEEE","IEEE Journals"
"Random Access Memories: A New Paradigm for Target Detection in High Resolution Aerial Remote Sensing Images","Z. Zou; Z. Shi","Image Processing Center, School of Astronautics, Beihang University, Beijing, China; Image Processing Center, School of Astronautics, Beihang University, Beijing, China","IEEE Transactions on Image Processing","","2018","27","3","1100","1111","We propose a new paradigm for target detection in high resolution aerial remote sensing images under small target priors. Previous remote sensing target detection methods frame the detection as learning of detection model + inference of class-label and bounding-box coordinates. Instead, we formulate it from a Bayesian view that at inference stage, the detection model is adaptively updated to maximize its posterior that is determined by both training and observation. We call this paradigm “random access memories (RAM).” In this paradigm, “Memories” can be interpreted as any model distribution learned from training data and “random access” means accessing memories and randomly adjusting the model at detection phase to obtain better adaptivity to any unseen distribution of test data. By leveraging some latest detection techniques e.g., deep Convolutional Neural Networks and multi-scale anchors, experimental results on a public remote sensing target detection data set show our method outperforms several other state of the art methods. We also introduce a new data set “LEarning, VIsion and Remote sensing laboratory (LEVIR)”, which is one order of magnitude larger than other data sets of this field. LEVIR consists of a large set of Google Earth images, with over 22 k images and 10 k independently labeled targets. RAM gives noticeable upgrade of accuracy (an mean average precision improvement of 1% ~ 4%) of our baseline detectors with acceptable computational overhead.","","","10.1109/TIP.2017.2773199","National Natural Science Foundation of China; Beijing Natural Science Foundation; project of State Key Laboratory of Virtual Reality Technology and Systems, Beihang University; Excellence Foundation of BUAA for Ph.D. Students; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8106808","High resolution aerial remote sensing image;target detection;convolutional neural networks;random access memories","Remote sensing;Object detection;Random access memory;Adaptation models;Data models;Training;Detectors","Bayes methods;geophysical image processing;image classification;image resolution;learning (artificial intelligence);object detection;remote sensing","public remote sensing target detection data set;random access memories;high resolution aerial remote sensing images;training data;detection phase;LEVIR data set;learning vision and remote sensing laboratory;Google Earth images","","6","50","","","","","IEEE","IEEE Journals"
"DNN-based approach for fault detection in a direct drive wind turbine","W. Teng; H. Cheng; X. Ding; Y. Liu; Z. Ma; H. Mu","North China Electric Power University, People's Republic of China; North China Electric Power University, People's Republic of China; North China Electric Power University, People's Republic of China; North China Electric Power University, People's Republic of China; North China Electric Power University, People's Republic of China; Tsinghua University, People's Republic of China","IET Renewable Power Generation","","2018","12","10","1164","1171","Incipient fault detection of wind turbines is beneficial for making maintenance strategy and avoiding catastrophic result in a wind farm. A deep neural network (DNN)-based approach is proposed to deal with the challenging task for a direct drive wind turbine, involving four steps: a preprocessing method considering operational mechanism is presented to get rid of the outliers in supervisory control and data acquisition (SCADA); the conventional random forest method is used to evaluate the importance of variables related to the target variable; the historical healthy SCADA data excluding outliers is used to train a deep neural network; and the exponentially weighted moving average control chart is adopted to determine the fault threshold. With the online data being input into the trained deep neural network model of a wind turbine with healthy state, the testing error is regarded as the metric of fault alarm of the wind turbine. The proposed approach is successfully applied to the fault detection of the fall off of permanent magnets in a direct drive wind turbine generator.","","","10.1049/iet-rpg.2017.0867","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8418202","","","electric drives;fault diagnosis;learning (artificial intelligence);maintenance engineering;neural nets;permanent magnets;power generation faults;SCADA systems;wind turbines","permanent magnets;fault alarm;testing error;exponential weighted moving average control chart;historical healthy SCADA data;random forest method;supervisory control-and-data acquisition;operational mechanism;preprocessing method;deep neural network-based approach;maintenance strategy;direct drive wind turbine generator;incipient fault detection;DNN-based approach","","2","30","","","","","IET","IET Journals"
"Training-Free, Single-Image Super-Resolution Using a Dynamic Convolutional Network","A. Bhowmik; S. Shit; C. S. Seelamantula","Department of Electrical Engineering, Indian Institute of Science, Bangalore, India; Department of Electrical Engineering, Indian Institute of Science, Bangalore, India; Department of Electrical Engineering, Indian Institute of Science, Bangalore, India","IEEE Signal Processing Letters","","2018","25","1","85","89","The typical approach for solving the problem of single-image super-resolution (SR) is to learn a nonlinear mapping between the low-resolution (LR) and high-resolution (HR) representations of images in a training set. Training-based approaches can be tuned to give high accuracy on a given class of images, but they call for retraining if the HR → LR generative model deviates or if the test images belong to a different class, which limits their applicability. On the other hand, we propose a solution that does not require a training dataset. Our method relies on constructing a dynamic convolutional network (DCN) to learn the relation between the consecutive scales of Gaussian and Laplacian pyramids. The relation is in turn used to predict the detail at a finer scale, thus leading to SR. Comparisons with state-of-the-art techniques on standard datasets show that the proposed DCN approach results in about 0.8 and 0.3 dB gain in peak signal-to-noise ratio for 2× and 3× SR, respectively. The structural similarity index is on par with the competing techniques.","","","10.1109/LSP.2017.2752806","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8038812","Convolutional neural network (CNN);deep learning;dynamic convolutional network (DCN);Gaussian/Laplacian pyramids;super-resolution (SR)","Laplace equations;Training;Image resolution;Signal resolution;Feature extraction;Convolution;Dictionaries","Gaussian processes;image representation;image resolution;Laplace equations","dynamic convolutional network;single-image super-resolution;HR → LR generative model;low-resolution-high-resolution image representations;Gaussian pyramids;Laplacian pyramids","","2","37","Traditional","","","","IEEE","IEEE Journals"
"Unsupervised Discovery of Character Dictionaries in Animation Movies","K. Somandepalli; N. Kumar; T. Guha; S. S. Narayanan","Department of Electrical Engineering, Signal and Image Processing Institute, University of Southern California, Los Angeles, CA, USA; Sony Computer Entertainment America, San Mateo, CA, USA; Department of Electrical Engineering, Indian Institute of Technology Kanpur, India; Department of Electrical Engineering, Signal and Image Processing Institute, University of Southern California, Los Angeles, CA, USA","IEEE Transactions on Multimedia","","2018","20","3","539","551","Automatic content analysis of animation movies can enable an objective understanding of character (actor) representations and their portrayals. It can also help illuminate potential markers of unconscious biases and their impact. However, multimedia analysis of movie content has predominantly focused on live-action features. A dearth of multimedia research in this field is because of the complexity and heterogeneity in the design of animated characters-an extremely challenging problem to be generalized by a single method or model. In this paper, we address the problem of automatically discovering characters in animation movies as a first step toward automatic character labeling in these media. Movie-specific character dictionaries can act as a powerful first step for subsequent content analysis at scale. We propose an unsupervised approach which requires no prior information about the characters in a movie. We first use a deep neural network-based object detector that is trained on natural images to identify a set of initial character candidates. These candidates are further pruned using saliency constraints and visual object tracking. A character dictionary per movie is then generated from exemplars obtained by clustering these candidates. We are able to identify both anthropomorphic and nonanthropomorphic characters in a dataset of 46 animation movies with varying composition and character design. Our results indicate high precision and recall of the automatically detected characters compared to human-annotated ground truth, demonstrating the generalizability of our approach.","","","10.1109/TMM.2017.2745712","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8017484","Animation movies;deep neural networks;object tracking;saliency;unsupervised clustering;video diarization","Motion pictures;Dictionaries;Media;Facial animation;Labeling;Streaming media","computer animation;feature extraction;neural nets;object detection;object tracking;unsupervised learning","movie-specific character dictionaries;subsequent content analysis;initial character candidates;character dictionary;anthropomorphic characters;nonanthropomorphic characters;automatic content analysis;character representations;multimedia analysis;movie content;animated characters;automatic character labeling","","1","48","","","","","IEEE","IEEE Journals"
"Multilabel Image Classification With Regional Latent Semantic Dependencies","J. Zhang; Q. Wu; C. Shen; J. Zhang; J. Lu","School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; Australia Centre for Robotic Vision, Adelaide SA, Australia; Australia Centre for Robotic Vision, Adelaide SA, Australia; Faculty of Engineering and Information Technology, University of Technology Sydney, Sydney, NSW, Australia; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China","IEEE Transactions on Multimedia","","2018","20","10","2801","2813","Deep convolution neural networks (CNNs) have demonstrated advanced performance on single-label image classification, and various progress also has been made to apply CNN methods on multilabel image classification, which requires annotating objects, attributes, scene categories, etc., in a single shot. Recent state-of-the-art approaches to the multilabel image classification exploit the label dependencies in an image, at the global level, largely improving the labeling capacity. However, predicting small objects and visual concepts is still challenging due to the limited discrimination of the global visual features. In this paper, we propose a regional latent semantic dependencies model (RLSD) to address this problem. The utilized model includes a fully convolutional localization architecture to localize the regions that may contain multiple highly dependent labels. The localized regions are further sent to the recurrent neural networks to characterize the latent semantic dependencies at the regional level. Experimental results on several benchmark datasets show that our proposed model achieves the best performance compared to the state-of-the-art models, especially for predicting small objects occurring in the images. Also, we set up an upper bound model (RLSD+ft-RPN) using bounding-box coordinates during training, and the experimental results also show that our RLSD can approach the upper bound without using the bounding-box annotations, which is more realistic in the real world.","","","10.1109/TMM.2018.2812605","CKCY2016082919273553; National Key Research and Development Plan of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8310600","Multilabel image classification;semantic dependence;deep neural network","Semantics;Visualization;Predictive models;Recurrent neural networks;Proposals;TV","image classification;learning (artificial intelligence);recurrent neural nets","multilabel image classification;convolution neural networks;single-label image classification;recent state-of-the-art approaches;label dependencies;labeling capacity;regional latent semantic dependencies model;fully convolutional localization architecture","","8","57","","","","","IEEE","IEEE Journals"
"Adversarial Examples for Hamming Space Search","E. Yang; T. Liu; C. Deng; D. Tao","School of Electronic Engineering, Xidian University, Xi'an 710071, China.; UBTECH Sydney Artificial Intelligence Centre, Faculty of Engineering and Information Technologies, University of Sydney, Darlington, NSW 2008, Australia, and also with the School of Information Technologies, Faculty of Engineering and Information Technologies, University of Sydney, Darlington, NSW 2008, Australia.; School of Electronic Engineering, Xidian University, Xi'an 710071, China (e-mail: chdeng.xd@gmail.com).; UBTECH Sydney Artificial Intelligence Centre, Faculty of Engineering and Information Technologies, University of Sydney, Darlington, NSW 2008, Australia, and also with the School of Information Technologies, Faculty of Engineering and Information Technologies, University of Sydney, Darlington, NSW 2008, Australia.","IEEE Transactions on Cybernetics","","2018","PP","99","1","12","Due to its strong representation learning ability and its facilitation of joint learning for representation and hash codes, deep learning-to-hash has achieved promising results and is becoming increasingly popular for the large-scale approximate nearest neighbor search. However, recent studies highlight the vulnerability of deep image classifiers to adversarial examples; this also introduces profound security concerns for deep retrieval systems. Accordingly, in order to study the robustness of modern deep hashing models to adversarial perturbations, we propose hash adversary generation (HAG), a novel method of crafting adversarial examples for Hamming space search. The main goal of HAG is to generate imperceptibly perturbed examples as queries, whose nearest neighbors from a targeted hashing model are semantically irrelevant to the original queries. Extensive experiments prove that HAG can successfully craft adversarial examples with small perturbations to mislead targeted hashing models. The transferability of these perturbations under a variety of settings is also verified. Moreover, by combining heterogeneous perturbations, we further provide a simple yet effective method of constructing adversarial examples for black-box attacks.","","","10.1109/TCYB.2018.2882908","National Natural Science Foundation of China; Key Research and Development Program The Key Industry Innovation Chain of Shaanxi; Australian Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8573146","Adversarial examples;deep neural network (DNN);hashing;image search","Binary codes;Perturbation methods;Semantics;Quantization (signal);Neural networks;Optimization","","","","4","","","","","","IEEE","IEEE Early Access Articles"
"Modality-Specific Cross-Modal Similarity Measurement With Recurrent Attention Network","Y. Peng; J. Qi; Y. Yuan","Institute of Computer Science and Technology, Peking University, Beijing, China; Institute of Computer Science and Technology, Peking University, Beijing, China; Institute of Computer Science and Technology, Peking University, Beijing, China","IEEE Transactions on Image Processing","","2018","27","11","5585","5599","Nowadays, cross-modal retrieval plays an important role to flexibly find useful information across different modalities of data. Effectively measuring the similarity between different modalities of data is the key of cross-modal retrieval. Different modalities, such as image and text, have imbalanced and complementary relationship, and they contain unequal amount of information when describing the same semantics. For example, images often contain more details that cannot be demonstrated by textual descriptions and vice versa. Existing works based on deep neural network mostly construct one common space for different modalities, to find the latent alignments between them, which lose their exclusive modality-specific characteristics. Therefore, we propose modality-specific cross-modal similarity measurement approach by constructing the independent semantic space for each modality, which adopts an end-to-end framework to directly generate the modality-specific cross-modal similarity without explicit common representation. For each semantic space, modality-specific characteristics within one modality are fully exploited by recurrent attention network, while the data of another modality is projected into this space with attention based joint embedding, which utilizes the learned attention weights for guiding the fine-grained cross-modal correlation learning, and captures the imbalanced and complementary relationship between different modalities. Finally, the complementarity between the semantic spaces for different modalities is explored by adaptive fusion of the modality-specific cross-modal similarities to perform the cross-modal retrieval. Experiments on the widely used Wikipedia, Pascal Sentence, and MS-COCO data sets as well as our constructed large-scale XMediaNet data set verify the effectiveness of our proposed approach, outperforming nine state-of-the-art methods.","","","10.1109/TIP.2018.2852503","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8401908","Modality-specific cross-modal similarity measurement;recurrent attention network;attention based joint embedding;adaptive fusion","Semantics;Correlation;Extraterrestrial measurements;Visualization;Internet;Neural networks;Encyclopedias","information retrieval;learning (artificial intelligence);natural language processing;recurrent neural nets;text analysis","recurrent attention network;cross-modal retrieval;exclusive modality-specific characteristics;modality-specific cross-modal similarity measurement approach;fine-grained cross-modal correlation learning;textual descriptions;attention based joint embedding;Wikipedia;Pascal Sentence;MS-COCO data sets;large-scale XMediaNet data set","","4","53","","","","","IEEE","IEEE Journals"
"Tradeoffs Between Convergence Speed and Reconstruction Accuracy in Inverse Problems","R. Giryes; Y. C. Eldar; A. M. Bronstein; G. Sapiro","School of Electrical Engineering, Tel Aviv University, Tel Aviv, Israel; Department of Electrical Engineering, Technion—Israel Institute of Technology, Haifa, Israel; Department of Computer Science, Technion—Israel Institute of Technology, Haifa, Israel; Department of Electrical and Computer Engineering, Duke University, Durham, NC, USA","IEEE Transactions on Signal Processing","","2018","66","7","1676","1690","Solving inverse problems with iterative algorithms is popular, especially for large data. Due to time constraints, the number of possible iterations is usually limited, potentially affecting the achievable accuracy. Given an error one is willing to tolerate, an important question is whether it is possible to modify the original iterations to obtain faster convergence to a minimizer achieving the allowed error without increasing the computational cost of each iteration considerably. Relying on recent recovery techniques developed for settings in which the desired signal belongs to some low-dimensional set, we show that using a coarse estimate of this set may lead to faster convergence at the cost of an additional reconstruction error related to the accuracy of the set approximation. Our theory ties to recent advances in sparse recovery, compressed sensing, and deep learning. Particularly, it may provide a possible explanation to the successful approximation of the ℓ1-minimization solution by neural networks with layers representing iterations, as practiced in the learned iterative shrinkage-thresholding algorithm.","","","10.1109/TSP.2018.2791945","GIF; ERC-StG; European Union's Horizon 2020 research and innovation program; ERC StG RAPID; ONR; NSF; NGA; ARO; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8253896","Training;iterative methods;neural networks;compressed sensing;optimization;approximate computing;gradient methods;convergence of numerical methods;approximation methods","Convergence;Acceleration;Signal processing algorithms;Noise measurement;Iterative algorithms;Compressed sensing","image reconstruction;inverse problems;iterative methods;learning (artificial intelligence);minimisation","tradeoffs;convergence speed;reconstruction accuracy;inverse problems;iterative algorithms;time constraints;possible iterations;achievable accuracy;allowed error;computational cost;low-dimensional set;set approximation;sparse recovery;learned iterative shrinkage-thresholding algorithm;convergence;reconstruction error;l2-minimization solution","","5","68","","","","","IEEE","IEEE Journals"
"Embedding Attention and Residual Network for Accurate Salient Object Detection","S. Chen; B. Wang; X. Tan; X. Hu","School of Information Engineering, Yangzhou University, Yangzhou 225127, China (e-mail: c.shuhan@gmail.com).; School of Information Engineering, Yangzhou University, Yangzhou 225127, China.; School of Information Engineering, Yangzhou University, Yangzhou 225127, China.; School of Information Engineering, Yangzhou University, Yangzhou 225127, China.","IEEE Transactions on Cybernetics","","2018","PP","99","1","13","Salient object detection is usually used as a preprocessing step to facilitate a variety of subsequent applications which should take little time cost. With the quick development of deep learning recently, profound progresses have been made to achieve a new state-of-the-art performance. However, the learned features of the existing deep learning-based methods are not accurate enough thus leading to unsatisfactory detection in complex scenes, such as low contrast or very similar between salient object and background region and multiple (small) salient objects with diverse characteristics. In addition, some post-processing techniques are usually needed for refinement, which is time consuming. To address these issues, this paper presents an efficient fully convolutional salient object detection network. Specifically, we first introduce a visual attention mechanism to guide feature learning in side output layers. In detail, attention weight is employed in a top-down manner which can bridge high level semantic information to help shallow layers better locate salient objects and also filter out noisy response in the background region. Second, we propose a residual refinement network to fuse the learned multilevel features gradually. Not to simply add or concatenate them step by step as previous works, we introduce a second-order term into element-wise addition to learn stage-wise residual features for refinement. Such a second-order term not only benefits efficient gradient propagation but also increases network nonlinearity. Extensive experiments on seven standard benchmarks demonstrate that the proposed approach achieves consistently superior performance and performs well on small salient object detection in comparison with the very recent state-of-the-arts, especially in the metric of structure-measure.","","","10.1109/TCYB.2018.2879859","National Natural Science Foundation of China; Jiangsu Province 7th Projects for Summit Talents in Six Main Industries; Electronic Information Industry; Foundation of Yangzhou University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8546752","Deep supervision;residual refinement;salient object detection;top-down residual attention","Object detection;Feature extraction;Visualization;Image color analysis;Semantics;Noise measurement;Task analysis","","","","","","","","","","IEEE","IEEE Early Access Articles"
"J-MOD2: Joint Monocular Obstacle Detection and Depth Estimation","M. Mancini; G. Costante; P. Valigi; T. A. Ciarfuglia","Department of Engineering, University of Perugia, Perugia, Italy; Department of Engineering, University of Perugia, Perugia, Italy; Department of Engineering, University of Perugia, Perugia, Italy; Department of Engineering, University of Perugia, Perugia, Italy","IEEE Robotics and Automation Letters","","2018","3","3","1490","1497","In this letter, we propose an end-to-end deep architecture that jointly learns to detect obstacles and estimate their depth for MAV flight applications. Most of the existing approaches rely either on Visual simultaneous localization and mapping (SLAM) systems or on depth estimation models to build three-dimensional maps and detect obstacles. However, for the task of avoiding obstacles this level of complexity is not required. Recent works have proposed multitask at its first ocurrence in the text.""?> architectures to perform both scene understanding and depth estimation. We follow their path and propose a specific architecture to jointly estimate depth and obstacles, without the need to compute a global map, but maintaining compatibility with a global SLAM system if needed. The network architecture is devised to jointly exploit the information learned from the obstacle detection task, which produces reliable bounding boxes, and the depth estimation one, increasing the robustness of both to scenario changes. We call this architecture J-MOD2. We test the effectiveness of our approach with experiments on sequences with different appearance and focal lengths and compare it to SotA multitask methods that perform both semantic segmentation and depth estimation. In addition, we show the integration in a full system using a set of simulated navigation experiments, where a micro aerial vehicle explores an unknown scenario and plans safe trajectories by using our detection model.","","","10.1109/LRA.2018.2800083","NVIDIA; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8276580","Range sensing;visual learning;visual-based navigation","Estimation;Task analysis;Cameras;Feature extraction;Three-dimensional displays;Robustness;Computer architecture","autonomous aerial vehicles;collision avoidance;mobile robots;navigation;object detection;robot vision;SLAM (robots)","joint monocular obstacle detection and depth estimation;MAV flight applications;J-MOD2 architecture;SotA multitask methods;semantic segmentation;simultaneous localization and mapping;depth estimation models;end-to-end deep architecture;detection model;global SLAM system","","1","35","","","","","IEEE","IEEE Journals"
"Predicting Emotionally Salient Regions using Qualitative Agreement of Deep Neural Network Regressors","S. Parthasarathy; C. Busso","Electrical Engineering, The University of Texas at Dallas, Richardson, Texas United States (e-mail: sxp120931@utdallas.edu); Electrical Engineering, The University of Texas at Dallas, Richardson, Texas United States 75080 (e-mail: busso@utdallas.edu)","IEEE Transactions on Affective Computing","","2018","PP","99","1","1","Automatic emotion recognition plays a crucial role in various fields such as healthcare, human-computer interaction (HCI) and security and defense. While most of previous studies have focused on the recognition of emotion in isolated utterances, a more natural approach is to continuously track emotions during human interaction, identifying regions that are highly emotional. This study proposes a framework to define emotionally salient regions (hotspots), which we then attempt to dynamically detect. Our proposed approach defines hotspots relying on the qualitative agreement (QA) method, which searches for trends across continuous-time evaluations provided by different raters for arousal and valence. We illustrate the benefits of the QA method over averaging absolute values of the traces without considering trends across evaluators. After defining hotspot regions, we propose a deep learning framework to automatically detect these emotional hotspots. The proposed method relies on an ensemble of bidirectional long short term memory (BLSTM) regressors, trained on individual emotional traces provided by the evaluators, which are combined to automatically detect emotional hotspots. An appealing fusion approach to combine these regressors is to rely again on the QA method, which detects emotional salient regions with F1-scores as high as 60.9% for arousal and 50.4% for valence on the RECOLA dataset.","","","10.1109/TAFFC.2018.2878715","Division of Information and Intelligent Systems; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8515042","Emotion recognition;affective computing;emotionally salient regions;regressors of attribute-based descriptors","Emotion recognition;Market research;Databases;Affective computing;Speech recognition;Task analysis","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Automatic feature learning for predicting vulnerable software components","H. K. Dam; T. Tran; T. T. M. Pham; S. W. Ng; J. Grundy; A. Ghose","School of Computing and Information Technology, University of Wollongong, Wollongong, New South Wales Australia (e-mail: hoa@uow.edu.au); Centre for Pattern Recognition and Data Analytics, Deakin University, Waurn Ponds, Victoria Australia 3216 (e-mail: truyen.tran@deakin.edu.au); 434468, Deakin University, Waurn Ponds, Victoria Australia 3216 (e-mail: phtra@deakin.edu.au); School of Computing and Information Technology, University of Wollongong, Wollongong, New South Wales Australia (e-mail: swn881@uowmail.edu.au); Faculty of Information Technology, Monash University, Melbourne, Victoria Australia (e-mail: john.grundy@monash.edu); School of Computing and Information Technology, University of Wollongong, 8691 Wollongong, New South Wales Australia (e-mail: aditya@uow.edu.au)","IEEE Transactions on Software Engineering","","2018","PP","99","1","1","Code flaws or vulnerabilities are prevalent in software systems and can potentially cause a variety of problems including deadlock, hacking, information loss and system failure. A variety of approaches have been developed to try and detect the most likely locations of such code vulnerabilities in large code bases. Most of them rely on manually designing code features (e.g. complexity metrics or frequencies of code tokens) that represent the characteristics of the potentially problematic code to locate. However, all suffer from challenges in sufficiently capturing both semantic and syntactic representation of source code, an important capability for building accurate prediction models. In this paper, we describe a new approach, built upon the powerful deep learning Long Short Term Memory model, to automatically learn both semantic and syntactic features of code. Our evaluation on 18 Android applications and the Firefox application demonstrates that the prediction power obtained from our learned features is better than what is achieved by state of the art vulnerability prediction models, for both within-project prediction and cross-project prediction.","","","10.1109/TSE.2018.2881961","Samsung; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8540022","Software vulnerability prediction;Mining software engineering repositories;Empirical software engineering","Semantics;Software systems;Predictive models;Security;Feature extraction;System recovery","","","","4","","","","","","IEEE","IEEE Early Access Articles"
"Multi-level image representation for large-scale image-based instance retrieval","Q. Deng; S. Wu; J. Wen; Y. Xu",", Shenzhen Graduate School, Harbin Institute of Technology, People's Republic of China; , Shenzhen Graduate School, Harbin Institute of Technology, People's Republic of China; , Shenzhen Graduate School, Harbin Institute of Technology, People's Republic of China; , Shenzhen Graduate School, Harbin Institute of Technology, People's Republic of China","CAAI Transactions on Intelligence Technology","","2018","3","1","33","39","In recent years, instance-level-image retrieval has attracted massive attention. Several researchers proposed that the representations learned by convolutional neural network (CNN) can be used for image retrieval task. In this study, the authors propose an effective feature encoder to extract robust information from CNN. It consists of two main steps: the embedding step and the aggregation step. Moreover, they apply the multi-task loss function to train their model in order to make the training process more effective. Finally, this study proposes a novel representation policy that encodes feature vectors extracted from different layers to capture both local patterns and semantic concepts from deep CNN. They call this ‘multi-level-image representation’, which could further improve the performance. The proposed model is helpful to improve the retrieval performance. For the sake of comprehensively evaluating the performance of their approach, they conducted ablation experiments with various convolutional NN architectures. Furthermore, they apply their approach to a concrete challenge – Alibaba large-scale search challenge. The results show that their model is effective and competitive.","","","10.1049/trit.2018.0003","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8379766","","","image retrieval;learning (artificial intelligence);feature extraction;image representation;feedforward neural nets","multilevel image representation;large-scale image;instance-level-image retrieval;convolutional neural network;image retrieval task;effective feature encoder;embedding step;aggregation step;multitask loss;novel representation policy;deep CNN;multilevel-image representation;retrieval performance;Alibaba large-scale search challenge","","","30","","","","","IET","IET Journals"
"Denoising Sparse Autoencoder-Based Ictal EEG Classification","Y. Qiu; W. Zhou; N. Yu; P. Du","School of Microelectronics, Shandong University, Jinan, China; School of Microelectronics, Shandong University, Jinan, China; School of Microelectronics, Shandong University, Jinan, China; School of Microelectronics, Shandong University, Jinan, China","IEEE Transactions on Neural Systems and Rehabilitation Engineering","","2018","26","9","1717","1726","Automatic seizure detection technology can automatically mark the EEG by using the epileptic detection algorithm, which is helpful to the diagnosis and treatment of epileptic diseases. This paper presents an EEG classification framework based on the denoising sparse autoencoder. The denoising sparse autoencoder (DSAE) is an improved unsupervised deep neural network over sparse autoencoder and denoising autoencoder, which can learn the closest representation of the data. The sparsity constraint applied in the hidden layer of the network makes the expression of data as sparse as possible so as to obtain a more efficient representation of EEG signals. In addition, corrupting operation used in input data help to enhance the robustness of the system and make it suitable for the analysis of non-stationary epileptic EEG signals. In this paper, we first imported the pre-processed training data to the DSAE network and trained the network. A logistic regression classifier was connected to the top of the DSAE. Then, put the test data into the system for classification. Finally, the output results of the overall network were post-processed to obtain the final epilepsy detection results. In the two-class (nonseizure and seizure EEGs) problem, the system has achieved effective results with the average sensitivity of 100%, specificity of 100%, and recognition of 100%, showing that the proposed framework can be efficient for the classification of epileptic EEGs.","","","10.1109/TNSRE.2018.2864306","Natural Science Foundation of Shandong Province; Development Program of Science and Technology of Shandong; Shandong University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8429921","Automatic seizure detection;epileptic EEG;denoising sparse autoencoder;logistic regression classifier","Electroencephalography;Epilepsy;Noise reduction;Neurons;Feature extraction;Databases;Standardization","diseases;electroencephalography;medical signal detection;medical signal processing;neural nets;regression analysis;signal classification;signal denoising;unsupervised learning","epileptic EEGs;automatic seizure detection technology;epileptic detection algorithm;epileptic diseases;denoising sparse autoencoder;nonstationary epileptic EEG signals;pre-processed training data;DSAE network;unsupervised deep neural network;epilepsy detection results;ictal EEG classification;diagnosis;sparsity constraint;hidden layer;logistic regression classifier","","4","64","","","","","IEEE","IEEE Journals"
"Single Image Super-Resolution Based on Wiener Filter in Similarity Domain","C. Cruz; R. Mehta; V. Katkovnik; K. O. Egiazarian","Noiseless Imaging Oy, Tampere, Finland; United Technology Research Centre Ireland, Cork, Ireland; Signal Processing Group, Tampere University of Technology, Tampere, Finland; Signal Processing Group, Tampere University of Technology, Tampere, Finland","IEEE Transactions on Image Processing","","2018","27","3","1376","1389","Single image super-resolution (SISR) is an ill-posed problem aiming at estimating a plausible high-resolution (HR) image from a single low-resolution image. Current state-of-the-art SISR methods are patch-based. They use either external data or internal self-similarity to learn a prior for an HR image. External data-based methods utilize a large number of patches from the training data, while self-similarity-based approaches leverage one or more similar patches from the input image. In this paper, we propose a self-similarity-based approach that is able to use large groups of similar patches extracted from the input image to solve the SISR problem. We introduce a novel prior leading to the collaborative filtering of patch groups in a 1D similarity domain and couple it with an iterative back-projection framework. The performance of the proposed algorithm is evaluated on a number of SISR benchmark data sets. Without using any external data, the proposed approach outperforms the current non-convolutional neural network-based methods on the tested data sets for various scaling factors. On certain data sets, the gain is over 1 dB, when compared with the recent method A+. For high sampling rate (x4), the proposed method performs similarly to very recent state-of-the-art deep convolutional network-based approaches.","","","10.1109/TIP.2017.2779265","Academy of Finland, from 2015 to 2019; European Union’s H2020 Framework Programme; MacSeNet; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8125699","Block matching;sparsity;single image super-resolution","Image resolution;Dictionaries;Training data;Image reconstruction;Training;Image edge detection;Signal resolution","convolution;image resolution;learning (artificial intelligence);neural nets;Wiener filters","single image super-resolution;high-resolution image;single low-resolution image;internal self-similarity;HR image;input image;SISR problem;patch groups;SISR benchmark data sets;Wiener filter;SISR methods;collaborative filtering;deep convolutional network","","14","49","","","","","IEEE","IEEE Journals"
"First-Person Daily Activity Recognition With Manipulated Object Proposals and Non-Linear Feature Fusion","M. Wang; C. Luo; B. Ni; J. Yuan; J. Wang; S. Yan","School of Computer Science and Information Engineering, Hefei University of Technology, Hefei, China; School of Computer Science and Information Engineering, Hefei University of Technology, Hefei, China; Department of Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Electrical and Computer Engineering, National University of Singapore, Singapore; Department of Electronic Engineering and Information Science, University of Science and Technology of China, Hefei, China; Department of Electrical and Computer Engineering, National University of Singapore, Singapore","IEEE Transactions on Circuits and Systems for Video Technology","","2018","28","10","2946","2955","Most previous works on the first-person video recognition focus on measuring the similarity of different actions by using low-level features of objects interacting with humans. However, due to noisy camera motion and frequent changes in viewpoint and scale, they fail to capture and model highly discriminative object features. In this paper, we propose a novel pipeline for the first-person daily activity recognition. Our object feature extraction pipeline is inspired by the recent success of object hypotheses and deep convolutional neural network (CNN)-based detection frameworks. Our key contribution is a simple yet effective manipulated object proposal generation scheme. This scheme leverages motion cues, such as motion boundary and motion magnitude (in contrast, camera motion is usually considered as “noise” for most previous methods), to generate a more compact and discriminative set of object proposals, which are more closely related to the objects, which are being manipulated. Then, we learn more discriminative object detectors from these manipulated object proposals based on region-based CNN. Meanwhile, we develop a non-linear feature fusion scheme, which better combines object and motion features. We show in experiments that the proposed framework significantly outperforms the state-of-the-art recognition performance on a challenging first-person daily activity benchmark.","","","10.1109/TCSVT.2017.2716819","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950969","First-person;activity recognition;manipulated object proposal;feature fusion","Proposals;Activity recognition;Feature extraction;Image motion analysis;Computer vision;Object detection;Cameras","feature extraction;image motion analysis;learning (artificial intelligence);neural nets;object detection;video signal processing","deep convolutional neural network;object proposal generation scheme;CNN-based detection frameworks;object feature extraction pipeline;highly discriminative object features;noisy camera motion;low-level features;first-person video recognition focus;first-person daily activity recognition;first-person daily activity benchmark;state-of-the-art recognition performance;motion features;nonlinear feature fusion scheme;manipulated object proposals;discriminative object detectors;motion magnitude;motion boundary;motion cues;object hypotheses","","3","48","","","","","IEEE","IEEE Journals"
"Dehazing for Multispectral Remote Sensing Images Based on a Convolutional Neural Network With the Residual Architecture","M. Qin; F. Xie; W. Li; Z. Shi; H. Zhang","Image Processing Center, School of Astronautics, Beihang University, Beijing, China; Image Processing Center, School of Astronautics, Beihang University, Beijing, China; Shanghai Institute of Satellite Engineering, Shanghai, China; Image Processing Center, School of Astronautics, Beihang University, Beijing, China; Image Processing Center, School of Astronautics, Beihang University, Beijing, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2018","11","5","1645","1655","Multispectral remote sensing images are often contaminated by haze, which causes low image quality. In this paper, a novel dehazing method based on a deep convolutional neural network (CNN) with the residual structure is proposed for multispectral remote sensing images. First, multiple CNN individuals with the residual structure are connected in parallel and each individual is used to learn a regression from the hazy image to the clear image. Then, the outputs of CNN individuals are fused with weight maps to produce the final dehazing result. In the designed network, the CNN individuals, mining multiscale haze features through multiscale convolutions, are trained using different levels of haze samples to achieve different dehazing abilities. In addition, the weight maps change with the haze distribution, and the fusion of the CNN individuals is adaptive. The designed network is end-to-end, and putting a hazy image into it, the clear scene can be restored. To train the network, a wavelength-dependent haze simulation method is proposed to generate labeled data, which can synthesize hazy multispectral images highly close to real conditions. Experimental results show that the proposed method can accurately remove the haze in each band of multispectral images under different scenes.","","","10.1109/JSTARS.2018.2812726","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8325417","Convolutional neural network (CNN);haze removal;haze simulation;multispectral remote sensing images","Remote sensing;Atmospheric modeling;Earth;Atmospheric waves;Scattering;Cloud computing;Image restoration","feedforward neural nets;geophysical image processing;image colour analysis;image denoising;image enhancement;image filtering;image fusion;image restoration;learning (artificial intelligence);neural net architecture;remote sensing","multispectral remote sensing images;low image quality;deep convolutional neural network;residual structure;multiple CNN individuals;hazy image;clear image;wavelength-dependent haze simulation method;hazy multispectral images;dehazing abilities;weight maps;haze samples;haze distribution","","4","31","","","","","IEEE","IEEE Journals"
"Cascaded Hidden Space Feature Mapping, Fuzzy Clustering, and Nonlinear Switching Regression on Large Datasets","J. Wang; H. Liu; X. Qian; Y. Jiang; Z. Deng; S. Wang","School of Digital Media, Jiangnan University, Wuxi, China; School of Digital Media, Jiangnan University, Wuxi, China; Department of Radiology, Wake Forest School of Medicine, Winston-Salem, NC, USA; School of Digital Media, Jiangnan University, Wuxi, China; School of Digital Media, Jiangnan University, Wuxi, China; School of Digital Media, Jiangnan University, Wuxi, China","IEEE Transactions on Fuzzy Systems","","2018","26","2","640","655","The success of fuzzy clustering heavily relies on the features of the input data. Based on the fact that deep architectures are able to more accurately characterize the data representations in a layer-by-layer manner, this paper proposes a novel feature mapping technique called cascaded hidden-space (CHS) feature mapping and investigates its combination with classical fuzzy c-means (FCM) and fuzzy c-regressions (FCR). Since the parameters between the layers of CHS feature mapping are randomly generated and need not be tuned layer-by-layer, CHS is easily implemented with less training data. By performing classical FCM in CHS, a novel fuzzy clustering framework called CHS-FCM is developed; several of its variants are presented using different dimension-reduction methods in a CHS-FCM clustering framework. The combination of CHS-FCM with nonlinear switch regressions is called CHS-FCR, and it performs FCR in CHS. The proposed CHS-FCR provides better results than FCR for nonlinear process modeling. Both CHS-FCM and CHS-FCR exhibit low memory consumption and require less training data. The experimental results verify the superiority of the proposed methods over classical fuzzy clustering methods.","","","10.1109/TFUZZ.2017.2687407","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; Natural Science Foundation of Jiangsu Province; Outstanding Youth Fund of Jiangsu Province; University Natural Science Research Project in Jiangsu Province; Open Fund Project of Fujian Provincial Key Laboratory of Information Processing and Intelligent Control (Minjiang University); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7886302","Cascaded hidden-space (CHS) feature mapping;fuzzy clustering;nonlinear switching regressions","Kernel;Clustering algorithms;Switches;Machine learning algorithms;Training data;Clustering methods;Prototypes","fuzzy set theory;learning (artificial intelligence);pattern clustering;regression analysis","CHS-FCR exhibit low memory consumption;training data;classical fuzzy clustering methods;hidden space feature mapping;nonlinear switching regression;input data;data representations;layer-by-layer manner;fuzzy c-regressions;CHS feature mapping;classical FCM;CHS-FCM clustering framework","","2","48","","","","","IEEE","IEEE Journals"
"Radio Galaxy Zoo: machine learning for radio source host galaxy cross-identification","M. J. Alger; J. K. Banfield; C. S. Ong; L. Rudnick; O. I. Wong; C. Wolf; H. Andernach; R. P. Norris; S. S. Shabala","Research School of Astronomy and Astrophysics, The Australian National University, Canberra, ACT 2611, Australia, Data61, CSIRO, Canberra, ACT 2601, Australia, matthew.alger@anu.edu.au; Research School of Astronomy and Astrophysics, The Australian National University, Canberra, ACT 2611, Australia, ARC Centre of Excellence for All-Sky Astrophysics (CAASTRO); Data61, CSIRO, Canberra, ACT 2601, Australia; Research School of Computer Science, The Australian National University, Canberra, ACT 2601, Australia; Minnesota Institute for Astrophysics, University of Minnesota, 116 Church St. SE, Minneapolis, MN 55455, USA; ARC Centre of Excellence for All-Sky Astrophysics (CAASTRO); International Centre for Radio Astronomy Research-M468, The University of Western Australia, 35 Stirling Hwy, Crawley, WA 6009, Australia; Research School of Astronomy and Astrophysics, The Australian National University, Canberra, ACT 2611, Australia; ARC Centre of Excellence for All-Sky Astrophysics (CAASTRO); Departamento de Astronomía, DCNE, Universidad de Guanajuato, Apdo. Postal 144, CP 36000, Guanajuato, Gto., Mexico; Western Sydney University, Locked Bag 1797, Penrith South, NSW 1797, Australia, CSIRO Astronomy and Space Science, PO Box 76, Epping, NSW 1710, Australia; School of Natural Sciences, University of Tasmania, Private Bag 37, Hobart, Tasmania 7001, Australia","Monthly Notices of the Royal Astronomical Society","","2018","478","4","5556","5572","We consider the problem of determining the host galaxies of radio sources by cross-identification. This has traditionally been done manually, which will be intractable for wide-area radio surveys like the Evolutionary Map of the Universe. Automated cross-identification will be critical for these future surveys, and machine learning may provide the tools to develop such methods. We apply a standard approach from computer vision to cross-identification, introducing one possible way of automating this problem, and explore the pros and cons of this approach. We apply our method to the 1.4 GHz Australian Telescope Large Area Survey (ATLAS) observations of the Chandra Deep Field South (CDFS) and the ESO Large Area ISO Survey South 1 fields by cross-identifying them with the Spitzer Wide-area Infrared Extragalactic survey. We train our method with two sets of data: expert cross-identifications of CDFS from the initial ATLAS data release and crowdsourced cross-identifications of CDFS from Radio Galaxy Zoo. We found that a simple strategy of cross-identifying a radio component with the nearest galaxy performs comparably to our more complex methods, though our estimated best-case performance is near 100 per cent. ATLAS contains 87 complex radio sources that have been cross-identified by experts, so there are not enough complex examples to learn how to cross-identify them accurately. Much larger data sets are therefore required for training methods like ours. We also show that training our method on Radio Galaxy Zoo cross-identifications gives comparable results to training on expert cross-identifications, demonstrating the value of crowdsourced training data.","","","10.1093/mnras/sty1308","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8434768","methods: statistical;techniques: miscellaneous;galaxies: active;infrared: galaxies;radio continuum: galaxies","","","","","","","","","","","OUP","OUP Journals"
"Unsupervised Generation of Free-Form and Parameterized Avatars","A. Polyak; L. Wolf; Y. Taigman","Computer Science, Tel-Aviv University, Tel Aviv, Tel Aviv Israel (e-mail: adampolyak@gmail.com); Computer Science, Tel-Aviv University, Tel-Aviv, Tel-Aviv Israel (e-mail: liorwolf@gmail.com); Computer Science, Tel-Aviv University, Tel-aviv, OUTSIDE USA Israel 69978 (e-mail: ytaigman@gmail.com)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","PP","99","1","1","We study two problems involving the task of mapping images between different domains. The first problem, transfers an image in one domain to an analog image in another domain. The second problem, extends the previous one by mapping an input image to a tied pair, consisting of a vector of parameters and an image that is created using a graphical engine from this vector of parameters. Similar to the first problem, the mapping's objective is to have the output image as similar as possible to the input image. In both cases, no supervision is given during training in the form of matching inputs and outputs. We compare the two unsupervised learning problems to the problem of unsupervised domain adaptation, define generalization bounds that are based on discrepancy, and employ a GAN to implement network solutions that correspond to these bounds. Experimentally, our methods are shown to solve the problem of automatically creating avatars.","","","10.1109/TPAMI.2018.2863282","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8425579","Deep Learning;Domain Adaptation;Neural Network;Cross-Domain Transfer;Analysis by Synthesis;Domain Transfer Network;Tied Output Synthesis","Training;Gallium nitride;Avatars;Generative adversarial networks;Engines;Face;Three-dimensional displays","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Predicting Human Eye Fixations via an LSTM-Based Saliency Attentive Model","M. Cornia; L. Baraldi; G. Serra; R. Cucchiara","Department of Engineering “Enzo Ferrari,”, University of Modena and Reggio Emilia, Modena, Italy; Department of Engineering “Enzo Ferrari,”, University of Modena and Reggio Emilia, Modena, Italy; Department of Computer Science, Mathematics and Physics, University of Udine, Udine, Italy; Department of Engineering “Enzo Ferrari,”, University of Modena and Reggio Emilia, Modena, Italy","IEEE Transactions on Image Processing","","2018","27","10","5142","5154","Data-driven saliency has recently gained a lot of attention thanks to the use of convolutional neural networks for predicting gaze fixations. In this paper, we go beyond standard approaches to saliency prediction, in which gaze maps are computed with a feed-forward network, and present a novel model which can predict accurate saliency maps by incorporating neural attentive mechanisms. The core of our solution is a convolutional long short-term memory that focuses on the most salient regions of the input image to iteratively refine the predicted saliency map. In addition, to tackle the center bias typical of human eye fixations, our model can learn a set of prior maps generated with Gaussian functions. We show, through an extensive evaluation, that the proposed architecture outperforms the current state-of-the-art on public saliency prediction datasets. We further study the contribution of each key component to demonstrate their robustness on different scenarios.","","","10.1109/TIP.2018.2851672","JUMP Project; Emilia-Romagna Region through the POR-FESR 2014-2020 Program; CultMedia Project; Italian Ministry of Education, Universities and Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8400593","Saliency;human eye fixations;convolutional neural networks;deep learning","","eye;Gaussian processes;neural nets;object detection","Gaussian functions;neural attentive mechanisms;saliency maps;feed-forward network;gaze maps;standard approaches;gaze fixations;convolutional neural networks;data-driven saliency;LSTM-based saliency;public saliency prediction datasets;prior maps;human eye fixations;short-term memory","","17","74","","","","","IEEE","IEEE Journals"
"Monocular Depth Estimation with Augmented Ordinal Depth Relationships","Y. Cao; T. Zhao; K. Xian; C. Shen; Z. Cao; S. Xu","University of Adelaide, SA 5005, Australia.; Tsinghua University, Beijing 100084, China.; Huazhong University of Science and Technology, Wuhan 430074, China and University of Adelaide.; University of Adelaide, SA 5005, Australia.; Huazhong University of Science and Technology, Wuhan 430074, China.; Shanghai Institute for Advanced Communications and Data Science, Shanghai University, Shanghai 200444, China.","IEEE Transactions on Image Processing","","2018","PP","99","1","1","Most existing algorithms for depth estimation from single monocular images need large quantities of metric groundtruth depths for supervised learning. We show that relative depth can be an informative cue for metric depth estimation and can be easily obtained from vast stereo videos. Acquiring metric depths from stereo videos is sometimes impracticable due to the absence of camera parameters. In this paper, we propose to improve the performance of metric depth estimation with relative depths collected from stereo movie videos using existing stereo matching algorithm.We introduce a new “Relative Depth in Stereo” (RDIS) dataset densely labelled with relative depths. We first pretrain a ResNet model on our RDIS dataset. Then we finetune the model on RGB-D datasets with metric ground-truth depths. During our finetuning, we formulate depth estimation as a classification task. This re-formulation scheme enables us to obtain the confidence of a depth prediction in the form of probability distribution. With this confidence, we propose an information gain loss to make use of the predictions that are close to ground-truth. We evaluate our approach on both indoor and outdoor benchmark RGB-D datasets and achieve state-of-the-art performance.","","","10.1109/TIP.2018.2877944","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8506384","Depth estimation;RGB-D;ordinal relationship;deep learning","Estimation;Measurement;Videos;Motion pictures;Training;Task analysis;Cameras","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Listen and Look: Audio–Visual Matching Assisted Speech Source Separation","R. Lu; Z. Duan; C. Zhang","Department of Automation, Tsinghua University, Beijing, China; Department of Electrical and Computer Engineering, University of Rochester, Rochester, NY, USA; Department of Automation, Tsinghua University, Beijing, China","IEEE Signal Processing Letters","","2018","25","9","1315","1319","Source permutation, i.e., assigning separated signal snippets to wrong sources over time, is a major issue in the state-of-the-art speaker-independent speech source separation methods. In addition to auditory cues, humans also leverage visual cues to solve this problem at cocktail parties: matching lip movements with voice fluctuations helps humans to better pay attention to the speaker of interest. In this letter, we propose an audio-visual matching network to learn the correspondence between voice fluctuations and lip movements. We then propose a framework to apply this network to address the source permutation problem and improve over audio-only speech separation methods. The modular design of this framework makes it easy to apply the matching network to any audio-only speech separation method. Experiments on two-talker mixtures show that the proposed approach significantly improves the separation quality over the state-of-the-art audio-only method. This improvement is especially pronounced on mixtures that the audio-only method fails, in which the speakers often have similar voice characteristics.","","","10.1109/LSP.2018.2853566","National Natural Science Foundation of China; Deutsche Forschungsgemeinschaft; National Natural Science Foundation of China; National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8404105","Audio–visual matching;deep learning;speaker-independent speech source separation","Visualization;Predictive models;Lips;Training;Radio frequency;Spectrogram;Source separation","computer vision;image matching;source separation;speech processing","speaker-independent speech source separation methods;visual cues;audio-only speech separation method;source permutation problem;audio-visual matching network;voice fluctuations;lip movements;auditory cues;separated signal snippets;audio-visual matching assisted speech source separation","","2","42","","","","","IEEE","IEEE Journals"
"Short-term Rainfall Forecasting Using Multi-layer Perceptron","P. Zhang; Y. Jia; J. Gao; W. Song; H. K. N. Leung","Hohai University, Nanjing, Jiangsu China (e-mail: pchzhang@hhu.edu.cn); College of Computer and Information, Hohai University, Nanjing, Jiangsu China (e-mail: 1817582819@qq.com); Computer Engineering, San Jose, San Jose, California United States 95192 (e-mail: jerry.gao@sjsu.edu); School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, Jiangsu China 210094 (e-mail: wsong@njust.edu.cn); Department of Computing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong Hong Kong (e-mail: hareton.leung@polyu.edu.hk)","IEEE Transactions on Big Data","","2018","PP","99","1","1","Rainfall forecasting is crucial in the field of meteorology and hydrology. However, existing solutions always achieve low prediction accuracy for short-term rainfall forecasting. Numerical forecasting models perform worse in many conditions. Machine learning approaches neglect the influences of physical factors in upstream or downstream regions, which make forecasting accuracy fluctuate in different areas. To improve the overall forecasting accuracy for short-term rainfall, this paper proposes a novel solution called Dynamic Regional Combined short-term rainfall Forecasting approach (DRCF) using Multi-layer Perceptron (MLP). First, Principal Component Analysis (PCA) is used to reduce the dimension of thirteen physical factors, which serves as the input of MLP. Second, a greedy algorithm is applied to determine the structure of MLP. The surrounding sites are perceived based on the forecasting site. Finally, to solve the clutter interference which is caused by the extension of the perception range, DRCF is enhanced with several dynamic strategies. Experiments are conducted on data from 56 real-world meteorology sites in China, and we compare DRCF with atmospheric models and other machine learning approaches. The experimental results show that DRCF outperforms existing approaches in both threat score (TS) and root mean square error (RMSE).","","","10.1109/TBDATA.2018.2871151","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8468083","Rainfall forecast;deep neural network;multi-layer perceptron;short-term;atmospheric models","Forecasting;Atmospheric modeling;Predictive models;Numerical models;Meteorology;Principal component analysis;Mathematical model","","","","","","","","","","IEEE","IEEE Early Access Articles"
"An Attention-Based Word-Level Interaction Model for Knowledge Base Relation Detection","H. Zhang; G. Xu; X. Liang; G. Xu; F. Li; K. Fu; L. Wang; T. Huang","Key Laboratory of Technology in Geo-spatial Information Processing and Application System, Institute of Electronics, Chinese Academy of Sciences, Beijing, China; Advanced Analytics Institute, University of Technology of Sydney, Sydney, NSW, Australia; School of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences, Beijing, China; Key Laboratory of Technology in Geo-spatial Information Processing and Application System, Institute of Electronics, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Technology in Geo-spatial Information Processing and Application System, Institute of Electronics, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Technology in Geo-spatial Information Processing and Application System, Institute of Electronics, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Technology in Geo-spatial Information Processing and Application System, Institute of Electronics, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Technology in Geo-spatial Information Processing and Application System, Institute of Electronics, Chinese Academy of Sciences, Beijing, China","IEEE Access","","2018","6","","75429","75441","Relation detection plays a crucial role in knowledge base question answering, and it is challenging because of the high variance of relation expression in real-world questions. Traditional relation detection models based on deep learning follow an encoding-comparing paradigm, where the question and the candidate relation are represented as vectors to compare their semantic similarity. Maxor average-pooling operation, which is used to compress the sequence of words into fixed-dimensional vectors, becomes the bottleneck of information flow. In this paper, we propose an attention-based word-level interaction model (ABWIM) to alleviate the information loss issue caused by aggregating the sequence into a fixed-dimensional vector before the comparison. First, attention mechanism is adopted to learn the soft alignments between words from the question and the relation. Then, fine-grained comparisons are performed on the aligned words. Finally, the comparison results are merged with a simple recurrent layer to estimate the semantic similarity. Besides, a dynamic sample selection strategy is proposed to accelerate the training procedure without decreasing the performance. Experimental results of relation detection on both SimpleQuestions and WebQuestions datasets show that ABWIM achieves the state-of-the-art accuracy, demonstrating its effectiveness.","","","10.1109/ACCESS.2018.2883304","Foundation of Precision Poverty Alleviation Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8546730","Relation detection;knowledge base question answering;word-level interaction;attention;dynamic sample selection","Feature extraction;Semantics;Task analysis;Training;Knowledge based systems;Natural languages","knowledge based systems;neural nets;question answering (information retrieval)","fixed-dimensional vector;semantic similarity;attention-based word-level interaction model;knowledge base relation detection;knowledge base question answering;relation expression;relation detection models;ABWIM;deep learning","","","55","","","","","IEEE","IEEE Journals"
"An Improved ResNet Based on the Adjustable Shortcut Connections","B. Li; Y. He","School of Marine Science and Technology, Northwestern Polytechnical University, Xi’an, China; School of Marine Science and Technology, Northwestern Polytechnical University, Xi’an, China","IEEE Access","","2018","6","","18967","18974","ResNet can achieve deeper network and higher performance, but there is no good explanation for how identity shortcut connections solve the gradient fading problems. Moreover, it is not reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified ResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. Second, according to the back propagation of the simplified ResNet, we indirectly explain how the identity shortcut connections solve the problems of gradient fading in convolutional neural networks. Third, we propose an improved ResNet via adjustable shortcut connections, and design a convex k strategy for the improved ResNet according to the different region parameters changing rules. Experimental results on the CIFAR-10 data set show that the test accuracy of the improved ResNet is 78.63%, which is 2.85% higher than that of ResNet. On the CIFAR-100 data set, the test accuracy of the improved ResNet is 42.53%, which is 3.66% higher than that of ResNet. More importantly, the improved ResNet does not increase the amount of computation compared with the classical ResNet.","","","10.1109/ACCESS.2018.2814605","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8315010","Deep convolutional neural networks;gradient fading;ResNet;adjustable shortcut connections;convex k strategy","Fading channels;Training;Convolutional neural networks;Feature extraction;Visualization;Computer vision;Task analysis","convolution;feedforward neural nets;learning (artificial intelligence)","CIFAR-10 data set;convex k strategy;convolutional neural networks;back propagation;identity mapping;gradient fading problems;classical ResNet;identity shortcut connections;simplified ResNet;adjustable shortcut connections;improved ResNet","","4","22","","","","","IEEE","IEEE Journals"
"Iterative Reconstrained Low-Rank Representation via Weighted Nonconvex Regularizer","J. Zheng; C. Lu; H. Yu; W. Wang; S. Chen","School of Computer Science and Engineering, Zhejiang University of Technology, Hangzhou, China; School of Computer Science and Engineering, Zhejiang University of Technology, Hangzhou, China; National Centre for Computer Animation, Bournemouth University, Poole, U.K.; School of Computer Science and Engineering, Zhejiang University of Technology, Hangzhou, China; School of Computer Science and Engineering, Zhejiang University of Technology, Hangzhou, China","IEEE Access","","2018","6","","51693","51707","Benefiting from the joint consideration of geometric structures and low-rank constraint, graph low-rank representation (GLRR) method has led to the state-of-the-art results in many applications. However, it faces the limitations that the structure of errors should be known a prior, the isolated construction of graph Laplacian matrix, and the over shrinkage of the leading rank components. To improve GLRR in these regards, this paper proposes a new LRR model, namely iterative reconstrained LRR via weighted nonconvex regularization, using three distinguished properties on the concerned representation matrix. The first characterizes various distributions of the errors into an adaptively learned weight factor for more flexibility of noise suppression. The second generates an accurate graph matrix from weighted observations for less afflicted by noisy features. The third employs a parameterized rational function to reveal the importance of different rank components for better approximation to the intrinsic subspace structure. Following a deep exploration of automatic thresholding, parallel update, and partial SVD operation, we derive a computationally efficient low-rank representation algorithm using an iterative reconstrained framework and accelerated proximal gradient method. Comprehensive experiments are conducted on synthetic data, image clustering, and background subtraction to achieve several quantitative benchmarks as clustering accuracy, normalized mutual information, and execution time. Results demonstrate the robustness and efficiency of IRWNR compared with other state-of-the-art models.","","","10.1109/ACCESS.2018.2870371","National Natural Science Foundation of China; Natural Science Foundation of Zhejiang Province; Royal Society-Newton Mobility; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8466962","Low-rank representation (LRR);weighted nonconvex constraint;accelerated proximal gradient;singular value thresholding;power method","Laplace equations;Noise measurement;Robustness;Cost function;Adaptation models;Approximation algorithms","gradient methods;graph theory;image classification;image representation;learning (artificial intelligence);matrix decomposition;pattern clustering;regression analysis;singular value decomposition","iterative reconstrained low-rank representation;weighted nonconvex regularizer;joint consideration;geometric structures;low-rank constraint;low-rank representation method;GLRR;isolated construction;graph Laplacian matrix;leading rank components;LRR model;iterative reconstrained LRR;weighted nonconvex regularization;adaptively learned weight factor;accurate graph matrix;weighted observations;intrinsic subspace structure;low-rank representation algorithm;iterative reconstrained framework;proximal gradient method;rank components;representation matrix;IRWNR","","1","52","","","","","IEEE","IEEE Journals"
"Favorite Video Classification Based on Multimodal Bidirectional LSTM","T. Ogawa; Y. Sasaka; K. Maeda; M. Haseyama","Graduate School of Information Science and Technology, Hokkaido University, Sapporo, Japan; Graduate School of Information Science and Technology, Hokkaido University, Sapporo, Japan; Graduate School of Information Science and Technology, Hokkaido University, Sapporo, Japan; Graduate School of Information Science and Technology, Hokkaido University, Sapporo, Japan","IEEE Access","","2018","6","","61401","61409","Video classification based on the user's preference (information of what a user likes: WUL) is important for realizing human-centered video retrieval. A better understanding of the rationale of WUL would greatly contribute to the support for successful video retrieval. However, a few studies have shown the relationship between information of what a user watches and WUL. A new method that classifies videos on the basis of WUL using video features and electroencephalogram (EEG) signals collaboratively with a multimodal bidirectional Long Short-Term Memory (Bi-LSTM) network is presented in this paper. To the best of our knowledge, there has been no study on WUL-based video classification using video features and EEG signals collaboratively with LSTM. First, we newly apply transfer learning to the WUL-based video classification since the number of labels (liked or not liked) attached to videos by users is small, and it is difficult to classify videos based on WUL. Furthermore, we conduct a user study for showing that the representation of psychophysiological signals calculated from Bi-LSTM is effective for the WUL-based video classification. Experimental results showed that our deep neural network feature representations can distinguish WUL for each subject.","","","10.1109/ACCESS.2018.2876710","MIC/SCOPE #181601001 and JSPS KAKENHI; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8496751","Multimodal fusion;video classification;LSTM;EEG","Electroencephalography;Feature extraction;Streaming media;Visualization;Brain modeling;Training data;Sensors","electroencephalography;feature extraction;image classification;learning (artificial intelligence);medical image processing;recurrent neural nets;video retrieval;video signal processing","video features;WUL-based video classification;multimodal bidirectional LSTM;bi-LSTM;video retrieval;multimodal bidirectional long short-term memory network;electroencephalogram signals;EEG signals;transfer learning;psychophysiological signals","","","53","","","","","IEEE","IEEE Journals"
"Reassessing Hierarchical Representation for Action Recognition in Still Images","R. Li; Z. Liu; J. Tan","State Key Laboratory of CAD&CG, Zhejiang University, Hangzhou, China; State Key Laboratory of CAD&CG, Zhejiang University, Hangzhou, China; State Key Laboratory of CAD&CG, Zhejiang University, Hangzhou, China","IEEE Access","","2018","6","","61386","61400","Typical still action recognition methods rely on human body part detection and object detection. However, current human body part detectors and object detectors are far from perfect, leading to a negative impact on subsequent spatial relation learning of human-object interactions (HOIs). Bag-of-features (BoF)based methods go beyond such modeling paradigms, but they do not achieve the state-of-the-art accuracies. In this paper, we propose two still action recognition methods that model HOI layouts by image hierarchical representation, rather than explicitly constructing HOI relations. The first method encodes a dense set of SIFT features using Fisher vectors, where an image is divided into increasingly fine regions with the spatial pyramid. The second method takes recent pretrained deep networks as feature execrators, where an image is divided into overlapped regions. The improvement effect of the hierarchical representation is proven by extensive comparison experiments. Our methods are very simple and easy-to-use, which remarkably outperform those BoF-based methods and complicated human-centric methods. To the best of our knowledge, our methods achieve the highest accuracies to date on the Sports, PPMI, and extended PPMI data sets.","","","10.1109/ACCESS.2018.2872798","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8478261","Action recognition;hierarchical representation;Fisher vector;spatial pyramid","Detectors;Feature extraction;Training;Object detection;Pose estimation;Face;Object recognition","feature extraction;image recognition;image representation;learning (artificial intelligence);object detection;transforms;vectors","action recognition methods;model HOI layouts;image hierarchical representation;HOI relations;SIFT features;feature execrators;BoF-based methods;human-centric methods;human body part detection;object detection;current human body part detectors;subsequent spatial relation learning;human-object interactions;modeling paradigms;bag-of-features based methods;still images;Fisher vectors;spatial pyramid","","","61","","","","","IEEE","IEEE Journals"
"Person Re-Identification by Multi-Camera Networks for Internet of Things in Smart Cities","S. Zhang; H. Yu","Beijing Key Laboratory of Urban Road Intelligent Traffic Control, North China University of Technology, Beijing, China; College of Electrical and Control Engineering, North China University of Technology, Beijing, China","IEEE Access","","2018","6","","76111","76117","As one of the most important areas of public safety and security, intelligent video surveillance is an indispensable part of the urban Internet of Things infrastructure. Person re-identification (person re-ID), which aims to track and recognize a person in a multi-camera scene, is mostly viewed as an image retrieval problem, and this task has been greatly boosted by deep convolutional neural networks (CNNs) in recent years. In practice, person re-ID usually adopts automatic detectors to obtain cropped pedestrian images, and CNNs are inherently limited to model geometric transformations due to the fixed geometric structures in their building modules. We incorporate the deformable convolution module to the traditional baseline to enhance the transformation modeling capability without additional supervision. The new module can readily replace their plain counterparts in the existing CNNs and can be easily trained end-to-end by standard backpropagation. Experiments on two large-scale re-ID datasets confirm the performance of our approach. The experiments also show that learning dense spatial transformation in deep CNNs is effective for person re-ID task and has a bright future in the intelligent video surveillance area.","","","10.1109/ACCESS.2018.2883560","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8548589","Neural networks;video surveillance;Internet of Thing;identification of persons","Convolution;Feature extraction;Task analysis;Two dimensional displays;Training;Internet of Things","backpropagation;cameras;convolutional neural nets;image retrieval;Internet of Things;object detection;pedestrians;transforms;video surveillance","multicamera networks;multicamera scene;image retrieval problem;deep convolutional neural networks;CNNs;deformable convolution module;intelligent video surveillance area;dense spatial transformation learning;cropped pedestrian images;standard backpropagation;urban Internet of Things infrastructure;person re-identification;person re-ID","","3","48","","","","","IEEE","IEEE Journals"
"Towards Clinical Diagnosis: Automated Stroke Lesion Segmentation on Multi-Spectral MR Image Using Convolutional Neural Network","Z. Liu; C. Cao; S. Ding; Z. Liu; T. Han; S. Liu","Tianjin Key Laboratory of Optoelectronic Sensor and Sensing Network Technology, College of Electronic Information and Optical Engineering, Nankai University, Tianjin, China; Department of Medical Imaging, Key Laboratory for Cerebral Artery and Neural Degeneration of Tianjin, Tianjin Huanhu Hospital, Tianjin, China; Tianjin Key Laboratory of Optoelectronic Sensor and Sensing Network Technology, College of Electronic Information and Optical Engineering, Nankai University, Tianjin, China; School of Electrical Engineering and Automation, Harbin Institute of Technology, Harbin, China; Department of Medical Imaging, Key Laboratory for Cerebral Artery and Neural Degeneration of Tianjin, Tianjin Huanhu Hospital, Tianjin, China; School of Basic Medical Sciences, Tianjin Medical University, Tianjin, China","IEEE Access","","2018","6","","57006","57016","The patient with ischemic stroke can benefit most from the earliest possible definitive diagnosis. While a quantitative evaluation of the stroke lesions on the magnetic resonance images (MRIs) is effective in clinical diagnosis, manually segmenting the stroke lesions is commonly used, which is, however, a tedious and time-consuming task. Therefore, how to segment the stroke lesions in a fully automated manner has recently extracted extensive attentions. Considering that the clinically acquired MRIs usually have thick slices, we propose a 2D-slice-based segmentation method. In particular, we use multi-spectral MRIs, i.e., diffusion weighted image, apparent diffusion coefficient, and T2-weighted image, as input, and propose a residual-structured fully convolutional network (Res-FCN). The proposed Res-FCN is trained and evaluated on a large data set with 212 clinically acquired MRIs, which achieves a mean dice coefficient of 0.645 with a mean number of false negative lesions of 1.515 per subject. The proposed Res-FCN is further evaluated on a public data set, i.e., ISLES2015-SISS, which presents a very competitive result among all 2D-slice-based segmentation methods.","","","10.1109/ACCESS.2018.2872939","National Natural Science Foundation of China; Ministry of Education, Culture, Sports, Science and Technology; Natural Science Foundation of Tianjin City; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8478270","Deep learning;stroke lesion segmentation;residual network (ResNet);convolutional neural network (CNN);fully convolutional network (FCN)","Lesions;Image segmentation;Magnetic resonance imaging;Task analysis;Training;Testing;Biomedical imaging","biomedical MRI;image segmentation;medical disorders;medical image processing;neural nets","Res-FCN;2D-slice-based segmentation method;automated stroke lesion segmentation;convolutional neural network;ischemic stroke;magnetic resonance images;diffusion weighted image;T2-weighted image;residual-structured fully convolutional network;clinical diagnosis;multispectral MRI image;apparent diffusion coefficient","","7","40","","","","","IEEE","IEEE Journals"
"Interaction Force Estimation Using Camera and Electrical Current Without Force/Torque Sensor","D. Lee; W. Hwang; S. Lim","Department of Mechanical, Robotics and Energy Engineering, Dongguk University, Seoul, South Korea; Department of Software and Computer Engineering, Ajou University, Suwon, South Korea; Department of Mechanical, Robotics and Energy Engineering, Dongguk University, Seoul, South Korea","IEEE Sensors Journal","","2018","18","21","8863","8872","In this paper, we propose a method for the estimation of the interaction forces between the motorized system and object through the visual and electric information. In particular, we propose a new interaction force sensing method based on sequential images and the electrical current from the motor during the interaction between the system and environment to estimate the interaction force using deep learning. In the previous method, to measure the interaction force using only visual information, the prediction is inaccurate when the system interacts with an undeformable target, even though the aspect of the change appears small in the image. We use a neural network structure for estimating the interaction force from the time-series data of visual and electric information using deep learning, which combines the convolution neural network and long short-term memory models. From the evaluation to show the feasibility of the interaction force estimation, the proposed learning models successfully estimate the forces for four targets (rigid box, rigid box on sponge, sponge, and stapler), which are both deformable and undeformable objects. The proposed method demonstrates the best results in the interaction force estimation between the motorized system and object.","","","10.1109/JSEN.2018.2868332","Samsung; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453883","Force sensors;force estimation;interaction force;vision;electric current","Force;Robot sensing systems;Visualization;Convolution;Biological neural networks","convolution;image recognition;learning (artificial intelligence);recurrent neural nets","interaction force estimation;force/torque sensor;motorized system;visual information;electric information;electrical current","","2","52","","","","","IEEE","IEEE Journals"
"Toward Arbitrary-Oriented Ship Detection With Rotated Region Proposal and Discrimination Networks","Z. Zhang; W. Guo; S. Zhu; W. Yu","Shanghai Key Laboratory of Intelligent Sensing and Recognition, Shanghai Jiao Tong University, Shanghai, China; Shanghai Key Laboratory of Intelligent Sensing and Recognition, Shanghai Jiao Tong University, Shanghai, China; Shanghai Key Laboratory of Intelligent Sensing and Recognition, Shanghai Jiao Tong University, Shanghai, China; Shanghai Key Laboratory of Intelligent Sensing and Recognition, Shanghai Jiao Tong University, Shanghai, China","IEEE Geoscience and Remote Sensing Letters","","2018","15","11","1745","1749","Ship detection from remote sensing images can provide important information for maritime reconnaissance and surveillance and is also a challenging task. Although previous detection methods including some advanced ones based on deep convolutional neural network expertize in detecting horizontal or nearly horizontal targets, they cannot give satisfying detection results for arbitrary-oriented ship detection. In this letter, we introduce a novel ship detection system that can detect arbitrary-oriented ships. In this method, a rotated region proposal networks (R2PN) is proposed to generate multiorientated proposals with ship orientation angle information. In R2PN, the orientation angles of bounding boxes are also regressed to make the inclined ship region proposals generated more accurately. For ship discrimination, a rotated region of interest pooling layer is adopted in the following classification subnetwork to extract discriminative features from such inclined candidate regions. The proposed whole ship detection system can be trained end to end. Experimental results conducted on our rotated ship data set and HRSD2016 benchmark demonstrate that our proposed method outperforms state-of-the-art approaches for the arbitrary-oriented ship detection task.","","","10.1109/LGRS.2018.2856921","National Natural Science Foundation of China; China Postdoctoral Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8438330","Convolutional neural network (CNN);Faster R-CNN;rotated region;ship detection","Marine vehicles;Proposals;Feature extraction;Task analysis;Shape;Remote sensing;Convolutional neural networks","feature extraction;geophysical image processing;image classification;learning (artificial intelligence);neural nets;object detection;remote sensing;ships","inclined ship region;ship detection system;remote sensing images;discrimination networks;toward arbitrary-oriented ship detection;arbitrary-oriented ship detection task;rotated ship data;inclined candidate regions;discriminative features;ship discrimination;orientation angles;angle information;rotated region proposal networks;arbitrary-oriented ships;horizontal targets;deep convolutional neural network;important information","","5","15","","","","","IEEE","IEEE Journals"
"Check Out This Place: Inferring Ambiance From Airbnb Photos","L. S. Nguyen; S. Ruiz-Correa; M. S. Mast; D. Gatica-Perez","Social Computing Group, Idiap Research Institute, Martigny, Switzerland; Centro Nacional de Supercómputo, Instituto Potosino de Investigacion Cientifica y Tecnologica, San Luis Potosí, Mexico; Faculté des Hautes Etudes Commerciales (HEC Lausanne), Universite de Lausanne, Lausanne, Switzerland; Ecole Polytechnique Federale de Lausanne (EPFL), Idiap Research Institute, Martigny, Switzerland","IEEE Transactions on Multimedia","","2018","20","6","1499","1511","Airbnb is changing the landscape of the hospitality industry, and to this day, little is known about the inferences that guests make about Airbnb listings. Our work constitutes a first attempt at understanding how potential Airbnb guests form first impressions from images, one of the main modalities featured on the platform. We contribute to the multimedia community by proposing the novel task of automatically predicting human impressions of ambiance from pictures of listings on Airbnb. We collected Airbnb images, focusing on the countries Switzerland and Mexico as case studies, and used crowdsourcing mechanisms to gather annotations on physical and ambiance attributes, finding that agreement among raters was high for most of the attributes. Our cluster analysis showed that both physical and psychological attributes could be grouped into three clusters. We then extracted state-of-the-art features from the images to automatically infer the annotated variables in a regression task. Results show the feasibility of predicting ambiance impressions of homes on Airbnb, with up to 42% of the variance explained by our model, and best results were obtained using activation layers of deep convolutional neural networks trained on the Places dataset, a collection of scene-centric images.","","","10.1109/TMM.2017.2769444","EPFL-UNIL CROSS; Swiss National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094318","Ambiance prediction;first impressions;home environments;Airbnb;social media;image processing","Multimedia communication;Psychology;Urban areas;Social network services;Observers","crowdsourcing;feature extraction;image processing;learning (artificial intelligence);neural nets;pattern clustering;psychology;regression analysis;social networking (online)","Airbnb photos;hospitality industry;Airbnb listings;human impressions;physical attributes;psychological attributes;ambiance impressions;scene-centric images;multimedia community;Switzerland;Mexico;crowdsourcing mechanisms;cluster analysis;state-of-the-art features extraction;regression task;deep convolutional neural networks training;home environments;social media;image processing;ambiance inferences;Airbnb guests","","","49","","","","","IEEE","IEEE Journals"
"Building Extraction at Scale Using Convolutional Neural Network: Mapping of the United States","H. L. Yang; J. Yuan; D. Lunga; M. Laverdiere; A. Rose; B. Bhaduri","Computing and Computational Sciences Directorate, Oak Ridge National Laboratory, Oak Ridge, TN, USA; Computing and Computational Sciences Directorate, Oak Ridge National Laboratory, Oak Ridge, TN, USA; Computing and Computational Sciences Directorate, Oak Ridge National Laboratory, Oak Ridge, TN, USA; Computing and Computational Sciences Directorate, Oak Ridge National Laboratory, Oak Ridge, TN, USA; Computing and Computational Sciences Directorate, Oak Ridge National Laboratory, Oak Ridge, TN, USA; Computing and Computational Sciences Directorate, Oak Ridge National Laboratory, Oak Ridge, TN, USA","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2018","11","8","2600","2614","Establishing up-to-date large scale building maps is essential to understand the urban dynamics, such asestimating population, urban planning, and many other applications. Although many computer vision tasks have been successfully carried out with deep convolutional neural networks, there is a growing need to understand their large scale impact on building mapping with remote sensing imagery. Taking advantage of the scalability of convolutional neural networks (CNNs) and using only few areas with the abundance of building footprints, for the first time we conduct a comparative analysis of four state-of-the-art CNNs for extracting building footprints across the entire continental United States. The four CNN architectures namely: Branch-out CNN, fully convolutional network (FCN), conditional random field as recurrent neural network (CRFasRNN), and SegNet, support semantic pixelwise labeling and focus on capturing textural information at multiscale. We use 1-meter resolution aerial images from National Agriculture Imagery Program as the test-bed, and compare the extraction results across the four methods. In addition, we propose to combine signed-distance labels with SegNet, the preferred CNN architecture identified by our extensive evaluations, to advance building extraction results to instance level. We further demonstrate the usefulness of fusing additional near IR information into the building extraction framework. Large scale experimental evaluations are conducted and reported using metrics that include: Precision, recall rate, intersection over union, and the number of buildings extracted. With the improved CNN model and no requirement of further postprocessing, we have generated building maps for the United States with an average processing time less than one minute for an area of size ~56 km2. The quality of extracted buildings and processing time demonstrated that the proposed CNN based framework fits the need of building extraction at scale.","","","10.1109/JSTARS.2018.2835377","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8392725","Building extraction;convolutional neural networks (CNN);FCN;large scale;segnet;signed-distance","Buildings;Remote sensing;Feature extraction;Labeling;Training;Convolutional neural networks;Task analysis","cellular neural nets;computer vision;feature extraction;feedforward neural nets;geophysical image processing;image classification;image resolution;image segmentation;image texture;learning (artificial intelligence);neural net architecture;remote sensing;town and country planning","extracted buildings;processing time;CNN based framework;convolutional neural network;urban dynamics;urban planning;computer vision tasks;deep convolutional neural networks;scale impact;remote sensing imagery;building footprints;CNN architectures;Branch-out CNN;fully convolutional network;recurrent neural network;support semantic pixelwise labeling;1-meter resolution aerial images;National Agriculture Imagery Program;building extraction framework;improved CNN model;continental United States;large scale experimental evaluations;SegNet","","5","47","","","","","IEEE","IEEE Journals"
"GUN: Gradual Upsampling Network for Single Image Super-Resolution","Y. Zhao; G. Li; W. Xie; W. Jia; H. Min; X. Liu","School of Computer Science and Information Engineering, Hefei University of Technology, Hefei, China; School of Computer Science and Information Engineering, Hefei University of Technology, Hefei, China; School of Computer Science and Information Engineering, Hefei University of Technology, Hefei, China; School of Computer Science and Information Engineering, Hefei University of Technology, Hefei, China; School of Computer Science and Information Engineering, Hefei University of Technology, Hefei, China; School of Computer Science and Information Engineering, Hefei University of Technology, Hefei, China","IEEE Access","","2018","6","","39363","39374","In this paper, an efficient super-resolution (SR) method based on deep convolutional neural network (CNN) is proposed, namely gradual upsampling network (GUN). Recent CNN-based SR methods often preliminarily magnify the low-resolution (LR) input to high-resolution (HR) input and then reconstruct the HR input, or directly reconstruct the LR input and then recover the HR result at the last layer. The proposed GUN utilizes a gradual process instead of these two commonly used frameworks. The GUN consists of an input layer, multiple upsampling and convolutional layers, and an output layer. By means of the gradual process, the proposed network can simplify the direct SR problem to multistep easier upsampling tasks with very small magnification factor in each step. Furthermore, a gradual training strategy is presented for the GUN. In the proposed training process, an initial network can be easily trained with edgelike samples, and then, the weights are gradually tuned with more complex samples. The GUN can recover fine and vivid results and is easy to be trained. The experimental results on several image sets demonstrate the effectiveness of the proposed network.","","","10.1109/ACCESS.2018.2855127","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities of China; National Natural Science Foundation of China; Open Foundation of Science and Technology on Communication Networks Laboratory; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8410509","Super-resolution;upsampling;convolutional neural network","Image reconstruction;Training;Image resolution;Task analysis;Interpolation;Computational modeling;Convolutional neural networks","image reconstruction;image resolution;image sampling;learning (artificial intelligence);neural nets","deep convolutional neural network;gradual upsampling network;GUN;low-resolution input;high-resolution input;HR input;LR input;gradual process;multiple upsampling;convolutional layers;direct SR problem;gradual training strategy;single image super-resolution;super-resolution method;CNN-based SR methods;upsampling tasks","","10","70","","","","","IEEE","IEEE Journals"
"Age-Related Factor Guided Joint Task Modeling Convolutional Neural Network for Cross-Age Face Recognition","H. Li; H. Hu; C. Yip","School of Electronics and Information Technology, Sun Yat-Sen University, Guangzhou, China; School of Electronics and Information Technology, Sun Yat-Sen University, Guangzhou, China; School of Electronics and Information Technology, Sun Yat-Sen University, Guangzhou, China","IEEE Transactions on Information Forensics and Security","","2018","13","9","2383","2392","Cross-age face recognition has remained a popular research topic as most regular facial recognition systems have failed in dealing with facial changes through age. In order to enhance the system's capability of discriminating facial identity features in spite of age changes, this paper proposes a novel deep convolutional network method for cross-age face recognition called age-related factor guided joint task modeling convolutional neural networks, which combines an identity discrimination network with an age discrimination network that shares the same feature layers. By alternatively training the fusion networks and the combined factor model, the cross-age identity features and cross-identity age features can be effectively separated with high inter-class distension and intra-class compactness. Extensive experiments have been performed on the benchmark aging data sets, including MORPH, CACD-VS, and Cross Age LFW. The results have demonstrated the superiority and effectiveness of our model.","","","10.1109/TIFS.2018.2819124","National Natural Science Foundation of China; Natural Science Foundation of Guangdong; Science and Technology Program of Guangzhou; Fundamental Research Funds for the Central Universities of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8323422","Age-related factor guided joint task modeling convolutional neural network;cross-age face recognition;joint task factor analysis","Feature extraction;Aging;Task analysis;Face;Face recognition;Convolution;Training","face recognition;feature extraction;feedforward neural nets;learning (artificial intelligence)","cross-age face recognition;regular facial recognition systems;facial identity features;deep convolutional network method;convolutional neural networks;identity discrimination network;age discrimination network;cross-age identity features;cross-identity age features;convolutional neural network;Age-Related Factor Guided Joint Task Modeling;inter-class distension;intra-class compactness;MORPH benchmark aging data sets;CACD-VS benchmark aging data sets;Cross Age LFW benchmark aging data sets","","4","38","","","","","IEEE","IEEE Journals"
"DFTerNet: Towards 2-bit Dynamic Fusion Networks for Accurate Human Activity Recognition","Z. Yang; O. I. Raymond; C. Zhang; Y. Wan; J. Long","School of Information Science and Engineering, Central South University, Changsha, China; School of Information Science and Engineering, Central South University, Changsha, China; School of Information Science and Engineering, Central South University, Changsha, China; School of Information Science and Engineering, Central South University, Changsha, China; School of Information Science and Engineering, Central South University, Changsha, China","IEEE Access","","2018","6","","56750","56764","Deep convolutional neural networks (DCNNs) are currently popular in human activity recognition (HAR) applications. However, in the face of modern artificial intelligence sensor-based games, many research achievements cannot be practically applied on portable devices (i.e., smart phone, VR/AR). DCNNs are typically resource-intensive and too large to be deployed on portable devices, and thus, this limits the practical application of complex activity detection. In addition, since portable devices do not possess high-performance graphic processing units, there is hardly any improvement in Action Game (ACT) experience. Besides, in order to deal with multi-sensor collaboration, all previous HAR models typically treated the representations from different sensor signal sources equally. However, distinct types of activities should adopt different fusion strategies. In this paper, a novel scheme is proposed. This scheme is used to train 2-bit CNNs with weights and activations constrained to {-0.5, 0, 0.5}. It takes into account the correlation between different sensor signal sources and the activity types. This model, which we refer to as DFTerNet, aims at producing a more reliable inference and better trade-offs for practical applications. It is known that quantization of weights and activations can substantially reduce memory size and use more efficient bitwise operations to replace floating or matrix operations to achieve much faster calculation and lower power consumption. Our basic idea is to exploit quantization of weights and activations directly in pre-trained filter banks and adopt dynamic fusion strategies for different activity types. Experiments demonstrate that by using a dynamic fusion strategy, it is possible to exceed the baseline model performance by up to ~5% on activity recognition data sets, such as the OPPORTUNITY and PAMAP2 data sets. Using the quantization method proposed, we were able to achieve performances closer to that of the full-precision counterpart. These results were also verified using the UniMiB-SHAR data set. In addition, the proposed method can achieve ~9x acceleration on CPUs and ~11x memory saving.","","","10.1109/ACCESS.2018.2873315","National Natural Science Foundation of China; Natural Science Foundation of Hunan Province; Science and Technology Plan of Hunan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8478282","Human activity recognition;2-bit neural networks;dynamic fusion strategy","Quantization (signal);Activity recognition;Convolutional neural networks;Computational modeling;Games;Memory management","computer games;convolution;feedforward neural nets;image recognition;intelligent sensors;learning (artificial intelligence)","accurate human activity recognition;DCNNs;modern artificial intelligence sensor-based games;portable devices;high-performance graphic processing units;multisensor collaboration;2-bit CNNs;activations;DFTerNet;baseline model performance;activity recognition data sets;UniMiB-SHAR data set;quantization method;OPPORTUNITY data sets;PAMAP2 data sets;pre-trained filter banks;weights;ACT experience;sensor signal sources;action game experience;2-bit dynamic fusion networks;HAR models;deep convolutional neural networks","","","55","","","","","IEEE","IEEE Journals"
"Weighted Quantization-Regularization in DNNs for Weight Memory Minimization Toward HW Implementation","M. Wess; S. M. P. Dinakarrao; A. Jantsch","Institute of Computer Technology, TU Wien, Vienna, Austria; Electrical Engineering Department, George Mason University, Fairfax, VA, USA; Institute of Computer Technology, TU Wien, Vienna, Austria","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","","2018","37","11","2929","2939","Deployment of deep neural networks on hardware platforms is often constrained by limited on-chip memory and computational power. The proposed weight quantization offers the possibility of optimizing weight memory alongside transforming the weights to hardware friendly data types. We apply dynamic fixed point (DFP) and power-of-two (Po2) quantization in conjunction with layer-wise precision scaling to minimize the weight memory. To alleviate accuracy degradation due to precision scaling, we employ quantization-aware fine-tuning. For fine-tuning, quantization-regularization (QR) and weighted QR are introduced to force the trained quantization by adding the distance of the weights to the desired quantization levels as a regularization term to the loss-function. While DFP quantization performs better when allowing different bit-widths for each layer, Po2 quantization in combination with retraining allows higher compression rates for equal bit-width quantization. The techniques are verified on an all-convolutional network. With accuracy degradation of 0.10% points, for DFP with layer-wise precision scaling we achieve compression ratios of 7.34 for CIFAR-10, 4.7 for CIFAR-100, and 9.33 for SVHN dataset.","","","10.1109/TCAD.2018.2857080","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8412511","Convolutional neural networks;memory minimization;quantization;regularization","Quantization (signal);Neural networks;Hardware;Degradation;Training;Force;Task analysis","convolution;data compression;feedforward neural nets;learning (artificial intelligence);minimisation;quantisation (signal)","weight quantization;hardware friendly data types;dynamic fixed point;power-of-two quantization;layer-wise precision scaling;quantization-aware fine-tuning;DFP quantization;Po2 quantization;weighted quantization-regularization;deep neural networks;hardware platforms;on-chip memory;computational power;DNNs;weight memory minimization;HW implementation;bit-width quantization;all-convolutional network;compression ratios;SVHN dataset","","1","29","","","","","IEEE","IEEE Journals"
"Convolutional neural network for smooth filtering detection","B. Yang; X. Sun; E. Cao; W. Hu; X. Chen","School of Design, Jiangnan University, People's Republic of China; Jiangsu Engineering Center of Network Monitoring, Nanjing University of Information Science and Technology, People's Republic of China; School of Design, Jiangnan University, People's Republic of China; School of Design, Jiangnan University, People's Republic of China; Jiangsu Engineering Center of Network Monitoring, Nanjing University of Information Science and Technology, People's Republic of China","IET Image Processing","","2018","12","8","1432","1438","Smooth filtering is a common post-operation which is exploited to blur and conceal the traces of tampered objects. Most of the existing forensic methods aim at detecting only one type of filtering process, such as median filtering or Gaussian filtering, which limits their applications. The authors present a new forensic method based on deep learning technique, which utilises a convolutional neural network (CNN) to automatically learn hierarchical representations from the input images. Unlike conventional CNN models, a modified CNN architecture is specifically designed to identify traces left by the manipulation. A filter layer is added into the CNN. The filtering residual in frequency feature of the input image is extracted by this added layer. The output feature is then fed into the next layer of the CNN. Radon transform is applied to increase the distinctiveness of the residual feature. Experimental results on several public datasets show that the proposed CNN-based model outperforms some state-of-the-art methods.","","","10.1049/iet-ipr.2017.0683","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8423389","","","convolution;image representation;median filters;neural nets;Radon transforms","convolutional neural network;smooth filtering detection;tampered objects;median filtering;Gaussian filtering;deep learning technique;hierarchical representations;modified CNN architecture;filter layer;frequency feature;residual feature;Radon transform","","","42","","","","","IET","IET Journals"
"Thermal Augmented Expression Recognition","S. Wang; B. Pan; H. Chen; Q. Ji","School of Computer Science and Technology, University of Science and Technology of China, Hefei, China; School of Computer Science and Technology, University of Science and Technology of China, Hefei, China; School of Computer Science and Technology, University of Science and Technology of China, Hefei, China; Department of Electrical, Computer, and Systems Engineering, Rensselaer Polytechnic Institute, Troy, NY, USA","IEEE Transactions on Cybernetics","","2018","48","7","2203","2214","Visible facial images provide geometric and appearance patterns of facial expressions and are sensitive to illumination changes. Thermal facial images record facial temperature distribution and are robust to light conditions. Therefore, expression recognition is enhanced by visible and thermal image fusion. In most cases, only visible images are available due to the widespread popularity of visible cameras and the high cost of thermal cameras. Thus, we propose a novel visible expression recognition method by using thermal infrared (IR) data as privileged information, which is only available during training. Specifically, we first learn a deep model for visible images and thermal images. Then we use the learned feature representations to train support vector machine (SVM) classifiers for expression classification. We jointly refine the deep models as well as the SVM classifiers for both thermal images and visible images by imposing the constraint that the outputs of the SVM classifiers from two views are similar. Thermal IR images during training are then exploited to construct better facial representations and expression classifiers from visible images. We extend the proposed thermal augmented expression recognition method for partially unpaired data, acknowledging that visible images and thermal images maybe not be recorded synchronously. Experimental result on the MAHNOB laughter database demonstrate that the proposed thermal augmented expression recognition method can effectively exploit thermal IR images' supplementary role for visible facial expression recognition during training to obtain better facial representations and a better visible expression classifier. The proposed thermal augmented expression recognition method achieves state-of-the-art expression recognition performance for both paired and unpaired facial images.","","","10.1109/TCYB.2017.2786309","National Science Foundation of China; Project from Anhui Science and Technology Agency; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8253869","Deep models;facial expression recognition;privileged information;support vector machine;thermal images;visible images","Image recognition;Face recognition;Feature extraction;Training;Support vector machines;Temperature distribution;Videos","cameras;emotion recognition;face recognition;feature extraction;image classification;image fusion;image representation;infrared imaging;support vector machines;temperature distribution","visible facial images;visible image fusion;thermal image fusion;visible cameras;thermal cameras;thermal infrared data;SVM classifiers;thermal IR images;facial representations;expression classifiers;visible facial expression recognition;visible expression classifier;unpaired facial images;thermal facial images;facial temperature distribution;visible expression recognition method;thermal augmented expression recognition method;feature representations;support vector machine;expression classification","Databases, Factual;Facial Expression;Humans;Image Processing, Computer-Assisted;Laughter;Models, Statistical;Pattern Recognition, Automated;Support Vector Machine;Thermography","2","37","","","","","IEEE","IEEE Journals"
"Robust Multi-Classifier for Camera Model Identification Based on Convolution Neural Network","H. Yao; T. Qiao; M. Xu; N. Zheng","School of Cyberspace, Hangzhou Dianzi University, Hangzhou, China; School of Cyberspace, Hangzhou Dianzi University, Hangzhou, China; School of Cyberspace, Hangzhou Dianzi University, Hangzhou, China; School of Cyberspace, Hangzhou Dianzi University, Hangzhou, China","IEEE Access","","2018","6","","24973","24982","With the prevalence of adopting data-driven convolution neural network (CNN)-based algorithms into the community of digital image forensics, some novel supervised classifiers have indeed increasingly sprung up with nearly perfect detection rate, compared with the conventional supervised mechanism. The goal of this paper is to investigate a robust multi-classifier for dealing with one of the image forensic problems, referred to as source camera identification. The main contributions of this paper are threefold: (1) by mainly analyzing the image features characterizing different source camera models, we design an improved architecture of CNN for adaptively and automatically extracting characteristics, instead of hand-crafted extraction; (2) the proposed efficient CNN-based multi-classifier is capable of simultaneously classifying the tested images acquired by a large scale of different camera models, instead of utilizing a binary classifier; and (3) numerical experiments show that our proposed multi-classifier can effectively classify different camera models while achieving an average accuracy of nearly 100% relying on majority voting, which indeed outperforms some prior arts; meanwhile, its robustness has been verified by considering that the images are attacked by post-processing such as JPEG compression and noise adding.","","","10.1109/ACCESS.2018.2832066","Cyberspace Security Major Program in National Key Research and Development Plan of China; Natural Science Foundation of China; State Key Program of Zhejiang Province Natural Science Foundation of China; Key Research and Development Plan Project of Zhejiang Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8353219","Camera model identification;deep learning;convolution neural network (CNN);passive image forensics","Cameras;Feature extraction;Robustness;Forensics;Numerical models;Digital images;Transform coding","cameras;convolution;feature extraction;feedforward neural nets;image classification;image coding;image forensics","JPEG compression;supervised mechanism;image features;image forensic problems;digital image forensics;convolution neural network;camera model identification;robust multiclassifier","","6","41","","","","","IEEE","IEEE Journals"
"Object Proposal Generation With Fully Convolutional Networks","Z. Jie; W. F. Lu; S. Sakhavi; Y. Wei; E. H. F. Tay; S. Yan","Keio-National University of Singapore (NUS) Connective Ubiquitous Technology for Embodiments Center, Interactive and Digital Media Institute, NUS, Singapore; Department of Mechanical Engineering, National University of Singapore, Singapore; Department of Electrical and Computer Engineering, National University of Singapore, Singapore; Department of Electrical and Computer Engineering, National University of Singapore, Singapore; Department of Mechanical Engineering, National University of Singapore, Singapore; Department of Electrical and Computer Engineering, National University of Singapore, Singapore","IEEE Transactions on Circuits and Systems for Video Technology","","2018","28","1","62","75","Object proposal generation, as a preprocessing technique, has been widely used in current object detection pipelines to guide the search of objects and avoid exhaustive sliding window search across images. Current object proposals are mostly based on low-level image cues, such as edges and saliency. However, objectness is possibly a high-level semantic concept showing whether one region contains objects. This paper presents a framework utilizing fully convolutional networks (FCNs) to produce object proposal positions and bounding box location refinement with Support Vector Machine (SVM) to further improve proposal localization. Experiments on the PASCAL VOC 2007 show that using high-level semantic object proposals obtained by FCN, the object recall can be improved. An improvement in detection mean average precision is also seen when using our proposals in the Fast R-convolutional neural network framework. In addition, we also demonstrate that our method shows stronger robustness when introduced to image perturbations, e.g., blurring, JPEG compression, and salt and pepper noise. Finally, the generalization capability of our model (trained on the PASCAL VOC 2007) is evaluated and validated by testing on PASCAL VOC 2012 validation set, ILSVRC 2013 validation set, and MS COCO 2014 validation set.","","","10.1109/TCSVT.2016.2576759","National Research Foundation, Prime Minister’s Office, Singapore; International Research Centres in Singapore Funding Initiative; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7484700","Box location refinement;deep learning;fully convolutional networks (FCNs);object proposals","Proposals;Semantics;Object detection;Image edge detection;Support vector machines;Pipelines;Testing","convolution;edge detection;neural nets;object detection;support vector machines","object proposal generation;low-level image cues;high-level semantic object proposals;Fast R-convolutional neural network framework;convolutional networks;sliding window search;object detection pipelines","","5","42","","","","","IEEE","IEEE Journals"
"“Elbows Out”—Predictive Tracking of Partially Occluded Pose for Robot-Assisted Dressing","G. Chance; A. Jevtić; P. Caleb-Solly; G. Alenyà; C. Torras; S. Dogramadzi","Bristol Robotics Laboratory, University of the West of England, Bristol, U.K.; Institut de Robòtica i Informàtica Industrial, CSIC-UPC, Barcelona, Spain; Bristol Robotics Laboratory, University of the West of England, Bristol, U.K.; Institut de Robòtica i Informàtica Industrial, CSIC-UPC, Barcelona, Spain; Institut de Robòtica i Informàtica Industrial, CSIC-UPC, Barcelona, Spain; Bristol Robotics Laboratory, University of the West of England, Bristol, U.K.","IEEE Robotics and Automation Letters","","2018","3","4","3598","3605","Robots that can assist in the activities of daily living, such as dressing, may support older adults, addressing the needs of an aging population in the face of a growing shortage of care professionals. Using depth cameras during robot-assisted dressing can lead to occlusions and loss of user tracking, which may result in unsafe trajectory planning or prevent the planning task proceeding altogether. For the dressing task of putting on a jacket, which is addressed in this letter, tracking of the arm is lost when the user's hand enters the jacket, which may lead to unsafe situations for the user and a poor interaction experience. Using motion tracking data, free from occlusions, gathered from a human-human interaction study on an assisted dressing task, recurrent neural network models were built to predict the elbow position of a single arm based on other features of the user pose. The best features for predicting the elbow position were explored by using regression trees indicating the hips and shoulder as possible predictors. Engineered features were also created based on observations of real dressing scenarios and their effectiveness explored. Comparison between position and orientation-based datasets was also included in this study. A 12-fold cross-validation was performed for each feature set and repeated 20 times to improve statistical power. Using position-based data, the elbow position could be predicted with a 4.1 cm error but adding engineered features reduced the error to 2.4 cm. Adding orientation information to the data did not improve the accuracy and aggregating univariate response models failed to make significant improvements. The model was evaluated on Kinect data for a robot dressing task and although not without issues, demonstrates potential for this application. Although this has been demonstrated for jacket dressing, the technique could be applied to a number of different situations during occluded tracking.","","","10.1109/LRA.2018.2854926","I-DRESS; Acciones de Programacion Conjunta Internacional 2015 of the Spanish Ministry of Economy, Industry and Competitiveness; UK EPSRC; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8410029","Physical human–robot interaction;human detection and tracking;deep learning in robotics and automation;robot safety","Elbow;Cameras;Task analysis;Tracking;Robot vision systems;Trajectory","biomechanics;cameras;geriatrics;gesture recognition;human computer interaction;image motion analysis;pose estimation;recurrent neural nets;regression analysis;robot vision;robots;statistical analysis;trees (mathematics)","position-based data;elbow position;robot dressing task;jacket dressing;occluded tracking;predictive tracking;robot-assisted dressing;occlusions;motion tracking data;human-human interaction study;assisted dressing task;recurrent neural network models;user pose;dressing scenarios;orientation-based datasets;trajectory planning;interaction experience;partially occluded pose predictive tracking;regression trees;older adult support;12-fold cross-validation","","2","28","CCBY","","","","IEEE","IEEE Journals"
"Recurrent Multiresolution Convolutional Networks for VHR Image Classification","J. R. Bergado; C. Persello; A. Stein","Department of Earth Observation Science, Faculty of Geoinformation Science and Earth Observation, University of Twente, Enschede, The Netherlands; Department of Earth Observation Science, Faculty of Geoinformation Science and Earth Observation, University of Twente, Enschede, The Netherlands; Department of Earth Observation Science, Faculty of Geoinformation Science and Earth Observation, University of Twente, Enschede, The Netherlands","IEEE Transactions on Geoscience and Remote Sensing","","2018","56","11","6361","6374","Classification of very high-resolution (VHR) satellite images has three major challenges: 1) inherent low intraclass and high interclass spectral similarities; 2) mismatching resolution of available bands; and 3) the need to regularize noisy classification maps. Conventional methods have addressed these challenges by adopting separate stages of image fusion, feature extraction, and postclassification map regularization. These processing stages, however, are not jointly optimizing the classification task at hand. In this paper, we propose a single-stage framework embedding the processing stages in a recurrent multiresolution convolutional network trained in an end-to-end manner. The feedforward version of the network, called FuseNet, aims to match the resolution of the panchromatic and multispectral bands in a VHR image using convolutional layers with corresponding downsampling and upsampling operations. Contextual label information is incorporated into FuseNet by means of a recurrent version called ReuseNet. We compared FuseNet and ReuseNet against the use of separate processing steps for both image fusions, e.g., pansharpening and resampling through interpolation and map regularization such as conditional random fields. We carried out our experiments on a land-cover classification task using a Worldview-03 image of Quezon City, Philippines, and the International Society for Photogrammetry and Remote Sensing 2-D semantic labeling benchmark data set of Vaihingen, Germany. FuseNet and ReuseNet surpass the baseline approaches in both the quantitative and qualitative results.","","","10.1109/TGRS.2018.2837357","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8388225","Convolutional networks;deep learning;land cover classification;recurrent networks;very high-resolution (VHR) image","Feature extraction;Spatial resolution;Image fusion;Task analysis;Kernel;Labeling","convolution;feature extraction;feedforward neural nets;geophysical image processing;geophysical techniques;image classification;image denoising;image fusion;image resolution;interpolation;photogrammetry;remote sensing;terrain mapping","recurrent multiresolution convolutional network;VHR image classification;high-resolution satellite images;high interclass spectral similarities;noisy classification maps;image fusion;panchromatic bands;multispectral bands;convolutional layers;ReuseNet;interpolation;land-cover classification task;Worldview-03 image;Remote Sensing 2-D semantic labeling benchmark data;FuseNet;post classification map regularization;feature extraction","","5","41","","","","","IEEE","IEEE Journals"
"Forecasting the High Penetration of Wind Power on Multiple Scales Using Multi-to-Multi Mapping","J. Yan; H. Zhang; Y. Liu; S. Han; L. Li; Z. Lu","State Key Laboratory of Alternate Electrical Power System with Renewable Energy Sources, School of Renewable Energy, North China Electric Power University, Beijing, China; State Key Laboratory of Alternate Electrical Power System with Renewable Energy Sources, School of Renewable Energy, North China Electric Power University, Beijing, China; State Key Laboratory of Alternate Electrical Power System with Renewable Energy Sources, School of Renewable Energy, North China Electric Power University, Beijing, China; State Key Laboratory of Alternate Electrical Power System with Renewable Energy Sources, School of Renewable Energy, North China Electric Power University, Beijing, China; State Key Laboratory of Alternate Electrical Power System with Renewable Energy Sources, School of Renewable Energy, North China Electric Power University, Beijing, China; Department of Electrical Engineering, Tsinghua University, Beijing, China","IEEE Transactions on Power Systems","","2018","33","3","3276","3284","Highly wind penetrated future power system will couple to the variabilities and nonlinear correlations of wind. Reliable wind power forecasting (WPF) for a region is critical to the security and economics of the power system operation. Therefore, this paper proposes a multiscale WPF method by establishing a multi-to-multi (m2m) mapping network and the use of stacked denoising autoencoder (SDAE). The concerned forecast time horizon is 24-72 hours. First, multi-NWPs in a region are corrected based on SDAE to generate better inputs for the following regional WPF. Second, a number of SDAEs with diverse model parameters and input features are integrated into ensemble SDAE for predicting the wind power generated from various wind farms in a region. Two sets of data are utilized in this case study to validate the proposed method. The results show that the proposed m2m mapping and SDAE are able to capture the real correlations of wind at multiple sites, and outperform the other counterparts in terms of multi-NWPs correction as well as the WPF for both the region and individual concerned wind farm. Moreover, the ensemble SDAE performs better than any other individual regional WPF model.","","","10.1109/TPWRS.2017.2787667","National Key Research and Development Program of China: Fundamental Theory of Planning and Operation for Power Systems with High Share of Renewable Energy Generations; State Key Laboratory of Alternate Electrical Power System with Renewable Energy Sources; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8240639","Multi-scale forecasting;regional forecasting;wind power forecasting;high penetration;deep learning;multiple NWP","Wind farms;Correlation;Wind speed;Wind forecasting;Forecasting;Wind power generation","load forecasting;neural nets;power engineering computing;power generation reliability;wind power;wind power plants","stacked denoising autoencoder;concerned forecast time horizon;ensemble SDAE;wind farms;individual concerned wind farm;individual regional WPF model;future power system;reliable wind power forecasting;power system operation;multiscale WPF method;multi-to-multimapping network;wind penetrated future power system;regional WPF;multiNWP correction","","9","26","","","","","IEEE","IEEE Journals"
"Spectral–Spatial Unified Networks for Hyperspectral Image Classification","Y. Xu; L. Zhang; B. Du; F. Zhang","State Key Laboratory of Information Engineering in Surveying, Mapping, and Remote Sensing, Wuhan University, Wuhan, China; State Key Laboratory of Information Engineering in Surveying, Mapping, and Remote Sensing, Wuhan University, Wuhan, China; School of Computer, Wuhan University, Wuhan, China; State Key Laboratory of Information Engineering in Surveying, Mapping, and Remote Sensing, Wuhan University, Wuhan, China","IEEE Transactions on Geoscience and Remote Sensing","","2018","56","10","5893","5909","In this paper, we propose a spectral-spatial unified network (SSUN) with an end-to-end architecture for the hyperspectral image (HSI) classification. Different from traditional spectral-spatial classification frameworks where the spectral feature extraction (FE), spatial FE, and classifier training are separated, these processes are integrated into a unified network in our model. In this way, both FE and classifier training will share a uniform objective function and all the parameters in the network can be optimized at the same time. In the implementation of the SSUN, we propose a band grouping-based long short-term memory model and a multiscale convolutional neural network as the spectral and spatial feature extractors, respectively. In the experiments, three benchmark HSIs are utilized to evaluate the performance of the proposed method. The experimental results demonstrate that the SSUN can yield a competitive performance compared with existing methods.","","","10.1109/TGRS.2018.2827407","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8356713","Convolutional neural network (CNN);deep learning;feature extraction (FE);hyperspectral image (HSI) classification;long short-term memory (LSTM)","Feature extraction;Iron;Training;Logic gates;Hyperspectral imaging;Computer architecture","feature extraction;geophysical image processing;hyperspectral imaging;image classification;neural nets","band grouping-based long short-term memory model;spatial feature extractors;spectral feature extractors;multiscale convolutional neural network;classifier training;spatial FE;spectral feature extraction;spectral-spatial classification frameworks;end-to-end architecture;SSUN;spectral-spatial unified network;hyperspectral image classification","","17","65","","","","","IEEE","IEEE Journals"
"Asynchronous and Event-Based Fusion Systems for Affect Recognition on Naturalistic Data in Comparison to Conventional Approaches","F. Lingenfelser; J. Wagner; J. Deng; R. Brueckner; B. Schuller; E. André","Universität Augsburg, Augsburg, Germany; Universität Augsburg, Augsburg, Germany; Technische Universität München, München, Germany; Technische Universität München, München, Germany; Technische Universität München, München, Germany; Universität Augsburg, Augsburg, Germany","IEEE Transactions on Affective Computing","","2018","9","4","410","423","Throughout many present studies dealing with multi-modal fusion, decisions are synchronously forced for fixed time segments across all modalities. Varying success is reported, sometimes performance is worse than unimodal classification. Our goal is the synergistic exploitation of multimodality whilst implementing a real-time system for affect recognition in a naturalistic setting. Therefore we present a categorization of possible fusion strategies for affect recognition on continuous time frames of complete recording sessions and we evaluate multiple implementations from resulting categories. These involve conventional fusion strategies as well as novel approaches that incorporate the asynchronous nature of observed modalities. Some of the latter algorithms consider temporal alignments between modalities and observed frames by applying asynchronous neural networks that use memory blocks to model temporal dependencies. Others use an indirect approach that introduces events as an intermediate layer to accumulate evidence for the target class through all modalities. Recognition results gained on a naturalistic conversational corpus show a drop in recognition accuracy when moving from unimodal classification to synchronous multimodal fusion. However, with our proposed asynchronous and event-based fusion techniques we are able to raise the recognition system's accuracy by 7.83 percent compared to video analysis and 13.71 percent in comparison to common fusion strategies.","","","10.1109/TAFFC.2016.2635124","ARIA-VALUSPA; KRISTINA; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7765044","Affective computing;multimodal recognition;sensor fusion;artificial neural networks;deep learning","Hidden Markov models;Emotion recognition;Recurrent neural networks;Visualization;Heuristic algorithms;Affective computing","affective computing;neural nets;sensor fusion","affect recognition;unimodal classification;real-time system;asynchronous neural networks;synchronous multimodal fusion;asynchronous event-based fusion techniques","","","43","","","","","IEEE","IEEE Journals"
"Hardware-Oriented Compression of Long Short-Term Memory for Efficient Inference","Z. Wang; J. Lin; Z. Wang","School of Electronic Science and Engineering, Nanjing University, Nanjing, China; School of Electronic Science and Engineering, Nanjing University, Nanjing, China; School of Electronic Science and Engineering, Nanjing University, Nanjing, China","IEEE Signal Processing Letters","","2018","25","7","984","988","Long short-term memory (LSTM) and its variants have been widely adopted in processing sequential data. However, the intrinsic large memory requirement and high computational complexity make it hard to be employed in embedded systems. This incurs the need of model compression and dedicated hardware accelerator for LSTM. In this letter, efficient clipped gating and top-k pruning schemes are introduced to convert the dense matrix computations in LSTM into structured sparse-matrix-sparse-vector multiplications. Then, mixed quantization schemes are developed to eliminate most of the multiplications in LSTM. The proposed compression scheme is well suited for efficient hardware implementations. Experimental results show that the model size and the number of matrix operations can be reduced by 32× and 18.5×, respectively, at a cost of less than 1% accuracy loss on a word-level language modeling task.","","","10.1109/LSP.2018.2834872","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8358763","Deep learning;long short-term memory (LSTM);network compression;recurrent neural networks (RNNs)","Computational modeling;Quantization (signal);Computational complexity;Hardware;Sparse matrices;Logic gates;Training","computational complexity;data compression;embedded systems;matrix multiplication;recurrent neural nets;sparse matrices;vectors","recurrent neural networks;hardware implementations;mixed quantization;computational complexity;sequential data processing;compression scheme;sparse-matrix-sparse-vector multiplications;dense matrix computations;top-k pruning schemes;dedicated hardware accelerator;model compression;embedded systems;intrinsic large memory requirement;LSTM;efficient inference;long short-term memory;hardware-oriented compression","","2","28","","","","","IEEE","IEEE Journals"
"Stacked Auto-Encoder Based Fault Location in VSC-HVDC","G. Luo; C. Yao; Y. Liu; Y. Tan; J. He; K. Wang","School of Electrical Engineering, Beijing Jiaotong University, Beijing, China; School of Electrical Engineering, Beijing Jiaotong University, Beijing, China; School of Electrical Engineering, Beijing Jiaotong University, Beijing, China; School of Electrical Engineering, Beijing Jiaotong University, Beijing, China; School of Electrical Engineering, Beijing Jiaotong University, Beijing, China; CloudMinds Technologies Inc., Beijing, China","IEEE Access","","2018","6","","33216","33224","This paper presents an end-to-end approach for locating faults on high-voltage dc (HVDC) transmission lines. Different from traditional methods which rely on communications between different measuring units or feature extraction of post fault transients, the proposed algorithm takes the raw data of locally detected traveling current surges as the only-input and outputs the fault locations directly. Especially, the stacked auto-encoder (SAE) is utilized to model the relationship between fault currents and fault locations. The SAE-based method is performed in time domain and tested with a simulated HVDC transmission line modeled in PSCAD/EMTDC. The simulation results show that this method is effective in locating faulted points and robust against attenuation, overlapping of traveling surges, and various ground resistances.","","","10.1109/ACCESS.2018.2848841","National Natural Science Foundation of China; National Key Research and Development Program of China; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8387831","VSC-HVDC;fault location;stacked auto-encoder;deep learning","","fault location;feature extraction;HVDC power convertors;HVDC power transmission;power transmission faults;voltage-source convertors","feature extraction;post fault transients;fault locations;fault currents;SAE-based method;VSC-HVDC;high-voltage dc transmission lines;PSCAD-EMTDC;time domain;traveling current surge detection;fault location;stacked auto-encoder;HVDC transmission line","","","38","","","","","IEEE","IEEE Journals"
"Convolutional Neural Network Based Metal Artifact Reduction in X-Ray Computed Tomography","Y. Zhang; H. Yu","Department of Electrical and Computer Engineering, University of Massachusetts at Lowell, Lowell, MA, USA; Department of Electrical and Computer Engineering, University of Massachusetts at Lowell, Lowell, MA, USA","IEEE Transactions on Medical Imaging","","2018","37","6","1370","1381","In the presence of metal implants, metal artifacts are introduced to x-ray computed tomography CT images. Although a large number of metal artifact reduction (MAR) methods have been proposed in the past decades, MAR is still one of the major problems in clinical x-ray CT. In this paper, we develop a convolutional neural network (CNN)-based open MAR framework, which fuses the information from the original and corrected images to suppress artifacts. The proposed approach consists of two phases. In the CNN training phase, we build a database consisting of metal-free, metal-inserted and pre-corrected CT images, and image patches are extracted and used for CNN training. In the MAR phase, the uncorrected and pre-corrected images are used as the input of the trained CNN to generate a CNN image with reduced artifacts. To further reduce the remaining artifacts, water equivalent tissues in a CNN image are set to a uniform value to yield a CNN prior, whose forward projections are used to replace the metal-affected projections, followed by the FBP reconstruction. The effectiveness of the proposed method is validated on both simulated and real data. Experimental results demonstrate the superior MAR capability of the proposed method to its competitors in terms of artifact suppression and preservation of anatomical structures in the vicinity of metal implants.","","","10.1109/TMI.2018.2823083","NIH/NIBIB U01; R21; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8331163","X-ray computed tomography (CT);metal artifacts;convolutional neural networks;deep learning","Metals;Computed tomography;Databases;Image reconstruction;Bones;Attenuation;Convolutional neural networks","biological tissues;biomedical materials;computerised tomography;convolution;diagnostic radiography;image reconstruction;medical image processing;neural nets;prosthetics","metal implants;convolutional neural network;metal artifact reduction methods;Convolutional Neural Network Based Metal Artifact Reduction;CNN image patches;X-ray computed tomography CT images;anatomical structures;water equivalent tissues","","1","53","","","","","IEEE","IEEE Journals"
"Automated video face labelling for films and TV material","O. Parkhi; E. Rahtu; Q. Cao; A. Zisserman","Department of Engineering Science, Visual Geometry Group, Oxford University, Oxford, Oxfordshire United Kingdom of Great Britain and Northern Ireland (e-mail: omkar@robots.ox.ac.uk); Computer Science and Engineering, University of Oulu, Oulu, Northern Ostrobothnia Finland (e-mail: erahtu@ee.oulu.fi); Department of Engineering Science, Visual Geometry Group, Oxford University, Oxford, Oxfordshire United Kingdom of Great Britain and Northern Ireland (e-mail: qiong@robots.ox.ac.uk); Department of Engineering Science, University of Oxford, Oxford, Oxford United Kingdom of Great Britain and Northern Ireland (e-mail: az@robots.ox.ac.uk)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","PP","99","1","1","The objective of this work is automatic labelling of characters in TV video and movies, given weak supervisory information provided by an aligned transcript. We make five contributions: (i) a new strategy for obtaining stronger supervisory information from aligned transcripts; (ii) an explicit model for classifying background characters, based on their face-tracks; (iii) employing new ConvNet based face features, and (iv) a novel approach for labelling all face tracks jointly using linear programming. Each of these contributions delivers a boost in performance, and we demonstrate this on standard benchmarks using tracks provided by authors of prior work. As a fifth contribution, we also investigate the generalisation and strength of the features and classifiers by applying them ""in the raw"" on new video material where no supervisory information is used. In particular, to provide high quality tracks on those material, we propose efficient track classifiers to remove false positive tracks by the face tracker. Overall we achieve a dramatic improvement over the state of the art on both TV series and film datasets, and almost saturate performance on some benchmarks.","","","10.1109/TPAMI.2018.2889831","Engineering and Physical Sciences Research Council; Intelligence Advanced Research Projects Activity; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8590759","Automatic face labelling;Face tracking;Deep learning","Face;Target tracking;Labeling;TV;Visualization;Pattern analysis","","","","","","","","","","IEEE","IEEE Early Access Articles"
"IMG2DSM: Height Simulation From Single Imagery Using Conditional Generative Adversarial Net","P. Ghamisi; N. Yokoya","Earth Observation Center, SAR Signal Processing, Remote Sensing Technology Institute, Oberpfaffenhofen, Wessling, Germany; RIKEN Center for Advanced Intelligence Project, RIKEN, Tokyo, Japan","IEEE Geoscience and Remote Sensing Letters","","2018","15","5","794","798","This letter proposes a groundbreaking approach in the remote-sensing community to simulating the digital surface model (DSM) from a single optical image. This novel technique uses conditional generative adversarial networks whose architecture is based on an encoder-decoder network with skip connections (generator) and penalizing structures at the scale of image patches (discriminator). The network is trained on scenes where both the DSM and optical data are available to establish an image-to-DSM translation rule. The trained network is then utilized to simulate elevation information on target scenes where no corresponding elevation information exists. The capability of the approach is evaluated both visually (in terms of photographic interpretation) and quantitatively (in terms of reconstruction errors and classification accuracies) on subdecimeter spatial resolution data sets captured over Vaihingen, Potsdam, and Stockholm. The results confirm the promising performance of the proposed framework.","","","10.1109/LGRS.2018.2806945","Kayamori Foundation of Information Science Advancement and Japan Society for the Promotion of Science KAKENHI; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8306501","Conditional generative adversarial networks (cGANs);convolutional neural network (CNN);deep learning;digital surface model (DSM);encoder–decoder networks;optical images","Generators;Optical imaging;Optical sensors;Remote sensing;Gallium nitride;Training;Adaptive optics","feature extraction;geophysical image processing;image classification;image reconstruction;image resolution;image texture;optical radar;remote sensing;terrain mapping","skip connections;penalizing structures;image patches;optical data;image-to-DSM translation rule;trained network;target scenes;corresponding elevation information;subdecimeter spatial resolution data sets;IMG2DSM;height simulation;single imagery;conditional generative adversarial net;groundbreaking approach;remote-sensing community;digital surface model;single optical image;conditional generative adversarial networks;encoder-decoder network;Vaihingen;Potsdam;Stockholm","","8","6","","","","","IEEE","IEEE Journals"
"Hubble Tarantula Treasury Project – VI. Identification of pre-main-sequence stars using machine-learning techniques","V. F. Ksoll; D. A. Gouliermis; R. S. Klessen; E. K. Grebel; E. Sabbi; J. Anderson; D. J. Lennon; M. Cignoni; G. de Marchi; L. J. Smith; M. Tosi; R. P. van der Marel","Institut für Theoretische Astrophysik, Zentrum für Astronomie der Universität Heidelberg, Albert-Ueberle-Str 2, D-69120 Heidelberg, Germany; Interdisciplinary Center for Scientific Computing, University of Heidelberg, Mathematikon, Im Neuenheimer Feld 205, D-69120 Heidelberg, Germany, v.ksoll@stud.uni-heidelberg.de; Institut für Theoretische Astrophysik, Zentrum für Astronomie der Universität Heidelberg, Albert-Ueberle-Str 2, D-69120 Heidelberg, Germany; Max Planck Institute for Astronomy, Königstuhl 17, D-69117 Heidelberg, Germany, gouliermis@uni-heidelberg.de; Institut für Theoretische Astrophysik, Zentrum für Astronomie der Universität Heidelberg, Albert-Ueberle-Str 2, D-69120 Heidelberg, Germany; Astronomisches Rechen-Institut, Zentrum für Astronomie der Universität Heidelberg, Mönchhofstr 12-14, D-69120 Heidelberg, Germany; Space Telescope Science Institute, 3700 San Martin Drive, Baltimore, MD 21218, USA; Space Telescope Science Institute, 3700 San Martin Drive, Baltimore, MD 21218, USA; ESA – European Space Astronomy Center, Apdo. de Correo 78, E-28691 Associate Villanueva de la Caada, Madrid, Spain; Department of Physics, University of Pisa, Largo Pontecorvo 3, I-56127 Pisa, Italy; European Space Research and Technology Centre, Keplerlaan 1, NL-2200 AG Noordwijk, the Netherlands; European Space Agency and Space Telescope Science Institute, 3700 San Martin Drive, Baltimore, MD 21218, USA; INAF-Osservatorio Astronomico di Bologna, Via Ranzani 1, I-40127 Bologna, Italy; Space Telescope Science Institute, 3700 San Martin Drive, Baltimore, MD 21218, USA","Monthly Notices of the Royal Astronomical Society","","2018","479","2","2389","2414","The Hubble Tarantula Treasury Project (HTTP) has provided an unprecedented photometric coverage of the entire starburst region of 30 Doradus down to the half Solar mass limit. We use the deep stellar catalogue of HTTP to identify all the pre-main-sequence (PMS) stars of the region, i.e. stars that have not started their lives on the main-sequence yet. The photometric distinction of these stars from the more evolved populations is not a trivial task due to several factors that alter their colour–magnitude diagram positions. The identification of PMS stars requires, thus, sophisticated statistical methods. We employ machine-learning classification techniques on the HTTP survey of more than 800 000 sources to identify the PMS stellar content of the observed field. Our methodology consists of (1) carefully selecting the most probable low-mass PMS stellar population of the star-forming cluster NGC 2070, (2) using this sample to train classification algorithms to build a predictive model for PMS stars, and (3) applying this model in order to identify the most probable PMS content across the entire Tarantula Nebula. We employ decision tree, random forest (RF), and support vector machine (SVM) classifiers to categorize the stars as PMS and non-PMS. The RF and SVM provided the most accurate models, predicting about 20 000 sources with a candidateship probability higher than 50 per cent, and almost 10 000 PMS candidates with a probability higher than 95 per cent. This is the richest and most accurate photometric catalogue of extragalactic PMS candidates across the extent of a whole star-forming complex.","","","10.1093/mnras/sty1317","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8433376","methods: data analysis;methods: statistical;Hertzsprung–Russell and colour–magnitude diagrams;stars: pre-main-sequence;Magellanic Clouds;galaxies: star clusters: individual: NGC2060, NGC2070","","","","","","","","","","","OUP","OUP Journals"
"Profit Maximization Mechanism and Data Management for Data Analytics Services","Y. Jiao; P. Wang; S. Feng; D. Niyato","School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore","IEEE Internet of Things Journal","","2018","5","3","2001","2014","With the advancement and emergence of new network services, such as social network, Internet of Things, and crowd-sensing, large volume of diverse data is collected, shared, and leveraged to develop analytics services. The data analytics service has become a key commodity that can be traded among various economic entities. In this paper, we address the optimal pricing mechanisms and data management for data analytics services and further discuss the perishable services in the time varying environment. We first propose a data market model and define the data utility based on the impact of data size on the performance of data analytics, e.g., prediction and verification accuracy. For perishable services, we study the perishability of data that affects the service quality and provide a quality decay function. The data analytics services are considered as digital goods and uniquely characterized by “unlimited supply” compared to conventional goods. Therefore, we apply the Bayesian profit maximization mechanism in selling data analytics services, which is truthful, rational, and computationally efficient. The optimal service price, data amount, and service update interval are obtained to maximize the profit under different customer's valuation distributions. Finally, experimental results on realworld datasets show that our data market model and pricing mechanism effectively solve the profit maximization problem and provide useful strategies for the data analytics service provider.","","","10.1109/JIOT.2018.2819706","Singapore MOE Tier 1; MOE Tier 2; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8326475","Data analytics;deep learning;digital goods auction;Internet of Things (IoT);optimal pricing;perishable service","Data analysis;Data models;Pricing;Analytical models;Big Data;Cloud computing;Internet of Things","data analysis;optimisation;pricing;profitability","data market model;perishable services;data analytics service provider;data management;profit maximization mechanism","","6","43","","","","","IEEE","IEEE Journals"
"Sequence-to-Sequence Model for Trajectory Planning of Nonprehensile Manipulation Including Contact Model","K. Kutsuzawa; S. Sakaino; T. Tsuji","Graduate School of Science and Engineering, Saitama University, Saitama, Japan; JST PRESTO and the Graduate School of Science and Engineering, Saitama University, Saitama, Japan; Graduate School of Science and Engineering, Saitama University, Saitama, Japan","IEEE Robotics and Automation Letters","","2018","3","4","3606","3613","Nonprehensile manipulation is necessary for robots to operate in humans' daily lives. As nonprehensile manipulation should satisfy both kinematics and dynamics requirements simultaneously, it is difficult to manipulate objects along given paths. Previous studies have considered the problems with sequence-to-sequence models, which are neural networks for time-series conversion. However, they did not consider nonlinear contact models, such as friction models. When we train the seq2seq models using end-to-end backpropagation, training losses vanish owing to static friction. In this letter, we realize sequence-to-sequence models for trajectory planning of nonprehensile manipulation including contact models between the robots and target objects. This letter proposes a training curriculum that commences training without contact models to bring the seq2seq models outside of the gradient-vanishing zone. This letter discusses sliding manipulation, which includes a friction model between objects and tools, such as frying pans fixed onto the robots. We validated the proposed curriculum through a simulation. In addition, we observed that the trained seq2seq models could handle parameter fluctuations that did not exist during training.","","","10.1109/LRA.2018.2854958","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8410030","Deep learning in robotics and automation;motion and path planning;nonprehensile manipulation;sequence-to-sequence model","Trajectory;Robots;Training;Friction;Decoding;Acceleration;Task analysis","backpropagation;friction;manipulator dynamics;manipulator kinematics;neurocontrollers;path planning","sequence-to-sequence model;trajectory planning;friction model;trained seq2seq models;nonlinear contact models;nonprehensile manipulation;kinematics requirements;dynamics requirements;neural networks;time-series conversion;end-to-end backpropagation;static friction;robots;target objects;sliding manipulation;parameter fluctuations","","","28","CCBY","","","","IEEE","IEEE Journals"
"Scale-Aware Fast R-CNN for Pedestrian Detection","J. Li; X. Liang; S. Shen; T. Xu; J. Feng; S. Yan","School of Optical Engineering, Beijing Institute of Technology, Beijing, China; Carnegie Mellon University, Pittsburgh, USA; Panasonic R&amp;D Center Singapore, Singapore; School of Optical Engineering, Beijing Institute of Technology, Beijing, China; Department of Electrical and Computer Engineering, National University of Singapore, Singapore; Department of Electrical and Computer Engineering, National University of Singapore, Singapore","IEEE Transactions on Multimedia","","2018","20","4","985","996","In this paper, we consider the problem of pedestrian detection in natural scenes. Intuitively, instances of pedestrians with different spatial scales may exhibit dramatically different features. Thus, large variance in instance scales, which results in undesirable large intracategory variance in features, may severely hurt the performance of modern object instance detection methods. We argue that this issue can be substantially alleviated by the divide-and-conquer philosophy. Taking pedestrian detection as an example, we illustrate how we can leverage this philosophy to develop a Scale-Aware Fast R-CNN (SAF R-CNN) framework. The model introduces multiple built-in subnetworks which detect pedestrians with scales from disjoint ranges. Outputs from all of the subnetworks are then adaptively combined to generate the final detection results that are shown to be robust to large variance in instance scales, via a gate function defined over the sizes of object proposals. Extensive evaluations on several challenging pedestrian detection datasets well demonstrate the effectiveness of the proposed SAF R-CNN. Particularly, our method achieves state-of-the-art performance on Caltech, and obtains competitive results on INRIA, ETH, and KITTI.","","","10.1109/TMM.2017.2759508","China Scholarship Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8060595","Pedestrian detection;scale-aware;deep learning","Proposals;Feature extraction;Detectors;Training;Logic gates;Skeleton;Robustness","object detection;pedestrians","SAF R-CNN;modern object instance detection methods;Scale-Aware Fast R-CNN framework;pedestrian detection datasets","","31","64","","","","","IEEE","IEEE Journals"
"Fully Convolutional Networks With Sequential Information for Robust Crop and Weed Detection in Precision Farming","P. Lottes; J. Behley; A. Milioto; C. Stachniss","Institute of Geodesy and Geoinformation, University of Bonn, Bonn, Germany; Institute of Geodesy and Geoinformation, University of Bonn, Bonn, Germany; Institute of Geodesy and Geoinformation, University of Bonn, Bonn, Germany; Institute of Geodesy and Geoinformation, University of Bonn, Bonn, Germany","IEEE Robotics and Automation Letters","","2018","3","4","2870","2877","Reducing the use of agrochemicals is an important component toward sustainable agriculture. Robots that can perform targeted weed control offer the potential to contribute to this goal, for example, through specialized weeding actions such as selective spraying or mechanical weed removal. A prerequisite of such systems is a reliable and robust plant classification system that is able to distinguish crop and weed in the field. A major challenge in this context is the fact that different fields show a large variability. Thus, classification systems have to robustly cope with substantial environmental changes with respect to weed pressure and weed types, growth stages of the crop, visual appearance, and soil conditions. In this letter, we propose a novel crop-weed classification system that relies on a fully convolutional network with an encoder-decoder structure and incorporates spatial information by considering image sequences. Exploiting the crop arrangement information that is observable from the image sequences enables our system to robustly estimate a pixel-wise labeling of the images into crop and weed, i.e., a semantic segmentation. We provide a thorough experimental evaluation, which shows that our system generalizes well to previously unseen fields under varying environmental conditions-a key capability to actually use such systems in precision framing. We provide comparisons to other state-of-the-art approaches and show that our system substantially improves the accuracy of crop-weed classification without requiring a retraining of the model.","","","10.1109/LRA.2018.2846289","EC; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8379414","Deep learning in robotics and automation;robotics in agriculture and forestry","Agriculture;Visualization;Image sequences;Robots;Robustness;Soil;Image segmentation","agricultural engineering;agrochemicals;convolution;crops;feedforward neural nets;image classification;image segmentation;image sequences","crop arrangement information;image sequences;fully convolutional network;sequential information;precision farming;sustainable agriculture;weed control;selective spraying;mechanical weed removal;weed pressure;weed types;spatial information;plant classification system;robust crop detection;robust weed detection;crop-weed classification system","","3","29","","","","","IEEE","IEEE Journals"
"An Energy-Efficient Architecture for Binary Weight Convolutional Neural Networks","Y. Wang; J. Lin; Z. Wang","School of Electronic Science and Engineering, Nanjing University, Nanjing, China; School of Electronic Science and Engineering, Nanjing University, Nanjing, China; School of Electronic Science and Engineering, Nanjing University, Nanjing, China","IEEE Transactions on Very Large Scale Integration (VLSI) Systems","","2018","26","2","280","293","Binary weight convolutional neural networks (BCNNs) can achieve near state-of-the-art classification accuracy and have far less computation complexity compared with traditional CNNs using high-precision weights. Due to their binary weights, BCNNs are well suited for vision-based Internet-of-Things systems being sensitive to power consumption. BCNNs make it possible to achieve very high throughput with moderate power dissipation. In this paper, an energy-efficient architecture for BCNNs is proposed. It fully exploits the binary weights and other hardware-friendly characteristics of BCNNs. A judicious processing schedule is proposed so that off-chip I/O access is minimized and activations are maximally reused. To significantly reduce the critical path delay, we introduce optimized compressor trees and approximate binary multipliers with two novel compensation schemes. The latter is able to save significant hardware resource, and almost no computation accuracy is compromised. Taking advantage of error resiliency of BCNNs, an innovative approximate adder is developed, which significantly reduces the silicon area and data path delay. Thorough error analysis and extensive experimental results on several data sets show that the approximate adders in the data path cause negligible accuracy loss. Moreover, algorithmic transformations for certain layers of BCNNs and a memory-efficient quantization scheme are incorporated to further reduce the energy cost and on-chip storage requirement. Finally, the proposed BCNN hardware architecture is implemented with the SMIC 130-nm technology. The postlayout results demonstrate that our design can achieve an energy efficiency over 2.0TOp/s/W when scaled to 65 nm, which is more than two times better than the prior art.","","","10.1109/TVLSI.2017.2767624","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8103902","Approximate computing;binary weight convolutional neural network (BCNN) architecture;convolutional neural network (CNN);deep learning;energy-efficient design;signal processing;VLSI architecture","Computer architecture;Hardware;Neural networks;Neurons;Adders;Quantization (signal);Convolution","adders;convolution;energy conservation;error analysis;feedforward neural nets;multiplying circuits;neural chips;trees (mathematics)","energy-efficient architecture;binary weight convolutional neural networks;high-precision weights;binary weights;approximate binary multipliers;BCNN hardware architecture;energy efficiency;classification accuracy;data path delay;processing schedule;off-chip I/O access;critical path delay;optimized compressor trees;approximate adder;error analysis;memory-efficient quantization;on-chip storage requirement;size 65.0 nm","","12","35","","","","","IEEE","IEEE Journals"
"An Attentive Neural Sequence Labeling Model for Adverse Drug Reactions Mentions Extraction","P. Ding; X. Zhou; X. Zhang; J. Wang; Z. Lei","School of Information Science and Engineering, Yunnan University, Kunming, China; School of Information Science and Engineering, Yunnan University, Kunming, China; School of Information Science and Engineering, Yunnan University, Kunming, China; School of Information Science and Engineering, Yunnan University, Kunming, China; School of Information Science and Engineering, Xiamen University, Xiamen, China","IEEE Access","","2018","6","","73305","73315","Adverse drug reactions (ADRs) are a main cause of morbidity and mortality in patients. Extracting mentions of ADRs from the health-related text has important applications in biomedical research. Existing work mainly utilizes feature-based pipeline methods or neural network models that use only word embeddings as input features. These methods either require many efforts to design task-specific features or suffer misclassification on those words, which have not been seen before. Therefore, we propose an end-to-end neural sequence labeling model that labels words in an input sequence with ADRs membership tags. In addition to word-level embeddings, we also adopt character-level embeddings and combine them via an embedding-level attention mechanism. Through such an attention mechanism, our model can dynamically determine how much information to utilize from a word- or character-level component. In addition, we use the intermediate output of the model as an auxiliary classifier and combine it with the final output of the model to improve the overall performance. We evaluate different architectures on two ADRs labeling datasets. One is an ADRs-related Twitter corpus that includes many informal vocabularies and irregular grammar, and the other is a biomedical text extracted from PubMed abstracts with many professional terms and technical descriptions. Our model achieves approximate match F1 scores of 0.844 and 0.906 for ADRs identification on the Twitter and PubMed datasets, respectively. It presents the state-of-the-art performance on both the datasets. Our system is completely end-to-end, requires no task-specific feature engineering or hand-crafted features, and thus can be generalized to a wide range of sequence labeling tasks.","","","10.1109/ACCESS.2018.2882443","National Natural Science Foundation of China; NSF of Yunnan Province; Educational Commission of Yunnan Province of China; Project of Innovative Research Team of Yunnan Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8540859","Adverse drug reactions;biomedical text;deep learning;neural network;sequence labeling;social media","Biological system modeling;Labeling;Drugs;Task analysis;Feature extraction;Neural networks;Twitter","","","","1","47","","","","","IEEE","IEEE Journals"
"A Hyperspectral Target Detection Framework With Subtraction Pixel Pair Features","J. Du; Z. Li","School of Electronic Science, National University of Defense Technology, Changsha, China; Hunan Shenfan Technology Co., Ltd., Changsha, China","IEEE Access","","2018","6","","45562","45577","In recent years, due to its strong nonlinear mapping and research capacities, the convolutional neural network (CNN) has been widely used in the field of hyperspectral image (HSI) processing. Recently, pixel pair features (PPFs) and spatial PPFs (SPPFs) for HSI classification have served as the new tools for feature extraction. In this paper, on top of PPF, improved subtraction pixel pair features (subtraction-PPFs) are applied for HSI target detection. Unlike original PPF and SPPF, the subtraction-PPF considers target classes to afford the CNN, a target detection function. Using subtraction-PPF, a sufficiently large number of samples are obtained to ensure the excellent performance of the multilayer CNN. For a testing pixel, the input of the trained CNN is the spectral difference between the central pixel and its adjacent pixels. When a test pixel belongs to the target, the output score will be close to the target label. To verify the effectiveness of the proposed method, aircrafts and vehicles are used as targets of interest, while another 27 objects are chosen as background classes (e.g., vegetation and runways). Our experimental results on four images indicate that the proposed detector outperforms classic hyperspectral target detection algorithms.","","","10.1109/ACCESS.2018.2865963","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8438875","Target detection;hyperspectral imagery;deep learning;convolutional neural network;subtraction pixel pair features","Feature extraction;Object detection;Hyperspectral imaging;Training;Detectors;Signal processing algorithms","feature extraction;feedforward neural nets;geophysical image processing;hyperspectral imaging;image classification;image representation;image sensors;object detection","hyperspectral target detection framework;convolutional neural network;hyperspectral image processing;HSI classification;feature extraction;subtraction-PPF;HSI target detection;target classes;target detection function;multilayer CNN;testing pixel;trained CNN;central pixel;adjacent pixels;test pixel;target label;classic hyperspectral target detection algorithms;nonlinear mapping;subtraction pixel pair features","","1","30","","","","","IEEE","IEEE Journals"
"A Recurrent Neural Network Solution for Predicting Driver Intention at Unsignalized Intersections","A. Zyner; S. Worrall; E. Nebot","Australian Centre for Field Robotics, University of Sydney, Sydney, NSW, Australia; Australian Centre for Field Robotics, University of Sydney, Sydney, NSW, Australia; Australian Centre for Field Robotics, University of Sydney, Sydney, NSW, Australia","IEEE Robotics and Automation Letters","","2018","3","3","1759","1764","In this letter, we present a system capable of inferring intent from observed vehicles traversing an unsignalized intersection, a task critical for the safe driving of autonomous vehicles, and beneficial for advanced driver assistance systems. We present a prediction method based on recurrent neural networks that takes data from a Lidar-based tracking system similar to those expected in future smart vehicles. The model is validated on a roundabout, a popular style of unsignalized intersection in urban areas. We also present a very large naturalistic dataset recorded in a typical intersection during two days of operation. This comprehensive dataset is used to demonstrate the performance of the algorithm introduced in this letter. The system produces excellent results, giving a significant 1.3-s prediction window before any potential conflict occurs.","","","10.1109/LRA.2018.2805314","Australian Research Council Discovery; Next Generation Vehicle; University of Michigan and Ford Motor Company; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8290702","Intelligent transportation systems;deep learning in robotics and automation","Roads;Automobiles;Laser radar;Sensors;Recurrent neural networks;Task analysis","driver information systems;optical radar;recurrent neural nets;road safety;road traffic;road vehicles","unsignalized intersection;recurrent neural network solution;predicting driver intention;autonomous vehicles;recurrent neural networks;driver assistance systems;observed vehicles traversing;lidar-based tracking system;naturalistic dataset;smart vehicles;urban areas","","11","23","","","","","IEEE","IEEE Journals"
"Real-Time 3-D Shape Instantiation From Single Fluoroscopy Projection for Fenestrated Stent Graft Deployment","X. Zhou; J. Lin; C. Riga; G. Yang; S. Lee","Hamlyn Centre for Robotic Surgery, Imperial College London, London, U.K.; Hamlyn Centre for Robotic Surgery, Imperial College London, London, U.K.; Regional Vascular Unit, St Mary's Hospital, London, U.K.; Hamlyn Centre for Robotic Surgery, Imperial College London, London, U.K.; Hamlyn Centre for Robotic Surgery, Imperial College London, London, U.K.","IEEE Robotics and Automation Letters","","2018","3","2","1314","1321","Robot-assisted deployment of fenestrated stent grafts in fenestrated endovascular aortic repair (FEVAR) requires accurate geometrical alignment. Currently, this process is guided by two-dimensional (2-D) fluoroscopy, which is insufficiently informative and error prone. In this letter, a real-time framework is proposed to instantiate the 3-D shape of a fenestrated stent graft by utilizing only a single low-dose 2-D fluoroscopic image. First, markers were placed on the fenestrated stent graft. Second, the 3-D pose of each stent segment was instantiated by the robust perspective-n-point method. Third, the 3-D shape of the whole stent graft was instantiated via graft gap interpolation. Focal UNet was proposed to segment the markers from 2-D fluoroscopic images to achieve semiautomatic marker detection. The proposed framework was validated on five patient-specific 3-D printed aortic aneurysm phantoms and three stent grafts with new marker placements, showing an average distance error of 1-3 mm and an average angular error of 4°. Shape instantiation codes are available online.","","","10.1109/LRA.2018.2798286","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8269290","Deep learning in robotics and automation;computer vision for medical robotics;surgical robotics: planning;visual-based navigation;motion and path planning","Three-dimensional displays;Shape;Two dimensional displays;Image segmentation;Robots;Aneurysm;Navigation","blood vessels;cardiovascular system;diagnostic radiography;image segmentation;medical image processing;phantoms;stents","single fluoroscopy projection;fenestrated stent graft deployment;fenestrated endovascular aortic repair;stent segment;graft gap interpolation;shape instantiation codes;real-time 3D shape instantiation;2D fluoroscopic image;3D printed aortic aneurysm phantoms;robot-assisted deployment;perspective-n-point method;semiautomatic marker detection","","4","16","CCBY","","","","IEEE","IEEE Journals"
"Generative Adversarial Networks for Hyperspectral Image Classification","L. Zhu; Y. Chen; P. Ghamisi; J. A. Benediktsson","School of Electronics and Information Engineering, Harbin Institute of Technology, Harbin, China; School of Electronics and Information Engineering, Harbin Institute of Technology, Harbin, China; German Aerospace Center (DLR), Remote Sensing Technology Institute (IMF), Wessling, Germany; Faculty of Electrical and Computer Engineering, University of Iceland, Reykjavik, Iceland","IEEE Transactions on Geoscience and Remote Sensing","","2018","56","9","5046","5063","A generative adversarial network (GAN) usually contains a generative network and a discriminative network in competition with each other. The GAN has shown its capability in a variety of applications. In this paper, the usefulness and effectiveness of GAN for classification of hyperspectral images (HSIs) are explored for the first time. In the proposed GAN, a convolutional neural network (CNN) is designed to discriminate the inputs and another CNN is used to generate so-called fake inputs. The aforementioned CNNs are trained together: the generative CNN tries to generate fake inputs that are as real as possible, and the discriminative CNN tries to classify the real and fake inputs. This kind of adversarial training improves the generalization capability of the discriminative CNN, which is really important when the training samples are limited. Specifically, we propose two schemes: 1) a well-designed 1D-GAN as a spectral classifier and 2) a robust 3D-GAN as a spectral-spatial classifier. Furthermore, the generated adversarial samples are used with real training samples to fine-tune the discriminative CNN, which improves the final classification performance. The proposed classifiers are carried out on three widely used hyperspectral data sets: Salinas, Indiana Pines, and Kennedy Space Center. The obtained results reveal that the proposed models provide competitive results compared to the state-of-the-art methods. In addition, the proposed GANs open new opportunities in the remote sensing community for the challenging task of HSI classification and also reveal the huge potential of GAN-based methods for the analysis of such complex and inherently nonlinear data.","","","10.1109/TGRS.2018.2805286","National Natural Science Foundation of China; National Natural Science Foundation of Key International Cooperation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8307247","Convolutional neural network (CNN);deep learning;generative adversarial network (GAN);hyperspectral image (HSI) classification","Gallium nitride;Training;Hyperspectral imaging;Feature extraction;Generators","convolution;feedforward neural nets;gallium compounds;hyperspectral imaging;image classification;remote sensing","generative adversarial network;hyperspectral image classification;generative network;discriminative network;hyperspectral images;convolutional neural network;generative CNN;discriminative CNN;adversarial training;1D-GAN;3D-GAN;spectral-spatial classifier;generated adversarial samples;GAN-based methods;classification performance;remote sensing community;HSI classification","","21","52","","","","","IEEE","IEEE Journals"
"Classification of Mixed-Type Defect Patterns in Wafer Bin Maps Using Convolutional Neural Networks","K. Kyeong; H. Kim","Department of Industrial and Systems Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Department of Industrial and Systems Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea","IEEE Transactions on Semiconductor Manufacturing","","2018","31","3","395","402","In semiconductor manufacturing, a wafer bin map (WBM) represents the results of wafer testing for dies using a binary pass or fail value. For WBMs, defective dies are often clustered into groups of local systematic defects. Determining their specific patterns is important, because different patterns are related to different root causes of failure. Recently, because wafer sizes have increased and the process technology has become more complicated, the probability of observing mixed-type defect patterns, i.e., two or more defect patterns in a single wafer, has increased. In this paper, we propose the use of convolutional neural networks (CNNs) to classify mixed-type defect patterns in WBMs in the framework of an individual classification model for each defect pattern. Through simulated and real data examples, we show that the CNN is robust to random noise and performs effectively, even if there are many random defects in WBMs.","","","10.1109/TSM.2018.2841416","National Research Foundation of Korea; Ministry of Science, ICT and Future Planning; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8368296","Classification;convolutional neural network;deep learning;semiconductor manufacturing","Semiconductor device modeling;Systematics;Feature extraction;Numerical models;Convolutional neural networks;Convolution;Manufacturing","integrated circuit manufacture;integrated circuit testing;neural nets;pattern classification;semiconductor device manufacture","convolutional neural networks;wafer bin map;wafer testing;defective dies;local systematic defects;wafer sizes;mixed-type defect patterns;defect pattern;random defects","","6","14","","","","","IEEE","IEEE Journals"
"Semantic Segmentation of Aerial Images With Shuffling Convolutional Neural Networks","K. Chen; K. Fu; M. Yan; X. Gao; X. Sun; X. Wei","Key Laboratory of Technology in Geo-Spatial Information Processing and Application System, Institute of Electronics, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Technology in Geo-Spatial Information Processing and Application System, Institute of Electronics, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Technology in Geo-Spatial Information Processing and Application System, Institute of Electronics, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Technology in Geo-Spatial Information Processing and Application System, Institute of Electronics, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Technology in Geo-Spatial Information Processing and Application System, Institute of Electronics, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Technology in Geo-Spatial Information Processing and Application System, Institute of Electronics, Chinese Academy of Sciences, Beijing, China","IEEE Geoscience and Remote Sensing Letters","","2018","15","2","173","177","Semantic segmentation of aerial images refers to assigning one land cover category to each pixel. This is a challenging task due to the great differences in the appearances of ground objects. Many attempts have been made during the past decades. In recent years, convolutional neural networks (CNNs) have been introduced in the remote sensing field, and various solutions have been proposed to realize dense semantic labeling with CNNs. In this letter, we propose shuffling CNNs to realize semantic segmentation of aerial images in a periodic shuffling manner. This approach is a supplement to current methods for semantic segmentation of aerial images. We propose a naive version and a deeper version of this method, and both are adept at detecting small objects. Additionally, we propose a method called field-of-view (FoV) enhancement that can enhance the predictions. This method can be applied to various networks, and our experiments verify its effectiveness. The final results are further improved through an ensemble method that averages the score maps generated by the models at different checkpoints of the same network. We evaluate our models using the ISPRS Vaihingen and Potsdam data sets, and we acquire promising results using these two data sets.","","","10.1109/LGRS.2017.2778181","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8246726","Aerial images;convolutional neural networks (CNNs);deep learning;remote sensing;semantic segmentation","Semantics;Image segmentation;Training;Remote sensing;Labeling;Data models","convolution;feedforward neural nets;geophysical image processing;image segmentation;land cover;remote sensing;terrain mapping","semantic segmentation;aerial images;shuffling convolutional neural networks;land cover category;CNNs;dense semantic labeling;periodic shuffling manner;objects detection","","6","18","","","","","IEEE","IEEE Journals"
"Improving Indoor Localization Using Convolutional Neural Networks on Computationally Restricted Devices","K. Bregar; M. Mohorčič","Department of Communication Systems, Jožef Stefan Institute, Ljubljana, Slovenia; Department of Communication Systems, Jožef Stefan Institute, Ljubljana, Slovenia","IEEE Access","","2018","6","","17429","17441","Indoor localization is one of the key enablers for various application and service areas that rely on precise locations of people, goods, and assets, ranging from home automation and assisted living to increased automation of production and logistic processes and wireless network optimization. Existing solutions provide various levels of precision, which also depends on the complexity of the indoor radio environment. In this paper, we propose two methods for reducing the localization error in indoor non-line-of-sight (NLoS) conditions using raw channel impulse response (CIR) information obtained from ultra-wide band radios requiring no prior knowledge about the radio environment. The methods are based on NLoS channel classification and ranging error regression models, both using convolutional neural networks (CNNs) and implemented in the TensorFlow computational framework. We first show that NLoS channel classification using raw CIR data outperforms existing approaches that are based on derived input signal features. We further demonstrate that the predicted NLoS channel state and predicted ranging error information, used in combination with least squares (LS) and weighted LS location estimation algorithms, significantly improve indoor localization performance. We also evaluate the computational performance and suitability of the proposed CNN-based algorithms on various computing platforms with a wide range of different capabilities and show that in a distributed localization system, they can also be used on computationally restricted devices.","","","10.1109/ACCESS.2018.2817800","Slovenian Research Agency Through the Young Researcher Scheme; European Community through the H2020 eWINE Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8320781","Channel impulse response;convolutional neural network;deep learning;indoor localization;non-line-of-sight;ranging error mitigation;ultra-wide band","Distance measurement;Convolutional neural networks;Heuristic algorithms;Performance evaluation;Computational modeling;Estimation;Prediction algorithms","feedforward neural nets;indoor navigation;indoor radio;least squares approximations;mobile radio;radionavigation;regression analysis;transient response","convolutional neural networks;home automation;logistic processes;wireless network optimization;indoor radio environment;nonline-of-sight conditions;raw channel impulse response information;ultra-wide band radios;NLoS channel classification;ranging error regression models;TensorFlow computational framework;raw CIR data;predicted NLoS channel state;indoor localization performance;distributed localization system;weighted LS location estimation algorithms;least squares;CNN","","12","20","","","","","IEEE","IEEE Journals"
"Video Super-Resolution via Bidirectional Recurrent Convolutional Networks","Y. Huang; W. Wang; L. Wang","Center for Research on Intelligent Perception and Computing (CRIPAC), National Laboratory of Pattern Recognition (NLPR), Institute of Automation, Chinese Academy of Sciences (CASIA), University of Chinese Academy of Sciences (UCAS), Huairou, Beijing, China; Center for Research on Intelligent Perception and Computing (CRIPAC), National Laboratory of Pattern Recognition (NLPR), Institute of Automation, Chinese Academy of Sciences (CASIA), University of Chinese Academy of Sciences (UCAS), Huairou, Beijing, China; Center for Research on Intelligent Perception and Computing (CRIPAC), National Laboratory of Pattern Recognition (NLPR), Institute of Automation, Chinese Academy of Sciences (CASIA), University of Chinese Academy of Sciences (UCAS), Huairou, Beijing, China","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","4","1015","1028","Super resolving a low-resolution video, namely video super-resolution (SR), is usually handled by either single-image SR or multi-frame SR. Single-Image SR deals with each video frame independently, and ignores intrinsic temporal dependency of video frames which actually plays a very important role in video SR. Multi-Frame SR generally extracts motion information, e.g., optical flow, to model the temporal dependency, but often shows high computational cost. Considering that recurrent neural networks (RNNs) can model long-term temporal dependency of video sequences well, we propose a fully convolutional RNN named bidirectional recurrent convolutional network for efficient multi-frame SR. Different from vanilla RNNs, 1) the commonly-used full feedforward and recurrent connections are replaced with weight-sharing convolutional connections. So they can greatly reduce the large number of network parameters and well model the temporal dependency in a finer level, i.e., patch-based rather than frame-based, and 2) connections from input layers at previous timesteps to the current hidden layer are added by 3D feedforward convolutions, which aim to capture discriminate spatio-temporal patterns for short-term fast-varying motions in local adjacent frames. Due to the cheap convolutional operations, our model has a low computational complexity and runs orders of magnitude faster than other multi-frame SR methods. With the powerful temporal dependency modeling, our model can super resolve videos with complex motions and achieve well performance.","","","10.1109/TPAMI.2017.2701380","National Key Research and Development Program of China; National Natural Science Foundation of China; Strategic Priority Research Program of the CAS; Beijing Natural Science Foundation; NVIDIA; NVIDIA DGX-1 AI Supercomputer; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7919264","Deep learning;recurrent neural networks;3D convolution;video super-resolution","Solid modeling;Three-dimensional displays;Feedforward neural networks;Computational modeling;Motion estimation;Recurrent neural networks;Visualization","computational complexity;image resolution;image sequences;recurrent neural nets;video signal processing","video super-resolution;bidirectional recurrent convolutional network;low-resolution video;video frame;intrinsic temporal dependency;video SR;recurrent neural networks;model long-term temporal dependency;video sequences;fully convolutional RNN;efficient multiframe SR;recurrent connections;weight-sharing convolutional connections;network parameters;spatio-temporal patterns;local adjacent frames;cheap convolutional operations;multiframe SR methods;powerful temporal dependency modeling;super resolve videos;Single-Image SR","","7","53","","","","","IEEE","IEEE Journals"
"Building Footprint Extraction From VHR Remote Sensing Images Combined With Normalized DSMs Using Fused Fully Convolutional Networks","K. Bittner; F. Adam; S. Cui; M. Körner; P. Reinartz","Earth Observation Center, German Aerospace Center (DLR), Oberpfaffenhofen, Germany; Earth Observation Center, German Aerospace Center (DLR), Oberpfaffenhofen, Germany; Earth Observation Center, German Aerospace Center (DLR), Oberpfaffenhofen, Germany; Department of Civil, Geo and Environmental Engineering, Technical University of Munich, München, Germany; Earth Observation Center, German Aerospace Center (DLR), Oberpfaffenhofen, Germany","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2018","11","8","2615","2629","Automatic building extraction and delineation from high-resolution satellite imagery is an important but very challenging task, due to the extremely large diversity of building appearances. Nowadays, it is possible to use multiple high-resolution remote sensing data sources, which allow the integration of different information in order to improve the extraction accuracy of building outlines. Many algorithms are built on spectral-based or appearance-based criteria, from single or fused data sources, to perform the building footprint extraction. But the features for these algorithms are usually manually extracted, which limits their accuracy. Recently developed fully convolutional networks (FCNs), which are similar to normal convolutional neural networks (CNN), but the last fully connected layer is replaced by another convolution layer with a large “receptive field,” quickly became the state-of-the-art method for image recognition tasks, as they bring the possibility to perform dense pixelwise classification of input images. Based on these advantages, i.e., the automatic extraction of relevant features, and dense classification of images, we propose an end-to-end FCN, which effectively combines the spectral and height information from different data sources and automatically generates a full resolution binary building mask. Our architecture (Fused-FCN4s) consists of three parallel networks merged at a late stage, which helps propagating fine detailed information from earlier layers to higher levels, in order to produce an output with more accurate building outlines. The inputs to the proposed Fused-FCN4s are three-band (RGB) , panchromatic (PAN), and normalized digital surface model (nDSM) images. Experimental results demonstrate that the fusion of several networks is able to achieve excellent results on complex data. Moreover, the developed model was successfully applied to different cities to show its generalization capacity.","","","10.1109/JSTARS.2018.2849363","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8447548","Binary classification;building footprint;data fusion;deep learning;fully convolutional networks (FCNs);satellite images","Buildings;Feature extraction;Remote sensing;Task analysis;Data mining;Shape;Satellites","buildings (structures);feature extraction;geophysical image processing;image classification;neural nets;remote sensing","three-band image;panchromatic image;fused fully convolutional networks;normalized digital surface model;VHR remote sensing images;normalized digital surface model images;height information;automatic extraction;dense pixelwise classification;image recognition tasks;normal convolutional neural networks;single fused data sources;extraction accuracy;multiple high-resolution remote sensing data sources;high-resolution satellite imagery;building footprint extraction","","3","71","","","","","IEEE","IEEE Journals"
"Clustering Millions of Faces by Identity","C. Otto; D. Wang; A. K. Jain","Computer Science & Engineering, Michigan State University, East Lansing, MI; Computer Science & Engineering, Michigan State University, East Lansing, MI; Computer Science & Engineering, Michigan State University, East Lansing, MI","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","2","289","303","Given a large collection of unlabeled face images, we address the problem of clustering faces into an unknown number of identities. This problem is of interest in social media, law enforcement, and other applications, where the number of faces can be of the order of hundreds of million, while the number of identities (clusters) can range from a few thousand to millions. To address the challenges of run-time complexity and cluster quality, we present an approximate Rank-Order clustering algorithm that performs better than popular clustering algorithms (k-Means and Spectral). Our experiments include clustering up to 123 million face images into over 10 million clusters. Clustering results are analyzed in terms of external (known face labels) and internal (unknown face labels) quality measures, and run-time. Our algorithm achieves an F-measure of 0.87 on the LFW benchmark (13 K faces of 5,749 individuals), which drops to 0.27 on the largest dataset considered (13 K faces in LFW + 123M distractor images). Additionally, we show that frames in the YouTube benchmark can be clustered with an F-measure of 0.71. An internal per-cluster quality measure is developed to rank individual clusters for manual exploration of high quality clusters that are compact and isolated.","","","10.1109/TPAMI.2017.2679100","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7873333","Face recognition;face clustering;deep learning;scalability;cluster validity","Clustering algorithms;Approximation algorithms;Social network services;Videos;Face recognition;Scalability;Clustering methods","face recognition;image matching;pattern clustering","face images;approximate rank-order clustering algorithm;LFW benchmark;internal per-cluster quality measure;face identity;F-measure;internal quality measures;run-time complexity;law enforcement;social media","","8","33","","","","","IEEE","IEEE Journals"
"Speech Dereverberation With Context-Aware Recurrent Neural Networks","J. F. Santos; T. H. Falk","Énergie, Matériaux, Télécommunications Research Centre, Institut National de la Recherche Scientifique, Montréal, QC, Canada; Énergie, Matériaux, Télécommunications Research Centre, Institut National de la Recherche Scientifique, Montréal, QC, Canada","IEEE/ACM Transactions on Audio, Speech, and Language Processing","","2018","26","7","1236","1246","In this paper, we propose a model to perform speech dereverberation by estimating its spectral magnitude from the reverberant counterpart. Our models are capable of extracting features that take into account both short- and long-term dependencies in the signal through a convolutional encoder (which extracts features from a short, bounded context of frames) and a recurrent neural network for extracting long-term information. Our model outperforms a recently proposed model that uses different context information depending on the reverberation time, without requiring any sort of additional input, yielding improvements of up to 0.4 on perceptual evaluation of speech quality, 0.3 on short-time objective intelligibility, and 1.0 on perceptual objective listening quality assessment relative to reverberant speech. We also show our model is able to generalize to real room impulse responses even when only trained with simulated room impulse responses, different speakers, and high reverberation times. Finally, listening tests show the proposed method outperforming benchmark models in reduction of perceived reverberation.","","","10.1109/TASLP.2018.2821899","Natural Sciences and Engineering Research Council of Canada; Fonds Québécois de la Recherche sur la Nature et les Technologies; Google; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8329129","Dereverberation;speech enhancement;deep learning;recurrent neural networks;reverberation","Speech;Context modeling;Speech enhancement;Reverberation;Time-frequency analysis;Feature extraction;Convolution","architectural acoustics;convolutional codes;feature extraction;recurrent neural nets;reverberation;speech coding;speech intelligibility","perceived reverberation;speech dereverberation;context-aware recurrent neural networks;spectral magnitude;reverberant counterpart;long-term dependencies;convolutional encoder;recurrent neural network;long-term information;reverberation time;perceptual evaluation;speech quality;short-time objective intelligibility;perceptual objective listening quality assessment;reverberant speech;simulated room impulse responses;high reverberation times;context information","","2","41","","","","","IEEE","IEEE Journals"
"Speech-to-Text for Broadcasters, From Research to Implementation","M. Haynes; A. Norton; A. McParland; R. Cooper","NA; NA; NA; NA","SMPTE Motion Imaging Journal","","2018","127","2","27","33","Speech to text has recently moved from the laboratory to the newsroom as a tool for broadcasters and journalists. Breakthroughs in automatic analysis and improvements in affordability mean that running it at a scale of over hundreds of thousands of hours of content is now feasible. Increases in accuracy mean that users will have a realistic chance of finding what they want in minutes rather than hours, especially in genres such as news or factual content. In this paper, we detail the work the British Broadcasting Corp. (BBC) Research and Development (R & D) have done in this area, and in particular how we built a speech-to-text system using open-source tools, broadcast audio, and subtitles. We detail its accuracy across a range of genres and how it performs on real-life broadcasting problems such as cross-talk, music beds, and laughter. We also explain how an in-house innovation team called BBC News Labs took our work and turned it into digital systems that journalists and program makers can use.","","","10.5594/JMI.2018.2790658","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8304854","Automatic transcription;broadcast;deep neural networks;machine learning;open source;speech recognition;subtitling","","","","","","12","","","","","SMPTE","SMPTE Journals"
"Chinese Language Processing Based on Stroke Representation and Multidimensional Representation","H. Zhuang; C. Wang; C. Li; Y. Li; Q. Wang; X. Zhou","Department of Computer Science, University of Science and Technology of China, Hefei, China; Department of Computer Science, University of Science and Technology of China, Hefei, China; Department of Computer Science, University of Science and Technology of China, Hefei, China; Suzhou Industry Park Kuatang Experimental Primary School, Suzhou, China; Department of Software Engineering, University of Science and Technology of China, Hefei, China; Department of Computer Science, University of Science and Technology of China, Hefei, China","IEEE Access","","2018","6","","41928","41941","With the development of deep learning and artificial intelligence, deep neural networks are increasingly being applied for natural language processing tasks. However, the majority of research on natural language processing focuses on alphabetic languages. Few studies have paid attention to the characteristics of ideographic languages, such as the Chinese language. In addition, the existing Chinese processing algorithms typically regard Chinese words or Chinese characters as the basic units while ignoring the information contained within the deeper architecture of Chinese characters. In the Chinese language, each Chinese character can be split into several components, or strokes. This means that strokes are the basic units of a Chinese character, in a manner similar to the letters of an English word. Inspired by the success of character-level neural networks, we delve deeper into Chinese writing at the stroke level for Chinese language processing. We extract the basic features of strokes by considering similar Chinese characters to learn a continuous representation of Chinese characters. Furthermore, word embeddings trained at different granularities are not exactly the same. In this paper, we propose an algorithm for combining different representations of Chinese words within a single neural network to obtain a better word representation. We develop a Chinese word representation service for several natural language processing tasks, and cloud computing is introduced to deal with preprocessing challenges and the training of basic representations from different dimensions.","","","10.1109/ACCESS.2018.2860058","National Natural Science Foundation of China; Natural Science Foundation of Anhui Province; Suzhou Research Foundation; Youth Innovation Promotion Association of CAS; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8421226","Chinese word representation;stroke-based word representation;multidimensional word representation;convolutional neural networks;natural language processing;word similarity;text classification;automatic text summarization","Dictionaries;Natural language processing;Electronic mail;Computer science;Neural networks;Task analysis;Thesauri","learning (artificial intelligence);natural language processing;neural nets","Chinese language processing;similar Chinese characters;Chinese character;Chinese words;Chinese word representation service;natural language processing tasks;alphabetic languages;ideographic languages;existing Chinese processing algorithms;character-level neural networks;Chinese writing","","1","44","","","","","IEEE","IEEE Journals"
"A Benchmark Dataset and Saliency-Guided Stacked Autoencoders for Video-Based Salient Object Detection","J. Li; C. Xia; X. Chen","State Key Laboratory of Virtual Reality Technology and Systems, School of Computer Science and Engineering, Beihang University, Beijing, China; State Key Laboratory of Virtual Reality Technology and Systems, School of Computer Science and Engineering, Beihang University, Beijing, China; State Key Laboratory of Virtual Reality Technology and Systems, School of Computer Science and Engineering, Beihang University, Beijing, China","IEEE Transactions on Image Processing","","2018","27","1","349","364","Image-based salient object detection (SOD) has been extensively studied in past decades. However, video-based SOD is much less explored due to the lack of large-scale video datasets within which salient objects are unambiguously defined and annotated. Toward this end, this paper proposes a video-based SOD dataset that consists of 200 videos. In constructing the dataset, we manually annotate all objects and regions over 7650 uniformly sampled keyframes and collect the eye-tracking data of 23 subjects who free-view all videos. From the user data, we find that salient objects in a video can be defined as objects that consistently pop-out throughout the video, and objects with such attributes can be unambiguously annotated by combining manually annotated object/region masks with eye-tracking data of multiple subjects. To the best of our knowledge, it is currently the largest dataset for video-based salient object detection. Based on this dataset, this paper proposes an unsupervised baseline approach for video-based SOD by using saliency-guided stacked autoencoders. In the proposed approach, multiple spatiotemporal saliency cues are first extracted at the pixel, superpixel, and object levels. With these saliency cues, stacked autoencoders are constructed in an unsupervised manner that automatically infers a saliency score for each pixel by progressively encoding the high-dimensional saliency cues gathered from the pixel and its spatiotemporal neighbors. In experiments, the proposed unsupervised approach is compared with 31 state-of-the-art models on the proposed dataset and outperforms 30 of them, including 19 image-based classic (unsupervised or non-deep learning) models, six image-based deep learning models, and five video-based unsupervised models. Moreover, benchmarking results show that the proposed dataset is very challenging and has the potential to boost the development of video-based SOD.","","","10.1109/TIP.2017.2762594","National Natural Science Foundation of China; Beijing Nova Program; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8066351","Salient object detection;video dataset;stacked autoencoders;model benchmarking","Benchmark testing;Solid modeling;Object detection;Spatiotemporal phenomena;Motion segmentation;Animals","learning (artificial intelligence);object detection;video coding","benchmark dataset;stacked autoencoders;salient object detection image;large-scale video datasets;SOD dataset;eye-tracking data;manually annotated object/region masks;multiple spatiotemporal saliency cues;saliency score;high-dimensional saliency cues;uniformly sampled keyframes","","13","75","","","","","IEEE","IEEE Journals"
"XNOR Neural Engine: A Hardware Accelerator IP for 21.6-fJ/op Binary Neural Network Inference","F. Conti; P. D. Schiavone; L. Benini","Integrated Systems Laboratory, D-ITET, ETH Zürich, Zürich, Switzerland; Integrated Systems Laboratory, D-ITET, ETH Zürich, Zürich, Switzerland; Integrated Systems Laboratory, D-ITET, ETH Zürich, Zürich, Switzerland","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","","2018","37","11","2940","2951","Binary neural networks (BNNs) are promising to deliver accuracy comparable to conventional deep neural networks at a fraction of the cost in terms of memory and energy. In this paper, we introduce the XNOR neural engine (XNE), a fully digital configurable hardware accelerator IP for BNNs, integrated within a microcontroller unit (MCU) equipped with an autonomous I/O subsystem and hybrid SRAM/standard cell memory. The XNE is able to fully compute convolutional and dense layers in autonomy or in cooperation with the core in the MCU to realize more complex behaviors. We show post-synthesis results in 65- and 22-nm technology for the XNE IP and post-layout results in 22 nm for the full MCU indicating that this system can drop the energy cost per binary operation to 21.6 fJ per operation at 0.4 V, and at the same time is flexible and performant enough to execute state-of-the-art BNN topologies such as ResNet-34 in less than 2.2 mJ per frame at 8.9 frames/s.","","","10.1109/TCAD.2018.2857019","Samsung; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8412533","Binary neural networks (BNNs);hardware accelerator;microcontroller system","Neural networks;Hardware;Convolutional codes;Engines;IP networks;Microcontrollers;Machine learning","integrated circuit layout;logic design;low-power electronics;microcontrollers;neural nets;SRAM chips","MCU;hybrid SRAM/standard cell memory;post-synthesis results;XNE IP;post-layout results;energy cost;binary operation;XNOR neural engine;BNNs;conventional deep neural networks;fully digital configurable hardware accelerator IP;binary neural network inference;microcontroller unit;size 22.0 nm;voltage 0.4 V;size 65 nm","","4","43","","","","","IEEE","IEEE Journals"
"LSTM-Based EEG Classification in Motor Imagery Tasks","P. Wang; A. Jiang; X. Liu; J. Shang; L. Zhang","College of Internet of Things Engineering, Hohai University, Changzhou Campus, Changzhou, China; College of Internet of Things Engineering, Hohai University, Changzhou Campus, Changzhou, China; Jiangsu Key Laboratory of Special Robots, Hohai University, Changzhou Campus, Changzhou, China; College of Internet of Things Engineering, Hohai University, Changzhou Campus, Changzhou, China; Department of Mathematics and Physics, Hohai University, Changzhou Campus, Changzhou, China","IEEE Transactions on Neural Systems and Rehabilitation Engineering","","2018","26","11","2086","2095","Classification of motor imagery electroencephalograph signals is a fundamental problem in brain-computer interface (BCI) systems. We propose in this paper a classification framework based on long short-term memory (LSTM) networks. To achieve robust classification, a one dimension-aggregate approximation (1d-AX) is employed to extract effective signal representation for LSTM networks. Inspired by classical common spatial pattern, channel weighting technique is further deployed to enhance the effectiveness of the proposed classification framework. Public BCI competition data are used for the evaluation of the proposed feature extraction and classification network, whose performance is also compared with that of the state-of-the-arts approaches based on other deep networks.","","","10.1109/TNSRE.2018.2876129","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; Key Development Program of Jiangsu Province of China; Projects of International Cooperation and Exchanges of Changzhou of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8496885","Electroencephalograph (EEG);long short-term memory (LSTM);motor imagery;one dimension-aggregate approximation (1d-AX)","Feature extraction;Electroencephalography;Task analysis;Data mining;Machine learning;Neural networks;Support vector machines","approximation theory;brain-computer interfaces;electroencephalography;feature extraction;medical signal processing;neurophysiology;recurrent neural nets;signal classification;signal representation","motor imagery electroencephalograph signals;brain-computer interface systems;classification framework;short-term memory networks;1d-AX;LSTM networks;channel weighting technique;public BCI competition data;deep networks;signal representation;common spatial pattern;one dimension-aggregate approximation;LSTM-based EEG classification;feature extraction","","5","41","","","","","IEEE","IEEE Journals"
"Gastroenterology Ontology Construction Using Synonym Identification and Relation Extraction","Y. Shen; Y. Li; Y. Deng; J. Zhang; M. Yang; J. Chen; S. Si; K. Lei","Shenzhen Key Lab for Information Centric Networking & Blockchain Technology, School of Electronics and Computer Engineering, Peking University, Shenzhen, China; Tencent Medical AI Lab, Palo Alto, CA, USA; Shenzhen Key Lab for Information Centric Networking & Blockchain Technology, School of Electronics and Computer Engineering, Peking University, Shenzhen, China; Shenzhen Key Lab for Information Centric Networking & Blockchain Technology, School of Electronics and Computer Engineering, Peking University, Shenzhen, China; Chinese Academy of Sciences, SIAT, Beijing, China; Shenzhen Maternal and Child Healthcare Hospital, Shenzhen, China; Shenzhen Key Lab for Information Centric Networking & Blockchain Technology, School of Electronics and Computer Engineering, Peking University, Shenzhen, China; Shenzhen Key Lab for Information Centric Networking & Blockchain Technology, School of Electronics and Computer Engineering, Peking University, Shenzhen, China","IEEE Access","","2018","6","","52095","52104","Ontology plays an increasingly important role in knowledge management and the semantic Web. However, ontology cannot perform well in realistic diagnosis reasoning unless it contains timely and accurate medical information and its individual items display all attributes of the categories they belong to. In this paper, we present a method that extracts synonyms along with concepts and their relationships for gastroenterology ontology construction. Specifically, we reuse the existing ontology as the basis for ontology completion. In addition, we conduct synonym identification through a combined application of global context features, local context features, and medical-specific features, and incorporate dependency information into deep neural networks for relation extraction. The extracted information is merged for ontology completion. Experimental results demonstrate that the proposed synonym identification and relation extraction method achieves the best performance compared with state-of-the-art methods and also builds a more complete ontology compared with existing gastroenterology disease ontologies. Our results are reproducible, and we will release the source code and ontology of this work after publication: https://github.com/shenyingpku/gastrointestinal_owl.","","","10.1109/ACCESS.2018.2862885","National Natural Science Foundation of China; Shenzhen Key Fundamental Research Projects; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8425033","Artificial neural networks;data acquisition;knowledge representation;machine learning;text mining","Ontologies;Feature extraction;Data mining;Semantics;Medical diagnostic imaging;Gastroenterology;Neural networks","diseases;feature extraction;information retrieval;knowledge management;medical diagnostic computing;medical information systems;neural nets;ontologies (artificial intelligence);semantic Web;text analysis;word processing","synonym identification;knowledge management;semantic Web;realistic diagnosis reasoning;medical information;global context features;local context features;medical-specific features;gastroenterology ontology construction;information extraction;relation extraction;gastroenterology disease ontologies;deep neural networks","","1","37","","","","","IEEE","IEEE Journals"
"Hierarchical Parsing Net: Semantic Scene Parsing From Global Scene to Objects","H. Shi; H. Li; F. Meng; Q. Wu; L. Xu; K. N. Ngan","School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; Department of Electronic Engineering, The Chinese University of Hong Kong, Hong Kong","IEEE Transactions on Multimedia","","2018","20","10","2670","2682","This paper proposes a novel Hierarchical Parsing Net (HPN) for semantic scene parsing. Unlike previous methods, which separately classify each object, HPN leverages global scene semantic information and the context among multiple objects to enhance scene parsing. On the one hand, HPN uses the global scene category to constrain the semantic consistency between the scene and each object. On the other hand, the context among all objects is also modeled to avoid incompatible object predictions. Specifically, HPN consists of four steps. In the first step, we extract scene and local appearance features. Based on these appearance features, the second step is to encode a contextual feature for each object, which models both the scene-object context (the context between the scene and each object) and the interobject context (the context among different objects). In the third step, we classify the global scene and then use the scene classification loss and a backpropagation algorithm to constrain the scene feature encoding. In the fourth step, a label map for scene parsing is generated from the local appearance and contextual features. Our model outperforms many state-of-the-art deep scene parsing networks on five scene parsing databases.","","","10.1109/TMM.2018.2812600","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8306891","Semantic scene parsing;scene-aware feature encoding;context learning","Context modeling;Semantics;Feature extraction;Proposals;Image segmentation;Predictive models;Computational modeling","backpropagation;feature extraction;image classification;image coding","local appearance features;contextual feature;scene-object context;scene classification loss;state-of-the-art deep scene parsing networks;scene parsing databases;semantic scene parsing;HPN leverages global scene semantic information;multiple objects;global scene category;semantic consistency;incompatible object predictions;hierarchical parsing net","","3","48","","","","","IEEE","IEEE Journals"
"An In-Memory VLSI Architecture for Convolutional Neural Networks","M. Kang; S. Lim; S. Gonugondla; N. R. Shanbhag","IBM Thomas J. Watson Research Center, Yorktown Heights, NY, USA; Coordinated Science Laboratory, University of Illinois at Urbana–Champaign, Champaign, IL, USA; Coordinated Science Laboratory, University of Illinois at Urbana–Champaign, Champaign, IL, USA; Coordinated Science Laboratory, University of Illinois at Urbana–Champaign, Champaign, IL, USA","IEEE Journal on Emerging and Selected Topics in Circuits and Systems","","2018","8","3","494","505","This paper presents an energy-efficient and high throughput architecture for convolutional neural networks (CNN). Architectural and circuit techniques are proposed to address the dominant energy and delay costs associated with data movement in CNNs. The proposed architecture employs a deep in-memory architecture, to embed energy-efficient low swing mixed-signal computations in the periphery of the SRAM bitcell array. An efficient data access pattern and a mixed-signal multiplier are proposed to exploit data reuse opportunities in convolution. Silicon-validated energy, delay, and behavioral models of the proposed architecture are developed and employed to perform large-scale system simulations. System-level simulations using these models show 97% detection accuracy on the MNIST data set, along with 4.9× and 2.4× improvements in energy efficiency and throughput, respectively, leading to 11.9× reduction in energy-delay product as compared with a conventional (SRAM + digital processor) architecture.","","","10.1109/JETCAS.2018.2829522","Semiconductor Research Corporation; Defense Advanced Research Projects Agency; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8345293","Convolutional neural networks (CNN);in-memory computing;machine learning;analog processing;accelerator","Computer architecture;Random access memory;Frequency modulation;Delays;Convolution;Standards;Convolutional neural networks","low-power electronics;memory architecture;multiplying circuits;neural nets;SRAM chips;VLSI","energy-efficient low swing mixed-signal computations;deep in-memory architecture;energy-delay product;energy efficiency;MNIST data set;system-level simulations;large-scale system simulations;data reuse opportunities;mixed-signal multiplier;efficient data access pattern;SRAM bitcell array;data movement;convolutional neural networks;In-Memory VLSI Architecture","","6","34","","","","","IEEE","IEEE Journals"
"Analysis and Simulation of Capacitor-Less ReRAM-Based Stochastic Neurons for the in-Memory Spiking Neural Network","J. Lin; J. Yuan","Department of Electrical and Computer Engineering, University of Central Florida, Orlando, FL, USA; Department of Electrical and Computer Engineering, University of Central Florida, Orlando, FL, USA","IEEE Transactions on Biomedical Circuits and Systems","","2018","12","5","1004","1017","The stochastic neuron is a key for event-based probabilistic neural networks. We propose a stochastic neuron using a metal-oxide resistive random-access memory (ReRAM). The ReRAM's conducting filament with built-in stochasticity is used to mimic the neuron's membrane capacitor, which temporally integrates input spikes. A capacitor-less neuron circuit is designed, laid out, and simulated. The output spiking train of the neuron obeys the Poisson distribution. Using the 65-nm CMOS technology node, the area of the neuron is 14 × 5 μm2, which is one ninth the size of a 1-pF capacitor. The average power consumption of the neuron is 1.289 μW. We introduce the neural array-A modified one-transistor-one-ReRAM (1T1R) crossbar that integrates the ReRAM neurons with ReRAM synapses to form a compact and energy efficient in-memory spiking neural network. A spiking deep belief network (DBN) with a noisy rectified linear unit (NReLU) is trained and mapped to the spiking DBN using the proposed ReRAM neurons. Simulation results show that the ReRAM neuron-based DBN is able to recognize the handwritten digits with 94.7% accuracy and is robust against the ReRAM process variation effect.","","","10.1109/TBCAS.2018.2843286","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8411148","Neuromorphic;resistive random-access memory (ReRAM);spiking neural network;stochastic neuron;unsupervised learning","Stochastic processes;Biological neural networks;Synapses;Power demand;Integrated circuit modeling","belief networks;CMOS memory circuits;energy conservation;integrated circuit modelling;low-power electronics;neural nets;Poisson distribution;power consumption;resistive RAM","in-memory spiking neural network;stochastic neuron;event-based probabilistic neural networks;metal-oxide resistive random-access memory;one-transistor-one-ReRAM crossbar;ReRAM neurons;ReRAM synapses;energy efficient in-memory spiking;spiking deep belief network;spiking DBN;ReRAM neuron-based DBN;ReRAM process variation effect;CMOS technology node;neural array;noisy rectified linear unit;NReLU;power consumption;power 1.289 muW;size 65 nm;capacitance 1 pF;size 14 mum;size 5 mum","Memory;Models, Neurological;Neural Networks (Computer);Poisson Distribution;Transistors, Electronic","","44","","","","","IEEE","IEEE Journals"
"Automatic Recognition of Children Engagement from Facial Video using Convolutional Neural Networks","W. Yun; D. Lee; C. Park; J. Kim; J. Kim","HMI Research Group, Electronics and Telecommunications Research Institute, 65678 Daejeon, Daejeon Korea (the Republic of) (e-mail: yochin@etri.re.kr); HMI Research Group, Electronics and Telecommunications Research Institute, 65678 Daejeon, Daejeon Korea (the Republic of) (e-mail: robin2002@etri.re.kr); HMI Research Group, Electronics and Telecommunications Research Institute, 65678 Daejeon, Daejeon Korea (the Republic of) (e-mail: parkck@etri.re.kr); HMI Research Group, Electronics and Telecommunications Research Institute, 65678 Daejeon, Daejeon Korea (the Republic of) (e-mail: jhkim504@etri.re.kr); Electrical Engineering, KAIST, Daejeon, Daejeon Korea, Republic of (e-mail: junmo.kim@kaist.ac.kr)","IEEE Transactions on Affective Computing","","2018","PP","99","1","1","Automatic engagement recognition is a technique that is used to measure the engagement level of people in a specific task. Although previous research has utilized expensive and intrusive devices such as physiological sensors and pressure-sensing chairs, methods using RGB video cameras have become the most common because of the cost efficiency and noninvasiveness of video cameras. Automatic engagement recognition methods using video cameras are usually based on hand-crafted features and a statistical temporal dynamics modeling algorithm. This paper proposes a data-driven convolutional neural networks (CNNs)-based engagement recognition method that uses only facial images from input videos. As the amount of data in a dataset of children's engagement is insufficient for deep learning, pre-trained CNNs are utilized for low-level feature extraction from each video frame. In particular, a new layer combination for temporal dynamics modeling is employed to extract high-level features from low-level features. Experimental results on a database created using images of children from kindergarten demonstrate that the performance of the proposed method is superior to that of previous methods. The results indicate that the engagement level of children can be gauged automatically via deep learning even when the available database is deficient.","","","10.1109/TAFFC.2018.2834350","Ministry of Science, ICT and Future Planning; Institute for Information and Communications Technology Promotion IITP; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8355953","Affective computing;artificial neural networks;convolutional neural networks;engagement recognition;multilayer neural networks;pattern recognition","Feature extraction;Face recognition;Cameras;Face;Heuristic algorithms;Machine learning;Databases","","","","2","","","","","","IEEE","IEEE Early Access Articles"
"Preconditioned Stochastic Gradient Descent","X. Li","Independent Researcher, San Jose, CA, USA","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","5","1454","1466","Stochastic gradient descent (SGD) still is the workhorse for many practical problems. However, it converges slow, and can be difficult to tune. It is possible to precondition SGD to accelerate its convergence remarkably. But many attempts in this direction either aim at solving specialized problems, or result in significantly more complicated methods than SGD. This paper proposes a new method to adaptively estimate a preconditioner, such that the amplitudes of perturbations of preconditioned stochastic gradient match that of the perturbations of parameters to be optimized in a way comparable to Newton method for deterministic optimization. Unlike the preconditioners based on secant equation fitting as done in deterministic quasi-Newton methods, which assume positive definite Hessian and approximate its inverse, the new preconditioner works equally well for both convex and nonconvex optimizations with exact or noisy gradients. When stochastic gradient is used, it can naturally damp the gradient noise to stabilize SGD. Efficient preconditioner estimation methods are developed, and with reasonable simplifications, they are applicable to large-scale problems. Experimental results demonstrate that equipped with the new preconditioner, without any tuning effort, preconditioned SGD can efficiently solve many challenging problems like the training of a deep neural network or a recurrent neural network requiring extremely long-term memories.","","","10.1109/TNNLS.2017.2672978","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7875097","Neural network;Newton method;nonconvex optimization;preconditioner;stochastic gradient descent (SGD)","Eigenvalues and eigenfunctions;Optimization;Neural networks;Convergence;Newton method;Training;Acceleration","concave programming;convergence of numerical methods;convex programming;gradient methods;Hessian matrices;Newton method;stochastic programming","deterministic quasi-Newton methods;SGD stability;gradient noise damping;convex stochastic optimization;preconditioned stochastic gradient match;stochastic gradient descent;preconditioned SGD;efficient preconditioner estimation methods;nonconvex optimizations;deterministic optimization","","6","27","","","","","IEEE","IEEE Journals"
"Emotion Recognition on Twitter: Comparative Study and Training a Unison Model","N. Colneriĉ; J. Demsar","Bioinformatics Laboratory, Univerza v Ljubljani Fakulteta za Racunalnistvo in Informatiko, 172648 Ljubljana, Slovenia Slovenia (e-mail: niko.colneric@fri.uni-lj.si); Bioinformatics Laboratory, Univerza v Ljubljani Fakulteta za Racunalnistvo in Informatiko, 172648 Ljubljana, Slovenia Slovenia (e-mail: janez.demsar@fri.uni-lj.si)","IEEE Transactions on Affective Computing","","2018","PP","99","1","1","Despite recent successes of deep learning in many fields of natural language processing, previous studies of emotion recognition on Twitter mainly focused on the use of lexicons and simple classifiers on bag-of-words models. The central question of our study is whether we can improve their performance using deep learning. To this end, we exploit hashtags to create three large emotion-labeled data sets corresponding to different classifications of emotions. We then compare the performance of several word- and character-based recurrent and convolutional neural networks with the performance on bag-of-words and latent semantic indexing models. We also investigate the transferability of the final hidden state representations between different classifications of emotions, and whether it is possible to build a unison model for predicting all of them using a shared representation. We show that recurrent neural networks, especially character-based ones, can improve over bag-of-words and latent semantic indexing models. Although the transfer capabilities of these models are poor, the newly proposed training heuristic produces a unison model with performance comparable to that of the three single models.","","","10.1109/TAFFC.2018.2807817","Javna Agencija za Raziskovalno Dejavnost RS; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8295234","Emotion Recognition;Text Mining;Twitter;Recurrent Neural Networks;Convolutional Neural Networks","Twitter;Tagging;Mood;Machine learning;Training;Emotion recognition;Convolutional neural networks","","","","2","","","","","","IEEE","IEEE Early Access Articles"
"Modern Trends in Hyperspectral Image Analysis: A Review","M. J. Khan; H. S. Khan; A. Yousaf; K. Khurshid; A. Abbas","Department of Electrical Engineering, Institute of Space Technology, Islamabad, Pakistan; Global Business Services, IBM Corporation, Islamabad, Pakistan; Department of Electrical Engineering, Institute of Space Technology, Islamabad, Pakistan; Department of Electrical Engineering, Institute of Space Technology, Islamabad, Pakistan; School of Electrical Engineering and Computing, The University of Newcastle, Callaghan, NSW, Australia","IEEE Access","","2018","6","","14118","14129","Over the past three decades, significant developments have been made in hyperspectral imaging due to which it has emerged as an effective tool in numerous civil, environmental, and military applications. Modern sensor technologies are capable of covering large surfaces of earth with exceptional spatial, spectral, and temporal resolutions. Due to these features, hyperspectral imaging has been effectively used in numerous remote sensing applications requiring estimation of physical parameters of many complex surfaces and identification of visually similar materials having fine spectral signatures. In the recent years, ground based hyperspectral imaging has gained immense interest in the research on electronic imaging for food inspection, forensic science, medical surgery and diagnosis, and military applications. This review focuses on the fundamentals of hyperspectral image analysis and its modern applications such as food quality and safety assessment, medical diagnosis and image guided surgery, forensic document examination, defense and homeland security, remote sensing applications such as precision agriculture and water resource management and material identification and mapping of artworks. Moreover, recent research on the use of hyperspectral imaging for examination of forgery detection in questioned documents, aided by deep learning, is also presented. This review can be a useful baseline for future research in hyperspectral image analysis.","","","10.1109/ACCESS.2018.2812999","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8314827","Agriculture;document images;food quality and safety;hyperspectral imaging;medical imaging;remote sensing","Hyperspectral imaging;Spatial resolution;Imaging;Safety","forensic science;geophysical image processing;hyperspectral imaging;inspection;remote sensing;surgery","hyperspectral image analysis;military applications;modern sensor technologies;temporal resolutions;electronic imaging;medical diagnosis;image guided surgery;questioned documents;deep learning;forgery detection;civil applications;environmental applications;exceptional resolutions;spatial resolutions;spectral resolutions;remote sensing applications","","16","129","","","","","IEEE","IEEE Journals"
"Optimally Removing Synchronization Overhead for CNNs in Three-Dimensional Neuromorphic Architecture","Y. Wang; R. Chen; R. Mao; Z. Shao","College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China; College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China; College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China; Embedded Systems and CPS Laboratory, Department of Computing, The Hong Kong Polytechnic University, Hong Kong","IEEE Transactions on Industrial Electronics","","2018","65","11","8973","8981","Recent three-dimensional (3-D) neuromorphic processing-in-memory (PIM) architecture provides a promising hardware-based solution to speed up the processing of convolutional neural networks. However, the limited capacity of the global buffer in this architecture is unable to efficiently handle synchronization overhead. In this paper, we jointly optimize the allocation of computation and memory resources on the 3-D-stacked PIM architecture. The objective is to minimize schedule length by removing synchronization overhead. To guarantee the generation of a feasible task schedule, we theoretically obtain the upper bound to reschedule each computation task. The target problem is further formulated as a dynamic programming model to get an optimal solution. We evaluate our technique with a variety of realistic neural network applications running on deep learning frameworks Caffe and TensorFlow. The results show that the proposed technique can achieve a significant reduction in processing time and improve the utilization of processing cores compared to previous studies.","","","10.1109/TIE.2018.2813959","National Natural Science Foundation of China; Research Grants Council of the Hong Kong Special Administrative Region China; Guangdong Natural Science Foundation; Shenzhen Science and Technology Foundation; Guangdong Provincial General University National Development Program; Natural Science Foundation of SZU; State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8310609","Convolutional neural networks (CNNs);embedded systems;neuromorphic computing;processing-in-memory;scheduling","Task analysis;Synchronization;Computer architecture;Schedules;Job shop scheduling;Computational modeling;Neuromorphics","dynamic programming;feedforward neural nets;processor scheduling","synchronization overhead;memory resources;PIM architecture;schedule length;feasible task schedule;computation task;optimal solution;realistic neural network applications;processing time;processing cores;three-dimensional neuromorphic architecture;processing-in-memory architecture;convolutional neural networks;global buffer;3-D-stacked PIM architecture;dynamic programming model;deep learning frameworks;Caffe;TensorFlow","","1","30","","","","","IEEE","IEEE Journals"
"Sound Texture Generative Model Guided by a Lossless Mel-Frequency Convolutional Neural Network","W. Liu; G. Liu; X. Ji; J. Zhai; Y. Dai","School of Automation, Nanjing University of Science and Technology, Nanjing, China; School of Automation, Nanjing University of Science and Technology, Nanjing, China; School of Automation, Nanjing University of Science and Technology, Nanjing, China; School of Electrical and Computer Engineering, Jiangsu University of Science and Technology, Zhenjiang, China; School of Automation, Nanjing University of Science and Technology, Nanjing, China","IEEE Access","","2018","6","","48030","48041","Rainstorms, insect swarms, and galloping horses produce “sound textures,”which are the resulting natural sounds of many similar acoustic events. With new achievements emerging regularly for generative models, the deep convolutional neural network (CNN) has proven to be a tremendously successful approach for image and sound synthesis. Existing state-of-the-art sound texture generative models simply treat sound texture signals as 1-D images while discarding the difference between the human vision and auditory systems. This paper considers mel-frequency statistical features, which are designed according to the human auditory system and have been viewed as the dominant features for sound identification. We first construct a CNN structure for extracting mel-frequency features from sounds losslessly. This structure is called mel-frequency CNN (MF-CNN). Next, we investigate a novel sound texture generative model by incorporating the MF-CNN into a convolutional generative network composed of cascading upsampling groups. A jointly alternating back propagation algorithm is proposed to train the overall network. The feedback of the MF-CNN is used to advise the gradients in the inferential and learning back propagation to make the mel-frequency features of the synthesized sounds more similar to the natural ones. Moreover, the proposed generative model can also be extended to other sound synthesis tasks.","","","10.1109/ACCESS.2018.2867804","National Natural Science Foundation of China; Natural Science Foundation of Jiangsu Province; CCF-VENUSTECH Foundation; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8449933","Convolutional neural network;generative model;sound texture;mel-frequency features;jointly alternating back propagation","Convolutional neural networks;Auditory system;Training;Feature extraction;Gallium nitride;Data models;Generators","acoustic signal processing;audio signal processing;backpropagation;convolution;feature extraction;feedforward neural nets;image texture;statistical analysis","human auditory system;sound identification;CNN structure;mel-frequency CNN;MF-CNN;convolutional generative network;sound synthesis tasks;sound texture generative model guided;lossless mel-frequency convolutional neural network;insect swarms;galloping horses;deep convolutional neural network;sound texture signals;human vision;auditory systems;mel-frequency statistical features;natural sounds;acoustic events;image synthesis;learning back propagation;sound texture generative model","","1","30","","","","","IEEE","IEEE Journals"
"Exploring the Potential of Conditional Adversarial Networks for Optical and SAR Image Matching","N. Merkle; S. Auer; R. Müller; P. Reinartz","Remote Sensing Technology Institute of the German Aerospace Center (DLR), Wessling, Germany; Remote Sensing Technology Institute of the German Aerospace Center (DLR), Wessling, Germany; Remote Sensing Technology Institute of the German Aerospace Center (DLR), Wessling, Germany; Remote Sensing Technology Institute of the German Aerospace Center (DLR), Wessling, Germany","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2018","11","6","1811","1820","Tasks such as the monitoring of natural disasters or the detection of change highly benefit from complementary information about an area or a specific object of interest. The required information is provided by fusing high accurate coregistered and georeferenced datasets. Aligned high-resolution optical and synthetic aperture radar (SAR) data additionally enable an absolute geolocation accuracy improvement of the optical images by extracting accurate and reliable ground control points (GCPs) from the SAR images. In this paper, we investigate the applicability of a deep learning based matching concept for the generation of precise and accurate GCPs from SAR satellite images by matching optical and SAR images. To this end, conditional generative adversarial networks (cGANs) are trained to generate SAR-like image patches from optical images. For training and testing, optical and SAR image patches are extracted from TerraSAR-X and PRISM image pairs covering greater urban areas spread over Europe. The artificially generated patches are then used to improve the conditions for three known matching approaches based on normalized cross-correlation (NCC), scale-invariant feature transform (SIFT), and binary robust invariant scalable key (BRISK), which are normally not usable for the matching of optical and SAR images. The results validate that a NCC-, SIFT-, and BRISK-based matching greatly benefit, in terms of matching accuracy and precision, from the use of the artificial templates. The comparison with two state-of-the-art optical and SAR matching approaches shows the potential of the proposed method but also revealed some challenges and the necessity for further developments.","","","10.1109/JSTARS.2018.2803212","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8328024","Artificial image generation;conditional generative adversarial networks (cGANs);multisensor image matching;optical satellite images;synthetic aperture radar (SAR)","Optical sensors;Optical imaging;Adaptive optics;Synthetic aperture radar;Optical distortion;Biomedical optical imaging;Geology","geophysical image processing;geophysical techniques;image matching;image registration;synthetic aperture radar","conditional adversarial networks;SAR image matching;high accurate coregistered datasets;georeferenced datasets;high-resolution optical;synthetic aperture radar data;absolute geolocation accuracy improvement;optical images;extracting accurate ground control points;reliable ground control points;matching concept;precise GCPs;accurate GCPs;SAR satellite images;conditional generative adversarial networks;SAR-like image patches;PRISM image pairs;artificially generated patches;known matching approaches;scale-invariant feature;BRISK-based matching;matching accuracy;state-of-the-art optical;SAR matching approaches;natural disasters;deep learning based matching concept;TerraSAR-X image pair;urban areas;Europe;normalized cross-correlation;binary robust invariant scalable key;artificial templates","","6","35","","","","","IEEE","IEEE Journals"
"Survey of advances and challenges in intelligent autonomy for distributed cyber-physical systems","D. W. McKee; S. J. Clement; J. Almutairi; J. Xu","School of Computing, University of Leeds, UK; School of Computing, University of Leeds, UK; School of Computing, University of Leeds, UK; School of Computing, University of Leeds, UK","CAAI Transactions on Intelligence Technology","","2018","3","2","75","82","With the evolution of the Internet of things and smart cities, a new trend of the Internet of simulation has emerged to utilise the technologies of cloud, edge, fog computing, and high-performance computing for design and analysis of complex cyber-physical systems using simulation. These technologies although being applied to the domains of big data and deep learning are not adequate to cope with the scale and complexity of emerging connected, smart, and autonomous systems. This study explores the existing state-of-the-art in automating, augmenting, and integrating systems across the domains of smart cities, autonomous vehicles, energy efficiency, smart manufacturing in Industry 4.0, and healthcare. This is expanded to look at existing computational infrastructure and how it can be used to support these applications. A detailed review is presented of advances in approaches providing and supporting intelligence as a service. Finally, some of the remaining challenges due to the explosion of data streams; issues of safety and security; and others related to big data, a model of reality, augmentation of systems, and computation are examined.","","","10.1049/trit.2018.0010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8396911","","","security of data;cloud computing;Big Data;production engineering computing;Internet of Things;cyber-physical systems;smart cities;energy conservation;intelligent manufacturing systems;service-oriented architecture","big data;distributed cyber-physical systems;smart cities;fog computing;complex cyber-physical systems;deep learning;autonomous systems;autonomous vehicles;energy efficiency;smart manufacturing;data streams;computational infrastructure;intelligent autonomy survey;internet of things;edge computing;cloud computing;smart systems;automating systems;augmenting systems;integrating systems;healthcare;intelligence service;data safety;data security","","1","138","","","","","IET","IET Journals"
"Regression-based convolutional 3D pose estimation from single image","S. Ershadi-Nasab; S. Kasaei; E. Sanaei","Sharif University of Technology, Iran; Sharif University of Technology, Iran; Sharif University of Technology, Iran","Electronics Letters","","2018","54","5","292","293","Estimation of 3D human pose from a single image is a challenging task because of ambiguities in projection from 3D space to the 2D image plane. A new two-stage deep convolutional neural network-based method is proposed for regressing the distance and angular difference matrices among body joints. Using the angular difference between body joints in addition to the distance between them in articulated objects such as human body can better model the structure of the shapes and increases the modelling capability of the learning method. Experimental results on HumanEva I and Human3.6M datasets show that the proposed method has substantial improvement in the mean per joint position error measure over the state-of-the-art methods.","","","10.1049/el.2017.4052","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8304717","","","neural nets;pose estimation;regression analysis","joint position error measure;Human3.6M datasets;HumanEva I datasets;shape structure modeling;human body;articulated objects;body joints;angular difference matrices;two-stage deep convolutional neural network-based method;2D image plane;3D space;3D human pose estimation;regression-based convolutional 3D pose estimation","","","11","","","","","IET","IET Journals"
"Mapping the Cortical Network Arising From Up-Regulated Amygdaloidal Activation Using  $\lambda$ -Louvain Algorithm","N. Liu; X. Yu; L. Yao; X. Zhao","College of Information Science and Technology, Beijing Normal University, Beijing, China; College of Information Science and Technology, Beijing Normal University, Beijing, China; State Key Laboratory of Cognitive Neuroscience and Learning and the College of Information Science and Technology, Beijing Normal University, Beijing, China; College of Information Science and Technology, Beijing Normal University, Beijing, China","IEEE Transactions on Neural Systems and Rehabilitation Engineering","","2018","26","6","1169","1177","The amygdala plays an important role in emotion processing. Several studies have proved that its activation can be regulated by real-time functional magnetic resonance imaging (rtfMRI)-based neurofeedback training. However, although studies have found brain regions that are functionallycloselyconnectedto the amygdala in the cortex, it is not clear whether these brain regions and the amygdala are structurally closely connected, and if they show the same training effect as the amygdala in the process of emotional regulation. In this paper, we instructed subjects to up-regulate the activation of the left amygdala (LA) through rtfMRI-based neurofeedback training. In order to fuse multimodal imaging data, we introduced a network analysis method called the λ-Louvain clustering algorithm. This method was used to integrate multimodal data from the training experiment and construct an LA-cortical network. Correlation analysis and main-effect analysis were conducted to determine the signal covariance associated with the activation of the target area; ultimately, we identified the left temporal pole superior as the amygdaloidal-cortical network region. As a deep nucleus in the brain, the treatment and stimulation of the amygdala remains challenging. Our results provide new insights for the regulation of activation in a deep nucleus using more neurofeedback techniques.","","","10.1109/TNSRE.2018.2838075","Funds for National Natural Science Foundation of China; International Cooperation and Exchange of the National Natural Science Foundation of China; Key Program of National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8360962","Amygdala;real-time fMRI;cortical network;multimodal;clustering","Training;Functional magnetic resonance imaging;Diffusion tensor imaging;Neurofeedback;Clustering algorithms;Real-time systems","biomedical MRI;brain;cognition;correlation methods;covariance analysis;medical image processing;neurophysiology;sensor fusion","emotion processing;real-time functional magnetic resonance imaging;rtfMRI;neurofeedback training;brain regions;emotional regulation;network analysis method;λ-Louvain clustering algorithm;LA-cortical network;main-effect analysis;amygdaloidal-cortical network region;amygdala;cortical network mapping;up-regulated amygdaloidal activation;multimodal imaging data fusion;correlation analysis;signal covariance","","","47","","","","","IEEE","IEEE Journals"
"Spectral–Spatial Feature Extraction for HSI Classification Based on Supervised Hypergraph and Sample Expanded CNN","Y. Kong; X. Wang; Y. Cheng","School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, China; School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, China; School of Information and Control Engineering, China University of Mining and Technology, Xuzhou, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2018","11","11","4128","4140","Hyperspectral image (HSI) classification remains a challenging problem due to unique characteristics of HSI data (such as numerous bands and strong correlations in the spectral and spatial domains) and small sample size. To address such concerns, we propose a novel spectral-spatial feature extraction method for HSI classification by employing graph embedding and deep learning (DL) models. Since the conventional graph cannot capture the complex manifold relationship of HSI data, and there exist the observations of within-class variation as well as the similarity between different classes in the spectral domain, we construct the supervised within-class/between-class hypergraph (SWBH) to extract the spectral features of HSI. Since it is difficult for DL models to learn representative features for HSI data when the labeled training samples are limited, we propose the random zero settings to newly generate a large amount of labeled HSI samples for the training of convolutional neural network (CNN). The designed sample expanded CNN (SECNN) is used to extract the HSI spatial features. Thus, the spectral-spatial features of HSI can be learned by integrating the features extracted from SWBH and SECNN, respectively. Experiments on three real HSI datasets demonstrate higher classification accuracy of the proposed SWBH-SECNN method.","","","10.1109/JSTARS.2018.2869210","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8472143","Convolutional neural network (CNN);feature extraction (FE);hyperspectral image (HSI);hypergraph;sample expansion","Feature extraction;Iron;Training;Measurement;Principal component analysis;Data mining;Linear programming","feature extraction;geophysical image processing;graph theory;hyperspectral imaging;image classification;image representation;learning (artificial intelligence);neural nets","HSI data;labeled training samples;labeled HSI samples;HSI spatial features;spectral-spatial features;HSI datasets;HSI classification;supervised hypergraph;sample expanded CNN;hyperspectral image classification;spectral domains;spatial domains;novel spectral-spatial feature extraction method;within-class variation;spectral domain;spectral features;representative features;within-class-between-class hypergraph","","","50","","","","","IEEE","IEEE Journals"
"Robust Guided Image Filtering Using Nonconvex Potentials","B. Ham; M. Cho; J. Ponce","School of Electrical and Electronic Engineering, Yonsei University, Seoul, Korea; Department of Computer Science and Engineering, POSTECH, Pohang, Seoul, Korea; École Normale Supérieure / PSL Research University and WILLOW project-team (CNRS/ENS/INRIA UMR 8548), Paris, France","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","1","192","207","Filtering images using a guidance signal, a process called guided or joint image filtering, has been used in various tasks in computer vision and computational photography, particularly for noise reduction and joint upsampling. This uses an additional guidance signal as a structure prior, and transfers the structure of the guidance signal to an input image, restoring noisy or altered image structure. The main drawbacks of such a data-dependent framework are that it does not consider structural differences between guidance and input images, and that it is not robust to outliers. We propose a novel SD (for static/dynamic) filter to address these problems in a unified framework, and jointly leverage structural information from guidance and input images. Guided image filtering is formulated as a nonconvex optimization problem, which is solved by the majorize-minimization algorithm. The proposed algorithm converges quickly while guaranteeing a local minimum. The SD filter effectively controls the underlying image structure at different scales, and can handle a variety of types of data from different sensors. It is robust to outliers and other artifacts such as gradient reversal and global intensity shift, and has good edge-preserving smoothing properties. We demonstrate the flexibility and effectiveness of the proposed SD filter in a variety of applications, including depth upsampling, scale-space filtering, texture removal, flash/non-flash denoising, and RGB/NIR denoising.","","","10.1109/TPAMI.2017.2669034","Institute for Information & communications Technology Promotion (IITP); Korea government (MSIP); Development of the high-precision natural 3D view generation technology using smart-car multi sensors and deep learning; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7855782","Guided image filtering;joint image filtering;nonconvex optimization;majorize-minimization algorithm","Image edge detection;Color;Linear programming;Noise reduction;Robustness;Image color analysis;Optimization","computer vision;concave programming;edge detection;image denoising;image filtering;image sampling;minimisation;smoothing methods","edge-preserving smoothing properties;majorize-minimization algorithm;noise reduction;guided image filtering;joint upsampling;computational photography;computer vision;scale-space filtering;SD filter;nonconvex optimization problem","","18","65","Traditional","","","","IEEE","IEEE Journals"
"A Heterogeneous Multicore System on Chip for Energy Efficient Brain Inspired Computing","A. Pullini; F. Conti; D. Rossi; I. Loi; M. Gautschi; L. Benini","Integrated Systems Laboratory, ETH Zurich, Zürich, Switzerland; Integrated Systems Laboratory, ETH Zurich, Zürich, Switzerland; DEI, University of Bologna, Bologna, Italy; DEI, University of Bologna, Bologna, Italy; Integrated Systems Laboratory, ETH Zurich, Zürich, Switzerland; Integrated Systems Laboratory, ETH Zurich, Zürich, Switzerland","IEEE Transactions on Circuits and Systems II: Express Briefs","","2018","65","8","1094","1098","Convolutional neural networks (CNNs) have revolutionized computer vision, speech recognition, and other fields requiring strong classification capabilities. These strengths make CNNs appealing in edge node Internet-of-Things (IoT) applications requiring near-sensors processing. Specialized CNN accelerators deliver significant performance per watt and satisfy the tight constraints of deeply embedded devices, but they cannot be used to implement arbitrary CNN topologies or nonconventional sensory algorithms where CNNs are only a part of the processing stack. A higher level of flexibility is desirable for next generation IoT nodes. Here, we present Mia Wallace, a 65-nm system-on-chip integrating a near-threshold parallel processor cluster tightly coupled with a CNN accelerator: it achieves peak energy efficiency of 108 GMAC/s/W at 0.72 V and peak performance of 14 GMAC/s at 1.2 V, leaving 1.2 GMAC/s available for general-purpose parallel processing.","","","10.1109/TCSII.2017.2652982","Swiss National Foundation (MicroLearn: Micropower Deep Learning); ERC MultiTherman Project; Horizon 2020 ExaNoDe EU Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7817777","Convolutional neural networks (CNNs);heterogeneous computing;multiprocessor system on a chip (SoC);near threshold computing","Computer architecture;Convolution;Topology;Nickel;Neural networks;System-on-chip;Hardware","convolution;coprocessors;feedforward neural nets;Internet of Things;mixed analogue-digital integrated circuits;multiprocessing systems;parallel processing;pattern clustering;system-on-chip","stack processing;IoT node;edge node Internet-of-things applications;deeply embedded devices;near-sensors processing;speech recognition;computer vision;convolutional neural networks;energy efficient brain inspired computing;heterogeneous multicore system;peak energy efficiency;CNN accelerator;near-threshold parallel processor cluster;65-nm system-on-chip;nonconventional sensory algorithms;arbitrary CNN topologies","","6","23","","","","","IEEE","IEEE Journals"
"Sequence Mining Based Alarm Suppression","G. Dorgo; J. Abonyi","MTA-PE Lendület Complex Systems Monitoring Research Group, University of Pannonia, Veszprém, Hungary; MTA-PE Lendület Complex Systems Monitoring Research Group, University of Pannonia, Veszprém, Hungary","IEEE Access","","2018","6","","15365","15379","Despite the high-pace improvement of industrial process automation, the management of abnormal events still requires human actions. Alarm systems are becoming crucial in providing situation-specific information to the decreasing number of operators. The key role of an alarm management system is to ensure that only the currently significant alarms are annunciated. The design of alarm suppression rules requires the systematic analysis of the process and its control system. We give an overview of the recently developed data-driven techniques and show that the widely applied correlation-based methods utilize a static view of the system. To provide more insight into the process dynamics and represent the temporal relationships among faults, control actions, and process variables, we propose of a multi-temporal sequence mining-based algorithm. The methodology starts with the generation of frequent temporal patterns of the alarm signals. We transform the multi-temporal sequences into Bayes classifiers. The obtained association rules can be used to define the alarm suppression rules. We analyze the data set of a laboratory-scale water treatment testbed to illustrate that multi-temporal sequences are applicable for the description of operation patterns. We extended the benchmark simulator of a vinyl acetate production technology to generate easily reproducible results and stimulate the development of alarm management algorithms. The results of detailed sensitivity analyses confirm the benefits of the application of temporal alarm suppression rules, which are reflecting the dynamical behavior of the process.","","","10.1109/ACCESS.2018.2797247","National Research, Development and Innovation Office NKFIH, through the Project OTKA (Process mining and deep learning in the natural sciences and process development); New National Excellence Program of the Ministry of Human Capacities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8268070","Alarm management;process safety;frequent pattern mining;data mining","Heuristic algorithms;Alarm systems;Correlation;Algorithm design and analysis;Process control;Data mining;Measurement","alarm systems;data mining;production engineering computing;water treatment","high-pace improvement;industrial process automation;abnormal events;human actions;situation-specific information;alarm management system;currently significant alarms;widely applied correlation;process dynamics;temporal relationships;multitemporal sequence mining;frequent temporal patterns;multitemporal sequences;association rules;temporal alarm suppression rules;sequence mining based alarm suppression","","2","38","","","","","IEEE","IEEE Journals"
"A High Performance Spelling System based on EEG-EOG Signals With Visual Feedback","M. Lee; J. Williamson; D. Won; S. Fazli; S. Lee","Department of Brain and Cognitive Engineering, Korea University, Seoul, South Korea; Department of Brain and Cognitive Engineering, Korea University, Seoul, South Korea; Department of Brain and Cognitive Engineering, Korea University, Seoul, South Korea; Nazarbayev University, Astana, Kazakhstan; Department of Brain and Cognitive Engineering, Korea University, Seoul, South Korea","IEEE Transactions on Neural Systems and Rehabilitation Engineering","","2018","26","7","1443","1459","In this paper, we propose a highly accurate and fast spelling system that employs multi-modal electroencephalography-electrooculography (EEG-EOG) signals and visual feedback technology. Over the last 20 years, various types of speller systems have been developed in brain-computer interface and EOG/eye-tracking research; however, these conventional systems have a tradeoff between the spelling accuracy (or decoding) and typing speed. Healthy users and physically challenged participants, in particular, may become exhausted quickly; thus, there is a need for a speller system with fast typing speed while retaining a high level of spelling accuracy. In this paper, we propose the first hybrid speller system that combines EEG and EOG signals with visual feedback technology so that the user and the speller system can act cooperatively for optimal decision-making. The proposed spelling system consists of a classic row-column event-related potential (ERP) speller, an EOG command detector, and visual feedback modules. First, the online ERP speller calculates classification probabilities for all candidate characters from the EEG epochs. Second, characters are sorted by their probability, and the characters with the highest probabilities are highlighted as visual feedback within the row-column spelling layout. Finally, the user can actively select the character as the target by generating an EOG command. The proposed system shows 97.6% spelling accuracy and an information transfer rate of 39.6 (±13.2) [bits/min] across 20 participants. In our extended experiment, we redesigned the visual feedback and minimized the number of channels (four channels) in order to enhance the speller performance and increase usability. Most importantly, a new weighted strategy resulted in 100% accuracy and a 57.8 (±23.6) [bits/min] information transfer rate across six participants. This paper demonstrates that the proposed system can provide a reliable communication channel for practical speller applications and may be used to supplement existing systems.","","","10.1109/TNSRE.2018.2839116","Ministry of Science and ICT, South Korea, through the SW Starlab Support Program supervised by the Institute for Information and Communications Technology Promotion; Korean Government: Development of BCI based Brain and Cognitive Computing Technology for Recognizing User’s Intentions using Deep Learning; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8361842","Brain-computer interfaces (BCI);electroencephalography (EEG);electrooculogram (EOG);P300 speller;visual feedback","Electrooculography;Electroencephalography;Visualization;Task analysis;Decoding;Layout","bioelectric potentials;brain-computer interfaces;decision making;electroencephalography;electro-oculography;gaze tracking;medical signal processing;signal classification","typing speed;multimodal electroencephalography-electrooculography signals;brain-computer interface;spelling accuracy;optimal decision-making;classification probabilities;EEG epochs;hybrid speller system;EOG/eye-tracking research;EEG-EOG signals;high performance spelling system;practical speller applications;speller performance;row-column spelling layout;online ERP speller;visual feedback modules;EOG command detector;classic row-column event-related potential speller;visual feedback technology","","3","72","","","","","IEEE","IEEE Journals"
"Rearview Camera-Based Backover Warning System Exploiting a Combination of Pose-Specific Pedestrian Recognitions","J. K. Suhr; H. G. Jung","School of Intelligent Mechatronics Engineering, Sejong University, Seoul, South Korea; Department of Information and Communication Engineering, Korea National University of Transportation, Chungju, South Korea","IEEE Transactions on Intelligent Transportation Systems","","2018","19","4","1122","1129","This paper proposes a practical backover warning system using a wide-angle rearview camera. The proposed system utilizes simple but cost-effective techniques for pedestrian detection, verification, and tracking to achieve real-time operation. This system first transforms fisheye images via Mercator projection to reduce pedestrian shape variations. Second, it detects pedestrians based on lower and upper body detectors. This is for handling upright and non-upright poses as well as severe occlusions of upper bodies. Then, it confirms pedestrians by checking the existence of feet or a head inside the lower or upper body region. This step ensures that the system achieves a low false alarm rate. Finally, the confirmed pedestrians are visually tracked by fusing generative and discriminative models in a score level. In the experiment, the proposed system was quantitatively evaluated and compared with the previous method.","","","10.1109/TITS.2017.2709797","LG Innotek and Institute for Information and Communications Technology Promotion (IITP); Korean government (MSIP); Development of Smart Car Vision Techniques based on Deep Learning for Pedestrian Safety; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7964717","Backover warning system;pedestrian recognition;rearview camera","Cameras;Distortion;Feature extraction;Optical distortion;Alarm systems;Head;Lenses","cameras;image fusion;object detection;object recognition;object tracking;pedestrians;pose estimation;traffic engineering computing","pedestrian detection;pedestrian shape variations;lower body detectors;upper body detectors;lower body region;upper body region;pose-specific pedestrian recognitions;practical backover warning system;wide-angle rearview camera;cost-effective techniques;rearview camera-based backover warning system;pedestrian verification;pedestrian tracking;fisheye images;Mercator projection;generative model fusion;discriminative model fusion","","1","35","","","","","IEEE","IEEE Journals"
"Motion-Based Rapid Serial Visual Presentation for Gaze-Independent Brain-Computer Interfaces","D. Won; H. Hwang; D. Kim; K. Müller; S. Lee","Department of Brain and Cognitive Engineering, Korea University, Seoul, South Korea; Department of Medical IT Convergence Engineering, Kumoh National Institute of Technology, Gumi, South Korea; Department of Brain and Cognitive Engineering, Korea University, Seoul, South Korea; Department of Brain and Cognitive Engineering, Korea University, Seoul, South Korea; Department of Brain and Cognitive Engineering, Korea University, Seoul, South Korea","IEEE Transactions on Neural Systems and Rehabilitation Engineering","","2018","26","2","334","343","Most event-related potential (ERP)-based brain-computer interface (BCI) spellers primarily use matrix layouts and generally require moderate eye movement for successful operation. The fundamental objective of this paper is to enhance the perceptibility of target characters by introducing motion stimuli to classical rapid serial visual presentation (RSVP) spellers that do not require any eye movement, thereby applying them to paralyzed patients with oculomotor dysfunctions. To test the feasibility of the proposed motion-based RSVP paradigm, we implemented three RSVP spellers: 1) fixed-direction motion (FM-RSVP); 2) random-direction motion (RM-RSVP); and 3) (the conventional) non-motion stimulation (NM-RSVP), and evaluated the effect of the three different stimulation methods on spelling performance. The two motion-based stimulation methods, FMand RM-RSVP, showed shorter P300 latency and higher P300 amplitudes (i. e., 360.4-379.6 ms; 5.5867- 5.7662 μV) than the NM-RSVP (i.e., 480.4 ms; 4.7426 μV). This led to higher and more stable performances for FMand RM-RSVP spellers than NM-RSVP speller (i. e., 79.06±6.45% for NM-RSVP, 90.60±2.98% for RM-RSVP, and 92.74±2.55% for FM-RSVP). In particular, the proposed motion-based RSVP paradigm was significantly beneficial for about half of the subjects who might not accurately perceive rapidly presented static stimuli. These results indicate that the use of proposed motion-based RSVP paradigm is more beneficial for target recognition when developing BCI applications for severely paralyzed patients with complex ocular dysfunctions.","","","10.1109/TNSRE.2017.2736600","Institute for Information and Communications Technology Promotion (IITP) through the Korea Government (MSIT); Development of BCI-based Brain and Cognitive Computing Technology for Recognizing User’s Intentions using Deep Learning) and the MSIT, South Korea, under the SW Starlab support program supervised by the IITP; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8008839","Brain-computer interface (BCI);gaze-independent;event-related potential (ERP);rapid serial visual presentation (RSVP)","Visualization;Color;Electroencephalography;Training;Target recognition;Shape;Character recognition","brain-computer interfaces;electroencephalography;eye;medical computing;neurophysiology;visual evoked potentials","gaze-independent brain-computer interfaces;event-related potential;brain-computer interface spellers;moderate eye movement;classical rapid serial visual presentation spellers;RSVP paradigm;fixed-direction motion;FM-RSVP;nonmotion stimulation;motion-based stimulation methods;FMand RM-RSVP spellers;NM-RSVP speller;motion-based rapid serial visual presentation;motion stimuli;paralyzed patients;oculomotor dysfunctions;random-direction motion;P300 latency;P300 amplitudes;target recognition","Adult;Brain-Computer Interfaces;Communication Aids for Disabled;Electroencephalography;Equipment Design;Event-Related Potentials, P300;Eye Movements;Female;Fixation, Ocular;Healthy Volunteers;Humans;Male;Paralysis;Psychomotor Performance;Young Adult","1","60","","","","","IEEE","IEEE Journals"
"YodaNN: An Architecture for Ultralow Power Binary-Weight CNN Acceleration","R. Andri; L. Cavigelli; D. Rossi; L. Benini","Integrated Systems Laboratory, ETH Zurich, Zürich, Switzerland; Integrated Systems Laboratory, ETH Zurich, Zürich, Switzerland; Department of Electrical, Electronic and Information Engineering, University of Bologna, Bologna, Italy; Integrated Systems Laboratory, ETH Zurich, Zürich, Switzerland","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","","2018","37","1","48","60","Convolutional neural networks (CNNs) have revolutionized the world of computer vision over the last few years, pushing image classification beyond human accuracy. The computational effort of today's CNNs requires power-hungry parallel processors or GP-GPUs. Recent developments in CNN accelerators for system-on-chip integration have reduced energy consumption significantly. Unfortunately, even these highly optimized devices are above the power envelope imposed by mobile and deeply embedded applications and face hard limitations caused by CNN weight I/O and storage. This prevents the adoption of CNNs in future ultralow power Internet of Things end-nodes for near-sensor analytics. Recent algorithmic and theoretical advancements enable competitive classification accuracy even when limiting CNNs to binary (+1/-1) weights during training. These new findings bring major optimization opportunities in the arithmetic core by removing the need for expensive multiplications, as well as reducing I/O bandwidth and storage. In this paper, we present an accelerator optimized for binary-weight CNNs that achieves 1.5 TOp/s at 1.2 V on a core area of only 1.33 million gate equivalent (MGE) or 1.9 mm2 and with a power dissipation of 895 μW in UMC 65-nm technology at 0.6 V. Our accelerator significantly outperforms the state-of-the-art in terms of energy and area efficiency achieving 61.2 TOp/s/W@0.6 V and 1.1 TOp/s/MGE@1.2 V, respectively.","","","10.1109/TCAD.2017.2682138","Swiss National Science Foundation; (MicroLearn: Micropower Deep Learning); Armasuisse Science and Technology; ERC MultiTherman Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7878541","ASIC;binary weights;convolutional neural networks (CNNs);hardware accelerator;Internet of Things (IoT)","Accelerators;Hardware;Internet of Things;Convolutional neural networks ;Computer vision","CMOS logic circuits;computer vision;convolution;coprocessors;embedded systems;image classification;integrated circuit design;low-power electronics;neural nets;optimisation;power aware computing;system-on-chip","I/O storage;I/O bandwidth;algorithmic advancements;binary weights;competitive classification accuracy;hard limitations;deeply embedded applications;mobile embedded applications;power envelope;energy consumption;system-on-chip integration;CNN accelerators;GP-GPUs;power-hungry parallel processors;computational effort;human accuracy;image classification;computer vision;convolutional neural networks;ultralow power binary-weight CNN acceleration;power dissipation;binary-weight CNNs;accelerator;optimization opportunities","","32","53","","","","","IEEE","IEEE Journals"
"Hierarchical Fully Convolutional Network for Joint Atrophy Localization and Alzheimer's Disease Diagnosis using Structural MRI","C. Lian; M. Liu; J. Zhang; D. Shen","Department of Radiology and BRIC, University of North Carolina at Chapel Hill, Chapel Hill, North Carolina United States 27599 (e-mail: chunfeng_lian@med.unc.edu); Department of Radiology and BRIC, University of North Carolina at Chapel Hill, Chapel Hill, North Carolina United States (e-mail: mxliu@med.unc.edu); Department of Radiology and BRIC, University of North Carolina at Chapel Hill, Chapel Hill, North Carolina United States (e-mail: xdzhangjun@gmail.com); Department of Radiology, UNC Chapel Hill, Chapel Hill, North Carolina United States (e-mail: dgshen@med.unc.edu)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","PP","99","1","1","Structural magnetic resonance imaging (sMRI) has been widely used for computer-aided diagnosis of neurodegenerative disorders, e.g., Alzheimer's disease (AD), due to its sensitivity to morphological changes caused by brain atrophy. Recently, a few deep learning methods (e.g., convolutional neural networks, CNNs) have been proposed to learn task-oriented features from sMRI for AD diagnosis, and achieved superior performance than the conventional learning-based methods using hand-crafted features. However, these existing CNN-based methods still require the pre-determination of informative locations in sMRI. That is, the stage of discriminative atrophy localization is isolated to the latter stages of feature extraction and classifier construction. In this paper, we propose a hierarchical fully convolutional network (H-FCN) to automatically identify discriminative local patches and regions in the whole brain sMRI, upon which multi-scale feature representations are then jointly learned and fused to construct hierarchical classification models for AD diagnosis. Our proposed H-FCN method was evaluated on a large cohort of subjects from two independent datasets (i.e., ADNI-1 and ADNI-2), demonstrating good performance on joint discriminative atrophy localization and brain disease diagnosis.","","","10.1109/TPAMI.2018.2889096","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8585141","Computer-Aided Alzheimer's Disease Diagnosis;Fully Convolutional Networks;Discriminative Atrophy Localization;Weakly-Supervised Learning;Structural MRI","Feature extraction;Solid modeling;Atrophy;Brain modeling;Alzheimer's disease;Medical diagnosis;Support vector machines","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Cognitive Computing: Architecture, Technologies and Intelligent Applications","M. Chen; F. Herrera; K. Hwang","School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China; Department Computer Science and Artificial Intelligence, University of Granada, Granada, Spain; University of Southern California, Los Angeles, CA, USA","IEEE Access","","2018","6","","19774","19783","With the development of network-enabled sensors and artificial intelligence algorithms, various human-centered smart systems are proposed to provide services with higher quality, such as smart healthcare, affective interaction, and autonomous driving. Considering cognitive computing is an indispensable technology to develop these smart systems, this paper proposes human-centered computing assisted by cognitive computing and cloud computing. First, we provide a comprehensive investigation of cognitive computing, including its evolution from knowledge discovery, cognitive science, and big data. Then, the system architecture of cognitive computing is proposed, which consists of three critical technologies, i.e., networking (e.g., Internet of Things), analytics (e.g., reinforcement learning and deep learning), and cloud computing. Finally, it describes the representative applications of human-centered cognitive computing, including robot technology, emotional communication system, and medical cognitive system.","","","10.1109/ACCESS.2018.2791469","National Natural Science Foundation of China; Director Fund of WNLO; FEDER Funds; Spanish Ministry of Science and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8259243","Cognitive computing;big data analysis;Internet of Things;cloud computing","Cognitive systems;Big Data;Cognition;Cloud computing;Cognitive science;Cyberspace;Human computer interaction","Big Data;cloud computing;cognition;cognitive systems;data mining;health care;human computer interaction;human factors;learning (artificial intelligence);man-machine systems;robots;ubiquitous computing","smart systems;cloud computing;cognitive science;human-centered cognitive computing;medical cognitive system;cognitive computing;network-enabled sensors;artificial intelligence;knowledge discovery;Big Data;robot technology;emotional communication system","","17","44","","","","","IEEE","IEEE Journals"
"Adversarial Action Prediction Networks","Y. Kong; Z. Tao; Y. Fu","College of Computing and Information Sciences, Rochester Institute of Technology, 6925 Rochester, New York United States (e-mail: yu.kong@rit.edu); Electrical and Computer Engineering, Northeastern University, Boston, Massachusetts United States (e-mail: zqtao@ece.neu.edu); ECE, Northeastern University, Boston, Massachusetts United States (e-mail: yunfu@ece.neu.edu)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","PP","99","1","1","Different from after-the-fact action recognition, action prediction task requires action labels to be predicted from partially observed videos containing incomplete action executions. It is challenging because these partial videos have insufficient discriminative information, and their temporal structure is damaged. We study this problem in this paper, and propose an efficient and powerful deep network for learning representative and discriminative features for action prediction. Our approach exploits abundant sequential context information in full videos to enrich the feature representations of partial videos. This information is encoded in latent representations using a variational autoencoder (VAE), which are encouraged to be progress-invariant. Decoding such latent representations using another VAE, we can reconstruct missing information in the features extracted from partial videos. An adversarial learning scheme is adopted to differentiate the reconstructed features from the features directly extracted from full videos in order to well align their distributions. A multi-class classifier is also used to encourage the features to be discriminative. Our network jointly learns features and classifiers, and generates the features particularly optimized for action prediction. Extensive experimental results on UCF101, Sports-1M and BIT datasets demonstrate that our approach remarkably outperforms state-of-the-art methods, and shows significant speedup over these methods. Results also show that actions differ in their prediction characteristics; some actions can be correctly predicted even though only the beginning 10% portion of videos is observed.","","","10.1109/TPAMI.2018.2882805","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8543243","Action Prediction;Action Recognition;Sequential Context;Variational Autoencoder;Adversarial Learning","Videos;Feature extraction;Decoding;Accidents;Prediction methods;Training;Task analysis","","","","2","","","","","","IEEE","IEEE Early Access Articles"
"Autoencoder for Semisupervised Multiple Emotion Detection of Conversation Transcripts","D. Phan; Y. Matsumoto; H. Shindo","Information Technology, Nara Sentan Kagaku Gijutsu Daigakuin Daigaku, 12708 Ikoma, Nara Japan 630-0192 (e-mail: pducanh1988@gmail.com); Information Technology, Nara Sentan Kagaku Gijutsu Daigakuin Daigaku, 12708 Ikoma, Nara Japan (e-mail: matsu@is.naist.jp); Information Technology, Nara Sentan Kagaku Gijutsu Daigakuin Daigaku, 12708 Ikoma, Nara Japan (e-mail: shindo@is.naist.jp)","IEEE Transactions on Affective Computing","","2018","PP","99","1","1","Textual emotion detection is a challenge in computational linguistics and affective computing as it involves the discovery of all associated emotions expressed in a given piece of text. It becomes even more difficult when applied to conversation transcripts, as there arises a need to model the spoken utterances between speakers while keeping in mind the context of the entire conversation. In this paper, we propose a semisupervised multi-label method of predicting emotions from conversation transcripts. The corpus contains conversational quotes extracted from movies. A small number of them are annotated, whereas the rest are used for unsupervised training. The word2vec word-embedding method has been used to build an emotion lexicon from the corpus and then embed the utterances into vector representations. A deep-learning auto-encoder is then used to discover the underlying structure of the unsupervised data. We fine-tune the learned model based on labeled training data and measure its performance on a test set. The experiment result suggests that the method is effective and is only slightly less effective than human annotators.","","","10.1109/TAFFC.2018.2885304","Core Research for Evolutional Science and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8570758","Emotion recognition;semisupervised learning;multilabel;word2vec;autoencoder","Motion pictures;Correlation;Social network services;Neural networks;Context modeling;Data models;Training data","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Unsupervised Reverse Domain Adaptation for Synthetic Medical Images via Adversarial Training","F. Mahmood; R. Chen; N. J. Durr","Department of Biomedical Engineering, Johns Hopkins University, Baltimore, MD, USA; Department of Computer Science, Johns Hopkins University, Baltimore, MD, USA; Department of Biomedical Engineering, Johns Hopkins University, Baltimore, MD, USA","IEEE Transactions on Medical Imaging","","2018","37","12","2572","2581","To realize the full potential of deep learning for medical imaging, large annotated datasets are required for training. Such datasets are difficult to acquire due to privacy issues, lack of experts available for annotation, underrepresentation of rare conditions, and poor standardization. The lack of annotated data has been addressed in conventional vision applications using synthetic images refined via unsupervised adversarial training to look like real images. However, this approach is difficult to extend to general medical imaging because of the complex and diverse set of features found in real human tissues. We propose a novel framework that uses a reverse flow, where adversarial training is used to make real medical images more like synthetic images, and clinically-relevant features are preserved via self-regularization. These domain-adapted synthetic-like images can then be accurately interpreted by networks trained on large datasets of synthetic medical images. We implement this approach on the notoriously difficult task of depth-estimation from monocular endoscopy which has a variety of applications in colonoscopy, robotic surgery, and invasive endoscopic procedures. We train a depth estimator on a large data set of synthetic images generated using an accurate forward model of an endoscope and an anatomically-realistic colon. Our analysis demonstrates that the structural similarity of endoscopy depth estimation in a real pig colon predicted from a network trained solely on synthetic data improved by 78.7% by using reverse domain adaptation.","","","10.1109/TMI.2018.2842767","Johns Hopkins University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8370747","Convolutional neural networks;synthetic data;adversarial training;GANs;domain adaptation;medical imaging;endoscopy","Endoscopes;Training;Medical diagnostic imaging;Gallium nitride;Estimation;Data models","biological organs;biomedical optical imaging;endoscopes;learning (artificial intelligence);medical image processing;medical robotics;surgery","reverse domain adaptation;robotic surgery;colonoscopy;monocular endoscopy;domain-adapted synthetic-like images;self-regularization;clinically-relevant features;general medical imaging;unsupervised adversarial training;annotated datasets;unsupervised reverse domain adaptation;synthetic data;synthetic medical images","","7","63","","","","","IEEE","IEEE Journals"
"ADORE: An Adaptive Holons Representation Framework for Human Pose Estimation","L. Dong; X. Chen; R. Wang; Q. Zhang; E. Izquierdo","University of Electronic Science and Technology of China, Chengdu, China; University of Electronic Science and Technology of China, Chengdu, China; University of Electronic Science and Technology of China, Chengdu, China; Queen Mary University of London, London, U.K.; Queen Mary University of London, London, U.K.","IEEE Transactions on Circuits and Systems for Video Technology","","2018","28","10","2803","2813","In this paper, the problem of human pose estimation in a 2D still image is addressed. A framework called adaptive holons representation (ADORE) that takes advantage of local and global cues is proposed to improve the pose estimation accuracy. In particular, ADORE is made up of two components: 1) the holons part, independent losses pose nets (ILPNs) is designed to first infer joints location on the global level; and 2) the adaptive part, convolutional local detectors (CLDs) is proposed to subsequently detect the joints in the potential regions generated by ILPN. Pose estimation is formulated as a classification problem toward body joints in ILPN, which consists of two independent loss layers that, respectively, instruct the learning of x and y coordinates of a joint. Experimental results on two challenging benchmark tasks demonstrate that our proposed framework is more efficient than other deep models and has desirable performance.","","","10.1109/TCSVT.2017.2707477","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; Scientific Research Foundation for the Returned Overseas Chinese Scholars, State Education Ministry; Open Project of the State Key Laboratory of Virtual Reality Technology and System; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7932915","Pose estimation;convolutional neural network;holons;adaptivity","Pose estimation;Detectors;Adaptation models;Training;Computational modeling;Image color analysis","learning (artificial intelligence);pattern classification;pose estimation","body joints;ILPN;independent loss layers;ADORE;adaptive holons representation framework;local cues;global cues;pose estimation accuracy;holons part;adaptive part;convolutional local detectors;CLD","","1","45","","","","","IEEE","IEEE Journals"
"Extracting statistically significant behaviour from fish tracking data with and without large dataset cleaning","C. Beyan; V. Katsageorgiou; R. B. Fisher","Istituto Italiano di Tecnologia (IIT), Italy; Istituto Italiano di Tecnologia (IIT), Italy; University of Edinburgh, UK","IET Computer Vision","","2018","12","2","162","170","Extracting a statistically significant result from video of natural phenomenon can be difficult for two reasons: (i) there can be considerable natural variation in the observed behaviour and (ii) computer vision algorithms applied to natural phenomena may not perform correctly on a significant number of samples. This study presents one approach to clean a large noisy visual tracking dataset to allow extracting statistically sound results from the image data. In particular, analyses of 3.6 million underwater trajectories of a fish with the water temperature at the time of acquisition are presented. Although there are many false detections and incorrect trajectory assignments, by a combination of data binning and robust estimation methods, reliable evidence for an increase in fish speed as water temperature increases are demonstrated. Then, a method for data cleaning which removes outliers arising from false detections and incorrect trajectory assignments using a deep learning-based clustering algorithm is proposed. The corresponding results show a rise in fish speed as temperature goes up. Several statistical tests applied to both cleaned and not-cleaned data confirm that both results are statistically significant and show an increasing trend. However, the latter approach also generates a cleaner dataset suitable for other analysis.","","","10.1049/iet-cvi.2016.0462","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8306408","","","aquaculture;computer vision;data handling;estimation theory;image denoising;learning (artificial intelligence);pattern classification","data binning;image data;natural phenomena;computer vision;dataset cleaning;fish tracking data;statistical extraction","","1","54","","","","","IET","IET Journals"
"SV-Means: A Fast SVM-Based Level Set Estimator for Phase-Modulated Radar Waveform Classification","A. Pavy; B. Rigling","Air Force Research Laboratory Sensors Directorate in Dayton, Dayton, OH, USA; Department of Electrical Engineering, Wright State University, Dayton, OH, USA","IEEE Journal of Selected Topics in Signal Processing","","2018","12","1","191","201","In this paper, a novel algorithm, SV-Means, is formulated for open set radar waveform classification. The approach extends the quantile one-class support vector machine (q-OCSVM) density estimation algorithm into a classification formulation with inspiration from k-means and stochastic gradient descent principles. Phase-modulated radar waveform data is used to compare the primal and dual q-OCSVM (configured for classification) to SV-Means to verify the algorithm's classification and rejection performance. SV-Means is also shown to be an effective open set classification algorithm and is compared to these other open set classifiers: 1-vs-set machine, W-SVM, PI-SVM, and probabilistic open space (POS)-SVM. The SV-Means algorithm proves to achieve similar, and some cases better, performance against comparable algorithms in a fraction of the training time (as the data records increase and, in the case of the q-OCSVM, level sets increase). The SV-Means open set algorithm is an attractive adaptive classification framework using any feature extraction approach including deep-learning architectures.","","","10.1109/JSTSP.2018.2797798","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8268062","Open set classification;one-class support vector machines;random features;waveform classification","Support vector machines;Signal processing algorithms;Level set;Training;Estimation;Radar;Testing","feature extraction;gradient methods;learning (artificial intelligence);pattern classification;support vector machines","SV-mean open set algorithm;effective open set classification algorithm;dual q-OCSVM;primal q-OCSVM;radar waveform data;stochastic gradient descent principles;one-class support vector machine;open set radar waveform classification;phase-modulated radar waveform classification;level set estimator;fast SVM;attractive adaptive classification framework;probabilistic open space-SVM;PI-SVM;W-SVM;open set classifiers","","1","46","","","","","IEEE","IEEE Journals"
"Convolutional neural networks for gender prediction from smartphone-based ocular images","A. Rattani; N. Reddy; R. Derakhshani","Department of Computer Science and Electrical Engineering, University of Missouri-Kansas City, USA; Department of Computer Science and Electrical Engineering, University of Missouri-Kansas City, USA; Department of Computer Science and Electrical Engineering, University of Missouri-Kansas City, USA","IET Biometrics","","2018","7","5","423","430","Automated gender prediction has drawn significant interest in numerous applications such as surveillance, human-computer interaction, anonymous customised advertisement system, image retrieval system, and biometrics. In the context of smartphone devices, gender information has been used to enhance the accuracy of the integrated biometric authentication and mobile healthcare system. Here, the authors thoroughly investigate gender prediction from ocular images acquired using front-facing cameras of smartphones. This is a new problem as previous research in this area has not explored RGB ocular images captured by smartphones. The authors used deep learning for the task. Specifically, pre-trained and custom convolutional neural network architectures have been implemented for gender prediction. Multi-classifier fusion has been used to improve the prediction accuracy. Further, evaluation of off-the-self-texture descriptors and study of human ability in gender prediction has been conducted for comparative analysis.","","","10.1049/iet-bmt.2017.0171","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8440890","","","biometrics (access control);convolution;feature extraction;feedforward neural nets;gender issues;health care;human computer interaction;image classification;image colour analysis;image retrieval;learning (artificial intelligence);neural net architecture;smart phones","convolutional neural network architectures;pre-trained network architectures;mobile healthcare system;integrated biometric authentication;gender information;smartphone devices;image retrieval system;anonymous customised advertisement system;human-computer interaction;automated gender prediction;smartphone-based ocular images","","2","","","","","","IET","IET Journals"
"Autoencoder-Combined Generative Adversarial Networks for Synthetic Image Data Generation and Detection of Jellyfish Swarm","K. Kim; H. Myung","Urban Robotics Laboratory, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Urban Robotics Laboratory, Korea Advanced Institute of Science and Technology, Daejeon, South Korea","IEEE Access","","2018","6","","54207","54214","Image-based sensing of jellyfish is important as they can cause great damage to the fisheries and seaside facilities and need to be properly controlled. In this paper, we present a deep-learning-based technique to generate a synthetic image of the jellyfish easily with autoencoder-combined generative adversarial networks. The proposed system can easily generate simple images with a smaller number of data sets compared with other generative networks. The generated output showed high similarity with the real-image data set. The application using a fully convolutional network and regression network to estimate the size of the jellyfish swarm was also demonstrated, and showed high accuracy during the estimation test.","","","10.1109/ACCESS.2018.2872025","Ministry of Science, ICT and Future Planning; Ministry of Science, ICT and Future Planning; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8471171","Autoencoder;generative adversarial networks;jellyfish swarm;fully convolutional network;regression","Gallium nitride;Training;Generative adversarial networks;Oceans;Robot kinematics;Generators","aquaculture;feedforward neural nets;image segmentation;learning (artificial intelligence)","fully convolutional network;regression network;jellyfish swarm;autoencoder-combined generative adversarial networks;synthetic image data generation;fisheries;seaside facilities;data sets;generative networks;generated output;real-image data;synthetic image data detection;estimation test","","3","28","","","","","IEEE","IEEE Journals"
"Contextual Bag-of-Words for Robust Visual Tracking","F. Zeng; Y. Ji; M. D. Levine","State Key Laboratory of Information Photonics and Optical Communications, School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China; State Key Laboratory of Information Photonics and Optical Communications, School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China; Department of Electrical and Computer Engineering, Center for Intelligent Machines, McGill University, Montreal, QC, Canada","IEEE Transactions on Image Processing","","2018","27","3","1433","1447","An appearance model is critical for most modern trackers. While numerous novel appearance models have been proposed with demonstrated success, challenges such as occlusion and drifting are still not well addressed. In this paper, we propose a novel contextual bag-of-words (CBOW) discriminative appearance model that appropriately handles drifting and occlusion. Specifically, a contextual region containing both the target and its surroundings is explored to construct a compact representation with two bags-of-words. Each word carries discriminative appearance information that is learned by Bayesian inference. An adaptive updating approach, where the background BOWs of the CBOW model acts as a “sentinel” to prevent the integration of the background appearance with the object model, is introduced to alleviate the drifting problem. Based on CBOW, visual tracking is posed within a Bayesian framework. Moreover, an explicit detection method is employed to handle severe occlusions, which further reduces drifting. Two trackers based on the same CBOW model are implemented using either handcrafted color/texture or deep convolutional features. Our trackers are evaluated based on the popular OTB50 and VOT2015 benchmarks and perform competitively against the current state of the art. In addition, they outperform two recent BOWs trackers by a large margin using the currently available figures of merit. To take into account a tracking breakdown, we propose a new figure of merit called the mean maximum-tracked-frame ratio (MTFR) that evaluates a tracker's temporal persistence without any interruption. Experiments with OTB50 demonstrate the superior robustness of our tracker compared with all other evaluated trackers on the basis of MTFR.","","","10.1109/TIP.2017.2778561","National Natural Science Foundation of China; China Scholarship Council; Natural Sciences and the Engineering Research of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8123862","Visual tracking;contextual bag-of-words;appearance model","Adaptation models;Visualization;Context modeling;Robustness;Computational modeling;Bayes methods;Image color analysis","Bayes methods;image motion analysis;image representation;image texture;learning (artificial intelligence);object detection;object tracking;tracking;video signal processing","tracker evaluation;BOWs trackers;BOWs;adaptive updating;breakdown tracking;modern trackers;robust visual tracking;mean maximum-tracked-frame ratio;tracker;severe occlusions;drifting problem;object model;background appearance;CBOW model;discriminative appearance information;bags-of-words;contextual region;bag-of-words discriminative appearance model;occlusion","","1","56","","","","","IEEE","IEEE Journals"
"Real-World Railway Traffic Detection Based on Faster Better Network","J. Li; F. Zhou; T. Ye","School of Instrumentation Science and Opto-electronics Engineering, Beihang University, Beijing, China; Second Research Institute, China Aerospace Science and Industry Group, Beijing, China; Second Research Institute, China Aerospace Science and Industry Group, Beijing, China","IEEE Access","","2018","6","","68730","68739","Detection of railway shape and dangerous obstacles plays a critical role in the auxiliary driving of the train. Speed and accuracy are both of great significance to real-world railway traffic detection, which demands a higher efficiency and effectiveness. The goal of this paper is to design an architecture that achieves the right speed (for effectiveness)/accuracy (for effectiveness) balance for actual railway detection. Driven by this motivation and based on the advantages of some current algorithms, we propose FB-Net (faster better network), a robust end-to-end convolutional neural network. Detectors based on deep learning method are composed of feature extraction, candidate region generation,and classification. Specifically, our framework is focusing on with three embedded modules: 1) To improve efficiency, we replace standard convolutions with depthwise-pointwise convolutions in the feature extraction stage, aiming to red reduce model parameters; 2) To address the effectiveness, a priori module is added for candidate boxes to provide a coarse location for subsequent regressor and to reduce the searching space of objects significantly; 3) Meanwhile, we design a feature fusion module to enhance the semantic context interaction of adjacent feature maps for better detection of small objects. Experiments for railway traffic datasets on both computer device and mobile device demonstrate that FB-Net achieves good results when the input size is 320 pixels × 320 pixels.","","","10.1109/ACCESS.2018.2879270","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8528448","Railway traffic detection;efficiency and effectiveness;depthwise-pointwise convolution;priori module;feature fusion","Rail transportation;Detectors;Standards;Feature extraction;Surveillance;Object detection;Shape","computer vision;convolutional neural nets;feature extraction;image resolution;learning (artificial intelligence);object detection;railway engineering","faster better network;end-to-end convolutional neural network;depthwise-pointwise convolutions;feature extraction stage;feature fusion module;railway traffic datasets;FB-Net achieves good results;real-world railway traffic detection;railway shape;auxiliary driving","","","34","","","","","IEEE","IEEE Journals"
"A Skeletal Similarity Metric for Quality Evaluation of Retinal Vessel Segmentation","Z. Yan; X. Yang; K. Cheng","Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Clearwater Bay, Hong Kong; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Clearwater Bay, Hong Kong","IEEE Transactions on Medical Imaging","","2018","37","4","1045","1057","The most commonly used evaluation metrics for quality assessment of retinal vessel segmentation are sensitivity, specificity, and accuracy, which are based on pixel-to-pixel matching. However, due to the inter-observer problem that vessels annotated by different observers vary in both thickness and location, pixel-to-pixel matching is too restrictive to fairly evaluate the results of vessel segmentation. In this paper, the proposed skeletal similarity metric is constructed by comparing the skeleton maps generated from the reference and the source vessel segmentation maps. To address the inter-observer problem, instead of using a pixel-to-pixel matching strategy, each skeleton segment in the reference skeleton map is adaptively assigned with a searching range whose radius is determined based on its vessel thickness. Pixels in the source skeleton map located within the searching range are then selected for similarity calculation. The skeletal similarity consists of a curve similarity, which measures the structural similarity between the reference and the source skeleton maps and a thickness similarity, which measures the thickness consistency between the reference and the source vessel segmentation maps. In contrast to other metrics that provide a global score for the overall performance, we modify the definitions of true positive, false negative, true negative, and false positive based on the skeletal similarity, based on which sensitivity, specificity, accuracy, and other objective measurements can be constructed. More importantly, the skeletal similarity metric has better potential to be used as a pixelwise loss function for training deep learning models for retinal vessel segmentation. Through comparison of a set of examples, we demonstrate that the redefined metrics based on the skeletal similarity are more effective for quality evaluation, especially with greater tolerance to the inter-observer problem.","","","10.1109/TMI.2017.2778748","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8125187","Retinal vessel segmentation;quality evaluation;inter-observer problem;skeletal similarity","Image segmentation;Manuals;Skeleton;Retinal vessels;Observers;Thickness measurement","eye;image matching;image segmentation;learning (artificial intelligence);medical image processing","skeletal similarity metric;quality evaluation;retinal vessel segmentation;inter-observer problem;skeleton maps;pixel-to-pixel matching strategy;skeleton segment;reference skeleton map;searching range;vessel thickness;source skeleton map;similarity calculation;curve similarity;structural similarity;thickness similarity;vessel segmentation maps;evaluation metrics","Databases, Factual;Diagnostic Techniques, Ophthalmological;Humans;Image Processing, Computer-Assisted;Retinal Vessels","6","32","","","","","IEEE","IEEE Journals"
"Domain Adaptation Network Based on Autoencoder","X. WANG; Y. MA; Y. CHENG","China University of Mining and Technology, China; China University of Mining and Technology, China; China University of Mining and Technology, China","Chinese Journal of Electronics","","2018","27","6","1258","1264","The domain adaptation uses labeled source domain data to train a classifier to be used in the target domain with no or small amount of labeled data. Usually there exists discrepancy in terms of marginal and conditional distributions for both source and target domains, which is of critical importance to minimize the distribution discrepancy between domains. As a classical model in deep learning, the autoencoder is capable of realizing distribution matching and enhancing classification accuracy by extracting more abstract and effective features from data. A Domain adaptation network based on autoencoder (DANA) is proposed. The DANA structure consists of a couple of encoding layers: a feature extraction layer and a classification layer. For the feature extraction layer, the marginal distributions of source and target domains are matched by using the nonparametric maximum mean discrepancy measurement. For the classification layer, the softmax regression model is applied to encode the label information of source domains meanwhile to match the conditional distribution. Experimental results on ImageNet, Corel and Leaves datasets have shown the enhanced classification accuracy by our proposed algorithm compared with the classical methods.","","","10.1049/cje.2018.09.001","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8543907","","","feature extraction;image classification;learning (artificial intelligence);pattern classification;regression analysis","distribution discrepancy;autoencoder;distribution matching;enhancing classification accuracy;abstract features;effective features;Domain adaptation network;encoding layers;feature extraction layer;classification layer;marginal distributions;target domains;conditional distribution;enhanced classification accuracy;source domain data;target domain;conditional distributions","","","","","","","","IET","IET Journals"
"From Eyes to Face Synthesis: a New Approach for Human-Centered Smart Surveillance","X. Chen; L. Qing; X. He; J. Su; Y. Peng","College of Electronics and Information Engineering, Sichuan University, Chengdu, China; College of Electronics and Information Engineering, Sichuan University, Chengdu, China; College of Electronics and Information Engineering, Sichuan University, Chengdu, China; College of Electronics and Information Engineering, Sichuan University, Chengdu, China; Faculty of Computer Science, University of Sunderland, Sunderland, U.K.","IEEE Access","","2018","6","","14567","14575","With the popularity of surveillance cameras and the development of deep learning, significant progress has been made in the field of smart surveillance. Face recognition is one of the most important yet challenging tasks in human-centered smart surveillance, especially in public security, criminal investigation and anti-terrorism, and so on. Although, the state-of-the-art algorithms for face recognition have achieved dramatically improved results and have been widely applied in authentication scenario, the occlusion problem on face is still one of the critical issues for personal identification in smart surveillance, especially in the occasion of terrorist searching and identification. To address this issue, this paper proposed a new approach for eyes-to-face synthesis and personal identification for human-centered smart surveillance. An end-toend network based on conditional generative adversarial networks (GAN) is designed to generate the face information based only on the available data of eyes region. To obtain photorealistic faces and identitypreserving information, a synthesis loss function based on feature loss, GAN loss, and total variation loss is proposed to guide the training process. Both the subject and objective experimental results demonstrated that the proposed method can preserve the identity based on eyes-only data, and provide a potential solution for the identification of person even in the case of face occlusion.","","","10.1109/ACCESS.2018.2803787","National Natural Science Foundation of China; Chengdu Science and Technology Project; Scientific Research Project of Sichuan Education Department; Technology Program of Public Wellbeing of Chengdu; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8286933","Face synthesis;Face recognition;conditional GAN;smart surveillance;video surveillance;image generation","Face;Surveillance;Face recognition;Generators;Task analysis;Gallium nitride;Training","face recognition;learning (artificial intelligence);terrorism;video surveillance","eyes-to-face synthesis;personal identification;human-centered smart surveillance;face information;photorealistic faces;synthesis loss function;face occlusion;surveillance cameras;face recognition;criminal investigation;anti-terrorism;terrorist searching;identity preserving information;end-to-end network;conditional generative adversarial networks;feature loss;GAN loss","","","32","","","","","IEEE","IEEE Journals"
"Optimized Wishart Network for an Efficient Classification of Multifrequency PolSAR Data","T. Gadhiya; A. K. Roy","Dhirubhai Ambani Institute of Information and Communication Technology, Gandhinagar, India; Dhirubhai Ambani Institute of Information and Communication Technology, Gandhinagar, India","IEEE Geoscience and Remote Sensing Letters","","2018","15","11","1720","1724","High-resolution wide-area images are required in the diverse field of research ranging from urban planning and disaster prediction to agriculture and geology. Sometimes the image is taken under harsh weather conditions or at night time. Current optical remote sensing technology does not have the capability to acquire images in such conditions. Synthetic aperture radar (SAR) uses microwave signal which has a long-range propagation characteristic that allows us to capture images in difficult weather conditions. In addition to this, some polarimetric SAR (PolSAR) systems are also capable of capturing images using multifrequency bands simultaneously resulting into a multitude of information in comparison to the optical images. In this letter, we propose a single-hidden layer optimized Wishart network (OWN) and extended OWN for classification of the single-frequency and multifrequancy PolSAR data, respectively. Performance evaluation is conducted on a single-frequency as well as multifrequency SAR data obtained by Airborne Synthetic Aperture Radar. We observed that for combining multiple band information, proposed single-hidden layer network outperforms deep learning-based architecture involving multiple hidden layers.","","","10.1109/LGRS.2018.2861081","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8443088","k-means algorithm;multifrequency polarimetric synthetic aperture radar (PolSAR) image classification;neural network;optimized Wishart network (OWN);PolSAR;Wishart distance;WN","Synthetic aperture radar;Integrated circuits;Training;Adaptive optics;Optical imaging;Microwave imaging;Neural networks","disasters;geophysical techniques;learning (artificial intelligence);optical images;radar imaging;radar polarimetry;remote sensing by radar;synthetic aperture radar","optimized wishart network;efficient classification;multifrequency polsar data;high-resolution wide-area images;urban planning;disaster prediction;agriculture;night time;microwave signal;long-range propagation characteristic;polarimetric SAR systems;multifrequency bands;optical images;multifrequency SAR data;multiple band information;multiple hidden layers;optical remote sensing technology;weather conditions;airborne synthetic aperture radar;single-hidden layer network","","2","13","","","","","IEEE","IEEE Journals"
"Natural Language Description of Video Streams Using Task-Specific Feature Encoding","A. Dilawari; M. U. G. Khan; A. Farooq; Z. Rehman; S. Rho; I. Mehmood","Department of Computer Science and Engineering, University of Engineering & Technology at Lahore, Lahore, Pakistan; Department of Computer Science and Engineering, University of Engineering & Technology at Lahore, Lahore, Pakistan; Al-Khawarizmi Institute of Computer Science, University of Engineering & Technology at Lahore, Lahore, Pakistan; COMSATS Institute of Information Technology Attock, Attock, Pakistan; Department of Media Software, Sungkyul University, Anyang, South Korea; Department of Software, Sejong University, Seoul, South Korea","IEEE Access","","2018","6","","16639","16645","In recent years, deep learning approaches have gained great attention due to their superior performance and the availability of high speed computing resources. These approaches are also extended towards the real time processing of multimedia content exploiting its spatial and temporal structure. In this paper, we propose a deep learning-based video description framework which first extracts visual features from video frames using deep convolutional neural networks (CNN) and then pass the derived representations into a long-short term memory-based language model. In order to capture accurate information for human presence, a fine-tuned multi-task CNN is presented. The proposed pipeline is end-to-end, trainable, and capable of learning dense visual features along with an accurate framework for the generation of natural language descriptions of video streams. The evaluation is done by calculating Metric for Evaluation of Translation with Explicit ORdering and Recall-Oriented Understudy for Gisting Evaluation (ROUGE) scores between system generated and human annotated video descriptions for a carefully designed data set. The video descriptions generated by the traditional feature learning and proposed deep learning frameworks are also compared through the ROUGE scores.","","","10.1109/ACCESS.2018.2814075","Basic Science Research Program through the National Research Foundation of Korea (NRF); Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8319487","Convolutional neural network;encoder-decoder;LSTM;natural language generation;TRECVid 2007/2008;video description;video to text","Natural languages;Streaming media;Task analysis;Encoding","","","","2","21","","","","","IEEE","IEEE Journals"
"Convolutional Neural Networks for Noniterative Reconstruction of Compressively Sensed Images","S. Lohit; K. Kulkarni; R. Kerviche; P. Turaga; A. Ashok","Department of Electrical, Computer and Energy Engineering, Arizona State University, Tempe, AZ, USA; Department of Arts, Media and Engineering, Arizona State University, Tempe, AZ, USA; Apple Inc., College of Optical Sciences, University of Arizona, Tucson, AZ, USA; School of Arts, Media and Engineering, Arizona State University, Tempe, AZ, USA; College of Optical Sciences, University of Arizona, Tucson, AZ, USA","IEEE Transactions on Computational Imaging","","2018","4","3","326","340","Traditional algorithms for compressive sensing recovery are computationally expensive and are ineffective at low measurement rates. In this paper, we propose a data-driven noniterative algorithm to overcome the shortcomings of earlier iterative algorithms. Our solution, ReconNet, is a deep neural network, which is learned end-to-end to map block-wise compressive measurements of the scene to the desired image blocks. Reconstruction of an image becomes a simple forward pass through the network and can be done in real time. We show empirically that our algorithm yields reconstructions with higher peak signal-to-noise ratios (PSNRs) compared to iterative algorithms at low measurement rates and in presence of measurement noise. We also propose a variant of ReconNet, which uses adversarial loss in order to further improve reconstruction quality. We discuss how adding a fully connected layer to the existing ReconNet architecture allows for jointly learning the measurement matrix and the reconstruction algorithm in a single network. Experiments on real data obtained from a block compressive imager show that our networks are robust to unseen sensor noise.","","","10.1109/TCI.2018.2846413","ARO; Army STTR; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8379450","Compressive sensing;convolutional neural network;generative adversarial network","Image reconstruction;Image coding;Imaging;Loss measurement;Compressed sensing;Neural networks;Noise measurement","compressed sensing;convolution;feedforward neural nets;image reconstruction;matrix algebra","peak signal-to-noise ratios;measurement noise;reconstruction quality;measurement matrix;convolutional neural networks;noniterative reconstruction;compressive sensing recovery;data-driven noniterative algorithm;deep neural network;image blocks;ReconNet architecture;block compressive imager;block-wise compressive measurements;Compressively Sensed Images","","2","57","","","","","IEEE","IEEE Journals"
"Mouse face tracking using convolutional neural networks","İ. B. Akkaya; U. Halici","Middle East Technical University, Turkey; Middle East Technical University, Turkey","IET Computer Vision","","2018","12","2","153","161","Facial expressions of laboratory mice provide important information for pain assessment to explore the effect of drugs being developed for medical purposes. For automatic pain assessment, a mouse face tracker is needed to extract the face regions in videos recorded in pain experiments. However, since the body and face of mice are the same colour and mice move fast, tracking their face is a challenging task. In recent years, with their ability to learn from data, deep learning provides effective solutions for a wide variety of problems. In particular, convolutional neural networks (CNNs) are very successful in computer vision tasks. In this study, a CNN based tracker network called MFTN is proposed for mouse face tracking. CNNs are good at extracting hierarchical features from the training dataset. High-level features contain semantic features and low-level features have high spatial resolution. In the proposed MFTN architecture, target information is extracted from a combination of low- and high-level features by a sub-network, namely the Feature Adaptation Network (FAN), to achieve a robust and accurate tracker. Among the MFTN versions, the MFTN/c tracker achieved an accuracy of 0.8, robustness of 0.67, and a throughput of 213 fps on a workstation with GPU.","","","10.1049/iet-cvi.2017.0084","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8306413","","","computer vision;emotion recognition;face recognition;feature extraction;feedforward neural nets;image colour analysis;medical image processing;object tracking","graphics processing unit;feature adaptation network;high spatial resolution;low-level features;high-level features;semantic features;training dataset;hierarchical feature extraction;MFTN architecture;CNN-based tracker network;computer vision tasks;CNN;deep neural networks;training datasets;medical purposes;pain assessment;facial expressions;biomedical studies;laboratory mice;convolutional neural networks;mouse face tracking network","","","28","","","","","IET","IET Journals"
"Road Extraction From a High Spatial Resolution Remote Sensing Image Based on Richer Convolutional Features","Z. Hong; D. Ming; K. Zhou; Y. Guo; T. Lu","School of Information Engineering, China University of Geosciences, Beijing, China; School of Information Engineering, China University of Geosciences, Beijing, China; School of Information Engineering, China University of Geosciences, Beijing, China; School of Information Engineering, China University of Geosciences, Beijing, China; School of Information Engineering, China University of Geosciences, Beijing, China","IEEE Access","","2018","6","","46988","47000","The extraction and vectorization of roads from high spatial resolution remote sensing (HSRRS) images are of great significance to city planning and development. However, significant as they are, it is usually an arduous task to put them into practice because the HSRRS images are often filled with complex ground information. Furthermore, extracted roads may suffer from netsplit or brokenness. This paper thus proposes Richer convolutional features (RCFs)-based road extraction (Road-RCF) as a method which targets these issues. A modified roads sample set and RCF network are applied to generate road probabilities in order to extract initial road information. After the road centerlines extraction by the refinement algorithm, vectorized roads are ultimately extracted. The compared experiment results show that the Road-RCF method produce better road extraction results than the other four state-of-the-art methods, in both quantitative road extraction accuracy metrics and the qualitative visual evaluation. The benefits of this model are threefold. First, the image-to-image network structure of side-output realizes multi-scale and multi-level road feature fusion in order to make a full use of the information from a low level to a high level. Second, according to the deep supervision of the side-output, it guides the learning of the correct road information. Third, after the detection of the road, the road centerlines are vectorized to facilitate the attribute information management and electronic map production. In a word, the proposed Road-RCF method is both practical and meaningful toward updating the geo-information system database.","","","10.1109/ACCESS.2018.2867210","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; National Key Research and Development Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8447193","High spatial resolution remote sensing images;Richer convolutional features;road detection;road centerlines extraction and vectorization","Roads;Feature extraction;Data mining;Remote sensing;Training;Machine learning;Image edge detection","feature extraction;geographic information systems;geophysical image processing;image resolution;probability;remote sensing;roads","image-to-image network structure;high spatial resolution remote sensing image;city planning;HSRRS images;complex ground information;RCF network;road probabilities;road centerlines extraction;quantitative road extraction accuracy metrics;road information extraction;road-RCF method;richer convolutional features-based road extraction;refinement algorithm;vectorized roads extraction;qualitative visual evaluation;multilevel road feature fusion;multiscale road feature fusion;attribute information management;electronic map production;geo-information system database","","4","77","","","","","IEEE","IEEE Journals"
"An Iterative BP-CNN Architecture for Channel Decoding","F. Liang; C. Shen; F. Wu","Laboratory of Future Networks, School of Information Science and Technology, University of Science and Technology of China, Hefei, China; Laboratory of Future Networks, School of Information Science and Technology, University of Science and Technology of China, Hefei, China; Laboratory of Future Networks, School of Information Science and Technology, University of Science and Technology of China, Hefei, China","IEEE Journal of Selected Topics in Signal Processing","","2018","12","1","144","159","Inspired by the recent advances in deep learning, we propose a novel iterative belief propagation - convolutional neural network (BP-CNN) architecture for channel decoding under correlated noise. This architecture concatenates a trained CNN with a standard BP decoder. The standard BP decoder is used to estimate the coded bits, followed by a CNN to remove the estimation errors of the BP decoder and obtain a more accurate estimation of the channel noise. Iterating between BP and CNN will gradually improve the decoding SNR and, hence, result in better decoding performance. To train a well-behaved CNN model, we define a new loss function that involves not only the accuracy of the noise estimation but also the normality test for the estimation errors, i.e., to measure how likely the estimation errors follow a Gaussian distribution. The introduction of the normality test to the CNN training shapes the residual noise distribution and further reduces the bit error rate of the iterative decoding, compared to using the standard quadratic loss function. We carry out extensive experiments to analyze and verify the proposed framework.11Code is available at https://github.com/liangfei-info/Iterative-BP-CNN.","","","10.1109/JSTSP.2018.2794062","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8259241","Belief propagation;channel coding;neural networks","Iterative decoding;Decoding;Machine learning;Correlation;Computer architecture;Training","approximation theory;backpropagation;channel coding;error statistics;feedforward neural nets;Gaussian distribution;iterative decoding;telecommunication computing","Iterative BP-CNN architecture;channel decoding;correlated noise;trained CNN;standard BP decoder;decoding SNR;decoding performance;CNN model;noise estimation;normality test;CNN training;residual noise distribution;bit error rate;iterative decoding;standard quadratic loss function;Gaussian distribution;loss function;coded bits estimation;iterative belief propagation-convolutional neural network architecture;channel noise estimation","","31","44","","","","","IEEE","IEEE Journals"
"A Survey of Graph Cuts/Graph Search Based Medical Image Segmentation","X. Chen; L. Pan","School of Electronic and Information Engineering, Soochow University, Suzhou, China; School of Electronic and Information Engineering, Soochow University, Suzhou, China","IEEE Reviews in Biomedical Engineering","","2018","11","","112","124","Medical image segmentation is a fundamental and challenging problem for analyzing medical images. Among different existing medical image segmentation methods, graph-based approaches are relatively new and show good features in clinical applications. In the graph-based method, pixels or regions in the original image are interpreted into nodes in a graph. By considering Markov random field to model the contexture information of the image, the medical image segmentation problem can be transformed into a graph-based energy minimization problem. This problem can be solved by the use of minimum s-t cut/ maximum flow algorithm. This review is devoted to cut-based medical segmentation methods, including graph cuts and graph search for region and surface segmentation. Different varieties of cut-based methods, including graph-cuts-based methods, model integrated graph cuts methods, graph-search-based methods, and graph search/graph cuts based methods, are systematically reviewed. Graph cuts and graph search with deep learning technique are also discussed.","","","10.1109/RBME.2018.2798701","National Basic Research Program (973), in part by the Young Scientist Program Foundation of China; National Nature Science Foundation of China for Excellent Young Scholars; National Natural Science Foundation of China; Natural Science Foundation of the Jiangsu Province; Natural Science Foundation for colleges and universities of the Jiangsu Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8270593","Graph cuts (GCs);graph search (GS);medical image;segmentation","Image segmentation;Medical diagnostic imaging;Image edge detection;Shape;Minimization;Machine learning","graph theory;image resolution;image segmentation;Markov processes;medical image processing;minimisation","medical segmentation methods;surface segmentation;graph-cuts-based methods;model integrated graph cuts methods;graph-search-based methods;fundamental problem;medical images;graph-based approaches;pixels;regions;original image;medical image segmentation problem;graph-based energy minimization problem;minimum s-t cut;graph search;medical image segmentation methods","Algorithms;Humans;Image Interpretation, Computer-Assisted","4","140","","","","","IEEE","IEEE Journals"
"Human Action Recognition Based on Selected Spatio-Temporal Features via Bidirectional LSTM","W. Li; W. Nie; Y. Su","School of Electrical and Information Engineering, Tianjin University, Tianjin, China; School of Electrical and Information Engineering, Tianjin University, Tianjin, China; School of Electrical and Information Engineering, Tianjin University, Tianjin, China","IEEE Access","","2018","6","","44211","44220","Recently, many deep convolutional networks approaches have been proposed for human action recognition. The challenge is to capture complementary information from still and motion frames. In contrast to previous models, which use holistic clips to model spatial information and traditional temporal information for sequential processing, in this paper, we propose a novel framework that can select the discriminative part in the spatial dimension and enrich the modeling action of motion in the temporal dimension. We utilize part selection within clips and consider the bidirectional temporal information when modeling the temporal pattern using multiple layers of a long short-term memory framework, which can learn compositional representations in space and time. Our results are evaluated on the standard benchmarks UCF101 and HMDB51 and show that the proposed architecture achieves state-of-the-art results.","","","10.1109/ACCESS.2018.2863943","National Natural Science Foundation of China; Tianjin Research Program of Application Foundation and Advanced Technology; Tianjin University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8434092","Spatio-temporal part selection;LSTM;human action recognition","Videos;Feature extraction;Spatiotemporal phenomena;Convolution;Three-dimensional displays;Task analysis;Two dimensional displays","feature extraction;image motion analysis;image recognition;image representation;image sequences;video signal processing","short-term memory framework;human action recognition;bidirectional LSTM;complementary information;motion frames;holistic clips;spatial information;traditional temporal information;sequential processing;spatial dimension;temporal dimension;bidirectional temporal information;temporal pattern;spatio-temporal features;deep convolutional networks;HMDB51 standard benchmark;UCF101 standard benchmark","","1","46","","","","","IEEE","IEEE Journals"
"Partial reinforcement in game biofeedback for relaxation training","A. Parnandi; R. Gutierrez-Osuna","Neurology, NYU Langone Health, 12297 New York, New York United States (e-mail: avinash.parnandi@nyumc.org); Computer Science and Engineering, Texas A&M University, College Station, Texas United States 77840 (e-mail: rgutier@cse.tamu.edu)","IEEE Transactions on Affective Computing","","2018","PP","99","1","1","This paper investigates the effect of reinforcement schedules on biofeedback games for stress self-regulation. In particular, it examines whether partial reinforcement can improve resistance to extinction of relaxation behaviors, i.e., once biofeedback is removed. Namely, we compare two types of reinforcement schedules (partial and continuous) in a mobile biofeedback game that encourages players to slow their breathing during gameplay. The game uses a negative-reinforcement instrumental conditioning paradigm, removing an aversive stimulus (random actions in the game) if players slows down their breathing. We conducted an experimental trial with 24 participants to compare the two reinforcement schedules against a control condition. Our results indicate that partial reinforcement improves resistance to extinction, as measured by breathing rate and skin conductance post-treatment. In addition, based on slope and correlation analysis we found that participants in the partial reinforcement learned to slow their breathing at the same pace as those under continuous reinforcement. The article discusses the implications of these results and directions for future work.","","","10.1109/TAFFC.2018.2842727","Qatar National Research Fund a member of Qatar Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8400398","Biofeedback games;deep breathing;games for health;partial reinforcement;resistance to extinction;skill transfer;stress;video games;wearable sensors","Biological control systems;Games;Stress;Training;Heart rate;Schedules;Task analysis","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"An Unsupervised Game-Theoretic Approach to Saliency Detection","Y. Zeng; M. Feng; H. Lu; G. Yang; A. Borji","School of Information and Communication Engineering, Dalian University of Technology, Dalian, China; School of Information and Communication Engineering, Dalian University of Technology, Dalian, China; School of Information and Communication Engineering, Dalian University of Technology, Dalian, China; College of Information Science and Engineering, Northeastern University, Shenyang, China; Center for Research in Computer Vision and the Computer Science Department, University of Central Florida, Orlando, FL, USA","IEEE Transactions on Image Processing","","2018","27","9","4545","4554","We propose a novel unsupervised game-theoretic salient object detection algorithm that does not require labeled training data. First, saliency detection problem is formulated as a non-cooperative game, hereinafter referred to as Saliency Game, in which image regions are players who choose to be “background” or “foreground” as their pure strategies. A payoff function is constructed by exploiting multiple cues and combining complementary features. Saliency maps are generated according to each region's strategy in the Nash equilibrium of the proposed Saliency Game. Second, we explore the complementary relationship between color and deep features and propose an iterative random walk algorithm to combine saliency maps produced by the Saliency Game using different features. Iterative random walk allows sharing information across feature spaces, and detecting objects that are otherwise very hard to detect. Extensive experiments over six challenging data sets demonstrate the superiority of our proposed unsupervised algorithm compared with several state-of-the-art supervised algorithms.","","","10.1109/TIP.2018.2838761","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8361890","Saliency;salient object detection;visual attention","Games;Feature extraction;Saliency detection;Image color analysis;Extraterrestrial measurements;Iterative algorithms;Neural networks","game theory;learning (artificial intelligence);object detection","unsupervised Game-theoretic approach;labeled training data;Saliency Game;multiple cues;saliency maps;iterative random walk algorithm;unsupervised algorithm;salient object detection algorithm;complementary features;feature spaces","","","41","","","","","IEEE","IEEE Journals"
"Real-Time Continuous Action Recognition Using Pose Contexts With Depth Sensors","H. Wu; Z. Huang; B. Hu; Z. Yu; X. Li; M. Gao; Z. Shen","Department of Computer Science, Guangdong Key Laboratory of Big Data Analysis and Processing, Sun Yat-sen University, Guangzhou, China; Department of Computer Science, Guangdong Key Laboratory of Big Data Analysis and Processing, Sun Yat-sen University, Guangzhou, China; Department of Computer Science, Guangdong Key Laboratory of Big Data Analysis and Processing, Sun Yat-sen University, Guangzhou, China; School of Intelligent Systems Engineering, Sun Yat-sen University, Guangzhou, China; School of Intelligent Systems Engineering, Sun Yat-sen University, Guangzhou, China; Guangzhou HKUST Fok Ying Tung Research Institute, Guangzhou, China; Guangzhou HKUST Fok Ying Tung Research Institute, Guangzhou, China","IEEE Access","","2018","6","","51708","51720","We present an efficient approach for real-time continuous human action recognition with depth sensors. Instead of using the powerful but quite complex deep neural networks, our approach uses a lightweight discriminative frame-level descriptor, which is called the context pose (CP). The objective is to make our approach realistic in mobile depth sensor applications. CP integrates the context of the motion within a depth video. CP can increase the discriminative power of the frames and enable more frames to represent actions. CP is incorporated with a new part-based random decision forest (PRDF) method. The PRDF is designed to automatically select the optimal combination of body parts to represent and distinguish each action. We evaluate our approach on three classical single-action benchmark datasets. The experiments show that our approach has 200 frames/s and wins superior performances to the existing frame-level descriptors and classifiers in terms of accuracy.","","","10.1109/ACCESS.2018.2869330","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8458115","Depth sensor;sensor systems and applications;pattern recognition","Real-time systems;Forestry;Sensors;Skeleton;Three-dimensional displays;Hidden Markov models;Neural networks","gesture recognition;image motion analysis;image representation;image sensors;learning (artificial intelligence);pose estimation;video signal processing","real-time continuous human action recognition;mobile depth sensor applications;depth video;part-based random decision forest method;PRDF;pose contexts;discriminative frame-level descriptor;action representation;single-action benchmark datasets","","","40","","","","","IEEE","IEEE Journals"
"Improved Boundary Equilibrium Generative Adversarial Networks","Y. Li; N. Xiao; W. Ouyang","School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; School of Electrical and Information Engineering, University of Sydney, Camperdown, NSW, Australia","IEEE Access","","2018","6","","11342","11348","Boundary equilibrium generative adversarial networks (BEGANs) can generate impressively realistic face images, but there is a trade-off between the quality and the diversity of generated images. Based on BEGANs, we propose an effective approach to generate images with higher quality and better diversity. By adding a second loss function (a denoising loss) to the discriminator, the discriminator can learn more useful information about the distribution of real images. Naturally, the ability of discriminator in distinguishing between real and generated images is improved, which further guides the generator to produce more realistic images to confuse the discriminator. We also find that using technique of batch normalization in BEGANs architecture can improve the diversity of generated images. By using batch normalization and adding a denoising loss to the objective of discriminator, we achieve comparative generations on CIFAR-10 and CelebA data sets. In addition, we evaluate the effect of several techniques on BEGANs framework through ""Inception-Score"", a measure which has been found to correlate well with human assessment of generated samples.","","","10.1109/ACCESS.2018.2804278","National Natural Science Foundation of China; Public Research and Capacity Building of Guangdong Province of China; Basic and Applied Basic Research of Guangdong Province of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8288664","Generative adversarial networks (GANs);boundary equilibrium generative adversarial networks (BEGANs);deep generative model;image generation","Noise reduction;Gallium nitride;Training;Generators;Face;Linear programming;Image generation","face recognition;image denoising;realistic images","realistic images;denoising loss;BEGANs;boundary equilibrium generative adversarial networks","","4","29","","","","","IEEE","IEEE Journals"
"Ensemble classifier-based off-line handwritten word recognition system in holistic approach","J. Das Gupta; S. Samanta; B. Chanda","Applied Optics and Photonics, University of Calcutta, India; University of Liverpool, UK; Electronics and Communication Sciences Unit, Indian Statistical Institute, India","IET Image Processing","","2018","12","8","1467","1474","This study presents a novel ensemble classifier-based off-line handwritten word recognition system following a holistic approach. Here each handwritten word is recognised using two handcrafted features, namely (i) Arnold transform-based feature that addresses local directional feature which depends on the stroke orientation distribution of cursive word and (ii) oriented curvature-based feature which is basically the histogram of curvelet index and one machine generated feature using deep convolution neural network (DCNN). In this study, a new architecture of DCNN is proposed for handwritten word recognition. These features are recognised by three classifiers separately. Finally, the decision of three classifiers is combined to predict the ultimate word class level. To fuse the decision of individual classifiers, the authors have explored three strategies: (i) vote for strongest decision, (ii) vote for majority decision and (iii) vote for the sum of the decisions. The proposed handwritten word recognition system is tested on three handwritten word databases: (i) CENPARMI database, (ii) IAM database and (iii) ISIHWD database. The performance of the proposed system is promising and comparable to state-of-the-art handwriting recognition systems.","","","10.1049/iet-ipr.2017.0745","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8423349","","","feature extraction;handwriting recognition;handwritten character recognition;image classification;learning (artificial intelligence);neural nets;pattern classification","off-line handwritten word recognition system;holistic approach;ensemble classifier;handcrafted features;addresses local directional feature;cursive word;machine generated feature;ultimate word class level;individual classifiers;handwritten word databases;state-of-the-art handwriting recognition systems","","","43","","","","","IET","IET Journals"
"Collaborative Neural Social Recommendation","L. Wu; P. Sun; R. Hong; Y. Ge; M. Wang","School of Computer and Information, Hefei University of Technology, Hefei 230009, China.; School of Computer and Information, Hefei University of Technology, Hefei 230009, China.; School of Computer and Information, Hefei University of Technology, Hefei 230009, China (e-mail: hongrc.hfut@gmail.com).; Department of Management Information Systems, University of Arizona, Tucson, AZ 85721 USA.; School of Computer and Information, Hefei University of Technology, Hefei 230009, China.","IEEE Transactions on Systems, Man, and Cybernetics: Systems","","2018","PP","99","1","13","Collaborative filtering (CF) is one of the most popular techniques for building recommender systems. To overcome the data sparsity in CF, social recommender systems have emerged to boost recommendation performance by utilizing social correlation among users' interests. Recently, inspired by the immense success of deep learning for embedding learning, neural network-based recommender systems have shown promising recommendation performance. Nevertheless, few researchers have attempted to tackle the social recommendation problem with neural models. To this end, in this paper, we design a neural architecture that organically combines the intrinsic relationship between social network structure and user-item interaction behavior for social recommendation. Two key challenges arise in this process: first, how to incorporate the social correlation of users' interests in this neural model, and second, how to design a neural architecture to capture the unique characteristics of user-item interaction behavior for recommendation. To tackle these two challenges, we develop a model named collaborative neural social recommendation (CNSR) with two parts: 1) a social embedding part and 2) a collaborative neural recommendation (CNR) part. In CNSR, the user embedding leverages each user's social embedding learned from an unsupervised deep learning technique with social correlation regularization. The user and item embeddings are then fed into a unique neural network with a newly designed collaboration layer to model both the shallow collaborative and deep complex interaction relationships between users and items. We further propose a joint learning framework to allow the social embedding part and the CNR part to mutually enhance each other. Finally, extensive experimental results on two real-world datasets clearly demonstrate the effectiveness of our proposed model.","","","10.1109/TSMC.2018.2872842","National Key Research and Development Program; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8514809","Neural recommendation;social correlation;social embedding;social recommendation","Collaboration;Social network services;Correlation;Recommender systems;Neural networks;Biological system modeling","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Action recognition from mutually incoherent pose bases in static image","Y. Qian; W. Chen; I. Shen","Fudan University, People's Republic of China; Fudan University, People's Republic of China; Fudan University, People's Republic of China","IET Computer Vision","","2018","12","3","233","240","Action recognition in static image is challenging. The authors propose mutually incoherent pose bases which are implicit poselet co-occurrences and are learned by dictionary training to describe body pose. Poselets in a pose basis are not constrained in space and quantity, thus pose basis can describe body pose more flexibly than k-poselet. In their method, body pose in an image is represented by a sparse linear combination of pose bases because pose in an action varies while each image only captures a snapshot from a single viewpoint. In dictionary training, the challenge is how to stabilise the sparse representation which is the input of Support Vector Machine (SVM) for action recognition, because the original pose signal is ambiguous while dictionary is an over complete matrix. Their solution is to add cumulative coherence as penalty in objective function and induce pose bases become mutually incoherent. They evaluate the method on two popular datasets and experiment results show the pose representation has encouraging performance in action recognition. Furthermore, they empirically exploit the complementary role of the local pose feature with deep convolutional neural network features from holistic image. Experiment results demonstrate aggressive performance improvement by concatenating the two features.","","","10.1049/iet-cvi.2017.0233","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8319330","","","image representation;matrix algebra;neural nets;pose estimation;support vector machines","action recognition;static image;mutually incoherent pose bases;implicit poselet co-occurrences;dictionary training;sparse linear pose bases combination;sparse representation;SVM;overcomplete matrix;cumulative coherence;objective function;pose representation;local pose feature;deep convolutional neural network features","","","45","","","","","IET","IET Journals"
"Background Subtraction Using Multiscale Fully Convolutional Network","D. Zeng; M. Zhu","Chinese Academy of Sciences, Changchun Institute of Optics, Fine Mechanics and Physics, Changchun, China; Chinese Academy of Sciences, Changchun Institute of Optics, Fine Mechanics and Physics, Changchun, China","IEEE Access","","2018","6","","16010","16021","Background modeling and subtraction based on change detection are the first step in many high-level computer vision applications. Many background subtraction methods have been proposed in the recent past and their efforts mainly focus on two aspects: more advanced background models and more complex feature representations. Recently, hierarchical features learned from deep convolutional neural networks have been shown to be effective for many computer vision tasks, such as classification and recognition. However, few researchers try to learn the deep features to address the background subtraction problem. Therefore, in this paper, we propose a novel multiscale fully convolutional network (MFCN) architecture which takes advantage of different layer features for background subtraction. We show that the foreground detection accuracy can be greatly improved by using the deep features learned from the MFCN and instead of building highly complex background models, and the complexity of the background subtraction process can be easily solved during the subtraction operation itself. Experimental results on CDnet 2014 data set and SBM-RGBD data set show that the proposed MFCN-based method achieves state-of-the-art performance while operating at real time.","","","10.1109/ACCESS.2018.2817129","National Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8319408","Background subtraction;convolutional neural network;multiscale fully convolutional network;video surveillance","Training;Adaptation models;Semantics;Computer vision;Convolutional neural networks;Computational modeling;Task analysis","","","","11","45","","","","","IEEE","IEEE Journals"
"Computer says no: But why?","C. Edwards","NA","Engineering & Technology","","2018","13","4","32","35","FROM THE DEPTHS of its winter in the 1990s and 2000s, machine learning has become the technology everyone wants to muscle in on. Xilinx is the latest large chipmaker to realign its business to technologies such as deep learning, driven by the thirst among large data-centre users to hoover up as much data as they can for analysis.","","","10.1049/et.2018.0402","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8720830","","","","","","","","","","","","IET","IET Journals"
"A Progressively Enhanced Network for Video Satellite Imagery Superresolution","K. Jiang; Z. Wang; P. Yi; J. Jiang","School of Computer Science, Wuhan University, Wuhan, China; School of Computer Science, Wuhan University, Wuhan, China; School of Computer Science, Wuhan University, Wuhan, China; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China","IEEE Signal Processing Letters","","2018","25","11","1630","1634","Deep convolutional neural networks (CNNs) have been extensively applied to image or video processing and analysis tasks. For single-image superresolution (SR) processing, previous CNN-based methods have led to significant improvements, when compared to the shallow learning-based methods. However, these CNN-based algorithms with simply direct or skip connections are not suitable for satellite imagery SR because of complex imaging conditions and unknown degradation process. More importantly, they ignore the extraction and utilization of the structural information in satellite images, which is very unfavorable for video satellite imagery SR with such characteristics as small ground targets, weak textures, and over-compression distortion. To this end, this letter proposes a novel progressively enhanced network for satellite image SR called PECNN, which is composed of a pretraining CNN-based network and an enhanced dense connection network. The pretraining part is used to extract the low-level feature maps and reconstructs a basic high-resolution image from the low-resolution input. In particular, we propose a transition unit to obtain the structural information from the base output. Then, the obtained structural information and the extracted low-level feature maps are transmitted to the enhanced network for further extraction to enforce the feature expression. Finally, a residual image with enhanced fine details obtained from the dense connection network is used to enrich the basic image for the ultimate SR output. Experiments on real-world Jilin-1 video satellite images and Kaggle Open Source Dataset show that the proposed PECNN outperforms the state-of-the-art methods both in visual effects and quantitative metrics. Code is available at https://github.com/kuihua/PECNN.","","","10.1109/LSP.2018.2870536","National Natural Science Foundation of China; Hubei Technological Innovation Special Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8466642","Dense connection;residual network;superresolution;subpixel convolution;video satellite imagery","Feature extraction;Satellites;Image resolution;Data mining;Convolution;Training;Imaging","cellular neural nets;convolution;feature extraction;feedforward neural nets;geophysical image processing;image enhancement;image reconstruction;image resolution;image texture","video satellite imagery superresolution;convolutional neural networks;single-image superresolution processing;video satellite imagery SR;basic high-resolution image;real-world Jilin-1 video satellite images;shallow learning;CNN;progressively enhanced network for satellite image SR;PECNN;dense connection network enhancement;Kaggle Open Source Dataset;low-level feature map extraction","","4","33","","","","","IEEE","IEEE Journals"
"CaricatureShop: Personalized and Photorealistic Caricature Sketching","X. Han; K. Hou; D. Du; Y. Qiu; S. Cui; K. Zhou; Y. Yu","Department of Computer Science, The University of Hong Kong, Hong Kong, Hong Kong China (e-mail: hanxiaoguang@cuhk.edu.cn); Computer Science, Zhejiang University, Hangzhou, Zhejiang China (e-mail: kangchenghou@gmail.com); School of Mathematical Sciences, University of Science and Technology of China, Hefei, Anhui China 230026 (e-mail: dongdu@mail.ustc.edu.cn); Computer Science, the Chinese University of Hong Kong, Shenzhen, Shenzhen, Guangdong China (e-mail: qiuyuda@cuhk.edu.cn); Electrical and Computer Engineering, University of California Davis, 8789 Davis, California United States (e-mail: sgcui@ucdavis.edu); State Key Lab of CAD&CG, Zhejiang University, Hangzhou, Zhejiang China (e-mail: kunzhou@acm.org); Dept. of Computer Science, The University of Hong Kong, Pokfulam, Hong Kong Hong Kong (e-mail: yizhouy@acm.org)","IEEE Transactions on Visualization and Computer Graphics","","2018","PP","99","1","1","In this paper, we propose the first sketching system for interactively personalized and photorealistic face caricaturing. Input an image of a human face, the users can create caricature photos by manipulating its facial feature curves. Our system firstly performs exaggeration on the recovered 3D face model, which is conducted by assigning the laplacian of each vertex a scaling factor according to the edited sketches. The mapping between 2D sketches and the vertex-wise scaling field is constructed by a novel deep learning architecture. Our approach allows outputting different exaggerations when applying the same sketching on different input figures in term of their different geometric characteristics, which makes the generated results ""personalized"". With the obtained 3D caricature model, two images are generated, one obtained by applying 2D warping guided by the underlying 3D mesh deformation and the other obtained by re-rendering the deformed 3D textured model. These two images are then seamlessly integrated to produce our final output. Due to the severe stretching of meshes, the rendered texture is of blurry appearances. A deep learning approach is exploited to infer the missing details for enhancing these blurry regions. Moreover, a relighting operation is invented to further improve the photorealism of the result. These further make our results ""photorealistic"". The qualitative experiment results validated the efficiency of our sketching system.","","","10.1109/TVCG.2018.2886007","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8580421","photorealistic caricature;sketch-based face exaggeration;facial details enhancing","Face;Three-dimensional displays;Solid modeling;Two dimensional displays;Strain;Deformable models","","","","","","","","","","IEEE","IEEE Early Access Articles"
"MHTN: Modal-Adversarial Hybrid Transfer Network for Cross-Modal Retrieval","X. Huang; Y. Peng; M. Yuan","Institute of Computer Science and Technology, Peking University, Beijing 100871, China.; Institute of Computer Science and Technology, Peking University, Beijing 100871, China (e-mail: pengyuxin@pku.edu.cn).; Institute of Computer Science and Technology, Peking University, Beijing 100871, China.","IEEE Transactions on Cybernetics","","2018","PP","99","1","13","Cross-modal retrieval has drawn wide interest for retrieval across different modalities (such as text, image, video, audio, and 3-D model). However, existing methods based on a deep neural network often face the challenge of insufficient cross-modal training data, which limits the training effectiveness and easily leads to overfitting. Transfer learning is usually adopted for relieving the problem of insufficient training data, but it mainly focuses on knowledge transfer only from large-scale datasets as a single-modal source domain (such as ImageNet) to a single-modal target domain. In fact, such large-scale single-modal datasets also contain rich modal-independent semantic knowledge that can be shared across different modalities. Besides, large-scale cross-modal datasets are very labor-consuming to collect and label, so it is significant to fully exploit the knowledge in single-modal datasets for boosting cross-modal retrieval. To achieve the above goal, this paper proposes a modal-adversarial hybrid transfer network (MHTN), which aims to realize knowledge transfer from a single-modal source domain to a cross-modal target domain and learn cross-modal common representation. It is an end-to-end architecture with two subnetworks. First, a modal-sharing knowledge transfer subnetwork is proposed to jointly transfer knowledge from a single modality in the source domain to all modalities in the target domain with a star network structure, which distills modal-independent supplementary knowledge for promoting cross-modal common representation learning. Second, a modal-adversarial semantic learning subnetwork is proposed to construct an adversarial training mechanism between the common representation generator and modality discriminator, making the common representation discriminative for semantics but indiscriminative for modalities to enhance cross-modal semantic consistency during the transfer process. Comprehensive experiments on four widely used datasets show the effectiveness of MHTN.","","","10.1109/TCYB.2018.2879846","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8563047","Adversarial training;cross-modal retrieval;hybrid transfer network;knowledge transfer;modal-adversarial.","Semantics;Training data;Knowledge transfer;Training;Correlation;Task analysis;Solid modeling","","","","2","","","","","","IEEE","IEEE Early Access Articles"
"Integrating Scene Text and Visual Appearance for Fine-Grained Image Classification","X. Bai; M. Yang; P. Lyu; Y. Xu; J. Luo","School of Electronics Information and Communications, Huazhong University of Science and Technology, Wuhan, China; School of Electronics Information and Communications, Huazhong University of Science and Technology, Wuhan, China; School of Electronics Information and Communications, Huazhong University of Science and Technology, Wuhan, China; School of Electronics Information and Communications, Huazhong University of Science and Technology, Wuhan, China; Department of Computer Science, University of Rochester, Rochester, NY, USA","IEEE Access","","2018","6","","66322","66335","Text in natural images contains rich semantics that is often highly relevant to objects or scene. In this paper, we focus on the problem of fully exploiting scene text for visual understanding. The main idea is combining word representations and deep visual features in a globally trainable deep convolutional neural network. First, the recognized words are obtained by a scene text reading system. Next, we combine the word embedding of the recognized words and the deep visual features into a single representation that is optimized by a convolutional neural network for fine-grained image classification. In our framework, the attention mechanism is adopted to compute the relevance between each recognized word and the given image, which further enhances the recognition performance. We have performed experiments on two datasets: con-text dataset and drink bottle dataset, which are proposed for fine-grained classification of business places and drink bottles, respectively. The experimental results consistently demonstrate that the proposed method of combining textual and visual cues significantly outperforms classification with only visual representation. Moreover, we have shown that the learned representation improves the retrieval performance on the drink bottle images by a large margin, making it potentially powerful in product search.","","","10.1109/ACCESS.2018.2878899","National Key Research and Development Program of China; National Natural Science Foundation of China; Natural Science Foundation of Hubei Province; National Program for Support of Top-Notch Young Professionals; Program for HUST Academic Frontier Youth Team; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8517130","Scene text;fine-grained classification;convolutional neural networks;attention mechanism;product search","Visualization;Image recognition;Text recognition;Semantics;Feature extraction;Convolutional neural networks;Business","","","","3","89","","","","","IEEE","IEEE Journals"
"Saliency-aware Texture Smoothing","L. Zhu; X. Hu; C. Fu; J. Qin; P. Heng","Computer Science and Engineering, Chinese University of Hong Kong, 26451 Hong Kong, Hong Kong Hong Kong (e-mail: lzhu@cse.cuhk.edu.hk); 1Department of Computer Science and Engineering, The Chinese University of Hong Kong, Shatin, N.T. Hong Kong (e-mail: xwhu@cse.cuhk.edu.hk); Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, Hong Kong Hong Kong SIN (e-mail: philip.chiwing.fu@gmail.com); Nursing, Hong Kong Polytechnic University, 26680 Kowloon, Hong Kong Hong Kong (e-mail: harry.qin@polyu.edu.hk); Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, Hong Kong Hong Kong (e-mail: pheng@cse.cuhk.edu.hk)","IEEE Transactions on Visualization and Computer Graphics","","2018","PP","99","1","1","Texture smoothing aims to smooth out textures in images, while retaining the prominent structures. This paper presents a saliency-aware approach to the problem with two key contributions. First, we design a deep saliency network with guided non-local blocks (GNLBs) for learning long-range pixel dependencies by taking the predicted saliency map at former layer as the guidance image to help suppress the non-saliency regions in the shallow layer. The GNLB computes the saliency response at a position by a weighted sum of features at all positions, and enables us to produce results that outperform existing deep saliency models. Second, we formulate a joint optimization framework to take saliency information when iteratively separating textures from structures: on the texture layer, we smooth out structures with the help of the saliency information and migrate structures from the texture to structure layer, while on the structure layer, we adopt another deep model to detect edges and simultaneous sparse coding to push textures back to the texture layer. We tested our method on a rich variety of images and compared it with several state-of-the-art methods. Both visual and quantitative comparison results show that our method better preserves structures while removing the texture components.","","","10.1109/TVCG.2018.2889055","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8585158","","Smoothing methods;Image edge detection;Saliency detection;Optimization;Data models;Visualization;Semantics","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Capturing the Geometry of Object Categories from Video Supervision","D. Novotny; D. Larlus; A. Vedaldi","Engineering Science, University of Oxford, Oxford, Oxfordshire United Kingdom of Great Britain and Northern Ireland OX1 3PJ (e-mail: david@robots.ox.ac.uk); Computer Vision Group, Naver Labs Europe, 84341 Meylan, Auvergne-Rhône-Alpes France (e-mail: diane.larlus@naverlabs.com); Engineering Science, Oxford University, Oxford, Oxfordshire United Kingdom of Great Britain and Northern Ireland OX13PJ (e-mail: vedaldi@robots.ox.ac.uk)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","PP","99","1","1","In this article, we are interested in capturing the 3D geometry of object categories simply by looking around them. Our unsupervised method fundamentally departs from traditional approaches that require either CAD models or manual supervision. It only uses video sequences capturing a handful of instances of an object category to train a deep architecture tailored for extracting 3D geometry predictions. Our deep architecture has three components. First, a Siamese viewpoint factorization network robustly aligns the input videos and, as a consequence, learns to predict the absolute category-specific viewpoint from a single image depicting any previously unseen instance of that category. Second, a depth estimation network performs monocular depth prediction. Finally, a 3D shape completion network predicts the full shape of the depicted object instance by re-using the output of the monocular depth prediction module. We also propose a way to configure networks so they can perform probabilistic predictions. We demonstrate that, properly used in our framework, this self-assessment mechanism is crucial for obtaining high quality predictions. Our network achieves state-of-the-art results on viewpoint prediction, depth estimation, and 3D point cloud estimation on public benchmarks.","","","10.1109/TPAMI.2018.2871117","ERC; NAVER LABS Europe; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8468042","monocular pose estimation;monocular depth estimation;point-cloud estimation;geometry reconstruction","Three-dimensional displays;Geometry;Shape;Solid modeling;Estimation;Image reconstruction;Training","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Ship Classification in TerraSAR-X Images With Convolutional Neural Networks","C. Bentes; D. Velotto; B. Tings","Data Analysis, Software Technology and Application Center (STACC), Tartu, Tartumaa, Estonia; German Aerospace Center, Remote Sensing Technology Institute, Bremen, Germany; German Aerospace Center, Remote Sensing Technology Institute, Bremen, Germany","IEEE Journal of Oceanic Engineering","","2018","43","1","258","266","Synthetic aperture radar (SAR) is an important instrument for oceanographic observations, providing detailed information of oceans' surface and artificial floating structures. Due to advances in SAR technology and deployment of new SAR satellites, an increasing amount of data is available, and the development of efficient classification systems based on deep learning is possible. A deep neural network has improved the state of the art in classification tasks of optical images, but its use in SAR classification problems has been less exploited. In this paper, a full workflow for SAR maritime targets detection and classification on TerraSAR-X high-resolution image is presented, and convolutional neural networks (CNNs) recently proposed in the literature are cross evaluated on a common data set composed of five maritime classes, namely, cargo, tanker, windmill, platform, and harbor structure. Based on experiments and tests, a multiple input resolution CNN model is proposed and its performance is evaluated. Our results indicate that CNNs are efficient models to perform maritime target classification in SAR images, and the combination of different input resolutions in the CNN model improves its ability to derive features, increasing the overall classification score.","","","10.1109/JOE.2017.2767106","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8113469","Neural networks;object detection;synthetic aperture radar","Synthetic aperture radar;Marine vehicles;Neural networks;Oceans;Image resolution;Clutter;Feature extraction","image classification;neural nets;object detection;ships;synthetic aperture radar","ship classification;synthetic aperture radar;SAR maritime targets detection;TerraSAR-X high-resolution image classification;convolutional neural networks;maritime target classification","","10","44","","","","","IEEE","IEEE Journals"
"Non-Rigid 3D Model Retrieval Based on Quadruplet Convolutional Neural Networks","H. Zeng; Y. Liu; J. Liu; D. Fu","Beijing Engineering Research Center of Industrial Spectrum Imaging, School of Automation and Electrical Engineering, University of Science and Technology Beijing, Beijing, China; Beijing Engineering Research Center of Industrial Spectrum Imaging, School of Automation and Electrical Engineering, University of Science and Technology Beijing, Beijing, China; Beijing Engineering Research Center of Industrial Spectrum Imaging, School of Automation and Electrical Engineering, University of Science and Technology Beijing, Beijing, China; Beijing Engineering Research Center of Industrial Spectrum Imaging, School of Automation and Electrical Engineering, University of Science and Technology Beijing, Beijing, China","IEEE Access","","2018","6","","76087","76097","Non-rigid 3-D model retrieval is a challenging problem in 3-D shape analysis. Recently, deep learning-based 3-D feature extraction methods have been studied and have achieved better performance than the previous state-of-the-art methods. Inspired by the quadruplet neural networks proposed for learning local image feature descriptors, we propose a novel non-rigid 3-D model retrieval method based on quadruplet convolutional neural networks. For training the proposed networks, the quadruplet samples are first selected using the online sampling method. For each 3-D model, the wave kernel signature descriptor of each vertex is computed, and its corresponding multi-energy shape distribution matrix is constructed as the input of the network. Then, the quadruplet convolutional neural networks are trained using our improved quadruplet loss function, which not only preserves the advantages of existing quadruplet loss functions but also decreases the risk of underfitting. For the query sample, the 3-D shape features are computed using one branch of the trained quadruplet networks. Finally, the retrieval results are obtained by the L2 distance measure. Extensive experimental results have validated the effectiveness of the proposed method.","","","10.1109/ACCESS.2018.2882711","National Natural Science Foundation of China; Natural Science Foundation of Hebei Province; Fundamental Research Funds for the Central Universities; China Scholarship Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8543487","Non-rigid 3D model retrieval;convolutional neural network;quadruplet loss function;wave kernel signature;multi-energy shape distribution","Three-dimensional displays;Solid modeling;Shape;Computational modeling;Feature extraction;Biological system modeling;Convolutional neural networks","","","","","40","","","","","IEEE","IEEE Journals"
"IBM POWER9 systems designed for commercial, cognitive, and cloud","N. S. Nett; R. X. Arroyo; T. Nguyen; B. W. Mashak; R. M. Zgabay; H. Nguyen; C. W. Mann; E. J. Hauptli; S. P. Mroz; W. J. Anderl","NA; NA; NA; NA; NA; NA; NA; NA; NA; NA","IBM Journal of Research and Development","","2018","62","4/5","7:1","7:13","A new era of computing has emerged that focuses on actionable insights and predictive analytics with machine learning and deep learning algorithms. This is referred to as the cognitive era of computing. Servers designed for cognitive computing require a much different architecture than a traditional commercial server designed for database transactional processing and process automation. For example, graphics processing unit acceleration and high-bandwidth I/O for scalability are some of the key requirements for cognitive computing. Another different set of requirements is driven by servers designed for cloud infrastructure. The requirements for a cloud server place an emphasis on the total cost of ownership, total cost of acquisition, as well as compute density and server management. In this paper, we describe the family of IBM POWER9 servers that have been designed to meet the differing requirements for the cognitive, commercial, and cloud market spaces. We describe how each server in the family has been optimized for one (or more) of these workloads by implementing different combinations of POWER9 module packages, memory subsystems, internal storage subsystems, system management, and different levels of reliability, accessibility, and serviceability.","","","10.1147/JRD.2018.2848362","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8458311","","Servers;Bandwidth;Sockets;Switched mode power supplies;Memory management;Aerospace electronics;Nonvolatile memory","","","","1","8","","","","","IBM","IBM Journals"
"Data-Driven Fuzzy Modeling Using Restricted Boltzmann Machines and Probability Theory","E. de la Rosa; W. Yu","Department of Automatic Control, Center for Research and Advanced Studies, National Polytechnic Institute, Mexico City 07360, Mexico.; Department of Automatic Control, Center for Research and Advanced Studies, National Polytechnic Institute, Mexico City 07360, Mexico (e-mail: yuw@ctrl.cinvestav.mx).","IEEE Transactions on Systems, Man, and Cybernetics: Systems","","2018","PP","99","1","11","Fuzzy modeling has many advantages over nonfuzzy methods, such as robustness with respect to uncertainties and less sensitivity to the varying dynamics of nonlinear systems. Data-driven fuzzy modeling needs to extract fuzzy rules from input and output data, and to train the fuzzy parameters of the fuzzy model. This paper takes advantages from deep learning, probability theory, fuzzy modeling, and extreme learning machines (ELMs). Restricted Boltzmann machine (RBM) and probability theory are used to overcome some common problems in data-driven modeling methods. The RBM is modified such that it can be trained with continuous values. A probability-based clustering method is proposed to partition the hidden features from the RBM. The obtained fuzzy rules have probability measurement. ELM and an optimization method are applied to train the fuzzy model. The proposed method is validated with two benchmark problems.","","","10.1109/TSMC.2018.2812156","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8319509","Fuzzy neural networks;probability;restricted Boltzmann machines.","Data models;Nonlinear systems;Fuzzy systems;Mathematical model;Neural networks;Adaptation models;Probability distribution","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Eye feature point detection based on single convolutional neural network","X. Zhao; C. Meng; M. Feng; S. Chang; Q. Zeng","Nankai University, People's Republic of China; China Maritime Police Academy, People's Republic of China; China Maritime Police Academy, People's Republic of China; Nankai University, People's Republic of China; University of Illinois at Urbana-Champaign, USA","IET Computer Vision","","2018","12","4","453","457","Feature point detection based on convolutional neural network (CNN) has been studied widely. The effective approaches for improving detection accuracy are building a deeper network or using a multi-network cascade structure. However, some potential capacity of CNN has not been excavated. In this study, the authors mainly analyse several factors influencing CNN performance from two aspects: (i) the position relationships between feature points and (ii) the normalisation methods of coordinates. Whether the network can learn the position relationships is also studied. For extracting the deep features of images, a network containing three convolution layers is constructed. The specific geometric relationship constraints are applied during calibration to maximise the capability of the CNN for learning the position relationship between feature points. Considering that different feature points only appear in various local regions of an image, local normalisation is proposed, which increases the mapping scope of the feature points and decreases the mapping error. The experimental results prove that the specific position relationship and local normalisation obviously improve the feature point detection based on CNN. At the detection error of 5%, the average detection accuracy of eyelid feature points is improved by 7.1% and single-point detection receives a high accuracy of 97.96%.","","","10.1049/iet-cvi.2017.0096","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8361639","","","calibration;convolution;feature extraction;neural nets","eye feature point detection;single convolutional neural network;multinetwork cascade structure;CNN performance;normalisation methods;convolution layers;specific geometric relationship constraints;mapping error;single-point detection","","1","22","","","","","IET","IET Journals"
"Distinction of 3D Objects and Scenes via Classification Network and Markov Random Field","R. Song; Y. Liu; P. L. Rosin","Computing, Engineering and Mathematics, University of Brighton, Brighton, Brighton United Kingdom of Great Britain and Northern Ireland (e-mail: r.song@brighton.ac.uk); Department of Computer Science, Edge Hill University, 6249 Ormskirk, Lancashire United Kingdom of Great Britain and Northern Ireland (e-mail: Yonghuai.Liu@edgehill.ac.uk); Computer Science and Informatics, Cardiff University, Cardiff, South Glamorgan United Kingdom of Great Britain and Northern Ireland (e-mail: rosinpl@cardiff.ac.uk)","IEEE Transactions on Visualization and Computer Graphics","","2018","PP","99","1","1","An importance measure of 3D objects inspired by human perception has a range of applications since people want computers to behave like humans in many tasks. This paper revisits a well-defined measure, distinction of 3D mesh, which indicates how important a region of a mesh is with respect to classification. We develop a method to compute it based on a classification network and an MRF. The classification network learns view-based distinction by handling multiple views of a 3D object. Using a classification network has an advantage of avoiding the training data problem which has become a major obstacle of applying deep learning to 3D object understanding tasks. The MRF estimates the parameters of a linear model for combining the view-based distinction maps. The experiments using several publicly accessible datasets show that the distinctive regions detected by our method are not just significantly different from those detected by methods based on handcrafted features, but more consistent with human perception. We also compare it with other perceptual measures and quantitatively evaluate its performance in the context of two applications. Furthermore, due to the view-based nature of our method, we are able to easily extend mesh distinction to 3D scenes containing multiple objects.","","","10.1109/TVCG.2018.2885750","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8567954","3D mesh;distinction;neural network;Markov Random Field","Three-dimensional displays;Task analysis;Shape;Two dimensional displays;Feature extraction;Training;Markov random fields","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Salient Dual Activations Aggregation for Ground-Based Cloud Classification in Weather Station Networks","Z. Zhang; D. Li; S. Liu","Tianjin Key Laboratory of Wireless Mobile Communications and Power Transmission, Tianjin Normal University, Tianjin, China; Tianjin Key Laboratory of Wireless Mobile Communications and Power Transmission, Tianjin Normal University, Tianjin, China; Tianjin Key Laboratory of Wireless Mobile Communications and Power Transmission, Tianjin Normal University, Tianjin, China","IEEE Access","","2018","6","","59173","59181","Since appearances of clouds are always changeable, ground-based cloud classification is still in urgent need of development in weather station networks. Many existing methods resort to convolutional neural networks to improve the classification accuracy. However, these methods just carry out the feature extraction from one convolutional layer, hence making it difficult to obtain complete information of ground-based cloud images. To address this limitation, in this paper, we propose a novel method named salient dual activations aggregation (SDA2) to extract ground-based cloud features from different convolutional layers, which could learn the structural, textural, and high-level semantic information for ground-based cloud representation, simultaneously. Specifically, the salient patch selection strategy is first applied to select salient vectors from one shallow convolutional layer. Then, corresponding weights are learned from one deep convolutional layer. After obtaining a set of salient vectors with various weights, this paper is further designed to aggregate them into a representative vector for each ground-based cloud image by explicitly modeling the relationship among salient vectors. The proposed SDA2 is validated on three ground-based cloud databases, and the experimental results prove its effectiveness. Especially, we obtain the promising classification results of 91.24% on the MOC_e database, 91.15% on the IAP_e database, and 88.73% on the CAMS_e database.","","","10.1109/ACCESS.2018.2874994","National Natural Science Foundation of China; Natural Science Foundation of Tianjin City; Tianjin Normal University; National Laboratory of Pattern Recognition; China Scholarship Council; Tianjin Higher Education Creative Team Funds Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8487026","Weather station networks;salient dual activations aggregation;convolutional neural networks;ground-based cloud classification","Feature extraction;Clouds;Cloud computing;Cams;Meteorology;Databases;Histograms","","","","1","39","","","","","IEEE","IEEE Journals"
"Pelvic Organ Segmentation Using Distinctive Curve Guided Fully Convolutional Networks","K. He; X. Cao; Y. Shi; D. Nie; Y. Gao; D. Shen","State Key Laboratory for Novel Software Technology, Nanjing University, P. R. China and Biomedical Research Imaging Center, University of North Carolina, Chapel Hill, NC, U.S..; Biomedical Research Imaging Center, University of North Carolina, Chapel Hill, NC, U.S and School of Automation, Northwestern Polytechnical University, Xi’an, P. R. China.; State Key Laboratory for Novel Software Technology, Nanjing University, P. R. China.; Biomedical Research Imaging Center, University of North Carolina, Chapel Hill, NC, U.S..; State Key Laboratory for Novel Software Technology, Nanjing University, P. R. China.; Biomedical Research Imaging Center, University of North Carolina, Chapel Hill, NC, U.S and Department of Brain and Cognitive Engineering, Korea University, Seoul 02841, Republic of Korea.","IEEE Transactions on Medical Imaging","","2018","PP","99","1","1","Accurate segmentation of pelvic organs (i.e., prostate, bladder and rectum) from CT image is crucial for effective prostate cancer radiotherapy. However, it is a challenging task due to 1) low soft tissue contrast in CT images and 2) large shape and appearance variations of pelvic organs. In this paper, we employ a two-stage deep learning based method, with a novel distinctive curve guided fully convolutional network (FCN), to solve the aforementioned challenges. Specifically, the first stage is for fast and robust organ detection in the raw CT images. It is designed as a coarse segmentation network to provide region proposals for three pelvic organs. The second stage is for fine segmentation of each organ, based on the region proposal results. To better identify those indistinguishable pelvic organ boundaries, a novel morphological representation, namely distinctive curve, is also introduced to help better conduct the precise segmentation. To implement this, in this second stage, a multi-task FCN is initially utilized to learn the distinctive curve and the segmentation map separately, and then combine these two tasks to produce accurate segmentation map. The final segmentation results of all three pelvic organs are generated by a weighted max-voting strategy. We have conducted exhaustive experiments on a large and diverse pelvic CT dataset for evaluating our proposed method. The experimental results demonstrate that our proposed method is accurate and robust for this challenging segmentation task, by also outperforming the state-of-the-art segmentation methods.","","","10.1109/TMI.2018.2864958","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8434245","","Image segmentation;Computed tomography;Shape;Bladder;Task analysis;Robustness","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Automatic Estimation of Taste Liking through Facial Expression Dynamics","H. Dibeklioglu; T. Gevers","Computer Engineering Department, Bilkent University, Ankara, Ankara Turkey (e-mail: dibeklioglu@cs.bilkent.edu.tr); Informatics Institute, University of Amsterdam, Amsterdam, holland Netherlands 1098 XG (e-mail: th.gevers@uva.nl)","IEEE Transactions on Affective Computing","","2018","PP","99","1","1","The level of taste liking is an important measure for a number of applications such as the prediction of long-term consumer acceptance for different food and beverage products. Based on the fact that facial expressions are spontaneous, instant and heterogeneous sources of information, this paper aims to automatically estimate the level of taste liking through facial expression videos. Instead of using handcrafted features, the proposed approach deep learns the regional expression dynamics, and encodes them to a Fisher vector for video representation. Regional Fisher vectors are then concatenated, and classified by linear SVM classifiers. The aim is to reveal the hidden patterns of taste-elicited responses by exploiting expression dynamics such as the speed and acceleration of facial movements. To this end, we have collected the first large-scale beverage tasting database in the literature. The database has 2970 videos of taste-induced facial expressions collected from 495 subjects. Our large-scale experiments on this database show that the proposed approach achieves an accuracy of 70.37% for distinguishing between three levels of taste-liking. Furthermore, we assess the human performance recruiting 45 participants, and show that humans are significantly less reliable for estimating taste appreciation from facial expressions in comparison to the proposed method.","","","10.1109/TAFFC.2018.2832044","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8353117","Taste liking;taste appreciation;facial expression dynamics;spontaneous expression;taste-induced expression","Videos;Acceleration;Gold;Databases;Face;Shape;Estimation","","","","2","","","","","","IEEE","IEEE Early Access Articles"
"Optimizing Quality of Experience for Adaptive Bitrate Streaming via Viewer Interest Inference","G. Gao; H. Zhang; H. Hu; Y. Wen; J. Cai; C. Luo; W. Zeng","School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore; Microsoft Research Asia, Beijing, China; Microsoft Research Asia, Beijing, China","IEEE Transactions on Multimedia","","2018","20","12","3399","3413","Rate adaptation is widely adopted in video streaming to improve the quality of experience (QoE). However, most of the existing rate adaptation approaches neglect the underlying video semantic information. In fact, influenced by video semantics and viewer preferences, the viewer may have different degrees of interest on different parts of a video. The interesting parts of a video can draw more visual attention from the viewer and have higher visual importance. As such, delivering the parts of a video that are interesting to the viewer in a higher quality can improve the perceptual video quality, compared with the semantics-agnostic approaches that treat each part of a video equally. Thus, it is natural to wonder: how to allocate bitrate budgets temporally over a video session under time-varying bandwidth while considering viewer interest? As an exploratory study, we propose an interest-aware rate adaptation approach for improving QoE by inferring viewer interest based on video semantics. We adopt the deep learning method to recognize the scenes of video frames and leverage the term frequency-inverse document frequency method to analyze the degrees of an individual viewer's interest on different types of scenes. The bandwidth, buffer occupancy, and viewer interest are jointly considered under the model predictive control framework for selecting appropriate bitrates for maximizing QoE. The objective and subjective evaluations measured in a real environment show that our method can achieve a higher QoE compared with the semantics-agnostic approaches.","","","10.1109/TMM.2018.2838330","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8361841","Adaptive video streaming;QoE;rate adaptation;viewer interest;video semantics","Streaming media;Bit rate;Quality of experience;Bandwidth;Semantics","predictive control;quality of experience;video signal processing;video streaming","rate adaptation;visual importance;video semantic information;perceptual video quality;viewer preferences;viewer interest inference;adaptive bitrate streaming;semantics-agnostic approaches;individual viewer;video frames;video semantics;interest-aware rate adaptation approach;video session","","4","56","","","","","IEEE","IEEE Journals"
"A catalog of polychromatic bulge-disc decompositions of ∼17.600 galaxies in CANDELS","P. Dimauro; M. Huertas-Company; E. Daddi; P. G. Pérez-González; M. Bernardi; G. Barro; F. Buitrago; F. Caro; A. Cattaneo; H. Dominguez-Sánchez; S. M. Faber; B. Häußler; D. D. Kocevski; A. M. Koekemoer; D. C. Koo; C. T. Lee; S. Mei; B. Margalef-Bentabol; J. Primack; A. Rodriguez-Puebla; M. Salvato; F. Shankar; D. Tuccillo","Sorbonne Université, Observatoire de Paris, Université PSL, CNRS, LERMA, F-75014, Paris, France, paola.dimauro@obspm.fr; Sorbonne Université, Observatoire de Paris, Université PSL, CNRS, LERMA, F-75014, Paris, France; Department of Physics and Astronomy, University of Pennsylvania, Philadelphia, PA 19104, USA; Université Paris Diderot, 5 Rue Thomas Mann, F-75013, France; CEA Saclay, Laboratoire AIM-CNRS-Université Paris Diderot, Irfu/SAp, Orme des Merisiers, F-91191, Gif-sur-Yvette, France; Departamento de Astrofísica, Facultad de CC. Físicas, Universidad Complutense de Madrid, E-28040 Madrid, Spain; Department of Physics and Astronomy, University of Pennsylvania, Philadelphia, PA 19104, USA; University of California, Berkeley, CA 94720, USA 0000-0001-6813-875X; Instituto de Astrofisica e Ciencias do Espaco, Universidade de Lisboa, OAL, Tapada da Ajuda, P-1349-018 Lisbon, Portugal; Sorbonne Université, Observatoire de Paris, Université PSL, CNRS, LERMA, F-75014, Paris, France; Université Paris Diderot, 5 Rue Thomas Mann, F-75013, France; University of California, Santa Cruz, CA 95064, USA; GEPI, Observatoire de Paris, 61 Avenue de l’Observatoire, F-75014, Paris, France; Sorbonne Université, Observatoire de Paris, Université PSL, CNRS, LERMA, F-75014, Paris, France; University of California, Santa Cruz, CA 95064, USA; European Southern Observatory, Alonso de Cordova 3107, Vitacura, Casilla 19001, Santiago, Chile; Department of Physics and Astronomy, Colby College, Waterville, ME 04961, USA; Space Telescope Science Institute, 3700 San Martin Drive, Baltimore, MD 21218, USA; University of California, Santa Cruz, CA 95064, USA; University of California, Santa Cruz, CA 95064, USA; Sorbonne Université, Observatoire de Paris, Université PSL, CNRS, LERMA, F-75014, Paris, France; Université Paris Diderot, 5 Rue Thomas Mann, F-75013, France; Sorbonne Université, Observatoire de Paris, Université PSL, CNRS, LERMA, F-75014, Paris, France; University of California, Santa Cruz, CA 95064, USA; Instituto de Astronomía, Universidad Nacional Autónoma de México, A.P. 70-264, 04510 México, D.F., Mexico; Max Planck Institut fur Plasma Physik and Excellence Cluster, D-85748 Garching, Germany; Department of Physics and Astronomy, University of Southampton, Highfield, SO17 1BJ, UK; Sorbonne Université, Observatoire de Paris, Université PSL, CNRS, LERMA, F-75014, Paris, France; MINES Paristech, PSL Research University, Centre for Mathematical Morphology, Fontainebleau, France","Monthly Notices of the Royal Astronomical Society","","2018","478","4","5410","5426","Understanding how bulges grow in galaxies is a critical step towards unveiling the link between galaxy morphology and star-formation. To do so, it is necessary to decompose large sample of galaxies at different epochs into their main components (bulges and discs). This is particularly challenging, especially at high redshifts, where galaxies are poorly resolved. This work presents a catalog of bulge-disc decompositions of the surface brightness profiles of ∼17.600 H-band-selected galaxies in the CANDELS fields (F160W < 23, 0 <$z$< 2) in 4 to 7 filters covering a spectral range of 430 - 1600$\mathrm{nm}$. This is the largest available catalog of this kind up to$z$= 2. By using a novel approach based on deep learning to select the best model to fit, we manage to control systematics arising from wrong model selection and obtain less-contaminated samples than previous works. We show that the derived structural properties are within${\sim }10\hbox{--}20{\rm} \, \%$of random uncertainties. We then fit stellar population models to the decomposed spectral energy distributions of bulges and discs and derive stellar masses (and stellar mass bulge-to-total ratios) as well as rest-frame colors (U,V,J) for bulges and discs separately. All data products are publicly released with this paper and through the web page https://lerma.obspm.fr/huertas/form_CANDELS and will be used for scientific analysis in forthcoming works.","","","10.1093/mnras/sty1379","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8434802","galaxies: bulges;galaxies: fundamental parameters;galaxies: high-redshift","","","","","","","","","","","OUP","OUP Journals"
"Detection of Power Line Insulator Defects Using Aerial Images Analyzed With Convolutional Neural Networks","X. Tao; D. Zhang; Z. Wang; X. Liu; H. Zhang; D. Xu","Research Center of Precision Sensing and Control, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China (e-mail: taoxian2013@ia.ac.cn).; Research Center of Precision Sensing and Control, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China.; Sino-European Institute of Aviation Engineering, Civil Aviation University of China, Tianjin 300300, China.; Research Center of Precision Sensing and Control, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China.; School of Information Science and Technology, Hainan Normal University, Haikou 571158, China.; Research Center of Precision Sensing and Control, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China.","IEEE Transactions on Systems, Man, and Cybernetics: Systems","","2018","PP","99","1","13","As the failure of power line insulators leads to the failure of power transmission systems, an insulator inspection system based on an aerial platform is widely used. Insulator defect detection is performed against complex backgrounds in aerial images, presenting an interesting but challenging problem. Traditional methods, based on handcrafted features or shallow-learning techniques, can only localize insulators and detect faults under specific detection conditions, such as when sufficient prior knowledge is available, with low background interference, at certain object scales, or under specific illumination conditions. This paper discusses the automatic detection of insulator defects using aerial images, accurately localizing insulator defects appearing in input images captured from real inspection environments. We propose a novel deep convolutional neural network (CNN) cascading architecture for performing localization and detecting defects in insulators. The cascading network uses a CNN based on a region proposal network to transform defect inspection into a two-level object detection problem. To address the scarcity of defect images in a real inspection environment, a data augmentation method is also proposed that includes four operations: 1) affine transformation; 2) insulator segmentation and background fusion; 3) Gaussian blur; and 4) brightness transformation. Defect detection precision and recall of the proposed method are 0.91 and 0.96 using a standard insulator dataset, and insulator defects under various conditions can be successfully detected. Experimental results demonstrate that this method meets the robustness and accuracy requirements for insulator defect detection.","","","10.1109/TSMC.2018.2871750","Science Challenge Project; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8492359","Aerial image;convolutional neural network (CNN);data augmentation;defect detection;insulators","Insulators;Inspection;Feature extraction;Object detection;Shape;Support vector machines;Convolutional neural networks","","","","8","","","","","","IEEE","IEEE Early Access Articles"
"Understanding the Usage of Industrial Control System Devices on the Internet","Q. Li; X. Feng; H. Wang; L. Sun","School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China; School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China; Department of Electrical and Computer Engineering, University of Delaware, Newark, DE, USA; School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China","IEEE Internet of Things Journal","","2018","5","3","2178","2189","Industrial control system (ICS) devices play a crucial role in critical infrastructures, such as power grid. In recent years, numerous ICS devices are accessible on the Internet, resulting in potential security issues. However, there is a lack of deep understanding of these devices' characteristics in the cyberspace. In this paper, we take the first step in this direction by investigating these visible ICS devices on the Internet. Because of the critical nature of ICSs, the detection of online ICS devices should be done in a nonintrusive and timely manner. We first analyze 17 industrial protocols widely used in ICSs and train a probability model through the learning algorithm to improve detection accuracy. Then, we discover online ICS devices in the IPv4 space while reducing the negative effects caused by industrial honeypots and dynamic IP addresses. To observe the dynamics of ICS devices in a relatively long run, we have deployed our discovery system on Amazon EC2 and detected online ICS devices in the whole IPv4 space for eight times from August 2015 to March 2016. Based on the ICS device data collection, we conduct a comprehensive data analysis to characterize the usage of ICS devices, especially in answer to the following three questions: 1) what are the distribution features of ICS devices; 2) who use these ICS devices; and 3) what are the functions of these ICS devices.","","","10.1109/JIOT.2018.2826558","National Key Research and Development Program of China; Key Program of National Natural Science Foundation of China; National Natural Science Foundation of China; Program of Science and Technology Commission Foundation of Beijing; Fundamental Theory and Cutting Edge Technology Research Program of Institute of Information Engineering; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8337732","Industrial control system (ICS);Internet of Things;network measurement","Integrated circuits;Protocols;Industrial control;IP networks;Payloads;Object recognition;Internet","control engineering computing;data analysis;industrial control;Internet;IP networks;production engineering computing;protocols;security of data","industrial control system devices;ICS device data collection;ICS devices;Internet;industrial honeypots;dynamic IP addresses","","","26","","","","","IEEE","IEEE Journals"
"A Sequential Approach to Market State Modeling and Analysis in Online P2P Lending","H. Zhao; Q. Liu; H. Zhu; Y. Ge; E. Chen; Y. Zhu; J. Du","School of Computer Science and Technology, University of Science and Technology of China, Hefei, China; School of Computer Science and Technology, University of Science and Technology of China, Hefei, China; Big Data Laboratory, Baidu Research, Beijing, China; Eller College of Management, University of Arizona, Tucson, AZ, USA; School of Computer Science and Technology, University of Science and Technology of China, Hefei, China; School of Computer Science and Technology, University of Science and Technology of China, Hefei, China; School of Computer Science, Beijing University of Posts and Telecommunications, Beijing, China","IEEE Transactions on Systems, Man, and Cybernetics: Systems","","2018","48","1","21","33","Online peer-to-peer (P2P) lending is an emerging wealth-management service for individuals, which allows lenders to directly bid and invest on the listings created by borrowers without going through any traditional financial intermediaries. As a nonbank financial platform, online P2P lending tends to have both high volatility and liquidity. Therefore, it is of significant importance to discern the hidden market states of the listings (e.g., hot and cold), which open venues for enhancing business analytics and investment decision making. However, the problem of market state modeling remains pretty open due to many technical and domain challenges, such as the dynamic and sequential characteristics of listings. To that end, in this paper, we present a focused study on market state modeling and analysis for online P2P lending. Specifically, we first propose two enhanced sequential models by extending the Bayesian hidden Markov model (BHMM), namely listing-BHMM (L-BHMM) and listing and marketing-BHMM (LM-BHMM), for learning the latent semantics between listings' market states and lenders' bidding behaviors. Particularly, L-BHMM is a straightforward model that only considers the local observations of a listing itself, while LM-BHMM considers not only the listing information but also the global information of current market (e.g., the competitive and complementary relations among listings). Furthermore, we demonstrate several motivating applications enabled by our models, such as bidding prediction and herding detection. Finally, we construct extensive experiments on two real-world data sets and make some deep analysis on bidding behaviors, which clearly validate the effectiveness of our models in terms of different applications and also reveal some interesting business findings.","","","10.1109/TSMC.2017.2665038","National Key Research and Development Program of China; National Science Foundation for Distinguished Young Scholars of China; National Natural Science Foundation of China; Youth Innovation Promotion Association of CAS; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7858630","Bayesian hidden Markov model (BHMM);bidding behaviors;market state;peer-to-peer lending","Hidden Markov models;Peer-to-peer computing;Investment;Analytical models;Predictive models;Cybernetics","decision making;financial management;hidden Markov models;investment;peer-to-peer computing","Online P2P Lending;Online peer-to-peer lending;bidding behaviors;current market;listing information;LM-BHMM;L-BHMM;listing-BHMM;Bayesian hidden Markov model;enhanced sequential models;investment decision making;business analytics;hidden market states;nonbank financial platform;traditional financial intermediaries;emerging wealth-management service;market state modeling","","","51","","","","","IEEE","IEEE Journals"
"Metamorphic Testing: Testing the Untestable","S. Segura; D. Towey; Z. Q. Zhou; T. Y. Chen","Department of Computer Languages and Systems, University of Seville, Spain; School of Computer Science, University of Nottingham, Ningbo China, China; Institute of Cybersecurity and Cryptology, School of Computing and Information Technology, University of Wollongong, Australia; Department of Computer Science and Software Engineering, Swinburne University of Technology, Australia","IEEE Software","","2018","PP","99","1","1","What if we could know that a program is buggy, even if we could not tell whether or not its observed output is correct? This is one of the key strengths of metamorphic testing, a technique where failures are not revealed by checking an individual concrete output, but by checking the relations among the inputs and outputs of multiple executions of the program under test. Two decades after its introduction, metamorphic testing has become a fully-fledged testing technique with successful applications in multiple domains, including online search engines, autonomous machinery, compilers, Web APIs, and deep learning programs, among others. This article serves as a hands-on entry point for newcomers to metamorphic testing, describing examples, possible applications, and current limitations, providing readers with the basics for the application of the technique in their own projects.","","","10.1109/MS.2018.2875968","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8573811","Software testing;metamorphic testing;oracle problem;test case generation","Search engines;Standards;Computer science;Australia;Program processors;Software testing","","","","4","","","","","","IEEE","IEEE Early Access Articles"
"ROV-Based Automated Cable-Laying System: Application to DONET2 Installation","J. Choi; T. Yokobiki; K. Kawaguchi","Japan Agency for Marine-Earth Science and Technology, Yokosuka, Japan; Japan Agency for Marine-Earth Science and Technology, Yokosuka, Japan; Japan Agency for Marine-Earth Science and Technology, Yokosuka, Japan","IEEE Journal of Oceanic Engineering","","2018","43","3","665","676","We developed an automated cable-laying system operated through a remotely operated vehicle (ROV). This system can automatically install a thin optical-fiber submarine cable at a rate that matches the ground speed of the ROV and adjust the amount of cable slack. The use of an ROV allows accurate and safe deployment of a thin optical-fiber submarine cable on the deep seafloor. The automated cable-laying system has been successfully used in installing the dense oceanfloor network system for earthquakes and tsunamis (DONET2) off the Kii peninsula in Japan. In our previous paper, we described the development process of the automated cable-laying system in detail. The current study focuses on the application in DONET2 installation and shows the practical advantages produced through automation. First, we overview the automated cable-laying system and then report on the successful application in DONET2 installation. The operating time and number of operators were distinctly reduced. Moreover, the physical and mental burden on the operators was relieved. In addition, several lessons learned during DONET2 installation are presented, and the unmanned cable-laying using an autonomous underwater vehicle is briefly discussed.","","","10.1109/JOE.2017.2735598","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8027198","Automated cable-laying system;autonomous underwater vehicle (AUV);cabled ocean-observatory system;dense oceanfloor network system for earthquakes and tsunamis (DONET);remotely operated vehicle (ROV)","Underwater cables;Observatories;Earthquakes;Communication cables;Tsunami;Repeaters;Joining processes","autonomous underwater vehicles;cable laying;earthquakes;seafloor phenomena;submarine cables;tsunami","optical-fiber submarine cable;DONET2 installation;ROV-based automated cable-laying system;remotely operated vehicle;dense oceanfloor network system;earthquake;tsunami;Kii peninsula;Japan;autonomous underwater vehicle","","3","59","","","","","IEEE","IEEE Journals"
"CAAE++: Improved CAAE for Age Progression/Regression","J. Zeng; X. Ma; K. Zhou","Wuhan National Laboratory for Optoelectronics, Huazhong University of Science and Technology, Wuhan, China; School of Information and Safety Engineering, Zhongnan University of Economics and Law, Wuhan, China; Wuhan National Laboratory for Optoelectronics, Huazhong University of Science and Technology, Wuhan, China","IEEE Access","","2018","6","","66715","66722","Face age progression/regression has garnered substantial active research interest due to its tremendous impact on a wide-range of practical applications like searching for missing individuals with photos of childhood, entertainment, and so on. Most existing face aging models have proven to be successful and effective in learning the transformation between age groups with the aid of paired samples, i.e., face images of the same person at different ages. Considering the expensive cost of collecting paired datasets, Conditional Adversarial Autoencoder (CAAE) is designed for face aging task without paired samples and first achieves face age progression and regression in a holistic framework. However, only rough wrinkles are generated because of the insufficient discriminative and generative ability. To tackle this problem, in this paper, we develop a novel generative model based on CAAE, dubbed CAAE++, which defeats the previous CAAE mainly for two enhancements: 1) an auxiliary classifier is added on top of the discriminator, which allows a single discriminator not only distinguishes real images from synthetics but also classifies them into the target age group; and 2) a pre-trained deep face recognition model and a pre-trained age estimation model are exploited to preserve identity and age similarity, respectively. We train CAAE++ on UTKFace dataset and test on FGNET dataset. Experimental results demonstrate the efficacy of our proposed method in terms of fidelity.","","","10.1109/ACCESS.2018.2877706","National Natural Science Foundation of China; National Key Research and Development Program of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8528393","Age progression/regression;generative adversarial networks;conditional adversarial autoencoder;image generation;generators;face recognition","Face;Aging;Biological system modeling;Generative adversarial networks;Gallium nitride;Training;Generators","","","","2","50","","","","","IEEE","IEEE Journals"
"SCN: Switchable Context Network for Semantic Segmentation of RGB-D Images","D. Lin; R. Zhang; Y. Ji; P. Li; H. Huang","College of Computer Science and Software Engineering, Shenzhen University, Shenzhen 518060, China.; Department of Electronic Engineering, Chinese University of Hong Kong, Hong Kong.; College of Computer Science and Software Engineering, Shenzhen University, Shenzhen 518060, China.; Faculty of Information Technology, Macau University of Science and Technology, Macau 999078, China.; College of Computer Science and Software Engineering, Shenzhen University, Shenzhen 518060, China (e-mail: hhzhiyan@gmail.com).","IEEE Transactions on Cybernetics","","2018","PP","99","1","12","Context representations have been widely used to profit semantic image segmentation. The emergence of depth data provides additional information to construct more discriminating context representations. Depth data preserves the geometric relationship of objects in a scene, which is generally hard to be inferred from RGB images. While deep convolutional neural networks (CNNs) have been successful in solving semantic segmentation, we encounter the problem of optimizing CNN training for the informative context using depth data to enhance the segmentation accuracy. In this paper, we present a novel switchable context network (SCN) to facilitate semantic segmentation of RGB-D images. Depth data is used to identify objects existing in multiple image regions. The network analyzes the information in the image regions to identify different characteristics, which are then used selectively through switching network branches. With the content extracted from the inherent image structure, we are able to generate effective context representations that are aware of both image structures and object relationships, leading to a more coherent learning of semantic segmentation network. We demonstrate that our SCN outperforms state-of-the-art methods on two public datasets.","","","10.1109/TCYB.2018.2885062","National Natural Science Foundation of China; National 973 Program; Guangdong Science and Technology Program; Shenzhen Innovation Program; Macau Science and Technology Development Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8584494","Context representation;convolutional neural network (CNN);RGB-D images;semantic segmentation","Image segmentation;Semantics;Switches;Image color analysis;Image resolution;Computer architecture;Cybernetics","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Facial Soft Biometrics for Recognition in the Wild: Recent Works, Annotation, and COTS Evaluation","E. Gonzalez-Sosa; J. Fierrez; R. Vera-Rodriguez; F. Alonso-Fernandez","Nokia Bell-Labs, Madrid, Spain; Escuela Politecnica Superior, Universidad Autonoma de Madrid, Madrid, Spain; Escuela Politecnica Superior, Universidad Autonoma de Madrid, Madrid, Spain; School of Information Technology, Halmstad University, Halmstad, Sweden","IEEE Transactions on Information Forensics and Security","","2018","13","8","2001","2014","The role of soft biometrics to enhance person recognition systems in unconstrained scenarios has not been extensively studied. Here, we explore the utility of the following modalities: gender, ethnicity, age, glasses, beard, and moustache. We consider two assumptions: 1) manual estimation of soft biometrics and 2) automatic estimation from two commercial off-the-shelf systems (COTS). All experiments are reported using the labeled faces in the wild (LFW) database. First, we study the discrimination capabilities of soft biometrics standalone. Then, experiments are carried out fusing soft biometrics with two state-of-the-art face recognition systems based on deep learning. We observe that soft biometrics is a valuable complement to the face modality in unconstrained scenarios, with relative improvements up to 40%/15% in the verification performance when using manual/automatic soft biometrics estimation. Results are reproducible as we make public our manual annotations and COTS outputs of soft biometrics over LFW, as well as the face recognition scores.","","","10.1109/TIFS.2018.2807791","Spanish Guardia Civil and the project CogniMetrics from MINECO/FEDER; Imperial College London; Ph.D. Scholarship from the Universidad Autonoma de Madrid; Swedish Research Council; CAISR program; SIDUS-AIR project of the Swedish Knowledge Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8295149","Soft biometrics;hard biometrics;commercial systems;unconstrained scenarios","Face;Databases;Iris recognition;Manuals;Forensics","face recognition;visual databases","facial soft biometrics;person recognition systems;beard;COTS;soft biometrics standalone;manual/automatic soft biometrics estimation;face recognition scores;soft biometrics;gender;ethnicity;face recognition systems;glasses;moustache;age;labeled faces in the wild database;LFW database","","5","41","","","","","IEEE","IEEE Journals"
"High-Fidelity Monocular Face Reconstruction based on an Unsupervised Model-based Face Autoencoder","A. Tewari; M. Zollhoefer; F. Bernard; P. Garrido; H. Kim; P. Perez; C. Theobalt","Computer Graphics, Max-Planck-Institut fur Informatik, 28323 Saarbrucken, Saarland Germany 66123 (e-mail: atewari@mpi-inf.mpg.de); Computer Graphics, Stanford University, Stanford, California United States (e-mail: zollhoefer@cs.stanford.edu); Computer Graphics, Max-Planck-Institut fur Informatik, 28323 Saarbrucken, Saarland Germany (e-mail: f.bernardpi@gmail.com); Imaging Science Lab, Technicolor Rennes Research and Innovation, 399444 Cesson Sevigne, Bretagne France (e-mail: pablo.garrido.adrian@gmail.com); Computer Graphics, Max Planck Institute for Informatics, Saarbruecken, Saarland Germany (e-mail: hyeongwoo.kim@mpi-inf.mpg.de); Imaging Science Lab, Technicolor Rennes Research and Innovation, 399444 Cesson Sevigne, Bretagne France (e-mail: Patrick.Perez@technicolor.com); Graphics, Vision and Video, Max-Planck-Institut Informatik, Saarbruecken, Saarland Germany (e-mail: theobalt@mpi-inf.mpg.de)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","PP","99","1","1","In this work we propose a novel model-based deep convolutional autoencoder that addresses the highly challenging problem of reconstructing a 3D human face from a single in-the-wild color image. To this end, we combine a convolutional encoder network with an expert-designed generative model that serves as decoder. The core innovation is the differentiable parametric decoder that encapsulates image formation analytically based on a generative model. Our decoder takes as input a code vector with exactly defined semantic meaning that encodes detailed face pose, shape, expression, skin reflectance and scene illumination. Due to this new way of combining CNN-based with model-based face reconstruction, the CNN-based encoder learns to extract semantically meaningful parameters from a single monocular input image. For the first time, a CNN encoder and an expert-designed generative model can be trained end-to-end in an unsupervised manner, which renders training on very large (unlabeled) real world datasets feasible. The obtained reconstructions compare favorably to current state-of-the-art approaches in terms of quality and richness of representation. This work is an extended version of [1], where we additionally present a stochastic vertex sampling technique for faster training of our networks, and moreover, we propose and evaluate analysis-by-synthesis and shape-from-shading refinement approaches to achieve a high-fidelity reconstruction.","","","10.1109/TPAMI.2018.2876842","ERC Starting Grant CapReal; Max Planck Center for Visual Computing and Communications MPC-VCC; Technicolor; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8496850","","Face;Image reconstruction;Three-dimensional displays;Training;Decoding;Shape;Lighting","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Review on Intelligence Dehazing and Color Restoration for Underwater Images","M. Han; Z. Lyu; T. Qiu; M. Xu","Department of Electronic Information and Electrical Engineering, Dalian University of Technology, Dalian 116024, China.(e-mail: minhan@dlut.edu.cn); Department of Electronic Information and Electrical Engineering, Dalian University of Technology, Dalian 116024, China.; Department of Electronic Information and Electrical Engineering, Dalian University of Technology, Dalian 116024, China.; Department of Electronic Information and Electrical Engineering, Dalian University of Technology, Dalian 116024, China.","IEEE Transactions on Systems, Man, and Cybernetics: Systems","","2018","PP","99","1","13","Underwater image processing is an intelligence research field that has great potential to help developers better explore the underwater environment. Underwater image processing has been used in a wide variety of fields, such as underwater microscopic detection, terrain scanning, mine detection, telecommunication cables, and autonomous underwater vehicles. However, underwater imagery suffers from strong absorption, scattering, color distortion, and noise from the artificial light sources, causing image blur, haziness, and a bluish or greenish tone. Therefore, the enhancement of underwater imagery can be divided into two methods: 1) underwater image dehazing and 2) underwater image color restoration. This paper presents the reason for underwater image degradation, surveys the state-of-the-art intelligence algorithms like deep learning methods in underwater image dehazing and restoration, demonstrates the performance of underwater image dehazing and color restoration with different methods, introduces an underwater image color evaluation metric, and provides an overview of the major underwater image applications. Finally, we summarize the application of underwater image processing.","","","10.1109/TSMC.2017.2788902","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; Special Fund for Basic Research on Scientific Instruments of the National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8267119","Color restoration;image dehazing;image enhancement;underwater image processing","Image color analysis;Cameras;Image restoration;Image enhancement;Scattering","","","","7","","","","","","IEEE","IEEE Early Access Articles"
"Computation of Gray Level Co-Occurrence Matrix Based on CUDA and Optimization for Medical Computer Vision Application","H. Hong; L. Zheng; S. Pan","Engineering Institute, Huaqiao University, Quanzhou, China; Engineering Institute, Huaqiao University, Quanzhou, China; Engineering Institute, Huaqiao University, Quanzhou, China","IEEE Access","","2018","6","","67762","67770","Various fields in medicine require scientific research and computer application. This results in computation time optimization becoming a task that is of increasing importance due to its highly parallel architecture. As is well-known, the graphics processing unit (GPU) is regarded as a powerful engine for application programs that demand fairly high computation capabilities. Our study is based on the deep analysis of the parallelism pertaining to the calculation of the gray level co-occurrence matrix, whereby an algorithm was introduced to optimize the method used to compute the gray-level co-occurrence matrix (GLCM) of an image. Furthermore, strategies (e.g., copying, image partitioning, and so on) were proposed to optimize the parallel algorithm. Our experiments indicate that without losing the computational accuracy, the speed-up ratio of the GLCM computation of images with different resolutions by GPU utilizing compute unified device architecture was at least 50 times faster than that of the GLCM computation by the central processing unit. This manifestation of a significantly improved performance can lead to the development of a very useful computational tool in medical computer vision.","","","10.1109/ACCESS.2018.2877697","Science and Technology Bureau of Xiamen; Technology Bureau of Quanzhou; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8528364","CUDA;GPU;gray-level co-occurrence matrix;parallel computing;medical computer vision","Graphics processing units;Instruction sets;Biomedical imaging;Computer architecture;Optimization;Computer vision;Parallel processing","","","","1","27","","","","","IEEE","IEEE Journals"
"Running Experimental Research of a Wire Driven Astronaut Rehabilitative Training Robot","Y. Zou; L. Zhang; L. Li; H. Ma; K. Liu","College of Mechanical and Electronic Engineering, China University of Petroleum, Qingdao, China; College of Mechanical and Electrical Engineering, Harbin Engineering University, Harbin, China; College of Mechanical and Electrical Engineering, Harbin Engineering University, Harbin, China; College of Mathematics and System Science, Shandong University of Science and Technology, Qingdao, China; College of Mechanical and Electronic Engineering, China University of Petroleum, Qingdao, China","IEEE Access","","2018","6","","11464","11471","Keeping astronauts physically healthy in the harsh space environment is a key to the successful execution of a space mission. Long-term space missions in the weightless environment, however, can result in space adaptation syndrome, which seriously affects astronauts' health. To alleviate the adverse effects, this paper proposes a wire driven astronaut rehabilitative training robot that simulates the characteristics of the gravity environment and load force on the astronauts. The robot can realize multiple physical exercises including running, bench press, and deep squat. A dynamic model of the wire driven unit (WDU) was provided. On this basis, a hybrid force controller was designed to improve the precision and real-time performance of WDU. Furthermore, a dual-closed-loop control strategy was proposed to improve the loading precision of the robot. Running experimental results demonstrate that the robot can load force safely and reliably during the physical training, and the control strategies are effective.","","","10.1109/ACCESS.2018.2809735","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; Shandong Provincial Natural Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8302914","Astronaut rehabilitative training robot (ART);force control;space adaptation syndrome (SAS);weightless environment;wire driven","Training;Wires;Force;Subspace constraints;Robots;DC motors;Traction motors","aerospace biophysics;biomechanics;closed loop systems;force control;medical robotics;patient rehabilitation","physical training;experimental research;wire driven astronaut rehabilitative training robot;harsh space environment;successful execution;long-term space missions;weightless environment;space adaptation syndrome;adverse effects;gravity environment;load force;multiple physical exercises;wire driven unit;hybrid force controller;dual-closed-loop control strategy;WDU;dynamic model;space mission successful execution","","2","23","","","","","IEEE","IEEE Journals"
"Robust 3D Convolutional Neural Network With Boundary Correction for Accurate Brain Tissue Segmentation","B. Hou; G. Kang; N. Zhang; C. Hu","Key Laboratory of Universal Wireless Communications, Ministry of Education, Beijing University of Posts and Telecommunications, Beijing, China; Key Laboratory of Universal Wireless Communications, Ministry of Education, Beijing University of Posts and Telecommunications, Beijing, China; Key Laboratory of Universal Wireless Communications, Ministry of Education, Beijing University of Posts and Telecommunications, Beijing, China; Key Laboratory of Universal Wireless Communications, Ministry of Education, Beijing University of Posts and Telecommunications, Beijing, China","IEEE Access","","2018","6","","75471","75481","The morphology, symmetry, and volume of brain tissue are good indicators for measuring the central nervous system disease progression. The objective of this paper is to segment cerebrospinal fluid (CSF), gray matter (GM), and white matter (WM) automatically with multi-modality magnetic resonance scans. A novel coarse-to-fine method is proposed to segment CSF, GM, and WM using two cascade 3D convolutional neural networks. The first densely connected fully convolutional network (DC-FCN) is designed with feature reuse, which can take full advantage of the spatial information and alleviate computer memory limitation. The second 6-CNN is designed to correct boundary voxel, which can further reduce computational cost while improving the segmentation accuracy. As of today, our method ranks the 3rd on the MRBrainS13 challenge, outperforming most of the participant methods when using available input modalities (T1, T1-IR, and T2-FLAIR). In addition, we also verify the proposed framework on the IBSR dataset, which demonstrates the effectiveness of the boundary correction strategy. Through accurate segmentation of brain tissue, neuroimaging physicians can be assisted in assessing disease progression and even localizing lesions.","","","10.1109/ACCESS.2018.2882848","National Natural Science Foundation of China; National Science and Technology Major Project of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8543143","Multi-modality;coarse-to-fine;3D convolutional neural networks;cascade framework","Image segmentation;Three-dimensional displays;Brain modeling;Convolution;Magnetic resonance imaging;Diseases","biological tissues;biomedical MRI;brain;convolutional neural nets;diseases;edge detection;image segmentation;medical image processing;neurophysiology","central nervous system disease progression;multimodality magnetic resonance scans;fully convolutional network;feature reuse;spatial information;computer memory limitation;MRBrainS13 challenge;lesion localization;neuroimaging physicians;coarse-to-fine method;two cascade 3D convolutional neural networks;boundary voxel correction;white matter segmentation;gray matter segmentation;brain tissue segmentation;accurate segmentation","","2","58","","","","","IEEE","IEEE Journals"
"Guest Editorial Special Issue on Deep/Reinforcement Learning and Games","","","IEEE Transactions on Games","","2018","10","4","333","335","Deep learning (DL) and reinforcement learning (RL) have been applied with great success to many games, including Go and Atari 2600 games. Monte Carlo Tree Search (MCTS), developed in 2006, can be viewed as a kind of online RL. This technique has greatly improved the level of Go-playing programs. MCTS has since become the state of the art for many other games including Hex, Havannah, and general game playing, and has found much success in applications as diverse as scheduling, unit commitment problems, and probabilistic planning. DL has transformed fields such as image and video recognition and speech understanding. In computer games, DL started making its mark in 2014, when teams from the University of Edinburgh and Google DeepMind independently applied deep convolutional neural networks (DCNNs) to the problem of expertmove prediction in Go.Clark and Storkey’s DCNN achieved a move prediction rate of 44%, exceeding all previously published results. DeepMind’s publication followed soon after, with a DCNN that reached 55%. The combination of DL and RL led to great advances in Atari 2600 game playing, and to the ultimate breakthrough in computer Go. In 2017, DeepMind proposed a new deep reinforcement learning (DRL) algorithm and developed AlphaGo Zero, which is significant for not requiring any human knowledge of Go. By removing the requirement for domain knowledge, DRL is also flexible in that the method can be applied to a wide range of games and problems, ushering in a variety of new research opportunities. In this special issue, we are delighted to bring you eight articles on applying DL/RL related techniques to games research. ","","","10.1109/TG.2018.2882899","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8574346","","Special issues and sections;Reinforcement learning;Machine learning;Games;Deep learning","","","","","0","","","","","IEEE","IEEE Journals"
"Special Issue on Deep Reinforcement Learning and Adaptive Dynamic Programming","D. Zhao; D. Liu; F. L. Lewis; J. C. Principe; S. Squartini","NA; NA; NA; NA; NA","IEEE Transactions on Neural Networks and Learning Systems","","2018","29","6","2038","2041","In the first issue of Nature 2015, Google DeepMind published a paper “Human-level control through deep reinforcement learning.” Furthermore, in the first issue of Nature 2016, it published a cover paper “Mastering the game of Go with deep neural networks and tree search” and proposed the computer Go program, AlphaGo. In March 2016, AlphaGo beat the world’s top Go player Lee Sedol by 4:1. This becomes a new milestone in artificial intelligence history, the core of which is the algorithm of deep reinforcement learning (RL).","","","10.1109/TNNLS.2018.2818878","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8353782","","Optimal control;Task analysis;Heuristic algorithms;Games;Training data;Approximation algorithms;Nonlinear systems;Dynamic programming;Machine learning;Artificial intelligence","","","","","","","","","","IEEE","IEEE Journals"
"Deep Sequencing Data Analysis","B. K. Ghosh; A. Datta; R. Pal","Department of Mathematics and Statistics, Texas Tech University, Lubbock, TX; Department of Electrical and Computer Engineering, Texas A&M University, College Station, TX; Department of Electrical and Computer Engineering, Texas Tech University, Lubbock, TX","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2018","15","2","482","483","This paper discussed the recent advances in Deep Sequencing Data Analysis for systems biology research. Deep sequencing technologies have been primarily applied to genomic sequencing but have recently been applied for transcriptomic profiling or mapping histone modifications. Deep Sequencing technology shows clear advantages over existing profiling technologies in terms of amount of sequence coverage, revealing new transcriptomic insights, measurement of expression of different transcript isoforms and accuracy of defining transcription level. However, being a relatively newer method for transcriptomic profiling, standardized approaches for analysis of deep sequencing expression data are still being developed. The analysis and application of deep sequencing data presents enormous challenges in the areas of machine learning, signal processing, systems theory and statistics. The emphasis of the special issue is on the latest computational challenges and finding rigorous and novel engineering approaches to tackle structural and functional systems biology problems using deep sequencing technologies","","","10.1109/TCBB.2018.2805179","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8329204","","Special issues and sections;Sequential analysis;Bayes methods;Computational modeling;Fault detection;Data analysis;Machine learning;Signal processing;Systems engineering and theory","biological techniques;biology computing;genomics;learning (artificial intelligence);molecular biophysics;RNA","systems theory;signal processing;machine learning;deep sequencing expression data;transcriptomic insights;sequence coverage;profiling technologies;histone modifications;transcriptomic profiling;genomic sequencing;systems biology research;deep sequencing data analysis","","","","","","","","IEEE","IEEE Journals"
"Guest Editorial Special Issue on Deep Learning in Medical Imaging","","","IEEE Transactions on Biomedical Engineering","","2018","65","9","1898","1899","The papers in this special section focus on the leveraging of deep learning, especially convolutional neural network techniques, in a wide variety of classical tasks in medical imaging and analysis, e.g., registration, segmentation, classification, regression/prediction, and reconstruction.","","","10.1109/TBME.2018.2856101","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8440620","","Special issues and sections;Biomedical imaging;Machine learning;Image segmentation;Recurrent neural networking;Convultional neural networks","","","","","0","","","","","IEEE","IEEE Journals"
"Guest Editorial Deep Learning Models for Industry Informatics","D. P. Agrawal; B. B. Gupta; H. Wang; X. Chang; S. Yamaguchi; G. M. Perez","University of Cincinnati, Cincinnati, OH, USA; National Institute of Technology Kurukshetra, Thanesar, India; GoPerception Laboratory, Cornell University, Ithaca, NY, USA; Carnegie Mellon University, Pittsburgh, PA, USA; Graduate School of Sciences and Technology for Innovation, Yamaguchi University, Yamaguchi, Japan; University of Murcia, Murcia, Spain","IEEE Transactions on Industrial Informatics","","2018","14","7","3166","3169","The papers in this special issue mainly focus on deep learning models for industry informatics, addressing both original algorithmic development and new applications of deep learning.","","","10.1109/TII.2018.2834547","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8402153","","Special issues and sections;Machine learning;Learning systems;Informatics;Computational modeling;Predictive models;Malware;Feature extraction;Computer vision;Industrial control","","","","","8","","","","","IEEE","IEEE Journals"
"Guest Editors’ Introduction to the Special Section on Learning with Shared Information for Computer Vision and Multimedia Analysis","T. Darrell; C. Lampert; N. Sebe; Y. Wu; Y. Yan","Department of EECS, University of California, Berkeley, CA; Institute of Science and Technology, Klosterneuburg, Austria; Department of Information Engineering and Computer Science, University of Trento, Trento, TN, Italy; Department of EECS, Northwestern University, Evanston, IL; Department of Computer Science, Texas State University, San Marcos, TX","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2018","40","5","1029","1031","The twelve papers in this special section focus on learning systems with shared information for computer vision and multimedia communication analysis. In the real world, a realistic setting for computer vision or multimedia recognition problems is that we have some classes containing lots of training data and many classes containing a small amount of training data. Therefore, how to use frequent classes to help learning rare classes for which it is harder to collect the training data is an open question. Learning with shared information is an emerging topic in machine learning, computer vision and multimedia analysis. There are different levels of components that can be shared during concept modeling and machine learning stages, such as sharing generic object parts, sharing attributes, sharing transformations, sharing regularization parameters and sharing training examples, etc. Regarding the specific methods, multi-task learning, transfer learning and deep learning can be seen as using different strategies to share information. These learning with shared information methods are very effective in solving real-world large-scale problems.","","","10.1109/TPAMI.2018.2804998","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8329160","","Special issues and sections;Computer vision;Machine learning;Training data;Multimedia communication;Collaboration;Information sharing;Learning systems","","","","","","","","","","IEEE","IEEE Journals"
"Foreword to the Special Issue on Analysis of Multitemporal Remote Sensing Images","","","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2018","11","12","4548","4550","The thirteen papers in this special section were presented at the 9th International Workshop on the Analysis of Multitemporal Remote Sensing Images (MultiTemp 2017), hosted by VITO Remote Sensing on June 27–29, 2017. ","","","10.1109/JSTARS.2018.2885396","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8580595","","Special issues and sections;Meetings;Vegetation mapping;Time series analysis;Unsupervised learning;Change detection algorithms;Deep learning","","","","","0","","","","","IEEE","IEEE Journals"
"Introduction to the Special Issue on the 2018 IEEE Symposium on VLSI Circuits—Part II","A. L. S. Loke","Design and Technology Platform Taiwan Semiconductor Manufacturing Company, San Diego, CA, USA","IEEE Solid-State Circuits Letters","","2018","1","12","215","216","Parts I and II of the Special Issue of the IEEE Solid-State Circuits Letters are dedicated to selected papers presented at the IEEE Symposium on VLSI Circuits held on June 18–22, 2018, in Honolulu, HI, USA. The IEEE Symposium on VLSI Circuits is jointly organized with the IEEE Symposium on VLSI Technology, providing good opportunities for interaction between the experts in the two areas. Part II of the Special Issue covers papers on digital, memory, security, sensors, and wireline circuits and systems.","","","10.1109/LSSC.2019.2912280","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8716615","","Special issues and sections;Meetings;Very large scale integration;Deep learning;Photomultipliers;CMOS technology","","","","","0","","","","","IEEE","IEEE Journals"
"The Dangers of Following Trends in Research: Sparsity and Other Examples of Hammers in Search of Nails","T. Adalı; H. J. Trussell; L. K. Hansen; V. D. Calhoun","Department of CSEE, University of Maryland, Baltimore County, Baltimore, MD, USA; Department of Electrical and Computer Engineering, North Carolina State University, Raleigh, NC, USA; DTU Compute, Technical University of Denmark, Lyngby, DK, Denmark; University of New Mexico and the Mind Research Network, Albuquerque, NM, USA","Proceedings of the IEEE","","2018","106","6","1014","1018","Trends, they are not only for the fashion industry after all. Within the engineering and computer science research communities as well, we periodically observe the phenomenon, see how certain methods suddenly start receiving particular attention, and sometimes, even though they emerge as an attractive solution for a given set of problems, they tend to become a hammer looking for new nails. At fi rst, using a new method on old problems is the natural and reasonable way to proceed. There have been remarkable successes achieved through the adoption of a tool from another fi eld or a new way of looking at old problems that brings new insights and solutions. There have been a number of such trends throughout the years in every field. In signal processing, a few notable ones include maximum entropy, wavelets, kernel methods, and the multiple up and down cycles of neural nets. A current tool that is on the rise is sparsity, more specifically solutions that promote sparsity, including coding, compressive sensing, sparse learning/estimation, sparse factorizations, and of course deep nets, which, without careful use of sparsity, would be useless. We will use sparsity as the major example in this Point of View article because it is current and illustrates the points we are making very well. While we agree that sparsity is very useful and has led to some excellent results in the past decade or so, it also allows us to address the dangers and pitfalls of blindly following trends in research. These problems are reflected in our publications and help define the overall research climate. In the following, we provide an overview on use of sparsity and then discuss a couple of specific problems.","","","10.1109/JPROC.2018.2823428","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8365900","","Technological innovation;Tools;Market research;Research initiatives;Performance evaluation","compressed sensing;entropy;learning (artificial intelligence);matrix decomposition;neural nets;wavelet transforms","sparse factorizations;sparse estimation;sparse learning;compressive sensing;coding;deep nets;kernel methods;wavelets;entropy;signal processing;neural nets","","","20","","","","","IEEE","IEEE Journals"
"Guest Editorial: Special Issue on Human–Machine Symbiosis","","","IEEE Transactions on Emerging Topics in Computational Intelligence","","2018","2","4","246","248","The five papers in this special section address the topic of human-machine symbiosis. The field of Computational Intelligence (CI) continues to introduce game-changing and disruptive technologies with the potential for large acceleration of the human-machine symbiosis. Deep learning is resulting in machines that are smarter and adaptive. Fuzzy systems offer opportunities to provide more human-like processing and transparency for humans to understand what their machine counterparts are doing. Evolutionary computation can be used to optimize and adapt these systems. Swarm intelligence offers the foundation for effective machine teaming. Behavioral analytics using CI can be used to convert low-level actions by both humans and machines into high-level meaning. Yet, the literature on the use and effect of these tools on human-machine symbiosis is dispersed over scientific areas and researchers. This special issue aims to help foster a synergy of thought in this emerging direction.","","","10.1109/TETCI.2018.2853518","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8416801","","Special issues and sections;Machine learning;Symbiosis;Fuzzy systems;Artificial intelligence;Behavioral sciences;Human computer interaction;Man-machine systems","","","","1","","","","","","IEEE","IEEE Journals"
"Guest Editorial: Multifaceted Driver–Vehicle Systems: Toward More Effective Driving Simulations, Reliable Driver Modeling, and Increased Trust and Safety","","","IEEE Transactions on Human-Machine Systems","","2018","48","1","1","5","The papers in this special section focus on multifaceted driver-vehicle systems. The current panorama of driver–vehicle systems is rapidly evolving, as the path toward autonomous vehicles is being paved. Many design decisions are yet to be made, and evolving legislative policies will play a significant role in the scientific research, which needs to be addressed. For example, there are countries that are considering a “step change” from fully human- driven to fully automated vehicles, while others are designing a period of coexistence of the two driving modes. Clearly, either of these approaches will require deep study of the interactions that will develop between drivers and vehicles. Related to this, for the first time in history, automated systems will primarily control vehicles and drivers may become passive “spectators” to vehicle control. However, it is also reasonable to expect that humans will be asked to intervene in dubious and/or dangerous situations that are not manageable by automation alone. Such interventions may also be used as bases for “robotic drivers” to learn human-based reasoning and ethics in vehicle control. Some researchers have already started to ask for how long will “former” drivers be able to offer prompt and wise reactions to off-nominal events, as their capabilities will decline with automation dependence and loss of practice. It is easy to foresee that the next decade will be crucial for scientific research in this field. Scientists will be asked to provide prompt and reliable responses to whatever final human–automation interaction scenario will develop for driving activities. To address this need, human–machine systems competencies will be of the utmost importance. In the context outlined above, and in preparation for autonomous vehicles driving around the world, some of the issues that need to be tackled include design of more accurate and reliable driving simulation models for coexistence tests, in which autonomous vehicles are simulated together with humandriven ones. Such technology is needed to reproduce interaction schemes that will develop on roadways and replicate the specific cues to which drivers may be exposed for the assessment of consequent behaviors. These tools are expected to provide more efficient methods for estimating different aspects of driver behaviors.","","","10.1109/THMS.2017.2784018","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8259355","","Special issues and sections;Intelligent vehicles;Man-machine systems;Brain modeling;Solid modeling;Vehicle safety","","","","2","","","","","","IEEE","IEEE Journals"
"Call for papers special section on deep learning for natural language processing","","","Tsinghua Science and Technology","","2018","23","3","366","366","The publication of Tsinghua Science and Technology was started in 1996. Since then, it has been an international academic journal sponsored by Tsinghua University and published bimonthly. This journal aims at presenting the state-of-the-art scientific achievements in computer science and other IT fields. From 2012, the journal enters into IEEE Xplore Digital Library with the open access mode. In 2015, Tsinghua Science and Technology has been indexed in the Science Citation Index Expanded.","","","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8400438","","","","","","","","","","","","TUP","TUP Journals"
"Journal of Selected Topics in Quantam Electronics on Photonics for Deep Learning and Neural Computing","","","IEEE Journal of Quantum Electronics","","2018","54","6","1","1","Advertisement, IEEE.","","","10.1109/JQE.2018.2882729","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8548671","","","","","","","","","","","","IEEE","IEEE Journals"
"Photonics for Deep Learning and Neural Computing","","","IEEE Journal of Selected Topics in Quantum Electronics","","2018","24","6","1","1","Prospective authors are requested to submit new, unpublished manuscripts for inclusion in the upcoming event described in this call for papers.","","","10.1109/JSTQE.2018.2881528","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8558750","","","","","","","","","","","","IEEE","IEEE Journals"
