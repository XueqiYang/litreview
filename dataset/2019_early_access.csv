"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,"Reference Count","License","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Learning Deep Landmarks for Imbalanced Classification","F. Bao; Y. Deng; Y. Kong; Z. Ren; J. Suo; Q. Dai","Department of Automation, Tsinghua University, Beijing 100084, China.; School of Astronautics, Beihang University, Beijing 100191, China (e-mail: yuedeng.thu@gmail.com).; College of Computer Science, Southeast University, Nanjing 210096, China.; Department of Automation, Tsinghua University, Beijing 100084, China.; Department of Automation, Tsinghua University, Beijing 100084, China.; Department of Automation, Tsinghua University, Beijing 100084, China.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","14","We introduce a deep imbalanced learning framework called learning DEep Landmarks in laTent spAce (DELTA). Our work is inspired by the shallow imbalanced learning approaches to rebalance imbalanced samples before feeding them to train a discriminative classifier. Our DELTA advances existing works by introducing the new concept of rebalancing samples in a deeply transformed latent space, where latent points exhibit several desired properties including compactness and separability. In general, DELTA simultaneously conducts feature learning, sample rebalancing, and discriminative learning in a joint, end-to-end framework. The framework is readily integrated with other sophisticated learning concepts including latent points oversampling and ensemble learning. More importantly, DELTA offers the possibility to conduct imbalanced learning with the assistancy of structured feature extractor. We verify the effectiveness of DELTA not only on several benchmark data sets but also on more challenging real-world tasks including click-through-rate (CTR) prediction, multi-class cell type classification, and sentiment analysis with sequential inputs.","","","10.1109/TNNLS.2019.2927647","Project of Beijing Municipal Science and Technology Commission; Project of NSFC; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8788460","Classification;deep learning;imbalanced learning.","Deep learning;Neural networks;Data models;Feature extraction;Hidden Markov models;Task analysis;Learning systems","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Robust and Communication-Efficient Federated Learning From Non-i.i.d. Data","F. Sattler; S. Wiedemann; K. Müller; W. Samek","Fraunhofer Heinrich Hertz Institute, 10587 Berlin, Germany.; Fraunhofer Heinrich Hertz Institute, 10587 Berlin, Germany.; Technische Universität Berlin, 10587 Berlin, Germany, with the Max Planck Institute for Informatics, 66123~Saarbrücken, Germany, and also with the Department of Brain and Cognitive Engineering, Korea University, Seoul 136-713, South Korea (e-mail: klaus-robert.mueller@tu-berlin.de).; Fraunhofer Heinrich Hertz Institute, 10587 Berlin, Germany (e-mail: wojciech.samek@hhi.fraunhofer.de).","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","14","Federated learning allows multiple parties to jointly train a deep learning model on their combined data, without any of the participants having to reveal their local data to a centralized server. This form of privacy-preserving collaborative learning, however, comes at the cost of a significant communication overhead during training. To address this problem, several compression methods have been proposed in the distributed training literature that can reduce the amount of required communication by up to three orders of magnitude. These existing methods, however, are only of limited utility in the federated learning setting, as they either only compress the upstream communication from the clients to the server (leaving the downstream communication uncompressed) or only perform well under idealized conditions, such as i.i.d. distribution of the client data, which typically cannot be found in federated learning. In this article, we propose sparse ternary compression (STC), a new compression framework that is specifically designed to meet the requirements of the federated learning environment. STC extends the existing compression technique of top-k gradient sparsification with a novel mechanism to enable downstream compression as well as ternarization and optimal Golomb encoding of the weight updates. Our experiments on four different learning tasks demonstrate that STC distinctively outperforms federated averaging in common federated learning scenarios. These results advocate for a paradigm shift in federated optimization toward high-frequency low-bitwidth communication, in particular in the bandwidth-constrained learning environments.","","","10.1109/TNNLS.2019.2944481","Fraunhofer Society; German Ministry for Education and Research as Berlin Big Data Center; Berlin Center for Machine Learning; DFG; Information and Communications Technology Planning and Evaluation IITP Grant funded by the Korea Government; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8889996","Deep learning;distributed learning;efficient communication;federated learning;privacy-preserving machine learning.","Training;Data models;Servers;Deep learning;Protocols;Training data;Distributed databases","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Deep Reinforcement Learning for Sequence-to-Sequence Models","Y. Keneshloo; T. Shi; N. Ramakrishnan; C. K. Reddy","Discovery Analytics Center, Department of Computer Science, Virginia Tech, Arlington, VA 22203 USA (e-mail: yaserkl@vt.edu).; Discovery Analytics Center, Department of Computer Science, Virginia Tech, Arlington, VA 22203 USA.; Discovery Analytics Center, Department of Computer Science, Virginia Tech, Arlington, VA 22203 USA.; Discovery Analytics Center, Department of Computer Science, Virginia Tech, Arlington, VA 22203 USA.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","21","In recent times, sequence-to-sequence (seq2seq) models have gained a lot of popularity and provide state-of-the-art performance in a wide variety of tasks, such as machine translation, headline generation, text summarization, speech-to-text conversion, and image caption generation. The underlying framework for all these models is usually a deep neural network comprising an encoder and a decoder. Although simple encoder--decoder models produce competitive results, many researchers have proposed additional improvements over these seq2seq models, e.g., using an attention-based model over the input, pointer-generation models, and self-attention models. However, such seq2seq models suffer from two common problems: 1) exposure bias and 2) inconsistency between train/test measurement. Recently, a~completely novel point of view has emerged in addressing these two problems in seq2seq models, leveraging methods from reinforcement learning (RL). In this survey, we~consider seq2seq problems from the RL point of view and provide a formulation combining the power of RL methods in decision-making with seq2seq models that enable remembering long-term memories. We present some of the most recent frameworks that combine the concepts from RL and deep neural networks. Our work aims to provide insights into some of the problems that inherently arise with current approaches and how we can address them with better RL models. We also provide the source code for implementing most of the RL models discussed in this paper to support the complex task of abstractive text summarization and provide some targeted experiments for these RL models, both in terms of performance and training~time.","","","10.1109/TNNLS.2019.2929141","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8801910","Actor--critic (AC) methods;deep learning;policy gradients (PGs);Q-learning;reinforcement learning (RL);sequence-to-sequence (seq2seq) learning","Training;Analytical models;Maximum likelihood decoding;Computational modeling;Learning systems;Reinforcement learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Nonlinear Regression via Deep Negative Correlation Learning","L. Zhang; Z. Shi; M. Cheng; Y. Liu; J. Bian; J. T. Zhou; G. Zheng; Z. Zeng","Computer Science, Institute for Infocomm Research, 68705 Singapore, Singapore Singapore (e-mail: lzhang027@ntu.edu.sg); University of Amsterdam, Amsterdam, Amsterdam Netherlands (e-mail: iezlshi@gmail.com); Computer Science, Nankai University, 12538 Tianjin, Tianjin China (e-mail: cmm@nankai.edu.cn); CCCE & CS, Nankai University, 12538 Tianjin, Tianjin China (e-mail: nk12csly@mail.nankai.edu.cn); Computer Science, Nankai University, 12538 TIANJIN, TIANJIN China (e-mail: jiawang.bian@gmail.com); Computer Science, Institute of High Performance Computing, 208717 Singapore, Singapore Singapore (e-mail: joey.tianyi.zhou@gmail.com); Institute for Surgical Technology and Biomechanics, University of Bern, Bern, Select State/Province Switzerland 3014 (e-mail: guoyan.zheng@ieee.org); Institute for Infocomm Research, Agency for Science, Technology and Research, Singapore, Singapore Singapore (e-mail: zengz@i2r.a-star.edu.sg)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Nonlinear regression has been extensively employed in many computer vision problems (e.g., crowd counting, age estimation, affective computing). Under the umbrella of deep learning, two common solutions exist i) transforming nonlinear regression to a robust loss function which is jointly optimizable with the deep convolutional network, and ii) utilizing ensemble of deep networks. Although some improved performance is achieved, the former may be lacking due to the intrinsic limitation of choosing a single hypothesis and the latter usually suffers from much larger computational complexity. To cope with those issues, we propose to regress via an efficient ""divide and conquer"" manner. The core of our approach is the generalization of negative correlation learning that has been shown, both theoretically and empirically, to work well for non-deep regression problems. Without extra parameters, the proposed method controls the bias-variance-covariance trade-off systematically and usually yields a deep regression ensemble where each base model is both ""accurate"" and ""diversified."" Moreover, we show that each sub-problem in the proposed method has less Rademacher Complexity and thus is easier to optimize. Extensive experiments on several diverse and challenging tasks including crowd counting, personality analysis, age estimation, and image super-resolution demonstrate the superiority over challenging baselines.","","","10.1109/TPAMI.2019.2943860","Tianjin key S and T Projects on new generation AI; Tianjin Natural Science Foundation for Distinguished Young Scholars; the national youth talent support program; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8850209","deep learning;deep regression;negative correlation learning;convolutional neural network","Task analysis;Estimation;Training;Correlation;Computational modeling;Deep learning;Computer vision","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Approximate Policy-Based Accelerated Deep Reinforcement Learning","X. Wang; Y. Gu; Y. Cheng; A. Liu; C. L. P. Chen","School of Information and Control Engineering, China University of Mining and Technology, Xuzhou 221116, China, and also with the Xuzhou Key Laboratory of Artificial Intelligence and Big Data, Xuzhou 221116, China.; School of Information and Control Engineering, China University of Mining and Technology, Xuzhou 221116, China, and also with the Xuzhou Key Laboratory of Artificial Intelligence and Big Data, Xuzhou 221116, China.; School of Information and Control Engineering, China University of Mining and Technology, Xuzhou 221116, China, and also with the Xuzhou Key Laboratory of Artificial Intelligence and Big Data, Xuzhou 221116, China (e-mail: chengyuhu@163.com).; School of Information Science and Technology, University of Science and Technology of China, Hefei 230026, China.; School of Computer Science and Engineering, South China University of Technology, Guangzhou 510006, China, and also with the Faculty of Science and Technology, University of Macau, Macau 999078, China.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","11","In recent years, the deep reinforcement learning (DRL) algorithms have been developed rapidly and have achieved excellent performance in many challenging tasks. However, due to the complexity of network structure and a large amount of network parameters, the training of deep network is time-consuming, and consequently, the learning efficiency of DRL is limited. In this paper, aiming to speed up the learning process of DRL agent, we propose a novel approximate policy-based accelerated (APA) algorithm from the viewpoint of the error analysis of approximate policy iteration reinforcement learning algorithms. The proposed APA is proven to be convergent even with a more aggressive learning rate, making the DRL agent have a faster learning speed. Furthermore, to combine the accelerated algorithm with deep Q-network (DQN), Double DQN and deep deterministic policy gradient (DDPG), we proposed three novel DRL algorithms: APA-DQN, APA-Double DQN, and APA-DDPG, which demonstrates the adaptability of the accelerated algorithm with DRL algorithms. We have tested the proposed algorithms on both discrete-action and continuous-action tasks. Their superior performance demonstrates their great potential in the practical applications.","","","10.1109/TNNLS.2019.2927227","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8789695","Approximate policy;deep reinforcement learning (DRL);learning efficiency;value function estimate.","Approximation algorithms;Task analysis;Training;Acceleration;Convergence;Reinforcement learning;Graphics processing units","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Multimodal Deep Network Embedding With Integrated Structure and Attribute Information","C. Zheng; L. Pan; P. Wu","School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai 200240, China.; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai 200240, China (e-mail: panli@sjtu.edu.cn).; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai 200240, China.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","13","Network embedding is the process of learning low-dimensional representations for nodes in a network while preserving node features. Existing studies only leverage network structure information and emphasize the preservation of structural features. However, nodes in real-world networks often have a rich set of attributes providing extra semantic information. It has been demonstrated that both structural and attribute features are important for network analysis tasks. To preserve both features, we investigate the problem of integrating structure and attribute information to perform network embedding and propose a multimodal deep network embedding (MDNE) method. MDNE captures the non-linear network structures and the complex interactions among structures and attributes using a deep model consisting of multiple layers of non-linear functions. Since structures and attributes are two different types of information, a multimodal learning method is adopted to pre-process them and help the model to better capture the correlations between node structure and attribute information. We define the loss function employing structural and attribute proximities to preserve the respective features, and the representations are obtained by minimizing the loss function. Results of extensive experiments on four real-world data sets show that the proposed method performs significantly better than baselines on a variety of tasks, which demonstrates the effectiveness and generality of our method.","","","10.1109/TNNLS.2019.2920267","National Natural Science Foundation of China; National Key Research and Development Plan in China; Shanghai Sailing Program; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8745502","Deep learning;multimodal learning;network analysis;network embedding.","Task analysis;Correlation;Learning systems;Feature extraction;Data mining;Social networking (online);Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Regionlets: Blended Representation and Deep Learning for Generic Object Detection","H. Xu; X. Lv; X. Wang; Z. Ren; N. Bodla; R. Chellappa","Apple Inc, Apple Inc, 93243 Cupertino, California United States (e-mail: hyxu@umd.edu); Intellifusion Inc., Intellifusion Inc., Redmond, Washington United States (e-mail: lvxutao@gmail.com); Intellifusion Inc., Intellifusion Inc., Redmond, Washington United States (e-mail: fanghuaxue@gmail.com); Wormpex AI Research, Wormpex AI Research, Bellevue, Washington United States (e-mail: renzhou200622@gmail.com); Department of Electrical and Computer Engineering, University of Maryland at College Park, 1068 College Park, Maryland United States (e-mail: nbodla@umiacs.umd.edu); Electrical and Computer Engineering, University of Maryland, College Park, Maryland United States (e-mail: rama@umiacs.umd.edu)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","In this paper, we propose a novel object detection algorithm named ""Deep Regionlets"" by integrating deep neural networks and conventional detection schema for accurate generic object detection. Motivated by the advantages of regionlets on modeling object deformation and multiple aspect ratios, we incorporate regionlets into an end-to-end trainable deep learning framework. The deep regionlets framework consists of a region selection network and a deep regionlet learning module. Specifically, given a detection bounding box proposal, the region selection network provides guidance on where to select sub-regions from which features can be learned from. An object proposal typically contains 3-16 sub-regions. The regionlet learning module focuses on local feature selection and transformation to alleviate the effects of appearance variations. To this end, we first realize non-rectangular region selection within the detection framework to accommodate variations in object appearance. Moreover, we design a ""gating network"" within the regionlet leaning module to enable instance dependent soft feature selection and pooling. The Deep Regionlets framework is trained end-to-end without additional efforts. We present ablation studies and extensive experiments on the PASCAL VOC dataset and the Microsoft COCO dataset. The proposed method outperforms state-of-the-art algorithms, such as RetinaNet and Mask R-CNN, even without additional segmentation labels.","","","10.1109/TPAMI.2019.2957780","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8924653","Object Detection;Deep Learning;Deep Regionlets;Spatial Transformation","Feature extraction;Detectors;Object detection;Proposals;Machine learning;Deformable models;Strain","","","","","","","","","","IEEE","IEEE Early Access Articles"
"XFlow: Cross-Modal Deep Neural Networks for Audiovisual Classification","C. Cangea; P. Veličković; P. Liò","Department of Computer Science and Technology, University of Cambridge, Cambridge CB03DF, U.K. (e-mail: ccc53@cst.cam.ac.uk).; Department of Computer Science and Technology, University of Cambridge, Cambridge CB03DF, U.K..; Department of Computer Science and Technology, University of Cambridge, Cambridge CB03DF, U.K..","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","10","In recent years, there have been numerous developments toward solving multimodal tasks, aiming to learn a stronger representation than through a single modality. Certain aspects of the data can be particularly useful in this case--for example, correlations in the space or time domain across modalities--but should be wisely exploited in order to benefit from their full predictive potential. We propose two deep learning architectures with multimodal cross connections that allow for dataflow between several feature extractors (XFlow). Our models derive more interpretable features and achieve better performances than models that do not exchange representations, usefully exploiting correlations between audio and visual data, which have a different dimensionality and are nontrivially exchangeable. This article improves on the existing multimodal deep learning algorithms in two essential ways: 1) it presents a novel method for performing cross modality (before features are learned from individual modalities) and 2) extends the previously proposed cross connections that only transfer information between the streams that process compatible data. Illustrating some of the representations learned by the connections, we analyze their contribution to the increase in discrimination ability and reveal their compatibility with a lip-reading network intermediate representation. We provide the research community with Digits, a new data set consisting of three data types extracted from videos of people saying the digits 0-9. Results show that both cross-modal architectures outperform their baselines (by up to 11.5%) when evaluated on the AVletters, CUAVE, and Digits data sets, achieving the state-of-the-art results.","","","10.1109/TNNLS.2019.2945992","DREAM CDT; European Unions Horizon 2020 Research and Innovation Programme PROPAG-AGEING; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8894404","Audiovisual;cross modality;deep learning;integration;machine learning;multimodal.","Feature extraction;Task analysis;Videos;Correlation;Visualization;Neural networks;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Geometric Matrix Completion With Deep Conditional Random Fields","D. M. Nguyen; R. Calderbank; N. Deligiannis","Department of Electronics and Informatics, Vrije Universiteit Brussel, 1050 Brussels, Belgium, and also with imec, Leuven 3001, Belgium (e-mail: mdnguyen,ndeligia@etrovub.be).; Department of Electrical and Computer Engineering, Duke University, Durham, NC 27708 USA.; Department of Electronics and Informatics, Vrije Universiteit Brussel, 1050 Brussels, Belgium, and also with imec, Leuven 3001, Belgium.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","15","The problem of completing high-dimensional matrices from a limited set of observations arises in many big data applications, especially recommender systems. The existing matrix completion models generally follow either a memory- or a model-based approach, whereas geometric matrix completion (GMC) models combine the best from both approaches. Existing deep-learning-based geometric models yield good performance, but, in order to operate, they require a fixed structure graph capturing the relationships among the users and items. This graph is typically constructed by evaluating a pre-defined similarity metric on the available observations or by using side information, e.g., user profiles. In contrast, Markov-random-fields-based models do not require a fixed structure graph but rely on handcrafted features to make predictions. When no side information is available and the number of available observations becomes very low, existing solutions are pushed to their limits. In this article, we propose a GMC approach that addresses these challenges. We consider matrix completion as a structured prediction problem in a conditional random field (CRF), which is characterized by a maximum a posteriori (MAP) inference, and we propose a deep model that predicts the missing entries by solving the MAP inference problem. The proposed model simultaneously learns the similarities among matrix entries, computes the CRF potentials, and solves the inference problem. Its training is performed in an end-to-end manner, with a method to supervise the learning of entry similarities. Comprehensive experiments demonstrate the superior performance of the proposed model compared to various state-of-the-art models on popular benchmark data sets and underline its superior capacity to deal with highly incomplete matrices.","","","10.1109/TNNLS.2019.2945111","Vrije Universiteit Brussel through Ph.D. bursary; Francqui Foundation through the 2016-2017 International Francqui Chair; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8889998","Deep conditional random field (CRF);deep learning;geometric matrix completion (GMC);mean-field inference;probabilistic graphical model.","Data models;Predictive models;Computational modeling;Neural networks;Measurement;Benchmark testing;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Label-less Learning for Emotion Cognition","M. Chen; Y. Hao","School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan 430074, China, and also with the Wuhan National Laboratory for Optoelectronics, Huazhong University of Science and Technology, Wuhan 430074, China.; School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan 430074, China, and also with the Wuhan National Laboratory for Optoelectronics, Huazhong University of Science and Technology, Wuhan 430074, China (e-mail: yixuehao@ieee.org).","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","11","In this paper, we propose a label-less learning for emotion cognition (LLEC) to achieve the utilization of a large amount of unlabeled data. We first inspect the unlabeled data from two perspectives, i.e., the feature layer and the decision layer. By utilizing the similarity model and the entropy model, this paper presents a hybrid label-less learning that can automatically label data without human intervention. Then, we design an enhanced hybrid label-less learning to purify the automatic labeled data. To further improve the accuracy of emotion detection model and increase the utilization of unlabeled data, we apply enhanced hybrid label-less learning for multimodal unlabeled emotion data. Finally, we build a real-world test bed to evaluate the LLEC algorithm. The experimental results show that the LLEC algorithm can improve the accuracy of emotion detection significantly.","","","10.1109/TNNLS.2019.2929071","National Basic Research Program of China (973 Program); National Natural Science Foundation of China; China Postdoctoral Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8796387","Deep learning;emotion detection;label-less learning;multimodal emotion cognition.","Labeling;Cognition;Data models;Feature extraction;Deep learning;Learning systems;Emotion recognition","","","","3","","","","","","IEEE","IEEE Early Access Articles"
"AlphaSeq: Sequence Discovery With Deep Reinforcement Learning","Y. Shao; S. C. Liew; T. Wang","Department of Information Engineering, The Chinese University of Hong Kong, Hong Kong.; Department of Information Engineering, The Chinese University of Hong Kong, Hong Kong (e-mail: soung@ie.cuhk.edu.hk).; Department of Information Engineering, The Chinese University of Hong Kong, Hong Kong. He is now with the College of Information Engineering, Shenzhen University, Shenzhen 518061, China.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","15","Sequences play an important role in many applications and systems. Discovering sequences with desired properties has long been an interesting intellectual pursuit. This article puts forth a new paradigm, AlphaSeq, to discover desired sequences algorithmically using deep reinforcement learning (DRL) techniques. AlphaSeq treats the sequence discovery problem as an episodic symbol-filling game, in which a player fills symbols in the vacant positions of a sequence set sequentially during an episode of the game. Each episode ends with a completely filled sequence set, upon which a reward is given based on the desirability of the sequence set. AlphaSeq models the game as a Markov decision process (MDP) and adapts the DRL framework of AlphaGo to solve the MDP. Sequences discovered improve progressively as AlphaSeq, starting as a novice, and learns to become an expert game player through many episodes of game playing. Compared with traditional sequence construction by mathematical tools, AlphaSeq is particularly suitable for problems with complex objectives intractable to mathematical analysis. We demonstrate the searching capabilities of AlphaSeq in two applications: 1) AlphaSeq successfully rediscovers a set of ideal complementary codes that can zero-force all potential interferences in multi-carrier code-division multiple access (CDMA) systems and 2) AlphaSeq discovers new sequences that triple the signal-to-interference ratio--benchmarked against the well-known Legendre sequence--of a mismatched filter (MMF) estimator in pulse compression radar systems.","","","10.1109/TNNLS.2019.2942951","General Research Funds established under the University Grant Committee of the Hong Kong Special Administrative Region China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8877997","AlphaGo;deep reinforcement learning (DRL);Monte Carlo tree search (MCTS);multi-carrier code-division multiple access (MC-CDMA);pulse compression radar.","Games;Radar;Tools;Multiaccess communication;Machine learning algorithms;Approximation algorithms;Learning systems","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Realizing Data Features by Deep Nets","Z. Guo; L. Shi; S. Lin","School of Mathematical Sciences, Zhejiang University, Hangzhou 310027, China.; Shanghai Key Laboratory for Contemporary Applied Mathematics, School of Mathematical Sciences, Fudan University, Shanghai 200433, China.; Center of Intelligent Decision-Making and Machine Learning, School of Management, Xi'an Jiaotong University, Xi'an 710049, China, and also with the Department of Mathematics, Wenzhou University, Wenzhou 325035, China (e-mail: sblin1983@gmail.com).","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","13","This article considers the power of deep neural networks (deep nets) in realizing data features. Based on refined covering number estimates, we find that, to realize data features such as the locality, rotation invariance, and manifold structure, deep nets essentially improve the performances of shallow neural networks (shallow nets) without requiring additional capacity costs. Conversely, to realize some data features, such as the smoothness, we show that deep nets perform similar as shallow nets, provided the depth is not extremely large. Both sides show the advantages and limitations of deep nets in realizing data features and demonstrate that deep nets are not always better than shallow nets.","","","10.1109/TNNLS.2019.2951788","National Natural Science Foundation of China; Program of Shanghai Subject Chief Scientist; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8924927","Approximation rates;covering numbers;data feature;deep neural networks (deep nets);neural networks.","Neural networks;Machine learning;Manifolds;Computer vision;Sparse matrices;Learning systems","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Diagnosing Rotating Machines with Weakly Supervised Data Using Deep Transfer Learning","X. Li; W. Zhang; Q. Ding; X. Li","College of Sciences, Northeastern University, Shenyang China 110819 (e-mail: xiangli@mail.neu.edu.cn); School of Aerospace Engineering, Shenyang Aerospace University, 66284 Shenyang China 110136 (e-mail: zw_7126257@163.com); Department of Mechanics, Tianjin University, Tianjin China 300072 (e-mail: qding@tju.edu.cn); Sate Key Laboratory of Rolling and Automation, Northeastern University, Shenyang China 110819 (e-mail: lixu@ral.neu.edu.cn)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","Rotating machinery fault diagnosis problems have been well addressed when sufficient supervised data of the tested machine are available using the latest data-driven methods. However, it is still challenging to develop effective diagnostic method with insufficient training data, which is highly demanded in real industrial scenarios since high-quality data are usually difficult and expensive to collect. Considering the underlying similarities of rotating machines, data mining on different but related equipments potentially benefit the diagnostic performance on the target machine. Therefore, a novel transfer learning method for diagnostics based on deep learning is proposed in this paper, where the diagnostic knowledge learned from sufficient supervised data of multiple rotating machines is transferred to the target equipment with domain adversarial training. The experimental results on four datasets validate the effectiveness of the proposed method, and show it is feasible and promising to explore different datasets to improve diagnostic performance.","","","10.1109/TII.2019.2927590","Scientific Research Fund of Liaoning Provincial Education Department; the Fundamental Research Funds for the Central Universities; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8758199","Fault diagnosis;rotating machinery;transfer learning;deep learning;adversarial training","Fault diagnosis;Training;Task analysis;Feature extraction;Rotating machines;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Semi-Supervised Graph Regularized Deep NMF With Bi-Orthogonal Constraints for Data Representation","Y. Meng; R. Shang; F. Shang; L. Jiao; S. Yang; R. Stolkin","Joint International Research Laboratory of Intelligent Perception and Computation, Xidian University, Xi'an 710071, China, also with the Key Laboratory of Intelligent Perception and Image Understanding, Ministry of Education, Xidian University, Xi'an 710071, China, also with the International Research Center for Intelligent Perception and Computation, Xidian University, Xi'an 710071, China, and also with the School of Artificial Intelligence, Xidian University, Xi'an 710071, China.; Joint International Research Laboratory of Intelligent Perception and Computation, Xidian University, Xi'an 710071, China, also with the Key Laboratory of Intelligent Perception and Image Understanding, Ministry of Education, Xidian University, Xi'an 710071, China, also with the International Research Center for Intelligent Perception and Computation, Xidian University, Xi'an 710071, China, and also with the School of Artificial Intelligence, Xidian University, Xi'an 710071, China (e-mail: rhshang@mail.xidian.edu).; Joint International Research Laboratory of Intelligent Perception and Computation, Xidian University, Xi'an 710071, China, also with the Key Laboratory of Intelligent Perception and Image Understanding, Ministry of Education, Xidian University, Xi'an 710071, China, also with the International Research Center for Intelligent Perception and Computation, Xidian University, Xi'an 710071, China, and also with the School of Artificial Intelligence, Xidian University, Xi'an 710071, China.; Joint International Research Laboratory of Intelligent Perception and Computation, Xidian University, Xi'an 710071, China, also with the Key Laboratory of Intelligent Perception and Image Understanding, Ministry of Education, Xidian University, Xi'an 710071, China, also with the International Research Center for Intelligent Perception and Computation, Xidian University, Xi'an 710071, China, and also with the School of Artificial Intelligence, Xidian University, Xi'an 710071, China.; Joint International Research Laboratory of Intelligent Perception and Computation, Xidian University, Xi'an 710071, China, also with the Key Laboratory of Intelligent Perception and Image Understanding, Ministry of Education, Xidian University, Xi'an 710071, China, also with the International Research Center for Intelligent Perception and Computation, Xidian University, Xi'an 710071, China, and also with the School of Artificial Intelligence, Xidian University, Xi'an 710071, China.; Extreme Robotics Lab, University of Birmingham, Birmingham B15 2TT, U.K..","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","14","Semi-supervised non-negative matrix factorization (NMF) exploits the strengths of NMF in effectively learning local information contained in data and is also able to achieve effective learning when only a small fraction of data is labeled. NMF is particularly useful for dimensionality reduction of high-dimensional data. However, the mapping between the low-dimensional representation, learned by semi-supervised NMF, and the original high-dimensional data contains complex hierarchical and structural information, which is hard to extract by using only single-layer clustering methods. Therefore, in this article, we propose a new deep learning method, called semi-supervised graph regularized deep NMF with bi-orthogonal constraints (SGDNMF). SGDNMF learns a representation from the hidden layers of a deep network for clustering, which contains varied and unknown attributes. Bi-orthogonal constraints on two factor matrices are introduced into our SGDNMF model, which can make the solution unique and improve clustering performance. This improves the effect of dimensionality reduction because it only requires a small fraction of data to be labeled. In addition, SGDNMF incorporates dual-hypergraph Laplacian regularization, which can reinforce high-order relationships in both data and feature spaces and fully retain the intrinsic geometric structure of the original data. This article presents the details of the SGDNMF algorithm, including the objective function and the iterative updating rules. Empirical experiments on four different data sets demonstrate state-of-the-art performance of SGDNMF in comparison with six other prominent algorithms.","","","10.1109/TNNLS.2019.2939637","National Natural Science Foundation of China; Key Laboratory Fund; Program for Cheung Kong Scholars and Innovative Research Team in University; Science Foundation of Xidian University; National Science Basic Research Plan in Shaanxi Province of China; Royal Society Industry Fellowship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8858038","Bi-orthogonal constraints;deep non-negative matrix factorization (NMF);dimensionality reduction;dual-hypergraph Laplacian regularization;semi-supervised learning.","Matrix decomposition;Data mining;Dimensionality reduction;Linear programming;Deep learning;Laplace equations;Feature extraction","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Deep Supervised Learning Framework for Data-Driven Soft Sensor Modeling of Industrial Processes","X. Yuan; Y. Gu; Y. Wang; C. Yang; W. Gui","School of Automation, Central South University, Changsha 410083, China.; School of Automation, Central South University, Changsha 410083, China.; School of Automation, Central South University, Changsha 410083, China (e-mail: ylwang@csu.edu.cn).; School of Automation, Central South University, Changsha 410083, China.; School of Automation, Central South University, Changsha 410083, China.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","10","Deep learning has been recently introduced for soft sensors in industrial processes. However, most of the existing deep networks, such as stacked autoencoder, are pretrained in a layerwise unsupervised way to learn feature representations for the raw input data itself. For soft sensors, it is necessary to extract quality-relevant features for quality prediction. Thus, a deep layerwise supervised pretraining framework is proposed for quality-relevant feature extraction and soft sensor modeling in this article, which is based on stacked supervised encoder-decoder (SSED). In SSED, hierarchical quality-relevant features are successively learned by a number of supervised encoder-decoder (SED) models. For each SED, the features from the previous hidden layer are served as new inputs to generate the high-level features that are learned with the constraint of predicting the quality data as good as possible at the output layer of this SED. With this new structure, the SED can learn quality-relevant features that can largely improve the prediction performance. By stacking multiple SEDs, hierarchical quality-relevant features can be progressively learned, and irrelevant information is gradually reduced by deep SSED network. The effectiveness of the proposed model is demonstrated on a numerical example and an industrial process of the debutanizer column.","","","10.1109/TNNLS.2019.2957366","National Key R and D Program of China; National Natural Science Foundation of China; Natural Science Foundation of Hainan Province; Innovation-Driven Plan in Central South University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8941265","Deep learning;feature representation;quality prediction;soft sensor;supervised learning.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Communication-Efficient Federated Deep Learning With Layerwise Asynchronous Model Update and Temporally Weighted Aggregation","Y. Chen; X. Sun; Y. Jin","School of Information and Control Engineering, China University of Mining and Technology, Xuzhou 221116, China, and also with the School of Computer Science and Engineering, Nanyang Technological University, Singapore 639798.; School of Information and Control Engineering, China University of Mining and Technology, Xuzhou 221116, China.; Department of Computer Science, University of Surrey, Guildford GU2 7XH, U.K. (e-mail: yaochu.jin@surrey.ac.uk).","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","10","Federated learning obtains a central model on the server by aggregating models trained locally on clients. As a result, federated learning does not require clients to upload their data to the server, thereby preserving the data privacy of the clients. One challenge in federated learning is to reduce the client-server communication since the end devices typically have very limited communication bandwidth. This article presents an enhanced federated learning technique by proposing an asynchronous learning strategy on the clients and a temporally weighted aggregation of the local models on the server. In the asynchronous learning strategy, different layers of the deep neural networks (DNNs) are categorized into shallow and deep layers, and the parameters of the deep layers are updated less frequently than those of the shallow layers. Furthermore, a temporally weighted aggregation strategy is introduced on the server to make use of the previously trained local models, thereby enhancing the accuracy and convergence of the central model. The proposed algorithm is empirically on two data sets with different DNNs. Our results demonstrate that the proposed asynchronous federated deep learning outperforms the baseline algorithm both in terms of communication cost and model accuracy.","","","10.1109/TNNLS.2019.2953131","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8945292","Aggregation;asynchronous learning;deep neural network (DNN);federated learning;temporally weighted aggregation.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Teacher-Student Curriculum Learning","T. Matiisen; A. Oliver; T. Cohen; J. Schulman","Institute of Computer Science, University of Tartu, 51005 Tartu, Estonia (e-mail: tambet.matiisen@ut.ee).; OpenAI, San Francisco, CA 94110 USA. He is now with Google Brain, Amsterdam, The Netherlands.; Informatics Institute, University of Amsterdam, 1012 WX Amsterdam, The Netherlands.; OpenAI, San Francisco, CA 94110 USA.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","9","We propose Teacher-Student Curriculum Learning (TSCL), a framework for automatic curriculum learning, where the Student tries to learn a complex task, and the Teacher automatically chooses subtasks from a given set for the Student to train on. We describe a family of Teacher algorithms that rely on the intuition that the Student should practice more those tasks on which it makes the fastest progress, i.e., where the slope of the learning curve is highest. In addition, the Teacher algorithms address the problem of forgetting by also choosing tasks where the Student's performance is getting worse. We demonstrate that TSCL matches or surpasses the results of carefully hand-crafted curricula in two tasks: addition of decimal numbers with long short-term memory (LSTM) and navigation in Minecraft. Our automatically ordered curriculum of submazes enabled to solve a Minecraft maze that could not be solved at all when training directly on that maze, and the learning was an order of magnitude faster than a uniform sampling of those submazes.","","","10.1109/TNNLS.2019.2934906","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8827566","Active learning;curriculum learning;deep reinforcement learning;learning progress.","Task analysis;Training;Reinforcement learning;Supervised learning;Robots;Navigation","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Parallel Deep Learning Detection Network in the MIMO Channel","X. Jin; H. Kim","Department of Electronics Engineering, Pusan National University, Busan 46241, Republic of Korea.; Department of Electronics Engineering, Pusan National University, Busan 46241, Republic of Korea.","IEEE Communications Letters","","2019","PP","99","1","1","For deep learning detection networks in the multiple-input-multiple-output (MIMO) channel, deepening the network does not significantly improve performance beyond a certain number of layers. In this letter, we propose a parallel detection network (PDN) that consists of several deep learning detection networks in parallel without connection. By designing a specific loss function and reducing similarity between detection networks, the PDN obtains a considerable diversity effect. The performance of the PDN improves significantly as the number of parallel detection networks increases in time-varying MIMO channels. This is superior to the existing deep learning detection networks, in both performance and complexity.","","","10.1109/LCOMM.2019.2950201","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8886388","Deep learning;detection;MIMO.","MIMO communication;Deep learning;Detectors;Receiving antennas;Training;Signal to noise ratio;Training data","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Learning for Multiple-Image Super-Resolution","M. Kawulok; P. Benecki; S. Piechaczek; K. Hrynczenko; D. Kostrzewa; J. Nalepa","Future Processing, 44-100 Gliwice, Poland, with KP Labs, 44-100 Gliwice, Poland, and also with the Faculty of Automatic Control, Electronics and Computer Science, Silesian University of Technology, 44-100 Gliwice, Poland (e-mail: michal.kawulok@ieee.org).; Future Processing, 44-100 Gliwice, Poland, with KP Labs, 44-100 Gliwice, Poland, and also with the Faculty of Automatic Control, Electronics and Computer Science, Silesian University of Technology, 44-100 Gliwice, Poland.; Future Processing, 44-100 Gliwice, Poland, with KP Labs, 44-100 Gliwice, Poland, and also with the Faculty of Automatic Control, Electronics and Computer Science, Silesian University of Technology, 44-100 Gliwice, Poland.; Future Processing, 44-100 Gliwice, Poland, with KP Labs, 44-100 Gliwice, Poland, and also with the Faculty of Automatic Control, Electronics and Computer Science, Silesian University of Technology, 44-100 Gliwice, Poland.; Future Processing, 44-100 Gliwice, Poland, with KP Labs, 44-100 Gliwice, Poland, and also with the Faculty of Automatic Control, Electronics and Computer Science, Silesian University of Technology, 44-100 Gliwice, Poland.; Future Processing, 44-100 Gliwice, Poland, with KP Labs, 44-100 Gliwice, Poland, and also with the Faculty of Automatic Control, Electronics and Computer Science, Silesian University of Technology, 44-100 Gliwice, Poland.","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","Super-resolution (SR) reconstruction is a process aimed at enhancing the spatial resolution of images, either from a single observation, based on the learned relation between low and high resolution, or from multiple images presenting the same scene. SR is particularly important, if it is not feasible to acquire images at the desired resolution, while there are single or many observations available at lower resolution--this is inherent to a variety of remote sensing scenarios. Recently, we have witnessed substantial improvement in single-image SR attributed to the use of deep neural networks for learning the relation between low and high resolution. Importantly, deep learning has not been widely exploited for multiple-image super-resolution, which benefits from information fusion and in general allows for achieving higher reconstruction accuracy. In this letter, we introduce a new approach to combine the advantages of multiple-image fusion with learning the low-to-high resolution mapping using deep networks. The results of our extensive experiments indicate that the proposed framework outperforms the state-of-the-art SR methods.","","","10.1109/LGRS.2019.2940483","European Space Agency SuperDeep Project realized by Future Processing; Statutory Research Funds of Institute of Informatics Silesian University of Technology Poland; Silesian University of Technology Poland; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8884136","Convolutional neural networks (CNNs);deep learning;image processing;super resolution (SR).","Image reconstruction;Spatial resolution;Satellites;Deep learning;Imaging;Gallium nitride","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Deep Learning Model for Transportation Mode Detection Based on Smartphone Sensing Data","X. Liang; Y. Zhang; G. Wang; S. Xu","Department of Computer Science, New Jersey Institute of Technology, Newark, NJ 07102 USA (e-mail: xl367@njit.edu).; Big Data Engine Department, MicroStrategy, Annandale, VA 22182 USA.; Department of Computer Science, New Jersey Institute of Technology, Newark, NJ 07102 USA.; Department of Information System, New Jersey Institute of Technology, Newark, NJ 07102 USA.","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","13","Understanding people's transportation modes is beneficial for empowering many intelligent transportation systems, such as supporting urban transportation planning. Yet, current methodologies in collecting travelers' transportation modes are costly and inaccurate. Fortunately, the increasing sensing and computing capabilities of smartphones and their high penetration rate offer a promising approach to automatic transportation mode detection via mobile computation. This paper introduces a light-weighted and energy-efficient transportation mode detection system using only accelerometer sensors in smartphones. The system collects accelerometer data in an efficient way and leverages a deep learning model to determine transportation modes. Different architectures and classification methods are tested with the proposed deep learning model to optimize the system design. Performance evaluation shows that the proposed new approach achieves a better accuracy than existing work in detecting people's transportation modes.","","","10.1109/TITS.2019.2951165","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8913719","Transportation mode;deep learning;smartphone;accelerometer.","Transportation;Accelerometers;Sensors;Gravity;Acceleration;Deep learning;Data models","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Cross-Batch Reference Learning for Deep Retrieval","H. Yang; K. Lin; T. Chen; C. Chen","Department of Information Management, National Sun Yat-sen University, Kaohsiung 80424, Taiwan.; Department of Electrical and Computer Engineering, University of Washington, Seattle, WA 98105 USA.; Institute of Information Science, Academia Sinica, Taipei 11529, Taiwan.; Institute of Information Science, Academia Sinica, Taipei 11529, Taiwan, also with the Research Center for Information Technology Innovation, Academia Sinica, Taipei 11529, Taiwan, and also with the MOST Joint Research Center for AI Technology and All Vista Healthcare, Taipei 10617, Taiwan (e-mail: song@iis.sinica.edu.tw).","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","14","Learning effective representations that exhibit semantic content is crucial to image retrieval applications. Recent advances in deep learning have made significant improvements in performance on a number of visual recognition tasks. Studies have also revealed that visual features extracted from a deep network learned on a large-scale image data set (e.g., ImageNet) for classification are generic and perform well on new recognition tasks in different domains. Nevertheless, when applied to image retrieval, such deep representations do not attain performance as impressive as used for classification. This is mainly because the deep features are optimized for classification rather than for the desired retrieval task. We introduce the cross-batch reference (CBR), a novel training mechanism that enables the optimization of deep networks with a retrieval criterion. With the CBR, the networks leverage both the samples in a single minibatch and the samples in the others for weight updates, enhancing the stochastic gradient descent (SGD) training by enabling interbatch information passing. This interbatch communication is implemented as a cross-batch retrieval process in which the networks are trained to maximize the mean average precision (mAP) that is a popular performance measure in retrieval. Maximizing the cross-batch mAP is equivalent to centralizing the samples relevant to each other in the feature space and separating the samples irrelevant to each other. The learned features can discriminate between relevant and irrelevant samples and thus are suitable for retrieval. To circumvent the discrete, nondifferentiable mAP maximization, we derive an approximate, differentiable lower bound that can be easily optimized in deep networks. Furthermore, the mAP loss can be used alone or with a classification loss. Experiments on several data sets demonstrate that our CBR learning provides favorable performance, validating its effectiveness.","","","10.1109/TNNLS.2019.2936876","Ministry of Science and Technology, Taiwan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8844864","Convolutional neural networks (CNNs);deep learning;image retrieval;mean average precision (mAP).","Task analysis;Image retrieval;Training;Object detection;Measurement;Proposals;Semantics","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Land Cover Classification From VHR Optical Remote Sensing Images by Feature Ensemble Deep Learning Network","S. Dong; Y. Zhuang; Z. Yang; L. Pang; H. Chen; T. Long","Engineering Center of Digital Audio and Video, Communication University of China, Beijing 100024, China.; School of Electronic Engineering and Computer Science, Peking University, Beijing 100871, China (e-mail: zhuangyin640829@163.com).; Engineering Center of Digital Audio and Video, Communication University of China, Beijing 100024, China.; Engineering Center of Digital Audio and Video, Communication University of China, Beijing 100024, China.; Beijing Key Laboratory of Embedded Real-time Information Processing Technology, Beijing 100081, China.; Beijing Key Laboratory of Embedded Real-time Information Processing Technology, Beijing 100081, China.","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","Land cover classification is a popular research field in remote sensing applications, which have to both consider the pixel-level classification and boundary mapping comprehensively. Although multi-scale features in deep learning (DL) network have a powerful classification ability, how to use multi-scale feature description to produce an accurate land cover classification from very high resolution (VHR) optical remote sensing image is still a challenging task because of large intraclass or small interclass difference of land covers. Therefore, aiming at achieving more accurate pixel-level land cover classification, we proposed a novel feature ensemble network (FE-Net), which includes the multi-scale feature encapsulation and enhancement two phases. First, there are encapsulated shallow, middle, and deep scale feature layers from Resnet-101 backbone. Second, related to multi-scale feature description enhancement, these 2-D dilation convolutions with different sample rates are employed on each scale feature layer. After that, optimal channel selection works on each intrascale and interscale feature layers sequentially. Finally, extensive experiments proved that the proposed FE-Net combined with a special joint loss function outperforms state-of-the-art DL based methods. It can achieve the 68.08% and 65.16% of the mean of class-wise intersection over union (mIoU) on ISPRS and GID data sets, respectively.","","","10.1109/LGRS.2019.2947022","China Postdoctoral Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8880474","Deep learning (DL);feature ensemble;land cover classification;optical remote sensing;very high resolution (VHR).","Remote sensing;Optical imaging;Optical sensors;Encapsulation;Correlation;Semantics;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Learning-based Detection for Moderate-density Code Multiple Access in IoT Networks","Y. Han; Z. Wang; Q. Guo; W. Xiang","Electronics and Information Engineering, Harbin Institute of Technology, Harbin 150001, China.; Electronics and Information Engineering, Harbin Institute of Technology, Harbin 150001, China. (e-mail: ZYWang@hit.edu.cn); Electronics and Information Engineering, Harbin Institute of Technology, Harbin 150001, China.; College of Science and Engineering, James Cook University, Cairns 4878, Australia.","IEEE Communications Letters","","2019","PP","99","1","1","In the era of the Internet of Things, massive devices communications become a fundamental problem. To improve spectral efficiency and reduce latency, a new non-orthogonal multiple access scheme dubbed moderate-density code multiple access (MCMA) is presented. We also propose a new deep learningbased multi-user detection algorithm for MCMA systems, which is based upon a new graphic representation of the Tanner graph for the message passing algorithm (MPA). The proposed algorithm learns to adjust the weights of the edges of the neural network to realize multi-user detection without iterations as required in conventional MPA algorithms. Experimental results show that with an increase in the overloading factor and the number of users, the BER performance of the proposed scheme is better than that of deep learning-aided SCMA (DL-SCMA) with a lower computational complexity.","","","10.1109/LCOMM.2019.2952392","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8894490","Internet of Things;MCMA;multi-user detection;deep learning;low complexity","Multiuser detection;Decoding;Neural networks;Iterative decoding;Internet of Things;Deep learning;Graphics","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Multi-Agent Deep Reinforcement Learning for Large-Scale Traffic Signal Control","T. Chu; J. Wang; L. Codecà; Z. Li","Department of Civil and Environmental Engineering, Stanford University, CA 94305 USA (e-mail: cts198859@hotmail.com).; Department of Civil and Environmental Engineering, Stanford University, CA 94305 USA.; Communication Systems Department, EURECOM, 06904 Sophia-Antipolis, France; Department of Mechanical Engineering, Michigan State University, East Lansing, MI 48824 USA.","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","10","Reinforcement learning (RL) is a promising data-driven approach for adaptive traffic signal control (ATSC) in complex urban traffic networks, and deep neural networks further enhance its learning power. However, the centralized RL is infeasible for large-scale ATSC due to the extremely high dimension of the joint action space. The multi-agent RL (MARL) overcomes the scalability issue by distributing the global control to each local RL agent, but it introduces new challenges: now, the environment becomes partially observable from the viewpoint of each local agent due to limited communication among agents. Most existing studies in MARL focus on designing efficient communication and coordination among traditional Q-learning agents. This paper presents, for the first time, a fully scalable and decentralized MARL algorithm for the state-of-the-art deep RL agent, advantage actor critic (A2C), within the context of ATSC. In particular, two methods are proposed to stabilize the learning procedure, by improving the observability and reducing the learning difficulty of each local agent. The proposed multi-agent A2C is compared against independent A2C and independent Q-learning algorithms, in both a large synthetic traffic grid and a large real-world traffic network of Monaco city, under simulated peak-hour traffic dynamics. The results demonstrate its optimality, robustness, and sample efficiency over the other state-of-the-art decentralized MARL algorithms.","","","10.1109/TITS.2019.2901791","French National Research Agency ANR Project; EURECOM partners BMW Group IABG Monaco Telecom Orange SAP ST Microelectronics and Symantec; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8667868","Adaptive traffic signal control;reinforcement learning;multi-agent reinforcement learning;deep reinforcement learning;actor-critic.","Reinforcement learning;Scalability;Heuristic algorithms;Mathematical model;Codecs;Neural networks;Convergence","","","","2","","","","","","IEEE","IEEE Early Access Articles"
"Deep Learning for Intelligent Transportation Systems: A Survey of Emerging Trends","M. Veres; M. Moussa","School of Engineering, University of Guelph, Guelph, ON N1G 2W1, Canada (e-mail: mveres@uoguelph.ca).; School of Engineering, University of Guelph, Guelph, ON N1G 2W1, Canada.","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","17","Transportation systems operate in a domain that is anything but simple. Many exhibit both spatial and temporal characteristics, at varying scales, under varying conditions brought on by external sources such as social events, holidays, and the weather. Yet, modeling the interplay of factors, devising generalized representations, and subsequently using them to solve a particular problem can be a challenging task. These situations represent only a fraction of the difficulties faced by modern intelligent transportation systems (ITS). In this paper, we present a survey that highlights the role modeling techniques within the realm of deep learning have played within ITS. We focus on how practitioners have formulated problems to address these various challenges, and outline both architectural and problem-specific considerations used to develop solutions. We hope this survey can help to serve as a bridge between the machine learning and transportation communities, shedding light on new domains and considerations in the future.","","","10.1109/TITS.2019.2929020","Natural Sciences and Engineering Research Council of Canada NSERC; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8771378","Intelligent transportation systems (ITS);deep learning (DL);neural networks;pattern recognition;survey.","Transportation;Deep learning;Trajectory;Artificial neural networks;Convolution","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"DeepBalance: Deep-Learning and Fuzzy Oversampling for Vulnerability Detection","S. Liu; G. Lin; Q. Han; S. Wen; J. Zhang; Y. Xiang","Department of Computer Science and Software Engineering, School of Software and Electrical Engineering, Hawthorn, Victoria Australia 3122 (e-mail: shigang.liu@research.deakin.edu.au); Department of Computer Science and Software Engineering, Swinburne University of Technology, 3783 Hawthorn, Victoria Australia (e-mail: glin@swin.edu.au); Department of Computer Science and Software Engineering, Swinburne University of Technology, 3783 Hawthorn, Victoria Australia (e-mail: qhan@swin.edu.au); Department of Computer Science and Software Engineering, Swinburne University of Technology, 3783 Hawthorn, Victoria Australia (e-mail: swen@swin.edu.au); Department of Computer Science and Software Engineering, Swinburne University of Technology, 3783 Hawthorn, Victoria Australia (e-mail: junzhang@swin.edu.au); Department of Computer Science and Software Engineering, Swinburne University of Technology, 3783 Hawthorn, Victoria Australia (e-mail: yxiang@swin.edu.au)","IEEE Transactions on Fuzzy Systems","","2019","PP","99","1","1","Software vulnerability has long been an important but critical research issue in cybersecurity. Recently, the machine learning (ML) based approach has attracted increasing interest in the research of software vulnerability detection. However, the detection performance of existing ML-based methods require further improvement. There are two challenges: one is code representation for machine learning and the other is class imbalance between vulnerable code and non-vulnerable code. To overcome these challenges, this paper develops a DeepBalance system, which combines the new ideas of deep code representation learning and fuzzy-based class rebalancing. We design a deep neural network with Bidirectional Long Short-Term Memory (BiLSTM) to learn invariant and discriminative code representations from labelled vulnerable and non-vulnerable code. Then, a new fuzzy oversampling method is employed to rebalance the training data by generating synthetic samples for the class of vulnerable code. To evaluate the performance of the new system, we carry out a series of experiments in a real-world ground-truth data set that consists of the code from the projects of LibTIFF, LibPNG, and FFmpeg. The results show that the proposed new system can significantly improve the vulnerability detection performance. For example, the improvement achieves 15% in terms of F-measure.","","","10.1109/TFUZZ.2019.2958558","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8930093","Software vulnerability detection;class imbalance;machine learning;deep learning;feature learning","Software;Machine learning;Feature extraction;Training data;Measurement;Security;Databases","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Layer-Wise Data Augmentation Strategy for Deep Learning Networks and Its Soft Sensor Application in an Industrial Hydrocracking Process","X. Yuan; C. Ou; Y. Wang; C. Yang; W. Gui","School of Automation, Central South University, Changsha 410083, China; School of Automation, Central South University, Changsha 410083, China (e-mail: 657943838@qq.com).; School of Automation, Central South University, Changsha 410083, China (e-mail: ylwang@csu.edu.cn).; School of Automation, Central South University, Changsha 410083, China; School of Automation, Central South University, Changsha 410083, China","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","10","In industrial processes, inferential sensors have been extensively applied for prediction of quality variables that are difficult to measure online directly by hard sensors. Deep learning is a recently developed technique for feature representation of complex data, which has great potentials in soft sensor modeling. However, it often needs a large number of representative data to train and obtain a good deep network. Moreover, layer-wise pretraining often causes information loss and generalization degradation of high hidden layers. This greatly limits the implementation and application of deep learning networks in industrial processes. In this article, a layer-wise data augmentation (LWDA) strategy is proposed for the pretraining of deep learning networks and soft sensor modeling. In particular, the LWDA-based stacked autoencoder (LWDA-SAE) is developed in detail. Finally, the proposed LWDA-SAE model is applied to predict the 10% and 50% boiling points of the aviation kerosene in an industrial hydrocracking process. The results show that the LWDA-SAE-based soft sensor is superior to multilayer perceptron, traditional SAE, and the SAE with data augmentation only for its input layer (IDA-SAE). Moreover, LWDA-SAE can converge at a faster speed with a lower learning error than the other methods.","","","10.1109/TNNLS.2019.2951708","National Basic Research Program of China (973 Program); National Natural Science Foundation of China; Natural Science Foundation of Hainan Province; Innovation-Driven Plan in Central South University; Fundamental Research Funds for the Central Universities of Central South University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8932596","Data augmentation (DA);deep learning;hydrocracking process;quality prediction;soft sensor.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Knowledge-Driven Deep Unrolling for Robust Image Layer Separation","R. Liu; Z. Jiang; X. Fan; Z. Luo","DUT-RU International School of Information Science and Engineering, Dalian University of Technology, Dalian 116024, China, and also with the Key Laboratory for Ubiquitous Network and Service Software of Liaoning Province, Dalian University of Technology, Dalian 116024, China (e-mail: rsliu@dlut.edu.cn).; DUT-RU International School of Information Science and Engineering, Dalian University of Technology, Dalian 116024, China, and also with the Key Laboratory for Ubiquitous Network and Service Software of Liaoning Province, Dalian University of Technology, Dalian 116024, China.; DUT-RU International School of Information Science and Engineering, Dalian University of Technology, Dalian 116024, China, and also with the Key Laboratory for Ubiquitous Network and Service Software of Liaoning Province, Dalian University of Technology, Dalian 116024, China.; DUT-RU International School of Information Science and Engineering, Dalian University of Technology, Dalian 116024, China, also with the Key Laboratory for Ubiquitous Network and Service Software of Liaoning Province, Dalian University of Technology, Dalian 116024, China, also with the School of Mathematical Sciences, Dalian University of Technology, Dalian 116024, China, and also with the Institute of Artificial Intelligence, Guilin University of Electronic Technology, Guilin 541004, China.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","14","Single-image layer separation targets to decompose the observed image into two independent components in terms of different application demands. It is known that many vision and multimedia applications can be (re)formulated as a separation problem. Due to the fundamentally ill-posed natural of these separations, existing methods are inclined to investigate model priors on the separated components elaborately. Nevertheless, it is knotty to optimize the cost function with complicated model regularizations. Effectiveness is greatly conceded by the settled iteration mechanism, and the adaption cannot be guaranteed due to the poor data fitting. What is more, for a universal framework, the most taxing point is that one type of visual cue cannot be shared with different tasks. To partly overcome the weaknesses mentioned earlier, we delve into a generic optimization unrolling technique to incorporate deep architectures into iterations for adaptive image layer separation. First, we propose a general energy model with implicit priors, which is based on maximum a posterior, and employ the extensively accepted alternating direction method of multiplier to determine our elementary iteration mechanism. By unrolling with one general residual architecture prior and one task-specific prior, we attain a straightforward, flexible, and data-dependent image separation framework successfully. We apply our method to four different tasks, including single-image-rain streak removal, high-dynamic-range tone mapping, low-light image enhancement, and single-image reflection removal. Extensive experiments demonstrate that the proposed method is applicable to multiple tasks and outperforms the state of the arts by a large margin qualitatively and quantitatively.","","","10.1109/TNNLS.2019.2921597","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8760253","Deep unrolling;image enhancement;knowledge-driven;single-image layer separation.","Task analysis;Rain;Deep learning;Image edge detection;Lighting;Learning systems;Visualization","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Subject-Independent Brain-Computer Interfaces Based on Deep Convolutional Neural Networks","O. Kwon; M. Lee; C. Guan; S. Lee","Department of Brain and Cognitive Engineering, Korea University, Seoul 02841, South Korea.; Department of Computer Science, Nazarbayev University, Astana 010000, Kazakhstan.; School of Computer Science and Engineering, Nanyang Technological University, Singapore 639798.; Department of Artificial Intelligence, Korea University, Seoul 02841, South Korea (e-mail: sw.lee@korea.ac.kr).","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","14","For a brain-computer interface (BCI) system, a calibration procedure is required for each individual user before he/she can use the BCI. This procedure requires approximately 20-30 min to collect enough data to build a reliable decoder. It is, therefore, an interesting topic to build a calibration-free, or subject-independent, BCI. In this article, we construct a large motor imagery (MI)-based electroencephalography (EEG) database and propose a subject-independent framework based on deep convolutional neural networks (CNNs). The database is composed of 54 subjects performing the left- and right-hand MI on two different days, resulting in 21,600 trials for the MI task. In our framework, we formulated the discriminative feature representation as a combination of the spectral-spatial input embedding the diversity of the EEG signals, as well as a feature representation learned from the CNN through a fusion technique that integrates a variety of discriminative brain signal patterns. To generate spectral-spatial inputs, we first consider the discriminative frequency bands in an information-theoretic observation model that measures the power of the features in two classes. From discriminative frequency bands, spectral-spatial inputs that include the unique characteristics of brain signal patterns are generated and then transformed into a covariance matrix as the input to the CNN. In the process of feature representations, spectral-spatial inputs are individually trained through the CNN and then combined by a concatenation fusion technique. In this article, we demonstrate that the classification accuracy of our subject-independent (or calibration-free) model outperforms that of subject-dependent models using various methods [common spatial pattern (CSP), common spatiospectral pattern (CSSP), filter bank CSP (FBCSP), and Bayesian spatio-spectral filter optimization (BSSFO)].","","","10.1109/TNNLS.2019.2946869","Institute for Information and Communications Technology Planning and Evaluation IITP Grant funded by the Korea Government MSIT Development of Intelligent Pattern Recognition Softwares for Ambulatory Brain Computer Interface; Development of BCI based Brain and Cognitive Computing Technology for Recognizing Users Intentions using Deep Learning; Samsung Research Funding Center of Samsung Electronics; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8897723","Brain-computer interface (BCI);convolutional neural networks (CNNs);deep learning (DL);electroencephalography (EEG);motor imagery (MI);subject-independent.","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Qualitative Measurements of Policy Discrepancy for Return-Based Deep Q-Network","W. Meng; Q. Zheng; L. Yang; P. Li; G. Pan","College of Computer Science and Technology, Zhejiang University, Hangzhou 310027, China.; College of Computer Science and Technology, Zhejiang University, Hangzhou 310027, China.; College of Computer Science and Technology, Zhejiang University, Hangzhou 310027, China.; College of Computer Science and Technology, Zhejiang University, Hangzhou 310027, China.; State Key Lab of CAD&CG, Zhejiang University, Hangzhou 310027, China (e-mail: gpan@zju.edu.cn).","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","7","The deep Q-network (DQN) and return-based reinforcement learning are two promising algorithms proposed in recent years. The DQN brings advances to complex sequential decision problems, while return-based algorithms have advantages in making use of sample trajectories. In this brief, we propose a general framework to combine the DQN and most of the return-based reinforcement learning algorithms, named R-DQN. We show that the performance of the traditional DQN can be significantly improved by introducing return-based algorithms. In order to further improve the R-DQN, we design a strategy with two measurements to qualitatively measure the policy discrepancy. We conduct experiments on several representative tasks from the OpenAI Gym and Atari games. The state-of-the-art performance achieved by our method with this proposed strategy validates its effectiveness.","","","10.1109/TNNLS.2019.2948892","National Basic Research Program of China (973 Program); National Natural Science Foundation of China; Ten Thousand Talent Program of Zhejiang Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8910593","Deep Q-network (DQN);policy discrepancy;reinforcement learning;return-based algorithm.","Reinforcement learning;Learning systems;Trajectory;Task analysis;Research and development;Games;Neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Reconstruction Regularized Deep Metric Learning for Multi-Label Image Classification","C. Li; C. Liu; L. Duan; P. Gao; K. Zheng","School of Computer Science and Engineering and Big Data Research Center, University of Electronic Science and Technology of China, Chengdu 611731, China (e-mail:lichangsheng@uestc.edu.cn).; School of Computer Science and Engineering and Big Data Research Center, University of Electronic Science and Technology of China, Chengdu 611731, China.; School of Computer Science and Engineering and Big Data Research Center, University of Electronic Science and Technology of China, Chengdu 611731, China (e-mail:andyliu281@gmail.com).; PingAn Health Technology Company Ltd., Beijing 518000, China.; School of Computer Science and Engineering and Big Data Research Center, University of Electronic Science and Technology of China, Chengdu 611731, China.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","10","In this paper, we present a novel deep metric learning method to tackle the multi-label image classification problem. In order to better learn the correlations among images features, as well as labels, we attempt to explore a latent space, where images and labels are embedded via two unique deep neural networks, respectively. To capture the relationships between image features and labels, we aim to learn a two-way deep distance metric over the embedding space from two different views, i.e., the distance between one image and its labels is not only smaller than those distances between the image and its labels' nearest neighbors but also smaller than the distances between the labels and other images corresponding to the labels' nearest neighbors. Moreover, a reconstruction module for recovering correct labels is incorporated into the whole framework as a regularization term, such that the label embedding space is more representative. Our model can be trained in an end-to-end manner. Experimental results on publicly available image data sets corroborate the efficacy of our method compared with the state of the arts.","","","10.1109/TNNLS.2019.2924023","National Natural Science Foundation of China; Open Projects Program of National Laboratory of Pattern Recognition; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8766125","Deep metric learning;multi-label image classification;reconstruction regularization.","Measurement;Correlation;Image reconstruction;Learning systems;Deep learning;Neural networks;Semantics","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Automatic First Arrival Picking via Deep Learning With Human Interactive Learning","K. C. Tsai; W. Hu; X. Wu; J. Chen; Z. Han","Department of Electrical and Computer Engineering, University of Houston, Houston, TX 77204 USA (e-mail: kevintsai159@gmail.com).; Advanced Geophysical Technology Inc., Sugar Land, TX 77478 USA.; Department of Information and Logistics Technology, University of Houston, Houston, TX 77204 USA.; Department of Electrical and Computer Engineering, University of Houston, Houston, TX 77204 USA.; Department of Electrical and Computer Engineering, University of Houston, Houston, TX 77204 USA, and also with the Department of Computer Science and Engineering, Kyung Hee University, Seoul 02447, South Korea.","IEEE Transactions on Geoscience and Remote Sensing","","2019","PP","99","1","12","First break picking is an inevitable process in land seismic data processing, which involves a huge amount of human labor to perform. Even after decades of investigation on the first break picking process, there are still enormous challenges in developing a robust automatic approach. Although many experts proposed techniques to solve the first break picking problems automatically, there are no solid solutions to avoid human labors during the picking process. In the late 20th century, the rise of the artificial intelligence and the advancement of computer hardware have overcome some challenges in first break picking but the level of their success is limited. In this article, we proposed a deep machine learning model to achieve automatic seismic first break picking. Our proposed model can find the underlying factors and determine the first break curve. In addition, the network is capable of updating itself through continuous learning. The system is able to identify labeling anomalies on-site and update the model through active learning. Unfortunately, training the machine learning model on a huge data set that contains unnecessary data points is an inefficient way for both model learning process and human labeling labors. Therefore, training the model with data selected by the experts can highly reduce the training time and the number of data that human has to label. In simulation, we show the advantage of our proposed deep semisupervised neural network, which uses both labeled and unlabeled data sets to achieve higher accuracy compared with the supervised neural networks.","","","10.1109/TGRS.2019.2946118","National Science Foundation; US MURI AFOSR; NSF EARS; CNS; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8880673","Deep learning;first arrival picking;image processing;machine learning;neural network;segmentation.","Data models;Training;Deep learning;Task analysis;Data preprocessing","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Robust Student Network Learning","T. Guo; C. Xu; S. He; B. Shi; C. Xu; D. Tao","Key Laboratory of Machine Perception, Ministry of Education, Peking University, Beijing, 100871, China, and also with the Coopertative Medianet Innovation Center, Department of Machine Intelligence, Peking University, Beijing, 100871, China.; Key Laboratory of Machine Perception, Ministry of Education, Peking University, Beijing, 100871, China, and also with the Coopertative Medianet Innovation Center, Department of Machine Intelligence, Peking University, Beijing, 100871, China (e-mail:c.xu@sydney.edu.au).; Key Laboratory of Machine Perception, Ministry of Education, Peking University, Beijing, 100871, China, and also with the Coopertative Medianet Innovation Center, Department of Machine Intelligence, Peking University, Beijing, 100871, China.; National Engineering Laboratory for Video Technology, Department of Computer Science and Technology, Peking University, Beijing 100871, China, and also with the Peng Cheng Laboratory, Shenzhen 518040, China.; Key Laboratory of Machine Perception, Ministry of Education, Peking University, Beijing, 100871, China, and also with the Coopertative Medianet Innovation Center, Department of Machine Intelligence, Peking University, Beijing, 100871, China.; UBTECH Sydney Artificial Intelligence Center, Faculty of Engineering, University of Sydney, Darlington, NSW 2008, Australia, and also with the School of Computer Science, Faculty of Engineering, University of Sydney, Darlington, NSW 2008, Australia.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","14","Deep neural networks bring in impressive accuracy in various applications, but the success often relies on heavy network architectures. Taking well-trained heavy networks as teachers, classical teacher-student learning paradigm aims to learn a student network that is lightweight yet accurate. In this way, a portable student network with significantly fewer parameters can achieve considerable accuracy, which is comparable to that of a teacher network. However, beyond accuracy, the robustness of the learned student network against perturbation is also essential for practical uses. Existing teacher-student learning frameworks mainly focus on accuracy and compression ratios, but ignore the robustness. In this paper, we make the student network produce more confident predictions with the help of the teacher network, and analyze the lower bound of the perturbation that will destroy the confidence of the student network. Two important objectives regarding prediction scores and gradients of examples are developed to maximize this lower bound, to enhance the robustness of the student network without sacrificing the performance. Experiments on benchmark data sets demonstrate the efficiency of the proposed approach to learning robust student networks that have satisfying accuracy and compact sizes.","","","10.1109/TNNLS.2019.2929114","National Natural Science Foundation of China; ARC; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8804381","Deep learning;knowledge distillation (KD);teacher-student learning.","Perturbation methods;Convolution;Neural networks;Training;Redundancy;Feature extraction;Learning systems","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Reinforcement Learning (DRL): Another Perspective for Unsupervised Wireless Localization","Y. Li; X. Hu; Y. Zhuang; Z. Gao; P. Zhang; N. El-Sheimy","Department of Geomatics Engineering, University of Calgary.; School of Electronic Engineering, Beijing University of Posts and Telecommunications.; State Key Laboratory of Surveying, Mapping and Remote Sensing, Wuhan University.; Department of Land Sciences, China University of Geosciences (Beijing).; State Key Laboratory of Surveying, Mapping and Remote Sensing, Wuhan University.; Department of Geomatics Engineering, University of Calgary.","IEEE Internet of Things Journal","","2019","PP","99","1","1","Location is key to spatialize internet-of-things (IoT) data. However, it is challenging to use low-cost IoT devices for robust unsupervised localization (i.e., localization without training data that have known location labels). Thus, this paper proposes a deep reinforcement learning (DRL) based unsupervised wireless-localization method. The main contributions are as follows. (1) This paper proposes an approach to model a continuous wireless-localization process as a Markov decision process (MDP) and process it within a DRL framework. (2) To alleviate the challenge of obtaining rewards when using unlabeled data (e.g., daily-life crowdsourced data), this paper presents a reward-setting mechanism, which extracts robust landmark data from unlabeled wireless received signal strengths (RSS). (3) To ease requirements for model re-training when using DRL for localization, this paper uses RSS measurements together with agent location to construct DRL inputs. The proposed method was tested by using field testing data from multiple Bluetooth 5 smart ear tags in a pasture. Meanwhile, the experimental verification process reflected the advantages and challenges for using DRL in wireless localization.","","","10.1109/JIOT.2019.2957778","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8924617","Wireless positioning;Deep reinforcement learning;Indoor positioning;Machine learning.","Wireless communication;Navigation;Wireless sensor networks;Hidden Markov models;Internet of Things;Machine learning;Robustness","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Discrete Deep Hashing With Ranking Optimization for Image Retrieval","X. Lu; Y. Chen; X. Li","Key Laboratory of Spectral Imaging Technology CAS, Xi'an Institute of Optics and Precision Mechanics, Chinese Academy of Sciences, Xi'an 710119, China (e-mail: luxq666666@gmail.com).; Key Laboratory of Spectral Imaging Technology CAS, Xi'an Institute of Optics and Precision Mechanics, Chinese Academy of Sciences, Xi'an 710119, China, and also with the University of Chinese Academy of Sciences, Beijing 100049, China.; School of Computer Science, Northwestern Polytechnical University, Xi'an 710072, China, and also with the Center for Optical Imagery Analysis and Learning (OPTIMAL), Northwestern Polytechnical University, Xi'an 710072, China.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","12","For large-scale image retrieval task, a hashing technique has attracted extensive attention due to its efficient computing and applying. By using the hashing technique in image retrieval, it is crucial to generate discrete hash codes and preserve the neighborhood ranking information simultaneously. However, both related steps are treated independently in most of the existing deep hashing methods, which lead to the loss of key category-level information in the discretization process and the decrease in discriminative ranking relationship. In order to generate discrete hash codes with notable discriminative information, we integrate the discretization process and the ranking process into one architecture. Motivated by this idea, a novel ranking optimization discrete hashing (RODH) method is proposed, which directly generates discrete hash codes (e.g., +1/-1) from raw images by balancing the effective category-level information of discretization and the discrimination of ranking information. The proposed method integrates convolutional neural network, discrete hash function learning, and ranking function optimizing into a unified framework. Meanwhile, a novel loss function based on label information and mean average precision (MAP) is proposed to preserve the label consistency and optimize the ranking information of hash codes simultaneously. Experimental results on four benchmark data sets demonstrate that RODH can achieve superior performance over the state-of-the-art hashing methods.","","","10.1109/TNNLS.2019.2927868","National Natural Science Foundation of China; Key Research Program of Frontier Sciences Chinese Academy of Sciences CAS; Young Top notch Talent Program of Chinese Academy of Sciences; National Key Research and Development Program of China; CAS Light of West China Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8790997","Category-level Information;discrete deep hashing;image retrieval;ranking information.","Image retrieval;Optimization;Hash functions;Semantics;Learning systems;Task analysis;Feature extraction","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Resource Allocation in Wireless Networks With Deep Reinforcement Learning: A Circumstance-Independent Approach","H. Lee; J. Kim; J. Lee","Department of Electrical and Electronic Engineering, Yonsei University, Seoul 03722, South Korea (e-mail: hs.lee@yonsei.ac.kr).; Department of Electrical and Electronic Engineering, Yonsei University, Seoul 03722, South Korea (e-mail: gamaringu@yonsei.ac.kr).; Department of Electrical and Electronic Engineering, Yonsei University, Seoul 03722, South Korea (e-mail: jangwon@yonsei.ac.kr).","IEEE Systems Journal","","2019","PP","99","1","04","In the conventional approaches using reinforcement learning (RL) for resource allocation in wireless networks, the structure of the policy depends on network circumstances such as the number of users and quality-of-service requirements. Due to this dependence, the policy is hard to be used in a practical system where the network circumstance is dynamically changing. To resolve this issue, we propose a circumstance-independent policy that can effectively address the different network circumstances even with a single policy. Thus, contrary to the conventional RL approaches, the proposed policy can be easily applied in the practical system. We then develop a deep RL algorithm to learn it. Through simulation results, we show that a single proposed policy can be used over different circumstances, and it achieves a close performance to the circumstance-dependent policy for each circumstance, which learns the optimal policy for the corresponding circumstance.","","","10.1109/JSYST.2019.2933536","Midcareer Researcher Program through the NRF; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8809381","Circumstance-independent (CI);deep learning;resource allocation;reinforcement learning (RL);wireless networks","Resource management;Wireless networks;Indexes;Gain;Reinforcement learning;Quality of service;Fading channels","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Learning Method Based on Gated Recurrent Unit and Variational Mode Decomposition for Short-Term Wind Power Interval Prediction","R. Wang; C. Li; W. Fu; G. Tang","School of Hydropower and Information Engineering, Huazhong University of Science and Technology, Wuhan 430074, China.; School of Hydropower and Information Engineering, Huazhong University of Science and Technology, Wuhan 430074, China (e-mail: csli@hust.edu.cn).; College of Electrical Engineering and New Energy, China Three Gorges University, Yichang 443002, China (e-mail: ctgu_fuwenlong@126.com).; School of Hydropower and Information Engineering, Huazhong University of Science and Technology, Wuhan 430074, China.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","14","Wind power interval prediction (WPIP) plays an increasingly important role in evaluations of the uncertainty of wind power and becomes necessary for managing and planning power systems. However, the intermittent and fluctuating characteristics of wind power mean that high-quality prediction intervals (PIs) production is a challenging problem. In this article, we propose a novel hybrid model for the WPIP based on the gated recurrent unit (GRU) neural networks and variational mode decomposition (VMD). In the hybrid model, VMD is employed to decompose complex wind power data into simplified modes. Basic GRU prediction models, comprising a GRU input layer, multiple fully connected layers, and a rank-ordered terminal layer, are then trained for each mode to produce PIs, which are combined to obtain final PIs. In addition, an adaptive optimization method based on constructed intervals (CIs) is proposed to build high-quality training labels for supervised learning with the hybrid model. Several numerical experiments were implemented to validate the effectiveness of the proposed method. The results indicate that the proposed method performs better than the traditional interval prediction models with much higher quality PIs, and it requires less training time.","","","10.1109/TNNLS.2019.2946414","National Natural Science Foundation of China; Applied Fundamental the Frontier Project of Wuhan Science and Technology Bureau; Hubei Provincial Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; Fundamental Research Project for Application supported by Yichang Science and Technology Bureau; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8897724","Deep learning;gated recurrent unit (GRU);variational mode decomposition (VMD);wind power interval prediction (WPIP).","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Enabling Explainable Fusion in Deep Learning with Fuzzy Integral Neural Networks","M. A. Islam; D. T. Anderson; A. Pinar; T. C. Havens; G. Scott; J. M. Keller","Electrical and Computer Engineering, Mississippi State University, 5547 Mississippi State, Mississippi United States 39762 (e-mail: mig5g@missouri.edu); Electrical Engineering and Computer Science, University of Missouri, Columbia, Missouri United States 65211 (e-mail: andersondt@missouri.edu); Electrical and Computer Engineering, Michigan Technological University, Houghton, Michigan United States 49931 (e-mail: ajpinar@mtu.edu); Electrical and Computer Engineering, Michigan Technological University, Houghton, Michigan United States 49930 (e-mail: thavens@mtu.edu); ECE/CS, University of Missouri Columbia, 14716 Columbia, Missouri United States 65211 (e-mail: scottgs@missouri.edu); Electrical and Computer Engineering, University of Missouri, Columbia, Missouri United States 65211 (e-mail: kellerj@missouri.edu)","IEEE Transactions on Fuzzy Systems","","2019","PP","99","1","1","Information fusion is an essential part of numerous engineering systems and biological functions, e.g., human cognition. Fusion occurs at many levels, ranging from the low-level combination of signals to the high-level aggregation of heterogeneous decision-making processes. While the last decade has witnessed an explosion of research in deep learning, fusion in neural networks has not observed the same revolution. Specifically, most neural fusion approaches are ad hoc, are not understood, are distributed versus localized, and/or explainability is low (if present at all). Herein, we prove that the fuzzy Choquet integral (ChI), a powerful nonlinear aggregation function, can be represented as a multi-layer network, referred to hereafter as ChIMP. We also put forth an improved ChIMP (iChIMP) that leads to a stochastic gradient descent-based optimization in light of the exponential number of ChI inequality constraints. An additional benefit of ChIMP/iChIMP is that it enables eXplainable AI (XAI). Synthetic validation experiments are provided and iChIMP is applied to the fusion of a set of heterogeneous architecture deep models in remote sensing. We show an improvement in model accuracy and our previously established XAI indices shed light on the quality of our data, model, and its decisions.","","","10.1109/TFUZZ.2019.2917124","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8715679","data fusion;Choquet integral;deep learning;neural network;explainable AI","Artificial neural networks;Frequency modulation;Deep learning;Remote sensing;Sensors;Decision making","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Semi-Supervised Multi-Label Deep Learning based Non-intrusive Load Monitoring in Smart Grids","Y. Yang; J. Zhong; W. Li; T. A. Gulliver; S. Li","School of information and communication engineering, Beijing University of Posts and Telecommunications, 12472 Beijing China 100086 (e-mail: yydxlv@qq.com); Victoria Canada V8W 2Y2 (e-mail: jzhong@uvic.ca); University of Victoria, 8205 Victoria, British Columbia Canada V8W 2Y2 (e-mail: weili@ieee.org); University of Victoria, 8205 Victoria, British Columbia Canada V8W 2Y2 (e-mail: agullive@ece.uvic.ca); School of information and communication engineering, Beijing University of Posts and Telecommunications, 12472 Beijing China 100876 (e-mail: bupt_paper@126.com)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","Non-intrusive load monitoring (NILM) is a technique that infers appliance-level energy consumption patterns and operation state changes based on feeder power signals. With the availability of fine-grained electric load profiles, there has been increasing interest in using this approach for demand-side energy management in smart grids. NILM is a multi-label classification problem due to the simultaneous operation of multiple appliances. Recently, deep learning based techniques have been shown to be a promising approach to solving this problem, but annotating the huge volume of load profile data with multiple active appliances for learning is very challenging and impractical. In this paper, a new semi-supervised multi-label deep learning based framework is proposed to address this problem with the goal of mitigating the reliance on large labeled datasets. Specifically, a temporal convolutional neural network (CNN) is used to automatically extract high-level load signatures for individual appliances. These signatures can be efficiently used to improve the feature representation capability of the framework. Case studies conducted on two open-access NILM datasets demonstrate the effectiveness and superiority of the proposed approach.","","","10.1109/TII.2019.2955470","China Scholarship Council; BUPT Excellent Ph.D. Students Foundation; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8911216","Non-intrusive load monitoring;Deep learning;Multi-label classification;Semi-supervised learning;Load signatures","Deep learning;Feature extraction;Semisupervised learning;Monitoring;Informatics;Hidden Markov models;Transforms","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep reinforcement learning for power system: An overview","Z. Zhang; D. Zhang; R. C. Qiu","Research Center For Big Data Engineering And Technologies, Shanghai Jiao Tong University, Shanghai 200240, China; China Electric Power Research Institute, Beijing 100192, China; Research Center For Big Data Engineering And Technologies, Shanghai Jiao Tong University, Shanghai 200240, China; Department of Electrical and Computer Engineering, Tennessee Technological University, Cookeville, TN 38505, USA","CSEE Journal of Power and Energy Systems","","2019","PP","99","1","12","Due to increasing complexity, uncertainty, and data dimension in the power system, conventional methods often meet bottlenecks when attempting to solve decision and control problems. Therefore, data-driven methods toward solving such problems are being extensively studied. Deep reinforcement learning (DRL) is one of these data-driven methods and is regarded as real artificial intelligence (AI). DRL is a combination of deep learning (DL) and reinforcement learning (RL). This field of research has been applied to solve a wide scope of complex sequential decision-making problems, including those in the power system. This paper firstly reviews the basic ideas, models, algorithms, and techniques of DRL. It then introduces applications in the power system, such as energy management, demand response, electricity market, operational control, and many others. In addition, the recent advances in DRL, the combination of RL with other classical methods, and the prospect and challenges of its applications in the power system are also been discussed.","","","10.17775/CSEEJPES.2019.00920","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8859593","Deep reinforcement learning;power system;smart grids;artificial intelligence;machine learning","Reinforcement learning;Power systems;Optimization;Decision making;Computational modeling;Deep learning","","","","","","","","","","CSEE","CSEE Early Access Articles"
"BND*-DDQN: Learn to Steer Autonomously through Deep Reinforcement Learning","K. Wu; H. Wang; M. A. Esfahani; S. Yuan","School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore 639798.; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore 639798.; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore 639798.; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore 639798.","IEEE Transactions on Cognitive and Developmental Systems","","2019","PP","99","1","1","It is vital for mobile robots to achieve safe autonomous steering in various changing environments. In this paper, a novel end-to-end network architecture is proposed for mobile robots to learn steering autonomously through deep reinforcement learning. Specifically, two sets of feature representations are firstly extracted from the depth inputs through two different input streams. The acquired features are then merged together to derive both linear and angular actions simultaneously. Moreover, a new action selection strategy is also introduced to achieve motion filtering by taking the consistency in angular velocity into account. Besides, in addition to the extrinsic rewards, the intrinsic bonuses are also adopted during training to improve the exploration capability. Furthermore, it is worth noting the proposed model is readily transferable from the simple virtual training environment to much more complicated real-world scenarios so that no further fine-tuning is required for real deployment. Compared to the existing methods, the proposed method demonstrates significant superiority in terms of average reward, convergence speed, success rate, and generalization capability. In addition, it exhibits outstanding performance in various cluttered real-world environments containing both static and dynamic obstacles. A video of our experiments can be found at https://youtu.be/19jrQGG1oCU.","","","10.1109/TCDS.2019.2928820","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8764461","Deep reinforcement learning;depth image;difference image;autonomous steering;intrinsic reward.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Residual Encoder-Decoder Networks for Desert Seismic Noise Suppression","H. Ma; H. Yao; Y. Li; H. Wang","Department of Information, College of Communication Engineering, Jilin University, Changchun 130012, China.; Department of Information, College of Communication Engineering, Jilin University, Changchun 130012, China.; Department of Information, College of Communication Engineering, Jilin University, Changchun 130012, China (e-mail: liyue@jlu.edu.cn).; Department of Information, College of Communication Engineering, Jilin University, Changchun 130012, China.","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","The convolutional neural network (CNN) has achieved excellent performance in many fields, which has attracted much attention. CNN is a kind of feedforward neural network with convolution computation and depth structure. In this letter, aiming at the intense interference of seismic exploration noise in the desert of China, a desert seismic noise reduction system based on deep residual encoder-decoder network is proposed. In order to extract the characteristics and variation law of desert seismic noise, a noise set containing a large number of desert seismic noise is utilized for training the network so that the network forms the end-to-end mapping between the noisy records and the noise. Consequently, the effective signals are obtained by subtracting noise from the noisy records so as to achieve a satisfactory denoising performance. Compared with the traditional random noise suppression methods, the advantages of the proposed method are fully demonstrated in the processing of the synthetic records and the field records. Especially when the signal-to-noise ratio (SNR) is very low, this proposed method can still have a very good denoising effect.","","","10.1109/LGRS.2019.2925062","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8758359","Convolutional neural network (CNN);deep learning;denoising;desert seismic noise;residual learning;seismic exploration.","Noise reduction;Signal to noise ratio;Deconvolution;Convolution;Noise measurement;Training;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Coarse-to-Fine Deep Learning of Continuous Pedestrian Orientation Based on Spatial Co-Occurrence Feature","S. Kim; I. Gwak; S. Lee","Department of Computer and Radio Communications Engineering, Korea University, Seoul 02841, South Korea.; Department of Brain and Cognitive Engineering, Korea University, Seoul 02841, South Korea.; Department of Brain and Cognitive Engineering, Korea University, Seoul 02841, South Korea (e-mail: sw.lee@korea.ac.kr).","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","12","The continuous orientation estimation of a moving pedestrian is a crucial issue in autonomous driving that requires the detection of a pedestrian intending to cross a road. It is still a challenging task owing to several reasons, including the diversity of pedestrian appearances, the subtle pose difference between adjacent orientations, and similar poses with different orientations such as axisymmetric orientations. These problems render the task highly difficult. Recent studies involving convolutional neural networks (CNNs) have attempted to solve these problems. However, their performance is still far from satisfactory for application in intelligent vehicles. In this paper, we propose a CNN-based two-stream network for continuous orientation estimation. The network can learn representations based on the spatial co-occurrence of visual patterns among pedestrians. To boost estimation performance, we applied a coarse-to-fine learning approach that consists of two learning stages. We investigated continuous orientation performance on the TUD Multiview Pedestrian dataset and the KITTI dataset and compared them with the state-of-the-art methods. The results show that our method outperforms other existing methods.","","","10.1109/TITS.2019.2919920","Korea government MSIT; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8734128","Advanced driver assistance system;coarse-to-fine learning;convolutional neural networks;continuous orientation estimation.","Estimation;Visualization;Training;Task analysis;Feature extraction;Deep learning;Complexity theory","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Privacy-Enhanced Data Collection Based on Deep Learning for Internet of Vehicles","T. Wang; Z. Cao; S. Wang; J. Wang; L. Qi; A. Liu; M. Xie; X. Li","College of Computer Science and Technology, Huaqiao University, 12422 Xiamen China 361021 (e-mail: cs_tianwang@163.com); College of Computer Science and Technology, Huaqiao University, 12422 Xiamen China 361021 (e-mail: mail_caozhihan@163.com); College of Computer Science and Technology, Huaqiao University, 12422 Xiamen China 361021 (e-mail: ws752499660@foxmail.com); College of Computer Science and Technology, Huaqiao University, 12422 Xiamen China 361021 (e-mail: w_jianhuang@163.com); Qufu Normal University, 56650 Qufu, Shandong China 273165 (e-mail: lianyongqi@gmail.com); Central South University, 12570 Changsha, Hunan China 410083 (e-mail: afengliu@mail.csu.edu.cn); Zhejiang Gongshang University, 12625 Hangzhou, Zhejiang China 310018 (e-mail: xiemd@zjgsu.edu.cn); the School of Computer and Information Engineering, Hunan University of Commerce, 118399 Changsha, Hunan China 410205 (e-mail: xlli@guet.edu.cn)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","Privacy leakage and delay problem for data collection remain as the key concerns behind the fast development of the cyber intelligence (CI) technologies. If the original data collected is directly uploaded to the cloud for processing, it will bring huge load pressure and delay to the network communication. Moreover, during this process, it will lead to the leakage of data privacy. To this end, we design a data collection and preprocessing scheme based on deep learning, which adopts the semi-supervised learning algorithm of data augmentation and label guessing. Data filtering is performed at the edge layer, and a large amount of similar data and irrelevant data are cleared. At the same time, due to the adoption of federated learning technology, the cloud collects the training results on each edge device instead of the original data from end users directly, which protects the data privacy.","","","10.1109/TII.2019.2962844","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8945334","IoV;deep learning;federated learning;semisupervised learning","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Double Coded Caching in Ultra Dense Networks: Caching and Multicast Scheduling via Deep Reinforcement Learning","Z. Zhang; H. Chen; M. Hua; C. Li; Y. Huang; L. Yang","National Mobile Communications Research Laboratory, School of Information Science and Engineering, Southeast University, Nanjing 210096, China and Purple Mountain Laboratories, Nanjing 211111, China.; Institute of Industrial Science, The University of Tokyo, Japan.; National Mobile Communications Research Laboratory, School of Information Science and Engineering, Southeast University, Nanjing 210096, China.; National Mobile Communications Research Laboratory, School of Information Science and Engineering, Southeast University, Nanjing 210096, China.; National Mobile Communications Research Laboratory, School of Information Science and Engineering, Southeast University, Nanjing 210096, China and Purple Mountain Laboratories, Nanjing 211111, China.; National Mobile Communications Research Laboratory, School of Information Science and Engineering, Southeast University, Nanjing 210096, China and Purple Mountain Laboratories, Nanjing 211111, China.","IEEE Transactions on Communications","","2019","PP","99","1","1","Proposed by Maddah-Ali and Niesen, a coded caching scheme has been verified to alleviate the load of networks efficiently. Recently, a new technique called placement delivery array (PDA) was proposed to characterize the coded caching scheme. In this paper, we consider a caching system in the scope of ultra dense networks (UDNs). Each base station (BS) has a finite cache and stores some contents. We propose an efficient coded content caching scheme called double coded caching to make the transmission robust to in-and-out wireless network quality. Then the dynamic caching and multicast scheduling are considered to jointly minimize the average delay and power of the content-centric wireless networks. This stochastic optimization problem can be formulated as a Markov decision process (MDP) with unknown transition probabilities and large state space. We propose a deep reinforcement learning approach to deal with the decision problem. Our algorithm uses a variational auto-encoder (VAE) neural network to approximate the state sufficiently, and uses a weighted double Q-learning scheme to reduce variance and overestimation of the Q function. Numerical results demonstrate that the proposed double coded caching scheme increases the probability of the successful transmission, and the caching and scheduling policy can effectively reduce the delay and the power consumption.","","","10.1109/TCOMM.2019.2955490","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8911375","Coded caching;UDN;multicast;deep reinforcement learning","Servers;Reinforcement learning;Handheld computers;Dynamic scheduling;Base stations;Wireless networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Direct Error-Driven Learning for Deep Neural Networks With Applications to Big Data","R. Krishnan; S. Jagannathan; V. A. Samaranayake","Department of Electrical and Computer Engineering, Missouri University of Science and Technology, Rolla, MO 65401 USA (e-mail: krm9c@mst.edu).; Department of Electrical and Computer Engineering, Missouri University of Science and Technology, Rolla, MO 65401 USA.; Department of Mathematics and Statistics, Missouri University of Science and Technology, Rolla, MO 65401 USA.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","8","In this brief, heterogeneity and noise in big data are shown to increase the generalization error for a traditional learning regime utilized for deep neural networks (deep NNs). To reduce this error, while overcoming the issue of vanishing gradients, a direct error-driven learning (EDL) scheme is proposed. First, to reduce the impact of heterogeneity and data noise, the concept of a neighborhood is introduced. Using this neighborhood, an approximation of generalization error is obtained and an overall error, comprised of learning and the approximate generalization errors, is defined. A novel NN weight-tuning law is obtained through a layer-wise performance measure enabling the direct use of overall error for learning. Additional constraints are introduced into the layer-wise performance measure to guide and improve the learning process in the presence of noisy dimensions. The proposed direct EDL scheme effectively addresses the issue of heterogeneity and noise while mitigating vanishing gradients and noisy dimensions. A comprehensive simulation study is presented where the proposed approach is shown to mitigate the vanishing gradient problem while improving generalization by 6%.","","","10.1109/TNNLS.2019.2920964","NSF I UCRC Award IIP; Intelligent Systems Center; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8763927","Error-driven;exploratory learning;generalization error;neural network.","Artificial neural networks;Noise measurement;Indexes;Big Data;Data models;Cost function","","","","","","","","","","IEEE","IEEE Early Access Articles"
"ST-DeLTA: An Novel Spatial-Temporal Value Network Aided Deep Learning Based Intelligent Network Traffic Control System","F. Tang; B. Mao; Z. M. Fadlullah; J. Liu; N. Kato","Graduate School of Information Sciences, Tohoku Daigaku, 13101 Sendai, Miyagi Japan 980-8577 (e-mail: fengxiao.tang@it.is.tohoku.ac.jp); Graduate School of Information Science, Tohoku University, Sendai, Miyagi Japan (e-mail: bomin.mao@it.is.tohoku.ac.jp); Graduate School of Information Sciences (GSIS), Tohoku University, Sendai-Shi, Miyagi Japan (e-mail: zubair@it.is.tohoku.ac.jp); School of Cyber Engineering, Xidian Univ., Xi'an, Shaanxi China (e-mail: liujiajia@xidian.edu.cn); Graduate School of Information Sciences, Tohoku Univ., Sendai, Miyagi Japan 9808579 (e-mail: kato@it.is.tohoku.ac.jp)","IEEE Transactions on Sustainable Computing","","2019","PP","99","1","1","Deep learning has emerged as a popular Artificial Intelligence (AI) technique to make conventional cyber physical systems become intelligent and sustainable. Recently, deep learning has been widely used in the network domain. With the aid of powerful deep neural networks, the communication network can carry out packets forwarding actions intelligently to avoid possible failure and congestion. However, with the high computing cost and process limitation in only static network scenario, the existing deep learning based network traffic control algorithms cannot satisfy the sustainable requirement of next generation large scale dynamic network. To conquer the existing problems, a novel spatial-temporal value network aided deep learning based intelligent traffic control algorithm referred as ST-DeLTA is proposed in this paper. In ST-DeLTA, the value matrix and spatial temporal training model (ST model) are employed to intelligently extract the spatial as well as temporal features of traffic patterns and make adaptive packets forwarding decision in large scale and dynamic networks. The mathematical analysis gives the computing cost reduction of our proposal, and the computer simulation demonstrates that our proposal has significantly better training and network performance compared with tradition algorithms in terms of training accuracy, transmission throughput, and average packets loss rate.","","","10.1109/TSUSC.2019.2929935","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8766877","network traffic control;packets forwarding;Deep learning;convolutional neural network (CNN);deep belief network (DBN)","Deep learning;Training;Heuristic algorithms;Network topology;Routing protocols;Control systems;Feature extraction","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Hybrid Ensemble Deep Learning for Deterministic and Probabilistic Low-voltage Load Forecasting","Z. Cao; C. Wan; Z. Zhang; F. Li; Y. Song","College of Electrical Engineering, Zhejiang University, Hangzhou China (e-mail: caozhaojing@zju.edu.cn); College of Electrical Engineering, Zhejiang University, Hangzhou China (e-mail: canwan@zju.edu.cn); School of Data Science, City University of Hong Kong, Hong Kong Hong Kong 00000 (e-mail: zijzhang@cityu.edu.hk); Department of Electronic & Electrical Eng, University of Bath, Claverton Down United Kingdom of Great Britain and Northern Ireland BA2 7AY (e-mail: f.li@bath.ac.uk); Zhejiang University, Hangzhou, Zhejiang China (e-mail: yhsongcn@zju.edu.cn)","IEEE Transactions on Power Systems","","2019","PP","99","1","1","Accurate and reliable low-voltage load forecasting is critical to optimal operation and control of distribution network and smart grid. However, compared to traditional regional load forecasting at high-voltage level, it faces tough challenges due to inherent high uncertainty of the low-capacity load and distributed renewable energy integrated in the demand side. This paper proposes a novel hybrid ensemble deep learning (HEDL) approach for deterministic and probabilistic low-voltage load forecasting. The deep belief network (DBN) is applied for low voltage load point prediction with the strong ability of approximating nonlinear mapping. A series of ensemble learning methods including bagging and boosting variants are introduced to improve the regression ability of DBN. On basis of the integrated thought of ensemble learning, a new hybrid ensemble algorithm is developed via inte-grating multiple separate ensemble methods. Considering the diversity in various ensemble algorithms, an adaptive weight determination approach is proposed by means of an effective classification method K nearest neighbor. Furthermore, HEDL based probabilistic forecasting is proposed by taking advantage of the inherent resample idea in bagging and boosting. The effectiveness of the HEDL method for both deterministic and probabilistic forecasting has been verified based on realistic load data from East China and Australia, indicating its promising prospective for practical applications in distribution network.","","","10.1109/TPWRS.2019.2946701","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8863951","Forecasting;low-voltage load;deep learning;ensemble learning;K nearest neighbor","Load modeling;Load forecasting;Predictive models;Forecasting;Probabilistic logic;Bagging;Boosting","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Energy Disaggregation via Deep Temporal Dictionary Learning","M. Khodayar; J. Wang; Z. Wang","Department of Electrical and Computer Engineering, Southern Methodist University, Dallas, TX 75275 USA.; Department of Electrical and Computer Engineering, Southern Methodist University, Dallas, TX 75275 USA (e-mail: jianhui@smu.edu).; Department of Electrical and Computer Engineering, Iowa State University, Ames, IA 50011 USA.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","14","This paper presents a novel nonlinear dictionary learning (DL) model to address the energy disaggregation (ED) problem, i.e., decomposing the electricity signal of a home to its operating devices. First, ED is modeled as a new temporal DL problem where a set of dictionary atoms is learned to capture the most representative temporal features of electricity signals. The sparse codes corresponding to these atoms show the contribution of each device in the total electricity consumption. To learn powerful atoms, a novel deep temporal DL (DTDL) model is proposed that computes complex nonlinear dictionaries in the latent space of a long short-term memory autoencoder (LSTM-AE). While the LSTM-AE captures the deep temporal manifold of electricity signals, the DTDL model finds the most representative atoms inside this manifold. To simultaneously optimize the dictionary and the deep temporal manifold, a new optimization algorithm is proposed that alternates between finding the optimal LSTM-AE and the optimal dictionary. To the best of authors' knowledge, DTDL is the only DL model that understands the deep temporal structures of the data. Experiments on the Reference ED Data Set show an outstanding performance compared with the recent state-of-the-art algorithms in terms of precision, recall, accuracy, and F-score.","","","10.1109/TNNLS.2019.2921952","US Department of Energy DOE Office of Electricity; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8759065","Deep learning;dictionary learning (DL);energy disaggregation (ED);long short-term memory autoencoder (LSTM-AE).","Dictionaries;Hidden Markov models;Signal processing algorithms;Machine learning;Home appliances;Optimization;Computational modeling","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Contrastive Hebbian Feedforward Learning for Neural Networks","N. Kermiche","Western Digital Corporation, Irvine, CA 92612 USA (e-mail: noureddine.kermiche@wdc.com).","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","11","This paper addresses the biological plausibility of both backpropagation (BP) and contrastive Hebbian learning (CHL) used in the Boltzmann machines. The main claim of this paper is that CHL is a general learning algorithm that can be used to steer feedforward networks toward desirable outcomes, and steer them away from undesirable outcomes without any need for the specialized feedback circuit of BP or the symmetric connections used by the Boltzmann machines. After adding perturbations during the learning phase to all the neurons in the network, multiple feedforward outcomes are classified into Hebbian and anti-Hebbian sets based on the network predictions. The algorithm is applied to networks when optimizing a loss objective where BP excels and is also applied to networks with stochastic binary outputs where BP cannot be easily applied. The power of the proposed algorithm lies in its simplicity where both learning and gradient estimation through stochastic binary activations are combined into a single local Hebbian rule. We will also show that both Hebbian and anti-Hebbian correlations are evaluated from the readily available signals that are fundamentally different from CHL used in the Boltzmann machines. We will demonstrate that the new learning paradigm where Hebbian/anti-Hebbian correlations are based on correct/incorrect predictions is a powerful concept that separates this paper from other biologically inspired learning algorithms.","","","10.1109/TNNLS.2019.2927957","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8782836","Binary stochastic neurons;contrastive divergence;contrastive Hebbian;deep learning.","Neurons;Correlation;Learning systems;Training;Feedforward systems;Feedforward neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Classifier-Constrained Deep Adversarial Domain Adaptation for Cross-Domain Semisupervised Classification in Remote Sensing Images","W. Teng; N. Wang; H. Shi; Y. Liu; J. Wang","College of Forestry, University of Nanjing Forestry, Nanjing 210037, China (e-mail: wenxiu.teng@ieee.org).; College of Geographic Information and Tourism, University of Chuzhou, Chuzhou 239000, China (e-mail: wnstrive@163.com).; College of Geographic Information and Tourism, University of Chuzhou, Chuzhou 239000, China.; College of Geographic Information and Tourism, University of Chuzhou, Chuzhou 239000, China.; College of Geographic Information and Tourism, University of Chuzhou, Chuzhou 239000, China.","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","This letter presents a classifier-constrained deep adversarial domain adaptation (CDADA) method for cross-domain semisupervised classification in remote sensing (RS) images. A deep convolutional neural network (DCNN) is used to build feature representations to describe the semantic content of scenes before the adaptation process. Then, adversarial domain adaptation is used to align the feature distribution of the source and the target. Specifically, two different land-cover classifiers are used as a discriminator to consider land-cover decision boundaries between classes and increase their distance to separate them from the original land-cover class boundaries. The generator then creates robust transferable features far from the original land-cover class boundaries under the classifier constraint. The experimental results of six scenarios built from three benchmark RS scene data sets (AID, Merced, and RSI-CB data sets) are reported and discussed.","","","10.1109/LGRS.2019.2931305","National Natural Science Foundation of China; Key Projects of Anhui Natural Science Research in Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8794530","Cross-domain classification;deep convolutional neural networks (DCNNs);domain adaptation (DA);generative adversarial networks (GANs);remote sensing (RS).","Generators;Feature extraction;Training;Linear programming;Remote sensing;Data mining;Probabilistic logic","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Variational Matrix Factorization with Knowledge Embedding for Recommendation System","X. Shen; B. Yi; H. Liu; W. Zhang; Z. Zhang; S. Liu; N. Xiong","National Engineering Research Center for E-Learning, Huazhong Normal University, 12446 Wuhan, Hubei China (e-mail: shenxx630@gmail.com); National Engineering Research Center for E-Learning, Huazhong Normal University, 12446 Wuhan, Hubei China (e-mail: epower@mail.ccnu.edu.cn); National Engineering Research Center for E-Learning, Huazhong Normal University, 12446 Wuhan, Hubei China (e-mail: hailiu0204@mail.ccnu.edu.cn); National Engineering Research Center for E-Learning, Huazhong Normal University, 12446 Wuhan, Hubei China (e-mail: zwccnu@163.com); National Engineering Research Center for E-Learning, Huazhong Normal University, 12446 Wuhan, Hubei China (e-mail: zl.zhang@mail.ccnu.edu.cn); National Engineering Research Center for E-Learning Central, Huazhong Normal University, 12446 Wuhan, Hubei China (e-mail: lsy5918@mail.ccnu.edu.cn); National Engineering Laboratory for Educational Big Data, Huazhong Normal University, 12446 Wuhan, Hubei China (e-mail: xiongnaixue@gmail.com)","IEEE Transactions on Knowledge and Data Engineering","","2019","PP","99","1","1","Automatic recommendation has become an increasingly relevant problem to industries, which allows users to discover new items that match their tastes and enables the system to target items to the right users. In this article, we have proposed a deep learning based fully Bayesian treatment recommendation framework, DVMF, which has high-quality performance and ability to integrate any kinds of side information handily and efficiently. In DVMF, the variational inference technique and the reparameterization tricks are introduced to make DVMF possible to be optimized by the stochastic gradient-based methods, in addition, two novel deep neural networks have been constructed to infer the hyper-parameters of the distributions of latent factors from the knowledge of user and item, which are represented as low-dimensional real-valued vectors retaining primary features. Experimental results on five public databases indicate that the proposed method performs better than the state-of-the-art recommendation algorithms on prediction accuracy in terms of quantitative assessments.","","","10.1109/TKDE.2019.2952849","National Key R and D Program of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8896070","deep learning;matrix factorization;recommendation system;representation learning;variational inference","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Intelligent Missing Shots' Reconstruction Using the Spatial Reciprocity of Green's Function Based on Deep Learning","B. Wang; N. Zhang; W. Lu; J. Geng; X. Huang","State Key Laboratory of Marine Geology, School of Ocean and Earth Science, Institute for Advanced Study, Tongji University, Shanghai 200092, China (e-mail: wbf1232007@126.com).; EasySignal Group, Department of Automation, Tsinghua University, Beijing 100084, China.; EasySignal Group, Department of Automation, Tsinghua University, Beijing 100084, China.; State Key Laboratory of Marine Geology, School of Ocean and Earth Science, Institute for Advanced Study, Tongji University, Shanghai 200092, China.; Department of Mathematics, School of Science, Beijing Technology and Business University, Beijing 100048, China.","IEEE Transactions on Geoscience and Remote Sensing","","2019","PP","99","1","11","The trace interval in the common shot and receiver gathers is always inconsistent. The inconsistency affects the final performance of seismic data processing, and the reconstruction methods can enhance the consistency. Unfortunately, most interpolation algorithms are suitable in randomly missing cases, and the difficulty increases sharply in regularly missing cases, especially with big gaps. As deep learning (DL) has a strong self-learning ability in nonlinear characterizations to avoid linear events, sparsity, and low rank assumptions, we introduce DL into missing shots' reconstruction. The spatial reciprocity of Green's function is used to provide reasonable training data sets. First, the residual learning networks (ResNets) and the interpolation issue are briefly illustrated. Then, the spatial reciprocity is reviewed and illustrated qualitatively using the common shot and receiver gathers. The similar features in the common shot and receiver gathers guarantee the reasonability to regard the common shot gathers as the training sets and to regard the common receiver gathers as the test sets. The common shot gathers are divided into the training sets to train ResNets and the validation sets to verify the performance of the trained ResNets. Finally, the trained ResNets are used to reconstruct missing shots intelligently in the common receiver gather. Three different data sets are used to prove the validity of the proposed strategy. After reconstruction, the events are more continuous with less serrations and serious frequency wavenumber (FK) aliasing is attenuated effectively. The reconstructed data with a better consistency can improve the accuracy of migration and the final reservoir characterization.","","","10.1109/TGRS.2019.2947085","National Basic Research Program of China (973 Program); National Natural Science Foundation of China; Young Elite Scientists Sponsorship Program by China Association for Science and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8889764","Deep learning (DL);reconstruction;residual learning networks (ResNets);spatial reciprocity.","Interpolation;Receivers;Training;Transforms;Feature extraction;Computational efficiency;Convolution","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Predicting Remaining Useful Life of Rolling Bearings based on Deep Feature Representation and Transfer Learning","W. Mao; J. He; M. J. Zuo","School of Computer and Information Engineering, Henan Normal University, Xinxiang, P.R.China, 453007.; School of Computer and Information Engineering, Henan Normal University, Xinxiang, P.R.China, 453007.; Department of Mechanical Engineering, University of Alberta, Edmonton, Canada, T6G 1H9.","IEEE Transactions on Instrumentation and Measurement","","2019","PP","99","1","1","For the data-driven remaining useful life (RUL) prediction for rolling bearings, the traditional machine learning-based methods generally provide insufficient feature representation and adaptive extraction. Although deep learning-based RUL prediction methods can solve these problems to some extent, they still do not yield satisfactory predictive results due to less degradation data and inconsistent data distribution among different bearings. To solve these problems, a new RUL prediction method based on deep feature representation and transfer learning is proposed in this paper. This method includes an offline stage and an online stage. In the offline stage, the Hilbert-Huang transform marginal spectra of the raw vibration signal of auxiliary bearings are first calculated as the input, and then contractive denoising autoencoder is introduced to extract deep features with good and stable fault representation. Second, by using the obtained deep features and Pearson’s correlation coefficient, a new health condition assessment method is proposed to divide the whole life of each bearing into a normal state and a fast-degradation state. Finally, using the extracted deep features and their RUL values, a RUL prediction model for the fast-degradation state is trained by means of a least-square support vector machine. In the online stage, a kind of transfer learning algorithm, i.e., transfer component analysis, is introduced to sequentially adjust the features of target bearing from auxiliary bearings, and then the corresponding RUL is predicted using the corrected features. Results using the PHM Challenging 2012 dataset show a significant performance improvement when using the proposed method in terms of predictive accuracy and numerical stability.","","","10.1109/TIM.2019.2917735","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8718405","Remaining useful life prediction;Deep learning;Transfer learning;Transfer component analysis;Correlation coefficient","Feature extraction;Degradation;Predictive models;Prognostics and health management;Deep learning;Support vector machines;Prediction algorithms","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Memory-Based Deep Reinforcement Learning for Obstacle Avoidance in UAV With Limited Environment Knowledge","A. Singla; S. Padakandla; S. Bhatnagar","Robert Bosch Centre for Cyber-Physical Systems, Indian Institute of Science, Bangalore 560012, India.; Department of Computer Science and Automation, Indian Institute of Science, Bengaluru 560012, India (e-mail: sindhupr@iisc.ac.in).; Department of Computer Science and Automation, Indian Institute of Science, Bengaluru 560012, India.","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","12","This paper presents our method for enabling a UAV quadrotor, equipped with a monocular camera, to autonomously avoid collisions with obstacles in unstructured and unknown indoor environments. When compared to obstacle avoidance in ground vehicular robots, UAV navigation brings in additional challenges because the UAV motion is no more constrained to a well-defined indoor ground or street environment. Unlike ground vehicular robots, a UAV has to navigate across more types of obstacles - for e.g., objects like decorative items, furnishings, ceiling fans, sign-boards, tree branches, etc., are also potential obstacles for a UAV. Thus, methods of obstacle avoidance developed for ground robots are clearly inadequate for UAV navigation. Current control methods using monocular images for UAV obstacle avoidance are heavily dependent on environment information. These controllers do not fully retain and utilize the extensively available information about the ambient environment for decision making. We propose a deep reinforcement learning based method for UAV obstacle avoidance (OA) which is capable of doing exactly the same. The crucial idea in our method is the concept of partial observability and how UAVs can retain relevant information about the environment structure to make better future navigation decisions. Our OA technique uses recurrent neural networks with temporal attention and provides better results compared to prior works in terms of distance covered without collisions. In addition, our technique has a high inference rate and reduces power wastage as it minimizes oscillatory motion of UAV.","","","10.1109/TITS.2019.2954952","Robert Bosch Centre for Cyber Physical Systems Indian Institute of Science; Department of Science and Technology through the ICPS Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8917687","Unmanned aerial vehicle (UAV) obstacle avoidance (OA);deep reinforcement learning (DRL);partial observability;deep Q-networks (DQN).","Collision avoidance;Navigation;Cameras;Unmanned aerial vehicles;Simultaneous localization and mapping;Visualization","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Top-k Ranking for Image-Sentence Matching","L. Zhang; M. Luo; J. Liu; X. Chang; Y. Yang; A. Hauptmann","Computer Science, Xi'an Jiaotong University, 12480 Xi'an, SHAANXI China 710049 (e-mail: zhanglingling@stu.xjtu.edu.cn); Computer science and technology, Xi'an Jiaotong University, 12480 Xi'an, Shaanxi China (e-mail: minnluo@mail.xjtu.edu.cn); Computer science and technology, Xi'an Jiaotong University, 12480 Xi'an, Shaanxi China (e-mail: liujun@mail.xjtu.edu.cn); Language Technology Institute, Carnegie Mellon University, 6612 Pittsburgh, Pennsylvania United States 15213-3815 (e-mail: cxj273@gmail.com); Information Technology and Electrical Engineering, University of Queensland, Queensland Australia (e-mail: yee.i.yang@gmail.com); Computer Science, Carnegie Mellon University, Pittsburgh, Pennsylvania United States 15213-3891 (e-mail: alex@cs.cmu.edu)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","Image-sentence matching is a challenging task for the heterogeneity-gap between different modalities. Ranking-based methods have achieved excellent performance on this task in the past decades. Given an image query, these methods typically assume that the correct matched image-sentence pair must rank before all the other mismatched ones. However, this assumption may be too strict and prone to the overfitting problem, especially when some sentences in a massive database are similar and confusable with one another. In this paper, we relax the traditional ranking loss and propose a novel deep multi-modal network with a top-$k$ ranking loss to mitigate the data ambiguity problem. With this strategy, query results will not be penalized unless the index of ground truth is outside the range of top-$k$ query results. Considering the non-smoothness and non-convexity of the initial top-$k$ ranking loss, we exploit a tight convex upper bound to approximate the loss and then utilize the traditional back-propagation algorithm to optimize the deep multi-modal network. Finally, we apply the method on three benchmark datasets, namely, Flickr8k, Flickr30k, and MSCOCO. Empirical results on metrics R@K(K=1,5,10) show that our method achieves comparable performance to state-of-the-art methods.","","","10.1109/TMM.2019.2931352","National Natural Science Foundation of China; Project of China Knowledge Centre for Engineering Science and Technology; Innovative Research Group of the National Natural Science Foundation of China; Intelligence Advanced Research Projects Activity IARPA via Department of Interior Interior Business Center DOIIBC; Innovation Research Team of Ministry of Education; Defense Advanced Research Projects Agency; Australian Research Council Discovery Early Career Researcher Award; National Key Research and Development Program of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8777191","Image-sentence matching;Cross-modal retrieval;Deep learning;Top-k ranking","Task analysis;Bidirectional control;Databases;Training;Deep learning;Sports;Semantics","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Landslide Detection of Hyperspectral Remote Sensing Data Based on Deep Learning With Constrains","C. Ye; Y. Li; P. Cui; L. Liang; S. Pirasteh; J. Marcato; W. N. Gonçalves; J. Li","Key Laboratory of Earth Exploration and Information Technology of Ministry of Education, Chengdu University of Technology, Chengdu 610059, China (e-mail: rsgis@sina.com).; Key Laboratory of Mountain Hazards and Earth Surface Process, Chinese Academy of Sciences, Chengdu 610041, China, (e-mail: yaolicd@hotmail.com).; with the Institute of Mountain Hazards and Environment, Chinese Academy of Sciences, Chengdu 610041, China (e-mail: yaolicd@hotmail.com).; University of the Chinese Academy of Sciences, Beijing 100049, China (e-mail: yaolicd@hotmail.com).; Key Laboratory of Mountain Hazards and Earth Surface Process, Chinese Academy of Sciences, Chengdu 610041, China, (e-mail: pengcui@imde.ac.cn).; with the Institute of Mountain Hazards and Environment, Chinese Academy of Sciences, Chengdu 610041, China (e-mail: pengcui@imde.ac.cn).; University of the Chinese Academy of Sciences, Beijing 100049, China (e-mail: pengcui@imde.ac.cn).; College of Management Science, Chengdu University of Technology, Chengdu 610059, China (e-mail: liangl@cdut.edu.cn).","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2019","PP","99","1","14","Detecting and monitoring landslides are hot topics in remote sensing community, particularly with the development of remote sensing technologies and the significant progress of computer vision. To the best of our knowledge, no study focused on deep learning-based methods for landslide detection on hyperspectral images. We proposes a deep learning framework with constraints to detect landslides on hyperspectral image. The framework consists of two steps. First, a deep belief network is employed to extract the spectral–spatial features of a landslide. Second, we insert the high-level features and constraints into a logistic regression classifier for verifying the landslide. Experimental results demonstrated that the framework can achieve higher overall accuracy when compared to traditional hyperspectral image classification methods. The precision of the landslide detection on the whole image, obtained by the proposed method, can reach 97.91%, whereas the precision of the linear support vector machine, spectral information divergence, and spectral angle match are 94.36%, 84.50%, and 86.44%, respectively. Also, this article reveals that the high-level feature extraction system has a significant potential for landslide detection, especially in multi-source remote sensing.","","","10.1109/JSTARS.2019.2951725","Key Research Program of Frontier Sciences CAS; Key Program of Sichuan science and technology department; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8911205","Deep belief network (DBN);deep learning;feature extraction;hyperspectral data;landslide","Terrain factors;Feature extraction;Hyperspectral imaging;Deep learning;Support vector machines","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Reinforced Cross-media Correlation Learning by Context-aware Bidirectional Translation","Y. Peng; J. Qi","Institute of Computer Science and Technology, Peking University, Beijing 100871, China.; Institute of Computer Science and Technology, Peking University, Beijing 100871, China.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","The heterogeneity gap leads to inconsistent distributions and representations between image and text, which rises a challenging task to measure their similarities and construct crossmedia correlation between them. Existing works mainly model the cross-media correlation in a common subspace, which causes insufficient correlation modeling in such third-party subspace with intermediate unidirectional transformation. Inspired by the recent advances of neural machine translation, which aims to establish a corresponding relationship between two entirely different languages, we can naturally discover that it has striking common characteristic with cross-media correlation learning to consider image and text as bilingual pairs, where the image is treated as a special kind of language to provide visual description, so that bidirectional transformation can be conducted between image and text to effectively explore cross-media correlation in the feature space of each media type. Thus, we propose a Reinforced Cross-media Bidirectional Translation (RCBT) approach to model the correlation between visual and textual descriptions. First, cross-media bidirectional translation mechanism is proposed to conduct direct transformation between the bilingual pairs of visual and textual descriptions bidirectionally, where the cross-media correlation can be effectively captured in both feature spaces of image and text through bidirectional translation training. Second, cross-media context-aware network with residual attention is proposed to exploit rich spatial and temporal context hints with cross-media convolutional recurrent neural network, which can lead to more precise correlation learning for promoting bidirectional translation process. Third, cross-media reinforcement learning is proposed to perform a two-agent communication game played as a round between image and text to boost the bidirectional translation process, and we further extract intermedia and intra-media reward signals to provide complementary clues for learning cross-media correlation. Extensive experiments are conducted on cross-media retrieval to verify the effectiveness of our proposed RCBT approach, compared with 11 state-of-theart methods on 3 cross-media datasets.","","","10.1109/TCSVT.2019.2907400","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8673892","Cross-media correlation learning;bidirectional translation;context-aware network;reinforcement learning","Correlation;Media;Visualization;Reinforcement learning;Context modeling;Games;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Learning-Based Machinery Fault Diagnostics with Domain Adaptation Across Sensors At Different Places","X. Li; W. Zhang; N. Xu; Q. Ding","College of Sciences, Northeastern University, Shenyang, Liaoning China (e-mail: xiangli@mail.neu.edu.cn); School of Aerospace Engineering, Shenyang Aerospace University, 66284 Shenyang, Liaoning China (e-mail: zw_7126257@163.com); College of Sciences, Northeastern University, Shenyang, Liaoning China (e-mail: 812811071@qq.com); Department of Mechanics, Tianjin University, Tianjin, Tianjin China (e-mail: qding@tju.edu.cn)","IEEE Transactions on Industrial Electronics","","2019","PP","99","1","1","In the recent years, data-driven machinery fault diagnostic methods have been successfully developed, and the tasks where the training and testing data are from the same distribution have been well addressed. However, due to sensor malfunctions, the training and testing data can be collected at different places of machines, resulting in the feature space with significant distribution discrepancy. This challenging issue has received less attention in the current literature, and the existing approaches generally fail in such scenarios. This paper proposes a domain adaptation method for machinery fault diagnostics based on deep learning. Adversarial training is introduced for marginal domain fusion, and unsupervised parallel data are explored to achieve conditional distribution alignments with respect to different machine health conditions. Experiments on two rotating machinery datasets are carried out for validations. The results suggest the proposed method is promising to address the fault diagnostic tasks with data from different places of machines, further enhancing applicability of data-driven methods in real industries.","","","10.1109/TIE.2019.2935987","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8809926","Deep learning;fault diagnosis;transfer learning;rotating machines","Sensors;Training;Testing;Machinery;Fault diagnosis;Task analysis;Vibrations","","","","","","","","","","IEEE","IEEE Early Access Articles"
"GrAMME: Semisupervised Learning Using Multilayered Graph Attention Models","U. S. Shanthamallu; J. J. Thiagarajan; H. Song; A. Spanias","Sensor Signal and Information Processing (SenSIP) Center, School of Electrical, Computer and Energy Engineering (ECEE), Arizona State University, Tempe, AZ 85287 USA (e-mail: ushantha@asu.edu).; Center for Applied Scientific Computing, Lawrence Livermore National Laboratory, Livermore, CA 94550-5507 USA.; Bosch Research North America, Sunnyvale, CA 94085 USA.; Sensor Signal and Information Processing (SenSIP) Center, School of Electrical, Computer and Energy Engineering (ECEE), Arizona State University, Tempe, AZ 85287 USA.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","12","Modern data analysis pipelines are becoming increasingly complex due to the presence of multiview information sources. While graphs are effective in modeling complex relationships, in many scenarios, a single graph is rarely sufficient to succinctly represent all interactions, and hence, multilayered graphs have become popular. Though this leads to richer representations, extending solutions from the single-graph case is not straightforward. Consequently, there is a strong need for novel solutions to solve classical problems, such as node classification, in the multilayered case. In this article, we consider the problem of semisupervised learning with multilayered graphs. Though deep network embeddings, e.g., DeepWalk, are widely adopted for community discovery, we argue that feature learning with random node attributes, using graph neural networks, can be more effective. To this end, we propose to use attention models for effective feature learning and develop two novel architectures, GrAMME-SG and GrAMME-Fusion, that exploit the interlayer dependences for building multilayered graph embeddings. Using empirical studies on several benchmark data sets, we evaluate the proposed approaches and demonstrate significant performance improvements in comparison with the state-of-the-art network embedding strategies. The results also show that using simple random features is an effective choice, even in cases where explicit node attributes are not available.","","","10.1109/TNNLS.2019.2948797","Sensor Signal and Information Processing SenSIP Center Arizona State University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8901181","Attention;deep learning;multilayered graphs;network embeddings;semisupervised learning.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A deep learning framework for identifying essential proteins by integrating multiple types of biological information","M. Zeng; M. Li; Z. Fei; F. Wu; Y. Li; Y. Pan; J. Wang","Central South University, 12570 Changsha, Hunan China 410083 (e-mail: zengmin@csu.edu.cn); Computer Science, Central South University, Changsha, Hunan China (e-mail: limin@mail.csu.edu.cn); Changsha, Hunan China (e-mail: zhihuifei@foxmail.com); Department of Mechanical Engineering, University of Saskatchewan, Saskatoon, Saskatchewan Canada S7N 5A9 (e-mail: faw341@mail.usask.ca); Computer Science, Old Dominion University, Norfolk, Virginia United States 23508 (e-mail: yaohang@cs.odu.edu); Department of Computer Science, Georgia State University, Atlanta, Georgia United States (e-mail: yipan@gsu.edu); Computer Science, Central South University, ChangSha, Hunan China 410083 (e-mail: jxwang@mail.csu.edu.cn)","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2019","PP","99","1","1","Computational methods including centrality and machine learning-based methods have been proposed to identify essential proteins for understanding the minimum requirements of the survival and evolution of a cell. In centrality methods, researchers are required to design a score function which is based on prior knowledge, yet is usually not sufficient to capture the complexity of biological information. In machine learning-based methods, some selected biological features cannot represent the complete properties of biological information as they lack a computational framework to automatically select features. To tackle these problems, we propose a deep learning framework to automatically learn biological features without prior knowledge. We use node2vec technique to automatically learn a richer representation of protein-protein interaction (PPI) network topologies than a score function. Bidirectional long short term memory cells are applied to capture non-local relationships in gene expression data. For subcellular localization information, we exploit a high dimensional indicator vector to characterize their feature. To evaluate the performance of our method, we tested it on PPI network of S. cerevisiae. Our experimental results demonstrate that the performance of our method is better than traditional centrality methods and is superior to existing machine learning-based methods. To explore which of the three types of biological information is the most vital element, we conduct an ablation study by removing each component in turn. Our results show that the PPI network embedding contributes most to the improvement. In addition, gene expression profiles and subcellular localization information are also helpful to improve the performance in identification of essential proteins.","","","10.1109/TCBB.2019.2897679","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8634927","Deep learning;essential proteins;protein-protein interaction network;gene expression;subcellular localization","Proteins;Gene expression;Feature extraction;Deep learning;Learning systems;Biological information theory","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Robust Deep Sensing Through Transfer Learning in Cognitive Radio","Q. Peng; A. Gilman; N. Vasconcelos; P. C. Cosman; L. B. Milstein","University of Electronic Science and Technology of China, Chengdu, China 611731.; School of Natural and Computational Sciences, Massey University, Auckland, New Zealand.; Department of Electrical and Computer Engineering, University of California at San Diego, La Jolla, CA 92093 USA.; Department of Electrical and Computer Engineering, University of California at San Diego, La Jolla, CA 92093 USA.; Department of Electrical and Computer Engineering, University of California at San Diego, La Jolla, CA 92093 USA.","IEEE Wireless Communications Letters","","2019","PP","99","1","1","We propose a robust spectrum sensing framework based on deep learning. The received signals at the secondary user’s receiver are filtered, sampled and then directly fed into a convolutional neural network. Although this deep sensing is effective when operating in the same scenario as the collected training data, the sensing performance is degraded when it is applied in a different scenario with different wireless signals and propagation. We incorporate transfer learning into the framework to improve the robustness. Results validate the effectiveness as well as the robustness of the proposed deep spectrum sensing framework.","","","10.1109/LWC.2019.2940579","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8830453","Spectrum sensing;deep learning;robustness;transfer learning;cognitive radio.","Sensors;Phase shift keying;Robustness;Training;Receivers;Neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Learning driven Venue Recommender for Event-based Social Networks","S. Pramanik; R. Haldar; A. Kumar; S. Pathak; B. Mitra","Computer Science & Engineering, Indian Institute of Technology Kharagpur, 30133 Kharagpur, West Bengal India 721302 (e-mail: soumajit.pramanik@gmail.com); Computer Science & Engineering, Indian Institute of Technology Kharagpur, 30133 Kharagpur, West Bengal India (e-mail: rajarshi.haldar@iitkgp.ac.in); Computer Science & Engineering, Indian Institute of Technology Kharagpur, 30133 Kharagpur, West Bengal India (e-mail: anandsit043@iitkgp.ac.in); Artificial Intelligence, Microsoft Research, 214606 Redmond, Washington United States (e-mail: sayanpa@microsoft.com); Computer Science and Engineering, Indian Institute of Technology Kharagpur, 30133 Kharagpur, West Bengal India (e-mail: bivas@cse.iitkgp.ernet.in)","IEEE Transactions on Knowledge and Data Engineering","","2019","PP","99","1","1","Event-based online social platforms, such as Meetup and Plancast, have experienced increased popularity and rapid growth in recent years. In EBSN setup, selecting suitable venues for hosting events, which can attract a great turnout, is a key challenge. In this paper, we present a deep learning based venue recommendation system DeepVenue which provides context driven venue recommendations for the Meetup event-hosts to host their events. The crux of the proposed model relies on the notion of similarity between multiple Meetup entities such as events, venues, groups etc. We develop deep learning techniques to compute a compact descriptor for each entity, such that two entities (say, venues) can be compared numerically. Notably, to mitigate the scarcity of venue related information in Meetup, we leverage on the cross domain knowledge transfer from popular LBSN service Yelp to extract rich venue related content. For hosting an event, the proposed DeepVenue model computes a success score for each candidate venue and ranks those venues according to the scores and finally recommend the top k venues. Our rigorous evaluation on the Meetup data collected for city Chicago shows that DeepVenue significantly outperforms the baselines algorithms. Precisely, for 84% of events, the correct hosting venue appears in the top 5 of DeepVenue recommended list.","","","10.1109/TKDE.2019.2915523","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8709774","Deep Learning;Venue Recommender System;Transfer Learning;EBSN","Deep learning;History;Heterogeneous networks;Social networking (online);Metadata;Computational modeling;Numerical models","","","","","","","","","","IEEE","IEEE Early Access Articles"
"An Intelligent Route Computation Approach Based on Real-Time Deep Learning Strategy for Software Defined Communication Systems","B. Mao; F. Tang; Z. M. Fadlullah; N. Kato","Graduate School of Information Science, Tohoku University, Sendai, Miyagi Japan (e-mail: bomin.mao@it.is.tohoku.ac.jp); Graduate School of Information Sciences, Tohoku Daigaku, 13101 Sendai, Miyagi Japan 980-8577 (e-mail: fengxiao.tang@it.is.tohoku.ac.jp); Graduate School of Information Sciences (GSIS), Tohoku University, Sendai-Shi, Miyagi Japan (e-mail: zubair@it.is.tohoku.ac.jp); Graduate School of Information Sciences, Tohoku Univ., Sendai, Miyagi Japan 9808579 (e-mail: kato@it.is.tohoku.ac.jp)","IEEE Transactions on Emerging Topics in Computing","","2019","PP","99","1","1","Software Defined Networking (SDN) is regarded as the next generation paradigm as it simplifies the structure of the data plane and improves the resource utilization. However, in current Software Defined Communication Systems (SDCSs), the maximum or minimum metric value based routing strategies come from traditional networks, which lack the ability of self-adaptation and do not efficiently utilize the computation resource in the controllers. To solve these problems, in this paper, we utilize the deep learning technique to conduct the routing computation for the SDCSs. Specifically, in our proposal, the considered Convolutional Neural Networks (CNNs) are adopted to intelligently compute the paths according to the input real-time traffic traces. To reduce the computation overhead of the central controller and improve the adaptation of CNNs to the changing traffic pattern, we consider an online training manner. Analysis shows that the computation complexity can be significantly reduced through the online training manner. Moreover, the simulation results demonstrate that our proposed CNNs are able to compute the appropriate paths combinations with high accuracy. Furthermore, the adopted periodical retraining enables the deep learning structures to adapt to the traffic changes.","","","10.1109/TETC.2019.2899407","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8642376","Software Defined Communication Systems;deep learning;real-time learning;routing computation","Deep learning;Control systems;Routing;Training;Proposals;Software;Routing protocols","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Bayesian Deep Learning Based Probabilistic Load Forecasting in Smart Grids","Y. Yang; W. Li; T. A. Gulliver; S. Li","Beijing University of Posts and Telecommunications, 12472 Beijing China 100876 (e-mail: yydxlv@qq.com); University of Victoria, 8205 Victoria, British Columbia Canada V8P 5C2 (e-mail: weili@ieee.org); University of Victoria, 8205 Victoria, British Columbia Canada V8P 5C2 (e-mail: agullive@ece.uvic.ca); Beijing University of Posts and Telecommunications, 12472 Beijing China 100876 (e-mail: bupt_paper@126.com)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","The extensive deployment of smart meters in millions of households provides a huge amount of individual electricity consumption data for demand side analysis at a fine granularity. Different from traditional aggregated system-level data, smart meter data is more irregular and unpredictable. As a result, probabilistic load forecasting, which can provide a better understanding of the uncertainty and volatility in future demand, is critical to constructing energy-efficient and reliable smart grids. In this paper, a recently developed technique called Bayesian deep learning is employed to solve this challenging problem. In particular, a novel multitask probabilistic load forecasting framework based on Bayesian deep learning is proposed to quantify the shared uncertainties across distinct customer groups while accounting for their differences. Further, a clustering-based pooling method is designed to increase the data diversity and volume for the framework. This not only addresses the problem of overfitting but also improves the predictive performance. Numerical results are presented which demonstrate that the proposed framework provides superior probabilistic forecasting accuracy over conventional methods.","","","10.1109/TII.2019.2942353","National Natural Science Foundation of China; BUPT Excellent Ph.D. Students Foundation; China Scholarship Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8844831","Bayesian deep learning;clustering-based pooling;multitask learning;probabilistic load forecasting","Deep learning;Bayes methods;Probabilistic logic;Load forecasting;Smart meters;Uncertainty;Forecasting","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Learning-Based Technology in Responses to the Joint Call for Proposals on Video Compression with Capability beyond HEVC","D. Liu; Z. Chen; S. Liu; F. Wu","CAS Key Laboratory of Technology in Geo-Spatial Information Processing and Application System, University of Science and Technology of China, Hefei 230027, China.; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan 430079, China.; Tencent Media Lab, Palo Alto, CA 94301, USA.; CAS Key Laboratory of Technology in Geo-Spatial Information Processing and Application System, University of Science and Technology of China, Hefei 230027, China.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Deep learning has achieved great success in the past decade, especially in the fields of computer vision and image processing. After witnessing such success, video coding experts are motivated to consider whether deep learning can also benefit video coding, and if so, they seek to discover why and how. Indeed, a number of research studies have been conducted to explore deep learning for image and video coding, which has been an active and fast-growing research area especially since the year 2015. These prior arts can be divided into two categories: new coding schemes that are built solely upon deep networks (deep schemes), and deep network-based coding tools that are embedded into traditional coding schemes (deep tools). Moreover, in the responses to the joint call for proposals on video compression with capability beyond High Efficiency Video Coding (HEVC), a number of deep tools have been proposed, and some of them are further studied for the upcoming Versatile Video Coding (VVC). In this paper, we summarize the ongoing efforts in the Joint Video Experts Team about the proposed deep tools, and we discuss several promising tools in much detail, including neural network-based intra prediction, convolutional neural network (CNN) based in-loop filtering, and CNN-based block-adaptive-resolution coding. A series of experimental results are provided to demonstrate the capability of these tools in achieving higher compression efficiency than the VVC or HEVC anchor. These results shed light on the promising direction of deep learning-based future video coding, towards which a lot of open problems call for further study.","","","10.1109/TCSVT.2019.2945057","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8854824","Convolutional neural network (CNN);deep learning;High Efficiency Video Coding (HEVC);neural network (NN);Versatile Video Coding (VVC);video coding","Image coding;Tools;Deep learning;High efficiency video coding;Proposals;Neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Comparative Analysis of Deep Learning and Machine Learning on Detecting Movement Directions using PIR Sensors","J. Yun; J. Woo","Department of Internet of Things, Soonchunhyang University, Asan 31538, South Korea.; Department of Big Data Engineering, Soonchunhyang University, Asan 31538, South Korea.","IEEE Internet of Things Journal","","2019","PP","99","1","1","Machine learning has played a significant role in building intelligent systems in the history of data science. In the recent paradigm where objects in the world greenwill be connected with each other, commonly referred to as the Internet of Things (IoT), people begin to consider the challenges and opportunities to utilize the huge data sets generated, also referred to as Big data. One of the active research topics in dealing with the IoT’s big data is the practical feasibility of algorithms used in classical machine learning but also in a newly-emerging branch, called deep learning. In this paper, we demonstrate a quantitative analysis comparing performance between classical machine learning and deep learning algorithms with a human movement direction detecting application based on analog pyroelectric infrared (PIR) sensor signals. The sensing data acquisition and retrieval system is implemented with the open-source IoT software platforms based on the oneM2M standard. With the analog PIR data sets collected from 30 subjects, we perform experimental studies comparing classical machine learning and deep learning algorithms in terms of economic feasibility, scalability, generality, and real-time detection performance. The results show that classical machine learning shows better performance in real-time detection (i.e., with the sensing values within the first 0.5 seconds). In contrast, our simple deep learning model achieves about 90% accuracy for detecting moving directions even with the data sets from only three subjects and a single PIR sensor. Moreover, it could be applied to a larger number of subjects without updates.","","","10.1109/JIOT.2019.2963326","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8946758","Pyroelectric Infrared (PIR) sensor;machine learning;deep learning;IoT platform;oneM2M standards.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"DeepStealth: Game-Based Learning Stealth Assessment with Deep Neural Networks","W. Min; M. Frankosky; B. W. Mott; J. Rowe; P. A. M. Smith; E. Wiebe; K. Boyer; J. Lester","Computer Science, North Carolina State University, 6798 Raleigh, North Carolina United States (e-mail: wmin@ncsu.edu); Intelligent Devices Group, Lenovo Group Ltd USA, 377494 Morrisville, North Carolina United States (e-mail: meganfrankosky@gmail.com); Computer Science, North Carolina State University, 6798 Raleigh, North Carolina United States (e-mail: bwmott@ncsu.edu); Computer Science, North Carolina State University, 6798 Raleigh, North Carolina United States (e-mail: jprowe@ncsu.edu); Computer Science, North Carolina State University, 6798 Raleigh, North Carolina United States 27695 (e-mail: peter.andrew.smith@gmail.com); STEM Education, North Carolina State University, 6798 Raleigh, North Carolina United States (e-mail: wiebe@ncsu.edu); Computer & Information Science & Engineering, University of Florida, 3463 Gainesville, Florida United States (e-mail: keboyer@ufl.edu); Computer Science, North Carolina State University, 6798 Raleigh, North Carolina United States (e-mail: lester@ncsu.edu)","IEEE Transactions on Learning Technologies","","2019","PP","99","1","1","A distinctive feature of game-based learning environments is their capacity for enabling stealth assessment. Stealth assessment analyzes a stream of fine-grained student interaction data from a game-based learning environment to dynamically draw inferences about students' competencies through evidence-centered design. In evidence-centered design, evidence models have been traditionally designed using statistical rules authored by domain experts that are encoded using Bayesian networks. This article presents DeepStealth, a deep learning-based stealth assessment framework, that yields significant reductions in the feature engineering labor that has previously been required to create stealth assessments. DeepStealth utilizes end-to-end trainable deep neural network-based evidence models. Using this framework, evidence models are devised using a set of predictive features captured from raw, low-level interaction data to infer evidence for competencies. We investigate two deep learning-based evidence models, long short-term memory networks (LSTMs) and n-gram encoded feedforward neural networks (FFNNs). We compare these models' predictive performance for inferring students' knowledge to linear-chain conditional random fields (CRFs) and nave Bayes models. We perform feature set-level analyses of game trace logs and external pre-learning measures, and we examine the models early prediction capacity. The framework is evaluated using data collected from 182 middle school students interacting with a game-based learning environment for middle grade computational thinking. Results indicate that LSTM-based stealth assessors outperform competitive baseline approaches with respect to predictive accuracy and early prediction capacity. We find that LSTMs, FFNNs, and CRFs all benefit from combined feature sets derived from both game trace logs and external pre-learning measures.","","","10.1109/TLT.2019.2922356","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8735739","Computational Thinking;Deep Learning;Educational Games;Game-Based Learning;Stealth Assessment","Hidden Markov models;Computational modeling;Games;Predictive models;Task analysis;Adaptation models;Computer science","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Deep Residual Learning Meets OFDM Channel Estimation","L. Li; H. Chen; H. Chang; L. Liu","Electrical and Computer Engineering Department, Virginia Tech.; Samsung Research America.; Electrical and Computer Engineering Department, Virginia Tech.; Electrical and Computer Engineering Department, Virginia Tech.","IEEE Wireless Communications Letters","","2019","PP","99","1","1","In this work we apply deep learning tools to conduct channel estimation for an orthogonal frequency division multiplexing (OFDM) system based on downlink pilots. To be specific, a residual learning based deep neural network specifically designed for channel estimation is introduced. Due to the compact network size as well as the underlying network architecture, the computation cost can be greatly reduced. Furthermore, this residual network architecture is compatible with any downlink pilot patterns making it compatible for modern wireless systems. The estimation error of the introduced residual learning approach is evaluated under 3rd Generation Partnership Project (3GPP) channel models. It outperforms other deep learning based estimation method with comparable to minimum mean square error (MMSE) estimation performance.","","","10.1109/LWC.2019.2962796","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8944280","Channel estimation;OFDM;Deep residual learning;Image super-resolution.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Hierarchical quality-relevant feature representation for soft sensor modeling: a novel deep learning strategy","X. Yuan; J. Zhou; B. Huang; Y. Wang; C. Yang; W. Gui","Central South University, 12570 Changsha, Hunan China 410083 (e-mail: yuanxf@csu.edu.cn); Central South University, 12570 Changsha, Hunan China 410083 (e-mail: 754712094@qq.com); Chemical and Materials Engineering, University of Alberta, Edmonton, Alberta Canada T6G2V4 (e-mail: biao.huang@ualberta.ca); Central South University, 12570 Changsha, Hunan China 410083 (e-mail: ylwang@csu.edu.cn); Changsha, Hunan China 410083 (e-mail: ychh@csu.edu.cn); Central South University, 12570 Changsha, Hunan China 410083 (e-mail: gwh@csu.edu.cn)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","Deep learning is a recently developed feature representation technique for data with complicated structures, which has great potential for soft sensing of industrial processes. However, most deep networks mainly focus on hierarchical feature learning for the raw observed input data. For soft sensor applications, it is important to reduce irrelevant information and extract quality-relevant features from the raw input data for quality prediction. To deal with this problem, a novel deep learning network is proposed for quality-relevant feature representation in this paper, which is based on stacked quality-driven autoencoder (SQAE). First, quality-driven autoencoder (QAE) is designed by exploiting the quality data to guide feature extraction with the constraint that the potential features should largely reconstruct the input layer data and the quality data at the output layer. In this way, quality-relevant features can be captured by QAE. Then, by stacking multiple QAEs to construct the deep SQAE network, SQAE can gradually reduce irrelevant features and learn hierarchical quality-relevant features. Finally, the high-level quality-relevant features can be directly applied for soft sensing of the quality variables. The effectiveness and flexibility of the proposed deep learning model are validated on an industrial debutanizer column process.","","","10.1109/TII.2019.2938890","Natural Science Foundation of Hainan Province; Fundamental Research Funds for the Central Universities; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8822746","Deep learning;Artificial neural network;Quality-driven autoencoder (QAE);Stacked QAE;Soft sensor","Deep learning;Feature extraction;Data models;Informatics;Principal component analysis;Support vector machines;Correlation","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Comparative Measurement Study of Deep Learning as a Service Framework","Y. Wu; L. Liu; C. Pu; W. Cao; S. Sahin; W. Wei; Q. Zhang","School of Computer Science, Georgia Institute of Technology College of Computing, 166857 Atlanta, Georgia United States 30332-0280 (e-mail: yanzhaowu@gatech.edu); Computer Science, Georgia Institute of Technology, Atlanta, Georgia United States (e-mail: lingliu@cc.gatech.edu); College of Computing, Georgia Institute of Technology, Atlanta, Georgia United States (e-mail: calton.pu@cc.gatech.edu); School of Computer Science, Georgia Institute of Technology College of Computing, 166857 Atlanta, Georgia United States (e-mail: wcao39@gatech.edu); School of Computer Science, Georgia Institute of Technology College of Computing, 166857 Atlanta, Georgia United States (e-mail: ssahin7@gatech.edu); School of Computer Science, Georgia Institute of Technology, Atlanta, Georgia United States (e-mail: wenqiwei@gatech.edu); IBM Thomas J Watson Research Center, 71353 Yorktown Heights, New York United States (e-mail: Q.Zhang@ibm.com)","IEEE Transactions on Services Computing","","2019","PP","99","1","1","Big data powered Deep Learning (DL) and its applications have blossomed in recent years, fueled by three technological trends: a large amount of data openly accessible, a growing number of DL frameworks, and a selection of affordable hardware devices. However, no single DL framework, to date, dominates, making the selection of DL frameworks overwhelming. This paper takes a holistic approach to conduct empirical comparison and analysis of four representative DL frameworks with three unique contributions. First, we show that for a specific DL framework, different configurations of its hyper-parameters may have a significant impact on performance. Second, this study is the first to identify the opportunities for improving the runtime performance and accuracy of DL frameworks by configuring computing libraries and tuning individual and multiple hyper-parameters. Third, we conduct a comparative measurement study on the resource consumption patterns and their performance implications, including CPU and memory usage, and their correlations to hyper-parameters. We argue that this study provides in-depth empirical comparison and analysis of DL frameworks, and offers practical guidance for service providers to deploying and delivering DL as a Service and for application developers and DLaaS consumers to select the right DL frameworks for the right DL workloads.","","","10.1109/TSC.2019.2928551","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8765795","Deep Learning as a Service;Big Data;Deep Neural Networks;Accuracy","Libraries;Parallel processing;Hardware;Training;Runtime;Deep learning;Task analysis","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"A Model-driven Deep Reinforcement Learning Heuristic Algorithm for Resource Allocation in Ultra-dense Cellular Networks","X. Liao; J. Shi; Z. Li; L. Zhang; B. Xia","Xi,an, shanxi China 710071 (e-mail: lxm8410@163.com); State Key Lab of ISN, Xidian University, 47905 Xian, Shaanxi China 710071 (e-mail: jiashi@xidian.edu.cn); State Key Laboratory of ISN, School of Communication, Xidian University, xi'an, Shannxi China 710071 (e-mail: zanli@xidian.edu.cn); School of Engineering, University of Glasgow, Glasgow, Glasgow United Kingdom of Great Britain and Northern Ireland G12 8QQ (e-mail: lei.zhang@glasgow.ac.uk); Top Data Science Ltd, Helsinki, Helsinki Finland (e-mail: baiqiang.xia@topdatascience.com)","IEEE Transactions on Vehicular Technology","","2019","PP","99","1","1","This paper investigates a model-driven deep reinforcement learning assisted resource allocation for future ultra-dense cellular networks (UDNs). The multi-objective optimization problem is formulated to jointly maximize the network spectrum efficiency (SE), energy efficiency (EE) and fairness in the presence of a very limited amount of channel state information (CSI). To solve this NP-hard nonconvex multi-objective problem, we design a novel deep neural network (DNN)-based optimization frame- work which consists of a series of Alternating Direction Method of Multipliers (ADMM) iterative procedures. Then a novel channel information absent Q-learning resource allocation (CIAQ) algorithm is proposed by leveraging the DNN-based optimization framework, where the SE, the EE, and the fairness can be optimized simultaneously. In particular, the CIAQ algorithm sets the CSI as the unknown weights, while it takes the EE and the fairness as the rewards to train the designed DNN-based optimization framework without massive labeling data, thereby efficiently solving the multi-objective optimization problem. Our simulation results show that, the proposed CIAQ with rapid convergence speed not only well characterizes the extent of optimization objective by adjusting discount factor, but also significantly outperforms the current random initialization method of neural network and the other existing resource allocation algorithms.","","","10.1109/TVT.2019.2954538","China Postdoctoral Science Foundation; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8907392","Ultra-dense cellular networks;resource allocation;deep reinforcement learning;model-driven;optimization","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Memory Optimization for Energy-Efficient Differentially Private Deep Learning","J. Edstrom; H. Das; Y. Xu; N. Gong","Department of Electrical and Computer Engineering, North Dakota State University, Fargo, ND 58108 USA.; Department of Electrical and Computer Engineering, North Dakota State University, Fargo, ND 58108 USA.; Department of Industrial and Manufacturing Engineering, North Dakota State University, Fargo, ND 58108 USA.; Department of Electrical and Computer Engineering, University of South Alabama, Mobile, AL 36688 USA (e-mail: nagong@southalabama.edu).","IEEE Transactions on Very Large Scale Integration (VLSI) Systems","","2019","PP","99","1","10","With the advent of Internet of Things (IoT) technologies and availability of a large amount of data, deep learning has been applied in a variety of artificial intelligence (AI) applications. However, sharing personal data using IoT edge devices carries inherent risks to individual privacy. Meanwhile, the energy and memory resources needed during the inference process become a constraint to the resource-limited IoT edge devices. This article brings memory hardware optimization to meet the tight power budget in IoT edge devices by considering the privacy, accuracy, and power efficiency tradeoff in differentially efficient deep learning systems. Based on a detailed analysis on these characteristics, an integer linear programs (ILP) model is developed to minimize mean square error (MSE), thereby enabling optimal input data memory design. Our simulation results in 45-nm CMOS technology show that the proposed technique can enable near-threshold energy-efficient memory operation for different privacy requirements, with less than 1% degradation in classification accuracy.","","","10.1109/TVLSI.2019.2946128","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8897079","Accuracy;deep learning;differential privacy;embedded memory;integer linear programs (ILP);model power consumption.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Accurate Deep Learning-Based Sleep Staging in a Clinical Population with Suspected Obstructive Sleep Apnea","H. Korkalainen; J. Aakko; S. Nikkonen; S. Kainulainen; A. Leino; B. Duce; I. O. Afara; S. Myllymaa; J. Toyras; T. Leppänen","Department of Clinical Neurophysiology, Diagnostic Imaging Centerter, Kuopio University Hospital, 60650 Kuopio, Pohjois-Savo Finland (e-mail: henri.korkalainen@uef.fi); CGI Suomi Oy, Helsinki Finland (e-mail: juhani.aakko@cgi.com); Department of Clinical Neurophysiology, Diagnostic Imaging Centerter, Kuopio University Hospital, 60650 Kuopio, Pohjois-Savo Finland (e-mail: sami.nikkonen@uef.fi); Department of Clinical Neurophysiology, Diagnostic Imaging Centerter, Kuopio University Hospital, 60650 Kuopio, Pohjois-Savo Finland (e-mail: samu.kainulainen@uef.fi); Department of Clinical Neurophysiology, Diagnostic Imaging Centerter, Kuopio University Hospital, 60650 Kuopio, Pohjois-Savo Finland (e-mail: akseli.leino@uef.fi); Department of Respiratory & Sleep Medicine, Sleep Disorders Centre, Princess Alexandra Hospital Health Service District, 1966 Woolloongabba, Queensland Australia (e-mail: brett.duce@health.qld.gov.au); Department of Clinical Neurophysiology, Diagnostic Imaging Centerter, Kuopio University Hospital, 60650 Kuopio, Pohjois-Savo Finland (e-mail: isaac.afara@uef.fi); Department of Applied Physics, University of Eastern Finland Faculty of Natural Science and Forestry Sciences, 205539 Kuopio Finland (e-mail: sami.myllymaa@uef.fi); Department of Clinical Neurophysiology, Diagnostic Imaging Centerter, Kuopio University Hospital, 60650 Kuopio, Pohjois-Savo Finland (e-mail: juha.toyras@uef.fi); Department of Clinical Neurophysiology, Diagnostic Imaging Centerter, Kuopio University Hospital, 60650 Kuopio, Pohjois-Savo Finland (e-mail: timo.leppanen@uef.fi)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","The identification of sleep stages is essential in the diagnostics of sleep disorders, among which obstructive sleep apnea (OSA) is one of the most prevalent. However, manual scoring of sleep stages is time-consuming, subjective, and costly. To overcome this shortcoming, we aimed to develop an accurate deep learning approach for automatic classification of sleep stages and to study the effect of OSA severity on the classification accuracy. Overnight polysomnographic recordings from a public dataset of healthy individuals (Sleep-EDF, n=153) and from a clinical dataset (n=891) of patients with suspected OSA were used to develop a combined convolutional and long short-term memory neural network. On the public dataset, the model achieved sleep staging accuracy of 83.7% (κ=0.77) with a single frontal EEG channel and 83.9% (κ=0.78) when supplemented with EOG. For the clinical dataset, the model achieved accuracies of 82.9% (κ=0.77) and 83.8% (κ=0.78) with a single EEG channel and two channels (EEG+EOG), respectively. The sleep staging accuracy decreased with increasing OSA severity. The single-channel accuracy ranged from 84.5% (κ=0.79) for individuals without OSA diagnosis to 76.5% (κ=0.68) for severe OSA patients. In conclusion, deep learning enables automatic sleep staging for suspected OSA patients with high accuracy and expectedly, the accuracy lowered with increasing OSA severity. Furthermore, the accuracies achieved in the public dataset were superior to previously published state-of-the-art methods. Adding an EOG channel did not significantly increase the accuracy. The automatic, single-channel-based sleep staging could enable easy, accurate, and cost-efficient integration of EEG recording into diagnostic ambulatory recordings.","","","10.1109/JBHI.2019.2951346","Research Committee of the Kuopio University Hospital Catchment Area for the State Research Funding; Academy of Finland; Respiratory Foundation of Kuopio Region; Research Foundation of the Pulmonary Diseases; Foundation of the Finnish Anti-Tuberculosis Association; Paivikki and Sakari Sohlberg Foundation; Orion Research Foundation; Instrumentarium Science Foundation; Finnish Cultural Foundation via the Post Docs in Companies program and via the Central Fund; Paulo Foundation; Tampere Tuberculosis Foundation; Business Finland; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8936942","Deep learning;Electroencephalography;Obstructive sleep apnea;Recurrent neural network;Sleep staging","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Semiautomatic Labeling for Deep Learning in Robotics","D. De Gregorio; A. Tonioni; G. Palli; L. Di Stefano","DISI Department, University of Bologna, 40136 Bologna, Italy. They are now with the Department of Computer Science and Engineering, University of Bologna, 40136 Bologna, Italy (e-mail: d.degregorio@unibo.it).; DISI Department, University of Bologna, 40136 Bologna, Italy. They are now with the Department of Computer Science and Engineering, University of Bologna, 40136 Bologna, Italy.; DEI Department, University of Bologna, 40136 Bologna, Italy. He is now with the Department of Electrical, Electronics and Information Engineering, University of Bologna, 40136 Bologna, Italy.; DISI Department, University of Bologna, 40136 Bologna, Italy. They are now with the Department of Computer Science and Engineering, University of Bologna, 40136 Bologna, Italy.","IEEE Transactions on Automation Science and Engineering","","2019","PP","99","1","10","In this article, we propose an augmented reality semiautomatic labeling (ARS), a semiautomatic method which leverages on moving a 2-D camera by means of a robot, proving precise camera tracking, and an augmented reality pen (ARP) to define initial object bounding box, to create large labeled data sets with minimal human intervention. By removing the burden of generating annotated data from humans, we make the deep learning technique applied to computer vision, which typically requires very large data sets, truly automated and reliable. With the ARS pipeline, we created two novel data sets effortlessly, one on electromechanical components (industrial scenario) and other on fruits (daily-living scenario) and trained two state-of-the-art object detectors robustly, based on convolutional neural networks, such as you only look once (YOLO) and single shot detector (SSD). With respect to conventional manual annotation of 1000 frames that takes us slightly more than 10 h, the proposed approach based on ARS allows to annotate 9 sequences of about 35,000 frames in less than 1 h, with a gain factor of about 450. Moreover, both the precision and recall of object detection is increased by about 15% with respect to manual labeling. All our software is available as a robot operating system (ROS) package in a public repository alongside with the novel annotated data sets.","","","10.1109/TASE.2019.2938316","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8844069","Artificial intelligence;computer vision;object detection.","Cameras;Labeling;Training;Robot vision systems;Deep learning;Augmented reality","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Multiset Feature Learning for Highly Imbalanced Data Classification","X. Jing; X. Zhang; X. Zhu; F. Wu; X. You; Y. Gao; S. Shan; J. Yang","School of Computer, Wuhan University, Wuhan City, Hubei Province China (e-mail: jingxy_2000@126.com); School of Computer, Wuhan University, Wuhan, Hubei China (e-mail: zhangxinyu247@163.com); School of Computer, Wuhan University, 12390 Wuhan, Hubei China (e-mail: henuzxk@163.com); College of Automation, Nanjing University of Posts and Telecommunications, 12577 Nanjing, Jiangsu China 210003 (e-mail: wufei_8888@126.com); Institute for Pattern Recognition & Artificial Intelligence, Huazhong University of Science & Technology, Wuhan, Hubei China (e-mail: youxg@mail.hust.edu.cn); State Key Laboratory for Novel Software Technology, The Department of Computer Science and Technology, Nanjing University, Nanjing, Jiangsu China 210046 (e-mail: gaoy@nju.edu.cn); Institute of Computing Technology, Chinese Academy of Science, Haidian, Beijing China 100080 (e-mail: sgshan@ict.ac.cn); College of Computer and Technology, Nanjing University of Science and Technology, Nanjing, Jiangsu China (e-mail: yangjy@mail.njust.edu.cn)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","With the expansion of data, increasing imbalanced data has emerged. When the imbalance ratio (IR) of data is high, most existing imbalanced learning methods decline seriously in classification performance. In this paper, we systematically investigate the highly imbalanced data classification problem, and propose an uncorrelated cost-sensitive multiset learning (UCML) approach for it. Specifically, UCML first constructs multiple balanced subsets through random partition, and then employs the multiset feature learning (MFL) to learn discriminant features from the constructed multiset. To enhance the usability of each subset and deal with the non-linearity issue existed in each subset, we further propose a deep metric based UCML (DM-UCML) approach. DM-UCML introduces the generative adversarial network technique into the multiset constructing process, such that each subset can own similar distribution with the original dataset. To cope with the non-linearity issue, DM-UCML integrates deep metric learning with MFL, such that more favorable performance can be achieved. In addition, DM-UCML designs a new discriminant term to enhance the discriminability of learned metrics. Experiments on eight traditional highly class-imbalanced datasets and two large-scale datasets indicate that: the proposed approaches outperform state-of-the-art highly imbalanced learning methods and are more robust to high IR.","","","10.1109/TPAMI.2019.2929166","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8765367","Highly imbalanced data classification;multiset feature learning;deep metric learning;generative adversarial network;cost-sensitive factor;weighted uncorrelated constraint","Learning systems;Measurement;Task analysis;Correlation;Training;Usability;Generative adversarial networks","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Sample Balancing for Deep Learning-Based Visual Recognition","X. Chen; J. Weng; W. Luo; W. Lu; H. Wu; J. Xu; Q. Tian","College of Information Science and Technology, Jinan University, Guangzhou 510632, China.; College of Information Science and Technology, Jinan University, Guangzhou 510632, China (e-mail: cryptjweng@gmail.com).; College of Information Science and Technology, Jinan University, Guangzhou 510632, China.; Guangdong Key Laboratory of Information Security Technology, Ministry of Education Key Laboratory of Machine Intelligence and Advanced Computing, School of Data and Computer Science, Sun Yat-sen University, Guangzhou 510006, China.; College of Information Science and Technology, Jinan University, Guangzhou 510632, China.; Baiyun District Bureau of Justice, Guangzhou 510405, China.; Noah's Ark Lab, Huawei, Shenzhen 518129, China.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","15","Sample balancing includes sample selection and sample reweighting. Sample selection aims to remove some bad samples that may lead to bad local optima. Sample reweighting aims to assign optimal weights to samples to improve performance. In this article, we integrate a sample selection method based on self-paced learning into deep learning frameworks and study the influence of different sample selection strategies on training deep networks. In addition, most of the existing sample reweighting methods mainly take per-class sample number as a metric, which does not fully consider sample qualities. To improve the performance, we propose a novel metric based on the multiview semantic encoders to reweight the samples more appropriately. Then, we propose an optimization mechanism to embed sample weights into loss functions of deep networks, which can be trained in end-to-end manners. We conduct experiments on the CIFAR data set and the ImageNet data set. The experimental results demonstrate that our proposed sample balancing method can improve the performances of deep learning methods in several visual recognition tasks.","","","10.1109/TNNLS.2019.2947789","National Natural Science Foundation of China; National Key Research and Development Plan of China; National Joint Engineering Research Center of Network Security Detection and Protection Technology; Guangdong Provincial Special Funds for Applied Technology Research and Development and Transformation of Important Scientific and Technological Achieve; Guangdong Key Laboratory of Data Security and Privacy Preserving; Science and Technology Project of Guangdong China; Project funded by the China Postdoctoral Science Foundation; Key Areas Research and Development Program of Guangdong; Key Scientific Research Program of Guangzhou; Natural Science Foundation of Guangdong; Special Funds for Science and Technology Development of Guangdong; National Key Research and Development Program of China; Science and Technology Program of Guangzhou of China; Guangdong Basic and Applied Basic Research Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8897722","Deep learning;image classification;sample reweighting;sample selection;self-paced learning.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Learning Based Code Smell Detection","H. Liu; J. Jin; Z. Xu; Y. Bu; Y. Zou; L. Zhang","Computer Science and Technology, Software Lab, Beijing, Beijing China 100081 (e-mail: liuhui2005@gmail.com); School of Computer Science and Technology, Beijing Institute of Technology, 47833 Beijing, Beijing China (e-mail: jinjiahao1993@gmail.com); School of Computer Science and Technology, Beijing Institute of Technology, 47833 Beijing, Beijing China (e-mail: 848602422@qq.com); School of Computer Science and Technology, Beijing Institute of Technology, 47833 Beijing, Beijing China (e-mail: yifan_bu@qq.com); Key Laboratory of High Confidence Software Technologies, Ministry of Education, Peking University, 12465 Beijing, Beijing China (e-mail: zouyz@pku.edu.cn); Electronics Engineering and Computer Science, Peking University, Beijing, Beijing China 100871 (e-mail: zhanglu@sei.pku.edu.cn)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Code smells are structures in the source code that suggest the possibility of refactorings. Consequently, developers may identify refactoring opportunities by detecting code smells. However, manual identification of code smells is challenging and tedious. To this end, a number of approaches have been proposed to identify code smells automatically or semi-automatically. Most of such approaches rely on manually designed heuristics to map manually selected source code metrics into predictions. However, it is challenging to manually select the best features. It is also difficult to manually construct the optimal heuristics. To this end, in this paper we propose a deep learning based novel approach to detecting code smells. The key insight is that deep neural networks and advanced deep learning techniques could automatically select features of source code for code smell detection, and could automatically build the complex mapping between such features and predictions. A big challenge for deep learning based smell detection is that deep learning often requires a large number of labeled training data (to tune a large number of parameters within the employed deep neural network) whereas existing datasets for code smell detection are rather small. To this end, we propose an automatic approach to generating labeled training data for the neural network based classifier, which does not require any human intervention. As an initial try, we apply the proposed approach to four common and well-known code smells, i.e., feature envy, long method, large class, and misplaced class. Evaluation results on open-source applications suggest that the proposed approach significantly improves the state-of-the-art.","","","10.1109/TSE.2019.2936376","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8807230","Software Refactoring;Code Smells;Identification;Deep Learning;Quality","Software;Deep learning;Feature extraction;Training data;Neural networks;Measurement","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Learning of Static and Dynamic Brain Functional Networks for Early MCI Detection","T. Kam; H. Zhang; Z. Jiao; D. Shen","Department of Radiology and BRIC, University of North Carolina at Chapel Hill, Chapel Hill, NC 27599 USA.; Department of Radiology and BRIC, University of North Carolina at Chapel Hill, Chapel Hill, NC 27599 USA.; Department of Radiology and BRIC, University of North Carolina at Chapel Hill, Chapel Hill, NC 27599 USA.; Department of Radiology and BRIC, University of North Carolina at Chapel Hill, Chapel Hill, NC 27599 USA, and also Department of Brain and Cognitive Engineering, Korea University, Seoul, 02841, Republic of Korea","IEEE Transactions on Medical Imaging","","2019","PP","99","1","1","While convolutional neural network (CNN) has been demonstrating powerful ability to learn hierarchical spatial features from medical images, it is still difficult to apply it directly to resting-state functional MRI (rs-fMRI) and the derived brain functional networks (BFNs). We propose a novel CNN framework to simultaneously learn embedded features from BFNs for brain disease diagnosis. Since BFNs can be built by considering both static and dynamic functional connectivity (FC), we first decompose rs-fMRI into multiple static BFNs with modified independent component analysis. Then, voxel-wise variability in dynamic FC is used to quantify BFN dynamics. A set of paired 3D images representing static/dynamic BFNs can be fed into 3D CNNs, from which we can hierarchically and simultaneously learn static/dynamic BFN features. As a result, dynamic BFN features can complement static BFN features and, at meantime, different BFNs can help each other towards a joint and better classification. We validate our method with a publicly accessible, large cohort of rs-fMRI dataset in early-stage mild cognitive impairment (eMCI) diagnosis, which is one of the most challenging problems to the clinicians. By comparing with a conventional method, our method shows significant diagnostic performance improvement by almost 10%. This result demonstrates the effectiveness of deep learning in preclinical Alzheimer’s disease diagnosis, based on the complex and high-dimensional voxel-wise spatiotemporal patterns of the resting-state brain functional connectomics. The framework provides a new but intuitive way to fully exploit deeply embedded diagnostic features from rs-fMRI for better individualized diagnosis of various neurological diseases.","","","10.1109/TMI.2019.2928790","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8765628","Diagnosis;Convolutional Neural Networks;Brain Network;Independent Component Analysis;Mild Cognitive Impairment;Deep Learning;Resting State;Functional MRI","Ions;Noise measurement;Manganese","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Multi-Objective Evolutionary Federated Learning","H. Zhu; Y. Jin","Department of Computer Science, University of Surrey, Guildford GU2 7XH, U.K..; Department of Computer Science, University of Surrey, Guildford GU2 7XH, U.K. (e-mail: hangyu.zhu@surrey.ac.uk).","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","13","Federated learning is an emerging technique used to prevent the leakage of private information. Unlike centralized learning that needs to collect data from users and store them collectively on a cloud server, federated learning makes it possible to learn a global model while the data are distributed on the users' devices. However, compared with the traditional centralized approach, the federated setting consumes considerable communication resources of the clients, which is indispensable for updating global models and prevents this technique from being widely used. In this paper, we aim to optimize the structure of the neural network models in federated learning using a multi-objective evolutionary algorithm to simultaneously minimize the communication costs and the global model test errors. A scalable method for encoding network connectivity is adapted to federated learning to enhance the efficiency in evolving deep neural networks. Experimental results on both multilayer perceptrons and convolutional neural networks indicate that the proposed optimization method is able to find optimized neural network models that can not only significantly reduce communication costs but also improve the learning performance of federated learning compared with the standard fully connected neural networks.","","","10.1109/TNNLS.2019.2919699","Royal Society Exchanges Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8744465","Communication cost;deep neural networks;federated learning;multi-objective evolutionary optimization;neural architecture search.","","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"A Deep One-Class Neural Network for Anomalous Event Detection in Complex Scenes","P. Wu; J. Liu; F. Shen","Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, Xidian University, Xi'an 710071, China.; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, Xidian University, Xi'an 710071, China (e-mail: neouma@163.com).; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, Xidian University, Xi'an 710071, China.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","14","How to build a generic deep one-class (DeepOC) model to solve one-class classification problems for anomaly detection, such as anomalous event detection in complex scenes? The characteristics of existing one-class labels lead to a dilemma: it is hard to directly use a multiple classifier based on deep neural networks to solve one-class classification problems. Therefore, in this article, we propose a novel DeepOC neural network, termed as DeepOC, which can simultaneously learn compact feature representations and train a DeepOC classifier. Only with the given normal samples, we use the stacked convolutional encoder to generate their low-dimensional high-level features and train a one-class classifier to make these features as compact as possible. Meanwhile, for the sake of the correct mapping relation and the feature representations' diversity, we utilize a decoder in order to reconstruct raw samples from these low-dimensional feature representations. This structure is gradually established using an adversarial mechanism during the training stage. This mechanism is the key to our model. It organically combines two seemingly contradictory components and allows them to take advantage of each other, thus making the model robust and effective. Unlike methods that use handcrafted features or those that are separated into two stages (extracting features and training classifiers), DeepOC is a one-stage model using reliable features that are automatically extracted by neural networks. Experiments on various benchmark data sets show that DeepOC is feasible and achieves the state-of-the-art anomaly detection results compared with a dozen existing methods.","","","10.1109/TNNLS.2019.2933554","General Program of National Natural Science Foundation of China NSFC; Key Program of Fundamental Research Project of Natural Science of Shaanxi Province China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8825555","Anomaly detection;deep one-class (DeepOC) classifier;learning representation;neural networks;video surveillance.","Anomaly detection;Feature extraction;Neural networks;Training;Event detection;Testing;Optical imaging","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Distribution-Free Probability Density Forecast Through Deep Neural Networks","T. Hu; Q. Guo; Z. Li; X. Shen; H. Sun","Shenzhen Environmental Science and New Energy Technology Engineering Laboratory, Tsinghua-Berkeley Shenzhen Institute (TBSI), Shenzhen 518055, China.; Shenzhen Environmental Science and New Energy Technology Engineering Laboratory, Tsinghua-Berkeley Shenzhen Institute (TBSI), Shenzhen 518055, China, and also with the Department of Electrical Engineering, State Key Laboratory of Power Systems, Tsinghua University, Beijing 100084, China.; Department of Electrical Engineering, Southern Methodist University, Dallas, TX 75205 USA.; Shenzhen Environmental Science and New Energy Technology Engineering Laboratory, Tsinghua-Berkeley Shenzhen Institute (TBSI), Shenzhen 518055, China.; Shenzhen Environmental Science and New Energy Technology Engineering Laboratory, Tsinghua-Berkeley Shenzhen Institute (TBSI), Shenzhen 518055, China, and also with the Department of Electrical Engineering, State Key Laboratory of Power Systems, Tsinghua University, Beijing 100084, China (e-mail: shb@tsinghua.edu.cn).","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","14","Probability density forecast offers the whole distributions of forecasting targets, which brings greater flexibility and practicability than the other probabilistic forecast models such as prediction interval (PI) and quantile forecast. However, existing density forecast models have introduced various constraints on forecasted distributions, which has limited their ability to approximate real distributions and may result in suboptimality. In this paper, a distribution-free density forecast model based on deep learning is proposed, in which the real cumulative density functions (CDFs) of forecasting target are approximated by a large-capacity positive-weighted deep neural network (NN). Benefiting from the universal approximation ability of NNs, the range of forecasted distributions has been proven to contain all the distributions with continuous CDFs, which is superior to existing models' considering both width and accordance with reality. Three tests from different scenarios were implemented for evaluation, i.e., very-short-term wind power, wind speed, and day-ahead electricity price forecast, in which the proposed density forecast model has shown superior performance over the state of the art.","","","10.1109/TNNLS.2019.2907305","Science Technology and Innovation Commission of Shenzhen Municipality; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8703389","Deep learning;monotone neural network (NN);NNs;probability density forecast.","Predictive models;Wind forecasting;Forecasting;Artificial neural networks;Probabilistic logic;Training;Adaptation models","","","","","","","","","","IEEE","IEEE Early Access Articles"
"DeepChain: Auditable and Privacy-Preserving Deep Learning with Blockchain-based Incentive","J. Weng; J. Weng; J. Zhang; M. Li; Y. Zhang; W. Luo","College of Information Science and Technology, Jinan University, 47885 Guangzhou, Guangdong China (e-mail: wengjiasi@gmail.com); Computer Science, Jinan University, 47885 Guangzhou, Guangdong China (e-mail: cryptjweng@gmail.com); College of Cyber Security, Jinan University, 47885 Guangzhou, Guangdong China 510632 (e-mail: jilian.z.2007@smu.edu.sg); College of Information Science and Technology, Jinan University, 47885 Guangzhou, Guangdong China (e-mail: limjnu@gmail.com); College of Information Science and Technology, Jinan University, 47885 Guangzhou, Guangdong China (e-mail: zyueinfosec@gmail.com); College of Information Science and Technology, Jinan University, 47885 Guangzhou, Guangdong China (e-mail: lwq@jnu.edu.cn)","IEEE Transactions on Dependable and Secure Computing","","2019","PP","99","1","1","Deep learning can achieve higher accuracy than traditional machine learning algorithms in a variety of machine learning tasks. Recently, privacy-preserving deep learning has drawn tremendous attention from information security community, in which neither training data nor the training model is expected to be exposed. Federated learning is a popular learning mechanism, where multiple parties upload local gradients to a server and the server updates model parameters with the collected gradients. However, there are many security problems neglected in federated learning, for example, the participants may behave incorrectly in gradient collecting or parameter updating, and the server may be malicious as well. In this paper, we present a distributed, secure, and fair deep learning framework named \textit{DeepChain} to solve these problems. DeepChain provides a value-driven incentive mechanism based on Blockchain to force the participants to behave correctly. Meanwhile, DeepChain guarantees data privacy for each participant and provides auditability for the whole training process. We implement a DeepChain prototype and conduct experiments on a real dataset for different settings, and the results show that our DeepChain is promising.","","","10.1109/TDSC.2019.2952332","National Natural Science Foundation of China; Guangdong Provincial Special Funds for Applied Technology Research and Development and Transformation of Important Scientific and Technological Achieve; National Key RD Program of China; National Key RD Plan of China; Guangdong Provincial Engineering Technology Research Center on Network Security Detection and Defence; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8894364","Deep learning;Privacy-preserving training;Blockchain;Incentive","Deep learning;Training;Servers;Blockchain;Collaboration;Training data;Data models","","","","2","","","","","","IEEE","IEEE Early Access Articles"
"Deep Reinforcement Learning for Image Hashing","Y. Peng; J. Zhang; Z. Ye","Wangxuan Institute of Computer Technology, Peking University, Beijing China (e-mail: pengyuxin@pku.edu.cn); Wangxuan Institute of Computer Technology, Peking University, Beijing, BeiJing China (e-mail: zhangjianmonk@gmail.com); Wangxuan Institute of Computer Technology, Peking University, Beijing, BeiJing China (e-mail: magicfisk@pku.edu.cn)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","Deep hashing methods have received much attention recently, which achieve promising results by taking advantage of the strong representation power of deep networks. However, most existing deep hashing methods learn a whole set of hashing functions independently, while ignore the correlations between different hashing functions that can promote the retrieval accuracy greatly. Inspired by the sequential decision ability of deep reinforcement learning, we propose a new Deep Reinforcement Learning approach for Image Hashing (DRLIH). Our proposed DRLIH approach models the hashing learning problem as a sequential decision process, which learns each hashing function by correcting the errors imposed by previous ones and promotes retrieval accuracy. To the best of our knowledge, this is the first work to address hashing problem from deep reinforcement learning perspective. The main contributions of our proposed DRLIH approach can be summarized as follows: (1) We propose a deep reinforcement learning hashing network. In the proposed network, we utilize recurrent neural network (RNN) as agents to model the hashing functions, which take actions of projecting images into binary codes sequentially, so that the current hashing function learning can take previous hashing functions' error into account. (2) We propose a sequential learning strategy based on proposed DRLIH. We define the state as a tuple of internal features of RNN's hidden layers and image features, which can reflect history decisions made by the agents. We also propose an action group method to enhance the correlation of hash functions in the same group. Experiments on three widely-used datasets demonstrate the effectiveness of our proposed DRLIH approach.","","","10.1109/TMM.2019.2951462","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8890894","Deep reinforcement learning;image hashing;image retrieval","Reinforcement learning;Binary codes;Image retrieval;Correlation;Learning systems;Optimization;Training","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Deep Learning Framework for Optimization of MISO Downlink Beamforming","W. Xia; G. Zheng; Y. Zhu; J. Zhang; J. Wang; A. P. Petropulu","Jiangsu Key Laboratory of Wireless Communications, Nanjing University of Posts and Telecommunications and Engineering Research Center of Health Service System Based on Ubiquitous Wireless Networks, Ministry of Education, Nanjing University of Posts and Telecommunications, Nanjing 210003, China.; Wolfson School of Mechanical, Electrical and Manufacturing Engineering, Loughborough University, Leicestershire, LE11 3TU, UK.; Division of Computer Science and Informatics, London South Bank University, London, SE1 0AA, UK.; Jiangsu Key Laboratory of Wireless Communications, Nanjing University of Posts and Telecommunications and Engineering Research Center of Health Service System Based on Ubiquitous Wireless Networks, Ministry of Education, Nanjing University of Posts and Telecommunications, Nanjing 210003, China.; School of Engineering and Digital Arts at the University of Kent, Kent, CT2 7NT, UK.; Department of Electrical & Computer Engineering Rutgers, The State University of New Jersey, Piscataway, NJ 08854.","IEEE Transactions on Communications","","2019","PP","99","1","1","Beamforming is an effective means to improve the quality of the received signals in multiuser multiple-input-singleoutput (MISO) systems. Traditionally, finding the optimal beamforming solution relies on iterative algorithms, which introduces high computational delay and is thus not suitable for realtime implementation. In this paper, we propose a deep learning framework for the optimization of downlink beamforming. In particular, the solution is obtained based on convolutional neural networks and exploitation of expert knowledge, such as the uplink-downlink duality and the known structure of optimal solutions. Using this framework, we construct three beamforming neural networks (BNNs) for three typical optimization problems, i.e., the signal-to-interference-plus-noise ratio (SINR) balancing problem, the power minimization problem, and the sum rate maximization problem. For the former two problems the BNNs adopt the supervised learning approach, while for the sum rate maximization problem a hybrid method of supervised and unsupervised learning is employed. Simulation results show that the BNNs can achieve near-optimal solutions to the SINR balancing and power minimization problems, and a performance close to that of the weighted minimum mean squared error algorithm for the sum rate maximization problem, while in all cases enjoy significantly reduced computational complexity. In summary, this work paves the way for fast realization of optimal beamforming in multiuser MISO systems.","","","10.1109/TCOMM.2019.2960361","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8935405","Deep learning;beamforming;MISO;beamforming neural network","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Method of Information Protection for Collaborative Deep Learning under GAN Model Attack","X. Yan; B. Cui; Y. Xu; P. Shi; Z. Wang","Beijing University of Posts and Telecommunications, 12472 Beijing, Beijing China (e-mail: xdyan@bupt.edu.cn); School of Computer Science, Beijing University of Posts and Telecommunications, Beijing, Beijing China (e-mail: cuibj@bupt.edu.cn); Central South University, 12570 Changsha, Hunan China 410083 (e-mail: xuyangcsu@gmail.com); Lenovo Beijing Ltd Bigdata Partment, Beijing, Beijing China (e-mail: noahstone@163.com); Beijing University of Posts and Telecommunications, Beijing, Beijing China (e-mail: wangziqi@bupt.edu.cn)","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2019","PP","99","1","1","Deep learning has recently gained more and more popularity, because of its high accuracy and wide range of coverage. In particular, deep learning is widely used in the medical field. Because in the field of image classification and biological applications, the accuracy of deep learning is very high. Unfortunately, even under the collaborative deep learning, there is still serious risk of information leakage. Moreover, the risk of information leakage in the medical field is greater and the harm is even greater. For example, medical treatment data may be leaked to third-party organizations. When these important medical data is illegally used by for-profit organizations or obtained by criminals, it will not only lead to the disclosure of personal privacy information, but also cause serious economic losses to the victims. However, the victim cannot delete the leaked information by itself or limit the scope and use of the information that has been leaked. Therefore, the adverse effects are unimaginable. This paper mainly studies the information protection methods under GAN model attack, in order to find a better way to prevent attacks and effectively protect information.","","","10.1109/TCBB.2019.2940583","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8827915","GAN;Collaborative deep learning;Security;Privacy","Deep learning;Generative adversarial networks;Training;Collaboration;Privacy;Biomedical imaging;Gallium nitride","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Review of Deep Learning Models for Time Series Prediction","Z. Han; J. Zhao; H. Leung; K. F. Ma; W. Wang","School of Control Sciences and Engineering, Dalian University of Technology, Dalian 116023, China.; School of Control Sciences and Engineering, Dalian University of Technology, Dalian 116023, China.; Department of Electrical and Computer Engineering, University of Calgary, Calgary, AB T2N 1N4, Canada.; Department of Electrical and Computer Engineering, University of Calgary, Calgary, AB T2N 1N4, Canada.; School of Control Sciences and Engineering, Dalian University of Technology, Dalian 116023, China.","IEEE Sensors Journal","","2019","PP","99","1","1","In order to approximate the underlying process of temporal data, time series prediction has been a hot research topic for decades. Developing predictive models plays an important role in interpreting complex real-world elements. With the sharp increase in the quantity and dimensionality of data, new challenges, such as extracting deep features, recognizing deep latent patterns have emerged, demanding novel approaches and effective solutions. Deep learning, composed of multiple processing layers to learn with multiple levels of abstraction, are now commonly deployed for overcoming the newly arisen difficulties. This paper reviews state-of-the-art developments in deep learning for time series prediction. Based on modeling for the perspective of conditional or joint probability, we categorize them into discriminative, generative and hybrids models. Experiments are implemented on both benchmarks and real-world data to elaborate the performance of representative deep learning-based prediction methods. Finally, we conclude with comments on possible future perspectives and ongoing challenges with time series prediction.","","","10.1109/JSEN.2019.2923982","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8742529","Review;Discriminative models;Generative models;Deep Learning;Time series prediction","Time series analysis;Predictive models;Deep learning;Biological system modeling;Support vector machines;Artificial neural networks;Data models","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Distributed Deep Learning Optimized System over the Cloud and Smart Phone Devices","H. Jiang; J. Starkman; Y. Lee; H. Chen; X. Qian; M. Huang","Electrical Engineering and Computer Science, Case Western Reserve University, Cleveland, Ohio United States (e-mail: hxj172@case.edu); Electrical Engineering and Computer Science, Case Western Reserve University Case School of Engineering, 142683 Cleveland, Ohio United States (e-mail: -1@case.edu); Computer Science, University of Colorado Boulder, Boulder, Colorado United States (e-mail: yuju.lee@colorado.edu); Electrical Engineering and Computer Science, Case Western Reserve University, Cleveland, Ohio United States (e-mail: hxc556@case.edu); Electrical Engineering and Computer Science, Case Western Reserve University, Cleveland, Ohio United States 44106 (e-mail: xxq82@case.edu); Electrical Engineering and Computer Science, Case Western Reserve University, Cleveland, Ohio United States 44106 (e-mail: ming-chun.huang@case.edu)","IEEE Transactions on Mobile Computing","","2019","PP","99","1","1","With deep learning techniques, researchers can discover deep properties and features of events from quantitative mobile sensor data. However, many data sources are geographically separated and have strict privacy, security, and regulatory constraints. Upon releasing the privacy-sensitive data, these data sources generally no longer physically possess their data and cannot interfere with the way their personal data being used. Therefore, it is necessary to explore distributed data mining architecture which is able to conduct consensus learning based on needs. Accordingly, we propose a distributed deep learning optimized system which contains a cloud server and multiple smartphone devices with computation capabilities and each device is served as a personal mobile data hub for enabling mobile computing while preserving data privacy. The proposed system keeps the private data locally in smartphones, shares trained parameters and builds a global consensus model. The feasibility and usability of the proposed system are evaluated by three experiments and related discussion. The experimental results show that the proposed distributed deep learning system can reconstruct the behavior of centralized training. We also measure the cumulative network traffic in different scenarios and show that the partial parameter sharing strategy does not only preserve the performance of the trained model but also can reduce network traffic.","","","10.1109/TMC.2019.2941492","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8839508","Mobile Computing;Distributed System;Deep Learning;Wearable Computers and Body Area Networks;Data Communication","Deep learning;Data models;Data mining;Distributed databases;Computational modeling;Computer architecture;Mobile handsets","","","","","","","","","","IEEE","IEEE Early Access Articles"
"iCELIA: A Full-Stack Framework for STT-MRAM-Based Deep Learning Acceleration","H. Yan; H. R. Cherian; E. C. Ahn; X. Qian; L. Duan","Electrical and Computer Engineering, University of Texas at San Antonio, San Antonio, Texas United States (e-mail: hao.yan@utsa.edu); Electrical and Computer Engineering, University of Texas at San Antonio, San Antonio, Texas United States (e-mail: hebin.cherian@utsa.edu); Electrical and Computer Engineering, University of Texas at San Antonio, San Antonio, Texas United States (e-mail: chiyui.ahn@utsa.edu); Ming Hsieh Department of Electrical Engineering, University of Southern California, Los Angeles, California United States (e-mail: xuehai.qian@usc.edu); Electrical and Computer Engineering, University of Texas at San Antonio, San Antonio, Texas United States 78249 (e-mail: lide.duan@gmail.com)","IEEE Transactions on Parallel and Distributed Systems","","2019","PP","99","1","1","A large variety of applications rely on deep learning to process big data, learn sophisticated features, and perform complicated tasks. Utilizing emerging non-volatile memory (NVM)s unique characteristics, including the crossbar array structure and gray-scale cell resistances, to perform neural network (NN) computation is a well-studied approach in accelerating deep learning applications. Compared to other NVM technologies, STT-MRAM has its unique advantages in performing NN computation. However, the state-of-the-art research have not utilized STT-MRAM for deep learning acceleration due to its device- and architecture-level challenges. Consequently, this paper enables STT-MRAM, for the firs time, as an effective and practical deep learning accelerator. In particular, it proposes a full-stack framework iCELIA spanning multiple design levels, including device-level fabrication, circuit-level enhancements, architecture-level synaptic weight quantization, and system-level accelerator design. The primary contributions of iCELIA over our prior work CELIA include a new non-uniform weight quantization scheme and much enhanced accelerator system design. The proposed framework significantly mitigates the model accuracy loss due to reduced data precision in a cohesive manner, constructing a comprehensive STT-MRAM accelerator system for fast NN computation with high energy efficiency and low cost.","","","10.1109/TPDS.2019.2937517","University of Texas at San Antonio; University of Texas System; Division of Computing and Communication Foundations; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812913","STT-MRAM;deep learning acceleration;processing-in-memory;device and architecture co-design","Deep learning;Nonvolatile memory;Computer architecture;Acceleration;Artificial neural networks;Resistance;Microprocessors","","","","","","","","","","IEEE","IEEE Early Access Articles"
"DeepPAR and DeepDPA: Privacy-Preserving and Asynchronous Deep Learning for Industrial IoT","X. Zhang; X. Chen; J. Liu; Y. Xiang","State Key Laboratory of Integrated Service Networks (ISN), Xidian University, Xi’an, 710071, Shaaixi and the State Key Laboratory of Cryptology, PO Box 5159, Beijing 100878, China (e-mail: moliyanyan@163.com); State Key Laboratory of Integrated Service Networks (ISN), Xidian University, Xi’an, 710071, Shaaixi and the State Key Laboratory of Cryptology, PO Box 5159, Beijing 100878, China (e-mail: xfchen@xidian.edu.cn); Faculty of Information Technology, Monash University, Melbourne, VIC 3800, Australia (e-mail: joseph.liu@monash.edu); School of Software and Electrical Engineering, Swinburne University of Technology, Hawthorn, VIC 3122, Australia (e-mail: yxiang@swin.edu.au)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","Industrial IoT (IIoT) is significant of building powerful industrial systems and applications. Deep learning has provided a promising opportunity to extract useful knowledge by utilizing vast amounts of data in IIoT. However, lacking of massive public datasets will lead to low performance and overfitting of the learned model. Therefore, the federated deep learning over distributed datasets has been proposed. Whereas, it inevitably introduces some new security challenges, i.e., disclosing participant's data privacy. However, existing methods can not guarantee each participant's data privacy in a learning group. In this paper, we propose two privacy-preserving asynchronous deep learning schemes (DeepPAR and DeepDPA). Compared to the state-of-the-art work, DeepPAR protects each participant's input privacy while preserving dynamic update secrecy inherently. Meanwhile, DeepDPA enables to guarantee backward secrecy of group participants in a lightweight manner. Security analysis and performance evaluations on real dataset show that our proposed schemes are secure, efficient and effective.","","","10.1109/TII.2019.2941244","National Cryptography Development Fund; China 111 Project; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8836609","Privacy protection;asynchronous deep learning;proxy re-encryption;key management","Deep learning;Encryption;Data privacy;Privacy;Training","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Travel Mode Identification With GPS Trajectories Using Wavelet Transform and Deep Learning","J. J. Q. Yu","Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen 518055, China (e-mail: yujq3@sustech.edu.cn).","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","11","Accurate identification in public travel modes is an essential task in intelligent transportation systems. In recent years, GPS-based identification is gradually replacing the conventional survey-based information-gathering process due to the more detailed and precise data on individual's travel patterns. Nonetheless, existing research suffers from deficient feature selection, high data dimensionality, and data under-utilization issues. In this work, we propose a novel travel mode identification mechanism based on discrete wavelet transform and recent developments of deep learning techniques. The proposed mechanism aims to take GPS trajectories of arbitrary lengths to develop accurate travel mode results in both global and online identification scenarios. In this mechanism, raw GPS data is first pre-processed to compute preliminary motion and displacement attributes, which are input into a tailor-made deep neural network. Discrete wavelet transform is also adopted to further extract time-frequency domain characteristics of the trajectories to assist the neural network in the classification task. To evaluate the performance of the proposed mechanism, a series of comprehensive case studies are conducted. The results indicate that the mechanism can notably outperform existing travel mode identifications on a same data set with minuscule computation time. Furthermore, an architecture test is performed to determine the best-performing structure for the proposed mechanism. Lastly, we demonstrate the capability of the mechanism in handling online identifications, and the performance sensitivity of the selected attributes is evaluated.","","","10.1109/TITS.2019.2962741","General Program of Guangdong Basic and Applied Basic Research Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8947978","Travel mode identification;GPS trajectory;discrete wavelet transform;deep learning;feature selection.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Reinforcement Learning for Online Computation Offloading in Wireless Powered Mobile-Edge Computing Networks","L. Huang; S. Bi; Y. J. Zhang","College of Information Engineering, Zhejiang University of Technology, 12624 Hangzhou, Zhejiang China (e-mail: lianghuang@zjut.edu.cn); College of Information Engineering, Shenzhen University, 47890 Shenzhen, Guangdong China (e-mail: bsz@szu.edu.cn); Information Engineering, The Chinese University of Hong Kong, Hong Kong, Shatin Hong Kong (e-mail: yjzhang@ie.cuhk.edu.hk)","IEEE Transactions on Mobile Computing","","2019","PP","99","1","1","Wireless powered mobile-edge computing (MEC) has recently emerged as a promising paradigm to enhance the data processing capability of low-power networks, such as wireless sensor networks and internet of things (IoT). In this paper, we consider a wireless powered MEC network that adopts a binary offloading policy, so that each computation task of wireless devices (WDs) is either executed locally or fully offloaded to an MEC server. Our goal is to acquire an online algorithm that optimally adapts task offloading decisions and wireless resource allocations to the time-varying wireless channel conditions. This requires quickly solving hard combinatorial optimization problems within the channel coherence time, which is hardly achievable with conventional numerical optimization methods. To tackle this problem, we propose a Deep Reinforcement learning-based Online Offloading (DROO) framework that implements a deep neural network as a scalable solution that learns the binary offloading decisions from the experience. It eliminates the need of solving combinatorial optimization problems, and thus greatly reduces the computational complexity especially in large-size networks. To further reduce the complexity, we propose an adaptive procedure that automatically adjusts the parameters of the DROO algorithm on the fly. Numerical results show that the proposed algorithm can achieve near-optimal performance while significantly decreasing the computation time by more than an order of magnitude compared with existing optimization methods. For example, the CPU execution latency of DROO is less than 0.1 second in a 30-user network, making real-time and optimal offloading truly viable even in a fast fading environment.","","","10.1109/TMC.2019.2928811","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8771176","Mobile-edge computing;wireless power transfer;reinforcement learning;resource allocation","Wireless communication;Task analysis;Wireless sensor networks;Resource management;Fading channels;Computational complexity;Reinforcement learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Reinforcement Learning Based Mode Selection and Resource Allocation for Cellular V2X Communications","X. Zhang; M. Peng; S. Yan; Y. Sun","State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing 100876, China.; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing 100876, China.; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing 100876, China.; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing 100876, China.","IEEE Internet of Things Journal","","2019","PP","99","1","1","Cellular vehicle-to-everything (V2X) communication is crucial to support future diverse vehicular applications. However, for safety-critical applications, unstable vehicle-to-vehicle (V2V) links and high signalling overhead of centralized resource allocation approaches become bottlenecks. In this paper, we investigate a joint optimization problem of transmission mode selection and resource allocation for cellular V2X communications. In particular, the problem is formulated as a Markov decision process, and a deep reinforcement learning (DRL) based decentralized algorithm is proposed to maximize the sum capacity of vehicle-to-infrastructure users while meeting the latency and reliability requirements of V2V pairs. Moreover, considering training limitation of local DRL models, a two-timescale federated DRL algorithm is developed to help obtain robust model. Wherein, the graph theory based vehicle clustering algorithm is executed on a large timescale and in turn the federated learning algorithm is conducted on a small timescale. Simulation results show that the proposed DRL-based algorithm outperforms other decentralized baselines, and validate the superiority of the two-timescale federated DRL algorithm for newly activated V2V pairs.","","","10.1109/JIOT.2019.2962715","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8944302","Mode selection;resource allocation;cellular vehicle-to-everything;deep reinforcement learning.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Free Market of Multi-Leader Multi-Follower Mobile Crowdsensing: An Incentive Mechanism Design by Deep Reinforcement Learning","Y. Zhan; C. H. Liu; Y. Zhao; J. Zhang; J. Tang","School of Computer Science and Technology, Beijing Institute of Technology, 47833 Beijing, Beijing China (e-mail: zhanyf1989@gmail.com); School of Computer Science and Technology, Beijing Institute of Technology, 47833 Beijing, Beijing China (e-mail: liuchi02@gmail.com); School of Computer Science and Technology, Beijing Institute of Technology, 47833 Beijing, Beijing China (e-mail: 769572294@qq.com); School of Computer Science and Technology, Beijing Institute of Technology, 47833 Beijing, Beijing China (e-mail: bitzj2015@outlook.com); Computer Science, Montana State University, Montana, Montana United States 59717-3880 (e-mail: jtang02@syr.edu)","IEEE Transactions on Mobile Computing","","2019","PP","99","1","1","The explosive increase of mobile devices with built-in sensors such as GPS, accelerometer, gyroscope and camera has made the design of mobile crowdsensing (MCS) applications possible, which create a new interface between humans and their surroundings. Until now, various MCS applications have been designed, where the task initiators (TIs) recruit mobile users (MUs) to complete the required sensing tasks. In this paper, deep reinforcement learning (DRL) based techniques are investigated to address the problem of assigning satisfactory but profitable amount of incentives to multiple TIs and MUs as a MCS game. Specifically, we first formulate the problem as a multi-leader and multi-follower Stackelberg game, where TIs are the leaders and MUs are the followers. Then, the existence of the Stackelberg Equilibrium (SE) is proved. Considering the challenge to compute the SE, a DRL based Dynamic Incentive Mechanism (DDIM) is proposed. It enables the TIs to learn the optimal pricing strategies directly from game experiences without knowing the private information of MUs. Finally, numerical experiments are provided to illustrate the effectiveness of the proposed incentive mechanism compared with both state-of-the-art and baseline approaches.","","","10.1109/TMC.2019.2927314","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8758205","Incentive mechanism;Multi-leader multi-follower mobile crowdsensing;Stackelberg Equilibrium;Deep reinforcement learning","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Learning Based Channel Estimation Algorithm for Fast Time-Varying MIMO-OFDM Systems","Y. Liao; Y. Hua; Y. Cai","Center of Communication and TT&C, Chongqing University, Chongqing 400044, China.; Center of Communication and TT&C, Chongqing University, Chongqing 400044, China.; Department of Information Science and Electronic Engineering, Zhejiang University, Hangzhou 310027, China.","IEEE Communications Letters","","2019","PP","99","1","1","Channel estimation is very challenging for multiple-input and multiple-output orthogonal frequency division multiplexing (MIMO-OFDM) systems in high mobility environments with non-stationarity channel characteristics. In order to handle this problem, we propose a deep learning (DL)-based MIMO-OFDM channel estimation algorithm. By performing offline training to the learning network, the channel state information (CSI) generated by the training samples can be effectively utilized to adapt the characteristics of fast time-varying channels in the high mobility scenarios. The simulation results show that the proposed DL-based algorithm is more robust for the scenarios of high mobility in MIMO-OFDM systems, compared to the conventional algorithms.","","","10.1109/LCOMM.2019.2960242","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933411","MIMO-OFDM;channel estimation;fast time-varying channel;deep learning;non-stationarity channel","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Distributed Deep Learning System for Web Attack Detection on Edge Devices","Z. Tian; C. Luo; J. Qiu; X. Du; M. Guizani","Guangzhou China 510006 (e-mail: tianzhihong@gzhu.edu.cn); Institute of Computer Application, China Academy of Engineer Physics, Mianyang China 621000 (e-mail: luochaochaoforaffair@gmail.com); Cyberspace Institute of Advanced Technology, Guangzhou China 510006 (e-mail: qiujing.ch@gmail.com); Department of Computer and Information Sciences, Temple University, Philadelphia, Pennsylvania United States 19122 (e-mail: dxj@ieee.org); Dept. of Computer Science and Engineering, Qatar University, 61780 Doha, Ad Dawhah Qatar 2713 (e-mail: mguizani@gmail.com)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","With the development of Internet of Things (IoT) and cloud technologies, numerous IoT devices and sensors transmit huge amounts of data to cloud data centers for further processing. While providing us considerable convenience, cloud-based computing and storage also bring us many security problems, such as the abuse of information collection and concentrated web servers in the cloud. Traditional intrusion detection systems (IDS) and web application firewalls (WAF) are becoming incompatible with the new network environment, and related systems with machine learning or deep learning are emerging. However, cloud-IoT systems increase attacks against web servers, since data centralization carries a more attractive reward. In this paper, based on distributed deep learning, we propose a web attack detection system that takes advantage of analyzing URLs. The system is designed to detect web attacks and is deployed on edge devices. The cloud handles the above challenges in the paradigm of the Edge of Things (EoT). Multiple concurrent deep models are used to enhance the stability of the system and the convenience in updating. We implemented experiments on the system with two concurrent deep models and compared the system with existing systems by using several datasets. The experimental results with 99.410% in accuracy, 98.91% in TPR and 99.55% in DRN demonstrate the system is competitive in detecting web attacks.","","","10.1109/TII.2019.2938778","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8821336","Distributed Deep Learning;Distributed System;Edge of Things;Web Attack Detection","Deep learning;Feature extraction;Image edge detection;Computer hacking;Cloud computing;Internet of Things;Uniform resource locators","","","","3","","","","","","IEEE","IEEE Early Access Articles"
"Relaxed Asymmetric Deep Hashing Learning: Point-to-Angle Matching","J. Li; B. Zhang; G. Lu; J. You; Y. Xu; F. Wu; D. Zhang","School of Science and Engineering, The Chinese University of Hong Kong (Shenzhen), Shenzhen 518172, China, and the University of Science and Technology of China, Hefei 230000, China.; Department of Computer and Information Science, University of Macau, Macau 999078, China.; Department of Computer Science, Harbin Institute of Technology Shenzhen Graduate School, Shenzhen 518000, China.; Department of Computing, The Hong Kong Polytechnic University, Hong Kong.; Department of Computer Science, Harbin Institute of Technology Shenzhen Graduate School, Shenzhen 518000, China.; CAS Key Laboratory of Technology in Geo-Spatial Information Processing and Application System, University of Science and Technology of China, Hefei 230000, China.; School of Science and Engineering, The Chinese University of Hong Kong (Shenzhen), Shenzhen 518172, China (e-mail: davidzhang@cuhk.edu.cn).","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","15","Due to the powerful capability of the data representation, deep learning has achieved a remarkable performance in supervised hash function learning. However, most of the existing hashing methods focus on point-to-point matching that is too strict and unnecessary. In this article, we propose a novel deep supervised hashing method by relaxing the matching between each pair of instances to a point-to-angle way. Specifically, an inner product is introduced to asymmetrically measure the similarity and dissimilarity between the real-valued output and the binary code. Different from existing methods that strictly enforce each element in the real-valued output to be either +1 or -1, we only encourage the output to be close to its corresponding semantic-related binary code under the cross-angle. This asymmetric product not only projects both the real-valued output and the binary code into the same Hamming space but also relaxes the output with wider choices. To further exploit the semantic affinity, we propose a novel Hamming-distance-based triplet loss, efficiently making a ranking for the positive and negative pairs. An algorithm is then designed to alternatively achieve optimal deep features and binary codes. Experiments on four real-world data sets demonstrate the effectiveness and superiority of our approach to the state of the art.","","","10.1109/TNNLS.2019.2958061","China Postdoctoral Science Foundation; NSFC fund; Shenzhen Municipal Science and Technology Innovation Council; Shenzhen Fundamental Research fund; Medical Biometrics Perception and Analysis Engineering Laboratory Shenzhen; Shenzhen Research Institute of Big Data Shenzhen Institute of Artificial Intelligence and Robotics for Society; Fundamental Research Funds for the Central Universities; Scientific Reserve Talent Programs of Chongqing University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8946869","Asymmetric;deep learning;hashing learning;point-to-angle;triplet loss.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Cytokeratin-supervised deep learning for automatic recognition of epithelial cells in breast cancers stained for ER, PR, and Ki-67","M. Valkonen; J. Isola; J. Isola; O. Ylinen; V. Muhonen; A. Saxlin; T. Tolonen; M. Nykter; P. Ruusuvuori","Faculty of Medicine and Health Technology, Tampere University, Finland.; Faculty of Medicine and Health Technology, Tampere University, Finland.; Shareholder and CEO of Jilab Inc. O. Ylinen and V. Muhonen are part-time employees of Jilab Inc.; Faculty of Medicine and Health Technology, Tampere University, Finland.; NA; Department of Pathology, Fimlab Laboratories, Tampere University Hospital, Tampere, Finland.; Department of Pathology, Fimlab Laboratories, Tampere University Hospital, Tampere, Finland.; Faculty of Medicine and Health Technology, Tampere University, Finland.; Faculty of Medicine and Health Technology, Tampere University, Finland.","IEEE Transactions on Medical Imaging","","2019","PP","99","1","1","Immunohistochemistry (IHC) of ER, PR, and Ki-67 are routinely used assays in breast cancer diagnostics. Determination of the proportion of stained cells (labeling index) should be restricted on malignant epithelial cells, carefully avoiding tumor infiltrating stroma and inflammatory cells. Here, we developed a deep learning based digital mask for automated epithelial cell detection using fluoro-chromogenic cytokeratin-Ki-67 double staining and sequential hematoxylin-IHC staining as training material. A partially pre-trained deep convolutional neural network was fine-tuned using image batches from 152 patient samples of invasive breast tumors. Validity of the trained digital epithelial cell masks was studied with 366 images captured from 98 unseen samples, by comparing the epithelial cell masks to cytokeratin images and by visual evaluation of the brightfield images performed by two pathologists. A good discrimination of epithelial cells was achieved (AUC of mean ROC = 0.93; defined as the area under mean receiver operating characteristics), and well in concordance with pathologists’ visual assessment (4.01/5 and 4.67/5). The effect of epithelial cell masking on the Ki-67 labeling index was substantial. 52 tumor images initially classified as low proliferation (Ki-67<14%) without epithelial cell masking were re-classified as high proliferation (Ki-67≥14%) after applying the deep learning based epithelial cell mask. The digital epithelial cell masks were found applicable also to IHC of ER and PR. We conclude that deep learning can be applied to detect carcinoma cells in breast cancer samples stained with conventional brightfield IHC.","","","10.1109/TMI.2019.2933656","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8790728","Deep learning;image segmentation;breast cancer;histopathology;digital pathology","Training;Deep learning;Breast cancer;Tumors;Immune system;Indexes;Convolutional neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Learning-Based Gleason Grading of Prostate Cancer from Histopathology Images - Role of Multiscale Decision Aggregation and Data Augmentation","D. Karimi; G. Nir; L. Fazli; P. C. Black; L. Goldenberg; S. E. Salcudean","Electrical and Computer Engineering, University of British Columbia, 8166 Vancouver, British Columbia Canada V6T 1Z4 (e-mail: karimi@ece.ubc.ca); Urologic Sciences, University of British Columbia, Vancouver, British Columbia Canada V6T 1Z4 (e-mail: guynir@ece.ubc.ca); Vancouver Prostate Centre, 483154 Vancouver, British Columbia Canada (e-mail: lfazli@prostatecentre.com); Department of Urologic Sciences, University of British Columbia, 8166 Vancouver, British Columbia Canada (e-mail: pblack@mail.ubc.ca); University of British Columbia, 8166 Vancouver, British Columbia Canada (e-mail: goldenb@icloud.com); ECE, University of British Columbia, Vancouver, British Columbia Canada V6R1K3 (e-mail: tims@ece.ubc.ca)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","Visual inspection of histopathology images of stained biopsy tissue by expert pathologists is the standard method for grading of prostate cancer (PCa). However, this process is time-consuming and subject to high inter-observer variability. Machine learning-based methods have the potential to improve efficient throughput of large volumes of slides while decreasing variability, but they are not easy to develop because they require substantial amounts of labeled training data. In this paper, we propose a deep learning-based classification technique and data augmentation methods for accurate grading of PCa in histopathology images in the presence of limited data. Our method combines the predictions of three separate convolutional neural networks (CNNs) that work with different patch sizes. This enables our method to take advantage of the greater amount of contextual information in larger patches as well as greater quantity of smaller patches in the labeled training data. The predictions produced by the three CNNs are combined using a logistic regression model, which is trained separately after the CNN training. To effectively train our models, we propose new data augmentation methods and empirically study their effects on the classification accuracy. The proposed method achieves an accuracy of 92 % in classifying cancerous patches versus benign patches and an accuracy of 90 % in classifying low-grade (i.e., Gleason grade 3) from high-grade (i.e., Gleason grades 4 and 5) patches. The agreement level of our automatic grading method with expert pathologists is within the range of agreement between pathologists. Our experiments indicate that data augmentation is necessary for achieving expert-level performance with deep learning-based methods. A combination of image-space augmentation and feature-space augmentation leads to the best results. Our study shows that well-designed and properly trained deep learning models can achieve PCa Gleason grading accuracy that is comparable to an expert pathologist.","","","10.1109/JBHI.2019.2944643","Canadian Institutes of Health Research; Prostate Cancer Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8853320","prostate cancer;Gleason grading;histopathology;deep learning","Deep learning;Training data;Training;Glands;Biomedical imaging;Informatics;Principal component analysis","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Predicting DNA methylation states with hybrid information based deep-learning model","L. Fu; Q. Peng; L. Chai","Xian Jiaotong university, Systems engineering institute, Xian, Shanxi China (e-mail: sperfu@stu.xjtu.edu.cn); Xian Jiaotong university, Systems engineering institute, Xian, Shanxi China (e-mail: qkpeng@mail.xjtu.edu.cn); Xian Jiaotong university, Systems engineering institute, Xian, Shanxi China (e-mail: chailing@stu.xjtu.edu.cn)","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2019","PP","99","1","1","DNA methylation plays an important role in the regulation of some biological processes. Up to now, with the development of machine learning models, there are several sequence-based deep learning models designed to predict DNA methylation states, which gain better performance than traditional methods like random forest and SVM. However, convolutional network based deep learning models that use one-hot encoding DNA sequence as input may discover limited information and cause unsatisfactory prediction performance, so more data and model structures of diverse angles should be considered. In this work, we proposed a hybrid sequence-based deep learning model with both MeDIP-seq data and Histone information to predict DNA methylated CpG states (MHCpG). We combined both MeDIP-seq data and histone modification data with sequence information and implemented convolutional network to discover sequence patterns. In addition, we used statistical data gained from previous three input data and adopted a 3-layer feedforword neuron network to extract more high-level features. We compared our method with traditional predicting methods using random forest and other previous methods like CpGenie and DeepCpG, the result showed that MHCpG exceeded the other approaches and gained more satisfactory performance.","","","10.1109/TCBB.2019.2909237","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8681141","DNA methylation;deep learning;hybrid structure;histone modification;MeDIP-seq","DNA;Convolution;Deep learning;Bioinformatics;Genomics;Predictive models;Feature extraction","","","","","","","","","","IEEE","IEEE Early Access Articles"
"EdgeAI: A Vision for Deep Learning in IoT Era","K. Bhardwaj; N. Suda; R. Marculescu","Arm, Inc., San Jose, USA, 95134.; Arm, Inc., San Jose, USA, 95134.; Electrical and Computer Engineering Department, Carnegie Mellon University, Pittsburgh, USA, 15213.","IEEE Design & Test","","2019","PP","99","1","1","The significant computational requirements of deep learning present a major bottleneck for its large-scale adoption on hardware-constrained IoT-devices. Here, we envision a new paradigm called EdgeAI to address major impediments associated with deploying deep networks at the edge. Specifically, we discuss the existing directions in computation-aware deep learning and describe two new challenges in the IoT era: (1) Data-independent deployment of learning, and (2) Communication-aware distributed inference. We further present new directions from our recent research to alleviate the latter two challenges. Overcoming these challenges is crucial for rapid adoption of learning on IoT-devices in order to truly enable EdgeAI.","","","10.1109/MDAT.2019.2952350","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8894495","EdgeAI;Deep Networks;Knowledge Distillation;Learning from Small Data","Computational modeling;Deep learning;Metadata;Image coding;Hardware;Knowledge engineering","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Utilizing Deep Learning Towards Multi-modal Bio-sensing and Vision-based Affective Computing","S. Siddharth; T. Jung; T. J. Sejnowski","Electrical and Computer Engineering, University of California San Diego, La Jolla, California United States (e-mail: ssiddhar@eng.ucsd.edu); Institute for Neural Computation, University of California, San Diego, La Jolla, California United States (e-mail: jung@sccn.ucsd.edu); Institute for Neural Computation, University of California, San Diego, San Diego, California United States (e-mail: terry@salk.edu)","IEEE Transactions on Affective Computing","","2019","PP","99","1","1","In recent years, the use of bio-sensing signals such as electroencephalogram (EEG), electrocardiogram (ECG) etc. have garnered interest towards applications in affective computing. The parallel trend of deep learning has led to a huge leap in performance towards solving various vision-based research problems such as object detection. Yet, these advances in deep learning have not adequately translated into bio-sensing research. This work applies novel deep-learning-based methods to various bio-sensing and video data of four publicly available multi-modal emotion datasets. For each dataset, we first individually evaluate the emotion-classification performance obtained by each modality. We then evaluate the performance obtained by fusing the features from these modalities. We show that our algorithms outperform the results reported by other studies for emotion/valence/arousal/liking classification on DEAP and MAHNOB-HCI datasets and set up benchmarks for the newer AMIGOS and DREAMER datasets. We also evaluate the performance of our algorithms by combining the datasets and by using transfer learning to show that the proposed method overcomes the inconsistencies between the datasets. Hence, we do a thorough analysis on multi-modal affective data from more than 120 subjects and 2,800 trials. Finally, utilizing a convolution-deconvolution network, we propose a new technique towards identifying salient brain regions corresponding to various affective states.","","","10.1109/TAFFC.2019.2916015","University of California, San Diego; National Science Foundation; Army Research Laboratory; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8713896","Brain-Computer Interface (BCI);EEG;Multimodality;Bio-sensing;ECG;GSR;PPG;Computer Vision;Deep Learning;Emotion Processing","Electroencephalography;Electrocardiography;Feature extraction;Deep learning;Affective computing;Face;Support vector machines","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Low-Complexity Deep-Learning-Based DOA Estimation for Hybrid Massive MIMO Systems with Uniform Circular Arrays","D. Hu; Y. Zhang; L. He; J. Wu","Key Laboratory of EMW Information, Fudan University, Shanghai 200433, China.; Key Laboratory of EMW Information, Fudan University, Shanghai 200433, China.; Department of Computer Science and Technology, Tongji University, Shanghai 201804, China.; Department of Computer Science and Technology, Tongji University, Shanghai 201804, China.","IEEE Wireless Communications Letters","","2019","PP","99","1","1","This letter proposes a low-complexity deep-learning-based direction-of-arrival (DOA) estimation method for a hybrid massive multiple-input multiple-output (MIMO) system with a uniform circular array at the base station. In the proposed method, we first input the received signal vector into some small deep feedforward networks that are trained offline. Based on the outputs of the networks, we then generate a set of candidate angles. By selecting the optimal one from all candidate angles, we finally obtain the DOA estimation. Simulation results demonstrate that, compared with the conventional maximum likelihood (ML) method, the proposed DOA estimation method can achieve similar or even better performance with much less complexity.","","","10.1109/LWC.2019.2942595","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8845653","Massive MIMO;deep learning;uniform circular array;hybrid beamforming;DOA estimation.","Direction-of-arrival estimation;Radio frequency;Complexity theory;Maximum likelihood estimation;Array signal processing","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Deep Learning-based Limited Feedback Designs for MIMO Systems","J. Jang; H. Lee; S. Hwang; H. Ren; I. Lee","School of Electrical Engineering, Korea University, Seoul, Korea.; Department of Information and Communications Engineering, Pukyong National University, Busan, Korea.; School of Electrical Engineering, Korea University, Seoul, Korea.; Huawei Technologies, Shanghai, China.; School of Electrical Engineering, Korea University, Seoul, Korea.","IEEE Wireless Communications Letters","","2019","PP","99","1","1","We study a deep learning (DL) based limited feedback methods for multi-antenna systems. Deep neural networks (DNNs) are introduced to replace an end-to-end limited feedback procedure including pilot-aided channel training process, channel codebook design, and beamforming vector selection. The DNNs are trained to yield binary feedback information as well as an efficient beamforming vector which maximizes the effective channel gain. Compared to conventional limited feedback schemes, the proposed DL method shows an 1 dB symbol error rate (SER) gain with reduced computational complexity.","","","10.1109/LWC.2019.2962114","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8941111","MIMO;deep learning;limited feedback.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Active Deep Decoding of Linear Codes Ishay Be’ery, Nir Raviv, Tomer Raviv, Yair B’eery","I. Be’ery; N. Raviv; T. Raviv; Y. B’ery","School of Electrical Engineering, Tel-Aviv University, Tel-Aviv 6997801, Israel.; School of Electrical Engineering, Tel-Aviv University, Tel-Aviv 6997801, Israel.; School of Electrical Engineering, Tel-Aviv University, Tel-Aviv 6997801, Israel.; School of Electrical Engineering, Tel-Aviv University, Tel-Aviv 6997801, Israel.","IEEE Transactions on Communications","","2019","PP","99","1","1","High quality data is essential in deep learning to train a robust model. While in other fields data is sparse and costly to collect, in error decoding it is free to query and label thus allowing potential data exploitation. Utilizing this fact and inspired by active learning, two novel methods are introduced to improve Weighted Belief Propagation (WBP) decoding. These methods incorporate machine-learning concepts with error decoding measures. For BCH(63,36), (63,45) and (127,64) codes, with cycle-reduced parity-check matrices, improvement of up to 0.4dB at the waterfall region, and of up to 1.5dB at the errorfloor region in FER, over the original WBP, is demonstrated by smartly sampling the data, without increasing inference (decoding) complexity. The proposed methods constitutes an example guidelines for model enhancement by incorporation of domain knowledge from error-correcting field into a deep learning model. These guidelines can be adapted to any other deep learning based communication block.","","","10.1109/TCOMM.2019.2955724","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8911465","Deep Learning;Error Correcting Codes;Machine Learning;Active Learning;Belief Propagation","Decoding;Training;Signal to noise ratio;Artificial neural networks;Deep learning;Belief propagation;Complexity theory","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Pay Attention to Them: Deep Reinforcement Learning-Based Cascade Object Detection","S. Liu; D. Huang; Y. Wang","Beijing Advanced Innovation Center for Big Data and Brain Computing, State Key Laboratory of Software Development Environment, School of Computer Science and Engineering, Beihang University, Beijing 100191, China.; Beijing Advanced Innovation Center for Big Data and Brain Computing, State Key Laboratory of Software Development Environment, School of Computer Science and Engineering, Beihang University, Beijing 100191, China (e-mail: dhuang@buaa.edu.cn).; Beijing Advanced Innovation Center for Big Data and Brain Computing, School of Computer Science and Engineering, Beihang University, Beijing 100191, China.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","13","This paper proposes a novel and effective approach, namely pay attention to them (PAT), to general object detection, which integrates the bottom-up single-shot convolutional neural networks (CNNs) and a top-down operating strategy. PAT starts by routinely applying a CNN regression detector to the entire input image. It then conducts refinement, which locates a sub-region that probably contains relevant objects through an intelligent agent built with an attentional mechanism and zooms it in to launch the detector again. This refining step is repeated in a cascaded way, where all the bounding boxes produced are scaled according to the original resolution and the sub-marginal and overlapping parts are wiped out to generate the final output. Due to such progressive processing, PAT improves the detection accuracy, especially for the objects of small sizes. Extensive experiments are conducted on the Pascal VOC and MS COCO benchmarks, and the results show that PAT is able to improve the representative baseline detectors, i.e., single shot multibox detector, YOLOv2, and Faster regions with CNN features, with remarkable accuracy gains [about 2%-5% mean Average Precision (mAP)], which demonstrates its competency.","","","10.1109/TNNLS.2019.2933451","National Key Research and Development Plan; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8822635","Attention;convolutional neural network (CNN);object detection;reinforcement learning (RL).","Feature extraction;Detectors;Object detection;Proposals;Image resolution;Intelligent agents;Benchmark testing","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Fast Enhanced CT Metal Artifact Reduction using Data Domain Deep Learning","M. U. Ghani; W. C. Karl","Electrical and Computer Engineering, Boston University, 1846 Boston, Massachusetts United States 02215-1300 (e-mail: mughani@bu.edu); Electrical and Computer Department, Boston University, Boston, Massachusetts United States 02215 (e-mail: wckarl@bu.edu)","IEEE Transactions on Computational Imaging","","2019","PP","99","1","1","Filtered back projection (FBP) is the most widely used method for image reconstruction in X-ray computed tomography (CT) scanners, and can produce excellent images in many cases. However, the presence of dense materials, such as metals, can strongly attenuate or even completely block X-rays, producing severe streaking artifacts in the FBP reconstruction. These metal artifacts can greatly limit subsequent object delineation and information extraction from the images, restricting their diagnostic value. This problem is particularly acute in the security domain, where there is great heterogeneity in the objects that can appear in a scene, highly accurate decisions must be made quickly, and processing time is highly constrained. The standard practical approaches to reducing metal artifacts in CT imagery are either simplistic non-adaptive interpolation-based projection data completion methods or direct image post-processing methods. These standard approaches have had limited success. Motivated primarily by security applications, we present a new deep-learning-based metal artifact reduction approach that tackles the problem in the projection data domain. We treat the projection data corresponding to dense, metal objects as missing data and train an adversarial deep network to complete the missing data directly in the projection domain. The subsequent complete projection data is then used with conventional FBP to reconstruct an image intended to be free of artifacts. This new approach results in an end-to-end metal artifact reduction algorithm that is computationally efficient and therefore practical and fits well into existing CT workflows allowing easy adoption in existing scanners. Training deep networks can be challenging, and another contribution of our work is to demonstrate that training data generated using an accurate X-ray simulation can be used to successfully train the deep network, when combined with transfer learning using limited real data sets. We demonstrate the effectiveness and potential of our algorithm on simulated and real examples.","","","10.1109/TCI.2019.2937221","Science and Technology Directorate; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8815915","Computed tomography;Metal artifact reduction;Sinogram completion;Deep learning","Metals;Computed tomography;Image reconstruction;Security;Training;Task analysis;Deep learning","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"k-Space Deep Learning for Accelerated MRI","Y. Han; L. Sunwoo; J. C. Ye","Department of Bio and Brain Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon 34141, Republic of Korea.; Department of Radiology, Seoul National University College of Medicine, Seoul National University Bundang Hospital, Seongnam, Republic of Korea.; Department of Bio and Brain Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon 34141, Republic of Korea.","IEEE Transactions on Medical Imaging","","2019","PP","99","1","1","The annihilating filter-based low-rank Hankel matrix approach (ALOHA) is one of the state-of-the-art compressed sensing approaches that directly interpolates the missing k-space data using low-rank Hankel matrix completion. The success of ALOHA is due to the concise signal representation in the k-space domain thanks to the duality between structured low-rankness in the k-space domain and the image domain sparsity. Inspired by the recent mathematical discovery that links convolutional neural networks to Hankel matrix decomposition using datadriven framelet basis, here we propose a fully data-driven deep learning algorithm for k-space interpolation. Our network can be also easily applied to non-Cartesian k-space trajectories by simply adding an additional regridding layer. Extensive numerical experiments show that the proposed deep learning method consistently outperforms the existing image-domain deep learning approaches.","","","10.1109/TMI.2019.2927101","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8756028","Compressed sensing MRI;Deep Learning;Hankel structured low-rank completion;Convolution framelets","Deep learning;Convolution;Neural networks;Matrix converters;Matrix decomposition;Interpolation;Signal representation","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Deep Learning for Smartphone-based Malaria Parasite Detection in Thick Blood Smears","F. Yang; M. Poostchi; H. Yu; Z. Zhou; K. Silamut; J. Yu; R. J. Maude; S. Jaeger; S. Antani","Lister Hill National Center for Biomedical Communications, National Library of Medicine, National Institute of Health, Bethesda, Maryland United States (e-mail: fengyang@bjtu.edu.cn); Lister Hill National Center for Biomedical Communications, National Library of Medicine, NIH, National Institutes of Health (NIH), Bethesda, Maryland United States (e-mail: mahdieh.p82@gmail.com); Lister Hill National Center for Biomedical Communications, National Library of Medicine, National Institute of Health, Bethesda United States (e-mail: hang.yu@nih.gov); Biomedical Engineering Department, Beijing JiaoTong University, Beijing China (e-mail: zhouphd@bjtu.edu.cn); Mahidol-Oxford Tropical Medicine Research Unit, Bangkok Thailand (e-mail: ksilamut@gmail.com); School of Computer and Information Technology, Beijing Jiaotong University, 47829 Beijing, Beijing China (e-mail: jianyu@bjtu.edu.cn); Mahidol-Oxford Tropical Medicine Research Unit, Bangkok Thailand (e-mail: richard@tropmedres.ac); National Library of Medicine, National Institutes of Health, Bethesda, Maryland United States 20894 (e-mail: stefan.jaeger@nih.gov); National Library of Medicine, 10952 Bethesda, Maryland United States 20894-0001 (e-mail: santani@mail.nih.gov)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","Objective: This work investigates the possibility of automated malaria parasite detection in thick blood smears with smartphones. Methods: We are developing the first deep learning method that can detect malaria parasites in thick blood smear images and can run on smartphones. Our method consists of two processing steps. First, we apply an intensity-based Iterative Global Minimum Screening (IGMS), which performs a fast screening of a thick smear image to find parasite candidates. Then, a customized Convolutional Neural Network (CNN) classifies each candidate as either parasite or background. Together with this paper, we make a dataset of 1819 thick smear images from 150 patients publicly available to the research community. We used this dataset to train and test our deep learning method, as described in this paper. Results: A patient-level five-fold cross-evaluation demonstrates the effectiveness of the customized CNN model in discriminating between positive (parasitic) and negative image patches in terms of the following performance indicators: accuracy (93.46%±0.32%), AUC (98.39%±0.18%), sensitivity (92.59%±1.27%), specificity (94.33%±1.25%), precision (94.25%±1.13%), and negative predictive value (92.74%±1.09%). High correlation coefficients (>0.98) between automatically detected parasites and ground truth, on both image level and patient level, demonstrate the practicality of our method. Conclusion: Promising results are obtained for parasite detection in thick blood smears for a smartphone application using deep learning methods. Significance: Automated parasite detection running on smartphones is a promising alternative to manual parasite counting for malaria diagnosis, especially in areas lacking experienced parasitologists.","","","10.1109/JBHI.2019.2939121","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8846750","Deep learning;Convolutional neural networks;Computer-aided diagnosis;Malaria","Feature extraction;Blood;Diseases;Support vector machines;Deep learning;Sensitivity;Image segmentation","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"A Safe, Secure, and Predictable Software Architecture for Deep Learning in Safety-Critical Systems","A. Biondi; F. Nesti; G. Cicero; D. Casini; G. Buttazzo","Scuola Superiore Sant’Anna, Pisa, Italy.; Scuola Superiore Sant’Anna, Pisa, Italy.; Scuola Superiore Sant’Anna, Pisa, Italy.; Scuola Superiore Sant’Anna, Pisa, Italy.; Scuola Superiore Sant’Anna, Pisa, Italy.","IEEE Embedded Systems Letters","","2019","PP","99","1","1","In the last decade, deep learning techniques reached human-level performance in several specific tasks, as image recognition, object detection, and adaptive control. For this reason, deep learning is being seriously considered by the industry to address difficult perceptual and control problems in several safety-critical applications (e.g., autonomous driving, robotics, and space missions). However, at the moment, deep learning software poses a number of issues related to safety, security, and predictability, which prevent its usage in safety-critical systems. This work proposes a visionary software architecture that allows embracing deep learning while guaranteeing safety, security, and predictability by design. To achieve this goal, the architecture integrates multiple and diverse technologies, as hypervisors, run-time monitoring, redundancy with diversity, predictive fault detection, fault recovery, and predictable resource management. Open challenges that stems from the proposed architecture are finally discussed.","","","10.1109/LES.2019.2953253","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8897630","Deep learning;machine learning;deep neural networks;safety-critical systems;safety;security;fault-tolerance;predictability.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Least Squares Fisher Discriminant Analysis","D. Díaz-Vico; J. R. Dorronsoro","Dpto. Ing. Informática, Instituto de Ingeniería del Conocimiento, Universidad Autónoma de Madrid, 28049 Madrid, Spain (e-mail: david.diaz.vico@outlook.com).; Dpto. Ing. Informática, Instituto de Ingeniería del Conocimiento, Universidad Autónoma de Madrid, 28049 Madrid, Spain.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","12","While being one of the first and most elegant tools for dimensionality reduction, Fisher linear discriminant analysis (FLDA) is not currently considered among the top methods for feature extraction or classification. In this paper, we will review two recent approaches to FLDA, namely, least squares Fisher discriminant analysis (LSFDA) and regularized kernel FDA (RKFDA) and propose deep FDA (DFDA), a straightforward nonlinear extension of LSFDA that takes advantage of the recent advances on deep neural networks. We will compare the performance of RKFDA and DFDA on a large number of two-class and multiclass problems, many of them involving class-imbalanced data sets and some having quite large sample sizes; we will use, for this, the areas under the receiver operating characteristics (ROCs) curve of the classifiers considered. As we shall see, the classification performance of both methods is often very similar and particularly good on imbalanced problems, but building DFDA models is considerably much faster than doing so for RKFDA, particularly in problems with quite large sample sizes.","","","10.1109/TNNLS.2019.2906302","Mineco; Comunidad de Madrid; Project FACIL Ayudas Fundacion BBVA a Equipos de Investigacion Cientifica 2016; Universidad Autonoma de Madrid UAM Asociacion para el Desarrollo de la Ingenieria del Conocimiento ADIC Chair for Data Science and Machine Learning; Instituto de Ingenieria del Conocimiento; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8688630","Deep neural networks (DNNs);Fisher discriminant analysis (FDA);kernel discriminant analysis;nonlinear classifiers.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Flow Prediction in Spatio-Temporal Networks Based on Multitask Deep Learning","J. Zhang; Y. Zheng; J. Sun; D. Qi","Urban Computing Group, Microsoft Research Asia, 216064 Beijing, Beijing China (e-mail: msjunbozhang@outlook.com); Urban Computing Group, Microsoft Research Asia, 216064 Beijing, Beijing China (e-mail: msyuzheng@outlook.com); School of Computer Science and Technology, Xidian University, 47905 Xian, Shaanxi China (e-mail: junkaisun@outlook.com); School of Information Science and Technology, Southwest Jiaotong University, 56711 Chengdu, Sichuan China (e-mail: dekangqi@outlook.com)","IEEE Transactions on Knowledge and Data Engineering","","2019","PP","99","1","1","Predicting flows (e.g. the traffic of vehicles, crowds and bikes), consisting of the in-out traffic at a node and transitions between different nodes, in a spatio-temporal network plays an important role in transportation systems. However, this is a very challenging problem, affected by multiple complex factors, such as spatial correlations between different locations, temporal correlations among different time intervals, and external factors (like events and weather). In addition, the flow at a node (called node flow) and transitions between nodes (edge flow) mutually influence each other. To address these issues, we propose a multitask deep-learning framework that simultaneously predicts the node flow and edge flow throughout a spatio-temporal network. Using fully convolutional networks, our approach designs two sophisticated models for predicting node flow and edge flow respectively. Two models are connected by coupling their latent representations of middle layers, and trained together. The external factors are also integrated into the framework through a gating fusion mechanism. In the edge flow prediction model, we employ an embedding component to deal with the sparse transitions between nodes. We evaluate our method based on the taxicab data in Beijing and New York City.Experimental results show advantages of our method beyond 11 baselines, such as ConvLSTM, CNN, and Markov Random Field.","","","10.1109/TKDE.2019.2891537","National Natural Science Foundation of China; China National Basic Research Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8606218","Deep Learning;Spatio-temporal Data;Urban Computing","Correlation;Predictive models;Urban areas;Matrix converters;Sparse matrices;Sun","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Reinforcement Learning for Joint Datacenter and HVAC Load Control in Distributed Mixed-Use Buildings","T. Wei; S. Ren; Q. Zhu","Electrical and Computer Engineering, UC Riverside, Riverside, California United States 92521 (e-mail: twei002@ucr.edu); Department of Electrical and Computer Engineering, University of California, Riverside, Riverside, California United States (e-mail: sren@ece.ucr.edu); EECS, Northwestern University, Evanston, Illinois United States (e-mail: qzhu@northwestern.edu)","IEEE Transactions on Sustainable Computing","","2019","PP","99","1","1","The majority of today's power-hungry datacenters are physically co-located with office rooms in mixed-use buildings (MUBs). The heating, ventilation and air conditioning (HVAC) system within each MUB is often shared or partially-shared between datacenter rooms and office zones, for removing the heat generated by computing equipment and maintaining desired room temperature for building tenants. To effectively reduce the total energy cost of MUBs, it is important to leverage the scheduling flexibility in both the HVAC system and the datacenter workload. In this work, we formulate both HVAC control and datacenter workload scheduling as a Markov decision process (MDP), and propose a deep reinforcement learning (DRL) based algorithm for minimizing the total energy cost while maintaining desired room temperature and meeting datacenter workload deadline constraints. Moreover, we also develop a heuristic DRL-based algorithm to enable interactive workload allocation among geographically distributed MUBs for further energy reduction. The experiment results demonstrate that our regular DRL-based algorithm can achieve up to 26.9% cost reduction for a single MUB, when compared with a baseline strategy. Our heuristic DRL-based algorithm can reduce the total energy cost by an additional 5.5%, when intelligently allocating interactive workload for multiple geographically distributed MUBs.","","","10.1109/TSUSC.2019.2910533","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8691496","Deep reinforcement learning;Mixed-use buildings;HVAC;datacenter;geographically distributed","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Multi-Agent Deep Reinforcement Learning based Spectrum Allocation for D2D Underlay Communications","Z. Li; C. Guo","Beijing, Beijing China (e-mail: lizhengzachary@bupt.edu.cn); beijing, beijing China 100876 (e-mail: guocaili@bupt.edu.cn)","IEEE Transactions on Vehicular Technology","","2019","PP","99","1","1","Device-to-device (D2D) communication underlay cellular networks is a promising technique to improve spectrum efficiency. In this situation, D2D transmission may cause severe interference to both the cellular and other D2D links, which imposes a great technical challenge to spectrum allocation. Existing centralized schemes require global information, which causes a large signaling overhead. While existing distributed schemes requires frequent information exchange among D2D users and cannot achieve global optimization. In this paper, a distributed spectrum allocation framework based on multi-agent deep reinforcement learning is proposed, named multi-agent actor critic (MAAC). MAAC shares global historical states, actions and policies during centralized training, requires no signal interaction during execution and utilizes cooperation among users to further optimize system performance. Moreover, in order to decrease the computing complexity of the training, we further propose the neighbor-agent actor critic (NAAC) based on the neighbor users' historical information for centralized training. The simulation results show that the proposed MAAC and NAAC can effectively reduce the outage probability of cellular links, greatly improve the sum rate of D2D links and converge quickly.","","","10.1109/TVT.2019.2961405","National Key R and D Program of China; National Natural Science Foundation of China; Natural Science Foundation of Beijing Municipality; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8938826","Device-to-device (D2D) communications;multiagent deep reinforcement learning;spectrum allocation","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Hyperspectral Image Classification With Deep Metric Learning and Conditional Random Field","Y. Liang; X. Zhao; A. J. X. Guo; F. Zhu","Center for Applied Mathematics, Tianjin University, Tianjin 300072, China.; Center for Applied Mathematics, Tianjin University, Tianjin 300072, China.; Center for Applied Mathematics, Tianjin University, Tianjin 300072, China (e-mail: jiaxiang.guo@tju.edu.cn).; Center for Applied Mathematics, Tianjin University, Tianjin 300072, China.","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","To improve the classification performance in the context of hyperspectral image (HSI) processing, many works have been developed based on two common strategies, namely, the spatial-spectral information integration and the utilization of neural networks. However, both strategies typically require more training data than the classical algorithms, aggregating the shortage of labeled samples. In this letter, we propose a novel framework that organically combines the spectrum-based deep metric learning (DML) model and the conditional random field (CRF) algorithm. The DML model is supervised by the center loss to produce spectrum-based features that gather more tightly in Euclidean space within classes. The CRF with Gaussian edge potentials, which is first proposed for image segmentation tasks, is introduced to give the pixel-wise classification over the HSI by utilizing both the geographical distances between pixels and the Euclidean distances between the features produced by the DML model. The proposed framework is trained by spectral pixels at the DML stage and utilizes the half handcrafted spatial features at the CRF stage. This settlement alleviates the shortage of training data to some extent. Experiments on two real HSIs demonstrate the advantages of the proposed method in terms of both classification accuracy and computation cost.","","","10.1109/LGRS.2019.2939356","National Natural Science Foundation of China; Natural Science Foundation of Tianjin City; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8845628","Conditional random field;deep learning;hyperspectral image classification.","Feature extraction;Kernel;Artificial neural networks;Prediction algorithms;Task analysis;Loss measurement","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Robust BICM Design for the LDPC Coded DCO-OFDM: A Deep Learning Approach","Y. He; M. Jiang; X. Ling; C. Zhao","National Mobile Communications Research Laboratory, Southeast University, Nanjing 210096, China, and are with the Purple Mountain Laboratories, Nanjing, China.; National Mobile Communications Research Laboratory, Southeast University, Nanjing 210096, China, and are with the Purple Mountain Laboratories, Nanjing, China.; National Mobile Communications Research Laboratory, Southeast University, Nanjing 210096, China, and are with the Purple Mountain Laboratories, Nanjing, China.; National Mobile Communications Research Laboratory, Southeast University, Nanjing 210096, China, and are with the Purple Mountain Laboratories, Nanjing, China.","IEEE Transactions on Communications","","2019","PP","99","1","1","In this paper, a deep learning (DL) approach for enhancing the bit-interleaved coded modulation (BICM) receiver is designed to mitigate the clipping distortion in the low-density parity-check (LDPC) coded direct current-biased optical orthogonal frequency division multiplexing (DCO-OFDM) systems. This work aims to combine the neural network (NN) with the physical layer communications by using a model-driven DL architecture. We first develop a non-iterative NN-aided BICM (NN-BICM) receiver, where the NN is trained with the loss function of cross-entropy to output the modified conditional probability through the softmax activation function, thereby assisting in a log-likelihood ratio (LLR) improvement. Then, we propose two iterative NN-BICM receivers for iterative demapping and decoding. The single iterative design feeds the soft decisions from the LDPC decoder back to the demapper only, while the joint iterative design feeds the soft decisions back to the demapper and NN jointly. By adopting the iteration-wise pre-training strategy, the joint iterative design has been improved by representing the intractable relationship between the conditional probability and the a priori probability with a deeper NN architecture. We further investigate an efficient bit loading algorithm for DCOOFDM systems employing the NN-BICM receiver. Both NNBICM receivers and iterative schemes can obtain remarkable erformance gains over the existing benchmarks.","","","10.1109/TCOMM.2019.2954399","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8906157","DCO-OFDM;LDPC code;BICM-ID;deep learning;neural network","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Intelligent and Practical Deep Learning Aided Positioning Design for Visible Light Communication Receivers","X. Lin; L. Zhang","School of Electronics and Information Technology of Sun Yat-sen University, Guangzhou 510006, China.; School of Electronics and Information Technology of Sun Yat-sen University, Guangzhou 510006, China and Shandong Provincial Key Lab. of Wireless Communication Technologies.","IEEE Communications Letters","","2019","PP","99","1","1","Visible light positioning (VLP) systems can achieve high positioning precision. However, they are not compatible with visible communication systems. They require special positioning modules and could not reuse functional communication modules, while requiring more than two light emitting diodes (LEDs) to be deployed at user ends. In order to address the issues of weak compatibility and high complexity of VLP, we present a novel position estimation deep neural network (PE-DNN) and propose to add a PE-DNN aided module at the visible light communication (VLC) receivers. The proposed module firstly learns features of the VLC channel from received pilot signals implicitly, then it can estimate receivers’ 2-dimension positions intelligently with a single LED. Accordingly, VLC systems can simultaneously provide positioning and information transmission services with only one LED and one photodiode (PD), thus the compatibility and the practicality are greatly improved. Simulation results show that the proposed system achieves a centimeter-level positioning accuracy, and can provide intelligent and practical positioning services for the users.","","","10.1109/LCOMM.2019.2958629","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8930567","Deep Learning;Intelligence and practicality;Position estimation;Visible light communication receiver","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Actor-Critic Learning-based Robustness Enhancement of Internet of Things","N. Chen; T. Qiu; C. Mu; M. Han; P. Zhou","School of Computer Science and Technology, College of Intelligence and Computing, Tianjin University, Tianjin 300350, China, and also with the Tianjin Key Laboratory of Advanced Networking, Tianjin 300350, China.; School of Computer Science and Technology, College of Intelligence and Computing, Tianjin University, Tianjin 300350, China, and also with the Tianjin Key Laboratory of Advanced Networking, Tianjin 300350, China.; School of Electrical and Information Engineering, Tianjin University, Tianjin 300072, China.; Faculty of Electronic Information and Electrical Engineering, Dalian University of Technology, Dalian 116023, China.; School of Cyber Science and Engineering, Huazhong University of Science & Technology, Wuhan, 430074, China.","IEEE Internet of Things Journal","","2019","PP","99","1","1","The extensive applications in the Internet of Things (IoT) have inspired a growing network scale. However, due to the resources-limited IoT devices and the numerous cyber-attacks against applications, maintaining the robustness and communication capabilities for the applications is increasingly challenging. In this paper, we consider IoT network topologies that provide robust communication for heterogeneous networks and study the networking stability of IoT devices and the intelligent evolution computing in network architectures. We explicate the network robustness problem both for the network architecture and the resistance to cyber-attacks. For the network architecture, we optimize the robustness of IoT network topology with a scale-free network model which has good performance in random attacks. In the case with the resistance to cyber-attacks, a deep deterministic policy learning (DDLP) algorithm is proposed to improve the stability for large scale IoT applications. Simulations show that the proposed algorithms greatly advance the robustness of IoT network topology compared to other algorithms, with a less computational cost.","","","10.1109/JIOT.2019.2963499","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8948047","Robustness Optimization;Internet of Things;Reinforcement Learning;Networking Evolution;Deep Neural Network.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Intelligent VNF Orchestration and Flow Scheduling via Model-assisted Deep Reinforcement Learning","L. Gu; D. Zeng; W. Li; S. Guo; A. Y. Zomaya; H. Jin","National Engineering Research Center for Big Data Technology and System, Services Computing Technology and System Lab, Cluster and Grid Computing Lab, School of Computer Science and Technology, Huazhong University of Science and Technology, China.; Hubei Key Laboratory of Intelligent Geo-Information Processing, School of Computer Science, China University of Geosciences, Wuhan, China.; School of Computer Science and The University of Sydney, Australia.; Department of Computing, The Hong Kong Polytechnic University, Hong Kong.; School of Computer Science and The University of Sydney, Australia.; National Engineering Research Center for Big Data Technology and System, Services Computing Technology and System Lab, Cluster and Grid Computing Lab, School of Computer Science and Technology, Huazhong University of Science and Technology, China.","IEEE Journal on Selected Areas in Communications","","2019","PP","99","1","1","Hosting virtualized network functions (VNF) has been regarded as an effective way to realize network function virtualization (NFV). Considering the cost diversity in cloud computing, from the perspective of service providers, it is significant to orchestrate the VNFs and schedule the traffic flows for network utility maximization (NUM) as it implies maximal revenue. However, traditional heuristic solutions based on optimization models usually follow some assumptions, limiting their applicability. Recent studies have shown that deep reinforcement learning (DRL) is a promising way to tackle such limitations. However, DRL agent training also suffers from slow convergence problem, especially with complex control problems. We notice that optimization models actually can be applied to accelerate the DRL training. Therefore, we are motivated to design a modelassisted DRL framework for VNF orchestration in this paper. Other than letting the agent blindly explore actions, the heuristic solutions are used to guide the training process. Based on such principle, the DRL framework is also redesigned accordingly. Experiment results validate the high efficiency of our modelassisted DRL framework as it not only converges 23x faster than traditional DRL algorithm, but also with higher performance at the same time.","","","10.1109/JSAC.2019.2959182","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8931775","VNF Orchestration;Flow Scheduling;Deep Reinforcement Learning;Network Utility Maximization","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Joint Demodulation and Estimation Algorithm for Plasma Sheath Channel: Extract Principal Curves with Deep Learning","H. Liu; Y. Liu; M. Yang; X. Li","School of Aerospace Science and Technology, Xidian University, Xi’an 710071, China.; School of Aerospace Science and Technology, Xidian University, Xi’an 710071, China.; School of Aerospace Science and Technology, Xidian University, Xi’an 710071, China.; School of Aerospace Science and Technology, Xidian University, Xi’an 710071, China.","IEEE Wireless Communications Letters","","2019","PP","99","1","1","For reentry communication, owing to the influence of the time-varying plasma sheath, the received IQ baseband signals are severely rotated on constellation. Researches have shown that the frequency of electron density varies from 20kHz to 100 kHz which is on the same order as the symbol rate of most TT&C communication systems and traditional estimation algorithms cannot track the variation of channel. In this paper, motivated by principal curve analysis, we propose a deep learning (DL) algorithm which is called symmetric manifold network (SMN) to extract the curves on the constellation and classify the signals based on the curves. The key advantage is that SMN can achieve joint optimization of demodulation and estimation. From our simulation results, the new algorithm significantly reduces the symbol error rate (SER) compared to existing algorithms and enables accurate estimation of fading with extremely high bandwidth utilization rate.","","","10.1109/LWC.2019.2957811","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8924648","plasam sheath;deep learning;demodulation;channel estimation.","Fading channels;Decoding;Estimation;Signal processing algorithms;Demodulation;Plasma sheaths","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Smart Resource Allocation for Mobile Edge Computing: A Deep Reinforcement Learning Approach","J. Wang; L. Zhao; J. Liu; N. Kato","State Key Laboratory of Integrated Services Networks, Xidian University, 47905 Xian, Shaanxi China 710071 (e-mail: jdwang_xd@163.com); School of Cyber Engineering, Xidian University, 47905 Xian, Shaanxi China (e-mail: dreamofsophy@gmail.com); School of Cyber Engineering, Xidian Univ., Xian, Shaanxi China (e-mail: liujiajia@xidian.edu.cn); Graduate School of Information Sciences, Tohoku Univ., Sendai, Miyagi Japan 9808579 (e-mail: kato@it.is.tohoku.ac.jp)","IEEE Transactions on Emerging Topics in Computing","","2019","PP","99","1","1","The development of mobile devices with improving communication and perceptual capabilities has brought about a proliferation of numerous complex and computation-intensive mobile applications. Mobile devices with limited resources face more severe capacity constraints than ever before. As a new concept of network architecture and an extension of cloud computing, Mobile Edge Computing (MEC) seems to be a promising solution to meet this emerging challenge. However, MEC also has some limitations, such as the high cost of infrastructure deployment and maintenance, as well as the severe pressure that the complex and mutative edge computing environment brings to MEC servers. At this point, how to allocate computing resources and network resources rationally to satisfy the requirements of mobile devices under the changeable MEC conditions has become a great aporia. To combat this issue, we propose a smart, Deep Reinforcement Learning based Resource Allocation (DRLRA) scheme, which can allocate computing and network resources adaptively, reduce the average service time and balance the use of resources under varying MEC environment. Experimental results show that the proposed DRLRA performs better than the traditional OSPF algorithm in the mutative MEC conditions.","","","10.1109/TETC.2019.2902661","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8657791","Mobile edge computing;resource allocation;deep reinforcement learning","Mobile handsets;Resource management;Servers;Delays;Computer architecture;Routing;Cloud computing","","","","4","","","","","","IEEE","IEEE Early Access Articles"
"Multi-Scale Deep Residual Learning-Based Single Image Haze Removal via Image Decomposition","C. Yeh; C. Huang; L. Kang","Department of Electrical Engineering, National Taiwan Normal University, Taipei 10610, Taiwan and Department of Electrical Engineering, National Sun Yat-Sen University, Kaohsiung 80424, Taiwan.; Department of Electrical Engineering, National Sun Yat-Sen University, Kaohsiung 80424, Taiwan.; Department of Electrical Engineering, National Taiwan Normal University, Taipei 10610, Taiwan.","IEEE Transactions on Image Processing","","2019","PP","99","1","1","Images/videos captured from outdoor visual devices are usually degraded by turbid media, such as haze, smoke, fog, rain, and snow. Haze is the most common one in outdoor scenes due to the atmosphere conditions. In this paper, a novel deep learning-based architecture (denoted by MSRL-DehazeNet) for single image haze removal relying on multi-scale residual learning (MSRL) and image decomposition is proposed. Instead of learning an end-to-end mapping between each pair of hazy image and its corresponding haze-free one adopted by most existing learningbased approaches, we reformulate the problem as restoration of the image base component. Based on the decomposition of a hazy image into the base and the detail components, haze removal (or dehazing) can be achieved by both of our multi-scale deep residual learning and our simplified U-Net learning only for mapping between hazy and haze-free base components, while the detail component is further enhanced via the other learned convolutional neural network (CNN). Moreover, benefited by the basic building block of our deep residual CNN architecture and our simplified UNet structure, the feature maps (produced by extracting structural and statistical features), and each previous layer can be fully preserved and fed into the next layer. Therefore, possible color distortion in the recovered image would be avoided. As a result, the final haze-removed (or dehazed) image is obtained by integrating the haze-removed base and the enhanced detail image components. Experimental results have demonstrated good effectiveness of the proposed framework, compared with state-ofthe-art approaches.","","","10.1109/TIP.2019.2957929","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8931240","haze removal;single image dehazing;deep learning;deep residual learning;U-Net;convolutional neural networks;image decomposition;image restoration","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Unsupervised Domain Adaptation for Depth Prediction from Images","A. Tonioni; M. Poggi; S. Mattoccia; L. Di Stefano","DISI, University of Bologna, Bologna, Bologna Italy (e-mail: alessio.tonioni@unibo.it); Department of Computer Science and Engineering (DISI), Universita degli Studi di Bologna Dipartimento di Informatica Scienza e Ingegneria, 166478 Bologna, Bologna Italy 40127 (e-mail: m.poggi@unibo.it); Department of Computer Science and Engineering, University of Bologna, Bologna, -- Please Select (only U.S. / Can / Aus) Italy 40136 (e-mail: stefano.mattoccia@unibo.it); DISI Department of Computer Science and Engineering, University of Bologna, Bologna, BO Italy (e-mail: luigi.distefano@unibo.it)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","State-of-the-art methods to infer dense and accurate depth measurements from images rely on deep CNN models trained in an end-to-end fashion on a significant amount of data. However, despite the outstanding performance achieved, these frameworks suffer a drastic drop in accuracy when dealing with unseen environments much different, concerning appearance (e.g., synthetic vs. real) or context (e.g., indoor vs. outdoor), from those observed during the training phase. Such domain shift issue is usually softened by fine-tuning on smaller sets of images with depth labels acquired in the target domain with active sensors (e.g., LiDAR). However, relying on such supervised labeled data is seldom feasible in practical applications. Therefore, we propose an effective unsupervised domain adaptation technique enabling to overcome the domain shift problem without requiring any groundtruth label. Our method, deploying much more accessible to obtain stereo pairs, leverages traditional and not learning-based stereo algorithms to produce disparity/depth labels and on confidence measures to assess their degree of reliability. With these cues, we can fine-tune deep models through a novel confidence-guided loss function, neglecting the effect of outliers gathered from the output of conventional stereo algorithms.","","","10.1109/TPAMI.2019.2940948","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8834825","Deep learning;depth estimation;unsupervised learning;self-supervised learning;domain adaptation","Training;Reliability;Estimation;Loss measurement;Computer architecture;Prediction algorithms;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Deep Learning Framework for Single-Sided Sound Speed Inversion in Medical Ultrasound","M. Feigin-Almon; D. Freedman; B. W. Anthony","Mechanical Engineering, Massachusetts Institute of Technology, 2167 Cambridge, Massachusetts United States 02139 (e-mail: michaf@mit.edu); Google research, Haifa Israel (e-mail: danielfreedman@google.com); Mechanical Engineering, Massachusetts Institute of Technology, 2167 Cambridge, Massachusetts United States 02139-4307 (e-mail: banthony@mit.edu)","IEEE Transactions on Biomedical Engineering","","2019","PP","99","1","1","Objective: Ultrasound elastography is gaining traction as an accessible and useful diagnostic tool for such things as cancer detection and differentiation and thyroid disease diagnostics. Unfortunately, state of the art shear wave imaging techniques, essential to promote this goal, are limited to high-end ultrasound hardware due to high power requirements; are extremely sensitive to patient and sonographer motion, and generally, suffer from low frame rates. Motivated by research and theory showing that pressure wave sound speed carries similar diagnostic abilities to shear wave imaging, we present an alternative approach using single sided pressure-wave sound speed measurements from a conventional ultrasound probe, enabling elasticity based diagnostics using portable and low-cost devices. Methods: In this paper, we present a single-sided sound speed inversion solution using a fully convolutional deep neural network. We use simulations for training, allowing the generation of large volumes of ground truth data. Results: We show that it is possible to invert for longitudinal sound speed in soft tissue at super real-time frame rates. Our method shows exceptional results on simulated data and highly encouraging initial results on real data. Conclusion: Sound speed inversion on channel data has significant potential, made possible in real time with deep learning technologies. Significance: High-end ultrasound devices remain inaccessible in many locations. Utilizing pressure sound speed and deep learning technologies brings the same quality diagnostic abilities to low power devices at real-time frame rates. High potential frame rates also enable dynamic functional imaging, impossible with shear wave imaging.","","","10.1109/TBME.2019.2931195","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8772124","deep learning;inverse problems;ultrasound;sound speed inversion","Ultrasonic imaging;Deep learning;Diseases;Elastography;Young's modulus","","","","","","","","","","IEEE","IEEE Early Access Articles"
"An Improved Pretraining Strategy-Based Scene Classification With Deep Learning","Z. Chen; Y. Wang; W. Han; R. Feng; J. Chen","Department of Land and Resources of Guizhou Province, Guiyang 550004, China.; School of Computer Science, Northeast Forestry University, Harbin 150040, China.; School of Computer Science, China University of Geosciences, Wuhan 430074, China, and also with the Hubei Key Laboratory of Intelligent Geo-Information Processing, China University of Geosciences, Wuhan 430074, China (e-mail:weihan@cug.edu.cn).; School of Computer Science, China University of Geosciences, Wuhan 430074, China, and also with the Hubei Key Laboratory of Intelligent Geo-Information Processing, China University of Geosciences, Wuhan 430074, China (e-mail:fengry@cug.edu.cn).; School of Computer Science, China University of Geosciences, Wuhan 430074, China, and also with the Hubei Key Laboratory of Intelligent Geo-Information Processing, China University of Geosciences, Wuhan 430074, China.","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","High-resolution remote sensing (HRRS) image scene classification takes an important role in many applications and has attracted much attention. Recently, notable efforts have been made to present massive methods for HRRS scene classification, wherein deep-learning-based methods demonstrate remarkable performance compared with state-of-the-art methods. However, HRRS images contain complex contextual relationships and large differences of object scale, which are significantly different from natural images. The existing deep-learning-based scene classification methods are originally designed for natural image processing and have not been optimized to adapt to the characteristics of HRRS images, which significantly affects the efficiency of the feature extraction and recognition accuracy. In addition, when designing a model for remote sensing tasks, the pretraining of the model is time-consuming. The enormous amount of pretraining time and computation resources necessarily increase the difficulty of producing an excellent model. In this letter, focusing on the problems above, we proposed a new convolutional neural network (CNN)-based scene classification method. The CNN-based scene classification method is constructed by spatial-scale-aware blocks and is efficient in extracting the abundant spatial features, but can also adaptively adjust feature responses to maximize the function of informative features in the classification results. In addition, an HRRS imagery-based learning strategy is utilized to obtain an initial model for fine-tuning the model parameters, which drastically reduces the pretraining time. The proposed method has been demonstrated using two HRRS data sets, and experimental results have proven the superiority of the proposed method.","","","10.1109/LGRS.2019.2934341","National Natural Science Foundation of China; GF Innovative Research Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8816675","Deep learning;high-resolution remote sensing (HRRS) scene classification;spatial coding;weight-adaptive.","Feature extraction;Adaptation models;Computational modeling;Remote sensing;Deep learning;Data models;Convergence","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Deep Learning Approach to Infer Employment Status of Passengers by Using Smart Card Data","Y. Zhang; T. Cheng","SpaceTimeLab for Big Data Analytics, University College London, London WC1E 6BT, U.K. (e-mail: yang.zhang.16@ucl.ac.uk).; SpaceTimeLab for Big Data Analytics, University College London, London WC1E 6BT, U.K..","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","13","Understanding the employment status of passengers in public transit systems is significant for transport operators in many real applications such as forecasting travel demand and providing personalized transportation service. This paper develops a deep learning approach to infer a passenger's employment status by using smart card data (SCD) with a household survey. This paper first extracts an individual passenger's weekly travel patterns in different travel modes from the raw SCD as a three-dimensional image. A deep learning architecture, called a thresholding multi-channel convolutional neural network, was developed to predict an individual's employment status. The approach proposed here solves two critical problems of using the SCD for employment status studies. First, it automatically incorporates learning temporal features in different travel modes without the need for handcrafted travel feature design. Second, it considers the class-imbalance problem by leveraging the ensemble of oversampling and thresholding techniques. By applying our approach to a real dataset collected from the metropolitan area of London, U.K., about 72% of passengers were correctly categorized into six types of employment statuses. The promising results show the tight correlation between temporal travel behavior, mode choice, and social-demographic roles. To the best of our knowledge, this is the first paper to infer employment status by using the SCD.","","","10.1109/TITS.2019.2896460","Consumer Data Research Centre Economic and Social Research Council UK; China Scholarship Council; Deans Prize from University College London; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8645820","Deep learning;employment status inference;travel mode choice;smart card data;temporal travel behavior.","Employment;Feature extraction;Deep learning;Predictive models;Smart cards;Transportation;Correlation","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Deep Fuzzy Echo State Networks for Machinery Fault Diagnosis","S. Zhang; Z. Sun; M. Wang; J. Long; Y. Bai; C. Li","School of Mechanical Engineering, Dongguan University of Technology, Dongguan 523808, China; and is also with the School of Mechanical & Automotive Engineering, South China University of Technology, Guangzhou 510641, China. (e-mail: shaohui1985@hotmail.com); School of Mechanical Engineering, Dongguan University of Technology, Dongguan 523808, China. (e-mail: drzzsun@sina.com); School of Mechanical Engineering, Dongguan University of Technology, Dongguan 523808, China. (e-mail: man.zi@163.com); School of Mechanical Engineering, Dongguan University of Technology, Dongguan 523808, China. (e-mail: drlongjy@hotmail.com); School of Mechanical Engineering, Dongguan University of Technology, Dongguan 523808, China. (e-mail: baiyun@dgut.edu.cn); School of Mechanical Engineering, Dongguan University of Technology, Dongguan 523808, China (e-mail: c.li@ismmm.org)","IEEE Transactions on Fuzzy Systems","","2019","PP","99","1","1","An echo state network (ESN) is a recurrent neural network with low computational complexity. However, a single ESN cannot extract effective features from complex inputs, especially for dealing with low-cost condition signals in machinery fault diagnosis. A novel deep learning model, referred to as the deep fuzzy ESN (DFESN), was proposed to improve the feature extraction capability with less computational burden. In the present method, the output data of the previous ESN reservoir were regarded as abstract feature vectors for the next ESN input. The features were reinforced in each hidden layer by using fuzzy clustering as a tuning step for classification enhancement. In this way, layer-wise fuzzy-tuning was developed to replace traditional overall feedback fine-tuning in deep models. This improved learning efficiency and robustness while overcoming the vanishing gradient problem for deep learning. The superiority of the proposed approach was evaluated by both theoretical analysis and experimental tests. The results showed that the present DFESN features improved classification accuracy and reduced the computational burden. In addition to machinery fault diagnosis, the proposed DFESN also has potential for other deep learning applications.","","","10.1109/TFUZZ.2019.2914617","National Natural Science Foundation of China; Natural Science Foundation of Guangdong Province; Research Program of Higher Education of Guangdong; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8704873","Deep fuzzy echo state network;feature reinforcement;fuzzy-tuning;fault diagnosis;deep learning","Fault diagnosis;Feature extraction;Deep learning;Reservoirs;Recurrent neural networks;Machinery","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Person Reidentification via Unsupervised Cross-View Metric Learning","Y. Feng; Y. Yuan; X. Lu","Key Laboratory of Spectral Imaging Technology CAS, Xi'an Institute of Optics and Precision Mechanics, Chinese Academy of Sciences, Xi'an 710119, China.; Center for Optical Imagery Analysis and Learning, Northwestern Polytechnical University, Xi'an 710072, China.; Key Laboratory of Spectral Imaging Technology CAS, Xi'an Institute of Optics and Precision Mechanics, Chinese Academy of Sciences, Xi'an 710119, China (e-mail: luxq666666@gmail.com).","IEEE Transactions on Cybernetics","","2019","PP","99","1","11","Person reidentification (Re-ID) aims to match observations of individuals across multiple nonoverlapping camera views. Recently, metric learning-based methods have played important roles in addressing this task. However, metrics are mostly learned in supervised manners, of which the performance relies heavily on the quantity and quality of manual annotations. Meanwhile, metric learning-based algorithms generally project person features into a common subspace, in which the extracted features are shared by all views. However, it may result in information loss since these algorithms neglect the view-specific features. Besides, they assume person samples of different views are taken from the same distribution. Conversely, these samples are more likely to obey different distributions due to view condition changes. To this end, this paper proposes an unsupervised cross-view metric learning method based on the properties of data distributions. Specifically, person samples in each view are taken from a mixture of two distributions: one models common prosperities among camera views and the other focuses on view-specific properties. Based on this, we introduce a shared mapping to explore the shared features. Meanwhile, we construct view-specific mappings to extract and project view-related features into a common subspace. As a result, samples in the transformed subspace follow the same distribution and are equipped with comprehensive representations. In this paper, these mappings are learned in an unsupervised manner by clustering samples in the projected space. Experimental results on five cross-view datasets validate the effectiveness of the proposed method.","","","10.1109/TCYB.2019.2909480","National Natural Science Foundation of China; National Basic Research Program of China (973 Program); CAS Light of West China Program; Key Research Program of Frontier Sciences CAS; Young Top Notch Talent Program of Chinese Academy of Sciences; State Key Program of National Natural Science of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8694838","Metric learning;person reidentification (Re-ID);unsupervised learning;view-specific mapping","Cameras;Feature extraction;Learning systems;Deep learning;Extraterrestrial measurements;Cybernetics","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Unsupervised Tracklet Person Re-Identification","M. Li; X. Zhu; S. Gong","EECS, Queen Mary University of London, 4617 London, England United Kingdom of Great Britain and Northern Ireland (e-mail: m.li@qmul.ac.uk); R&D, Vision Semantics Limited, London, England United Kingdom of Great Britain and Northern Ireland (e-mail: xiatian.zhu@qmul.ac.uk); EECS, Queen Mary, University of London, London, London United Kingdom of Great Britain and Northern Ireland (e-mail: s.gong@qmul.ac.uk)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Most existing person re-identification (re-id) methods rely on supervised model learning on per-camera-pair manually labelled pairwise training data. This leads to poor scalability in a practical re-id deployment, due to the lack of exhaustive identity labelling of positive and negative image pairs for every camera-pair. In this work, we present an unsupervised re-id deep learning approach. It is capable of incrementally discovering and exploiting the underlying re-id discriminative information from automatically generated person tracklet data end-to-end. We formulate an Unsupervised Tracklet Association Learning (UTAL) framework. This is by jointly learning within-camera tracklet discrimination and cross-camera tracklet association in order to maximise the discovery of tracklet identity matching both within and across camera views. Extensive experiments demonstrate the superiority of the proposed model over the state-of-the-art unsupervised learning and domain adaptation person re-id methods on eight benchmarking datasets.","","","10.1109/TPAMI.2019.2903058","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8658110","Person Re-Identification;Unsupervised Tracklet Association;Trajectory Fragmentation;Multi-Task Deep Learning","Cameras;Data models;Deep learning;Labeling;Adaptation models;Unsupervised learning;Training data","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Deep Air Quality Forecasting Using Hybrid Deep Learning Framework","S. Du; T. Li; Y. Yang; S. Horng","School of Information Science and Technology, Southwest Jiaotong University, 56711 Chengdu, Sichuan China (e-mail: sddu@swjtu.edu.cn); School of Information Science and Technology, Southwest Jiaotong University, Chengdu, Sichuan China 610031 (e-mail: trli@swjtu.edu.cn); School of Information Science and Technology, Southwest Jiaotong University, Chengdu, Sichuan China 610031 (e-mail: yyang@swjtu.edu.cn); Department of Computer Science and Information Engineering, National Taiwan University of Science and Technology, Taipei, Taipei City Taiwan 106 (e-mail: horngsj@yahoo.com.tw)","IEEE Transactions on Knowledge and Data Engineering","","2019","PP","99","1","1","Air quality forecasting has been regarded as the key problem of air pollution early warning and control management. In this paper, we propose a novel deep learning model for air quality (mainly PM2.5) forecasting, which learns the spatial-temporal correlation features and interdependence of multivariate air quality related time series data by hybrid deep learning architecture. Due to the nonlinear and dynamic characteristics of multivariate air quality time series data, the base modules of our model include one-dimensional Convolutional Neural Networks (1D-CNNs) and Bi-directional Long Short-term Memory networks (Bi-LSTM). The former is to extract the local trend features and spatial correlation features, and the latter is to learn spatial-temporal dependencies. Then we design a jointly hybrid deep learning framework based on one-dimensional CNNs and Bi-LSTM for shared representation features learning of multivariate air quality related time series data. We conduct extensive experimental evaluations using two real-world datasets, and the results show that our model is capable of dealing with PM2.5 air pollution forecasting with satisfied accuracy.","","","10.1109/TKDE.2019.2954510","National Natural Science Foundation of China; Center for Cyber-physical System Innovation from The Featured Areas Research Center Program within the framework of the Higher Education Sprout Project by the Ministry of Education in Taiwan; Ministry of Science and Technology Taiwan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8907358","Air quality forecasting;deep learning;convolutional neural networks;long short-term memory networks","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Saliency Prediction in the Deep Learning Era: Successes and Limitations","A. Borji","Computer science, University of Southern California (USC), Los Angeles, California United States 90089 (e-mail: aliborji@gmail.com)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Visual saliency models have enjoyed a big leap in performance in recent years, thanks to advances in deep learning and large scale annotated data. Despite enormous effort and huge breakthroughs, however, models still fall short in reaching human-level accuracy. In this work, I explore the landscape of the field emphasizing on new deep saliency models, benchmarks, and datasets. A large number of image and video saliency models are reviewed and compared over two image benchmarks and two large scale video datasets. Further, I identify factors that contribute to the gap between models and humans and discuss remaining issues that need to be addressed to build the next generation of more powerful saliency models. Some specific questions that are addressed include: in what ways current models fail, how to remedy them, what can be learned from cognitive studies of attention, how explicit saliency judgments relate to fixations, how to conduct fair model comparison, and what are the emerging applications of saliency models.","","","10.1109/TPAMI.2019.2935715","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8805409","Visual saliency;eye movement prediction;attention;video saliency;benchmark;deep learning","Predictive models;Computational modeling;Benchmark testing;Data models;Visualization;Deep learning;Task analysis","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"A Deep Learning Approach to Recover High-g Shock Signals from the Faulty Accelerometer","J. Wen; H. Yao; B. Wu; Y. Ren; Z. Ji","School of Astronautics, Northwestern Polytechnical University, Xi’an 710072, China and Research Associate in the School of Engineering, Cardiff University, Cardiff CF243AA, UK.; Department of Mechanic and Aerospace Engineering, Arizona State University, Tempe 85281, USA.; School of Astronautics, Northwestern Polytechnical University, Xi’an 710072, China.; Department of Mechanic and Aerospace Engineering, Arizona State University, Tempe 85281, USA.; School of Engineering, Cardiff University, Cardiff CF243AA, UK.","IEEE Sensors Journal","","2019","PP","99","1","1","A deep learning based approach is proposed to accurately recover shock signals measured from a damaged high-g accelerometer without modifying the hardware. We first conducted shock tests and collected a large dataset of shock signals with different levels of acceleration by using an efficient experimental apparatus. The training data is composed of a pair of signals simultaneously obtained from a faulty accelerometer and a high-end accelerometer (served as the ground truth). A customized autoencoder neural network is designed and trained on this dataset, aiming to map the faulty signals to their reference counterparts. Experimental results show that, with the help of deep learning, shock signals can be accurately recovered from the faulty measurements. Compared with conventional approaches that require diagnosing and replacing faulty parts, the proposed data-driven method demonstrates a highly promising solution that allows recovering corrupted signals without introducing extra work to upgrade the hardware at almost zero cost. The dataset and code of this work are made publicly available on GitHub at https://github.com/hope-yao/SensorCalibration.","","","10.1109/JSEN.2019.2949241","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8880693","Autoencoder;deep learning;data recovery;high-g accelerometer;shock test","Electric shock;Accelerometers;Sensors;Deep learning;Calibration;Transmission line measurements;Hardware","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Learning based Channel Estimation Algorithm over Time Selective Fading Channels","Q. Bai; J. Wang; Y. Zhang; J. Song","Electronic Engineering Department, Tsinghua University, and Beijing National Research Center for Information Science and Technology (BNRist), Beijing 100084, China.; Electronic Engineering Department, Tsinghua University, and Beijing National Research Center for Information Science and Technology (BNRist), Beijing 100084, China.; Department of Engineering, University of Leicester, Leicester, LE1 7RH, United Kingdom.; Electronic Engineering Department, Tsinghua University, and Beijing National Research Center for Information Science and Technology (BNRist), Beijing 100084, China.","IEEE Transactions on Cognitive Communications and Networking","","2019","PP","99","1","1","The research about deep learning application for physical layer has been received much attention in recent years. In this paper, we propose a Deep Learning (DL) based channel estimator under time varying Rayleigh fading channel. We build up, train and test the channel estimator using Neural Network (NN). The proposed DL-based estimator can dynamically track the channel status without any prior knowledge about the channel model and statistic characteristics. The simulation results show the proposed NN estimator has better Mean Square Error (MSE) performance compared with the traditional algorithms and some other DL-based architectures. Furthermore, the proposed DL-based estimator also shows its robustness with the different pilot densities.","","","10.1109/TCCN.2019.2943455","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8847452","Deep learning;time varying channel;channel estimation;sliding structure;Neural Network.","Channel estimation;Artificial neural networks;Deep learning;Estimation;Communication systems;Rayleigh channels","","","","","","","","","","IEEE","IEEE Early Access Articles"
"μVulDeePecker: A Deep Learning-Based System for Multiclass Vulnerability Detection","D. Zou; S. Wang; S. Xu; Z. Li; H. Jin","School of Cyberspace Security, Huazhong University of Science and Technology, 12443 Wuhan, Hubei China (e-mail: Deqingzou@hust.edu.cn); School of Computer Science and Technology, Huazhong University of Science and Technology, 12443 Wuhan, Hubei China (e-mail: sophiewsj@hust.edu.cn); Computer Science, University of Texas at San Antonio, 12346 San Antonio, Texas United States (e-mail: shxu@cs.utsa.edu); School of Computer Science and Technology, Huazhong University of Science and Technology, 12443 Wuhan, Hubei China (e-mail: lizhen_hust@hust.edu.cn); School of Computer Science and Technology, Huazhong University of Science and Technology, 12443 Wuhan, Hubei China (e-mail: hjin@hust.edu.cn)","IEEE Transactions on Dependable and Secure Computing","","2019","PP","99","1","1","Fine-grained software vulnerability detection is an important and challenging problem. Ideally, a detection system (or detector) not only should be able to detect whether or not a program contains vulnerabilities, but also should be able to pinpoint the type of a vulnerability in question. Existing vulnerability detection methods based on deep learning can detect the presence of vulnerabilities (i.e., addressing the binary classification or detection problem), but cannot pinpoint types of vulnerabilities (i.e., incapable of addressing multiclass classification). In this paper, we propose the first deep learning-based system for multiclass vulnerability detection, dubbed μVulDeePecker. The key insight underlying μVulDeePecker is the concept of code attention, which can capture information that can help pinpoint types of vulnerabilities, even when the samples are small. For this purpose, we create a dataset from scratch and use it to evaluate the effectiveness of μVulDeePecker. Experimental results show that μVulDeePecker is effective for multiclass vulnerability detection and that accommodating control-dependence (other than data-dependence) can lead to higher detection capabilities.","","","10.1109/TDSC.2019.2942930","the NSF CREST; the National Key Research and Development Plan of China; the Shenzhen Fundamental Research Program; the National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8846081","Vulnerability detection;multiclass classification;data-dependence;control-dependence;code gadget;code attention;deep learning","Deep learning;Neural networks;Technological innovation;Software;Feature extraction;Big Data","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Learning-Based MIMO-NOMA With Imperfect SIC Decoding","J. Kang; I. Kim; C. Chun","School of Intelligent Mechatronics Engineering, Sejong University, Seoul 05006, South Korea. He is currently with the Department of Artificial Intelligence, Kyungpook National University, Daegu 41566, South Korea (e-mail: jmkang@knu.ac.kr).; Department of Electrical and Computer Engineering, Queen’s University, Kingston, ON K7L 3N6, Canada (e-mail: ilmin.kim@queensu.ca).; System Control Research Center, Korea Electrotechnology Research Institute, Changwon 51543, South Korea (e-mail: cjchun84@gmail.com).","IEEE Systems Journal","","2019","PP","99","1","4","Nonorthogonal multiple access (NOMA) and multiple-input multiple-output (MIMO) are two key enablers for 5G systems. In this article, considering the practical issue that successive interference cancellation (SIC) decoding is imperfect in the real-world NOMA system, we propose a novel scheme for the downlink of the MIMO-NOMA system based on deep learning. In this scheme, both precoding and SIC decoding of the MIMO-NOMA system are jointly optimized (or learned) in the sense of minimizing total mean square error of the users’ signals. To this end, we construct the precoder and SIC decoders using deep neural networks such that the transmitted signals intended to multiple users can be properly precoded at the transmitter based on the superposition coding technique and the received signals are accurately decodable at the users by the SIC decoding. Numerical results demonstrate the effectiveness and superior performance of the proposed scheme.","","","10.1109/JSYST.2019.2937463","Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8827912","Deep learning;multiple-input multiple-output (MIMO);nonorthogonal multiple access (NOMA);neural network;precoding;successive interference cancellation (SIC) decoding","Silicon carbide;Decoding;Precoding;NOMA;MIMO communication;Deep learning;Optimization","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Local Differential Privacy for Deep Learning","P. C. M. Arachchige; P. Bertok; I. Khalil; D. Liu; S. Camtepe; M. Atiquzzaman","department of Computer Science and Software Engineering at the School of Science, RMIT University, Australia.; department of Computer Science and Software Engineering at the School of Science, RMIT University, Melbourne, Australia.; department of Computer Science and Software Engineering at the School of Science, RMIT University, Melbourne, Australia.; CSIRO Data61, Sydney, Australia.; CSIRO Data61, Sydney, Australia.; School of Computer Science at the University of Oklahoma.","IEEE Internet of Things Journal","","2019","PP","99","1","1","The internet of things (IoT) is transforming major industries including but not limited to healthcare, agriculture, finance, energy, and transportation. IoT platforms are continually improving with innovations such as the amalgamation of software-defined networks (SDN) and network function virtualization (NFV) in the edge-cloud interplay. Deep learning (DL) is becoming popular due to its remarkable accuracy when trained with a massive amount of data, such as generated by IoT. However, DL algorithms tend to leak privacy when trained on highly sensitive crowd-sourced data such as medical data. Existing privacy-preserving DL algorithms rely on the traditional server-centric approaches requiring high processing powers. We propose a new local differentially private (LDP) algorithm named LATENT that redesigns the training process. LATENT enables a data owner to add a randomization layer before data leave the data owners’ devices and reach a potentially untrusted machine learning service. This feature is achieved by splitting the architecture of a convolutional neural network (CNN) into three layers: (1) convolutional module, (2) randomization module, and (3) fully connected module. Hence, the randomization module can operate as an NFV privacy preservation service in an SDN-controlled NFV, making LATENT more practical for IoT-driven cloud-based environments compared to existing approaches. The randomization module employs a newly proposed LDP protocol named utility enhancing randomization, which allows LATENT to maintain high utility compared to existing LDP protocols. Our experimental evaluation of LATENT on convolutional deep neural networks demonstrates excellent accuracy (e.g. 91%-96%) with high model quality even under low privacy budgets (e.g. ε=0.5).","","","10.1109/JIOT.2019.2952146","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8894030","Data privacy;deep learning;differential privacy;local differential privacy.","Privacy;Differential privacy;Economic indicators;Deep learning;Internet of Things;Protocols","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Defect Detection of Pantograph Slide Based on Deep Learning and Image Processing Technology","X. Wei; S. Jiang; Y. Li; C. Li; L. Jia; Y. Li","State Key Laboratory of Railway Traffic Control and Safety, Beijing Jiaotong University, Beijing 100044, China (e-mail: xkwei@bjtu.edu.cn).; State Key Laboratory of Railway Traffic Control and Safety, Beijing Jiaotong University, Beijing 100044, China.; State Key Laboratory of Railway Traffic Control and Safety, Beijing Jiaotong University, Beijing 100044, China.; State Key Laboratory of Railway Traffic Control and Safety, Beijing Jiaotong University, Beijing 100044, China.; State Key Laboratory of Railway Traffic Control and Safety, Beijing Jiaotong University, Beijing 100044, China.; State Key Laboratory of Railway Traffic Control and Safety, Beijing Jiaotong University, Beijing 100044, China.","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","12","Pantograph is one of the most important components in electrical railway vehicles. To guarantee steady power supply for the train, the surface of the pantograph slide plate should be smooth enough so that the catenary can move on it from one side to the other side steadily with low friction. In addition, the thickness of the pantograph slide plate cannot be smaller than the lower limit for the sake of safety. Therefore, periodical inspection and maintenance of the pantograph slide plate are significant in terms of safe and stable operation. In this paper, an innovative and intelligent method based on deep learning and image processing technologies is proposed for the online condition monitoring of the pantograph slide plate. In the first stage, the surface defect detection and recognition method of the pantograph slide plate is proposed. Four typical surface defects of the slide are considered, and a deep learning model, pantograph defect detection neural network (PDDNet), is trained for the defect detection and recognition. In the second stage, five key criteria for qualifying the wear condition are proposed. The wear edge estimation based on image processing technology is investigated in detail. Furthermore, they are used to calculate the wear depth and evaluate the wear condition of the pantograph slide. The experiment results demonstrate that the proposed PDDNet can detect the surface defects and also recognize the four kinds of defects with a sound accuracy. The wear depth estimation results are compared with on-site measurement data, and the proposed method can achieve high estimation accuracy.","","","10.1109/TITS.2019.2900385","State Key Lab of Rail Traffic Control and Safety Beijing Jiaotong University; Chinese National Key Project of Research and Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8667891","Pantograph;defect detection;deep learning;convolutional neural network;image processing;railway.","Rail transportation;Image edge detection;Head;Deep learning;Picture archiving and communication systems;Inspection","","","","","","","","","","IEEE","IEEE Early Access Articles"
"DeepWear: Adaptive Local Offloading for On-Wearable Deep Learning","M. Xu; F. Qian; M. Zhu; F. Huang; S. Pushp; X. Liu","Computer Science, School of EECS, Beijing, Beijing China (e-mail: xumengwei@pku.edu.cn); Computer Science, Indiana University, Bloomington, Indiana United States (e-mail: fengqian@indiana.edu); Computer Science and Technology, Peking University School of Electronics Engineering and Computer Science, Beijing, Beijing China (e-mail: zhumz@pku.edu.cn); Institute of Software, Peking University, Beijing, Beijing China (e-mail: feifanhuang1995@pku.edu.cn); Department of Computer Science, Korea Advanced Institute of Science and Technology, 34968 Daejeon, Daejeon Korea (the Republic of) (e-mail: saumay@nclab.kaist.ac.kr); Institute of Software, Peking University, Beijing, Beijing China 100871 (e-mail: liuxuanzhe@pku.edu.cn)","IEEE Transactions on Mobile Computing","","2019","PP","99","1","1","Due to their on-body and ubiquitous nature, wearables can generate a wide range of unique sensor data creating countless opportunities for deep learning tasks. We propose DeepWear, a deep learning (DL) framework optimized for wearable devices to improve the performance and reduce the energy footprint. DeepWear strategically offloads DL tasks from a wearable device to its paired handheld device through local network connectivity such as Bluetooth. Compared to the remote-cloud-based offloading, DeepWear requires no Internet connectivity, consumes less energy, and is not vulnerable to privacy breach. DeepWear provides various novel techniques such as context-aware offloading, strategic model partition, and pipelining support to efficiently utilize the processing capacity from nearby paired handhelds. Deployed as a user-space library, DeepWear offers developer-friendly APIs that are as simple as those in traditional DL libraries such as TensorFlow. We have implemented DeepWear on the Android OS and evaluated it on COTS smartphones and smartwatches with real DL models. DeepWear brings up to 5.08X and 23.0X execution speedup, as well as 53.5% and 85.5% energy saving compared to wearable-only and handheld-only strategies, respectively.","","","10.1109/TMC.2019.2893250","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8618364","Wearables;Deep Learning;Offloading","Task analysis;Computational modeling;Deep learning;Smart phones;Data models;Mobile computing;Handheld computers","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Fully Embedded Adaptive Real-Time Hand Gesture Classifier Leveraging HD-sEMG & Deep Learning","S. Tam; M. Boukadoum; A. Campeau-Lecours; B. Gosselin","Universite Laval, Quebec, Quebec Canada G1V 0A6 (e-mail: simon.tam.1@ulaval.ca); Informatique, UQAM, Montreal, Quebec Canada H3C 3P8 (e-mail: boukadoum.mounir@uqam.ca); Universite Laval Departement de genie mecanique, 120473 Quebec, Quebec Canada (e-mail: alexandre.campeau-lecours@gmc.ulaval.ca); Electrical and Computer Engineering, Laval University, Quebec, Quebec Canada G1V 0A6 (e-mail: Benoit.Gosselin@gel.ulaval.ca)","IEEE Transactions on Biomedical Circuits and Systems","","2019","PP","99","1","1","This paper presents a real-time fine gesture recognition system for multi-articulating hand prosthesis control, using an embedded convolutional neural network (CNN) to classify hand-muscle contractions sensed at the forearm. The sensor consists in a custom non-intrusive, compact, and easy-to-install 32-channel high-density surface electromyography (HDsEMG) electrode array, built on a flexible printed circuit board (PCB) to allow wrapping around the forearm. The sensor provides a low-noise digitization interface with wireless data transmission through an industrial, scientific and medical (ISM) radio link. An original frequency-time-space cross-domain preprocessing method is proposed to enhance gesture-specific data homogeneity and generate reliable muscle activation maps, leading to 98.15% accuracy when using a majority vote over 5 subsequent inferences by the proposed CNN. The obtained real-time gesture recognition, within 100 to 200 ms, and CNN properties show reliable and promising results to improve on the state-of-the-art of commercial hand prostheses. Moreover, edge computing using a specialized embedded artificial intelligence (AI) platform ensures reliable, secure and low latency real-time operation as well as quick and easy access to training, fine-tuning and calibration of the neural network. Co-design of the signal processing, AI algorithms and sensing hardware ensures a reliable and power-efficient embedded gesture recognition system.","","","10.1109/TBCAS.2019.2955641","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8911244","Myoelectric;Prosthetic Hand;Armband;HDEMG;Electromyography;Gesture;Motion;Recognition;Control;Deep Learning;Machine Learning;Convolution;Neural Network;Edge Computing;Real-Time","Electrodes;Real-time systems;Prosthetics;Muscles;Electromyography;Gesture recognition;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Corse-to-Fine Road Extraction Based on Local Dirichlet Mixture Models and Multiscale-High-Order Deep Learning","Z. Chen; W. Fan; B. Zhong; J. Li; J. Du; C. Wang","Department of Computer Science and Technology, Huaqiao University, Xiamen 361021, China.; Department of Computer Science and Technology, Huaqiao University, Xiamen 361021, China.; Department of Computer Science and Technology, Huaqiao University, Xiamen 361021, China.; Key Laboratory of Underwater Acoustic Communication and Marine Information Technology (MOE), Xiamen University, Xiamen 361005, China, and also with the Department of Geography and Environmental Management, University of Waterloo, Waterloo, ON N2L 3G1, Canada.; Department of Computer Science and Technology, Huaqiao University, Xiamen 361021, China.; School of Information Science and Engineering, Xiamen University, Xiamen 361005, China (e-mail: cwang@xmu.edu.cn).","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","11","Road extraction from remote sensing images is an attractive but difficult task. Gray-value distribution and structure feature information are both crucial for road extraction task. However, existing methods mainly focus on structure feature information which contains morphological shape features and machine learning features, suffering from lots of false positives which are generated at positions having similar structure features but different gray-value distribution with roads. To effectively fuse the two complementary gray-value distribution and structure feature information, we propose a coarse-to-fine road extraction algorithm from remote sensing images. First, at the coarse level, we introduce a local Dirichlet mixture models (LDMM) which utilizing gray-value distribution information to pre-segment images into potential roads and backgrounds. Thus, most backgrounds having different gray-value distribution with roads can be removed firstly. Compared with original Dirichlet mixture models, the LDMM is much faster and more accurate. Next, at the fine level, we introduce a multiscal-high-order deep learning strategy based on ResNet model which can learn robust structure context features for final road extraction step. Based on the results of LDMM, the multiscal-high-order strategy can further remove false positives which have different structure features with roads. Compared with a single scanning size ResNet, our multiscale-high-order strategy can learn higher-order context information, leading to better performances. We test our algorithm on Shaoshan dataset. Experiments illustrate our better performance compared with other six state-of-the-art methods.","","","10.1109/TITS.2019.2939536","Natural Science Foundation of Fujian Province; Huaqiao University Foundation; Fujian Key Laboratory of Sensing and Computing for Smart Cities of Xiamen University; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8861077","Road extraction;remote sensing image;local Dirichlet mixture model;multiscal-high-order;deep learning.","Roads;Feature extraction;Remote sensing;Mixture models;Data mining;Deep learning;Image segmentation","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Progressive Latent Models for Self-Learning Scene-Specific Pedestrian Detectors","Q. Ye; T. Zhang; W. Ke","School of Electronic, Electrical, and Communication Engineering, University of Chinese Academy of Sciences, Beijing 108408, China.; School of Electronic, Electrical, and Communication Engineering, University of Chinese Academy of Sciences, Beijing 108408, China.; School of Electronic, Electrical, and Communication Engineering, University of Chinese Academy of Sciences, Beijing 108408, China (e-mail: kewei11@mails.ucas.ac.cn).","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","12","The performance of offline learned pedestrian detectors significantly drops when they are applied to video scenes of various camera views, occlusions, and background structures. Learning a detector for each video scene can avoid the performance drop but it requires repetitive human effort on data annotation. In this paper, a self-learning approach is proposed, toward specifying a pedestrian detector for each video scene without any human annotation involved. Object locations in video frames are treated as latent variables and a progressive latent model (PLM) is proposed to solve such latent variables. The PLM is deployed as components of object discovery, object enforcement, and label propagation, which are used to learn the object locations in a progressive manner. With the difference of convex (DC) objective functions, PLM is optimized by a concave-convex programming algorithm. With specified network branches and loss functions, PLM is integrated with deep feature learning and optimized in an end-to-end manner. From the perspectives of convex regularization and error rate estimation, detailed optimization analysis and learning stability analysis of the proposed PLM are provided. The extensive experiments demonstrate that even without annotation involved the proposed self-learning approach outperforms weakly supervised learning approaches, while achieving comparable performance with transfer learning approaches.","","","10.1109/TITS.2019.2911315","National Natural Science Foundation of China; Beijing Municipal Science and Technology Commission; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8701617","Pedestrian detection;self-learning;progressive latent model;difference of convex.","Detectors;Proposals;Optimization;Feature extraction;Cameras;Stability analysis;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Dynamical Hyperparameter Optimization via Deep Reinforcement Learning in Tracking","X. Dong; J. Shen; W. Wang; L. Shao; H. Ling; F. Porikli","School of Computer Science, Beijing Institute of Technology, Beijing, Beijing China (e-mail: dongxingping@bit.edu.cn); Department of Information Technology and Electrical Engineering, ETH Zurich, Zurich, Zurich Switzerland CH-8092 (e-mail: shenjianbingcv@gmail.com); Statistics Department, University of California Los Angeles, 8783 Los Angeles, California United States 90095 (e-mail: wenguanwang.ai@gmail.com); School of Computing Sciences, University of East Anglia, Norwich, Norfolk United Kingdom of Great Britain and Northern Ireland NR4 7TJ (e-mail: ling.shao@ieee.org); Computer and Information Sciences, Temple University, Philadelphia, Pennsylvania United States (e-mail: hling@cs.stonybrook.edu); Computer Vision, Mitsubishi Electric Research Labs, Cambridge, Massachusetts United States 02472 (e-mail: fatih.porikli@anu.edu.au)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Hyperparameters are numerical pre-sets whose values are assigned prior to the commencement of a learning process. Selecting appropriate hyperparameters is often critical for achieving satisfactory performance in many vision problems such as deep learning-based visual object tracking. Yet it is difficult to determine their optimal values, in particular, adaptive ones for each specific video input. Most hyperparameter optimization algorithms depend on searching a generic range and they are imposed blindly on all sequences. In this paper, we propose a novel dynamical hyperparameter optimization method that adaptively optimizes hyperparameters for a given sequence using an action-prediction network leveraged on continuous deep Q-learning. Since the observation space for visual object tracking is significantly more complex than those in traditional control problems, existing continuous deep Q-learning algorithms cannot be directly applied. To overcome this challenge, we introduce an efficient heuristic strategy to handle high dimensional state space and meanwhile accelerate the convergence behavior. The proposed algorithm is applied to improve two representative trackers, a Siamese-based one and a correlation-filter-based one, to evaluate its generality. Their superior performances on several popular benchmarks are clearly demonstrated.","","","10.1109/TPAMI.2019.2956703","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8918068","Hyperparameters;Continuous Deep Q-Learning;Reinforcement Learning;Visual object tracking","Heuristic algorithms;Learning (artificial intelligence);Object tracking;Training;Visualization;Optimization methods","","","","","","","","","","IEEE","IEEE Early Access Articles"
"PersEmoN: A Deep Network for Joint Analysis of Apparent Personality, Emotion and Their Relationship","L. Zhang; S. Peng; S. Winkler","Institute for Infocomm Research, Agency for Science, Technology and Research (A*STAR), Singapore, Singapore Singapore (e-mail: lzhang027@e.ntu.edu.sg); Institute for Infocomm Research, Agency for Science, Technology and Research, Singapore, Singapore Singapore (e-mail: songyou.peng@adsc-create.edu.sg); University of Illinois at Urbana-Champaign, Advanced Digital Sciences Center, Singapore, Singapore Singapore (e-mail: Stefan.Winkler@adsc.com.sg)","IEEE Transactions on Affective Computing","","2019","PP","99","1","1","Apparent personality and emotion analysis are both central to affective computing. Existing works solve them individually. In this paper we investigate if such high-level affect traits and their relationship can be jointly learned from face images in the wild. To this end, we introduce PersEmoN, an end-to-end trainable and deep Siamese-like network. It consists of two convolutional network branches, one for emotion and the other for apparent personality. Both networks share their bottom feature extraction module and are optimized within a multi-task learning framework. Emotion and personality networks are dedicated to their own annotated dataset. Furthermore, an adversarial-like loss function is employed to promote representation coherence among heterogeneous dataset sources. Based on this, we also explore the emotion-to-apparent-personality relationship. Extensive experiments demonstrate the effectiveness of PersEmoN.","","","10.1109/TAFFC.2019.2951656","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8897617","Affective Computing;Emotion;Apparent Personality;Adversarial Learning;Multi-Task Learning;Deep Learning","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"DeePGA: A Privacy-Preserving Data Aggregation Game in Crowdsensing via Deep Reinforcement Learning","Y. Liu; H. Wang; M. Peng; J. Guan; J. Xu; Y. Wang","State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, 100876, China, and also with the Jiangsu Key Laboratory of Big Data Security and Intelligent Processing, Nanjing University of Posts and Telecommunications, Nanjing, Jiangsu 210023, China.; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, 100876, China.; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, 100876, China.; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, 100876, China.; Jiangsu Key Laboratory of Big Data Security and Intelligent Processing, Nanjing University of Posts and Telecommunications, Nanjing, Jiangsu 210023, China.; Department of Computer and Information Sciences, Temple University, Philadelphia, Pennsylvania 19122, USA.","IEEE Internet of Things Journal","","2019","PP","99","1","1","The Internet of Things (IoT) has such a profound impact that we have witnessed crowdsensing has emerged as the most popular sensing paradigm where participants sense and aggregate data to the platform by smart devices. However, the participants may not be willing to involve in data sensing and aggregation if they are not sufficiently compensated or their personalized private information are disclosed. In order to overcome the above issues, this paper proposes a payment-privacy protection level (PPL) game, where each participant submits his sensing data with a specified PPL while the platform chooses a corresponding payment to the participant. Additionally, we derive the Nash equilibrium (NE) point of the game. Considering that the payment-PPL model is unknown in practice, we employ a reinforcement learning technique, i.e., Q-learning to obtain the payment-PPL strategy in a dynamic payment-PPL game. We further use deep Q network (DQN), which combines a deep learning technique with Q-learning to accelerate learning speed. Through extensive simulations, we verify that our proposed algorithm using DQN achieves superior performance in terms of utilities of both platform and participants and data aggregation accuracy compared with the one using Q-learning.","","","10.1109/JIOT.2019.2957400","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8920035","Data aggregation;crowdsensing;differential privacy;equilibrium;Q-learning;deep reinforcement learning.","Sensors;Games;Data aggregation;Task analysis;Data privacy;Privacy;Machine learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"MoDL-MUSSELS: Model-Based Deep Learning for Multishot Sensitivity-Encoded Diffusion MRI","H. K. Aggarwal; M. P. Mani; M. Jacob","Department of electrical and computer engineering, University of Iowa, Iowa, USA.; Division of neuroradiology, University of Iowa, Iowa, USA.; Department of electrical and computer engineering, University of Iowa, Iowa, USA.","IEEE Transactions on Medical Imaging","","2019","PP","99","1","1","We introduce a model-based deep learning architecture termed MoDL-MUSSELS for the correction of phase errors in multishot diffusion-weighted echo-planar MR images. The proposed algorithm is a generalization of the existing MUSSELS algorithm with similar performance but significantly reduced computational complexity. In this work, we show that an iterative re-weighted least-squares implementation of MUSSELS alternates between a multichannel filter bank and the enforcement of data consistency. The multichannel filter bank projects the data to the signal subspace, thus exploiting the annihilation relations between shots. Due to the high computational complexity of the self-learned filter bank, we propose replacing it with a convolutional neural network (CNN) whose parameters are learned from exemplary data. The proposed CNN is a hybrid model involving a multichannel CNN in the k-space and another CNN in the image space. The k-space CNN exploits the annihilation relations between the shot images, while the image domain network is used to project the data to an image manifold. The experiments show that the proposed scheme can yield reconstructions that are comparable to state-of-the-art methods while offering several orders of magnitude reduction in run-time.","","","10.1109/TMI.2019.2946501","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8863423","Diffusion MRI;Echo Planar Imaging;Deep Learning;convolutional neural network","Magnetic resonance imaging;Convolution;Deep learning;Image reconstruction;Distortion;Computational complexity","","","","","","","","","","IEEE","IEEE Early Access Articles"
"SaliencyGAN: Deep Learning Semi-supervised Salient Object Detection in the Fog of IoT","C. Wang; S. Dong; X. Zhao; G. Papanastasiou; H. Zhang; G. Yang","BHF Centre for Cardiovascular Science, The University of Edinburgh, 3124 Edinburgh, Edinburgh United Kingdom of Great Britain and Northern Ireland EH16 4TJ (e-mail: Chengjia.Wang@ed.ac.uk); Shenzhen Institutes of Advanced Technology Chinese Academy of Sciences, 85411 Shenzhen, Guangdong China 518055 (e-mail: sz.dong@siat.ac.cn); School of Management Engineering and Business, Hebei University of Engineering, 117798 Handan, Hebei China 056038 (e-mail: zhaoxiaofeng@hebeu.edu.cn); Edinburgh Imaging Facility QMRI, The University of Edinburgh, 3124 Edinburgh, Edinburgh United Kingdom of Great Britain and Northern Ireland EH16 4TJ (e-mail: g.papanas@ed.ac.uk); School of Biomedical Engineering, Sun Yat-Sen University, 26469 Guagnzhou, Guangdong China 510275 (e-mail: heye.zhang@gmail.com); Imperial College London, 4615 London, London United Kingdom of Great Britain and Northern Ireland SW7 2AZ (e-mail: g.yang@imperial.ac.uk)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","In modern internet of things (IoT), visual analysis and predictions are often performed by deep learning models. Salient object detection (SOD) is a fundamental pre-processing for these applications. Executing SOD on the fog devices is a challenging task due to the diversity of data and fog devices. To adopt convolutional neural networks (CNN) on fog-cloud infrastructures for SOD-based applications, we introduce a semisupervised adversarial learning method in this paper. The proposed model, named as SaliencyGAN, is empowered by a novel concatenated-GAN framework with partially shared parameters. The backbone CNN can be chosen flexibly based on the specific devices and applications. In the meanwhile, our method uses both the labelled and unlabelled data from different problem domains for training. Using multiple popular benchmark datasets, we compared state-of-the-art baseline methods to our SaliencyGAN obtained with 10% to 100% labelled training data. SaliencyGAN gained performance comparable to the supervised baselines when the percentage of labelled data reached 30%, and outperformed the weakly supervised and unsupervised baselines. Furthermore, our ablation study shows that SaliencyGAN were more more robust to the common “mode missing” (or “mode collapse”) issue compared to the selected popular GAN models. The visualized ablation results proved that SaliencyGAN learned a better estimation of data distributions. To the best of our knowledge, this is the first IoT-oriented semi-supervised SOD method.","","","10.1109/TII.2019.2945362","Innovation funding of Guangdong Province; Fundamental Research Funds for the Central Universities; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8859383","Internet of Things;Deep Learning;Convolutional Neural Networks;Salient Object Detection;GAN","Internet of Things;Training;Computational modeling;Deep learning;Data models;Gallium nitride;Feature extraction","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Residual Shrinkage Networks for Fault Diagnosis","M. Zhao; S. Zhong; X. Fu; B. Tang; M. Pecht","School of Naval Architecture and Ocean Engineering, Harbin Institute of Technology at Weihai, Weihai, Shandong China 264209 (e-mail: zhaomh@hit.edu.cn); School of Naval Architecture and Ocean Engineering, Harbin Institute of Technology at Weihai, Weihai, Shandong China 264209 (e-mail: zhongss@hit.edu.cn); School of Naval Architecture and Ocean Engineering, Harbin Institute of Technology at Weihai, Weihai, Shandong China 264209 (e-mail: fuxuyun@hit.edu.cn); State Key Laboratory of Mechanical Transmission, Chongqing University, Chongqing China 400044 (e-mail: bptang@cqu.edu.cn); College Park, Maryland United States 20742 (e-mail: pecht@umd.edu)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","This paper develops new deep learning methods, namely, deep residual shrinkage networks, to improve the feature learning ability from highly noised vibration signals and achieve a high fault diagnosing accuracy. Soft thresholding is inserted as nonlinear transformation layers into the deep architectures to eliminate unimportant features. Moreover, considering that it is generally challenging to set proper values for the thresholds, the developed deep residual shrinkage networks integrate a few specialized neural networks as trainable modules to automatically determine the thresholds, so that professional expertise on signal processing is not required. The efficacy of the developed methods is validated through experiments with various types of noise.","","","10.1109/TII.2019.2943898","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8850096","Deep learning;deep residual networks;fault diagnosis;soft thresholding;vibration signal","Convolution;Fault diagnosis;Vibrations;Kernel;Deep learning;Rotating machines;Neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Improving Dataset Volumes and Model Accuracy with Semi-Supervised Iterative Self-Learning","R. Dupre; J. Fajtl; V. Argyriou; P. Remagnino","R.Dupre, J.Fajtl, V.Argyriou and P. Remagnino are members of the Robot Vision Team (RoViT) at Kingston University.; R.Dupre, J.Fajtl, V.Argyriou and P. Remagnino are members of the Robot Vision Team (RoViT) at Kingston University.; R.Dupre, J.Fajtl, V.Argyriou and P. Remagnino are members of the Robot Vision Team (RoViT) at Kingston University.; R.Dupre, J.Fajtl, V.Argyriou and P. Remagnino are members of the Robot Vision Team (RoViT) at Kingston University.","IEEE Transactions on Image Processing","","2019","PP","99","1","1","Within this work a novel semi-supervised learning technique is introduced based on a simple iterative learning cycle together with learned thresholding techniques and an ensemble decision support system. State-of-the-art model performance and increased training data volume are demonstrated, through the use of unlabelled data when training deeply learned classification models. The methods presented work independently from the model architectures or loss functions, making this approach applicable to a wide range of machine learning and classification tasks. Evaluation of the proposed approach is performed on commonly used datasets when evaluating semi-supervised learning techniques as well as a number of more challenging image classification datasets (CIFAR-100 and a 200 class subset of ImageNet).","","","10.1109/TIP.2019.2913986","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8706941","semi-supervised;image classification;deep learning;machine learning","Training;Data models;Semisupervised learning;Task analysis;Noise measurement;Deep learning;Solid modeling","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Three-Dimensional Deep Learning Framework for Human Behavior Analysis Using Range-Doppler Time Points","H. Du; T. Jin; Y. Song; Y. Dai; M. Li","College of Electronic Science and Technology, National University of Defense Technology, Changsha 410073, China.; College of Electronic Science and Technology, National University of Defense Technology, Changsha 410073, China (e-mail: tianjin@nudt.edu.cn).; College of Electronic Science and Technology, National University of Defense Technology, Changsha 410073, China.; College of Electronic Science and Technology, National University of Defense Technology, Changsha 410073, China.; Institute of Public Safety Research, Tsinghua University, Beijing 100084, China.","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","Deep neural networks have shown promise in the radar-based human activity analysis application. Different from existing deep learning models that take either micro-Doppler spectrograms or range profiles as their input, the proposed method can process micromotion signatures in a 3-D way. In this letter, we first transform radar echoes into range-Doppler (RD) time points and then directly process the point sets via a designed 3-D network called the RD PointNet. In fact, our point model is a discrete representation of the motion trajectory. Through this quantitative model, we can use the 3-D network to simultaneously capture human motion profiles and temporal variations. The motion capture simulations and ultrawideband radar measurements show that the proposed framework can achieve superior classification accuracy and noise robustness when compared with image-based methods.","","","10.1109/LGRS.2019.2930636","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8792134","Geometric deep learning;graph network;human activity recognition;micro-Doppler effect;point cloud.","Solid modeling;Radar;Doppler effect;Deep learning;Computational modeling;Analytical models;Trajectory","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Particle Image Velocimetry Based on a Deep Learning Motion Estimator","S. Cai; J. Liang; Q. Gao; C. Xu; R. Wei","State Key Laboratory of Industrial Control Technology and the Institute of Cyber-Systems & Control, Zhejiang University, Hangzhou 310027, China.; State Key Laboratory of Industrial Control Technology and the Institute of Cyber-Systems & Control, Zhejiang University, Hangzhou 310027, China.; School of Aeronautics and Astronautics, Zhejiang University, Hangzhou 310027, China.; State Key Laboratory of Industrial Control Technology and the Institute of Cyber-Systems & Control, Zhejiang University, Hangzhou 310027, China and National Engineering Center for Industrial Automation, Zhejiang University, Hangzhou 310027, China.; MicroVec., Inc, Beijing 100083, China.","IEEE Transactions on Instrumentation and Measurement","","2019","PP","99","1","1","Particle image velocimetry (PIV), as a common technology for analysing the global flow motion from images, plays a significant role in experimental fluid mechanics. In this paper, we investigate the deep learning-based techniques for such a fluid motion estimation problem. The aim of this novel technique is to extract two-dimensional velocity fields from fluid images efficiently and accurately. First, we introduce the convolutional neural network (CNN) called LiteFlowNet, which is proposed for end-to-end optical flow estimation. Enhanced configurations of LiteFlowNet are adopted for PIV estimation in order to refine the small-scale vortex structures. Furthermore, as the supervised learning strategy is considered, a dataset including particle images and the ground-truth fluid motions is generated to train the parameters of the networks. A number of fluidic images, from synthetic turbulent flow to laboratory boundary layer flow, are investigated in this paper. Experimental results indicate the proposed estimator can provide accuracy approaching that of state-of-the-art methods and high efficiency toward real-time estimation.","","","10.1109/TIM.2019.2932649","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8793167","Particle Image Velocimetry;Fluid Motion Estimation;Deep Learning;Convolutional Neural Network;Turbulent Boundary Layer","Estimation;Deep learning;Optical imaging;Motion estimation;Convolutional neural networks;Optical fiber networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Deep Learning-based Framework for Intersectional Traffic Simulation and Editing","H. Bi; T. Mao; Z. Wang; Z. Deng","Computer Science, University of the Chinese Academy of Sciences, 74519 Beijing, Beijing China (e-mail: xiaobi361@gmail.com); Lab for Advanced Computing Research, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, Beijing China 100190 (e-mail: ltm@ict.ac.cn); Institute of Computing Technology, Chinese Academy of Sciences, Beijing, Beijing China (e-mail: zqwang@ict.ac.cn); Computer Science, University of Houston, Houston, Texas United States (e-mail: zdeng4@uh.edu)","IEEE Transactions on Visualization and Computer Graphics","","2019","PP","99","1","1","Most of existing traffic simulation methods have been focused on simulating vehicles on freeways or city-scale urban networks. However, relatively little research has been done to simulate intersectional traffic to date despite its obvious importance in real-world traffic phenomena. In this paper we propose a novel deep learning-based framework to simulate and edit intersectional traffic. Specifically, based on an in-house collected intersectional traffic dataset, we employ the combination of convolution network (CNN) and recurrent network (RNN) to learn the patterns of vehicle trajectories in intersectional traffic. Besides simulating novel intersectional traffic, our method can be used to edit existing intersectional traffic. Through many experiments as well as comparison user studies, we demonstrate that the results by our method are visually indistinguishable from ground truth and perform better than other methods.","","","10.1109/TVCG.2018.2889834","Science and Technology Mobilization Program of Dongguan; National Natural Science Foundation of China; Division of Information and Intelligent Systems; 13th Five-Year Common Technology pre Research Program; National Key Research and Development Program of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8600335","Traffic simulation;crowd simulation;data-driven;deep learning;intersectional traffic","Trajectory;Solid modeling;Computational modeling;Vehicle dynamics;Traffic control;Data models;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Learning for Large-Scale Traffic-Sign Detection and Recognition","D. Tabernik; D. Skočaj","Faculty of Computer and Information Science, University of Ljubljana, Ljubljana 1000, Slovenia (e-mail: domen.tabernik@fri.uni-lj.si).; Faculty of Computer and Information Science, University of Ljubljana, Ljubljana 1000, Slovenia.","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","14","Automatic detection and recognition of traffic signs plays a crucial role in management of the traffic-sign inventory. It provides an accurate and timely way to manage traffic-sign inventory with a minimal human effort. In the computer vision community, the recognition and detection of traffic signs are a well-researched problem. A vast majority of existing approaches perform well on traffic signs needed for advanced driver-assistance and autonomous systems. However, this represents a relatively small number of all traffic signs (around 50 categories out of several hundred) and performance on the remaining set of traffic signs, which are required to eliminate the manual labor in traffic-sign inventory management, remains an open question. In this paper, we address the issue of detecting and recognizing a large number of traffic-sign categories suitable for automating traffic-sign inventory management. We adopt a convolutional neural network (CNN) approach, the mask R-CNN, to address the full pipeline of detection and recognition with automatic end-to-end learning. We propose several improvements that are evaluated on the detection of traffic signs and result in an improved overall performance. This approach is applied to detection of 200 traffic-sign categories represented in our novel dataset. The results are reported on highly challenging traffic-sign categories that have not yet been considered in previous works. We provide comprehensive analysis of the deep learning method for the detection of traffic signs with a large intra-category appearance variation and show below 3% error rates with the proposed approach, which is sufficient for deployment in practical applications of the traffic-sign inventory management.","","","10.1109/TITS.2019.2913588","ARRS Research Projects; ARRS Research Programme; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8709983","Deep learning;traffic-sign detection and recognition;traffic-sign dataset;mask R-CNN;traffic-sign inventory management.","Deep learning;Benchmark testing;Task analysis;Proposals;Detectors;Manuals;Inventory management","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Image-based 3D Object Reconstruction: State-of-the-Art and Trends in the Deep Learning Era","X. Han; H. Laga; M. Bennamoun","College of Computer and Information Science, Southwest University, 26463 Chongqing, Sichuan China (e-mail: hanxianf@163.com); Information Technology, Mathematics and Statistics, Murdoch University, Perth, Western Australia Australia (e-mail: hamid.laga@gmail.com); School of Computer Science and Software Engineering, UWA, Perth, Western Australia Australia (e-mail: mohammed.bennamoun@uwa.edu.au)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","3D reconstruction is a longstanding ill-posed problem, which has been explored for decades by the computer vision, computer graphics, and machine learning communities. Since 2015, image-based 3D reconstruction using convolutional neural networks (CNN) has attracted increasing interest and demonstrated an impressive performance. Given this new era of rapid evolution, this article provides a comprehensive survey of the recent developments in this field. We focus on the works which use deep learning techniques to estimate the 3D shape of generic objects either from a single or multiple RGB images. We organize the literature based on the shape representations, the network architectures, and the training mechanisms they use. While this survey is intended for methods which reconstruct generic objects, we also review some of the recent works which focus on specific object classes such as human body shapes and faces. We provide an analysis and comparison of the performance of some key papers, summarize some of the open problems in this field, and discuss promising directions for future research.","","","10.1109/TPAMI.2019.2954885","China Scholarship Council; Australian Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8908779","3D Reconstruction;Depth Estimation;SLAM;SfM;CNN;Deep Learning;LSTM;3D face;3D Human Body;3D Video","Three-dimensional displays;Image reconstruction;Shape;Training;Deep learning;Two dimensional displays;Australia","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Embedding Deep Learning in Inverse Scattering Problems","Y. Sanghvi; Y. N. G. B. Kalepu; U. Khankhoje","Electrical Engineering, Indian Institute of Technology, Madras, Chennai, Tamil Nadu India (e-mail: sanghviyash95@gmail.com); Electrical Engineering, Chennai, Tamil Nadu India 600036 (e-mail: yaswanthkalepu@gmail.com); Electrical Engineering, Indian Institute of Technology Madras, Chennai India 600036 (e-mail: uday@ee.iitm.ac.in)","IEEE Transactions on Computational Imaging","","2019","PP","99","1","1","We introduce a Deep Learning based framework to solve electromagnetic inverse scattering problems. This framework builds on and extends the capabilities of existing physicsbased inversion algorithms. These algorithms, such as the Contrast Source Inversion, Subspace-Optimization Method and their variants face a problem of getting trapped in false local minima when recovering objects with high permittivity. We propose a novel Convolutional Neural Network architecture, termed the Contrast Source Network, that learns the noise space components of the radiation operator. Together with the signal space components directly estimated from the data, we iteratively refine the solution and show convergence to the correct solution in cases where traditional techniques fail without any significant increase in computational time. We also propose a novel multi-resolution strategy that helps in producing high resolution solutions without any significant increase in computational costs. Through extensive numerical experiments, we demonstrate the ability to recover high permittivity objects which include homogeneous, heterogeneous, and lossy scatterers.","","","10.1109/TCI.2019.2915580","Science and Engineering Research Board; Indian Space Research Organisation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8709721","inverse scattering;contrast source inversion;subspace-based optimization;deep learning;convolutional neural networks","Inverse problems;Permittivity;Deep learning;Image reconstruction;Signal resolution;Iterative methods;Imaging","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Corn Plant Counting Using Deep Learning and UAV Images","B. T. Kitano; C. C. T. Mendes; A. R. Geus; H. C. Oliveira; J. R. Souza","Faculty of Computing, Federal University of Uberlêndia, Uberlêndia 38408-100, Brazil.; Faculty of Computing, Federal University of Uberlêndia, Uberlêndia 38408-100, Brazil.; Faculty of Computing, Federal University of Uberlêndia, Uberlêndia 38408-100, Brazil.; School of Civil Engineering, Architecture and Urban Planning, University of Campinas, Campinas 13083-970, Brazil.; Faculty of Computing, Federal University of Uberlêndia, Uberlêndia 38408-100, Brazil (e-mail: jrsouza@ufu.br).","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","The adoption of new technologies, such as unmanned aerial vehicles (UAVs), image processing, and machine learning, is disrupting traditional concepts in agriculture, with a new range of possibilities opening in its fields of research. Plant density is one of the most important corn (Zea mays L.) yield factors, yet its precise measurement after the emergence of plants is impractical in large-scale production fields due to the amount of labor required. This letter aims to develop techniques that enable corn plant counting and the automation of this process through deep learning and computational vision, using images of several corn crops obtained using a low-cost unmanned aerial vehicle (UAV) platform assembled with an RGB sensor.","","","10.1109/LGRS.2019.2930549","UNICAMP Federal University of Uberlêndia UFU; CNPq; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8792201","Deep learning (DL);plant counting;precision agriculture.","Agriculture;Computer architecture;Unmanned aerial vehicles;Training;Image segmentation;Deep learning;Cameras","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Discriminative Fisher Embedding Dictionary Learning Algorithm for Object Recognition","Z. Li; Z. Zhang; J. Qin; Z. Zhang; L. Shao","Industrial Training Center, Guangdong Polytechnic Normal University, Guangzhou 510665, China.; School of Information Technology and Electrical Engineering, The University of Queensland, Brisbane, QLD 4072, Australia (e-mail:darrenzz219@gmail.com).; Inception Institute of Artificial Intelligence, Abu Dhabi, United Arab Emirates.; School of Computer Science, Hefei University of Technology, Hefei, China, also with the School of Artificial Intelligence, Hefei University of Technology, Hefei, China, and also with the School of Computer Science, Soochow University, Suzhou, China; Inception Institute of Artificial Intelligence, Abu Dhabi, United Arab Emirates.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","15","Both interclass variances and intraclass similarities are crucial for improving the classification performance of discriminative dictionary learning (DDL) algorithms. However, existing DDL methods often ignore the combination between the interclass and intraclass properties of dictionary atoms and coding coefficients. To address this problem, in this paper, we propose a discriminative Fisher embedding dictionary learning (DFEDL) algorithm that simultaneously establishes Fisher embedding models on learned atoms and coefficients. Specifically, we first construct a discriminative Fisher atom embedding model by exploring the Fisher criterion of the atoms, which encourages the atoms of the same class to reconstruct the corresponding training samples as much as possible. At the same time, a discriminative Fisher coefficient embedding model is formulated by imposing the Fisher criterion on the profiles (row vectors of the coding coefficient matrix) and coding coefficients, which forces the coding coefficient matrix to become a block-diagonal matrix. Since the profiles can indicate which training samples are represented by the corresponding atoms, the proposed two discriminative Fisher embedding models can alternatively and interactively promote the discriminative capabilities of the learned dictionary and coding coefficients. The extensive experimental results demonstrate that the proposed DFEDL algorithm achieves superior performance in comparison with some state-of-the-art dictionary learning algorithms on both hand-crafted and deep learning-based features.","","","10.1109/TNNLS.2019.2910146","National Natural Science Foundation of China; Science and Technology Program of Guangzhou; Science and Technology Planning Project of Guangdong Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8703429","Analytical structure promotion;dictionary learning;discriminative embedding learning;Fisher criterion;sparse representation.","Dictionaries;Encoding;Training;Image coding;Image reconstruction;Dimensionality reduction","","","","2","","","","","","IEEE","IEEE Early Access Articles"
"Cross-Media Semantic Correlation Learning Based on Deep Hash Network and Semantic Expansion for Social Network Cross-Media Search","M. Liang; J. Du; C. Yang; Z. Xue; H. Li; F. Kou; Y. Geng","Beijing Key Laboratory of Intelligent Telecommunication Software and Multimedia, School of Computer Science, Beijing University of Posts and Telecommunications, Beijing 100876, China.; Beijing Key Laboratory of Intelligent Telecommunication Software and Multimedia, School of Computer Science, Beijing University of Posts and Telecommunications, Beijing 100876, China (e-mail: junpingdu@126.com).; Beijing Key Laboratory of Intelligent Telecommunication Software and Multimedia, School of Computer Science, Beijing University of Posts and Telecommunications, Beijing 100876, China.; Beijing Key Laboratory of Intelligent Telecommunication Software and Multimedia, School of Computer Science, Beijing University of Posts and Telecommunications, Beijing 100876, China.; Beijing Key Laboratory of Big Data Technology for Food Safety, Beijing Technology and Business University, Beijing 100048, China (e-mail: li_haisheng@163.com).; Beijing Key Laboratory of Intelligent Telecommunication Software and Multimedia, School of Computer Science, Beijing University of Posts and Telecommunications, Beijing 100876, China.; Beijing Key Laboratory of Intelligent Telecommunication Software and Multimedia, School of Computer Science, Beijing University of Posts and Telecommunications, Beijing 100876, China.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","15","Cross-media search from large-scale social network big data has become increasingly valuable in our daily life because it can support querying different data modalities. Deep hash networks have shown high potential in achieving efficient and effective cross-media search performance. However, due to the fact that social network data often exhibit text sparsity, diversity, and noise characteristics, the search performance of existing methods often degrades when dealing with this data. In order to address this problem, this article proposes a novel end-to-end cross-media semantic correlation learning model based on a deep hash network and semantic expansion for social network cross-media search (DHNS). The approach combines deep network feature learning and hash-code quantization learning for multimodal data into a unified optimization architecture, which successfully preserves both intramedia similarity and intermedia correlation, by minimizing both cross-media correlation loss and binary hash quantization loss. In addition, our approach realizes semantic relationship expansion by constructing the image-word relation graph and mining the potential semantic relationship between images and words, and obtaining the semantic embedding based on both internal graph deep walk and an external knowledge base. Experimental results demonstrate that DHNS yields better cross-media search performance on standard benchmarks.","","","10.1109/TNNLS.2019.2945567","National Natural Science Foundation of China; Science and Technology Major Project of Guangxi; Open Research Fund of Beijing Key Laboratory of Big Data Technology for Food Safety Beijing Technology and Business University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8931026","Cross-media search;cross-media semantic correlation learning;cross-media similarity calculation;deep hash network;semantic expansion.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Reinforcement Learning-Based Automatic Exploration for Navigation in Unknown Environment","H. Li; Q. Zhang; D. Zhao","State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China, and also with the School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing 100049, China.; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China, and also with the School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing 100049, China.; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China, and also with the School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing 100049, China (e-mail: dongbin.zhao@ia.ac.cn).","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","13","This paper investigates the automatic exploration problem under the unknown environment, which is the key point of applying the robotic system to some social tasks. The solution to this problem via stacking decision rules is impossible to cover various environments and sensor properties. Learning-based control methods are adaptive for these scenarios. However, these methods are damaged by low learning efficiency and awkward transferability from simulation to reality. In this paper, we construct a general exploration framework via decomposing the exploration process into the decision, planning, and mapping modules, which increases the modularity of the robotic system. Based on this framework, we propose a deep reinforcement learning-based decision algorithm that uses a deep neural network to learning exploration strategy from the partial map. The results show that this proposed algorithm has better learning efficiency and adaptability for unknown environments. In addition, we conduct the experiments on the physical robot, and the results suggest that the learned policy can be well transferred from simulation to the real robot.","","","10.1109/TNNLS.2019.2927869","Beijing Science and Technology Plan; National Natural Science Foundation of China NSFC; Noahs Ark Lab Huawei Technologies; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8789673","Automatic exploration;deep reinforcement learning (DRL);optimal decision;partial observation.","Robot sensing systems;Navigation;Entropy;Neural networks;Task analysis;Planning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep collaborative filtering for prediction of disease genes","X. Zeng; Y. Lin; Y. He; L. Lv; X. Min; A. Rodríguez-Paton","department of computer science, xiamen university, xiamen, fujian China (e-mail: xzeng@xmu.edu.cn); Department of Computer Science, Xiamen University, 12466 Xiamen, Fujian China (e-mail: 137655167@qq.com); Department of Computer Science, Xiamen University, xiamen, fujian China (e-mail: 597207374@qq.com); Alibaba Research Center for Complexity Sciences, Hangzhou Normal University, 26494 Hangzhou, Zhejiang China (e-mail: babyann519@hotmail.com); Computer Science, Xiamen University, 12466 Xiamen, Fujian China (e-mail: mxp@xmu.edu.cn); madrid, madrid Spain (e-mail: arpaton@fi.upm.es)","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2019","PP","99","1","1","Accurate prioritization of potential disease genes is a fundamental challenge in biomedical research. Various algorithms have been developed to solve such problems. Inductive Matrix Completion (IMC) is one of the most reliable models for its well established framework and its superior performance in predicting gene-disease associations. However, the IMC method does not hierarchically extract deep features, which might limit the quality of recovery. In this case, the architecture of deep learning, which obtains high-level representations and handles noises and outliers presented in large-scale biological datasets, is introduced into the side information of genes in our Deep Collaborative Filtering (DCF) model. Further, for lack of negative examples, we also exploit Positive-Unlabeled (PU) learning formulation to low-rank matrix completion.Our approach achieves substantially improved performance over other state-of-the-art methods on diseases from the Online Mendelian Inheritance in Man (OMIM) database. Our approach is 6% more efficient than standard IMC in detecting a true association, and significantly outperforms other alternatives in terms of the precision-recall metric at the top-k predictions. Moreover, we also validate the disease with no previously known gene associations and newly reported OMIM associations. The experimental results show that DCF is still satisfactory for ranking novel disease phenotypes as well as mining unexplored relationships. The source code and the data are available at https://github.com/xzenglab/Deep-Collaborative-Filtering.","","","10.1109/TCBB.2019.2907536","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8674571","Disease genes prediction;Data integration;Deep learning;PU learning;Matrix completion","Diseases;Collaboration;Biological system modeling;Loss measurement;Noise reduction;Feature extraction;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Interpretable Early Warning System for the Detection of Clinical Deterioration","F. E. Shamout; T. Zhu; P. Sharma; P. J. Watkinson; D. A. Clifton","Engineering Science, University of Oxford, Oxford, Oxfordshire United Kingdom of Great Britain and Northern Ireland OX13PJ (e-mail: farah.shamout@balliol.ox.ac.uk); University of Oxford, Oxford United Kingdom of Great Britain and Northern Ireland OX3 7DQ (e-mail: tingting.zhu@eng.ox.ac.uk); Dept of Engineering Science, Oxford United Kingdom of Great Britain and Northern Ireland OX3 7DQ (e-mail: pulkit.sharma@eng.ox.ac.uk); Nuffield Division of Anaesthetics, Nuffield Department of Clinical Neurosciences, University of Oxford, Oxford, Oxfordshire United Kingdom of Great Britain and Northern Ireland (e-mail: peter.watkinson@ndcn.ox.ac.uk); Dept. of Engineering Science, University of Oxford, Oxford United Kingdom of Great Britain and Northern Ireland OX3 7DQ (e-mail: davidc@robots.ox.ac.uk)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","Assessment of physiological instability preceding adverse events on hospital wards has been previously investigated through clinical early warning score systems. Early warning scores are simple to use yet they consider data as independent and identically distributed random variables. Deep learning applications are able to learn from sequential data, however they lack interpretability and are thus difficult to deploy in clinical settings. We propose the ‘Deep Early Warning System’ (DEWS), an interpretable end-to-end deep learning model that interpolates temporal data and predicts the probability of an adverse event, defined as the composite outcome of cardiac arrest, mortality or unplanned ICU admission. The model was developed and validated using routinely collected vital signs of patients admitted to the the Oxford University Hospitals between 21st March 2014 and 31st March 2018. We extracted 45,314 vital-sign measurements as a balanced training set and 359,481 vital-sign measurements as an imbalanced testing set to mimic a real-life setting of emergency admissions. DEWS achieved superior accuracy than the state-of-the-art that is currently implemented in clinical settings, the National Early Warning Score, in terms of the overall area under the receiver operating characteristic curve (AUROC) (0.880 vs. 0.866) and when evaluated independently for each of the three outcomes. Our attention-based architecture was able to recognize ‘historical’ trends in the data that are most correlated with the predicted probability. With high sensitivity, improved clinical utility and increased interpretability, our model can be easily deployed in clinical settings to supplement existing EWS systems.","","","10.1109/JBHI.2019.2937803","Health Innovation Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8844833","Early warning system;time-series data;data interpolation;supervised learning;deep learning","Ground penetrating radar;Microsoft Windows;Data models;Deep learning;Computational modeling;Informatics;Predictive models","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"DeepSCC: Deep Learning Based Fast Prediction Network for Screen Content Coding","W. Kuang; Y. Chan; S. Tsang; W. Siu","Department of Electronic and Information Engineering, The Hong Kong Polytechnic University, Hong Kong.; Department of Electronic and Information Engineering, The Hong Kong Polytechnic University, Hong Kong.; Department of Electronic and Information Engineering, The Hong Kong Polytechnic University, Hong Kong.; Department of Electronic and Information Engineering, The Hong Kong Polytechnic University, Hong Kong.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Screen Content Coding is an extension of High Efficiency Video Coding (HEVC), and it is developed to improve the coding efficiency of screen content videos by adopting two new coding modes, Intra Block Copy (IBC) and Palette (PLT). However, the flexible quadtree-based coding tree unit (CTU) partitioning structure and various mode candidates make the fast algorithms of SCC extremely challenging. To efficiently reduce the computational complexity of SCC, we propose a deep learning based fast prediction network DeepSCC, which contains two parts, DeepSCC-I and DeepSCC-II. Before fed to DeepSCC, incoming CUs are divided into two categories: dynamic CTUs and stationary CTUs. For dynamic CTUs having different content as their collocated CTUs, DeepSCC-I takes raw sample values as the input to make fast predictions. For stationary CTUs having the same content as their collocated CTUs, DeepSCC-II additionally utilizes the optimal mode maps of the stationary CTU to further reduce the computational complexity. Compared with the HEVCSCC reference software SCM-8.3, the proposed DeepSCC reduces encoding time by 48.81% on average with a negligible Bjxntegaard delta bitrate increase of 1.18% under all-intra configuration.","","","10.1109/TCSVT.2019.2929317","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8764598","Screen Content Coding (SCC);High Efficiency Video Coding (HEVC);fast algorithm;convolutional neural network;deep learning","Encoding;Copper;Partitioning algorithms;High efficiency video coding;Deep learning;Videos;Computational complexity","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Learning Approaches on Pedestrian Detection in Hazy Weather","G. Li; Y. Yang; X. Qu","Institute of Human Factors and Ergonomics, Shenzhen University, 47890 Shenzhen China (e-mail: hanshan198@gmail.com); Institute of Human Factors and Ergonomics, Shenzhen University, 47890 Shenzhen, Guangdong China (e-mail: lvan0619@qq.com); Institute of Human Factors and Ergonomics, Shenzhen University, 47890 Shenzhen, N/A China (e-mail: quxd@szu.edu.cn)","IEEE Transactions on Industrial Electronics","","2019","PP","99","1","1","Effectively detecting pedestrians in various environments would significantly improve driving safety for autonomous vehicles. However, the degraded visibility and blurred outline and appearance of pedestrian images captured during hazy weather strongly limit the effectiveness of current pedestrian detection methods. To solve this problem, this paper presents three novel deep learning approaches based on Yolo. The depthwise separable convolution and linear bottleneck skills were used to reduce the computational cost and number of parameters, rendering our network more efficient. We also innovatively developed a weighted combination layer in one of the approaches by combining multi-scale feature maps and a squeeze and excitation block. Collected pedestrian images in hazy weather were augmented using six strategies to enrich the database. Experimental results show that our proposed methods can effectively detect pedestrians in hazy weather, significantly outperforming state-of-the-art methods in both accuracy and speed.","","","10.1109/TIE.2019.2945295","Natural Science Foundation of Guangdong Province; National Natural Science Foundation of China; Young Elite Scientists Sponsorship Program by China Society of Automotive Engineers; State Key Laboratory of Automotive Safety and Energy; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8880634","Driver assistance systems;driving safety;pedestrian detection;deep learning;hazy weather","Convolution;Meteorology;Safety;Computational efficiency;Computer architecture;Computational modeling;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Fast Beamforming Design via Deep Learning","H. Huang; Y. Peng; J. Yang; W. Xia; G. Gui","Information and Communication Engineering, Nanjing University of Posts and Telecommunications, 12577 Nanjing, Jiangsu China 210003 (e-mail: 1017010502@njupt.edu.cn); Information and Communication Engineering, Nanjing University of Posts and Telecommunications, 12577 Nanjing, Jiangsu China (e-mail: 791212170@qq.com); School of Communication and Information Engineering, Nanjing University of Posts and Telecommunications, Nanjing, Jiangsu China (e-mail: jyang@njupt.edu.cn); College of Telecommunications and Information Engineering, Nanjing University of Posts and Telecommunications, 12577 Nanjing, Jiangsu China 210003 (e-mail: 2015010203@njupt.edu.cn); Information and Communication Engineering, Nanjing University of Posts and Telecommunications, 12577 Nanjing, Jiangsu China (e-mail: guiguan@njupt.edu.cn)","IEEE Transactions on Vehicular Technology","","2019","PP","99","1","1","Beamforming is considered one of the most important techniques for designing advanced multiple-input and multiple-output (MIMO) systems. Among these design criterions, sum rate maximization (SRM) under a total power constraint is a challenge issue due to its nonconvexity. Existing techniques for the SRM problem only obtain suboptimal solutions but require huge amount of computation due to their complex matrix operation and iterations. Unlike these conventional methods, we propose a deep learning based fast beamforming design method without complex matrix operation and iterations. Specifically, we first derive a heuristic solution structure of the downlink beamforming through the virtual equivalent uplink channel based on optimum MMSE receiver which separates the problem into power allocation and virtual uplink beamforming (VUB) design. Next, beamforming prediction network (BPNet) is designed to perform the joint optimization of power allocation and VUB. Moreover, the BPNet is trained offline using two-step training strategy. Simulation results demonstrate that our proposed method is fast while obtains the comparable performance to the state-of-the-art method.","","","10.1109/TVT.2019.2949122","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8880526","Beamforming design;sum rate maximization;deep learning;beamforming prediction network","Array signal processing;Uplink;Downlink;Resource management;Deep learning;MIMO communication;Optimization","","","","3","","","","","","IEEE","IEEE Early Access Articles"
"Deep Learning for Video Game Playing","N. Justesen; P. Bontrager; J. Togelius; S. Risi","Center for Computer Games Research, IT-Universitetet i Kobenhavn, 100335 Kobenhavn S, Denmark (e-mail: njustesen@gmail.com); Computer Science and Engineering, New York University, New York, New York United States (e-mail: philipjb@nyu.edu); Computer Science and Engineering, New York University, New York, New York United States 11201 (e-mail: julian@togelius.com); Center for Computer Games Research, IT University of Copenhagen, Copenhagen Denmark 2300 (e-mail: sebastian.risi@gmail.com)","IEEE Transactions on Games","","2019","PP","99","1","1","In this article, we review recent Deep Learning advances in the context of how they have been applied to play different types of video games such as first-person shooters, arcade games, and real-time strategy games. We analyze the unique requirements that different game genres pose to a deep learning system and highlight important open challenges in the context of applying these machine learning methods to video games, such as general game playing, dealing with extremely large decision spaces and sparse rewards.","","","10.1109/TG.2019.2896986","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8632747","","Games;Deep learning;Neural networks;Reinforcement learning;Mathematical model;Unsupervised learning","","","","5","","","","","","IEEE","IEEE Early Access Articles"
"Distributed Deep Learning Model for Intelligent Video Surveillance Systems with Edge Computing","J. Chen; K. Li; Q. Deng; K. Li; P. S. Yu","College of Computer Science and Electronic Engineering, Hunan University, 12569 Changsha, Hunan China 410082 (e-mail: cccjianguo@163.com); College of Computer Science and Electronic Engineering, Hunan University, 12569 Changsha, Hunan China 410082 (e-mail: lkl@hnu.edu.cn); School of Mathematics and Computational Science, Xiangtan University, 12665 Xiangtan, Hunan China 411105 (e-mail: qingying@xtu.edu.cn); Department of Computer Science, SUNY New Paltz, 14821 New Paltz, New York United States 12561-2443 (e-mail: lik@newpaltz.edu); University of Illinois at Chicago, 14681 Chicago, Illinois United States 60607-7101 (e-mail: psyu@uic.edu)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","In this paper, we propose a Distributed Intelligent Video Surveillance (DIVS) system using Deep Learning (DL) algorithms and deploy it in an edge computing environment. We establish a multi-layer edge computing architecture and a distributed DL training model for the DIVS system. The DIVS system can migrate computing workloads from the network center to network edges to reduce huge network communication overhead and provide low-latency and accurate video analysis solutions. We implement the proposed DIVS system and address the problems of parallel training, model synchronization, and workload balancing. Task-level parallel and model-level parallel training methods are proposed to further accelerate the video analysis process. In addition, we propose a model parameter updating method to achieve model synchronization of the global DL model in a distributed EC environment. Moreover, a dynamic data migration approach is proposed to address the imbalance of workload and computational power of edge nodes. Experimental results showed that the EC architecture can provide elastic and scalable computing power, and the proposed DIVS system can efficiently handle video surveillance and analysis tasks.","","","10.1109/TII.2019.2909473","National Science Foundation; National Natural Science Foundation of China; National Key R and D Program of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8681645","Edge computing;edge artificial intelligence;video surveillance;deep learning;neural network","Computational modeling;Monitoring;Streaming media;Edge computing;Training;Task analysis;Deep learning","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Exploiting Error-Correction-CRC for Polar SCL Decoding: A Deep Learning Based Approach","X. Liu; S. Wu; Y. Wang; N. Zhang; J. Jiao; Q. Zhang","Harbin Institute of Technology (Shenzhen), Guangdong 518055, China.; Harbin Institute of Technology (Shenzhen), Guangdong 518055, China.; Harbin Institute of Technology (Shenzhen), Guangdong 518055, China.; Texas A&M University, Corpus Christi, TX, USA.; Harbin Institute of Technology (Shenzhen), Guangdong 518055, China.; Harbin Institute of Technology (Shenzhen), Guangdong 518055, China.","IEEE Transactions on Cognitive Communications and Networking","","2019","PP","99","1","1","We investigate the cyclic redundancy check (CRC) codes aided successive cancellation list (SCL) decoding schemes to improve the performance of Polar codes. Distinguished from the existing literatures of Polar codes that only consider the error detection capability of CRC, we attempt to take advantage of the inherent error correction capability of CRC and we first devise a segmented CRC-error-correcting aided SCL decoding (SCC-SCL) framework. Based on this framework, an error-correcting table based SCC-SCL (ET-SCC-SCL) decoding scheme is proposed, by introducing the look-up-table based CRC error correction method into the segmented Polar SCL decoding process. Since the error correction capability is limited by the size of the look-up table, which in turn limits the performance gain, we further propose a deep learning based SCC-SCL (DL-SCC-SCL) decoding scheme. In this scheme, a long short-term memory (LSTM) network replaces the error correction table to perform error correction, combining the sequence of log likelihood ratios (LLRs) with the syndromes to determine the error patterns. Simulation results show that both of the proposed decoding schemes have significant performance gain over the classic CRC error-detection aided SCL decoding scheme. Especially for the DL-SCC-SCL, the performance gain at bit error rate of 10-5 is about 0.5 dB.","","","10.1109/TCCN.2019.2946358","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8863406","Polar codes;successive cancellation list decoding;CRC;error correction;deep learning.","Decoding;Error correction;Deep learning;Error correction codes;Cyclic redundancy check codes;Performance gain","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Semisupervised Recurrent Convolutional Attention Model for Human Activity Recognition","K. Chen; L. Yao; D. Zhang; X. Wang; X. Chang; F. Nie","School of Computer Science and Engineering, University of New South Wales, Sydney, NSW 2052, Australia (e-mail: kaixuan.chen@student.unsw.edu.au).; School of Computer Science and Engineering, University of New South Wales, Sydney, NSW 2052, Australia.; School of Computer Science and Engineering, University of New South Wales, Sydney, NSW 2052, Australia.; School of Computer Science, University of Technology Sydney, Sydney, NSW 2007, Australia.; Faculty of Information Technology, Monash University, Clayton, VIC 3800, Australia.; School of Computer Science, Northwestern Polytechnical University, Xi'an 710072, China, and also with the Center for OPTical IMagery Analysis and Learning (OPTIMAL), Northwestern Polytechnical University, Xi'an 710072, China.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","10","Recent years have witnessed the success of deep learning methods in human activity recognition (HAR). The longstanding shortage of labeled activity data inherently calls for a plethora of semisupervised learning methods, and one of the most challenging and common issues with semisupervised learning is the imbalanced distribution of labeled data over classes. Although the problem has long existed in broad real-world HAR applications, it is rarely explored in the literature. In this paper, we propose a semisupervised deep model for imbalanced activity recognition from multimodal wearable sensory data. We aim to address not only the challenges of multimodal sensor data (e.g., interperson variability and interclass similarity) but also the limited labeled data and class-imbalance issues simultaneously. In particular, we propose a pattern-balanced semisupervised framework to extract and preserve diverse latent patterns of activities. Furthermore, we exploit the independence of multi-modalities of sensory data and attentively identify salient regions that are indicative of human activities from inputs by our recurrent convolutional attention networks. Our experimental results demonstrate that the proposed model achieves a competitive performance compared to a multitude of state-of-the-art methods, both semisupervised and supervised ones, with 10% labeled training data. The results also show the robustness of our method over imbalanced, small training data sets.","","","10.1109/TNNLS.2019.2927224","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8767027","Attention;class imbalance;human activity recognition (HAR);semisupervised learning.","Training;Data models;Semisupervised learning;Training data;Labeling;Activity recognition;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Hyperspectral Pansharpening With Deep Priors","W. Xie; J. Lei; Y. Cui; Y. Li; Q. Du","State Key Laboratory of Integrated Service Networks, Xidian University, Xi'an 710071, China.; State Key Laboratory of Integrated Service Networks, Xidian University, Xi'an 710071, China (e-mail:jielei@mail.xidian.edu.cn).; State Key Laboratory of Integrated Service Networks, Xidian University, Xi'an 710071, China.; State Key Laboratory of Integrated Service Networks, Xidian University, Xi'an 710071, China (e-mail:ysli@mail.xidian.edu.cn).; Department of Electronic and Computer Engineering, Mississippi State University, Starkville, MS 39759 USA.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","15","Hyperspectral (HS) image can describe subtle differences in the spectral signatures of materials, but it has low spatial resolution limited by the existing technical and budget constraints. In this paper, we propose a promising HS pansharpening method with deep priors (HPDP) to fuse a low-resolution (LR) HS image with a high-resolution (HR) panchromatic (PAN) image. Different from the existing methods, we redefine the spectral response function (SRF) based on the larger eigenvalue of structure tensor (ST) matrix for the first time that is more in line with the characteristics of HS imaging. Then, we introduce HFNet to capture deep residual mapping of high frequency across the upsampled HS image and the PAN image in a band-by-band manner. Specifically, the learned residual mapping of high frequency is injected into the structural transformed HS images, which are the extracted deep priors served as additional constraint in a Sylvester equation to estimate the final HR HS image. Comparative analyses validate that the proposed HPDP method presents the superior pansharpening performance by ensuring higher quality both in spatial and spectral domains for all types of data sets. In addition, the HFNet is trained in the high-frequency domain based on multispectral (MS) images, which overcomes the sensitivity of deep neural network (DNN) to data sets acquired by different sensors and the difficulty of insufficient training samples for HS pansharpening.","","","10.1109/TNNLS.2019.2920857","National Natural Science Foundation of China; Young Talent fund of University Association for Science and Technology in Shaanxi of China; Special Financial Grant from the China Postdoctoral Science Foundation; 111 project; Fundamental Research Funds for the Central Universities; Natural Science Basic Research Plan in Shaanxi Province of China; General Financial Grant from the China Postdoctoral Science Foundation; Yangtse Rive Scholar Bonus Schemes; Ten Thousand Talent Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8750899","Deep priors;high frequency;hyperspectral (HS) pansharpening;structure tensor (ST);sylvester equation.","Bayes methods;Hyperspectral sensors;High frequency;Spatial resolution;Fuses;Imaging","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Virtual Reality Image Quality Assessment with Human Perception Guider for Omnidirectional Image","H. G. Kim; H. Lim; Y. M. Ro","Image and Video Systems Lab., School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), 291 Daehak-ro, Yuseong-gu, Daejeon, 34141, Republic of Korea.; Image and Video Systems Lab., School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), 291 Daehak-ro, Yuseong-gu, Daejeon, 34141, Republic of Korea.; Image and Video Systems Lab., School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), 291 Daehak-ro, Yuseong-gu, Daejeon, 34141, Republic of Korea.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","In this paper, we propose a novel deep learningbased virtual reality image quality assessment method that automatically predicts the visual quality of an omnidirectional image. In order to assess the visual quality in viewing the omnidirectional image, we propose deep networks consisting of VR quality score predictor and human perception guider. The proposed VR quality score predictor learns the positional and visual characteristics of the omnidirectional image by encoding the positional feature and visual feature of a patch on the omnidirectional image. With the encoded positional feature and visual feature, patch weight and patch quality score are estimated. Then, by aggregating all weights and scores of patches, the image quality score is predicted. The proposed human perception guider evaluates the predicted quality score by referring to the human subjective score (i.e., ground-truth obtained by subjects) using an adversarial learning. With adversarial learning, the VR quality score predictor is trained to accurately predict the quality score in order to deceive the guider while the proposed human perception guider is trained to precisely distinguish between the predictor score and the ground-truth subjective score. To verify the performance of the proposed method, we conducted comprehensive subjective experiments and evaluated the performance of the proposed method. Experimental results show that the proposed method outperforms the existing 2- D image quality models and the state-of-the-art image quality models for omnidirectional images.","","","10.1109/TCSVT.2019.2898732","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8638985","Adversarial learning;deep learning;omnidirectional image;quality assessment;virtual reality","Visualization;Image quality;Measurement;Image coding;Distortion;Deep learning;Quality assessment","","","","3","","","","","","IEEE","IEEE Early Access Articles"
"Weakly Supervised Deep Learning for Whole Slide Lung Cancer Image Analysis","X. Wang; H. Chen; C. Gan; H. Lin; Q. Dou; E. Tsougenis; Q. Huang; M. Cai; P. Heng","Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China.; Department of AI Image Research, Imsight Medical Technology Company Ltd., Shenzhen 518057, China (e-mail: hchen@cse.cuhk.edu.hk).; Hexian Memorial Hospital, Southern Medical University, Guangzhou 511400, China.; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China.; Department of Computing, Imperial College London, London SW7 2AZ, U.K.; Department of AI Image Research, Imsight Medical Technology Company Ltd., Shenzhen 518057, China; State Key Laboratory of Oncology in South China, Collaborative Innovation Center for Cancer Medicine, Sun Yat-sen University Cancer Center, Guangzhou 510060, China.; State Key Laboratory of Oncology in South China, Collaborative Innovation Center for Cancer Medicine, Sun Yat-sen University Cancer Center, Guangzhou 510060, China (e-mail: caimy@sysucc.org.cn).; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, China and also with the Guangdong Provincial Key Laboratory of Computer Vision and Virtual Reality Technology, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen 518055, China.","IEEE Transactions on Cybernetics","","2019","PP","99","1","13","Histopathology image analysis serves as the gold standard for cancer diagnosis. Efficient and precise diagnosis is quite critical for the subsequent therapeutic treatment of patients. So far, computer-aided diagnosis has not been widely applied in pathological field yet as currently well-addressed tasks are only the tip of the iceberg. Whole slide image (WSI) classification is a quite challenging problem. First, the scarcity of annotations heavily impedes the pace of developing effective approaches. Pixelwise delineated annotations on WSIs are time consuming and tedious, which poses difficulties in building a large-scale training dataset. In addition, a variety of heterogeneous patterns of tumor existing in high magnification field are actually the major obstacle. Furthermore, a gigapixel scale WSI cannot be directly analyzed due to the immeasurable computational cost. How to design the weakly supervised learning methods to maximize the use of available WSI-level labels that can be readily obtained in clinical practice is quite appealing. To overcome these challenges, we present a weakly supervised approach in this article for fast and effective classification on the whole slide lung cancer images. Our method first takes advantage of a patch-based fully convolutional network (FCN) to retrieve discriminative blocks and provides representative deep features with high efficiency. Then, different context-aware block selection and feature aggregation strategies are explored to generate globally holistic WSI descriptor which is ultimately fed into a random forest (RF) classifier for the image-level prediction. To the best of our knowledge, this is the first study to exploit the potential of image-level labels along with some coarse annotations for weakly supervised learning. A large-scale lung cancer WSI dataset is constructed in this article for evaluation, which validates the effectiveness and feasibility of the proposed method. Extensive experiments demonstrate the superior performance of our method that surpasses the state-of-the-art approaches by a significant margin with an accuracy of 97.3% . In addition, our method also achieves the best performance on the public lung cancer WSIs dataset from The Cancer Genome Atlas (TCGA). We highlight that a small number of coarse annotations can contribute to further accuracy improvement. We believe that weakly supervised learning methods have great potential to assist pathologists in histology image diagnosis in the near future.","","","10.1109/TCYB.2019.2935141","Hong Kong Innovation and Technology Commission through ITSP Tier 3; ITSP Tier 2 Platform; National Natural Science Foundation of China; Shenzhen Science and Technology Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8822590","Deep learning;histology image analysis;weakly supervised learning;whole slide images (WSIs)","Cancer;Lung;Feature extraction;Tumors;Task analysis;Supervised learning;Image analysis","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Spiking Neural Network for Video-Based Disguise Face Recognition Based on Dynamic Facial Movements","D. Liu; N. Bellotto; S. Yue","School of Computer Science, University of Lincoln, Lincoln LN6 7TS, U.K. He is now with the Center for Vision, Speech and Signal Processing, University of Surrey, Guildford GU2 7XH, U.K..; School of Computer Science, University of Lincoln, Lincoln LN6 7TS, U.K..; Machine Life and Intelligence Research Center, Guangzhou University, Guangzhou 510006, China, also with the School of Mechanical and Electronic Engineering, Guangzhou University, Guangzhou 510006, China, and also with the School of Computer Science, University of Lincoln, Lincoln LN6 7TS, U.K. (e-mail: syue@lincoln.ac.uk).","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","10","With the increasing popularity of social media and smart devices, the face as one of the key biometrics becomes vital for person identification. Among those face recognition algorithms, video-based face recognition methods could make use of both temporal and spatial information just as humans do to achieve better classification performance. However, they cannot identify individuals when certain key facial areas, such as eyes or nose, are disguised by heavy makeup or rubber/digital masks. To this end, we propose a novel deep spiking neural network architecture in this paper. It takes dynamic facial movements, the facial muscle changes induced by speaking or other activities, as the sole input. An event-driven continuous spike-timing-dependent plasticity learning rule with adaptive thresholding is applied to train the synaptic weights. The experiments on our proposed video-based disguise face database (MakeFace DB) demonstrate that the proposed learning method performs very well, i.e., it achieves from 95% to 100% correct classification rates under various realistic experimental scenarios.","","","10.1109/TNNLS.2019.2927274","EU Horizon 2020 through the project STEP2DYNA; project ENRICHME; ULTRACEPT; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8767026","Continuous learning;deep learning;event-driven spike-timing-dependent plasticity (STDP);spiking neural network (SNN);video-based disguise face recognition (VDFR).","Feature extraction;Face recognition;Learning systems;Computational modeling;Brain modeling;Facial muscles","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Incremental Deep Computation Model for Wireless Big Data Feature Learning","Q. Zhang; L. T. Yang; Z. Chen; P. Li","Computer Science, St. Francis Xavier University, Antigonish, Nova Scotia Canada (e-mail: qzhang@stfx.ca); Computer Science, St Francis Xavier University, Antigonish, Nova Scotia Canada (e-mail: ltyang@gmail.com); software school, Network communications and database technology, Dalian, Liaoning Province China 116620 (e-mail: zkchen@dlut.edu.cn); School of Software Technology, Dalian University of Technology, 12399 Dalian, Liaoning China (e-mail: lipeng2015@mail.dlut.edu.cn)","IEEE Transactions on Big Data","","2019","PP","99","1","1","Big data feature learning is a crucial issue for the service management for Internet of Things. However, big data collected from Internet of Things is of dynamic nature at a high speed, which poses an important challenge on wireless big data learning models, especially the deep computation model. In this paper, an incremental deep computation model is proposed for wireless big data feature learning in Internet of Things. First, two incremental tensor auto-encoders (ITAE) are developed by devising two incremental learning algorithms, namely parameter-based incremental learning algorithm (PI-TAE) and structure-based incremental learning algorithm (SI-TAE), when new wireless samples are available. PI-TAE only updates the network parameters while SI-TAE simultaneously adjusts the structure and updates the parameters to adapt to the new arriving wireless big data. Furthermore, an incremental deep computation model is constructed by stacking several ITAEs. Experiments are conducted to evaluate the performance of the proposed model by comparing with the conventional deep computation model and other two representative incremental learning algorithms, i.e., OANN and PIE. Results demonstrate that the presented model can modify the network in an incremental manner for new arriving data learning efficiently with preserving the prior knowledge for the previous data learning, proving its potential for dynamic wireless big data learning in Internet of Things.","","","10.1109/TBDATA.2019.2903092","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8660496","wireless big data;deep computation model;parameter-based incremental learning;structure-based incremental learning","Computational modeling;Big Data;Data models;Wireless communication;Adaptation models;Internet of Things","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Discriminative Representation Learning for Nonlinear Process Fault Detection","Q. Jiang; X. Yan; B. Huang","Key Laboratory of Advanced Control and Optimization for Chemical Processes, Ministry of Education, East China University of Science and Technology, Shanghai 200237, China, and also with the Shanghai Institute of Intelligent Science and Technology, Tongji University, Shanghai 200092, China.; Key Laboratory of Advanced Control and Optimization for Chemical Processes, Ministry of Education, East China University of Science and Technology, Shanghai 200237, China, and also with the Shanghai Institute of Intelligent Science and Technology, Tongji University, Shanghai 200092, China (e-mail: xfyan@ecust.edu.cn).; Department of Chemical and Materials Engineering, University of Alberta, Edmonton, AB T6G 2V4, Canada (e-mail: bhuang@ualberta.ca).","IEEE Transactions on Automation Science and Engineering","","2019","PP","99","1","10","Nonlinear process fault detection remains a challenge, with representation learning being a key step. In this article, a deep neural network (DNN)-based discriminative representation learning approach is proposed to achieve efficient fault detection for nonlinear plant-wide processes. An early-stage fault rarely affects several independent variables concurrently; hence, mutual information-based block division and randomized fault construction are performed to generate faulty validation data. By using the training data from the normal operation training data and the constructed validation data, a DNN with stacked autoencoders and a softmax classifier is trained to generate discriminative representations that maximize the capability of discriminating normal and abnormal statuses. Finally, on the basis of the learned deep discriminative representations, support vector data description is employed to discriminate the normal and abnormal process statuses. The proposed monitoring approach is tested on a numerical example and an industrial tail-gas treatment process, through which the efficiency is verified.","","","10.1109/TASE.2019.2956087","National Natural Science Foundation of China; Shanghai Pujiang Program; Fundamental Research Funds for the Central Universities; Program of Introducing Talents of Discipline to Universities the 111 Project; Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8941028","Deep neural network (DNN);discriminative representations;fault detection;nonlinear process monitoring.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Machine Learning System for Precipitation Estimation Using Satellite and Ground Radar Network Observations","H. Chen; V. Chandrasekar; R. Cifelli; P. Xie","Physical Sciences Division (PSD), National Oceanic and Atmospheric Administration (NOAA)'s Earth System Research Laboratory, Boulder, CO 80305 USA, and also with the Cooperative Institute for Research in the Atmosphere (CIRA), Fort Collins, CO 80523 USA (e-mail: haonan.chen@noaa.gov).; Department of Electrical and Computer Engineering, Colorado State University, Fort Collins, CO 80523 USA.; Physical Sciences Division (PSD), National Oceanic and Atmospheric Administration (NOAA)'s Earth System Research Laboratory, Boulder, CO 80305 USA.; National Oceanic and Atmospheric Administration (NOAA)' Climate Prediction Center, College Park, MD 20740 USA.","IEEE Transactions on Geoscience and Remote Sensing","","2019","PP","99","1","13","Space-based precipitation products are often used for regional and/or global hydrologic modeling and climate studies. A number of precipitation products at multiple space and time scales have been developed based on satellite observations. However, their accuracy is limited due to the restrictions on spatiotemporal sampling of the satellite sensors and the applied parametric retrieval algorithms. Similarly, a ground-based weather radar is widely used for quantitative precipitation estimation (QPE), especially after the implementation of dual-polarization capability and urban scale deployment of high-resolution X-band radar networks. Ground-based radars are often used for the validation of various spaceborne measurements and products. This article introduces a novel machine learning-based data fusion framework to improve the satellite-based precipitation retrievals by incorporating dual-polarization measurements from a ground radar network. The prototype architecture of this fusion system is detailed. In particular, a deep learning multi-layer perceptron (MLP) model is designed to produce the rainfall estimates using the geostationary satellite infrared (IR) data and low earth orbit satellite passive microwave (PMW)-based retrievals as inputs. The high-quality rainfall products from the ground radar network are used as the target labels to train this MLP model. An urban scale demonstration study over the Dallas-Fort Worth (DFW) metroplex is presented. In addition, the Climate Prediction Center morphing technique (i.e., CMORPH) is adopted for preprocessing of the satellite observations. Rainfall products from this deep learning system are evaluated using the standard CMORPH products. The results show that the proposed data fusion framework can be used for generating accurate precipitation estimates and could be considered as an alternative tool for developing future satellite retrieval algorithms.","","","10.1109/TGRS.2019.2942280","National Science Foundation NSF Hazards SEES Program; NASA Global Precipitation Measurement GPM Precipitation Measurement Mission PMM Program; Physical Sciences Division PSD NOAAs Earth System Research Laboratory ESRL; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8861302","CMORPH;Dallas-Fort Worth (DFW);deep learning;dual polarization;quantitative precipitation estimation (QPE);radar network;satellite observations.","Satellites;Spaceborne radar;Meteorology;Extraterrestrial measurements;Sea measurements;Machine learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Progressive Transfer Learning and Adversarial Domain Adaptation for Cross-Domain Skin Disease Classification","Y. Gu; Z. Ge; C. P. Bonnington; J. Zhou","School of Information and Communication Technology, Griffith University, 5723 Nathan Australia 4111 (e-mail: yanyang.gu@griffithuni.edu.au); Faculty of Engineering, Monash University, 2541 Clayton, Victoria Australia (e-mail: zongyuan.ge@monash.edu.au); Faculty of Engineering, Monash University, 2541 Clayton, Victoria Australia (e-mail: Paul.Bonnington@monash.edu); School of Information and Communication Technology, Griffith University, 5723 Nathan, Queensland Australia (e-mail: jun.zhou@griffith.edu.au)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","Deep learning has been used to analyze and diag-nose various skin diseases through medical imaging. However,recent researches show that a well trained deep learning modelmay not generalize well to data from different cohorts due todomain shift. Simple data fusion techniques such as combiningdisease samples from different data sources are not effective tosolve this problem. In this paper, we present two methods for anovel task of cross-domain skin disease recognition. Starting froma fully supervised deep convolutional neural network classifierpre-trained on ImageNet, we explore a two-step progressivetransfer learning technique by fine-tuning the network on twoskin disease datasets. We then propose to adopt adversariallearning as a domain adaptation technique to perform invariantattribute translation from source to target domain in orderto improve the recognition performance. In order to evaluatethese two methods, we analyze generalization capability of thetrained model on melanoma detection, cancer detection andcross-modality learning tasks on two skin image datasets collectedfrom different clinical settings and cohorts with different diseasedistributions. The experiments prove the effectiveness of ourmethod in solving the domain shift problem.","","","10.1109/JBHI.2019.2942429","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8846038","Automatic melanoma detection;dermoscopy image;cycle-GAN;deep learning;transfer learning;domain adaptation","Skin;Adaptation models;Melanoma;Deep learning;Data models","","","","","","","","","","IEEE","IEEE Early Access Articles"
"The Heterogeneous Deep Neural Network Processor With a Non-von Neumann Architecture","D. Shin; H. Yoo","School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon 34141, South Korea.; School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon 34141, South Korea (e-mail: hjyoo@kaist.ac.kr).","Proceedings of the IEEE","","2019","PP","99","1","16","Today's CPUs are general-purpose processors, which have the von Neumann architecture (including the Harvard architectures) to maximize the generality and programmability. On the other hand, application-specific integrated circuits (ASICs) have domain-specific architectures to optimize the cost-effective performance but show very low generality. The combination of generality and ASIC, which usually seemed to have no contact, is expected to be enabled by deep learning (DL). DL, realized with deep neural networks (DNNs), has changed the paradigm of machine learning (ML) and brought significant progress in vision, speech, language processing, and many other applications. DNNs have special features that can be efficiently implemented with dedicated architectures, ASICs. Sharing their special features, DNNs have a wide variety of network architectures, and even the same network architecture can be used for different applications depending on the weight parameters. This paper aims to provide the necessity, validity, and characteristics of the ML-specific integrated circuits (MSICs) that have a different architecture from the von Neumann architecture. MSICs can avoid the overhead from the complex instruction set, instruction decoder, multilevel caches, and branch prediction of the recent von Neumann architecture processors designed for high generality and programmability. We will also discuss the necessity and validity of a heterogeneous architecture in MSIC, starting from the differences between the visual-type information processing and the vector-type information processing, and show the chip implementation results.","","","10.1109/JPROC.2019.2897076","National Research Foundation of Korea Ministry of Science ICT and Future Planning through the Basic Science Research Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8653908","Application-specific integrated circuit (ASIC);convolutional neural networks (CNNs);deep learning (DL);heterogeneous architecture;machine learning (ML);multilayer perceptrons (MLPs);neural network hardware;neural networks;non-von Neumann architecture;recurrent neural networks (RNNs)","Computer architecture;Hardware;Biological neural networks;Computers;Recurrent neural networks;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Exploration of Chinese Sign Language Recognition Using Wearable Sensors Based on Deep Belief Net","Y. Yu; X. Chen; S. Cao; X. Zhang; X. Chen","Hefei China 230027 (e-mail: yyu309@mail.ustc.edu.cn); Department of Electronic Science &Technology, University of Science & Technology of China, Hefei China 230026 (e-mail: xch@ustc.edu.cn); Institute of Biomedical Engineering, University of Science & Technology of China, Hefei China (e-mail: caoshuai@ustc.edu.cn); Department of Electronic Science & Technology, University of Science & Technology of China, Hefei, Anhui China 230027 (e-mail: xuzhang90@ustc.edu.cn); University of Science and Technology of China, Hefei China (e-mail: xunchen@ustc.edu.cn)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","In this paper, deep belief net (DBN) was applied into the field of wearable-sensor based Chinese Sign Language (CSL) recognition. Eight subjects were involved in the study, and all of the subjects finished a five-day experiment performing CSL on a target word set consisting of 150 CSL subwords. During the experiment, surface electromyography (sEMG), accelerometer (ACC), and gyroscope (GYRO) signals were collected from the participants. In order to obtain the optimal structure of the network, three different sensor fusion strategies, including data-level fusion, feature-level fusion, and decision-level fusion, were explored. In addition, for the feature-level fusion strategy, two different feature sources, which are hand-crafted features and network generated features, and two different network structures, which are fully-connected net and DBN, were also compared. The result showed that feature level fusion could achieve the best recognition accuracy among the three fusion strategies, and feature-level fusion with network generated features and DBN could achieve the best recognition accuracy. The best recognition accuracy realized in this study was 95.1% for the user-dependent test and 88.2% for the user-independent test. The significance of the study is that it applied the deep learning method into the field of wearable sensors-based CSL recognition, and according to our knowledge it's the first study comparing human engineered features with the network generated features in the correspondent field. The results from the study shed lights on the method of using network-generated features during sensor fusion and CSL recognition.","","","10.1109/JBHI.2019.2941535","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8839065","Chinese Sign Language;wearable sensors;electromyography;gyroscope;accelerometer;sensor fusion;deep learning;deep belief net","Feature extraction;Deep learning;Assistive technology;Gesture recognition;Training;Muscles;Electromyography","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Attention-Based Deep Ensemble Net for Large-Scale Online Taxi-Hailing Demand Prediction","Y. Liu; Z. Liu; C. Lyu; J. Ye","Jiangsu Key Laboratory of Urban ITS, Jiangsu Province Collaborative Innovation Center of Modern Urban Traffic Technologies, School of Transportation, Southeast University, Nanjing 210096, China.; Jiangsu Key Laboratory of Urban ITS, Jiangsu Province Collaborative Innovation Center of Modern Urban Traffic Technologies, School of Transportation, Southeast University, Nanjing 210096, China (e-mail: zhiyuanl@seu.edu.cn).; Jiangsu Provincial Key Laboratory of Networked Collective Intelligence, School of Mathematics, and School of Transportation, Southeast University, Nanjing 210096, China.; Didi Research Institute, Didi Chuxing, Beijing 100193, China.","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","10","How to effectively ensemble different base models is a challenging but extremely valuable task. This study focuses on the construction of an ensemble framework designed for spatio-temporal data to predict large-scale online taxi-hailing demand, where an attention-based deep ensemble net is designed to enhance the prediction accuracy. We present three attention blocks to model the inter-channel relationship, inter-spatial relationship and position relationship of the feature maps. Then, the attention maps can be multiplied by the input feature map for adaptive feature refinement. The proposed method is a kind of commonly used ensemble method which applies to large-scale spatio-temporal prediction. Experimental results on city-wide online taxi-hailing demand predictions demonstrate that our proposed attention-based ensemble net is superior to the existing ensemble strategy in terms of the prediction accuracy.","","","10.1109/TITS.2019.2947145","General Projects; Key Projects of the National Natural Science Foundation of China; Jiangsu Provincial Key Laboratory of Networked Collective Intelligence; Postgraduate Research and Practice Innovation Program of Jiangsu Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8880638","Ensemble learning;attention mechanism;demand prediction.","Predictive models;Public transportation;Task analysis;Deep learning;Forecasting;Neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Toward Greater Intelligence in Route Planning: A Graph-Aware Deep Learning Approach","Z. Zhuang; J. Wang; Q. Qi; H. Sun; J. Liao","State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing 100876, China (e-mail: zhuangzirui@bupt.edu.cn).; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing 100876, China (e-mail: wangjingyu@bupt.edu.cn).; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing 100876, China (e-mail: qiqi8266@bupt.edu.cn).; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing 100876, China (e-mail: hfsun@bupt.edu.cn).; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing 100876, China (e-mail: liaojx@bupt.edu.cn).","IEEE Systems Journal","","2019","PP","99","1","12","Software-defined networking decouples the control plane and data plane, which grants more computing power for routing computations. Traditional routing methods suffer from the complex dynamics in networking, and they are facing issues such as slow convergence and performance decline. Deep learning techniques have shown preliminary results on solving the routing problem, and bringing more accuracy, precision, and intelligence compared with traditional modeling techniques. However, the existing deep learning architectures are not built to learn from the crucial topological relations between forwarding nodes, which restricts the model’s ability to handle different network conditions. In this paper, we propose a deep learning based intelligent routing strategy with revised graph-aware neural networks, which learns topological information efficiently. In addition, a set of features suitable for network routing are designed so that the networking state are well represented upon each routing decision. In experiments, the performance of the proposed work is demonstrated with a real-world topology and the production level software switches. The execution time is evaluated on various kinds of network topology and different network scales. Also, the simulation result shows that the proposed work is more accurate and efficient compared to the state-of-the-art routing strategy.","","","10.1109/JSYST.2019.2922217","National Natural Science Foundation of China; Natural Science Foundation of Beijing Municipality; National Basic Research Program of China (973 Program); Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8745681","Machine learning;routing;software-defined networking;traffic control","Routing;Deep learning;Network topology;Computer architecture;Topology;Measurement","","","","","","","","","","IEEE","IEEE Early Access Articles"
"DeepWelding: a Deep Learning Enhanced Approach to GTAW Using Multi-source Sensing Images","Y. Feng; Z. Chen; D. Wang; J. Chen; Z. Feng","Electrical Engineering and Computer Science, University of Tennessee, 4285 Knoxville, Tennessee United States 37996 (e-mail: yfeng14@vols.utk.edu); Mechanical, Aerospace and Biomedical Engineering, University of Tennessee, 4285 Knoxville, Tennessee United States 37996 (e-mail: zchen25@vols.utk.edu); Oak Ridge National Laboratory, 6146 Oak Ridge, Tennessee United States 37831-2008 (e-mail: wangd@ornl.gov); Oak Ridge National Laboratory, 6146 Oak Ridge, Tennessee United States 37831-2008 (e-mail: chenj2@ornl.gov); Oak Ridge National Laboratory, 6146 Oak Ridge, Tennessee United States 37831-2008 (e-mail: fengz@ornl.gov)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","Deep learning has great potential to reshape manufacturing industries. In this paper, we present DeepWelding, a novel framework that applies deep learning techniques to improve gas tungsten arc welding (GTAW) process monitoring and penetration detection using multi-source sensing images. The framework is capable of analyzing multiple types of optical sensing images synchronously and consists of three deep learning enhanced consecutive phases: image preprocessing, image selection, and weld penetration classification. Specifically, we adopted generative adversarial networks (pix2pix) for image denoising and classic convolutional neural networks (AlexNet) for image selection. Both pix2pix and AlexNet delivered satisfactory performance. However, five individual neural networks with heterogeneous architectures demonstrated inconsistent generalization capabilities in the classification phase when holding out multi-source images generated with specific experimental settings. Therefore, two ensemble methods combining multiple neural networks were designed to improve the model performance on unseen data collected from different experimental settings. We also found that the quality of model prediction was heavily influenced by the data stream collection environment. We think these findings are beneficial for the broad intelligent welding community.","","","10.1109/TII.2019.2937563","Office of Science; Oak Ridge National Laboratory; U.S. Department of Energy; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8815879","Arc welding;GTAW;monitoring and classification;deep neural networks;multi-source sensing images;pix2pix","Welding;Neural networks;Deep learning;Monitoring;Feature extraction;Robot sensing systems","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A New Deep Transfer Learning Method for Bearing Fault Diagnosis under Different Working Conditions","J. Zhu; N. Chen; C. Shen","Department of Industrial Systems Engineering and Management, Sembcrop-NUS Corporate Laboratory, National University of Singapore.; Department of Industrial Systems Engineering and Management, Sembcrop-NUS Corporate Laboratory, National University of Singapore.; School of Rail Transportation, Soochow University, Suzhou, Jiangsu, P.R. China.","IEEE Sensors Journal","","2019","PP","99","1","1","Fault diagnosis is very important for condition based maintenance. Recently, deep learning models are introduced to learn hierarchical representations from raw data instead of using hand-crafted features, which exhibit excellent performance. The success of current deep learning lies in: 1) the training (source domain) and testing (target domain) datasets are from the same feature distribution; 2) Enough labeled data with fault information exist. However, because the machine operates under a non-stationary working condition, the trained model built on the source domain can not be directly applied on the target domain. Moreover, since no sufficient labeled or even unlabeled data are available in target domain, collecting the labeled data and building the model from scratch is time-consuming and expensive. Motivated by transfer learning (TL), we present a new fault diagnosis method, which generalizes convolutional neural network (CNN) to TL scenario. Two layers with regard to task-specific features are adapted in a layer-wise way to regularize the parameters of CNN. What’s more, the domain loss is calculated by a linear combination of multiple Gaussian kernels so that the ability of adaptation is enhanced compared to single kernel. Through these two means, the distribution discrepancy is reduced and the transferable features are learned. The proposed method is validated by transfer fault diagnosis experiments. Compared to CNN without domain adaptation and shallow transfer learning methods, the proposed method gets the best performance for fault classification.","","","10.1109/JSEN.2019.2936932","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8809786","convolutional neural network;maximum mean discrepancy;transfer learning;fault diagnosis","Feature extraction;Fault diagnosis;Kernel;Deep learning;Sensors;Employee welfare;Convolution","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Fault Diagnosis in Microelectronics Attachment via Deep Learning Analysis of 3D Laser Scans","N. Dimitriou; L. Leontaris; T. Vafeiadis; D. Ioannidis; T. Wotherspoon; G. Tinker; D. Tzovaras","Information Technologies Institute, Centre of Research & Technology - Hellas, Greece (e-mail: nikdim@iti.gr); Information Technologies Institute, Centre of Research & Technology - Hellas, Greece (e-mail: lleontar@iti.gr); Information Technologies Institute, Centre of Research & Technology - Hellas, Greece (e-mail: thanvaf@iti.gr); Information Technologies Institute, Centre of Research & Technology - Hellas, Greece (e-mail: djoannid@iti.gr); Microsemi Corp, 274152 United Kingdom of Great Britain and Northern Ireland (e-mail: Tracy.Wotherspoon@microsemi.com); Microsemi Corp, 274152 United Kingdom of Great Britain and Northern Ireland (e-mail: Gregory.Tinker@microsemi.com); Information Technologies Institute, Centre of Research & Technology - Hellas, Greece (e-mail: dimitrios.tzovaras@iti.gr)","IEEE Transactions on Industrial Electronics","","2019","PP","99","1","1","A common source of defects in manufacturing miniature Printed Circuits Boards (PCB) is the attachment of silicon die or other wire bondable components on a Liq- uid Crystal Polymer (LCP) substrate. Typically, a conductive glue is dispensed prior to attachment with defects caused either by insufficient or excessive glue. The current prac- tice in electronics industry is to examine the deposited glue by a human operator a process that is both time consuming and inefficient especially in preproduction runs where the error rate is high. In this paper we propose a system that automates fault diagnosis by accurately estimating the vol- ume of glue deposits before and even after die attachment. To this end a modular scanning system is deployed that produces high resolution point clouds whereas the actual estimation of glue volume is performed by (R)egression- Net (RNet), a 3D Convolutional Neural Network (3DCNN). RNet outperforms other deep architectures and is able to estimate the volume either directly from the point cloud of a glue deposit or more interestingly after die attachment when only a small part of glue is visible around each die. The entire methodology is evaluated under operational conditions where the proposed system achieves accurate results without delaying the manufacturing process.","","","10.1109/TIE.2019.2931220","Z-Fact0r; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8788364","3DCNN;deep learning;PCB;smart manufacturing","Three-dimensional displays;Fault diagnosis;Deep learning;Inspection;Manufacturing;Sensors;Computer architecture","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Camera geometric calibration using dynamic single-pixel illumination with deep learning networks","J. Li; Z. Liu","Electrical Engineering Division, Department of Engineering, University of Cambridge, Cambridge, CB3 0FA, UK.; Optic Division, National Institute of Metrology, Beijing 100029, China.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Traditional methods of geometric camera calibration (GCC) are based on angle measurements (AM) or diffractive optical elements (DOE). However, the AM-based approach has the low accuracy and reliability because the vibration of rotating mechanisms, i.e. turntables, and angle measuring accuracy easily influence the calibration accuracy. The DOE failure easily occurs in the calibration process when some micro-apertures are blocked by dust particles. In this paper, a new method for GCC by means of single pixel illumination in a deep neural network (DNN) is presented. A closed-loop calibration link is composed of a single stimulus input produced by a single pixel generator and a collimator, an uncalibrated camera, and a DNN. The dynamic single-pixel illumination forms the different stimulus input of the DNN at different stimulus time. The synaptic weights (the camera interior parameters) of multilayer perceptron are adjusted until the cost function is minimized. This method is able to avoid the aforementioned shortcoming of conventional calibration methods. This method can be especially used for on-ground calibration of remote sensing cameras but in principle also suitable for on-orbit GCC and other cameras.","","","10.1109/TCSVT.2019.2927550","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8758358","Camera geometric calibration;deep learning;single pixel","Cameras;Calibration;Optical imaging;Collimators;Deep learning;Optical sensors","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Is Travel Demand Actually Deep? An Application in Event Areas Using Semantic Information","I. Markou; F. Rodrigues; F. C. Pereira","Department of Management Engineering, Technical University of Denmark, DK-2800 Kgs. Lyngby, Denmark (e-mail: markou@dtu.dk).; Department of Management Engineering, Technical University of Denmark, DK-2800 Kgs. Lyngby, Denmark.; Department of Management Engineering, Technical University of Denmark, DK-2800 Kgs. Lyngby, Denmark.","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","12","In transportation, nature, economy, environment, and many other settings, there are multiple simultaneous phenomena happening that are of interest to model and predict. Over the last few years, the traffic data that we have at our disposal have significantly increased, and we have truly entered the era of big data for transportation. Most existing travel demand prediction methods mainly focus on capturing recurrent mobility trends that relate to habitual/routine behavior, and on exploiting short-term correlations with recent observation patterns. However, valuable information that is often available in the form of unstructured data is neglected when attempting to improve forecasting results. Particularly, under non-recurrent conditions, such as large events, or incidents, we need much better models. In this paper, we explore time-series data and semantic information combinations using machine learning and deep learning techniques in the context of creating a prediction model that is able to capture in real-time future stressful situations of the studied transportation system. We apply the proposed approaches in event areas in New York using publicly available taxi data. We empirically show that the proposed models are able to significantly reduce the error in the forecasts. The importance of semantic information is highlighted in all presented methods and the final mean absolute error of our prediction is decreased by 23.8% for a three months testing period.","","","10.1109/TITS.2019.2897341","People Programme Marie Curie Actions of the European Unions Seventh Framework Programme FP7 2007 2013; European Unions Horizon 2020 Research and Innovation Programme; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8643585","Time series forecasting;taxi demand;special events;semantic information;topic modeling;deep learning;deep Gaussian processes.","Public transportation;Predictive models;Urban areas;Deep learning;Internet;Semantics","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Towards Optimal Power Control via Ensembling Deep Neural Networks","F. Liang; C. Shen; W. Yu; F. Wu","School of Information Science and Technology, University of Science and Technology of China, Hefei, China and Huawei Technologies Co., Shanghai, China.; Charles L. Brown Department of Electrical and Computer Engineering, University of Virginia, Charlottesville, VA 22904, USA.; Electrical and Computer Engineering Department, University of Toronto, Toronto, Ontario M5S 3G4, Canada.; School of Information Science and Technology, University of Science and Technology of China, Hefei, China.","IEEE Transactions on Communications","","2019","PP","99","1","1","A deep neural network (DNN) based power control method that aims at solving the non-convex optimization problem of maximizing the sum rate of a fading multi-user interference channel is proposed. Towards this end, we first present PCNet, which is a multi-layer fully connected neural network that is specifically designed for the power control problem. A key challenge in training a DNN for the power control problem is the lack of ground truth, i.e., the optimal power allocation is unknown. To address this issue, PCNet leverages the unsupervised learning strategy and directly maximizes the sum rate in the training phase. We then present PCNet+, which enhances the generalization capacity of PCNet by incorporating noise power as an input to the network. Observing that a single PCNet(+) does not universally outperform the existing solutions, we further propose ePCNet(+), a network ensemble with multiple PCNets(+) trained independently. Simulation results show that for the standard symmetric K-user Gaussian interference channel, the proposed methods can outperform state-of-the-art power control solutions under a variety of system configurations. Furthermore, the performance improvement of ePCNet comes with a reduced computational complexity.","","","10.1109/TCOMM.2019.2957482","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8922744","Power control;Interference mitigation;Deep neural networks (DNN);Ensemble learning","Power control;Neural networks;Machine learning;Decoding;Receivers;Interference channels;Training","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep-Learning Inversion of Seismic Data","S. Li; B. Liu; Y. Ren; Y. Chen; S. Yang; Y. Wang; P. Jiang","School of Qilu Transportation, Shandong University, Jinan 250100, China, and also with the Geotechnical and Structural Engineering Research Center, Shandong University, Jinan 250100, China (e-mail: lishucai@sdu.edu.cn).; School of Qilu Transportation, Shandong University, Jinan 250100, China, and also with the Geotechnical and Structural Engineering Research Center, Shandong University, Jinan 250100, China.; School of Qilu Transportation, Shandong University, Jinan 250100, China, and also with the Geotechnical and Structural Engineering Research Center, Shandong University, Jinan 250100, China.; School of Earth Sciences, Zhejiang University, Hangzhou 310027, China.; School of Qilu Transportation, Shandong University, Jinan 250100, China, and also with the Geotechnical and Structural Engineering Research Center, Shandong University, Jinan 250100, China.; School of Computer Science and Technology, Shandong University, Qingdao 266237, China.; School of Qilu Transportation, Shandong University, Jinan 250100, China, and also with the Geotechnical and Structural Engineering Research Center, Shandong University, Jinan 250100, China.","IEEE Transactions on Geoscience and Remote Sensing","","2019","PP","99","1","15","We propose a new method to tackle the mapping challenge from time-series data to spatial image in the field of seismic exploration, i.e., reconstructing the velocity model directly from seismic data by deep neural networks (DNNs). The conventional way of addressing this ill-posed inversion problem is through iterative algorithms, which suffer from poor nonlinear mapping and strong nonuniqueness. Other attempts may either import human intervention errors or underuse seismic data. The challenge for DNNs mainly lies in the weak spatial correspondence, the uncertain reflection-reception relationship between seismic data and velocity model, as well as the time-varying property of seismic data. To tackle these challenges, we propose end-to-end seismic inversion networks (SeisInvNets) with novel components to make the best use of all seismic data. Specifically, we start with every seismic trace and enhance it with its neighborhood information, its observation setup, and the global context of its corresponding seismic profile. From the enhanced seismic traces, the spatially aligned feature maps can be learned and further concatenated to reconstruct a velocity model. In general, we let every seismic trace contribute to the reconstruction of the whole velocity model by finding spatial correspondence. The proposed SeisInvNet consistently produces improvements over the baselines and achieves promising performance on our synthesized and proposed SeisInv data set according to various evaluation metrics. The inversion results are more consistent with the target from the aspects of velocity values, subsurface structures, and geological interfaces. Moreover, the mechanism and the generalization of the proposed method are discussed and verified. Nevertheless, the generalization of deep-learning-based inversion methods on real data is still challenging and considering physics may be one potential solution.","","","10.1109/TGRS.2019.2953473","National Natural Science Foundation of China; Royal Academy of Engineering under the U.K.-China Industry Academia Partnership Program Scheme; Key Technology Research and Development Program of Shandong; Fundamental Research Funds of Shandong University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8931232","Deep neural networks (DNNs);seismic inversion.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Learning-Based Methodology for Recognition of Fetal Brain Standard Scan Planes in 2D Ultrasound Images","R. Qu; G. Xu; C. Ding; W. Jia; M. Sun","State Key Laboratory of Reliability and Intelligence of Electrical Equipment, Hebei University of Technology, Tianjin 300130, China.; State Key Laboratory of Reliability and Intelligence of Electrical Equipment, Hebei University of Technology, Tianjin 300130, China.; Ultrasound Department, Zhangjiakou Maternal and Child Health Hospital, Hebei, 075000, China.; Laboratory for Computational Neuroscience, University of Pittsburgh, Pittsburgh, PA, 15213, USA.; Laboratory for Computational Neuroscience, University of Pittsburgh, Pittsburgh, PA, 15213, USA.","IEEE Access","","2019","PP","99","1","1","Two-dimensional ultrasound scanning (US) has become a highly recommended examination in prenatal diagnosis in many countries. Accurate detection of abnormalities and correct fetal brain standard planes is the most necessary precondition for successful diagnosis and measurement. In the past few years, support vector machine (SVM) and other machine learning methods have been devoted to automatic recognition of 2D ultrasonic images, but the performance of recognition is not satisfactory due to the wide diversity of fetal postures, shortage of data, similarities between standard planes and other reasons. Especially in the recognition of fetal brain images, the features of fetal brain images such as shape, texture, color and others are very similar, which presents great challenges to the recognition work. In this study, we proposed two main methods based on deep convolutional neural networks to automatically recognize six standard planes of fetal brains. One is a deep convolutional neural network (CNN), and the other one is CNN-based domain transfer learning. To examine the performance of these algorithms, we constructed two datasets. Dataset 1 consists of 30,000 2D ultrasound images from 155 subjects between 16 and 34 weeks. Dataset 2, containing 1,200 images, was acquired from a research participant throughout 40 weeks, which is the entire pregnancy. Experimental results show that the proposed solutions achieve promising results and that the frameworks based on deep convolutional neural networks generally outperform the ones using other classical deep learning methods, thus demonstrating the great potential of convolutional neural networks in this area.","","","10.1109/ACCESS.2019.2950387","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8887441","Medical image processing;CNN;transfer learning","Standards;Feature extraction;Ultrasonic imaging;Deep learning;Image recognition;Convolutional neural networks;Medical services","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"A Generic Approach to Lung Field Segmentation from Chest Radiographs using Deep Space and Shape Learning","A. Mansoor; J. Cerrolaza; G. Perez; E. Biggs; K. Okada; G. Nino; M. G. Linguraru","Potomac, Maryland United States 20854 (e-mail: AMansoor@childrensnational.org); Sheikh Zayed Institute for Pediatric Surgical Innovation, Children's National Health System, Washington, District of Columbia United States 20009 (e-mail: jjcerromar@gmail.com); Sheikh Zayed Institute for Pediatric Surgical Innovation, Children's National Health System, Washington, District of Columbia United States (e-mail: GPerez@childrensnational.org); Sheikh Zayed Institute for Pediatric Surgical Innovation, Children's National Health System, Washington, District of Columbia United States (e-mail: ebiggs@childrensnational.org); Department of Computer Science, San Francisco State University, San Francisco, California United States 94132 (e-mail: kazokada@sfsu.edu); Sheikh Zayed Institute for Pediatric Surgical Innovation, Children's National Health System, Washington, District of Columbia United States (e-mail: gnino@childrensnational.org); Sheikh Zayed Institute, Children's National Health System, Washington, District of Columbia United States 20010 (e-mail: MLingura@childrensnational.org)","IEEE Transactions on Biomedical Engineering","","2019","PP","99","1","1","Computer-aided diagnosis (CAD) techniques for lung field segmentation from chest radiographs (CXR) have been proposed for adult cohorts, but rarely for pediatric subjects. Statistical shape models (SSMs), the workhorse of most stateof-the-art CXR-based lung field segmentation methods, do not efficiently accommodate shape variation of the lung field during the pediatric developmental stages. The main contributions of our work are: (1) a generic lung field segmentation framework from CXR accommodating large shape variation for adult and pediatric cohorts; (2) a deep representation learning detection mechanism, ensemble space learning, for robust object localization; and (3) marginal shape deep learning for the shape deformation parameter estimation. Unlike the iterative approach of conventional SSMs, the proposed shape learning mechanism transforms the parameter space into marginal subspaces that are solvable efficiently using the recursive representation learning mechanism. Furthermore, our method is the first to include the challenging retro-cardiac region in the CXR-based lung segmentation for accurate lung capacity estimation. The framework is evaluated on 668 CXRs of patients between 3 month to 89 year of age. We obtain a mean Dice similarity coefficient of 0.96$\pm$0.03 (including the retro-cardiac region). For a given accuracy, the proposed approach is also found to be faster than conventional SSM-based iterative segmentation methods. The computational simplicity of the proposed generic framework could be similarly applied to the fast segmentation of other deformable objects.","","","10.1109/TBME.2019.2933508","National Institutes of Health; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798867","Lung field;chest radiograph;deep learning;space learning;shape learning;statistical shape models","Lung;Shape;Spatial resolution;Diagnostic radiography;Strain;Image segmentation;Pediatrics","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Rate Distortion Via Deep Learning","Q. Li; Y. Chen","Western Digital Research, Milpitas, CA, 95035, USA. Yang Chen is now with the Department of Statistics and Michigan Institute for Data Science, University of Michigan, Ann Arbor, MI 48109, USA.; Western Digital Research, Milpitas, CA, 95035, USA. Yang Chen is now with the Department of Statistics and Michigan Institute for Data Science, University of Michigan, Ann Arbor, MI 48109, USA.","IEEE Transactions on Communications","","2019","PP","99","1","1","We explore the connections between rate distortion/ lossy source coding and deep learning models, the Restricted Boltzmann Machines (RBMs) and Deep Belief Networks (DBNs). We show that rate distortion is a function of the RBM log partition function and that RBM/DBN can be used to learn the rate distortion approaching posterior as in the Blahut-Arimoto algorithm. We propose an algorithm for lossy compressing of binary sources. The algorithm consists of two stages, a training stage that learns the posterior with training data of the same class as the source, and a compression/reproduction stage that is comprised of a lossless compression and a lossless reproduction. Theoretical results show that the proposed algorithm achieves the optimum rate distortion function for stationary ergodic sources asymptotically. Numerical experiments show that the proposed algorithm outperforms the reported best results.","","","10.1109/TCOMM.2019.2950714","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8888220","rate distortion;lossy source coding;partition function;Restricted Boltzmann Machine (RBM);Deep Belief Network (DBN);Blahut-Arimoto (BA) algorithm;block Gibbs sampling;annealed importance sampling","Rate-distortion;Deep learning;Distortion;Source coding;Partitioning algorithms;Probability distribution;Monte Carlo methods","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Smartphone Sensor Based Human Activity Recognition Using Feature Fusion and Maximum Full A Posteriori","Z. Chen; C. Jiang; S. Xiang; J. Ding; M. Wu; X. Li","Institute for Infocomm Research, Agency for Science, Technology and Research (A*STAR), 1 Fusionopolis Way, Sinagpore 138632.; Science and Technology on Vehicle Transmission Laboratoryo&lt;Œ School of Mechanical Engineering, Beijing Institute of Technology, Beijing, China 100081.; Institute for Infocomm Research, Agency for Science, Technology and Research (A*STAR), 1 Fusionopolis Way, Sinagpore 138632.; Institute for Infocomm Research, Agency for Science, Technology and Research (A*STAR), 1 Fusionopolis Way, Sinagpore 138632.; Institute for Infocomm Research, Agency for Science, Technology and Research (A*STAR), 1 Fusionopolis Way, Sinagpore 138632.; Institute for Infocomm Research, Agency for Science, Technology and Research (A*STAR), 1 Fusionopolis Way, Sinagpore 138632.","IEEE Transactions on Instrumentation and Measurement","","2019","PP","99","1","1","Human activity recognition (HAR) using smartphone sensors has attracted great attention, due to its wide range of applications. A standard solution for HAR is to firstly generate some features defined based on domain knowledge (handcrafted features), and then to train an activity classification model based on these features. Very recently, deep learning with automatic feature learning from raw sensory data has also achieved great performance for HAR task. We believe that both the handcrafted features and the learned features may convey some unique information which can complement each other for HAR. In this paper, we firstly propose a feature fusion framework to combine handcrafted features with automatically learned features by a deep algorithm for HAR. Then, taking the regular dynamics of human behaviour into consideration, we develop a maximum full a posterior (MFAP) algorithm to further enhance the performance of HAR. Our extensive experimental results show the proposed approach can achieve superior performance comparing with state-of-the-art methodologies across both a public dataset and a self-collected dataset.","","","10.1109/TIM.2019.2945467","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8856227","HAR;smartphone sensors;deep learning;feature fusion;MFAP","Feature extraction;Heuristic algorithms;Inference algorithms;Deep learning;Gyroscopes;Acceleration;Frequency-domain analysis","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Sparse Manifold-Regularized Neural Networks for Polarimetric SAR Terrain Classification","H. Liu; F. Shang; S. Yang; M. Gong; T. Zhu; L. Jiao","Key Laboratory of Intelligent Perception and Image Understanding, Ministry of Education, Xidian University, Xi'an 710071, China.; Key Laboratory of Intelligent Perception and Image Understanding, Ministry of Education, Xidian University, Xi'an 710071, China (e-mail: fhshang@xidian.edu.cn).; Key Laboratory of Intelligent Perception and Image Understanding, Ministry of Education, Xidian University, Xi'an 710071, China.; Key Laboratory of Intelligent Perception and Image Understanding, Ministry of Education, Xidian University, Xi'an 710071, China.; Key Laboratory of Intelligent Perception and Image Understanding, Ministry of Education, Xidian University, Xi'an 710071, China.; Key Laboratory of Intelligent Perception and Image Understanding, Ministry of Education, Xidian University, Xi'an 710071, China.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","10","In this article, a new deep neural network based on sparse filtering and manifold regularization (DSMR) is proposed for feature extraction and classification of polarimetric synthetic aperture radar (PolSAR) data. DSMR uses a novel deep neural network (DNN) to automatically learn features from raw SAR data. During preprocessing, the spatial information between pixels on PolSAR images is exploited to weight each data sample. Then, in the pretraining and fine-tuning, DSMR uses the population sparsity and the lifetime sparsity (dual sparsity) to learn the global features and preserves the local structure of data by neighborhood-based manifold regularization. The dual sparsity only needs to tune a few parameters, and the manifold regularization cuts down the number of training samples. Experimental results on synthesized and real PolSAR data sets from different SAR systems show that DSMR can improve classification accuracy compared with conventional DNNs, even for data sets with a large angle of incidence.","","","10.1109/TNNLS.2019.2935027","State Key Program of National Natural Science of China; Foundation for Innovative Research Groups of the National Natural Science Foundation of China; Major Research Plan of the National Natural Science Foundation of China; Fund for Foreign Scholars in University Research and Teaching Programs the 111 Project; National Natural Science Foundation of China; Program for Cheung Kong Scholars and Innovative Research Team in University; Science Foundation of Xidian University; National Science Basic Research Plan in Shaanxi Province of China; Fundamental Research Funds for the Central Universities; Key Special Project of China High Resolution Earth Observation System Young Scholar Innovation Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8835090","Deep learning;manifold regularization;polarimetric synthetic aperture radar (PolSAR);sparse filtering.","Feature extraction;Manifolds;Covariance matrices;Deep learning;Sociology;Learning systems","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Ensembling of Gene Clusters utilizing Deep Learning and Protein-protein Interaction Information","P. Dutta; S. Saha; S. Chopra; V. Miglani","Indian Institute of Technology Patna Department of Computer Science and Engineering, 250392 Patna, Bihar India 800013 (e-mail: pratik24111991@gmail.com); Department of CSE, IIT Patna, Patna, bihar India (e-mail: sriparna.saha@gmail.com); Indian Institute of Technology Patna, 250259 Patna, Bihar India (e-mail: saraansh.chopra@gmail.com); Meerut Institute of Engineering and Technology, 79621 Meerut, Uttar Pradesh India (e-mail: miglanivarnika.26@gmail.com)","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2019","PP","99","1","1","Cluster ensemble techniques aim to combine the outputs of multiple clustering algorithms to obtain a single consensus partitioning. The current paper reports about the development of a cluster ensemble based technique combining the concepts of multiobjective optimization and deep-learning models for gene clustering where some additional protein-protein interaction information are utilized for generating the consensus partitioning. The first approach is based on a traditional machine learning method, and another approach exploits the graph partitioning algorithm and two deep neural models to generate the final clustering. To validate the efficacy of the proposed ensemble framework, it is applied on five gene expression datasets. We present a comparative analysis of the proposed technique over different clustering algorithms in terms of biological homogeneity index (BHI) and biological stability index (BSI). The traditional approach attains an average 3% and 2% improvements over the best non-dominated solution with respect to BHI and BSI, respectively, whereas deep learning models illustrate an average 6.8% and 1.5% improvement over the proposed traditional approach with respect to BHI and BSI, respectively. Subsequently, Welch's t-test is executed to prove that the results obtained by the proposed methods are statistically significant.","","","10.1109/TCBB.2019.2918523","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8721175","","Proteins;Clustering algorithms;Partitioning algorithms;Deep learning;Machine learning algorithms;Gene expression","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Compressing Deep Neural Networks With Sparse Matrix Factorization","K. Wu; Y. Guo; C. Zhang","State Key Laboratory of Intelligent Technologies and Systems, Beijing National Research Center for Information Science and Technology (BNRist), Institute for Artificial Intelligence (THUAI), Tsinghua University, Beijing 100084, China, and also with the Department of Automation, Tsinghua University, Beijing 100084, China.; Cognitive Computing Lab, Intel Labs, Beijing 100190, China, with the State Key Laboratory of Intelligent Technologies and Systems, Beijing National Research Center for Information Science and Technology (BNRist), Institute for Artificial Intelligence (THUAI), Tsinghua University, Beijing 100084, China, and also with the Department of Automation, Tsinghua University, Beijing 100084, China.; State Key Laboratory of Intelligent Technologies and Systems, Beijing National Research Center for Information Science and Technology (BNRist), Institute for Artificial Intelligence (THUAI), Tsinghua University, Beijing 100084, China, and also with the Department of Automation, Tsinghua University, Beijing 100084, China (e-mail: zcs@mail.tsinghua.edu.cn).","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","11","Modern deep neural networks (DNNs) are usually overparameterized and composed of a large number of learnable parameters. One of a few effective solutions attempts to compress DNN models via learning sparse weights and connections. In this article, we follow this line of research and present an alternative framework of learning sparse DNNs, with the assistance of matrix factorization. We provide an underlying principle for substituting the original parameter matrices with the multiplications of highly sparse ones, which constitutes the theoretical basis of our method. Experimental results demonstrate that our method substantially outperforms previous states of the arts for compressing various DNNs, giving rich empirical evidence in support of its effectiveness. It is also worth mentioning that, unlike many other works that focus on feedforward networks like multi-layer perceptrons and convolutional neural networks only, we also evaluate our method on a series of recurrent networks in practice.","","","10.1109/TNNLS.2019.2946636","NSFC; Beijing Academy of Artificial Intelligence BAAI; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8901163","Deep neural networks (DNNs);memory efficiency;network compression;sparse representation.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Lightweight Pyramid Networks for Image Deraining","X. Fu; B. Liang; Y. Huang; X. Ding; J. Paisley","Fujian Key Laboratory of Sensing and Computing for Smart City, School of Information Science and Engineering, Xiamen University, Xiamen 361005, China, and also with the School of Information Science and Technology, University of Science and Technology of China, Hefei 230026, China.; Fujian Key Laboratory of Sensing and Computing for Smart City, School of Information Science and Engineering, Xiamen University, Xiamen 361005, China.; Fujian Key Laboratory of Sensing and Computing for Smart City, School of Information Science and Engineering, Xiamen University, Xiamen 361005, China.; Fujian Key Laboratory of Sensing and Computing for Smart City, School of Information Science and Engineering, Xiamen University, Xiamen 361005, China (e-mail: dxh@xmu.edu.cn).; Department of Electrical Engineering, Columbia University, New York, NY 10027 USA, and also with the Data Science Institute, Columbia University, New York, NY 10027 USA.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","14","Existing deep convolutional neural networks (CNNs) have found major success in image deraining, but at the expense of an enormous number of parameters. This limits their potential applications, e.g., in mobile devices. In this paper, we propose a lightweight pyramid networt (LPNet) for single-image deraining. Instead of designing a complex network structure, we use domain-specific knowledge to simplify the learning process. In particular, we find that by introducing the mature Gaussian-Laplacian image pyramid decomposition technology to the neural network, the learning problem at each pyramid level is greatly simplified and can be handled by a relatively shallow network with few parameters. We adopt recursive and residual network structures to build the proposed LPNet, which has less than 8K parameters while still achieving the state-of-the-art performance on rain removal. We also discuss the potential value of LPNet for other low- and high-level vision tasks.","","","10.1109/TNNLS.2019.2926481","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; CCF Tencent open fund; Natural Science Foundation of Fujian Province of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8767931","Deep convolutional neural network (CNN);image pyramid;lightweight networks;rain removal;residual learning.","Rain;Laplace equations;Feature extraction;Learning systems;Task analysis;Knowledge engineering;Computer vision","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Real-World ISAR Object Recognition Using Deep Multimodal Relation Learning","B. Xue; N. Tong","Graduate School, Air Force Engineering University, Xi'an 710051, China (e-mail: xxbbxl@sina.com).; Graduate School, Air Force Engineering University, Xi'an 710051, China.","IEEE Transactions on Cybernetics","","2019","PP","99","1","12","Real-world inverse synthetic aperture radar (ISAR) object recognition is a critical and challenging problem in computer vision tasks. In this article, an efficient real-world ISAR object recognition method is proposed, namely, real-world ISAR object recognition (RIOR), based on deep multimodal relation learning (DMRL). It cannot only handle the complex multimodal recognition problem efficiently but also exploit the relations among the features, attributes, labels, and classes with semantic knowledge: 1) an adaptive multimodal mechanism (AMM) is proposed in convolutional neural network (CNN) to substantially promote the CNN sampling and transformation capability and significantly raise the output feature map resolutions by keeping almost all of the information; 2) deep attribute relation graph learning (DARGL) is proposed to jointly estimate the large numbers of heterogeneous attributes and collaboratively explore the relations among the features, attributes, labels, and classes with common knowledge graphs; and 3) relational-regularized convolutional sparse learning (RCSL) is proposed to further achieve good translation invariance and improve the accuracy and speed of the entire system. Extensive qualitative and quantitative experiments are performed on two real-world ISAR datasets, demonstrating that RIOR outperforms the state-of-the-art methods while running quickly.","","","10.1109/TCYB.2019.2933224","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8811762","Attribute learning;deep learning;deformable;image matching;object recognition;radar;real-world environment;relation learning;statistic","Convolution;Object recognition;Kernel;Image resolution;Feature extraction;Cybernetics;Convolutional neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"DeepCoin: A Novel Deep Learning and Blockchain-Based Energy Exchange Framework for Smart Grids","M. A. Ferrag; L. Maglaras","Department of Computer Science, Guelma University, Guelma 24000, Algeria (e-mail: ferrag.mohamedamine@univ-guelma.dz).; School of Computer Science and Informatics, De Montfort University, LE1 9BH Leicester, U.K., and also with the General Secretariat of Digital Policy 10163, Athens, Greece (e-mail: leandrosmag@gmail.com).","IEEE Transactions on Engineering Management","","2019","PP","99","1","13","In this paper, we propose a novel deep learning and blockchain-based energy framework for smart grids, entitled DeepCoin. The DeepCoin framework uses two schemes, a blockchain-based scheme and a deep learning-based scheme. The blockchain-based scheme consists of five phases: setup phase, agreement phase, creating a block phase and consensus-making phase, and view change phase. It incorporates a novel reliable peer-to-peer energy system that is based on the practical Byzantine fault tolerance algorithm and it achieves high throughput. In order to prevent smart grid attacks, the proposed framework makes the generation of blocks using short signatures and hash functions. The proposed deep learning-based scheme is an intrusion detection system (IDS), which employs recurrent neural networks for detecting network attacks and fraudulent transactions in the blockchain-based energy network. We study the performance of the proposed IDS on three different sources the CICIDS2017 dataset, a power system dataset, and a web robot (Bot)-Internet of Things (IoT) dataset.","","","10.1109/TEM.2019.2922936","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8758147","Blockchain;intrusion detection system (IDS);machine learning;smart grid;security","Smart grids;Blockchain;Deep learning;Intrusion detection;Computational modeling;Privacy;Peer-to-peer computing","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Deep Class-Wise Hashing: Semantics-Preserving Hashing via Class-Wise Loss","X. Zhe; S. Chen; H. Yan","Department of Electronic Engineering, City University of Hong Kong, Hong Kong (e-mail: xfzhe2-c@my.cityu.edu.hk).; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen 518055, China.; Department of Electronic Engineering, City University of Hong Kong, Hong Kong.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","15","Deep supervised hashing has emerged as an effective solution to large-scale semantic image retrieval problems in computer vision. Convolutional neural network-based hashing methods typically seek pairwise or triplet labels to conduct similarity-preserving learning. However, complex semantic concepts of visual contents are hard to capture by similar/dissimilar labels, which limits the retrieval performance. Generally, pairwise or triplet losses not only suffer from expensive training costs but also lack sufficient semantic information. In this paper, we propose a novel deep supervised hashing model to learn more compact class-level similarity-preserving binary codes. Our model is motivated by deep metric learning that directly takes semantic labels as supervised information in training and generates corresponding discriminant hashing code. Specifically, a novel cubic constraint loss function based on Gaussian distribution is proposed, which preserves semantic variations while penalizes the overlapping part of different classes in the embedding space. To address the discrete optimization problem introduced by binary codes, a two-step optimization strategy is proposed to provide efficient training and avoid the problem of gradient vanishing. Extensive experiments on five large-scale benchmark databases show that our model can achieve the state-of-the-art retrieval performance.","","","10.1109/TNNLS.2019.2921805","Hong Kong Research Grants Council; City University of Hong Kong; Shenzhen Science and Technology Innovation Committee; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8759067","Deep convolutional neural network (CNN);deep supervised hashing;large-scale image retrieval;learn to hashing.","Training;Measurement;Semantics;Visualization;Optimization;Binary codes;Image retrieval","","","","","","","","","","IEEE","IEEE Early Access Articles"
"DNN-DP: Differential Privacy Enabled Deep Neural Network Learning Framework for Sensitive Crowdsourcing Data","Y. Wang; M. Gu; J. Ma; Q. Jin","College of Telecommunications and information Engineering, Nanjing University of Posts and Telecommunications, Nanjing 210023, China (e-mail: wfwang@njupt.edu.cn).; College of Telecommunications and information Engineering, Nanjing University of Posts and Telecommunications, Nanjing 210023, China.; Faculty of Computer and Information Sciences, Hosei University, Tokyo 102-8160, Japan.; Faculty of Human Sciences, Waseda University, Tokyo 169-8050, Japan.","IEEE Transactions on Computational Social Systems","","2019","PP","99","1","10","Deep neural network (DNN) learning has witnessed significant applications in various fields, especially for prediction and classification. Frequently, the data used for training are provided by crowdsourcing workers, and the training process may violate their privacy. A qualified prediction model should protect the data privacy in training and classification/prediction phases. To address this issue, we develop a differential privacy (DP)-enabled DNN learning framework, DNN-DP, that intentionally injects noise to the affine transformation of the input data features and provides DP protection for the crowdsourced sensitive training data. Specifically, we correspondingly estimate the importance of each feature related to target categories and follow the principle that less noise is injected into the more important feature to ensure the data utility of the model. Moreover, we design an adaptive coefficient for the added noise to accommodate the heterogeneous feature value ranges. Theoretical analysis proves that DNN-DP preserves ε-differentially private in the computation. Moreover, the simulation based on the US Census data set demonstrates the superiority of our method in predictive accuracy compared with other existing privacy-aware machine learning methods.","","","10.1109/TCSS.2019.2950017","Qinglan Project of Jiangsu Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8909376","Adaptive noise;crowdsourcing data;deep neural network (DNN);differential privacy (DP).","Data models;Training;Data privacy;Crowdsourcing;Privacy;Predictive models;Computational modeling","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Walk-Steered Convolution for Graph Classification","J. Jiang; C. Xu; Z. Cui; T. Zhang; W. Zheng; J. Yang","Key Laboratory of Intelligent Perception and Systems for High-Dimensional Information of the Ministry of Education, School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing 210094, China, and also with the Jiangsu Key Laboratory of Image and Video Understanding for Social Security, School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing 210094, China.; Key Laboratory of Intelligent Perception and Systems for High-Dimensional Information of the Ministry of Education, School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing 210094, China, and also with the Jiangsu Key Laboratory of Image and Video Understanding for Social Security, School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing 210094, China.; Key Laboratory of Intelligent Perception and Systems for High-Dimensional Information of the Ministry of Education, School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing 210094, China, and also with the Jiangsu Key Laboratory of Image and Video Understanding for Social Security, School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing 210094, China (e-mail: zhen.cui@njust.edu.cn).; Key Laboratory of Intelligent Perception and Systems for High-Dimensional Information of the Ministry of Education, School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing 210094, China, and also with the Jiangsu Key Laboratory of Image and Video Understanding for Social Security, School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing 210094, China.; Key Laboratory of Child Development and Learning Science of the Ministry of Education, School of Biological Science and Medical Engineering, Southeast University, Nanjing 210096, China.; Key Laboratory of Intelligent Perception and Systems for High-Dimensional Information of the Ministry of Education, School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing 210094, China, and also with the Jiangsu Key Laboratory of Image and Video Understanding for Social Security, School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing 210094, China.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","14","Graph classification is a fundamental but challenging issue for numerous real-world applications. Despite recent great progress in image/video classification, convolutional neural networks (CNNs) cannot yet cater to graphs well because of graphical non-Euclidean topology. In this article, we propose a walk-steered convolutional (WSC) network to assemble the essential success of standard CNNs, as well as the powerful representation ability of random walk. Instead of deterministic neighbor searching used in previous graphical CNNs, we construct multiscale walk fields (a.k.a. local receptive fields) with random walk paths to depict subgraph structures and advocate graph scalability. To express the internal variations of a walk field, Gaussian mixture models are introduced to encode the principal components of walk paths therein. As an analogy to a standard convolution kernel on image, Gaussian models implicitly coordinate those unordered vertices/nodes and edges in a local receptive field after projecting to the gradient space of Gaussian parameters. We further stack graph coarsening upon Gaussian encoding by using dynamic clustering, such that high-level semantics of graph can be well learned like the conventional pooling on image. The experimental results on several public data sets demonstrate the superiority of our proposed WSC method over many state of the arts for graph classification.","","","10.1109/TNNLS.2019.2956095","National Natural Science Foundation of China; Natural Science Foundation of Jiangsu Province; Jiangsu Provincial Key Research and Development Program; National Key Research and Development Program of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8945290","Deep learning;graph classification;graph convolution;random walk.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Task-Oriented Feature-Fused Network With Multivariate Dataset for Joint Face Analysis","X. Lin; J. Wan; Y. Xie; S. Zhang; C. Lin; Y. Liang; G. Guo; S. Z. Li","Center for Biometrics and Security Research, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China, and also with the National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China. He is now with the Faculty of Information Technology, Macau University of Science and Technology, Macau 999078, China.; Center for Biometrics and Security Research, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China, and also with the National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China.; Faculty of Information Technology, Macau University of Science and Technology, Macau 999078, China.; Center for Biometrics and Security Research, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China, and also with the National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China.; USC Viterbi School of Engineering, University of Southern California, Los Angeles, CA 90089 USA.; Faculty of Information Technology, Macau University of Science and Technology, Macau 999078, China (e-mail: yyliang@must.edu.mo).; Institute of Deep Learning, Baidu Research, Beijing 100193, China, and also with the National Engineering Laboratory for Deep Learning Technology and Application, Baidu Research, Beijing 100193, China.; Center for Biometrics and Security Research, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China, and also with the National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China.","IEEE Transactions on Cybernetics","","2019","PP","99","1","14","Deep multitask learning for face analysis has received increasing attentions. From literature, most existing methods focus on optimizing a main task by jointly learning several auxiliary tasks. It is challenging to consider the performance of each task in a multitask framework due to the following reasons: 1) different face tasks usually rely on different levels of semantic features; 2) each task has different learning convergence rate, which could affect the whole performance when joint training; and 3) multitask model needs rich label information for efficient training, but existing facial datasets provide limited annotations. To address these issues, we propose a task-oriented feature-fused network (TFN) for simultaneously solving face detection, landmark localization, and attribute analysis. In this network, a task-oriented feature-fused block is designed to learn task-specific feature combinations; then, an alternative multitask training scheme is presented to optimize each task with considering of their different learning capacities. We also present a large-scale face dataset called JFA in support of proposed method, which provides multivariate labels, including face bounding box, 68 facial landmarks, and 3 attribute labels (i.e., apparent age, gender, and ethnicity). The experimental results suggest that the TFN outperforms several multitask models on the JFA dataset. Furthermore, our approach achieves competitive performances on WIDER FACE and 300W dataset, and obtains state-of-the-art results for gender recognition on the MORPH II dataset.","","","10.1109/TCYB.2019.2917049","National Key Research and Development Plan; Chinese National Natural Science Foundation Projects; Science and Technology Development Fund of Macau; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8731901","Attribute analysis;face analysis;face detection;landmark localization;multitask learning","Face;Task analysis;Training;Face recognition;Facial features;Pipelines","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep-Learning-Based Wireless Resource Allocation With Application to Vehicular Networks","L. Liang; H. Ye; G. Yu; G. Y. Li","Intel Labs, Hillsboro, OR 97124 USA (e-mail: lliang@gatech.edu).; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA 30332 USA.; Department of Information Science and Electronic Engineering, Zhejiang University, Hangzhou 310027, China.; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA 30332 USA.","Proceedings of the IEEE","","2019","PP","99","1","16","It has been a long-held belief that judicious resource allocation is critical to mitigating interference, improving network efficiency, and ultimately optimizing wireless communication performance. The traditional wisdom is to explicitly formulate resource allocation as an optimization problem and then exploit mathematical programming to solve the problem to a certain level of optimality. Nonetheless, as wireless networks become increasingly diverse and complex, for example, in the high-mobility vehicular networks, the current design methodologies face significant challenges and thus call for rethinking of the traditional design philosophy. Meanwhile, deep learning, with many success stories in various disciplines, represents a promising alternative due to its remarkable power to leverage data for problem solving. In this article, we discuss the key motivations and roadblocks of using deep learning for wireless resource allocation with application to vehicular networks. We review major recent studies that mobilize the deep-learning philosophy in wireless resource allocation and achieve impressive results. We first discuss deep-learning-assisted optimization for resource allocation. We then highlight the deep reinforcement learning approach to address resource allocation problems that are difficult to handle in the traditional optimization framework. We also identify some research directions that deserve further investigation.","","","10.1109/JPROC.2019.2957798","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8943940","Deep learning;reinforcement learning (RL);resource allocation;vehicular networks;wireless communications.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Vehicle Turning Behavior Modeling at Conflicting Areas of Mixed-Flow Intersections Based on Deep Learning","J. Sun; X. Qi; Y. Xu; Y. Tian","Department of Traffic Engineering, Tongji University, Shanghai 201804, China, and also with the Key Laboratory of Road and Traffic Engineering, Ministry of Education, Tongji University, Shanghai 201804, China.; Department of Traffic Engineering, Tongji University, Shanghai 201804, China, and also with the Key Laboratory of Road and Traffic Engineering, Ministry of Education, Tongji University, Shanghai 201804, China.; Department of Traffic Engineering, Tongji University, Shanghai 201804, China, and also with the Key Laboratory of Road and Traffic Engineering, Ministry of Education, Tongji University, Shanghai 201804, China.; Department of Traffic Engineering, Tongji University, Shanghai 201804, China, and also with the Key Laboratory of Road and Traffic Engineering, Ministry of Education, Tongji University, Shanghai 201804, China (e-mail: tianye@tongji.edu.cn).","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","12","Performing a left turn in a non-protected phase at mixed-flow intersections is one of the most challenging driving maneuvers. In general, there are three typical behavioral features during this turning process: multiple conflicting objects, multi-layer interaction between vehicles, non-motorized vehicles, and pedestrians, and long-term interaction event chains. In current studies, few models consider the impact of these three typical features simultaneously. This paper proposes a Conv-LSTM model to predict the positions of turning vehicles at each moment during the turning process in these complicated environments. The model uses convolution, which is an essential part of a convolutional neural network (CNN), to extract higher-level features across different time segments. Afterward, a long short-term memory (LSTM) network is employed to obtain the feature sequence with long-term dependence on the features of historical periods. Finally, the initial prediction of the Conv-LSTM is modified by the non-holonomic constraints of vehicles. Left-turning trajectories extracted from a simulation environment are used for model training and testing. As a result, the Conv-LSTM model performs better compared with the CNN and LSTM models. The average offset of every point on the trajectories is reduced by 50.4% and 37.1%, respectively, relative to the CNN and LSTM, and the interactive behaviors during the left-turn process are well reproduced by the proposed model. Another round of testing shows that the generalization ability of proposed model to real environments was initially proved to be feasible with the extracted ground-truth trajectories in the field environment.","","","10.1109/TITS.2019.2931701","National Natural Science Foundation of China; Shuguang Program through the Shanghai Education Development Foundation and Shanghai Municipal Education Commission; Shanghai Sailing Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8789528","Vehicle;turning behavior;long short-term memory;deep learning;mixed-flow intersections.","Turning;Feature extraction;Hidden Markov models;Deep learning;Planning;Convolution","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Compact and Computationally Efficient Representation of Deep Neural Networks","S. Wiedemann; K. Müller; W. Samek","Fraunhofer Heinrich Hertz Institute, 10587 Berlin, Germany.; Fraunhofer Heinrich Hertz Institute, 10587 Berlin, Germany.; Fraunhofer Heinrich Hertz Institute, 10587 Berlin, Germany (e-mail: wojciech.samek@hhi.fraunhofer.de).","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","14","At the core of any inference procedure, deep neural networks are dot product operations, which are the component that requires the highest computational resources. For instance, deep neural networks, such as VGG-16, require up to 15-G operations in order to perform the dot products present in a single forward pass, which results in significant energy consumption and thus limits their use in resource-limited environments, e.g., on embedded devices or smartphones. One common approach to reduce the complexity of the inference is to prune and quantize the weight matrices of the neural network. Usually, this results in matrices whose entropy values are low, as measured relative to the empirical probability mass distribution of its elements. In order to efficiently exploit such matrices, one usually relies on, inter alia, sparse matrix representations. However, most of these common matrix storage formats make strong statistical assumptions about the distribution of the elements; therefore, cannot efficiently represent the entire set of matrices that exhibit low-entropy statistics (thus, the entire set of compressed neural network weight matrices). In this paper, we address this issue and present new efficient representations for matrices with low-entropy statistics. Alike sparse matrix data structures, these formats exploit the statistical properties of the data in order to reduce the size and execution complexity. Moreover, we show that the proposed data structures can not only be regarded as a generalization of sparse formats but are also more energy and time efficient under practically relevant assumptions. Finally, we test the storage requirements and execution performance of the proposed formats on compressed neural networks and compare them to dense and sparse representations. We experimentally show that we are able to attain up to x42 compression ratios, x5 speed ups, and x90 energy savings when we bflossless convert the state-of-the-art networks, such as AlexNet, VGG-16, ResNet152, and DenseNet, into the new data structures and benchmark their respective dot product.","","","10.1109/TNNLS.2019.2910073","Fraunhofer Society through the MPI FhG collaboration project Theory and Practice for Reduced Learning Machines; German Ministry for Education through the Berlin Big Data Center; Berlin Center for Machine Learning; DFG EXC 2046 1; Information and Communications Technology Planning and Evaluation IITP Grant funded by the Korean Government; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8725933","Computationally efficient deep learning;data structures;lossless coding;neural network compression;sparse matrices.","Sparse matrices;Data structures;Entropy;Biological neural networks;Complexity theory;Quantization (signal)","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Deep Affinity Network for Multiple Object Tracking","S. Sun; N. AKHTAR; H. Song; A. S. Mian; M. Shah","School of Information Engineering, Chang'an University, 66350 Xian, Shanxi China (e-mail: shijieSun@chd.edu.cn); Computer Science and Software Engineering, The University of Western Australia, Crawley, Western Australia Australia 6009 (e-mail: navid.915@gmail.com); School of Information Engineering, Chang'an University, 66350 Xian, Shanxi China (e-mail: hshsong@chd.edu.cn); Computer Science, The University of Western Australia, Perth, Western Australia Australia 6009 (e-mail: ajmal.mian@uwa.edu.au); Center for Research in Computer Vision, University of Central Florida, Orlando, Florida United States 32792 (e-mail: shah@crcv.ucf.edu)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Multiple Object Tracking (MOT) plays an important role in solving many fundamental problems in video analysis and computer vision. Most MOT methods employ two steps: Object Detection and Data Association. The first step detects objects of interest in every frame of a video, and the second establishes correspondence between the detected objects in different frames to obtain their tracks. Object detection has made tremendous progress in the last few years due to deep learning. However, data association for tracking still relies on hand crafted constraints such as appearance, motion, spatial proximity, grouping etc. to compute affinities between the objects in different frames. In this paper, we harness the power of deep learning for data association in tracking by jointly modeling object appearances and their affinities between different frames in an end-to-end fashion. The proposed Deep Affinity Network (DAN) learns compact, yet comprehensive features of pre-detected objects at several levels of abstraction, and performs exhaustive pairing permutations of those features in any two frames to infer object affinities. DAN also accounts for multiple objects appearing and disappearing between video frames. We exploit the resulting efficient affinity computations to associate objects in the current frame deep into the previous frames for reliable on-line tracking. Our technique is evaluated on popular multiple object tracking challenges MOT15, MOT17 and UA-DETRAC. Comprehensive benchmarking under twelve evaluation metrics demonstrates that our approach is among the best performing techniques on the leader board for these challenges. The open source implementation of our work is available at https://github.com/shijieS/SST.git.","","","10.1109/TPAMI.2019.2929520","Team cultivation project of Central University; Australian Research Council; Intelligence Advanced Research Projects Activity; Joint Found of of Ministry of Education of China; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8766896","Multiple object tracking;Deep tracking;Deep affinity;Tracking challenge;On-line tracking","Object tracking;Computational modeling;Deep learning;Detectors;Target tracking;Feature extraction","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Multisource Domain Adaptation for Remote Sensing Using Deep Neural Networks","A. Elshamli; G. W. Taylor; S. Areibi","School of Engineering, University of Guelph, Guelph, ON N1G 2W1, Canada (e-mail: ashamli@uoguelph.ca).; School of Engineering, University of Guelph, Guelph, ON N1G 2W1, Canada, and also with the Vector Institute for Artificial Intelligence, Toronto, ON M5G 1M1, Canada.; School of Engineering, University of Guelph, Guelph, ON N1G 2W1, Canada.","IEEE Transactions on Geoscience and Remote Sensing","","2019","PP","99","1","13","In applying machine learning to remote sensing problems, it is often the case that multiple training data sources, known as domains, are available for the same task. It is sample-inefficient to train separate models per domain, which motivates learning a single model from multiple sources. For example, the local climate zone (LCZ) classification problem that aims to produce per-pixel classifications of surface structure from remotely sensed images of urban and rural environments. These classification maps need to be generated for different cities at different times. To do this efficiently, available training data from different sources (i.e., cities) must be adapted for the task at hand. However, multisource domain adaptation (MDA) is a challenging problem and is particularly apparent when there are significant changes in the data distribution among these sources. In this article, we propose a scalable yet simple adaptive MDA (AMDA) framework to address this problem. AMDA is also capable of dealing with imbalanced data distributions among the sources more effectively than existing baselines. We also extend two techniques originally proposed for domain expansion (DE) to the task of DA. AMDA and the extended DE techniques are implemented and evaluated on the LCZ classification problem. Despite its simplicity, AMDA is able to achieve more than 12% improvement over the baseline.","","","10.1109/TGRS.2019.2953328","Libyan Ministry of Higher Education; Natural Sciences and Engineering Research Council of Canada NSERC through Discovery; Natural Sciences and Engineering Research Council of Canada NSERC through Discovery; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8935505","Deep neural networks (DNNs);land-use classification;Learning without Forgetting (LwF);local climate zones (LCZ);multisource domain adaptation (MDA);representation learning;transfer learning.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Learning on Computerized Analysis of Chronic Obstructive Pulmonary Disease","G. Altan; Y. Kutlu; N. Allahverdi","Computer engineering, Iskenderun Technical University, Hatay Turkey 31200 (e-mail: gokhan.altan@iste.edu.tr); Computer engineering, Iskenderun Technical University, Hatay Turkey (e-mail: yakup.kutlu@iste.edu.tr); Computer Engineering Dept., KTO Karatay Universitesi, 218507 Konya, Konya Turkey (e-mail: novruz.allahverdi@karatay.edu.tr)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","Goal: Chronic obstructive pulmonary disease (COPD) is one of the deadliest diseases in the world. Because COPD is an incurable disease and requires considerable time to be diagnosed even by an experienced specialist, it becomes important to provide analysis abnormalities in simple ways. The aim of the study is comparing multiple machine learning algorithms for the early diagnosis of COPD using multi-channel lung sounds. Methods: Deep learning is an efficient machine-learning algorithm, which comprises unsupervised training to reduce optimization and supervised training by a feature-based distribution of classification parameters. This study focuses on analyzing multichannel lung sounds using statistical features of frequency modulations that are extracted using the Hilbert-Huang transform. Results: Deep learning algorithm was used in the classification stage of the proposed model to separate the patients with COPD and healthy subjects. The proposed DL model with the Hilbert-Huang transform based statistical features was successful in achieving high classification performance rates of 93.67%, 91%, and 96.33% for accuracy, sensitivity, and specificity, respectively. Conclusion: The proposed computerized analysis of the multi-channel lung sounds using DL algorithms provides a standardized assessment with high classification performance. Significance: Our study is a pioneer study that directly focuses on the lung sounds to separate COPD and non-COPD patients. Analyzing 12-channel lung sounds gives the advantages of assessing the entire lung obstructions.","","","10.1109/JBHI.2019.2931395","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8777195","Deep Learning;Deep Belief Networks;RespiratoryDatabase@TR;Chronic Obstructive Pulmonary Disease","Lung;Diseases;Classification algorithms;Transforms;Training;Feature extraction;Frequency modulation","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Adversarial Examples Versus Cloud-based Detectors: A Black-box Empirical Study","X. Li; S. Ji; M. Han; J. Ji; Z. Ren; Y. Liu; C. Wu","College of Computer Science and Technology, Zhejiang University, 12377 Hangzhou, Zhejiang China (e-mail: lixurong@zju.edu.cn); Institute of Cyberspace Research and the College of Computer Science and Technology at Zhejiang University, Hangzhou, Zhejiang, 310027, China. Alibaba-Zhejiang University Joint Institute of Frontier Technologies (A.Z.F.T.), Hangzhou, China. The School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, Georgia 30332, USA. (e-mail: sji@zju.edu.cn); College of Computing and Software Engineering, Kennesaw State University, Marietta, Georgia United States (e-mail: mhan9@kennesaw.edu); College of Computer Science and Technique, Zhejiang University, 12377 Hangzhou, Zhejiang China (e-mail: 3160102420@zju.edu.cn); Colleage of Computer Science and Technique, Zhejiang University, 12377 Hangzhou, Zhejiang China (e-mail: rzheny@zju.edu.cn); Department of Electrical Engineering, Princeton University, 6740 Princeton, New Jersey United States (e-mail: yushan@princeton.edu); College of Computer Science, Zhejiang University, HangZhou, ZheJiang China (e-mail: wuchunming@zju.edu.cn)","IEEE Transactions on Dependable and Secure Computing","","2019","PP","99","1","1","Deep learning has been broadly leveraged by major cloud providers, such as Google, AWS and Baidu, to offer various computer vision related services including image classification, object identification, illegal image detection, etc. While recent works extensively demonstrated that deep learning classification models are vulnerable to adversarial examples, cloud-based image detection models, which are more complicated than classifiers, may also have similar security concern but not get enough attention yet. In this paper, we mainly focus on the security issues of real-world cloud-based image detectors. Specifically, (1) based on effective semantic segmentation, we propose four attacks to generate semantics-aware adversarial examples via only interacting with black-box APIs; and (2) we make the first attempt to conduct an extensive empirical study of black-box attacks against real-world cloud-based image detectors. Through the comprehensive evaluations on five major cloud platforms: AWS, Azure, Google Cloud, Baidu Cloud, and Alibaba Cloud, we demonstrate that our image processing based attacks can reach a success rate of approximately 100%, and the semantic segmentation based attacks have a success rate over 90% among different detection services, such as violence, politician, and pornography detection. We also proposed several possible defense strategies for these security challenges in the real-life situation.","","","10.1109/TDSC.2019.2943467","Major Scientific Project of Zhejiang Lab; Provincial Key Research and Development Program of Zhejiang China; Alibaba-ZJU Joint Research Institute of Frontier Technologies; Zhejiang Provincial Natural Science Foundation for Distinguished Young Scholars; National Natural Science Foundation of China; National Key Research and Development Program of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8847461","Cloud Vision API;Cloud-based Image Detection Service;Deep Learning;Adversarial Examples","Detectors;Image segmentation;Deep learning;Google;Computer vision;Computational modeling;Semantics","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Image-Based Time Series Representations for Pixelwise Eucalyptus Region Classification: A Comparative Study","D. Dias; U. Dias; N. Menini; R. Lamparelli; G. Le Maire; R. da S. Torres","Institute of Computing, University of Campinas (UNICAMP), Campinas 13083-970, Brazil (e-mail:danielle.dias@ic.unicamp.br).; School of Technology, University of Campinas (UNICAMP), Limeira 13484-350, Brazil.; Institute of Computing, University of Campinas (UNICAMP), Campinas 13083-970, Brazil.; Núcleo Interdisciplinar de Planejamento Energético, University of Campinas (UNICAMP), Campinas 13083-970, Brazil.; Eco&Sols, CIRAD, Univ Montpellier, INRA, IRD, Montpellier SupAgro, 34000 Montpellier, France.; Department of ICT and Natural Sciences, Norwegian University of Science and Technology (NTNU), Ålesund, Norway.","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","Pixelwise image classification based on time series profiles has been very effective in several applications. In this letter, we investigate recently proposed image-based time series encoding approaches [e.g., Gramian angular summation field/Gramian angular difference field (GASF/GADF) and Markov transition field (MTF)] to support the identification of eucalyptus regions in remote sensing images. We perform a comparative study concerning the combination of image-based representations suitable for encoding the most important time series patterns with the ability of state-of-the-art deep-learning-based approaches for characterizing image visual properties. The comparative study demonstrates that the evaluated image representations, combined with different deep learning feature extractors lead to highly effective classification results, which are superior to those of recently proposed methods for time-series-based eucalyptus plantation detection.","","","10.1109/LGRS.2019.2946951","Conselho Nacional de Desenvolvimento Cientifico e Tecnologico Brasil CNPq; Sao Paulo Research Foundation FAPESP; FAPESP Microsoft Virtual Institute; Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior Brazil CAPES; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8890766","Deep learning;eucalyptus;image representation;pixelwise image classification;time series.","Time series analysis;Feature extraction;Image coding;Vegetation mapping;Task analysis;Remote sensing;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Automating the Configuration of MapReduce: A Reinforcement Learning Scheme","T. Mu; A. Al-Fuqaha; K. Salah","Computer Science Department, Western Michigan University, Kalamazoo, MI 49008 USA.; College of Science and Engineering, Hamad Bin Khalifa University, Doha, Qatar, and also with the Computer Science Department, Western Michigan University, Kalamazoo, MI 49008 USA (e-mail: aalfuqaha@hbku.edu.qa).; Electrical and Computer Engineering Department, Khalifa University of Science and Technology, Abu Dhabi, UAE.","IEEE Transactions on Systems, Man, and Cybernetics: Systems","","2019","PP","99","1","14","With the exponential growth of data and the high demand for the analysis of large datasets, the MapReduce framework has been widely utilized to process data in a timely, cost-effective manner. It is well-known that the performance of MapReduce is limited by its default configuration parameters, and there are a few research studies that have focused on finding the optimal configurations to improve the performance of the MapReduce framework. Recently, machine learning based approaches have been receiving more attention to be utilized to auto configure the MapReduce parameters to account for the dynamic nature of the applications. In this article, we propose and develop a reinforcement learning (RL)-based scheme, named RL-MRCONF, to automatically configure the MapReduce parameters. Specifically, we explore and experiment with two variations of RL-MRCONF; one variation is based on the traditional RL algorithm and the second is based on the deep RL algorithm. Results obtained from simulations show that the RL-MRCONF has the ability to successfully and effectively auto-configure the MapReduce parameters dynamically according to changes in job types and computing resources. Moreover, simulation results show our proposed RL-MRCONF scheme outperforms the traditional RL-based implementation. Using datasets provided by MR-Perf, simulation results show that our proposed scheme provides around 50% performance improvement in terms of execution time when compared with MapReduce using default settings.","","","10.1109/TSMC.2019.2951789","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8910465","Deep learning;deep Q-network (DQN);machine learning;MapReduce;neural networks;reinforcement learning (RL);self-configuration","Tuning;Reinforcement learning;Computational modeling;Dynamic scheduling;Scalability;Heuristic algorithms","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Intelligent Multi-microgrid Energy Management based on Deep Neural Network and Model-free Reinforcement Learning","Y. Du; F. Li","Department of EECS, The University of Tennessee, Knoxville. TN 37996, USA.; Department of EECS, The University of Tennessee, Knoxville. TN 37996, USA.","IEEE Transactions on Smart Grid","","2019","PP","99","1","1","In this paper, an intelligent multi-microgrid (MMG) energy management method is proposed based on deep neural network (DNN) and model-free reinforcement learning techniques. In the studied problem, multiple microgrids are connected to a main distribution system and they purchase power from the distribution system to maintain local consumption. From the perspective of the distribution system operator (DSO), the target is to decrease the demand-side peak-to-average ratio (PAR), and to maximize the profit from selling energy. To protect user privacy, DSO learns the multi-microgrid response by implementing a deep neural network (DNN) without direct access to user’s information. Further, the DSO selects its retail pricing strategy via a Monte Carlo method from reinforcement learning, which optimizes the decision based on prediction. The simulation results from the proposed data-driven deep learning method, as well as comparisons with conventional model-based methods, substantiate the effectiveness of the proposed approach in solving power system problems with partial or uncertain information.","","","10.1109/TSG.2019.2930299","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8769895","Deep neural network (DNN);Monte Carlo method;multi-microgrid;reinforcement learning;peak-to-average ratio (PAR).","Microgrids;Reinforcement learning;Peak to average power ratio;Mathematical model;Energy management;Computational modeling","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Novel Deep Fuzzy Classifier by Stacking Adversarial Interpretable TSK Fuzzy Sub-classifiers with Smooth Gradient Information","G. Suhang; F. Chung; S. Wang","School of Digital Media, Jiangnan University, 66374 Wuxi China 214122 (e-mail: gusuhang09@163.com); Computing, Hong Kong Polytechnic University, Hong Kong Hong Kong N.A. (e-mail: cskchung@comp.polyu.edu.hk); School of Information, Southern Yangtse University, WuXi, Jiangsu China 214122 (e-mail: wxwangst@aliyun.com)","IEEE Transactions on Fuzzy Systems","","2019","PP","99","1","1","Different from our previous stacked-structure-based deep fuzzy classifier, in this study, we explore the distinctive role of adversarial outputs of training samples in enhancing the classification performance of a stacked-structure-based deep fuzzy classifier. In order to achieve such goals, an adversarial Takagi-Sugeno-Kang (TSK) fuzzy classifier, which is denoted as TSKa, is proposed. With TSKa, interpretable IF-parts of first-order fuzzy rules can be generated by random selection of fixed linguistic terms along each feature. According to our theoretical analysis, adversarial outputs of training samples enhance TSKa's generalization capability, thereby resulting in the potential feasibility of leveraging their smooth gradient information with respect to the inputs in the training input space to construct a stacked-structure-based deep fuzzy classifier. In this paper, a novel deep fuzzy classifier is devised by stacking a series of TSKa sub-classifiers and training them by a deep learning strategy. An advantage of the proposed deep fuzzy classifier is its easy yet fast training. The training of each layer consists of two basic steps: computation of the smooth gradient information of adversarial outputs with respect to the inputs, and fast training of each corresponding TSKa by the least learning machine method. Comprehensive experiments on both benchmark datasets and an industrial case demonstrate the promising performance and advantages of the proposed deep fuzzy classifier.","","","10.1109/TFUZZ.2019.2919481","National Natural Science Foundation of China; Central Research Grant of the Hong Kong Polytechnic University; Fundamental Research Funds for the Central Universities; National First-class Discipline Program of Light Industry and Engineering; NSFC-JSPS; Natural Science Foundation of Jiangsu Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8723436","Takagi-Sugeno-Kang (TSK) fuzzy classifiers;stacked generalization;deep learning;smooth gradients;adversarial attacks","Training;Task analysis;Deep learning;Stacking;Linguistics;Benchmark testing;Media","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Adversarial Deep Learning for Over-the-Air Spectrum Poisoning Attacks","Y. Sagduyu; Y. Shi; T. Erpek","Network and Security, Intelligent Automation Inc., Rockville, Maryland United States 20855 (e-mail: ysagduyu@i-a-i.com); Electrical and Computer Engineering, Virginia Tech, 1757 Blacksburg, Virginia United States (e-mail: yshi@i-a-i.com); Electrical and Computer Engineering, Virginia Tech Research Center Arlington, 501436 Arlington, Virginia United States (e-mail: terpek@vt.edu)","IEEE Transactions on Mobile Computing","","2019","PP","99","1","1","An adversarial deep learning approach is presented to launch over-the-air spectrum poisoning attacks. A transmitter applies deep learning on its spectrum sensing results to predict idle time slots for data transmission. In the meantime, an adversary learns the transmitter's behavior (exploratory attack) by building another deep neural network to predict when transmissions will succeed. The adversary falsifies (poisons) the transmitter's spectrum sensing data over the air by transmitting during the short spectrum sensing period of the transmitter. Depending on whether the transmitter uses the sensing results as test data to make transmit decisions or as training data to retrain its deep neural network, either it is fooled into making incorrect decisions (evasion attack), or the transmitter's algorithm is retrained incorrectly for future decisions (causative attack). Both attacks are energy efficient and hard to detect (stealth) compared to jamming the long data transmission period, and substantially reduce the throughput. A dynamic defense is designed for the transmitter that deliberately makes a small number of incorrect transmissions (selected by the confidence score on channel classification) to manipulate the adversary's training data. This defense effectively fools the adversary (if any) and helps the transmitter sustain its throughput with or without an adversary present.","","","10.1109/TMC.2019.2950398","Army Research Office; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8887196","Adversarial machine learning;deep learning;spectrum poisoning;jamming;exploratory attack;evasion attack;causative attack;adversarial attacks;defense","Transmitters;Sensors;Jamming;Wireless communication;Neural networks;Throughput;Training data","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Adversarial Domain Adaptation Model for Bearing Fault Diagnosis","Z. Liu; B. Lu; H. Wei; L. Chen; X. Li; M. Rätsch","School of Information and Electrical Engineering, Hunan University of Science and Technology, Xiangtan 411201, China (e-mail: zhaohualiu2009@hotmail.com).; School of Information and Electrical Engineering, Hunan University of Science and Technology, Xiangtan 411201, China.; Department of Automatic Control and Systems Engineering, University of Sheffield, Sheffield S1 3JD, U.K..; School of Information and Electrical Engineering, Hunan University of Science and Technology, Xiangtan 411201, China.; School of Information and Electrical Engineering, Hunan University of Science and Technology, Xiangtan 411201, China.; Image Understanding and Interactive Robotics Group, Reutlingen University, 72762 Reutlingen, Germany.","IEEE Transactions on Systems, Man, and Cybernetics: Systems","","2019","PP","99","1","10","Fault diagnosis of rolling bearings is an essential process for improving the reliability and safety of the rotating machinery. It is always a major challenge to ensure fault diagnosis accuracy in particular under severe working conditions. In this article, a deep adversarial domain adaptation (DADA) model is proposed for rolling bearing fault diagnosis. This model constructs an adversarial adaptation network to solve the commonly encountered problem in numerous real applications: the source domain and the target domain are inconsistent in their distribution. First, a deep stack autoencoder (DSAE) is combined with representative feature learning for dimensionality reduction, and such a combination provides an unsupervised learning method to effectively acquire fault features. Meanwhile, domain adaptation and recognition classification are implemented using a Softmax classifier to augment classification accuracy. Second, the effects of the number of hidden layers in the stack autoencoder network, the number of neurons in each hidden layer, and the hyperparameters of the proposed fault diagnosis algorithm are analyzed. Third, comprehensive analysis is performed on real data to validate the performance of the proposed method; the experimental results demonstrate that the new method outperforms the existing machine learning and deep learning methods, in terms of classification accuracy and generalization ability.","","","10.1109/TSMC.2019.2932000","National Natural Science Foundation of China; Hunan Provincial Hu-Xiang Young Talents Project of China; Hunan Provincial Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8805261","Adversarial network;bearing;deep learning;deep neural networks;domain adaptation (DA);fault diagnosis;feature extraction;machine learning;stack autoencoder (SAE);unsupervised learning","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Intermediate Deep Feature Compression: Toward Intelligent Sensing","Z. Chen; K. Fan; S. Wang; L. Duan; W. Lin; A. C. Kot","Interdisciplinary Graduate School, Nanyang Technological University, Singapore.; School of Electronic and Computer Engineering, Shenzhen Graduate School, Peking University, Shenzhen, China.; Department of Computer Science, City University of Hong Kong, Kowloon, Hong Kong.; National Engineering Laboratory of Video Technology, the School of Electronics Engineering and Computer Science, Peking University, Beijing 100871, China, and also with the Peng Cheng Laboratory, Shenzhen 518055, China.; School of Computer Science and Engineering, Nanyang Technological University, Singapore.; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore.","IEEE Transactions on Image Processing","","2019","PP","99","1","1","The recent advances of hardware technology have made the intelligent analysis equipped at the front-end with deep learning more prevailing and practical. To better enable the intelligent sensing at the front-end, instead of compressing and transmitting visual signals or the ultimately utilized top-layer deep learning features, we propose to compactly represent and convey the intermediate-layer deep learning features with high generalization capability, to facilitate the collaborating approach between front and cloud ends. This strategy enables a good balance among the computational load, transmission load and the generalization ability for cloud servers when deploying the deep neural networks for large scale cloud based visual analysis. Moreover, the presented strategy also makes the standardization of deep feature coding more feasible and promising, as a series of tasks can simultaneously benefit from the transmitted intermediate layer features. We also present the results for evaluations of both lossless and lossy deep feature compression, which provide meaningful investigations and baselines for future research and standardization activities.","","","10.1109/TIP.2019.2941660","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8848858","Deep learning;intelligent front-end;feature compression","Visualization;Image coding;Task analysis;Feature extraction;Deep learning;Video coding;Standardization","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Understanding and Learning Discriminant Features based on Multi-Attention 1DCNN for Wheelset Bearing Fault Diagnosis","H. Wang; Z. Liu; D. Peng; Y. Qin","School of Mechanical and Electrical Engineering, University of Electronic Science and Technology of China, 12599 Chengdu China 611731 (e-mail: wh.huanwang@gmail.com); School of Mechanical and Electrical Engineering, University of Electronic Science and Technology of China, 12599 Chengdu China 611731 (e-mail: zhiliang_liu@uestc.edu.cn); School of Mechanical and Electrical Engineering, University of Electronic Science and Technology of China, 12599 Chengdu China 611731 (e-mail: dandanpeng2@gmail.com); State Key Laboratory of Rail Traffic Control and Safety, Beijing Jiaotong University, 47829 Beijing, Beijing China 100044 (e-mail: yqin@bjtu.edu.cn)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","Recently, deep learning based fault diagnosis methods have been widely studied for rolling bearings. However, these neural networks lack of interpretability for fault diagnosis tasks. That is, how to understand and learn discriminant fault features from complex monitoring signals remains a great challenge. Considering this challenge, this paper explores the use of attention mechanism in fault diagnosis networks and designs attention module by fully considering characteristics of rolling bearing faults to enhance fault-related features and to ignore irrelevant features. Powered by the proposed attention mechanism, a multi-attention one-dimensional convolutional neural network (MA1DCNN) is further proposed to diagnose wheelset bearing faults. The MA1DCNN can adaptively recalibrate features of each layer and can enhance the feature learning of fault impulses. Experimental results on the wheelset bearing dataset show that the proposed multi-attention mechanism can significantly improve discriminant feature representation, thus the MA1DCNN outperforms eight state-of-the-arts networks.","","","10.1109/TII.2019.2955540","State Key Laboratory of Traction Power; National Natural Science Foundation of China; State Key Laboratory of Rail Traffic Control and Safety; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8911240","Wheelset bearing;Fault diagnosis;Deep learning;Convolutional neural network;Attention mechanism","Fault diagnosis;Rolling bearings;Convolution;Feature extraction;Learning systems;Deep learning;Informatics","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Movie Tags Prediction and Segmentation Using Deep Learning","U. A. Khan; M. Á. Martínez-del-Amor; S. Altowaijri; A. Ahmed; A. U. Rahman; N. U. Sama; K. Haseeb; N. Islam","Department of Computer Systems Engineering, Quaid-E-Awam University of Engineering, Nawabshah, Pakistan.; Department of Computer Science and Artificial Intelligence, Universidad de Sevilla, Seville, Spain.; Faculty of Computing and Information Technology, Northern Border University, Rafha, Saudi Arabia.; Department of Telecommunication Engineering, Quaid-E-Awam University of Engineering, Nawabshah, Pakistan.; Faculty of Computing and Information Technology, Northern Border University, Rafha, Saudi Arabia and Faculty of Computer Information Science, Higher Colleges of Technology, Ras Al Khaimah Campus, UAE.; Faculty of Computer Science & Information Technology (FCSIT), University Malaysia Sarawak, 94300 Kota Samarahan, Sarawak, Malaysia.; Department of Computer Science, Islamia College Peshawar, Pakistan.; Department of Computer Science, Islamia College Peshawar, Pakistan.","IEEE Access","","2019","PP","99","1","1","The sheer volume of movies generated these days requires an automated analytics for efficient classification, query-based search, and extraction of desired information. These tasks can only be efficiently performed by a machine learning based algorithm. We address the same issue in this paper by proposing a deep learning based technique for predicting the relevant tags for a movie and segmenting the movie with respect to the predicted tags. We construct a tag vocabulary and create the corresponding dataset in order to train a deep learning model. Subsequently, we propose an efficient shot detection algorithm to find the key frames in the movie. The extracted key frames are analyzed by the deep learning model to predict the top three tags for each frame. The tags are then assigned weighted scores and are filtered to generate a compact set of most relevant tags. This process also generates a corpus which is further used to segment a movie based on a selected tag. We present a rigorous analysis of the segmentation quality with respect to the number of tags selected for the segmentation. Our detailed experiments demonstrate that the proposed technique is not only efficacious in predicting the most relevant tags for a movie, but also in segmenting the movie with respect to the selected tags with a high accuracy.","","","10.1109/ACCESS.2019.2963535","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8947961","Tags prediction;movie segmentation;deep learning;transfer learning","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Angle-Closure Detection in Anterior Segment OCT Based on Multilevel Deep Network","H. Fu; Y. Xu; S. Lin; D. W. K. Wong; M. Baskaran; M. Mahesh; T. Aung; J. Liu","Inception Institute of Artificial Intelligence, Abu Dhabi, UAE, and also with the Institute for Infocomm Research, Agency for Science, Technology and Research, Singapore 138632 (e-mail: huazhufu@gmail.com).; Department of Artificial Intelligence Innovation Business, Baidu Inc., Beijing 100193, China (e-mail: ywxu@ieee.org).; Microsoft Research, Beijing 100080, China.; Singapore Eye Research Institute, Singapore 168751, and also with Advanced Ocular Imaging, Nanyang Technological University, Singapore 138632.; Singapore Eye Research Institute, Singapore 168751.; Singapore Eye Research Institute, Singapore 168751.; Singapore Eye Research Institute, Singapore 168751, and also with the Yong Loo Lin School of Medicine, National University of Singapore, Singapore 119077.; Cixi Institute of Biomedical Engineering, Chinese Academy of Sciences, Zhejiang 315201, China, and also with the Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen 518055, China.","IEEE Transactions on Cybernetics","","2019","PP","99","1","9","Irreversible visual impairment is often caused by primary angle-closure glaucoma, which could be detected via anterior segment optical coherence tomography (AS-OCT). In this paper, an automated system based on deep learning is presented for angle-closure detection in AS-OCT images. Our system learns a discriminative representation from training data that captures subtle visual cues not modeled by handcrafted features. A multilevel deep network is proposed to formulate this learning, which utilizes three particular AS-OCT regions based on clinical priors: 1) the global anterior segment structure; 2) local iris region; and 3) anterior chamber angle (ACA) patch. In our method, a sliding window-based detector is designed to localize the ACA region, which addresses ACA detection as a regression task. Then, three parallel subnetworks are applied to extract AS-OCT representations for the global image and at clinically relevant local regions. Finally, the extracted deep features of these subnetworks are concatenated into one fully connected layer to predict the angle-closure detection result. In the experiments, our system is shown to surpass previous detection methods and other deep learning systems on two clinical AS-OCT datasets.","","","10.1109/TCYB.2019.2897162","BEP; Ningbo 3315 Innovation Team; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8642855","Angle-closure detection;anterior chamber angle (ACA);anterior segment optical coherence tomography (AS-OCT);deep learning","Image segmentation;Deep learning;Feature extraction;Imaging;Iris;Visualization;Cornea","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"A Double-Deep Spatio-Angular Learning Framework for Light Field based Face Recognition","A. Sepas-Moghaddam; M. A. Haque; P. L. Correia; K. Nasrollahi; T. B. Moeslund; F. Pereira","NA; NA; NA; NA; NA; NA","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Face recognition has attracted increasing attention due to its wide range of applications, but it is still challenging when facing large variations in the biometric data characteristics. Lenslet light field cameras have recently come into prominence to capture rich spatio-angular information, thus offering new possibilities for advanced biometric recognition systems. This paper proposes a double-deep spatio-angular learning framework for light field based face recognition, which is able to model both the intra-view/spatial and inter-view/angular information using two deep networks in sequence. This is a novel recognition framework that has never been proposed in the literature for face recognition or any other visual recognition task. The proposed double-deep learning framework includes a long short-term memory (LSTM) recurrent network whose inputs are VGG-Face descriptions, computed using a VGG-16 convolutional neural network (CNN). The VGG-Face spatial descriptions are extracted from a selected set of 2D sub-aperture (SA) images rendered from the light field image, corresponding to different observation angles. A sequence of the VGG-Face spatial descriptions is then be analysed by the LSTM network. A comprehensive set of experiments has been conducted using the IST-EURECOM light field face database, addressing varied and challenging recognition tasks. Results show that the proposed framework achieves superior face recognition performance when compared to the state-of-the-art.","","","10.1109/TCSVT.2019.2916669","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8713930","Face Recognition;Lenslet Light Field Imaging;Spatio-Angular Information;Deep Learning;VGG-Face Descriptor;VGG-Very-Deep-16 CNN;Long Short-Term Memory Network","Light fields;Face recognition;Cameras;Face;Two dimensional displays;Visualization","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Eh?Predictor: A Deep Learning Framework to Identify Detailed Routing Short Violations from a Placed Netlist","A. F. Tabrizi; N. K. Darav; L. Rakai; I. Bustany; A. Kennings; L. Behjat","NA; NA; NA; NA; NA; NA","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","","2019","PP","99","1","1","Detailed routing is one of the most challenging aspects of the physical design process. Many of the violations that occur during the detailed routing stage stem from the placement of the cells. In this paper, we propose a deep learning framework to identify short violations that can occur during detailed routing from a placed netlist. One of the advantages of our technique is that by using the proposed deep learning based predictor, global routing is no longer required as frequently and hence the total runtime for place and route can be significantly reduced. In this paper, we discuss the proposed framework and the methodology for analyzing the extracted features. The experimental results show that the average sensitivity, specificity and accuracy of Eh?Predictor is above 90%. In addition, we show that Eh?Predictor is up to 14 times faster than NCTUgr for smaller designs and up to 96 times faster for larger designs.","","","10.1109/TCAD.2019.2917130","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8716564","Design automation;physical design;routing;placement;data mining;machine learning;imbalanced data.","Routing;Deep learning;Wires;Feature extraction;Training;Physical design","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Learning Heterogeneous Features Jointly: A Deep End-to-End Framework for Multi-Step Short-Term Wind Power Prediction","J. Chen; Q. Zhu; H. Li; L. Zhu; D. Shi; Y. Li; X. Duan; Y. Liu","School of Electrical and Electronic Engineering, Huazhong University of Science and Technology, 12443 Wuhan, Hubei China (e-mail: chenjinfu@mail.hust.edu.cn); School of Electrical and Electronic Engineering, Huazhong University of Science and Technology, 12443 Wuhan, Hubei China (e-mail: clark@hust.edu.cn); Economic and Technological Research Institute, State Grid Hunan Electric Power Company Limited, 529094 Changsha China (e-mail: lhydudu@gmail.com); Department of Electrical Engineering and Computer Science, University of Tennessee, 4285 Knoxville, Tennessee United States (e-mail: lzhu12@utk.edu); School of Electrical and Electronic Engineering, Huazhong University of Science and Technology, 12443 Wuhan, Hubei China (e-mail: dongyuanshi@hust.edu.cn); School of Electrical and Electronic Engineering, Huazhong University of Science and Technology, 12443 Wuhan, Hubei China (e-mail: liyinhong@hust.edu.cn); School of Electrical and Electronic Engineering, Huazhong University of Science and Technology, 12443 Wuhan, Hubei China (e-mail: xzduan@hust.edu.cn); Department of Electrical Engineering and Computer Science, University of Tennessee, 4285 Knoxville, Tennessee United States (e-mail: Liu@utk.edu)","IEEE Transactions on Sustainable Energy","","2019","PP","99","1","1","Leveraging multiple heterogeneous measurements to predict wind power has long been a challenging task in the electrical community. In this paper, a deep architecture incorporated with multitask learning and multimodal learning for wind power prediction, termed predictive stacked autoencoder (PSAE), is presented. PSAE is a unified framework integrating multiple stacked autoencoders (SAEs), one feature fusion layer, and one prediction terminal layer, which expands the architecture from two spatial dimensions, including the depth and width, compared to conventional prediction models. Initially, the SAEs at the bottom of PSAE extracted features from multiple kinds of measurements respectively. Following, the feature fusion layer encodes the high-order features extracted by different SAEs into a unified feature that is more informative and representative for wind power prediction. Finally, the prediction terminal layer functions as a regression machine which generates the predicted targets based on the fusion features. Trained in an end-to-end (E2E) manner, PSAE is capable of learning heterogeneous features jointly and achieving the prediction task of sequence-to-sequence (S2S). Experiments for multi-step short-term predictions are conducted on real-world data, and the results demonstrate the superiority of PSAE to prior methods.","","","10.1109/TSTE.2019.2940590","Ministry of Science and Technology of the Peoples Republic of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8828090","Deep learning;heterogeneous features;multimodal learning;multitask learning;sequence-to-sequence prediction;wind power prediction","Wind power generation;Feature extraction;Predictive models;Task analysis;Time measurement;Wind speed;Power measurement","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Latent Spectral Representation Learning-Based Hyperspectral Band Selection for Target Detection","W. Xie; J. Lei; J. Yang; Y. Li; Q. Du; Z. Li","State Key Laboratory of Integrated Service Networks, Xidian University, Xi'an 710071, China.; State Key Laboratory of Integrated Service Networks, Xidian University, Xi'an 710071, China, and also with the Science and Technology on Electro-Optic Control Laboratory, Luoyang 471000, China. (e-mail: jielei@mail.xidian.edu.cn).; State Key Laboratory of Integrated Service Networks, Xidian University, Xi'an 710071, China.; State Key Laboratory of Integrated Service Networks, Xidian University, Xi'an 710071, China. (e-mail: ysli@mail.xidian.edu.cn).; Department of Electronic and Computer Engineering, Mississippi State University, Starkville, MS 39759 USA.; Institute of Spacecraft System Engineering, China Academy of Space Technology (CAST), Beijing 100094, China.","IEEE Transactions on Geoscience and Remote Sensing","","2019","PP","99","1","12","Hyperspectral images (HSIs) can provide discriminative spectral signatures regarding the physical nature of different materials. It is this unique nature that makes HSIs to be of great interest in many fields. However, HSI application faces various challenges due to high dimensionality, redundant information, noisy bands, and insufficient samples. To address these problems, we propose an unsupervised band selection method based on deep latent spectral representation learning, called DLSRL, in this article. It imposes spectral consistency on deep latent space that resolves the issue of insufficient samples and spectral information lost in HSI interpretation. It pursues the low-dimensional optimal representation of the high-dimensional HSIs. In particular, an adaptive mapping relationship is constructed between the deep latent representation and the optimal subset to preserve physical significance optimally. Furthermore, a hierarchical optimization approach is introduced to achieve target detection with the selected subset. To verify the superiority of the proposed method, experiments have been conducted on four data sets captured by different sensors over different scenes. Comparative analyses validate that the proposed method presents superior performance in terms of high detection accuracy and low false alarm rate.","","","10.1109/TGRS.2019.2952091","National Natural Science Foundation of China; Young Talent Fund of the University Association for Science and Technology in Shaanxi of China; Special Financial Grant from the China Postdoctoral Science Foundation; Higher Education Discipline Innovation Project; Fundamental Research Funds for the Central Universities; Natural Science Basic Research Plan in Shaanxi Province of China; General Financial Grant from the China Postdoctoral Science Foundation; Yangtse River Scholar Bonus Schemes; Ten Thousand Talent Program and in part by the Science and Technology on Electro Optic Control Laboratory and Aeronautical Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8913676","Band selection;hierarchical optimization;hyperspectral image (HSI);representation learning;spectral consistency.","Hyperspectral imaging;Feature extraction;Object detection;Optimization;Principal component analysis;Noise measurement","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Transfer Learning for Segmenting Dimensionally Reduced Hyperspectral Images","J. Nalepa; M. Myller; M. Kawulok","Silesian University of Technology, 44-100 Gliwice, Poland and also with KP Labs, 44-100 Gliwice, Poland (e-mail: jnalepa@ieee.org).; Silesian University of Technology, 44-100 Gliwice, Poland and also with KP Labs, 44-100 Gliwice, Poland.; Silesian University of Technology, 44-100 Gliwice, Poland and also with KP Labs, 44-100 Gliwice, Poland.","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","Deep learning has established the state of the art in multiple fields, including hyperspectral image analysis. However, training large-capacity learners to segment such imagery requires representative training sets. Acquiring such data is human-dependent and time-consuming, especially in earth observation scenarios, where the hyperspectral data transfer is very costly and time-constrained. In this letter, we show how to effectively deal with a limited number and size of available hyperspectral ground-truth sets and apply transfer learning for building deep feature extractors. Also, we exploit spectral dimensionality reduction to make our technique applicable over hyperspectral data acquired using different sensors, which may capture different numbers of hyperspectral bands. The experiments, performed over several benchmarks and backed up with statistical tests, indicated that our approach allows us to effectively train well-generalizing deep convolutional neural nets even using significantly reduced data.","","","10.1109/LGRS.2019.2942832","European Space Agency; Polish National Centre for Research and Development; Silesian University of Technology Poland; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8864017","Classification;deep learning;hyperspectral imaging;segmentation;transfer learning.","Feature extraction;Hyperspectral imaging;Training;Earth;Sensors;Image segmentation","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Constrained EV Charging Scheduling Based on Safe Deep Reinforcement Learning","H. Li; Z. Wan; H. He","Department of Electrical, Computer and Biomedical Engineering, University of Rhode Island, RI 02881 USA.; Department of Electrical, Computer and Biomedical Engineering, University of Rhode Island, RI 02881 USA.; Department of Electrical, Computer and Biomedical Engineering, University of Rhode Island, RI 02881 USA.","IEEE Transactions on Smart Grid","","2019","PP","99","1","1","Electric vehicles (EVs) have been popularly adopted and deployed over the past few years because they are environment-friendly. When integrated into smart grids, EVs can operate as flexible loads or energy storage devices to participate in demand response (DR). By taking advantage of time-varying electricity prices in DR, the charging cost can be reduced by optimizing the charging/discharging schedules. However, since there exists randomness in the arrival and departure time of an EV and the electricity price, it is difficult to determine the optimal charging/discharging schedules to guarantee that the EV is fully charged upon departure. To address this issue, we formulate the EV charging/discharging scheduling problem as a constrained Markov Decision Process (CMDP). The aim is to find a constrained charging/discharging scheduling strategy to minimize the charging cost as well as guarantee the EV can be fully charged. To solve the CMDP, a model-free approach based on safe deep reinforcement learning (SDRL) is proposed. The proposed approach does not require any domain knowledge about the randomness. It directly learns to generate the constrained optimal charging/discharging schedules with a deep neural network (DNN). Unlike existing reinforcement learning (RL) or deep RL (DRL) paradigms, the proposed approach does not need to manually design a penalty term or tune a penalty coefficient. Numerical experiments with real-world electricity prices demonstrate the effectiveness of the proposed approach.","","","10.1109/TSG.2019.2955437","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8910361","Constrained Markov Decision Process;safe deep reinforcement learning;model-free;EV charging scheduling.","Electric vehicle charging;Schedules;Real-time systems;Scheduling;Batteries;Reinforcement learning;Neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Facial Action Unit Detection Using Attention and Relation Learning","Z. Shao; Z. Liu; J. Cai; Y. Wu; L. Ma","Department of Computer Science and Engineering, Shanghai Jiao Tong University, 12474 Shanghai, Shanghai China 200240 (e-mail: shaozhiwen@sjtu.edu.cn); School of Computer Science and Technology, Tianjin University, Tianjin, Tianjin China 300072 (e-mail: zhileiliu@tju.edu.cn); School of Computer Engineering, Nanyang Technological University, Singapore, Singapore Singapore (e-mail: asjfcai@ntu.edu.sg); Youtu Lab, Tencent, Shanghai, Shanghai China (e-mail: simonwu@tencent.com); School of Computer Science and Software Engineering, East China Normal University, 12655 Shanghai, Shanghai China 200062 (e-mail: ma-lz@cs.sjtu.edu.cn)","IEEE Transactions on Affective Computing","","2019","PP","99","1","1","Attention mechanism has recently attracted increasing attentions in the field of facial action unit (AU) detection. By finding the region of interest of each AU with the attention mechanism, AU-related local features can be captured. Most of the existing attention based AU detection works use prior knowledge to predefine fixed attentions or refine the predefined attentions within a small range, which limits their capacity to model various AUs. In this paper, we propose an end-to-end deep learning based attention and relation learning framework for AU detection with only AU labels, which has not been explored before. In particular, multi-scale features shared by each AU are learned firstly, and then both channel-wise and spatial attentions are adaptively learned to select and extract AU-related local features. Moreover, pixel-level relations for AUs are further captured to refine spatial attentions so as to extract more relevant local features. Without changing the network architecture, our framework can be easily extended for AU intensity estimation. Extensive experiments show that our framework (i) soundly outperforms the state-of-the-art methods for both AU detection and AU intensity estimation on the challenging BP4D, DISFA, FERA 2015 and BP4D+ benchmarks, (ii) can adaptively capture the correlated regions of each AU, and (iii) also works well under severe occlusions and large poses.","","","10.1109/TAFFC.2019.2948635","National Social Science Foundation of China; Science and Technology Commission of Shanghai Municipality Program; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8880512","Channel-wise and spatial attention learning;pixel-level relation learning;facial AU detection","Gold;Feature extraction;Estimation;Face;Deep learning;Computer science;Learning systems","","","","","","","","","","IEEE","IEEE Early Access Articles"
"DeepWiFi: Cognitive WiFi with Deep Learning","K. Davaslioglu; S. Soltani; T. Erpek; Y. Sagduyu","Networks and Security Group, Distributed Intelligent Systems Division, Intelligent Automation Inc, 338481 Rockville, Maryland United States (e-mail: kdavaslioglu@i-a-i.com); Networks and Security Group, Distributed Intelligent Systems Division, Intelligent Automation, Inc., Rockville, Maryland United States (e-mail: ssoltani@i-a-i.com); Electrical and Computer Engineering, Virginia Tech Research Center Arlington, 501436 Arlington, Virginia United States (e-mail: terpek@vt.edu); Network and Security, Intelligent Automation Inc., Rockville, Maryland United States (e-mail: ysagduyu@i-a-i.com)","IEEE Transactions on Mobile Computing","","2019","PP","99","1","1","We present the DeepWiFi protocol, which hardens the baseline WiFi (IEEE 802.11ac) with deep learning and sustains high throughput by mitigating out-of-network interference. DeepWiFi is interoperable with baseline WiFi and builds upon the existing WiFi's PHY transceiver chain without changing the MAC frame format. Users run DeepWiFi for i) RF front end processing; ii) spectrum sensing and signal classification; iii) signal authentication; iv) channel selection and access; v) power control; vi) modulation and coding scheme (MCS) adaptation; and vii) routing. DeepWiFi mitigates the effects of probabilistic, sensing-based, and adaptive jammers. RF front end processing applies a deep learning-based autoencoder to extract spectrum-representative features. Then a deep neural network is trained to classify waveforms reliably as idle, WiFi, or jammer. Utilizing channel labels, users effectively access idle or jammed channels, while avoiding interference with legitimate WiFi transmissions (authenticated by machine learning-based RF fingerprinting) resulting in higher throughput. Users optimize their transmit power for low probability of intercept/detection and their MCS to maximize link rates used by backpressure algorithm for routing. Supported by embedded platform implementation, DeepWiFi provides major throughput gains compared to baseline WiFi and another jamming-resistant protocol, especially when channels are likely to be jammed and the signal-to-interference-plus-noise-ratio is low.","","","10.1109/TMC.2019.2949815","Small Business Innovation Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8884151","WiFi;machine learning;deep learning;dynamic spectrum access;RF signal processing;signal classification;signal authentication","Wireless fidelity;Jamming;Radio frequency;Feature extraction;Protocols;Sensors;Routing","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Reinforcement Learning for Strategic Bidding in Electricity Markets","Y. Ye; D. Qiu; M. Sun; D. Papadaskalopoulos; G. Strbac","Fetch.AI, St. John’s Innovation Centre, Cambridge, CB4 0WS, U.K. and also with the Department of Electrical and Electronic Engineering, Imperial College London, London SW7 2AZ, U.K.; Department of Electrical and Electronic Engineering, Imperial College London, London, U.K.; Department of Electrical and Electronic Engineering, Imperial College London, London, U.K.; Department of Electrical and Electronic Engineering, Imperial College London, London, U.K.; Department of Electrical and Electronic Engineering, Imperial College London, London, U.K.","IEEE Transactions on Smart Grid","","2019","PP","99","1","1","Bi-level optimization and reinforcement learning (RL) constitute the state-of-the-art frameworks for modeling strategic bidding decisions in deregulated electricity markets. However, the former neglects the market participants’ physical non-convex operating characteristics, while conventional RL methods require discretization of state and / or action spaces and thus suffer from the curse of dimensionality. This paper proposes a novel deep reinforcement learning (DRL) based methodology, combining a deep deterministic policy gradient (DDPG) method with a prioritized experience replay (PER) strategy. This approach sets up the problem in multi-dimensional continuous state and action spaces, enabling market participants to receive accurate feedback regarding the impact of their bidding decisions on the market clearing outcome, and devise more profitable bidding decisions by exploiting the entire action domain, also accounting for the effect of non-convex operating characteristics. Case studies demonstrate that the proposed methodology achieves a significantly higher profit than the alternative state-of-the-art methods, and exhibits a more favourable computational performance than benchmark RL methods due to the employment of the PER strategy.","","","10.1109/TSG.2019.2936142","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8805177","Bi-level optimization;deep neural networks;deep reinforcement learning;electricity markets;strategic bidding;unit commitment.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Fast Calculation of Probabilistic Power Flow: A Model-based Deep Learning Approach","Y. Yang; Z. Yang; J. Yu; B. Zhang; Y. Zhang; H. Yu","Chongqing University, Chongqing 400044, China.; Chongqing University, Chongqing 400044, China.; Chongqing University, Chongqing 400044, China.; Department of Electrical and Computer Engineering, University of Washington, Seattle, WA 98195, USA.; State Grid Chongqing Electric Power Company Electric Power Research Institute, Chongqing 401123, China.; State Grid Chongqing Electric Power Company Electric Power Research Institute, Chongqing 401123, China.","IEEE Transactions on Smart Grid","","2019","PP","99","1","1","Probabilistic power flow (PPF) plays a critical role in power system analysis. However, the high computational burden makes it challenging for the practical implementation of PPF. This paper proposes a model-based deep learning approach to overcome the computational challenge. A deep neural network (DNN) is used to approximate the power flow calculation and is trained according to the physical power flow equations to improve its learning ability. The training process consists of several steps: 1) the branch flows are added into the objective function of the DNN as a penalty term, which improves the approximation accuracy of the DNN; 2) the gradients used in the back propagation process are simplified according to the physical characteristics of the transmission grid, which accelerates the training speed while maintaining effective guidance of the physical model; and 3) an improved initialization method for the DNN parameters is proposed to improve the convergence speed. The simulation results demonstrate the accuracy and efficiency of the proposed method in standard IEEE and utility benchmark systems.","","","10.1109/TSG.2019.2950115","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8887248","Model-based deep learning;initialization method;deep neural network;probabilistic power flow.","Load flow;Training;Mathematical model;Uncertainty;Neural networks;Standards;Probabilistic logic","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Learning for Environment Identification in Vehicular Networks","M. Elwekeil; T. Wang; S. Zhang","Guangdong Laboratory of Artificial Intelligence and Digital Economy (SZ), Shenzhen University, Shenzhen 518060, China, and also with the Department of Electronics and Electrical Communications Engineering, Faculty of Electronic Engineering, Menoufia University, Menouf 32952, Egypt.; Guangdong Laboratory of Artificial Intelligence and Digital Economy (SZ), Shenzhen University, Shenzhen 518060, China. (e-mail: ttwang@szu.edu.cn); Guangdong Laboratory of Artificial Intelligence and Digital Economy (SZ), Shenzhen University, Shenzhen 518060, China.","IEEE Wireless Communications Letters","","2019","PP","99","1","1","This paper proposes a deep learning approach for identifying the ambient environment of smart vehicles. Without deploying any dedicated sensors, we exploit the available wireless channel measurements at the wireless receivers of smart vehicles to identify the surrounding environment so that smart vehicles can behave accordingly. We treat the environment identification problem as a multi-class classification problem and employ a deep convolutional neural network (DCNN) to tackle it. The past observations of the estimated channel state information are used as the input features to train the DCNN. Then, the trained DCNN is deployed on vehicles to perform environment identifications. Our numerical results show that the proposed DCNN approach accurately identifies the surrounding environment and achieves the best classification performance compared to other rival machine learning approaches.","","","10.1109/LWC.2019.2959768","Shenzhen NSF project; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933039","Vehicular networks;environment identification;deep learning;deep convolutional neural networks;intelligent transportation systems.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"When Wireless Video Streaming Meets AI: A Deep Learning Approach","L. Liu; H. Hu; Y. Luo; Y. Wen","NA; NA; NA; NA","IEEE Wireless Communications","","2019","PP","99","2","8","Wireless multimedia big data contains valuable information on users' behavior, content characteristics and network dynamics, which can drive system design and optimization. The fundamental issue is how to mine data intelligence and further incorporate them into wireless multimedia systems. Motivated by the success of deep learning, in this work we propose and present an integration of wireless multimedia systems and deep learning. We start with decomposing a wireless multimedia system into three components, including end-users, network environment, and servers, and present several potential topics to embrace deep learning techniques. After that, we present deep learning based QoS/QoE prediction and bitrate adjustment as two case-studies. In the former case, we present an end-to-end and unified framework that consists of three phases, including data preprocessing, representation learning, and prediction. It achieves significant performance improvement in comparison to the best baseline algorithm (88 percent vs. 80 percent). In the latter case, we present a deep reinforcement learning based framework for bitrate adjustment. Evaluating the performance with a real wireless dataset, we show that the perceived video QoE average bitrate, rebuffering time and bitrate variation can be improved significantly.","","","10.1109/MWC.001.1900220","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8858585","","Streaming media;Wireless communication;Deep learning;Bit rate;Multimedia systems;Neural networks;Quality of service","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Spatiotemporal Anomaly Detection using Deep Learning for Real-time Video Surveillance","R. Nawaratne; D. Alahakoon; D. De Silva; X. Yu","La Trobe University, 2080 Melbourne, Victoria Australia 3086 (e-mail: B.Nawaratne@latrobe.edu.au); La Trobe University, 2080 Bundoora, Victoria Australia 3086 (e-mail: D.Alahakoon@latrobe.edu.au); Bundoora, Victoria Australia 3086 (e-mail: d.desilva@latrobe.edu.au); RMIT University, 5376 Melbourne, Victoria Australia 3000 (e-mail: x.yu@rmit.edu.au)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","Rapid developments in urbanisation and autonomous industrial environments have augmented and expedited the need for intelligent real-time video surveillance. Recent developments in artificial intelligence for anomaly detection in video surveillance only address some of the challenges, largely overlooking the evolving nature of anomalous behaviours over time. Tightly-coupled dependence on a known normality training dataset and sparse evaluation based on reconstruction error are further limitations. In this paper, we propose the Incremental Spatio-Temporal Learner (ISTL) to address challenges and limitations of anomaly detection and localisation for real-time video surveillance. ISTL is an unsupervised deep learning approach that utilises active learning with fuzzy aggregation, to continuously update and distinguish between new anomalies and normality that evolve over time. ISTL is demonstrated and evaluated on accuracy, robustness, computational overhead as well as contextual indicators, using three benchmark datasets. Results of these experiments validate our contribution and confirm its suitability for real-time video surveillance.","","","10.1109/TII.2019.2938527","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8820090","Unsupervised Learning;Anomaly Detection;Anomaly Localisation;Deep Learning;Active Learning;Real-time Video Surveillance;Spatiotemporal Analysis","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"DRAG: Deep Reinforcement Learning Based Base Station Activation in Heterogeneous Networks","J. YE; Y. J. Zhang","Information Engineering, The Chinese University of Hong Kong, Hong Kong, Hong Kong Hong Kong (e-mail: yejunhong1988@gmail.com); Information Engineering, The Chinese University of Hong Kong, Hong Kong, Shatin Hong Kong NA (e-mail: yjzhang@ie.cuhk.edu.hk)","IEEE Transactions on Mobile Computing","","2019","PP","99","1","1","Heterogeneous Network (HetNet), where Small cell Base Stations (SBSs) are densely deployed to offload traffic from macro Base Stations (BSs), is identified as a key solution to meet the unprecedented mobile traffic demand. The high density of SBSs are designed for peak traffic hours and consume an unnecessarily large amount of energy during off-peak time. In this paper, we propose a deep reinforcement-learning based SBS activation strategy that activates the optimal subset of SBSs to significantly lower the energy consumption without compromising the quality of service. In particular, we formulate the SBS on/off switching problem into a Markov Decision Process that can be solved by Actor Critic (AC) reinforcement learning methods. To avoid prohibitively high computational and storage costs of conventional tabular-based approaches, we propose to use deep neural networks to approximate the policy and value functions in the AC approach. Moreover, to expedite the training process, we adopt a Deep Deterministic Policy Gradient (DDPG) approach together with a novel action refinement scheme. Through extensive numerical simulations, we show that the proposed scheme greatly outperforms the existing methods in terms of both energy efficiency and computational efficiency. We also show that the proposed scheme can scale to large system with polynomial complexities in both storage and computation.","","","10.1109/TMC.2019.2922602","Research Grants Council University Grants Committee; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8735834","Heterogeneous network;base station activation;energy efficiency;deep reinforcement learning","Energy consumption;Base stations;Quality of service;Degradation;Switches;Reinforcement learning;Mobile computing","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deeply Encoding Stable Patterns From Contaminated Data for Scenery Image Recognition","L. Zhang; X. Ju; Y. Shang; X. Li","College of Computer Sciences, Zhejiang University, Hangzhou 310027, China.; School of Computer Science and Software Engineering, East China Normal University, Shanghai 200241, China.; School of Aeronautics and Astronautics, Zhejiang University, Hangzhou 310027, China (e-mail: yonghengshang7@zju.edu.cn).; School of Computer Science, Northwestern Polytechnical University, Xi'an 710072, China, and also with the Center for Optical Imagery Analysis and Learning, Northwestern Polytechnical University, Xi'an 710072, China.","IEEE Transactions on Cybernetics","","2019","PP","99","1","10","Effectively recognizing different sceneries with complex backgrounds and varied lighting conditions plays an important role in modern AI systems. Competitive performance has recently been achieved by the deep scene categorization models. However, these models implicitly hypothesize that the image-level labels are 100% correct, which is too restrictive. Practically, the image-level labels for massive-scale scenery sets are usually calculated by external predictors such as ImageNet-CN. These labels can easily become contaminated because no predictors are completely accurate. This article proposes a new deep architecture that calculates scene categories by hierarchically deriving stable templates, which are discovered using a generative model. Specifically, we first construct a semantic space by incorporating image-level labels using subspace embedding. Afterward, it is noticeable that in the semantic space, the superpixel distributions from identically labeled images remain unchanged, regardless of the image-level label noises. On the basis of this observation, a probabilistic generative model learns the stable templates for each scene category. To deeply represent each scenery category, a novel aggregation network is developed to statistically concatenate the CNN features learned from scene annotations predicted by HSA. Finally, the learned deep representations are integrated into an image kernel, which is subsequently incorporated into a multiclass SVM for distinguishing scene categories. Thorough experiments have shown the performance of our method. As a byproduct, an empirical study of 33 SIFT-flow categories shows that the learned stable templates remain almost unchanged under a nearly 36% image label contamination rate.","","","10.1109/TCYB.2019.2951798","National Natural Science Foundation of China; National Basic Research Program of China (973 Program); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8917698","Deep learning;machine learning;probabilistic model;scene categorization;stable templates","Semantics;Noise measurement;Feature extraction;Image recognition;Probabilistic logic;Cybernetics;Robots","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Reinforcement Learning for UAV Navigation Through Massive MIMO Technique","H. Huang; Y. Yang; H. Wang; Z. Ding; H. Sari; F. Adachi","Key Lab of Broadband Wireless Communication and Sensor Network Technology, Nanjing University of Posts and Telecommunications, 12577 Nanjing, Jiangsu China 210003 (e-mail: hongji.huang@ieee.org); Jilin University, 12510 Changchun, Jilin China (e-mail: yuchunyang.ee@gmail.com); Nanjing University of Posts and Telecommunications, 12577 Nanjing, Jiangsu China (e-mail: wanghong@njupt.edu.cn); University of Manchester, Manchester, Manchester United Kingdom of Great Britain and Northern Ireland M13 9PL (e-mail: zhiguo.ding@manchester.ac.uk); Nanjing University of Posts and Telecommunications, 12577 Nanjing, Jiangsu China (e-mail: hsari@ieee.org); Tohoku University, Sendai-shi, Miyagi-ken Japan 980-8579 (e-mail: adachi@ecei.tohoku.ac.jp)","IEEE Transactions on Vehicular Technology","","2019","PP","99","1","1","Unmanned aerial vehicles (UAVs) technique has been recognized as a promising solution in future wireless connectivity from the sky, and UAV navigation is one of the most significant open research problems, which has attracted wide interest in the research community. However, the current UAV navigation schemes are unable to capture the UAV motion and select the best UAV-ground links in real-time, and these weaknesses overwhelm the UAV navigation performance. To tackle these fundamental limitations, in this paper, we merge the state-of-theart deep reinforcement learning with the UAV navigation through massive multiple input multiple output (MIMO) technique. To be specific, we carefully design a deep Q-network (DQN) for optimizing the UAV navigation by selecting the optimal policy, and then we propose a learning mechanism for processing the DQN. The DQN is trained so that the agent is capable of making decisions based on the received signal strengths for navigating the UAVs with the aid of the powerful Q-learning. Simulation results are provided to corroborate the superiority of the proposed schemes in terms of the coverage and convergence compared with that of other schemes.","","","10.1109/TVT.2019.2952549","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8894381","Massive multiple-input-multiple-output;deep reinforcement learning;UAV navigation","Navigation;Reinforcement learning;Wireless communication;Unmanned aerial vehicles;Signal to noise ratio","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Fuzzy K-Means with Adaptive Loss and Entropy Regularization","R. Zhang; X. Li; H. Zhang; F. Nie","School of Computer Science and Center for OPTical IMagery Analysis and Learning (OPTIMAL), Northwestern Polytechnical University, 26487 Xi'an China 710072 (e-mail: ruizhang8633@gmail.com); School of Computer Science and Center for OPTIMAL, Northwestern Polytechnical University, 26487 Xi'an, Shaanxi China (e-mail: li@nwpu.edu.cn); School of Computer Science and Center for OPTical IMagery Analysis and Learning, Northwestern Polytechnical University, 26487 Xi'an China 710072 (e-mail: hyzhang98@gmail.com); School of Computer Science and Center for OPTical IMagery Analysis and Learning (OPTIMAL), Northwestern Polytechnical University, 26487 Xi'an, Shaanxi China (e-mail: feipingnie@gmail.com)","IEEE Transactions on Fuzzy Systems","","2019","PP","99","1","1","Neural network based clustering methods usually have better performance compared to the conventional approaches due to more efficient feature extraction. Most of existing deep clustering techniques either exploit graph information as prior to extract pivotal deep structure from the raw data or simply utilizes SGD. However, they frequently suffer from separating the learning steps regarding dimensionality reduction and clustering. To address the issues, a novel deep model named as deep fuzzy k-means with adaptive loss function and entropy regularization (DFKM) is proposed. DFKM performs deep feature extraction and fuzzy clustering simultaneously to generate a more appropriate non-linear feature map. Additionally, DFKM incorporates fuzzy k-means so that fuzzy information is utilized to represent a clear structure of deep clusters. To further promote the robustness of the model, a robust loss function is applied to the objective with adaptive weights. Moreover, an entropy regularization is employed for affinity to provide confidence of each assignment and the corresponding membership and centroid matrices are updated by close-form solutions rather than SGD. Extensive experiments show that DFKM has better performance compared to the state-of-the-art fuzzy clustering techniques under three clustering metrics.","","","10.1109/TFUZZ.2019.2945232","China Postdoctoral Science Foundation; Xian Postdoctoral Innovation Base Funding; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8859232","unsupervised embedded clustering;deep neural network;auto-encoder;robust fuzzy k-means;image segmentation","Feature extraction;Adaptation models;Entropy;Clustering methods;Robustness;Neural networks;Clustering algorithms","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Two-Stage Deep Learning Method for Robust Shape Reconstruction with Electrical Impedance Tomography","S. Ren; K. Sun; C. Tan; F. Dong","Tianjin Key Laboratory of Process Measurement and Control, School of Electrical and Information Engineering, Tianjin University, Tianjin, 300072 China.; Tianjin Key Laboratory of Process Measurement and Control, School of Electrical and Information Engineering, Tianjin University, Tianjin, 300072 China.; Tianjin Key Laboratory of Process Measurement and Control, School of Electrical and Information Engineering, Tianjin University, Tianjin, 300072 China.; Tianjin Key Laboratory of Process Measurement and Control, School of Electrical and Information Engineering, Tianjin University, Tianjin, 300072 China.","IEEE Transactions on Instrumentation and Measurement","","2019","PP","99","1","1","As a non-invasive and radiation-free imaging modality, electrical impedance tomography (EIT) has attracted much attention in the last two decades and owns many industry and biomedical applications. However, due to the nonlinearity and ill-posedness of its inverse problem, the EIT images always suffer from low spatial resolution and are sensitive to the modelling errors. To achieve high resolution and modelling error robust EIT image, a two-stage deep learning (TSDL) method is proposed. The proposed method consists of a pre-reconstruction block and a convolutional neural network (CNN). The pre-reconstruction block learns the regularization pattern from the training data set and provides a rough reconstruction of the target. The CNN post-processes the pre-reconstruction result in a multi-level feature analysis strategy, and eliminates the modelling errors with prior information of the observation domain shape. The pre-reconstruction and CNN blocks are trained together by using a minimum square approach. To evaluate the performance of the TSDL method, the lung EIT problem was studied. The training data set is calculated from more than 100 thousand EIT simulation models generated from CT scans across 792 patients. Lung injury, measurement noise and model errors are randomly simulated during the model generation process. The trained TSDL model is evaluated with simulation testes, as well as the experimental tests from a laboratory setting. According to the results, the TSDL method could achieve high accuracy shape reconstructions and is robust against measurement noise and modelling errors.","","","10.1109/TIM.2019.2954722","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8907811","electrical impedance tomography;convolutional neural network;image reconstruction;modelling error;machine learning","Tomography;Image reconstruction;Shape;Data models;Training data;Conductivity","","","","","","","","","","IEEE","IEEE Early Access Articles"
"GAN-powered Deep Distributional Reinforcement Learning for Resource Management in Network Slicing","Y. Hua; R. Li; Z. Zhao; X. Chen; H. Zhang","College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou 310027, China.; College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou 310027, China.; Zhejiang Lab, Hangzhou, China as well as the College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou 310027, China.; VTT Technical Research Centre of Finland, Oulu 90570, Finland.; College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou 310027, China.","IEEE Journal on Selected Areas in Communications","","2019","PP","99","1","1","Network slicing is a key technology in 5G communications system. Its purpose is to dynamically and efficiently allocate resources for diversified services with distinct requirements over a common underlying physical infrastructure. Therein, demand-aware resource allocation is of significant importance to network slicing. In this paper, we consider a scenario that contains several slices in a radio access network with base stations that share the same physical resources (e.g., bandwidth or slots). We leverage deep reinforcement learning (DRL) to solve this problem by considering the varying service demands as the environment state and the allocated resources as the environment action. In order to reduce the effects of the annoying randomness and noise embedded in the received service level agreement (SLA) satisfaction ratio (SSR) and spectrum efficiency (SE), we primarily propose generative adversarial network-powered deep distributional Q network (GAN-DDQN) to learn the action-value distribution driven by minimizing the discrepancy between the estimated action-value distribution and the target action-value distribution. We put forward a reward-clipping mechanism to stabilize GAN-DDQN training against the effects of widely-spanning utility values. Moreover, we further develop Dueling GAN-DDQN, which uses a specially designed dueling generator, to learn the action-value distribution by estimating the state-value distribution and the action advantage function. Finally, we verify the performance of the proposed GAN-DDQN and Dueling GAN-DDQN algorithms through extensive simulations.","","","10.1109/JSAC.2019.2959185","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8931561","network slicing;deep reinforcement learning;distributional reinforcement learning;generative adversarial network;GAN;5G","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Deep Transfer Learning Framework for Seismic Data Analysis: A Case Study on Bright Spot Detection","J. El Zini; Y. Rizk; M. Awad","Department of Electrical and Computer Engineering, American University of Beirut, Beirut 1107-2020, Lebanon.; Department of Electrical and Computer Engineering, American University of Beirut, Beirut 1107-2020, Lebanon.; Department of Electrical and Computer Engineering, American University of Beirut, Beirut 1107-2020, Lebanon (e-mail: mariette.awad@aub.edu.lb).","IEEE Transactions on Geoscience and Remote Sensing","","2019","PP","99","1","11","Bright spots, strong indicators of the existence of hydrocarbon accumulations, have been primarily used by geophysicists in oil and gas exploration. Recently, machine-learning algorithms, adopted to automate bright spot detection, have mainly relied on feature extraction and shallow classification workflows to achieve an 85.4% F1 score at best, on 2-D seismic data. Deep neural networks have proved their effectiveness in image classification applications, outperforming humans in some instances, but have not been applied to bright spot detection yet. However, their data-hungry nature poses a challenge in domains suffering from expensive data acquisition, such as seismic data analysis problems; they generally require millions of training samples before achieving good performance. In this article, we implement SeisNet, a convolutional neural network with a ``butterfly'' architecture that overcame the limited data challenge by implementing data augmentation and inductive transfer-learning techniques. Moreover, we adopt a novel formulation that allows us to detect bright spots and estimate their volume. Our approach was tested against different pretraining and transfer-learning methods and was shown to outperform other approaches in the literature by achieving a 95.6% F1 score on bright spot detection. Our model accurately predicted the volume of the bright spot with an average absolute error that is not more than 0.04% of the total volume of the seismic image. This article is an important step in establishing pretrained networks for other seismic applications such as earthquake prediction; our domain-specific pretrained network, proven to outperform state-of-the-art pretrained networks on bright spot detection, may be used to jump-start the training of deep models on other seismic problems.","","","10.1109/TGRS.2019.2950888","University Research Board at the American University of Beirut; Munib Masri Institute; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933067","Bright spot detection;convolutional neural networks (CNNs);deep learning;oil and gas;pretrained model;reservoir identification and estimation;seismic analysis;transfer learning.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Short-Term Prediction of Passenger Demand in Multi-Zone Level: Temporal Convolutional Neural Network With Multi-Task Learning","K. Zhang; Z. Liu; L. Zheng","State Key Laboratory of Advanced Design and Manufacturing for Vehicle Body, College of Mechanical and Vehicle Engineering, Hunan University, Changsha 410082, China.; State Key Laboratory of Advanced Design and Manufacturing for Vehicle Body, College of Mechanical and Vehicle Engineering, Hunan University, Changsha 410082, China (e-mail: zijianliu@hnu.edu.cn).; School of Traffic and Transportation Engineering, Central South University, Changsha 410083, China (e-mail: zhengliang@csu.edu.cn).","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","11","Accurate short-term passenger demand prediction contributes to the coordination of traffic supply and demand. This paper proposes an end-to-end multi-task learning temporal convolutional neural network (MTL-TCNN) to predict the short-term passenger demand in a multi-zone level. Along with a feature selector named spatiotemporal dynamic time warping (ST-DTW) algorithm, this proposed MTL-TCNN is quite qualified for the multi-task prediction problem with the consideration of spatiotemporal correlations. Then, based on the car-calling demand data from Didi Chuxing, Chengdu, China, and taxi demand data from the New York City, the numerical results show that the MTL-TCNN outperforms both classic methods (i.e., historical average (HA), v-support vector machine (v-SVM), and XGBoost) and the state-of-the-art deep learning approaches [e.g., long short-term memory (LSTM) and convolutional LSTM (ConvLSTM)] in both the single task learning (STL) and multi-task learning (MTL) scenarios. In summary, the proposed MTL-TCNN with the ST-DTW algorithm is a promising method for short-term passenger demand prediction in a multi-zone level.","","","10.1109/TITS.2019.2909571","National Natural Science Foundation of China; Innovation Driven Plan of Central South University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8691703","Short-term passenger demand prediction;multi-task learning;deep learning;convolutional neural network.","","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Lip-Reading Driven Deep Learning Approach for Speech Enhancement","A. Adeel; M. Gogate; A. Hussain; W. M. Whitmer","DeepCI, Edinburgh EH16 5XW, U.K., and also with the School of Mathematics and Computer Science, University of Wolverhampton, Wolverhampton WV1 1LY, U.K. (e-mail: ahsan.adeel@deepci.org).; School of Computing, Edinburgh Napier University, Edinburgh EH11 4DY, U.K. (e-mail: mgo@cs.stir.ac.uk).; School of Computing, Edinburgh Napier University, Edinburgh EH11 4DY, U.K. (e-mail: A.Hussain@napier.ac.uk).; MRC/CSO Institute of Hearing Research Scottish Section, Glasgow G31 2ER, U.K. (e-mail: william.whitmer@nottingham.ac.uk).","IEEE Transactions on Emerging Topics in Computational Intelligence","","2019","PP","99","1","10","This paper proposes a novel lip-reading driven deep learning framework for speech enhancement. The approach leverages the complementary strengths of both deep learning and analytical acoustic modeling (filtering-based approach) as compared to benchmark approaches that rely only on deep learning. The proposed audio-visual (AV) speech enhancement framework operates at two levels. In the first level, a novel deep learning based lip-reading regression model is employed. In the second level, lip-reading approximated clean-audio features are exploited, using an enhanced, visually-derived Wiener filter (EVWF), for estimating the clean audio power spectrum. Specifically, a stacked long-short-term memory (LSTM) based lip-reading regression model is designed for estimating the clean audio features using only temporal visual features (i.e., lip reading), by considering a range of prior visual frames. For clean speech spectrum estimation, a new filterbank-domain EVWF is formulated, which exploits the estimated speech features. The EVWF is compared with conventional spectral subtraction and log-minimum mean-square error methods using both ideal AV mapping and LSTM driven AV mapping approaches. The potential of the proposed AV speech enhancement framework is evaluated under four different dynamic real-world scenarios [cafe, street junction, public transport, and pedestrian area] at different SNR levels (ranging from low to high SNRs) using benchmark grid and ChiME3 corpora. For objective testing, perceptual evaluation of speech quality is used to evaluate the quality of restored speech. For subjective testing, the standard mean-opinion-score method is used with inferential statistics. Comparative simulation results demonstrate significant lip-reading and speech enhancement improvements in terms of both speech quality and speech intelligibility. Ongoing work is aimed at enhancing the accuracy and generalization capability of the deep learning driven lip-reading model, using contextual integration of AV cues, leading to context-aware, autonomous AV speech enhancement.","","","10.1109/TETCI.2019.2917039","Engineering and Physical Sciences Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8825842","Lip-reading;stacked long-short-term memory;enhanced visually-derived Wiener filtering;context-aware audio-visual speech enhancement;audio-visual ChiME3 corpus","Speech enhancement;Hidden Markov models;Deep learning;Visualization;Lips;Feature extraction","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Learning for Physical-Layer 5G Wireless Techniques: Opportunities, Challenges and Solutions","H. Huang; S. Guo; G. Gui; Z. Yang; J. Zhang; H. Sari; F. Adachi","NA; NA; NA; NA; NA; NA; NA","IEEE Wireless Communications","","2019","PP","99","1","9","The new demands for high-reliability and ultra-high capacity wireless communication have led to extensive research into 5G communications. However, current communication systems, which were designed on the basis of conventional communication theories, significantly restrict further performance improvements and lead to severe limitations. Recently, the emerging deep learning techniques have been recognized as a promising tool for handling the complicated communication systems, and their potential for optimizing wireless communications has been demonstrated. In this article, we first review the development of deep learning solutions for 5G communication, and then propose efficient schemes for deep learning-based 5G scenarios. Specifically, the key ideas for several important deep learning-based communication methods are presented along with the research opportunities and challenges. In particular, novel communication frameworks of NOMA, massive multiple-input multiple-output (MIMO), and millimeter wave (mmWave) are investigated, and their superior performances are demonstrated. We envision that the appealing deep learning-based wireless physical layer frameworks will bring a new direction in communication theories and that this work will move us forward along this road.","","","10.1109/MWC.2019.1900027","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8786074","","MIMO communication;Deep learning;5G mobile communication;Channel estimation;Wireless communication;NOMA","","","","15","","","","","","IEEE","IEEE Early Access Articles"
"Ensemble Super-Resolution With a Reference Dataset","J. Jiang; Y. Yu; Z. Wang; S. Tang; R. Hu; J. Ma","School of Computer Science and Technology, Harbin Institute of Technology, Harbin 150001, China, and also with Peng Cheng Laboratory, Shenzhen 518055, China.; Digital Content and Media Sciences Research Division, National Institute of Informatics, Tokyo 101-8430, Japan.; Digital Content and Media Sciences Research Division, National Institute of Informatics, Tokyo 101-8430, Japan.; Department of Communication Engineering and Informatics, University of Electro-Communications, Tokyo 182-8585, Japan.; National Engineering Research Center for Multimedia Software, School of Computer, Wuhan University, Wuhan 430072, China; Electronic Information School, Wuhan University, Wuhan 430072, China (e-mail: jyma2010@gmail.com).","IEEE Transactions on Cybernetics","","2019","PP","99","1","15","By developing sophisticated image priors or designing deep(er) architectures, a variety of image super-resolution (SR) approaches have been proposed recently and achieved very promising performance. A natural question that arises is whether these methods can be reformulated into a unifying framework and whether this framework assists in SR reconstruction? In this paper, we present a simple but effective single image SR method based on ensemble learning, which can produce a better performance than that could be obtained from any of SR methods to be ensembled (or called component super-resolvers). Based on the assumption that better component super-resolver should have larger ensemble weight when performing SR reconstruction, we present a maximum a posteriori (MAP) estimation framework for the inference of optimal ensemble weights. Especially, we introduce a reference dataset, which is composed of high-resolution (HR) and low-resolution (LR) image pairs, to measure the SR abilities (prior knowledge) of different component super-resolvers. To obtain the optimal ensemble weights, we propose to incorporate the reconstruction constraint, which states that the degenerated HR estimation should be equal to the LR observation one, as well as the prior knowledge of ensemble weights into the MAP estimation framework. Moreover, the proposed optimization problem can be solved by an analytical solution. We study the performance of the proposed method by comparing with different competitive approaches, including four state-of-the-art nondeep learning-based methods, four latest deep learning-based methods, and one ensemble learning-based method, and prove its effectiveness and superiority on some general image datasets and face image datasets.","","","10.1109/TCYB.2018.2890149","National Natural Science Foundation of China; JSPS KAKENHI; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8656554","Deep learning;ensemble learning;maximum a posteriori (MAP);reference dataset;super-resolution (SR)","Image reconstruction;Image resolution;Learning systems;Convolutional codes;Deep learning;Estimation;Task analysis","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"A Data-flow Oriented Deep Ensemble Learning Method for Real Time Surface Defect Inspection","Y. Liu; H. Gao; L. Guo; A. Qin; C. Cai; Z. You","Engineering Research Center of Advanced Driving Energy-saving Technology, Ministry of Education, Southwest Jiaotong University, Chengdu 610031, China and School of Mechanical Engineering, Southwest Jiaotong University, Chengdu 610031, China.; Engineering Research Center of Advanced Driving Energy-saving Technology, Ministry of Education, Southwest Jiaotong University, Chengdu 610031, China and School of Mechanical Engineering, Southwest Jiaotong University, Chengdu 610031, China.; Engineering Research Center of Advanced Driving Energy-saving Technology, Ministry of Education, Southwest Jiaotong University, Chengdu 610031, China and School of Mechanical Engineering, Southwest Jiaotong University, Chengdu 610031, China.; NA; NA; NA","IEEE Transactions on Instrumentation and Measurement","","2019","PP","99","1","1","Real time surface defect inspection plays an important role in the quality control of automated production. For the surface defect inspection, flowing data is a common data form in the automated pipeline production. Although flowing data provides rich information for surface defect inspection, there are still a lot of dynamic distribution challenges caused by flowing data, such as domain shift phenomenon and imbalanced training data. However, many existing industrial inspection solutions are still using static strategies. To solve the dynamic distribution influence in data flow domain, this paper proposes a new deep ensemble learning method with domain fluctuation adaptation. Specifically, a new distribution discrepancy identifier based on estimation of the data set distribution and data characteristic is proposed. It utilizes advantages of both the deep convolutional neural network and the shallow feature based learning method to achieve higher robustness and fine-grained detection in streaming data scenes. In order to validate the proposed method, an inspection bench test system in part of a real industrial surface mount technology production line, is designed and fabricated. The proposed inference model is successfully applied to an embedded terminal with a hybrid and heterogeneous computing architecture. At last, the method is validated on the data collected from the manufacturer. The result suggests that the proposed method possesses a competitive mAP rate with good adaptation and robustness in industrial streaming data scenes.","","","10.1109/TIM.2019.2957849","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8928581","Surface mounting technology (SMT) material;Deep ensemble learning;Domain fluctuation adaptation;visual fault diagnosis;streaming data","Inspection;Pipelines;Fluctuations;Learning systems;Three-dimensional printing;Computational modeling","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Learning Calibration of the High-Frequency Airborne Microwave and Millimeter-Wave Radiometer (HAMMR) Instrument","M. Ogut; X. Bosch-Lluis; S. C. Reising","Microwave Systems Laboratory, Colorado State University, Fort Collins, CO 80523 USA. They are now with the Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA 91109 USA (e-mail: mehmet.ogut@jpl.nasa.gov).; Microwave Systems Laboratory, Colorado State University, Fort Collins, CO 80523 USA. They are now with the Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA 91109 USA.; Microwave Systems Laboratory, Colorado State University, Fort Collins, CO 80523 USA.","IEEE Transactions on Geoscience and Remote Sensing","","2019","PP","99","1","9","Calibration plays an important role in improving the accuracy of the microwave and millimeter-wave radiometric measurements. Several calibration techniques have been used in radiometers including external calibration targets, vicarious sources, and internal calibrators such as noise diodes or matched reference load. A new calibration technique based on deep learning has recently been developed to calibrate microwave and millimeter-wave radiometers. The deep-learning calibrator has been previously demonstrated on a computer noise-wave modeled Dicke-switching radiometer. This article applies the new deep-learning calibration technique for the calibration of the high-frequency airborne microwave and millimeter-wave radiometer (HAMMR) instrument. A deep-learning neural network model is built to calibrate the 2014 West Coast Flight Campaign antenna temperature measurements of the HAMMR. The deep-learning calibrator antenna temperature estimates are obtained from the radiometric measurements. The deep-learning calibration results are compared with the existing conventional calibration techniques used in HAMMR 2014 field campaign. The results have shown that the deep-learning calibrator is in agreement with the conventional calibration techniques. In this article, it is demonstrated that the deep-learning calibrator can be employed for calibrating the radiometers with high accuracy.","","","10.1109/TGRS.2019.2954454","U.S. National Aeronautics and Space Administration Science Mission Directorate Earth Science Technology Office as part of the Instrument Incubator Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8936550","Airborne;calibration;deep learning;microwave radiometer;millimeter-wave radiometer;neural network;remote sensing.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Comparative Study of Deep Learning-based Sentiment Classification","S. Seo; C. Kim; H. Kim; K. Mo; P. Kang","School of Industrial Management Engineering, Korea University, Seoul, South Korea.; School of Industrial Management Engineering, Korea University, Seoul, South Korea.; Department of Industrial and Manufacturing Engineering, The Pennsylvania State University.; SK C&C, Seoul, South Korea.; School of Industrial Management Engineering, Korea University, Seoul, South Korea.","IEEE Access","","2019","PP","99","1","1","The purpose of sentiment classification is to determine whether a particular document has a positive or negative nuance. Sentiment classification is extensively used in many business domains to improve products or services by understanding the opinions of customers regarding these products. Deep learning achieves state-of-the-art results in various challenging domains. With the success of deep learning, many studies have proposed deep-learning-based sentiment classification models and achieved better performances compared with conventional machine learning models. However, one practical issue occurring in deep-learning-based sentiment classification is that the best model structure depends on the characteristics of the dataset on which the deep learning model is trained; moreover, it is manually determined based on the domain knowledge of an expert or selected from a grid search of possible candidates. Herein, we present a comparative study of different deep-learning-based sentiment classification model structures to derive meaningful implications for building sentiment classification models. Specifically, eight deep-learning models, three based on convolutional neural networks and five based on recurrent neural networks, with two types of input structures, i.e., word level and character level, are compared for 13 review datasets, and the classification performances are discussed under different perspectives.","","","10.1109/ACCESS.2019.2963426","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8948030","Sentiment classification;deep learning;convolutional neural network;recurrent neural network;word embedding;character embedding","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Task-Oriented Deep Reinforcement Learning for Robotic Skill Acquisition and Control","G. Xiang; J. Su","Key Laboratory of System Control and Information Processing, Ministry of Education, Department of Automation, Shanghai Jiao Tong University, Shanghai 200240, China.; Key Laboratory of System Control and Information Processing, Ministry of Education, Department of Automation, Shanghai Jiao Tong University, Shanghai 200240, China (e-mail: jbsu@sjtu.edu.cn).","IEEE Transactions on Cybernetics","","2019","PP","99","1","14","Reinforcement learning (RL) and imitation learning (IL), especially equipped with deep neural networks, have been widely studied for autonomous robotic skill acquisition and control tasks. However, these methods and their extensions require extensive environmental interactions during training, which greatly prevents them from being applied to real-world robots. To alleviate this problem, we present an efficient model-free off-policy actor-critic algorithm for robotic skill acquisition and continuous control, by fusing the task reward with a task-oriented guiding reward, which is formulated by leveraging few and imperfect expert demonstrations. In this framework, the agent can explore the environment more intentionally, thus sampling efficiency can be achieved; moreover, the agent can also exploit the experience more effectively, thereby substantially improved performance can be realized simultaneously. The empirical results on robotic locomotion tasks show that the proposed scheme can lower sample complexity by 2-10 times in contrast with the state-of-the-art baseline deep RL (DRL) algorithms, while achieving performance better than that of the expert. Furthermore, the proposed algorithm achieves significant improvement in both sampling efficiency and asymptotic performance on tasks with sparse and delayed reward, wherein those baseline DRL algorithms struggle to make progress. This takes a substantial step forward to implement these methods to acquire skills autonomously for real robots.","","","10.1109/TCYB.2019.2949596","Key Projects of Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8897016","Continuous control;deep neural networks (DNNs);exploration;imitation learning (IL);reinforcement learning (RL);robotics;skill acquisition","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Interpretable Deep Convolutional Fuzzy Classifier","M. Yeganejou; S. Dick; J. Miller","Electrical & Computer Engineering, University of Alberta, Edmonton, Alberta Canada (e-mail: yeganejo@ualberta.ca); Electrical & Computer Engineering, University of Alberta, Edmonton, Alberta Canada T6G 2V4 (e-mail: dick@ece.ualberta.ca); Electrical & Computer Engineering, University of Alberta, Edmonton, Alberta Canada (e-mail: jm@ece.ualberta.ca)","IEEE Transactions on Fuzzy Systems","","2019","PP","99","1","1","While deep learning has proven to be a powerful new tool for modeling and predicting a wide variety of complex phenomena, those models remain incomprehensible black boxes. This is a critical impediment to the widespread deployment of deep learning technology, as decades of research have found that users simply will not trust (i.e. make decisions based on) a model whose solutions cannot be $explained$. Fuzzy systems, on the other hand, are by design much more easily understood. We propose to create more comprehensible deep networks by hybridizing them with fuzzy logic. Our proposed architecture first employs a convolutional neural network as an automated feature extractor, and then performs a fuzzy clustering in the derived feature space. After hardening the clusters, we employ Rocchio's algorithm to classify the data points. Experiments on three datasets show that the automated feature extraction substantially improves the accuracy of the fuzzy classifier; and while the substitution of a fuzzy classifier slightly decreases the network's performance, we are able to introduce an effective interpretation mechanism.","","","10.1109/TFUZZ.2019.2946520","Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8863387","Deep learning;Fuzzy logic;Neuro-fuzzy systems;Explainable AI","Clustering algorithms;Feature extraction;Neurons;Deep learning;Convolution;Classification algorithms;Fuzzy systems","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Deep Learning Framework for Tactile Recognition of Known as well as Novel Objects","Z. Abderrahmane; G. Ganesh; A. Crosnier; A. Cherubini","LIRMM, 56227 Montpellier, Languedoc-Roussillon France 34000 (e-mail: az_abderrahmane@esi.dz); Robotics, LIRMM, 56227 Montpellier, Languedoc-Roussillon France 34000 (e-mail: g.ganesh@aist.go.jp); LIRMM, 56227 Montpellier, Languedoc-Roussillon France 34000 (e-mail: crosnier@lirmm.fr); LIRMM, 56227 Montpellier, Languedoc-Roussillon France 34000 (e-mail: Andrea.Cherubini@lirmm.fr)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","This paper addresses the recognition of daily-life objects by a robot equipped with tactile sensors. The main contribution is a deep learning framework that can recognize objects already touched as well as objects never touched before. To this end, we train a Deconvolutional Neural Network that generates synthetic tactile data for novel classes. Then, we use both these synthetic data and the real data collected by touching objects, to train a Convolutional Neural Network to recognize both known (trained) objects and novel objects. Furthermore, we propose a method for integrating newly encountered data into novel classes. Finally, we evaluate the framework using the largest available dataset of tactile objects descriptions.","","","10.1109/TII.2019.2898264","Ministry of Higher Education and Scientific Research of Algeria; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8637832","Tactile object recognition;Deep learning;Zero-Shot Learning;One-Shot Learning;Convolutional Neural Networks;Generative Adversarial Networks","Training;Semantics;Training data;Robot sensing systems;Object recognition;Visualization","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Distributed Energy-Efficient Multi-UAV Navigation for Long-Term Communication Coverage by Deep Reinforcement Learning","C. H. Liu; X. Ma; X. Gao; J. Tang","School of Computer Science and Technology, Beijing Institute of Technology, 47833 Beijing, Beijing China 100081 (e-mail: liuchi02@gmail.com); Computer Science, Beijing Institute of Technology, 47833 Beijing, Beijing China (e-mail: maxiaoxin@bit.edu.cn); Computer Science, Beijing Institute of Technology, 47833 Beijing, Beijing China (e-mail: voitgxd@163.com); EECS, Syracuse University, 2029 Syracuse, New York United States (e-mail: jtang02@syr.edu)","IEEE Transactions on Mobile Computing","","2019","PP","99","1","1","In this paper, we aim to design a fully-distributed control solution to navigate a group of unmanned aerial vehicles (UAVs), as the mobile Base Stations (BSs) to fly around a target area, to provide long-term communication coverage for the ground mobile users. Different from existing solutions that mainly solve the problem from optimization perspectives, we proposed a decentralized deep reinforcement learning (DRL) based framework to control each UAV in a distributed manner. Our goal is to maximize the temporal average coverage score achieved by all UAVs in a task, maximize the geographical fairness of all considered point-of-interests (PoIs), and minimize the total energy consumptions, while keeping them connected and not flying out of the area border. We designed the state, observation, action space, and reward in an explicit manner, and model each UAV by deep neural networks (DNNs). We conducted extensive simulations and found the appropriate set of hyperparameters, including experience replay buffer size, number of neural units for two fully-connected hidden layers of actor, critic and their target networks, discount factor for remembering the future reward. The simulation results justified the superiority of the proposed model over the state-of-the-art DRL-EC3 approach based on deep deterministic policy gradient (DDPG), and three other baselines.","","","10.1109/TMC.2019.2908171","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8676325","UAV Control;Deep Reinforcement Learning;Energy Efficiency;Communication Coverage","Navigation;Energy consumption;Reinforcement learning;Path planning;Drones;Three-dimensional displays","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Multi-Scale Convolutional LSTM Network for Travel Demand and Origin-Destination Predictions","K. Chu; A. Y. S. Lam; V. O. K. Li","Department of Electrical and Electronic Engineering, The University of Hong Kong, Hong Kong, and also with the Shenzhen Institute of Research and Innovation, The University of Hong Kong, Hong Kong (e-mail: kfchu@eee.hku.hk).; Department of Electrical and Electronic Engineering, The University of Hong Kong, Hong Kong, and also with the Shenzhen Institute of Research and Innovation, The University of Hong Kong, Hong Kong.; Department of Electrical and Electronic Engineering, The University of Hong Kong, Hong Kong, and also with the Shenzhen Institute of Research and Innovation, The University of Hong Kong, Hong Kong.","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","14","Advancements in sensing and the Internet of Things (IoT) technologies generate a huge amount of data. Mobility on demand (MoD) service benefits from the availability of big data in the intelligent transportation system. Given the future travel demand or origin-destination (OD) flows prediction, service providers can pre-allocate unoccupied vehicles to the customers' origins of service to reduce waiting time. Traditional approaches on future travel demand and the OD flows predictions rely on statistical or machine learning methods. Inspired by deep learning techniques for image and video processing, through regarding localized travel demands as image pixels, a novel deep learning model called multi-scale convolutional long short-term memory network (MultiConvLSTM) is developed in this paper. Rather than using the traditional OD matrix which may lead to loss of geographical information, we propose a new data structure, called OD tensor to represent OD flows, and a manipulation method, called OD tensor permutation and matricization, is introduced to handle the high dimensionality features of OD tensor. MultiConvLSTM considers both temporal and spatial correlations to predict the future travel demand and OD flows. Experiments on real-world New York taxi data of around 400 million records are performed. Our results show that the MultiConvLSTM achieves the highest accuracy in both one-step and multiple-step predictions and it outperforms the existing methods for travel demand and OD flow predictions.","","","10.1109/TITS.2019.2924971","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8758916","Travel demand prediction;origin-destination prediction;deep learning;multi-scale convolutional LSTM network;origin-destination tensor.","Deep learning;Public transportation;Correlation;Predictive models;Data models","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Position-Aware Deep Character-Level CTR Prediction for Sponsored Search","X. Bai; R. Abasi; B. Edizel; A. Mantrach","Yahoo Research, Yahoo Research, Sunnyvale, California United States (e-mail: xbai@oath.com); Ads engineering, Oath, Sunnyvale, California United States (e-mail: rabasi@ucla.edu); Computer Science, Pompeu Fabra University, Barcelona, Barcelona Spain (e-mail: bora.edizel@upf.edu); Labs, Criteo, Palo Alto, California United States (e-mail: a.mantrach@criteo.com)","IEEE Transactions on Knowledge and Data Engineering","","2019","PP","99","1","1","Predicting the click-through rate of an advertisement is a critical component of online advertising platforms. In sponsored search, the click-through rate estimates the probability that a displayed advertisement is clicked by a user after she submits a query to the search engine. Commercial search engines typically rely on machine learning models trained with a large number of features to make such predictions. In this paper, we propose two novel approaches (one working at character level and the other working at word level) that use deep convolutional neural networks to predict the click-through rate of a query-advertisement pair. By comparing the two models, we show that language representation can be learnt from scratch at character level when trained on enough data. Through extensive experiments using billions of query-advertisement pairs of a popular commercial search engine, we demonstrate that both approaches significantly outperform a baseline model built on well-selected text features and a state-of-the-art word2vec-based approach. We also show the importance of the position feature in the proposed approaches in improving the prediction accuracy. We also show the potential of leveraging the CTR prediction of the proposed deep learning models for query-ad relevance modeling and query-ad matching tasks in sponsored search.","","","10.1109/TKDE.2019.2941881","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8839819","Deep Learning;NLP;Online Advertising;Sponsored Search;CTR Prediction","Predictive models;Search engines;Deep learning;Context modeling;Advertising;Engines;Data models","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"A Deep Learning Network via Shunt-wound Restricted Boltzmann Machines Using Raw Data for Fault Detection","T. Pan; J. Chen; J. Pan; Z. Zhou","State Key Laboratory for Manufacturing Systems Engineering, Xi’an Jiaotong University, Xi’an, 710049 China.; State Key Laboratory for Manufacturing Systems Engineering, Xi’an Jiaotong University, Xi’an, 710049 China.; State Key Laboratory for Manufacturing Systems Engineering, Xi’an Jiaotong University, Xi’an, 710049 China.; State Key Laboratory for Manufacturing Systems Engineering, Xi’an Jiaotong University, Xi’an, 710049 China.","IEEE Transactions on Instrumentation and Measurement","","2019","PP","99","1","1","Intelligent fault detection has been widely used for feature extraction and fault classification. However, various complex signal processing methods are adopted in many researches. The paper presents a novel deep learning network via shunt-wound restricted Boltzmann machines with layerwise feature learning to learn the fault features from big raw vibration signals directly. The network consists of split layer, predict layer, update layer, dephasing layer and softmax layer. The shunt-wound restricted Boltzmann machines are used in both predict layer and update layer to improve feature extraction ability and to ensure effective training of the network. The operation of predicting and updating is considered to be a layerwise feature learning which makes the network effective. The proposed method is verified by three bearing datasets and a few related researches are introduced for comparison. Results prove that the proposed method is capable of extracting sensitive features for fault detection.","","","10.1109/TIM.2019.2953436","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8901146","fault diagnosis;neural network;bearing;big data;deep learning;restricted Boltzmann machine;layerwise feature learning;raw data","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Learning-based Intelligent Fault Diagnosis Methods towards Rotating Machinery","S. Tang; S. Yuan; Y. Zhu","National Research Center of Pumps, Jiangsu University, Zhenjiang 212013, Jiangsu, China.; National Research Center of Pumps, Jiangsu University, Zhenjiang 212013, Jiangsu, China and State Key Laboratory of Fluid Power and Mechatronic Systems, Zhejiang University, Hangzhou 310027, Zhejiang, China.; National Research Center of Pumps, Jiangsu University, Zhenjiang 212013, Jiangsu, China and State Key Laboratory of Fluid Power and Mechatronic Systems, Zhejiang University, Hangzhou 310027, Zhejiang, China.","IEEE Access","","2019","PP","99","1","1","Fault diagnosis of rotating machinery plays a significant role in the industrial production and engineering field. Owing to the drawbacks of traditional fault diagnosis methods, such as heavily dependence on human knowledge and professional experience, intelligent fault diagnosis based on deep learning (DL) has aroused the interest of researchers. DL achieves the desirable automatic feature learning and fault classification. Therefore, in this review, DL and DL-based intelligent fault diagnosis techniques are overviewed. DL-based fault diagnosis approaches for rotating machinery are summarized and discussed, primarily including bearing, gear/gearbox and pumps. Finally, with respect to modern intelligent fault diagnosis, the existing challenges and possible future research orientations are prospected and analyzed.","","","10.1109/ACCESS.2019.2963092","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8945322","Deep learning;deep neural network;intelligent fault diagnosis;rotating machinery","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Stacked Denoising Autoencoder Enhanced Polar Codes Over Rayleigh Fading Channels","J. Li; W. Cheng","State Key Laboratory of Integrated Services Networks, Xidian University, Xi’an, 710071, China.; State Key Laboratory of Integrated Services Networks, Xidian University, Xi’an, 710071, China.","IEEE Wireless Communications Letters","","2019","PP","99","1","1","Polar codes, with low encoding/decoding complexity and capacity-achieving potential, have drawn much attention recently. It is very critical to study the impact of fading on polar codes implementation into wireless communications. Existing research works on polar codes over the fading channel use simplified fading channel models while further reducing the frame error rate is highly needed. In this paper, using the structure of polar codes we propose the deep learning based scheme for polar codes over Rayleigh fading channels. Simulation results verify that our proposed scheme can significantly decrease the frame error rate for polar codes over Rayleigh fading channels.","","","10.1109/LWC.2019.2954907","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8908726","ls1.0 Polar codes;deep learning;stacked denoising autoencoder;Rayleigh fading channel..","Fading channels;Training;Deep learning;Decoding;Neural networks;Noise reduction","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Orthogonal Deep Neural Networks","K. Jia; S. Li; Y. Wen; T. Liu; D. Tao","School of Electronic and Information Engineering, South China University of Technology, 26467 guangzhou, guangdong China 510641 (e-mail: kuijia@scut.edu.cn); School of Electronic and Information Engineering, South China University of Technology, 26467 guangzhou, guangdong China (e-mail: lishuai918@gmail.com); School of Electronic and Information Engineering, South China University of Technology, 26467 guangzhou, guangdong China (e-mail: wen.yuxin@mail.scut.edu.cn); FEIT, University of Sydney School of Information Technologies, 217067 Darlington, New South Wales Australia 2008 (e-mail: tliang.liu@gmail.com); Engineering and Information Technologies, University of Sydney, 4334 Sydney, New South Wales Australia (e-mail: dacheng.tao@sydney.edu.au)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","In this paper, we introduce the algorithms of Orthogonal Deep Neural Networks (OrthDNNs) to connect with recent interest of spectrally regularized deep learning methods. OrthDNNs are theoretically motivated by generalization analysis of modern DNNs, with the aim to find solution properties of network weights that guarantee better generalization. To this end, we first prove that DNNs are of local isometry on data distributions of practical interest; by using a new covering of the sample space and introducing the local isometry property of DNNs into generalization analysis, we establish a new generalization error bound that is characterized by singular value spectrum of each of networks' weight matrices. We prove that the optimal bound w.r.t. the degree of isometry is attained when each weight matrix has a spectrum of equal singular values, among which that with orthonormal rows/columns is the most straightforward choice, suggesting the algorithms of OrthDNNs. We present both algorithms of strict and approximate OrthDNNs, and for the later ones we propose Singular Value Bounding, which performs as well as strict OrthDNNs but at a much lower computational cost. We also propose algorithms to make compatible use of batch normalization with OrthDNNs. Extensive comparative studies show the efficacy of OrthDNNs.","","","10.1109/TPAMI.2019.2948352","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8877742","Deep neural networks;generalization error;robustness;spectral regularization;image classification","Training;Robustness;Jacobian matrices;Task analysis;Neural networks;Optimization;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Stochastic Gradient Descent for Nonconvex Learning Without Bounded Gradient Assumptions","Y. Lei; T. Hu; G. Li; K. Tang","University Key Laboratory of Evolving Intelligent Systems of Guangdong Province, Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen 518055, China.; School of Mathematics and Statistics, Wuhan University, Wuhan 430072, China.; University Key Laboratory of Evolving Intelligent Systems of Guangdong Province, Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen 518055, China (e-mail: ligy@sustech.edu.cn).; University Key Laboratory of Evolving Intelligent Systems of Guangdong Province, Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen 518055, China.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","7","Stochastic gradient descent (SGD) is a popular and efficient method with wide applications in training deep neural nets and other nonconvex models. While the behavior of SGD is well understood in the convex learning setting, the existing theoretical results for SGD applied to nonconvex objective functions are far from mature. For example, existing results require to impose a nontrivial assumption on the uniform boundedness of gradients for all iterates encountered in the learning process, which is hard to verify in practical implementations. In this article, we establish a rigorous theoretical foundation for SGD in nonconvex learning by showing that this boundedness assumption can be removed without affecting convergence rates, and relaxing the standard smoothness assumption to Hölder continuity of gradients. In particular, we establish sufficient conditions for almost sure convergence as well as optimal convergence rates for SGD applied to both general nonconvex and gradient-dominated objective functions. A linear convergence is further derived in the case with zero variances.","","","10.1109/TNNLS.2019.2952219","National Key Research and Development Program of China; National Natural Science Foundation of China; Program for University Key Laboratory of Guangdong Province; Program for Guangdong Introducing Innovative and Entrepreneurial Teams; Alexander von Humboldt Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8930994","Learning theory;nonconvex optimization;Polyak-\L ojasiewicz condition;stochastic gradient descent (SGD).","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Reinforcement Learning for Cooperative Content Caching in Vehicular Edge Computing and Networks","G. Qiao; S. Leng; S. Maharjan; Y. Zhang; N. Ansari","School of Information & Communication Engineering, University of Electronic Science and Technology of China.; School of Information & Communication Engineering, University of Electronic Science and Technology of China.; Simula Metropolitan Center for Digital Engineering, Norway.; Department of Informatics, University of Oslo, Norway.; Advanced Networking Lab., Department of Electrical and Computer Engineering, New Jersey Institute of Technology, Newark, NJ, 07102 USA.","IEEE Internet of Things Journal","","2019","PP","99","1","1","In this paper, we propose a cooperative edge caching scheme, a new paradigm to jointly optimize content placement and content delivery in vehicular edge computing and networks, with the aid of the flexible trilateral cooperations among a macro-cell station, roadside units and smart vehicles. We formulate the joint optimization problem as a double time-scale Markov decision process (DTS-MDP), based on the fact that the time-scale of content timeliness changes less frequently as compared to the vehicle mobility and network states during the content delivery process. At the beginning of the large time-scale, the content placement/updating decision can be obtained according to the content popularity, vehicle driving paths and resource availability. On the small time-scale, the joint vehicle scheduling and bandwidth allocation scheme is designed to minimize the content access cost while satisfying the constraint on content delivery latency. To solve the long-term mixed integer linear programming (LT-MILP) problem, we propose a nature-inspired method based on the deep deterministic policy gradient (DDPG) framework to obtain a suboptimal solution with a low computation complexity. Simulation results demonstrate that the proposed cooperative caching system can reduce the system cost, as well as the content delivery latency, and improve content hit ratio, as compared to the non-cooperative and random edge caching schemes.","","","10.1109/JIOT.2019.2945640","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8879573","Vehicular edge computing and networks;cooperative edge caching;content placement;content delivery;double time-scale Markov decision process (DTS-MDP);deep deterministic policy gradient (DDPG).","Cooperative caching;Optimization;Edge computing;Computational modeling;Internet of Things;Indexes;Base stations","","","","","","","","","","IEEE","IEEE Early Access Articles"
"An Actor-Critic Deep Reinforcement Learning Approach for Transmission Scheduling in Cognitive Internet of Things Systems","H. Yang; X. Xie","School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore 639798 (e-mail: hyang013@e.ntu.edu.sg).; Chongqing Key Laboratory of Computer Network and Communication Technology, Chongqing University of Posts and Telecommunications, Chongqing 400065, China (e-mail: xiexzh@cqupt.edu.cn).","IEEE Systems Journal","","2019","PP","99","1","10","The cognitive Internet of Things (CIoT) has attracted much interest recently in wireless networks due to its wide applications in smart cities, intelligent transportation systems, and smart metering networks. However, how to smartly schedule the packet transmission in CIoT systems is still a key challenge, that is, how to design a smart agent to realize the intelligent decision making and effective interoperability. In this paper, we model the system state transformation as a Markov decision process, and an actor-critic deep reinforcement learning algorithm based on a fuzzy normalized radial basis function neural network (called AC-FNRBF) is proposed to efficiently solve the intelligent transmission scheduling problem in CIoT systems under high-dimensional variables. The proposed AC-FNRBF algorithm can better approximate both the action function of the actor and the state–action value function of the critic without requiring the system prior knowledge, and a new reward function is established to maximize the system benefit, which jointly takes the transmission packet rate, the system throughput, the power consumption, and the transmission delay into account. Moreover, the AC-FNRBF has the ability to adjust its learning structure and parameters in dynamic environments. Simulation results verify that the proposed algorithm achieves higher transmission packet rate and system throughput with lower power consumption and transmission delay, compared with other existing reinforcement learning algorithms.","","","10.1109/JSYST.2019.2891520","National Natural Science Foundation of China; Key Science and Technology Research Program of Chongqing Municipal Education Commission; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8668836","Actor-critic (AC);adaptive fuzzy neural network;cognitive Internet of Things (CIoT);deep reinforcement learning (DRL);transmission scheduling","Power demand;Internet of Things;Decision making;Resource management;Scheduling;Reinforcement learning;Signal to noise ratio","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Cooperative Deep Reinforcement Learning for Large-Scale Traffic Grid Signal Control","T. Tan; F. Bao; Y. Deng; A. Jin; Q. Dai; J. Wang","Department of Civil and Environmental Engineering, Stanford University, Stanford, CA 94305 USA.; Department of Automation, Tsinghua National Laboratory for Information Science and Technology, Tsinghua University, Beijing 100084, China.; School of Astronautics, Beihang University, Beijing 100191, China (e-mail: yuedeng.thu@gmail.com).; Computer Science Department, Stanford University, Stanford, CA 94305 USA.; Department of Automation, Tsinghua National Laboratory for Information Science and Technology, Tsinghua University, Beijing 100084, China.; Department of Civil and Environmental Engineering, Stanford University, Stanford, CA 94305 USA.","IEEE Transactions on Cybernetics","","2019","PP","99","1","14","Exploiting reinforcement learning (RL) for traffic congestion reduction is a frontier topic in intelligent transportation research. The difficulty in this problem stems from the inability of the RL agent simultaneously monitoring multiple signal lights when taking into account complicated traffic dynamics in different regions of a traffic system. Such challenge is even more outstanding when forming control decisions on a large-scale traffic grid, where the RL action space grows exponentially with the number of intersections within the traffic grid. In this paper, we tackle such a problem by proposing a cooperative deep reinforcement learning (Coder) framework. The intuition behind Coder is to decompose the original difficult RL task as a number of subproblems with relatively easy RL goals. Accordingly, we implement Coder with multiple regional agents and a centralized global agent. Each regional agent learns its own RL policy and value functions over a small region with limited actions. Then, the centralized global agent hierarchically aggregates RL achievements from different regional agents and forms the final Q-function over the entire large-scale traffic grid. The experimental investigations demonstrate that the proposed Coder could reduce on average 30% congestions in terms of the number of waiting vehicles during high density traffic flows in simulations.","","","10.1109/TCYB.2019.2904742","Stanford Center for Sustainable Development and Global Competitiveness; Project of Beijing Municipal Science and Technology Commission; Project of NSFC; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8676356","Deep reinforcement learning (DRL);intelligent transportation systems;traffic signal control","Reinforcement learning;Aerospace electronics;Transportation;Games;Vehicle dynamics;Task analysis","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"G-Softmax: Improving Intraclass Compactness and Interclass Separability of Features","Y. Luo; Y. Wong; M. Kankanhalli; Q. Zhao","Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN 55455 USA.; School of Computing, National University of Singapore, Singapore 117417.; School of Computing, National University of Singapore, Singapore 117417.; Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN 55455 USA (e-mail: qzhao@cs.umn.edu).","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","15","Intraclass compactness and interclass separability are crucial indicators to measure the effectiveness of a model to produce discriminative features, where intraclass compactness indicates how close the features with the same label are to each other and interclass separability indicates how far away the features with different labels are. In this paper, we investigate intraclass compactness and interclass separability of features learned by convolutional networks and propose a Gaussian-based softmax (G-softmax) function that can effectively improve intraclass compactness and interclass separability. The proposed function is simple to implement and can easily replace the softmax function. We evaluate the proposed G-softmax function on classification data sets (i.e., CIFAR-10, CIFAR-100, and Tiny ImageNet) and on multilabel classification data sets (i.e., MS COCO and NUS-WIDE). The experimental results show that the proposed G-softmax function improves the state-of-the-art models across all evaluated data sets. In addition, the analysis of the intraclass compactness and interclass separability demonstrates the advantages of the proposed function over the softmax function, which is consistent with the performance improvement. More importantly, we observe that high intraclass compactness and interclass separability are linearly correlated with average precision on MS COCO and NUS-WIDE. This implies that the improvement of intraclass compactness and interclass separability would lead to the improvement of average precision.","","","10.1109/TNNLS.2019.2909737","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8712413","Compactness and separability;deep learning;Gaussian-based softmax;multilabel classification.","Gaussian distribution;Predictive models;Feature extraction;Learning systems;Task analysis;Data models;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Generative Adversarial Attacks Against Deep-Learning-Based Camera Model Identification","C. Chen; X. Zhao; M. C. Stamm","Department of Electrical and Computer Engineering, Drexel University, Philadelphia, PA, 19104 USA.; Department of Electrical and Computer Engineering, Drexel University, Philadelphia, PA, 19104 USA.; Department of Electrical and Computer Engineering, Drexel University, Philadelphia, PA, 19104 USA.","IEEE Transactions on Information Forensics and Security","","2019","PP","99","1","1","Recently, deep learning techniques have gained popularity in multimedia forensics research designed to accomplish tasks such as camera model identification. However, despite the success of deep learning techniques, research has shown that they are vulnerable to adversarial perturbations. These adversarial perturbations can cause deep learning classifiers to misclassify images even though the perturbations are imperceptible to human eyes. To understand the vulnerabilities of deep-learning-based forensic algorithms, we propose a novel anti-forensic framework inspired by generative adversarial networks that is capable of falsifying an image’s source camera model. To accomplish this, we design a generator to anti-forensically falsify camera model traces in an image without introducing visually perceptible changes or artifacts. We propose two techniques to adversarially train this generator depending on the knowledge available to the attacker. In a white-box scenario when complete knowledge of an investigator’s camera model identification network is available to an attacker, we directly incorporate the network into our generator’s adversarial training strategy. In a black-box scenario when no internal details of the camera model classifier are available to the attacker, we construct a substitute network to mimic its decisions, then utilize this substitute network to adversarially train our generator. We conduct a series of experiments to evaluate the performance of our attack against several well-known CNNbased camera model classifiers. Experimental results show that our attack can successfully fool these CNNs in both white-box and black-box scenarios. Furthermore, our attack maintains high image quality and can be generalized to attack images from arbitrary source camera models.","","","10.1109/TIFS.2019.2945198","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8854834","Anti-forensics;Convolutional Neural Networks;Camera Model Identification;Generative Adversarial Network;White-box Attack;Black-box Attack;Substitute Network","Cameras;Forensics;Generators;Training;Gallium nitride;Deep learning;Task analysis","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Fuzzy Tree for Large-Scale Hierarchical Visual Classification","Y. Wang; Q. Hu; P. Zhu; L. Li; B. Lu; J. M. Garibaldi; X. Li","School of Intelligence and Computing, Tianjin University, Tianjin, Tianjin China (e-mail: armstrong_wangyu@tju.edu.cn); School of Intelligence and Computing, Tianjing University, Tianjin China (e-mail: huqinghua@tju.edu.cn); School of Intelligence and Computing, Tianjin University, Tianjin China (e-mail: zhupengfei@tju.edu.cn); School of Artificial Intellgence, Tianjin University, Tianjin China (e-mail: lilinhao@tju.edu.cn); School of Intelligence and Computing, Tianjin University, Tianjin China (e-mail: lubingxu@tju.edu.cn); School of Computer Science, University of Nottingham, Nottingham United Kingdom of Great Britain and Northern Ireland (e-mail: jon.garibaldi@nottingham.ac.uk); Wuhan, Science and Technology on Thermal Energy and Power Laboratory, Wuhan China (e-mail: lixl_csic719@163.com)","IEEE Transactions on Fuzzy Systems","","2019","PP","99","1","1","Deep learning models often use a flat softmax layer to classify samples after feature extraction in visual classification tasks. However, it is hard to make a single decision of finding the true label from massive classes. In this scenario, hierarchical classification is proved to be an effective solution and can be utilized to replace the softmax layer. A key issue of hierarchical classification is to construct a good label structure, which is very significant for classification performance. Several works have been proposed to address the issue, but they have some limits and are almost designed heuristically. In this paper, inspired by fuzzy rough set theory, we propose a deep fuzzy tree model which learns a better tree structure and classifiers for hierarchical classification with theory guarantee. Experimental results show the effectiveness and efficiency of the proposed model in various visual classification datasets.","","","10.1109/TFUZZ.2019.2936801","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8809246","Fuzzy rough set;hierarchical classification;label structure;deep learning","Task analysis;Visualization;Deep learning;Feature extraction;Rough sets;Kernel;Discrete Fourier transforms","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Joint Rain Detection and Removal from a Single Image with Contextualized Deep Networks","W. Yang; R. T. Tan; J. Feng; J. Liu; S. Yan; Z. Guo","Institute of computer science & technology, Peking University, Beijing, Beijing China (e-mail: yangwenhan@pku.edu.cn); National University of Singapore, National University of Singapore, Singapore, Singapore Singapore (e-mail: tanrobby@gmail.com); ECE, National University of Singapore, 37580 Singapore, Singapore Singapore (e-mail: elefjia@nus.edu.sg); Institute of computer science & technology, Peking University, 12465 Beijing, Beijing China (e-mail: liujiaying@pku.edu.cn); ece, NUS, sg, SG Singapore 117576 (e-mail: eleyans@nus.edu.sg); Institute of Computer Science and Technology, Peking University, Beijing, Beijing China (e-mail: guozongming@pku.edu.cn)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Rain streaks, particularly in heavy rain, not only degrade visibility but also make many computer vision algorithms fail to function properly. In this paper, we address this visibility problem by focusing on single-image rain removal, even in the presence of dense rain streaks and rain-streak accumulation, which is visually similar to mist or fog. To achieve this, we introduce a new rain model and a deep learning architecture. Our rain model incorporates a binary rain map indicating rain-streak regions, and accommodates various shapes, directions, and sizes of overlapping rain streaks, as well as rain accumulation, to model heavy rain. Based on this model, we construct a multi-task deep network, which jointly learns three targets: the binary rain-streak map, rain streak layers, and clean background, which is our ultimate output. To generate features that can be invariant to rain steaks, we introduce a contextual dilated network, which is able to exploit regional contextual information. To handle various shapes and directions of overlapping rain streaks, our strategy is to utilize a recurrent process that progressively removes rain streaks. Our binary map provides a constraint and thus additional information to train our network. Extensive evaluation on real images, particularly in heavy rain, shows the effectiveness of our model and architecture.","","","10.1109/TPAMI.2019.2895793","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8627954","Rain removal;rain detection;deep learning;rain accumulation;contextualized dilated network","Rain;Shape;Atmospheric modeling;Image restoration;Deep learning;Degradation;Computer vision","","","","2","","","","","","IEEE","IEEE Early Access Articles"
"Feature Extraction of Hyperspectral Images Based on Deep Boltzmann Machine","J. Yang; Y. Guo; X. Wang","Key Laboratory of Modern Teaching Technology, Ministry of Education, Xi'an 710119, China.; School of Data and Computer Science, Shandong Women's University, Ji'nan 250002, China.; School of Computer Science, Shaanxi Normal University, Xi'an 710119, China (e-mail: wangxili@snnu.edu.cn).","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","High dimensionality and lack of labeled samples are the difficulties in feature extraction for hyperspectral image (HSI) processing. In this letter, a deep-learning-based feature extraction method is proposed. First, the guided filter is used to preprocess the original HSI data. The result data contain the joint spectral and spatial information of the objects. Second, the local receptive field and weight sharing are introduced into deep Boltzmann machine(DBM) to establish a novel feature extractor, called local-global DBM (LGDBM). The LGDBM has two advantages: 1) it can learn both the local and global features of the high-dimensional input data and 2) it has much fewer parameters than the DBM. Therefore, only a few labeled samples are needed for training, and the local and global spectral-spatial features are extracted intrinsically. A group of classification experiments are performed to evaluate the advantages of the feature extraction method.","","","10.1109/LGRS.2019.2937601","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8879495","DBM;deep learning;feature extraction;hyperspectral image (HSI).","Feature extraction;Deep learning;Data models;Training;Hyperspectral imaging;Data mining","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Safe Off-policy Deep Reinforcement Learning Algorithm for Volt-VAR Control in Power Distribution Systems","W. Wang; N. Yu; Y. Gao; J. Shi","Department of Electrical and Computer Engineering at University of California, Riverside.; Department of Electrical and Computer Engineering at University of California, Riverside.; Department of Electrical and Computer Engineering at University of California, Riverside.; Department of Electrical and Computer Engineering at University of California, Riverside.","IEEE Transactions on Smart Grid","","2019","PP","99","1","1","Volt-VAR control is critical to keeping distribution network voltages within allowable range, minimizing losses, and reducing wear and tear of voltage regulating devices. To deal with incomplete and inaccurate distribution network models, we propose a safe off-policy deep reinforcement learning algorithm to solve Volt-VAR control problems in a model-free manner. The Volt-VAR control problem is formulated as a constrained Markov decision process with discrete action space, and solved by our proposed constrained soft actor-critic algorithm. Our proposed reinforcement learning algorithm achieves scalability, sample efficiency, and constraint satisfaction by synergistically combining the merits of the maximum-entropy framework, the method of multiplier, a device-decoupled neural network structure, and an ordinal encoding scheme. Comprehensive numerical studies with the IEEE distribution test feeders show that our proposed algorithm outperforms the existing reinforcement learning algorithms and conventional optimization-based approaches on a large feeder.","","","10.1109/TSG.2019.2962625","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8944292","Deep reinforcement learning;model-free;off-policy;safe reinforcement learning;Volt-VAR control.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Continuously Constructive Deep Neural Networks","O. İrsoy; E. Alpaydin","Bloomberg LP, New York, NY 10022 USA (e-mail: oirsoy@bloomberg.net).; Department of Computer Engineering, Boşaziçi University, 34342 Istanbul, Turkey.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","10","Traditionally, deep learning algorithms update the network weights, whereas the network architecture is chosen manually using a process of trial and error. In this paper, we propose two novel approaches that automatically update the network structure while also learning its weights. The novelty of our approach lies in our parameterization, where the depth, or additional complexity, is encapsulated continuously in the parameter space through control parameters that add additional complexity. We propose two methods. In tunnel networks, this selection is done at the level of a hidden unit, and in budding perceptrons, this is done at the level of a network layer; updating this control parameter introduces either another hidden unit or layer. We show the effectiveness of our methods on the synthetic two-spiral data and on three real data sets of MNIST, MIRFLICKR, and CIFAR, where we see that our proposed methods, with the same set of hyperparameters, can correctly adjust the network complexity to the task complexity.","","","10.1109/TNNLS.2019.2918225","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8744488","Constructive learning;deep learning;neural networks.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Neural Network for Robust Modulation Classification under Uncertain Noise Conditions","S. Hu; Y. Pei; P. P. Liang; Y. Liang","University of Electronic Science and Technology of China, 12599 Chengdu, Sichuan China 611731 (e-mail: hss_ss@163.com); Singapore Institute of Technology, Singapore, Singapore Singapore 138683 (e-mail: yiyang.pei@singaporetech.edu.sg); Machine Learning Department, Carnegie Mellon University, 6612 Pittsburgh, Pennsylvania United States 15213 (e-mail: pliang@cs.cmu.edu); University of Electronic Science and Technology of China, 12599 Chengdu, Sichuan China 611731 (e-mail: liangyc@ieee.org)","IEEE Transactions on Vehicular Technology","","2019","PP","99","1","1","Recently, classifying the modulation schemes of signals using deep neural network has received much attention. In this paper, we introduce a general model of deep neural network (DNN)-based modulation classifiers for single-input single-output (SISO) systems. Its feasibility is analyzed using maximum a posteriori probability (MAP) criterion and its robustness to uncertain noise conditions is compared to that of the conventional maximum likelihood (ML)-based classifiers. To reduce the design and training cost of DNN classifiers, a simple but effective pre-processing method is introduced and adopted. Furthermore, featuring multiple recurrent neural network (RNN) layers, the DNN modulation classifier is realized. Simulation results show that the proposed RNN-based classifier is robust to the uncertain noise conditions, and the performance of it approaches to that of the ideal ML classifier with perfect channel and noise information. Moreover, with a much lower complexity, it outperforms the existing ML-based classifiers, specifically, expectation maximization (EM) and expectation conditional maximization (ECM) classifiers which iteratively estimate channel and noise parameters. In addition, the proposed classifier is shown to be invariant to the signal distortion such as frequency offset. Furthermore, the adopted pre-processing method is shown to accelerate the training process of our proposed classifier, thus reducing the training cost. Lastly, the computational complexity of our proposed classifier is analyzed and compared to other traditional ones, which further demonstrates its overall advantage.","","","10.1109/TVT.2019.2951594","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8891763","Blind Modulation Classification;Cognitive Radio;Deep Neural Network","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Remote Sensing Image Classification via Improved Cross-Entropy Loss and Transfer Learning Strategy Based on Deep Convolutional Neural Networks","A. Bahri; S. G. Majelan; S. Mohammadi; M. Noori; K. Mohammadi","School of Electrical Engineering, Iran University of Science and Technology, Tehran 16846-13114, Iran (e-mail: alibahri.72.dl.k@gmail.com).; School of Electrical Engineering, Iran University of Science and Technology, Tehran 16846-13114, Iran.; School of Electrical Engineering, Iran University of Science and Technology, Tehran 16846-13114, Iran.; School of Electrical Engineering, Iran University of Science and Technology, Tehran 16846-13114, Iran.; School of Electrical Engineering, Iran University of Science and Technology, Tehran 16846-13114, Iran.","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","Recently, deep convolutional neural networks (DCNNs) have gained great success in classifying aerial images, but in this area, the existence of the hard images, due to their innate characteristics, and weak focus of the network on them, due to the use of the cross-entropy (CE) loss, lead to reducing the accuracy of classification of aerial images. Moreover, since the last convolutional layer in a CNN has highly class-specific information, giving equal importance to all the channels causes to extract less discriminative features in comparison to weighting each of the channels adaptively. The fact that data labeling as well as creating ground truth on large data set is expensive is another point of concern in this regard. To address these problems, we have proposed a novel method for classification of aerial images. Our method includes proposing a new loss function, which enhances the focus of the network on hard examples by adding a new term to CE as a penalty term, bringing about the state-of-the-art results; designing a new multilayer perceptron (MLP) as a classifier, in which the used attention mechanism extracts more discriminative features by weighting each of the channels adaptively; and applying transfer learning strategy by adopting neural architecture search network mobile (NASNet Mobile) as a feature descriptor for the first time in the field of aerial images, which can mitigate the aforementioned costs. As indicated in the results, our proposed method outperforms the existing baseline methods and achieves state-of-the-art results on all three data sets.","","","10.1109/LGRS.2019.2937872","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8844264","Aerial images;convolutional neural networks (CNNs);cross-entropy (CE);multilayer perceptron (MLP);neural architecture search network mobile (NASNet Mobile);transfer learning.","Feature extraction;Deep learning;Computer architecture;Data mining;Remote sensing;Convolutional neural networks;Multilayer perceptrons","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Learning-based Resource Management in Device-to-Device Communications with Energy Harvesting Requirements","K. Lee; J. Hong; H. Seo; W. Choi","School of Information and Communication Engineering, Chungbuk National University, Cheongju 28644, South Korea.; Department of Information and Communications Engineering, Pukyoung National University, Busan 48513, South Korea.; School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon 34141, South Korea.; School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon 34141, South Korea.","IEEE Transactions on Communications","","2019","PP","99","1","1","In this paper, we propose a resource management method based on deep learning, which controls both the transmit power and the power splitting ratio to maximize the sum rate with low computational complexity in D2D networks with energy harvesting requirements. The introduction of the energy harvesting requirements to D2D networks makes it hard to design an effective resource management solution since the treatment of interference signals should be completely different from the conventional resource management focusing only on the rate maximization. To deal with drawbacks of the conventional deep learning-based approach, we propose a new training algorithm suitable for our resource management problem. Numerical simulations show that the proposed learning-based method outperforms the benchmark methods, which are derived from some relevant works, in most situations and achieves performances comparable to an exhaustive search in terms of the sum rate and energy outage probability. Although the conventional optimization-based method is derived to achieve the asymptotic optimal performance for a large network, the proposed deep learning method is shown to achieve almost the same performance with much lower computational complexity. Furthermore, simulation results offer new insights to the impact of the energy harvesting requirements on the behaviour of the optimal resource management.","","","10.1109/TCOMM.2019.2947514","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8869795","Deep learning;D2D communications;energy harvesting;power splitting;interference channel","Device-to-device communication;Resource management;Computational complexity;Interference channels;Energy harvesting;Neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Multi-label Multi-task Deep Learning for Behavioral Coding","J. Gibson; D. Atkins; T. Creed; Z. Imel; P. Georgiou; S. Narayanan","Electrical Engineering, University of Southern California, Los Angeles, California United States (e-mail: jjgibson@usc.edu); Psychiatry and Behavioral Sciences, University of Washington, Seattle, Washington United States (e-mail: datkins@uw.edu); Psychiatry, University of Pennsylvania Perelman School of Medicine, 14640 Philadelphia, Pennsylvania United States (e-mail: tcreed@pennmedicine.upenn.edu); Ed Psych, U of Utah, Salt Lake City, Utah United States (e-mail: zac.imel@utah.edu); Electrical Engineering, University of Southern California, Los Angeles, California United States (e-mail: georgiou@sipi.usc.edu); Electrical Engineering, University of Southern California, Los Angeles, California United States (e-mail: shri@sipi.usc.edu)","IEEE Transactions on Affective Computing","","2019","PP","99","1","1","We propose a methodology for estimating human behaviors in psychotherapy sessions using multi-label and multi-task learning paradigms. We discuss the problem of behavioral coding in which data of human interactions are annotated with labels to describe relevant human behaviors of interest. We describe two related, yet distinct, corpora consisting of therapist-client interactions in psychotherapy sessions. We experimentally compare the proposed learning approaches for estimating behaviors of interest in these datasets. Specifically, we compare single and multiple label learning approaches, single and multiple task learning approaches, and evaluate the performance of these approaches when incorporating turn context. We demonstrate that the best multi-label, multi-task learning model with turn context achieves 18.9% and 19.5% absolute improvements with respect to a logistic regression classifier (for each behavioral coding task respectively) and 6.4% and 6.1% absolute improvements with respect to the best single-label, single-task deep neural network models. Lastly, we discuss the insights these modeling paradigms provide into these complex interactions including key commonalities and differences of behaviors within and between the two prevalent psychotherapy approaches-Motivational Interviewing and Cognitive Behavioral Therapy-considered.","","","10.1109/TAFFC.2019.2952113","National Institute on Alcohol Abuse and Alcoholism; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8894557","Behavioral coding;behavioral signal processing;multi-label learning;multi-task learning","Encoding;Medical treatment;Task analysis;Machine learning;Psychiatry;Neural networks;Indexes","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Joint Learning of Multiple Latent Domains and Deep Representations for Domain Adaptation","X. Wu; J. Chen; F. Yu; M. Yao; J. Luo","Beijing Laboratory of Intelligent Information Technology, Beijing Institute of Technology, Beijing 100081, China, and also with the School of Computer Science, Beijing Institute of Technology, Beijing 100081, China (e-mail: wuxinxiao@bit.edu.cn).; Beijing Laboratory of Intelligent Information Technology, Beijing Institute of Technology, Beijing 100081, China, and also with the School of Computer Science, Beijing Institute of Technology, Beijing 100081, China; Beijing Laboratory of Intelligent Information Technology, Beijing Institute of Technology, Beijing 100081, China, and also with the School of Computer Science, Beijing Institute of Technology, Beijing 100081, China; Beijing Laboratory of Intelligent Information Technology, Beijing Institute of Technology, Beijing 100081, China, and also with the School of Computer Science, Beijing Institute of Technology, Beijing 100081, China; Department of Computer Science, University of Rochester, Rochester, NY 14611 USA.","IEEE Transactions on Cybernetics","","2019","PP","99","1","12","In domain adaptation, the automatic discovery of multiple latent source domains has succeeded by capturing the intrinsic structure underlying the source data. Different from previous works that mainly rely on shallow models for domain discovery, we propose a novel unified framework based on deep neural networks to jointly address latent domain prediction from source data and deep representation learning from both source and target data. Within this framework, an iterative algorithm is proposed to alternate between 1) utilizing a new probabilistic hierarchical clustering method to separate the source domain into latent clusters and 2) training deep neural networks by using the domain membership as the supervision to learn deep representations. The key idea behind this joint learning framework is that good representations can help to improve the prediction accuracy of latent domains and, in turn, domain prediction results can provide useful supervisory information for feature learning. During the training of the deep model, a domain prediction loss, a domain confusion loss, and a task-specific classification loss are effectively integrated to enable the learned feature to distinguish between different latent source domains, transfer between source and target domains, and become semantically meaningful among different classes. Trained in an end-to-end fashion, our framework outperforms the state-of-the-art methods for latent domain discovery, as validated by extensive experiments on both object classification and human action-recognition tasks.","","","10.1109/TCYB.2019.2921559","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8745500","Deep feature learning;domain adaptation;latent domain discovery;probabilistic hierarchical clustering","Training;Neural networks;Task analysis;Adaptation models;Probabilistic logic;Clustering methods;Predictive models","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Adaptive Power System Emergency Control using Deep Reinforcement Learning","Q. Huang; R. Huang; W. Hao; J. Tan; R. Fan; Z. Huang","Pacific Northwest National Laboratory, Richland, WA 99354, USA.; Pacific Northwest National Laboratory, Richland, WA 99354, USA.; Department of Electrical and Computer Engineering, Duke University, Durham, NC, 27708, USA.; Google Brain, Google Inc, Mountain View, CA, 94043 USA.; Pacific Northwest National Laboratory, Richland, WA 99354, USA.; Pacific Northwest National Laboratory, Richland, WA 99354, USA.","IEEE Transactions on Smart Grid","","2019","PP","99","1","1","Power system emergency control is generally regarded as the last safety net for grid security and resiliency. Existing emergency control schemes are usually designed off-line based on either the conceived “worst” case scenario or a few typical operation scenarios. These schemes are facing significant adaptiveness and robustness issues as increasing uncertainties and variations occur in modern electrical grids. To address these challenges, this paper developed novel adaptive emergency control schemes using deep reinforcement learning (DRL) by leveraging the high-dimensional feature extraction and non-linear generalization capabilities of DRL for complex power systems. Furthermore, an open-source platform named Reinforcement Learning for Grid Control (RLGC) has been designed for the first time to assist the development and benchmarking of DRL algorithms for power system control. Details of the platform and DRL-based emergency control schemes for generator dynamic braking and under-voltage load shedding are presented. Robustness of the developed DRL method to different simulation scenarios, model parameter uncertainty and noise in the observations is investigated. Extensive case studies performed in both the two-area, four-machine system and the IEEE 39-bus system have demonstrated excellent performance and robustness of the proposed schemes.","","","10.1109/TSG.2019.2933191","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8787888","Deep reinforcement learning;emergency control;FIDVR;load shedding;dynamic breaking;transient stability.","Reinforcement learning;Power system stability;Control systems;Power system dynamics;Heuristic algorithms;Power system control;Adaptive systems","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Transforming Cooling Optimization for Green Data Center via Deep Reinforcement Learning","Y. Li; Y. Wen; D. Tao; K. Guan","School of Computer Science and Engineering, Nanyang Technological University, Singapore.; School of Computer Science and Engineering, Nanyang Technological University, Singapore.; UBTECH Sydney Artificial Intelligence Centre, Faculty of Engineering, University of Sydney, Darlington, NSW 2008, Australia, and also with the School of Computer Science, Faculty of Engineering, University of Sydney, Darlington, NSW 2008, Australia.; Bell Labs, Nokia, Holmdel, NJ 07733 USA (e-mail: kyle.guan@nokia.com).","IEEE Transactions on Cybernetics","","2019","PP","99","1","12","Data center (DC) plays an important role to support services, such as e-commerce and cloud computing. The resulting energy consumption from this growing market has drawn significant attention, and noticeably almost half of the energy cost is used to cool the DC to a particular temperature. It is thus an critical operational challenge to curb the cooling energy cost without sacrificing the thermal safety of a DC. The existing solutions typically follow a two-step approach, in which the system is first modeled based on expert knowledge and, thus, the operational actions are determined with heuristics and/or best practices. These approaches are often hard to generalize and might result in suboptimal performances due to intrinsic model errors for large-scale systems. In this paper, we propose optimizing the DC cooling control via the emerging deep reinforcement learning (DRL) framework. Compared to the existing approaches, our solution lends itself an end-to-end cooling control algorithm (CCA) via an off-policy offline version of the deep deterministic policy gradient (DDPG) algorithm, in which an evaluation network is trained to predict the DC energy cost along with resulting cooling effects, and a policy network is trained to gauge optimized control settings. Moreover, we introduce a de-underestimation (DUE) validation mechanism for the critic network to reduce the potential underestimation of the risk caused by neural approximation. Our proposed algorithm is evaluated on an EnergyPlus simulation platform and on a real data trace collected from the National Super Computing Centre (NSCC) of Singapore. The resulting numerical results show that the proposed CCA can achieve up to 11% cooling cost reduction on the simulation platform compared with a manually configured baseline control algorithm. In the trace-based study of conservative nature, the proposed algorithm can achieve about 15% cooling energy savings on the NSCC data trace. Our pioneering approach can shed new light on the application of DRL to optimize and automate DC operations and management, potentially revolutionizing digital infrastructure management with intelligence.","","","10.1109/TCYB.2019.2927410","Green Data Centre Research Project administrated by the Singapore Infocomm and Media Development Authority; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8772127","Data center (DC) cooling optimization;deep learning;reinforcement learning (RL)","Cooling;Optimization;Mathematical model;Computational modeling;Software algorithms;Data models;Atmospheric modeling","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Modeling Hierarchical Brain Networks via Volumetric Sparse Deep Belief Network (VS-DBN)","Q. Dong; F. Ge; N. Qiang; Y. Zhao; J. Lv; H. Huang; J. Yuan; X. Jiang; D. Shen; T. Liu","University of Georgia, athens, Georgia United States 30605 (e-mail: qinglin@uga.edu); UGA, Athens, GA Georgia (e-mail: fg28347@uga.edu); Shaanxi Normal University, Xian China (e-mail: qn315@snnu.edu.cn); Computer Science, University of Georgia, Athens, Georgia United States 30602 (e-mail: zhaoyu.hust@gmail.com); Automation, Northwestern Polytechnical University, Xian China (e-mail: lvjinglei@gmail.com); Northwestern Polytechnical University School of Automation, 307588 Xi'an, Shaanxi China (e-mail: huangheng2014@gmail.com); Nankai University, Tianjin China (e-mail: nkyuanjing@gmail.com); University of Electronic Science and Technology of China, 12599 Chengdu China (e-mail: xijiang@uestc.edu.cn); School of Medicine, Biomedical Research Imaging Center, University of North Carolina, Chapel Hill, North Carolina United States 27599 (e-mail: dinggang_shen@med.unc.edu); Radiology, Methodist Hospital Research Institute - Weill Medical College of Cornell University, Houston United States 77030 (e-mail: tianming.liu@gmail.com)","IEEE Transactions on Biomedical Engineering","","2019","PP","99","1","1","It has been recently shown that deep learning models such as convolutional neural networks (CNN), deep belief networks (DBN) and recurrent neural networks (RNN), exhibited remarkable ability in modeling and representing fMRI data for the understanding of functional activities and networks because of their superior data representation capability and wide availability of effective deep learning tools. For example, spatial and/or temporal patterns of functional brain activities embedded in fMRI data can be effectively characterized and modeled by a variety of CNN/DBN/RNN deep learning models as shown in recent studies. However, it has been rarely investigated whether it is possible to directly infer hierarchical brain networks from volumetric fMRI data using deep learning models such as DBN. The perceived difficulties of such studies include very large number of input variables, very large number of training parameters, the lack of effective software tools, the challenge of results interpretation, and etc. To bridge these technical gaps, we designed a novel volumetric sparse deep belief network (VS-DBN) model and implemented it through the popular TensorFlow open source platform to reconstruct hierarchical brain networks from volumetric fMRI data based on the Human Connectome Project (HCP) 900 subjects release. Our experimental results showed that a large number of interpretable and meaningful brain networks can be robustly reconstructed from HCP 900 subjects in a hierarchical fashion, and importantly, these brain networks exhibit reasonably good consistency and correspondence across multiple HCP task-based fMRI datasets. Our work contributed a new general deep learning framework for inferring multiscale volumetric brain networks and offered novel insights into the hierarchical organization of functional brain architecture.","","","10.1109/TBME.2019.2945231","National Institutes of Health; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8880543","Deep belief network;task fMRI;hierarchical brain network","Functional magnetic resonance imaging;Data models;Brain modeling;Task analysis;Deep learning;Image reconstruction;Training","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Intelligent IoT Connectivity: Deep Reinforcement Learning Approach","M. Kwon; J. Lee; H. Park","Department of Electrical and Computer Engineering, Rice University and Center for Neuroscience and Artificial Intelligence, Department of Neuroscience, Baylor College of Medicine, Houston, TX, USA; College of Information and Computer Sciences, University of Massachusetts Amherst, MA, USA; Department of Electronic and Electrical Engineering, Ewha Womans University, Seoul, Republic of Korea","IEEE Sensors Journal","","2019","PP","99","1","1","In this paper, we propose a distributed solution to design a multi-hop ad hoc Internet of Things (IoT) network where mobile IoT devices strategically determine their wireless transmission ranges based on a deep reinforcement learning approach. We consider scenarios where only a limited networking infrastructure is available but a large number of IoT devices are deployed in building a multi-hop ad hoc network to deliver source data to the destination. An IoT device is considered as a decision-making agent that strategically determines its transmission range in a way that maximizes network throughput while minimizing the corresponding transmission power consumption. Each IoT device collects information from its partial observations and learns its environment through a sequence of experiences. Hence, the proposed solution requires only a minimal amount of information from the system. We show that the actions that the IoT devices take from its policy are determined as to activate or inactivate its transmission, i.e., only necessary relay nodes are activated with the maximum transmit power, and nonessential nodes are deactivated to minimize power consumption. Using extensive experiments, we confirm that the proposed solution builds a network with higher network performance than the current state-of-the-art solutions in terms of system goodput and connectivity ratio.","","","10.1109/JSEN.2019.2949997","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8886442","Intelligent IoT Connectivity;Network Formation;Network Topology Design;Deep Reinforcement Learning;Wireless Ad Hoc Networks;Mobile Relay Networks","Internet of Things;Intelligent sensors;Reinforcement learning;Decision making;Spread spectrum communication","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Human Action Recognition Using Deep Learning Methods on Limited Sensory Data","N. Tufek; M. Yalcin; M. Altintas; F. Kalaoglu; Y. Li; S. K. Bahadir","NA; NA; NA; NA; NA; NA","IEEE Sensors Journal","","2019","PP","99","1","1","In recent years, due to the widespread usage of various sensors action recognition is becoming more popular in many fields such as person surveillance, human-robot interaction etc. In this study, we aimed to develop an action recognition system by using only limited accelerometer and gyroscope data. Several deep learning methods like Convolutional Neural Network(CNN), Long-Short Term Memory (LSTM) with classical machine learning algorithms and their combinations were implemented and a performance analysis was carried out. Data balancing and data augmentation methods were applied and accuracy rates were increased noticeably. We achieved new state-of-the-art result on the UCI HAR dataset by 97.4% accuracy rate with using 3 layer LSTM model. Also, we implemented same model on collected dataset (ETEXWELD) and 99.0% accuracy rate was obtained which means a solid contribution. Moreover, the performance analysis is not only based on accuracy results, but also includes precision, recall and f1-score metrics. Additionally, a real-time application was developed by using 3 layer LSTM network for evaluating how the best model classifies activities robustly.","","","10.1109/JSEN.2019.2956901","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8918509","Activity recognition;deep learning;CNN;LSTM;data augmentation;data balancing","Machine learning;Biomedical monitoring;Gyroscopes;Feature extraction;Accelerometers;Wearable sensors","","","","","","","","","","IEEE","IEEE Early Access Articles"
"End-to-end Navigation Strategy with Deep Reinforcement Learning for Mobile Robots","H. Shi; L. Shi; M. Xu; K. Hwang","School of Computer Science, Northwestern Polytechnical University, Xi'an 710129, China (e-mail: shihaobin@nwpu.edu.cn); School of Software and Microelectronics, Northwestern Polytechnical University, Xi'an 710072, China (e-mail: slsl@mail.nwpu.edu.cn); School of Computer Science, Northwestern Polytechnical University, Xi'an 710129, China (e-mail: 2991359742@qq.com); Department of Electrical Engineering, National Sun Yat-sen University, Kaohsiung 80424 Taiwan, and also with the Department of Healthcare Administration and Medical Informatic, Kaohsiung Medical University, Kaohsiung 80708, Taiwan (e-mail: hwang@mail.ee.nsysu.edu.tw)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","This paper develops a navigation strategy based on deep reinforcement learning (DRL) for mobile robots. Because of the large difference between simulation and reality, most of the trained DRL models cannot be directly migrated into real robots. Moreover, how to explore in a sparsely rewardedenvironment isalsoalong-standing problemof DRL. This study proposes an end-to-end navigation planner that translates sparse laser ranging results into movement actions. Using this highly abstract data as input, agents trained by simulation can be extended to the real scene for practical application. For map-less navigation across obstacles and traps, it is difficult to reach the target via random exploration. Curiosity is used to encourage agents to explore the state of an environment that has not been visited and as an additional reward for exploring behavior. The agent relies on the self-supervised model to predict the next state, based on the current state and the executed action. The prediction error is used as a measure of curiosity. The experimental results demonstrate that without any manual design features and previous demonstrations, the proposed method accomplishes map-less navigation in complex environments. Through a reward signal that is enhanced by intrinsic motivation, the agent explores more efficiently and the learned strategy is more reliable.","","","10.1109/TII.2019.2936167","National Natural Science Foundation of China; Shaanxi Province Key Research and Development Program of China; Seed Foundation of Innovation and Creation for Graduate Students in Northwestern Polytechnical University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8807287","Deep reinforcement learning (DRL);mobile robots;navigation;curiosity-driven","Navigation;Task analysis;Mobile robots;Mathematical model;Reinforcement learning;Sensors","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Weakly Supervised Deep Learning for Brain Disease Prognosis Using MRI and Incomplete Clinical Scores","M. Liu; J. Zhang; C. Lian; D. Shen","Department of Radiology and BRIC, University of North Carolina at Chapel Hill, Chapel Hill, NC 27599 USA.; Department of Radiology and BRIC, University of North Carolina at Chapel Hill, Chapel Hill, NC 27599 USA.; Department of Radiology and BRIC, University of North Carolina at Chapel Hill, Chapel Hill, NC 27599 USA.; Department of Radiology and BRIC, University of North Carolina at Chapel Hill, Chapel Hill, NC 27599 USA, and also with the Department of Brain and Cognitive Engineering, Korea University, Seoul 02841, South Korea (e-mail: dgshen@med.unc.edu).","IEEE Transactions on Cybernetics","","2019","PP","99","1","12","As a hot topic in brain disease prognosis, predicting clinical measures of subjects based on brain magnetic resonance imaging (MRI) data helps to assess the stage of pathology and predict future development of the disease. Due to incomplete clinical labels/scores, previous learning-based studies often simply discard subjects without ground-truth scores. This would result in limited training data for learning reliable and robust models. Also, existing methods focus only on using hand-crafted features (e.g., image intensity or tissue volume) of MRI data, and these features may not be well coordinated with prediction models. In this paper, we propose a weakly supervised densely connected neural network (wiseDNN) for brain disease prognosis using baseline MRI data and incomplete clinical scores. Specifically, we first extract multiscale image patches (located by anatomical landmarks) from MRI to capture local-to-global structural information of images, and then develop a weakly supervised densely connected network for task-oriented extraction of imaging features and joint prediction of multiple clinical measures. A weighted loss function is further employed to make full use of all available subjects (even those without ground-truth scores at certain time-points) for network training. The experimental results on 1469 subjects from both ADNI-1 and ADNI-2 datasets demonstrate that our proposed method can efficiently predict future clinical measures of subjects.","","","10.1109/TCYB.2019.2904186","NIH; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8674823","Alzheimer's disease (AD);clinical score;disease prognosis;neural network;weakly supervised learning","Magnetic resonance imaging;Diseases;Brain modeling;Feature extraction;Training;Deep learning;Prognostics and health management","","","","","","","","","","IEEE","IEEE Early Access Articles"
"An integrative framework for combining sequence and epigenomic data to predict transcription factor binding sites using deep learning","F. Jing; S. Zhang; Z. Cao; S. Zhang","Xian, Shanxi China (e-mail: jingfang@mail.nwpu.edu.cn); Northwestern Polytechnical University, Xian, Shaanxi China 710072 (e-mail: zhangsw@nwpu.edu.cn); Institute of Systems Science Academy of Mathematics and Systems Science Chinese Academy of Sciences, 74693 Beijing, Beijing China 100080 (e-mail: cz@amss.ac.cn); Academy of Mathematics and Systems Science, CAS, Beijing, Beijing China (e-mail: zsh@amss.ac.cn)","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2019","PP","99","1","1","Knowing the transcription factor binding sites (TFBSs) is essential for modeling the underlying binding mechanisms and follow-up cellular functions. Convolutional neural networks (CNNs) have outperformed methods in predicting TFBSs from the primary DNA sequence. In addition to DNA sequences, histone modifications and chromatin accessibility are also important factors influencing their activity. They have been explored to predict TFBSs recently. However, current methods rarely take into account histone modifications and chromatin accessibility using CNN in an integrative framework. To this end, we developed a general CNN model to integrate these data for predicting TFBSs. We systematically benchmarked a series of architecture variants by changing network structure in terms of width and depth, and explored the effects of sample length at flanking regions. We evaluated the performance of the three types of data and their combinations using 256 ChIP-seq experiments and also compared it with competing machine learning methods. We find that contributions from these three types of data are complementary to each other. Moreover, the integrative CNN framework is superior to traditional machine learning methods with significant improvements.","","","10.1109/TCBB.2019.2901789","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8654676","Bioinformatics;machine learning;transcription factors binding sites;convolutional neural networks;DNA accessibility;histone modification","DNA;Data models;Feature extraction;Bioinformatics;Genomics;Biological system modeling;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Seismic Facies Analysis Based on Deep Learning","Y. Zhang; Y. Liu; H. Zhang; H. Xue","State Key Laboratory of Petroleum Resources and Prospecting, China University of Petroleum-Beijing, Beijing 102249, China.; State Key Laboratory of Petroleum Resources and Prospecting, China University of Petroleum-Beijing, Beijing 102249, China, and also with the School of Petroleum, China University of Petroleum-Beijing, Karamay 834000, China (e-mail: wliuyang@vip.sina.com).; State Key Laboratory of Petroleum Resources and Prospecting, China University of Petroleum-Beijing, Beijing 102249, China.; CNOOC International Ltd., Beijing 100028, China.","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","Seismic facies analysis is to study the sedimentary environment of stratigraphic sequence and provides an important basis for reservoir prediction. Most of the existing analysis methods have low efficiency and heavily rely on manual experience, and therefore, it is difficult to interpret increasingly complex seismic data. Deep learning techniques can help to solve these problems and achieve automatic seismic facies classification. We regard seismic facies classification as a target segmentation problem and propose new method and training strategies. Our workflow primarily involves four sections. First, we process the manually annotated labels and seismic data with mirroring and cropping operations to ensure that network can accept input with arbitrary size and the model training is not limited to GPU memory. Second, data augmentation is applied to automatically generate massive training samples from the processed data. Third, we build two independent networks based on encoder-decoder architecture: one identifies all seismic facies simultaneously, and the other identifies single seismic facies in each model. However, both the results of the two networks have some drawbacks. Fourth, to overcome these drawbacks, we propose an ensemble learning method to get optimized model and test it on 3-D seismic data. The testing results manifest that the proposed method can improve the predictive ability of model, accurately describe the seismic facies, and can be applicable to entire seismic data volume.","","","10.1109/LGRS.2019.2941166","National Science and Technology Major Project of China 2017ZX05018-005; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8859617","Deep learning;encoder-decoder architecture;ensemble learning;seismic facies analysis.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Personalized Driver Workload Estimation Using Deep Neural Network Learning from Physiological and Vehicle Signals","Y. Xie; Y. L. Murphey; D. Kochhar","Electrical and Computer Engineering, University of Michigan Dearborn, 14711 Dearborn, Michigan United States (e-mail: yongquan@umich.edu); Electrical and Computer Engineering, University of Michigan Dearborn, 14711 Dearborn, Michigan United States (e-mail: yilu@umich.edu); Retired, Ford Motor Company, 1931 Dearborn, Michigan United States (e-mail: dkochhar@gmail.com)","IEEE Transactions on Intelligent Vehicles","","2019","PP","99","1","1","Drivers often engage in secondary in-vehicle activities that can be functional and/or to relieve monotony. Drivers believe they can safely do so when their perceived workload is low. However, driving requires concurrent execution of cognitive, physical, perceptual and motor tasks. Over allocation of a driver's attention to secondary tasks may impair the driver's control of the vehicle and attention to the surrounding traffic. Accurate assessment of a driver's workload is an important, but challenging, research topic with many applications in intelligent vehicle systems related to driving safety and enhance driving experience. In this paper, we present our research on driver workload detection based on driver's physiological, vehicle signals as well as traffic contexts such as congestion level and traffic events. We obtained a collection of data from real driving scenarios. Twenty participants were recruited, whose workload was scaled to ""low"" as a base level, and ""elevated"" as a higher level. We developed two convolutional neural networks for multivariate temporal series (MTS-CNN). Extensive experiments were conducted in two scopes: within driver and cross-driver. The within-driver scope concentrates on experiments using data from a single driver, while in the cross-driver scope, transfer learning is leveraged and discussed. The experimental results demonstrate that one of the proposed models, i.e., MTS-CNN2, which combines features captured by the convolutional layers at all levels, is capable of learning well from the combined temporal physiological and vehicle signals and obtains the best performance.","","","10.1109/TIV.2019.2960946","Ford-UM Alliance Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8936874","Driver workload estimation;multivariate temporal series (MTS);convolutional neural networks (CNN);driver assistance system;transfer learning","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Improved Deep Belief Network and Model Interpretation Method for Power System Transient Stability Assessment","S. Wu; L. Zheng; W. Hu; R. Yu; B. Liu","State Key Laboratory of Power System, Department of Electrical Engineering, Tsinghua University, Beijing 100084, China; Stanford University, Stanford, California 94305, USA; State Key Laboratory of Power System, Department of Electrical Engineering, Tsinghua University, Beijing 100084, China; Southwest Branch, State Grid Corporation of China, Chengdu 610041, China; Southwest Branch, State Grid Corporation of China, Chengdu 610041, China","Journal of Modern Power Systems and Clean Energy","","2019","PP","99","1","11","The real-time transient stability assessment and emergency control are effective measures to suppress accident expansion, prevent system instability, and avoid large-scale power outages in the event of power system failure. However, realtime assessment is extremely demanding on computing speed, and the traditional method is not competent. In this paper, an improved deep belief network (DBN) is proposed for the fast assessment of transient stability, which considers the structural characteristics of power system in the construction of loss function. Deep learning has been effective in many fields, but usually is considered as a black-box model. From the perspective of machine learning interpretation, this paper proposes a local linear interpreter (LLI) model, and tries to give a reasonable interpretation of the relationship between the system features and the assessment result, and illustrates the conversion process from the input feature space to the high-dimension representation space. The proposed method is tested on IEEE new England test system and demonstrated on a regional power system in China. The result demonstrates that the proposed method has rapidity, high accuracy and good interpretability in transient stability assessment.","","","10.35833/MPCE.2019.000058","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8913673","Transient stability assessment (TSA);representation learning;deep belief network (DBN);local linear interpretation (LLI);visualization;emergency control","Power system stability;Stability criteria;Transient analysis;Training;Thermal stability","","","","","","","","","","SGEPRI","SGEPRI Early Access Articles"
"What, Where, and How to Transfer in SAR Target Recognition Based on Deep CNNs","Z. Huang; Z. Pan; B. Lei","Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing 100094, China, with the University of Chinese Academy of Sciences, Beijing 101408, China, and also with the Key Laboratory of Technology in Geo-Spatial Information Processing and Application System, Chinese Academy of Sciences, Beijing 100190, China.; Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing 100094, China, with the University of Chinese Academy of Sciences, Beijing 101408, China, and also with the Key Laboratory of Technology in Geo-Spatial Information Processing and Application System, Chinese Academy of Sciences, Beijing 100190, China (e-mail: zxpan@mail.ie.ac.cn).; Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing 100094, China, with the University of Chinese Academy of Sciences, Beijing 101408, China, and also with the Key Laboratory of Technology in Geo-Spatial Information Processing and Application System, Chinese Academy of Sciences, Beijing 100190, China.","IEEE Transactions on Geoscience and Remote Sensing","","2019","PP","99","1","13","Deep convolutional neural networks (DCNNs) have attracted much attention in remote sensing recently. Compared with the large-scale annotated data set in natural images, the lack of labeled data in remote sensing becomes an obstacle to train a deep network very well, especially in synthetic aperture radar (SAR) image interpretation. Transfer learning provides an effective way to solve this problem by borrowing knowledge from the source task to the target task. In optical remote sensing application, a prevalent mechanism is to fine-tune on an existing model pretrained with a large-scale natural image data set, such as ImageNet. However, this scheme does not achieve satisfactory performance for SAR applications because of the prominent discrepancy between SAR and optical images. In this article, we attempt to discuss three issues that are seldom studied before in detail: 1) what network and source tasks are better to transfer to SAR targets; 2) in which layer are transferred features more generic to SAR targets; and 3) how to transfer effectively to SAR targets recognition. Based on the analysis, a transitive transfer method via multisource data with domain adaptation is proposed in this article to decrease the discrepancy between the source data and SAR targets. Several experiments are conducted on OpenSARShip. The results indicate that the universal conclusions about transfer learning in natural images cannot be completely applied to SAR targets, and the analysis of what and where to transfer in SAR target recognition is helpful to decide how to transfer more effectively.","","","10.1109/TGRS.2019.2947634","National Natural Science Foundation of China; Joint Training Program of the Univer- sity of Chinese Academy of Sciences; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8907833","Deep convolutional neural networks (DCNN);domain adaptation;synthetic aperture radar (SAR) target recognition;transfer learning.","Synthetic aperture radar;Task analysis;Target recognition;Optical sensors;Remote sensing;Optical imaging;Radar polarimetry","","","","","","","","","","IEEE","IEEE Early Access Articles"
"3D Human Pose Machines with Self-supervised Learning","K. Wang; L. Lin; C. Jiang; C. Qian; P. Wei","School of Data and Computer Science, Sun Yat-Sen University, 26469 Guangzhou, Guangdong China (e-mail: kezewang@gmail.com); School of Information Science and Technology, Sun Yat-sen University, Guangzhou, Guangdong China (e-mail: linliang@ieee.org); School of Information Science and Technology, Sun Yat-sen University, Guangzhou, Guangdong China (e-mail: jiangchh6@mail2.sysu.edu.cn); Research Deparment, SenseTime Group Limited, Hong Kong, Hong Kong China (e-mail: qianchen@sensetime.com); School of Data and Computer Science, Sun Yat-Sen University, 26469 Guangzhou, Guangdong China (e-mail: pengxu.07@163.com)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Driven by recent computer vision and robotic applications, recovering 3D human poses has become increasingly important and attracted growing interests. In fact, completing this task is quite challenging due to the diverse appearances, viewpoints, occlusions and inherently geometric ambiguities inside monocular images. Most of the existing methods focus on designing some elaborate priors/constraints to directly regress 3D human poses based on the corresponding 2D human pose-aware features or 2D pose predictions. However, due to the insufficient 3D pose data for training and the domain gap between 2D space and 3D space, these methods have limited scalabilities for all practical scenarios (e.g., outdoor scene). Attempt to address this issue, this paper proposes a simple yet effective self-supervised correction mechanism to learn all intrinsic structures of human poses from abundant images without 3D pose annotations. We further apply our self-supervised correction mechanism to develop a recurrent 3D pose machine, which jointly integrates the 2D spatial relationship, temporal smoothness of predictions and 3D geometric knowledge. Extensive evaluations on the Human3.6M and HumanEva-I benchmarks demonstrate the superior performance and efficiency of our framework over all the compared computing methods.","","","10.1109/TPAMI.2019.2892452","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8611195","human pose estimation;convolutional neural networks;spatio-temporal modeling;self-supervised learning;geometric deep learning","Three-dimensional displays;Two dimensional displays;Pose estimation;Solid modeling;Task analysis;Deep learning;Feature extraction","","","","","","","","","","IEEE","IEEE Early Access Articles"
"WiFi Fingerprinting Indoor Localization Using Local Feature-Based Deep LSTM","Z. Chen; H. Zou; J. Yang; H. Jiang; L. Xie","School of Electrical and Electronic Engineering, Nanyang Technological University Singapore, 639798 (e-mail: chen0832@ntu.edu.sg).; School of Electrical and Electronic Engineering, Nanyang Technological University Singapore, 639798 (e-mail: zouhan@ntu.edu.sg).; School of Electrical and Electronic Engineering, Nanyang Technological University Singapore, 639798 (e-mail: yang0478@ntu.edu.sg).; College of Electrical Engineering and Automation, Fuzhou University, Fuzhou 350001, China (e-mail: jiangh@fzu.edu.cn).; School of Electrical and Electronic Engineering, Nanyang Technological University Singapore, 639798 (e-mail: elhxie@ntu.edu.sg).","IEEE Systems Journal","","2019","PP","99","1","10","Indoor localization has attracted more and more attention because of its importance in many applications. One of the most popular techniques for indoor localization is the received signal strength indicator (RSSI) based fingerprinting approach. Since RSSI values are very complicated and noisy, conventional machine learning algorithms often suffer from limited performance. Recently developed deep learning algorithms have been shown to be powerful for the analysis of complex data. In this paper, we propose a local feature-based deep long short-term memory (LF-DLSTM) approach for WiFi fingerprinting indoor localization. The local feature extractor attempts to reduce the noise effect and extract robust local features. The DLSTM network is able to encode temporal dependencies and learn high-level representations for the extracted sequential local features. Real experiments have been conducted in two different environments, i.e., a research lab and an office. We also compare the proposed approach with some state-of-the-art methods for indoor localization. The results show that the proposed approach achieves the best localization performance with mean localization errors of 1.48 and 1.75 m under the research lab and office environments, respectively. The improvements of our proposed approach over the state-of-the-art methods range from $\text{18.98}\text{\%}$ to $\text{53.46}\text{\%}$.","","","10.1109/JSYST.2019.2918678","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8733822","Deep learning;local feature-based deep long short-term memory (LF-DLSTM);indoor localization;WiFi fingerprinting","Wireless fidelity;Feature extraction;Smart phones;Training;Testing;Machine learning algorithms;Random processes","","","","3","","","","","","IEEE","IEEE Early Access Articles"
"Deep Dual-Channel Neural Network for Image-Based Smoke Detection","K. Gu; Z. Xia; J. Qiao; W. Lin","Faculty of Information Technology, Beijing University of Technology, 12496 Beijing China (e-mail: guke.doctor@gmail.com); Faculty of Information Technology, Beijing University of Technology, 12496 Beijing China (e-mail: spidergirl21@163.com); Faculty of Information Technology, Beijing University of Technology, 12496 Beijing China (e-mail: junfeiq@bjut.edu.cn); SCE, Nanyang Technological University, Singapore Singapore (e-mail: wslin@ntu.edu.sg)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","Smoke detection plays an important role in industrial safety warning systems and fire prevention. Due to the complicated changes in the shape, texture and colour of smoke, identifying the smoke from a given image still remains a substantial challenge, and this has accordingly aroused a considerable amount of research attention recently. To address the problem, we devise a new deep dual-channel neural network (DCNN) for smoke detection. In contrast to popular deep convolutional networks, e.g., Alex-Net, VGG-Net, Res-Net, and Dense-Net, and the DNCNN that is specifically devoted to detecting smoke, our proposed end-to-end network is mainly composed of dual channels of deep subnetworks. In the first subnetwork, we sequentially connect multiple convolutional layers and max-pooling layers. Then, we selectively append the batch normalization layer to each convolutional layer for over-fitting reduction and training acceleration. The first subnetwork is shown to be good at extracting the detail information of smoke, such as texture. In the second subnetwork, in addition to the convolutional, batch normalization and max-pooling layers, we further introduce two important components. One is the skip connection for avoiding the vanishing gradient and improving the feature propagation. The other is the global average pooling for reducing the number of parameters and mitigating the over-fitting issue. The second subnetwork can capture the base information of smoke, such as contours. We finally deploy a concatenation operation to combine the aforementioned two deep subnetworks to complement each other. Based on the augmented data obtained by rotating the training images, our proposed DCNN can promptly and stably converge to the perfect performance. Experimental results conducted on the publicly available smoke detection database verify that the proposed DCNN has attained a very high detection rate that exceeds 99.5% on average, superior to state-of-the-art relevant competitors. Furthermore, our DCNN only employs approximately one-third of the parameters needed by the comparatively tested deep neural networks. The source code of DCNN will be released to the public.","","","10.1109/TMM.2019.2929009","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8764415","Smoke detection;deep learning;convolutional network;dual-channel network;classification","Feature extraction;Neural networks;Training;Deep learning;Convolutional codes;Convolution;Safety","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Video Anomaly Detection With Sparse Coding Inspired Deep Neural Networks","W. Luo; W. Liu; D. Lian; J. Tang; L. Duan; X. Peng; S. Gao","SIST, ShanghaiTech University, 387433 Shanghai, Shanghai China (e-mail: luowx@shanghaitech.edu.cn); SIST, ShanghaiTech University, 387433 Shanghai, SHANGHAI China (e-mail: liuwen@shanghaitech.edu.cn); SIST, ShanghaiTech University, 387433 Shanghai, SHANGHAI China (e-mail: liandz@shanghaitech.edu.cn); School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, Jiangsu China (e-mail: jinhuitang@njust.edu.cn); SCE, University of Electronic Science and Technology of China, 12599 Chengdu, Sichuan China (e-mail: lxduan@gmail.com); College of Computer Science, Sichuan University, 12530 Chengdu, Sichuan China 610065 (e-mail: pengx.gm@gmail.com); ShanghaiTech University, ShanghaiTech University, Shanghai, Shanghai China (e-mail: gaoshh@shanghaitech.edu.cn)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","This paper presents an anomaly detection method that is based on a sparse coding inspired Deep Neural Networks (DNN). Specifically, we propose a Temporally-coherent Sparse Coding (TSC), where a temporally-coherent term is used to preserve the similarity between two neighboring frames. The optimization of sparse coefficients in TSC is equivalent to a special stacked Recurrent Neural Networks (sRNN) architecture. Further, to reduce the computational cost in alternatively updating the dictionary and sparse coefficients in TSC optimization and to alleviate hyperparameters selection in TSC, we stack one more layer on top of the TSC-inspired sRNN to reconstruct the inputs, and arrive at an sRNN-AE. We further improve sRNN-AE in the following aspects: i) we propose to learn a data-dependent similarity measurement between neighboring frames in sRNN-AE; ii) we reduce the depth of the sRNN in sRNN-AE; iii) we conduct temporal pooling over the appearance features of several consecutive frames for motion characterization. We also build a large-scale anomaly detection dataset for performance evaluation. Extensive experiments on both a toy dataset under controlled settings and real datasets demonstrate the effectiveness of our sRNN-AE method for anomaly detection.","","","10.1109/TPAMI.2019.2944377","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8851288","Sparse Coding;Anomaly Detection;Stacked Recurrent Neural Networks","Anomaly detection;Encoding;Feature extraction;Training;Optimization;Dictionaries;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Comparative Study for Unsupervised Network Representation Learning","M. Khosla; V. Setty; A. Anand","L3S Research Center, Leibniz University Hanover, 26555 Hannover, Niedersachsen Germany 30167 (e-mail: khosla@l3s.de); Electrical Engineering and Computer Science, University of Stavanger, 56627 Stavanger, Rogaland Norway (e-mail: vsetty@acm.org); L3S Research center, Leibniz Universitat Hannover, 26555 Hannover, Niedersachsen Germany (e-mail: anand@l3s.de)","IEEE Transactions on Knowledge and Data Engineering","","2019","PP","99","1","1","There has been significant progress in unsupervised network representation learning (UNRL) approaches over graphs recently with flexible random-walk approaches, new optimization objectives and deep architectures. However, there is no common ground for systematic comparison of embeddings to understand their behavior for different graphs and tasks. We argue that most of the UNRL approaches either model and exploit neighborhood or what we call context information of a node. These methods largely differ in their definitions and exploitation of context. Consequently, we propose a framework that casts a variety of approaches - random walk based, matrix factorization and deep learning based - into a unified context-based optimization function. We systematically group the methods based on their similarities and differences. We study their differences which we later use to explain their performance differences (on downstream tasks). We conduct a large-scale empirical study considering 9 popular and recent UNRL techniques and 11 real-world datasets with varying structural properties and two common tasks - node classification and link prediction. We find that for non-attributed graphs there is no single method that is a clear winner and that the choice of a suitable method is dictated by certain properties of the embedding methods, task and structural properties of the underlying graph. In addition we also report the common pitfalls in evaluation of UNRL methods and come up with suggestions for experimental design and interpretation of results.","","","10.1109/TKDE.2019.2951398","H2020 Research Infrastructures; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8890798","","Task analysis;Deep learning;Linear programming;Context modeling;Optimization;Systematics;Social networking (online)","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Ultra-short-term industrial power demand forecasting using LSTM based hybrid ensemble learning","M. Tan; S. Yuan; S. Li; Y. Su; H. Li; F. He","Xiangtan China 411105 (e-mail: mr.tanmao@gmail.com); Xiangtan University, 12665 Xiangtan, Hunan China (e-mail: ysphhb@gmail.com); Electrical Engineering and Electronics, University of Liverpool, Liverpool United Kingdom of Great Britain and Northern Ireland L7 3QT (e-mail: lishuaihu2010@xtu.edu.cn); Xiangtan University, 12665 Xiangtan, Hunan China (e-mail: suyongxin@xtu.edu.cn); Xiangtan University, 12665 Xiangtan, Hunan China (e-mail: lihui7402@126.com); Hunan Valin Xiangtan Iron and Steel Co., Ltd., Xiangtan, Hunan China (e-mail: 163hefeng@163.com)","IEEE Transactions on Power Systems","","2019","PP","99","1","1","Power demand forecasting with high accuracy is a guarantee to keep the balance between power supply and demand. Due to strong volatility of industrial power load, ultra-short-term power demand is difficult to forecast accurately and robustly. To solve this problem, this paper proposes a Long Short-Term Memory (LSTM) network based hybrid ensemble learning forecasting model. A hybrid ensemble strategy---which consists of Bagging, Random Subspace, and Boosting with ensemble pruning---is designed to extract the deep features from multivariate data, and a new loss function that integrates peak demand forecasting error is proposed according to bias-variance tradeoff. Experimental results on open dataset and practical datasets show that the proposed model outperforms several state-of-the-art time series forecasting models, and obtains higher accuracy and robustness to forecast peak demand.","","","10.1109/TPWRS.2019.2963109","Hunan Provincial Science and Technology Department; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8946642","Short-term load forecasting;Power demand forecasting;Deep learning;Ensemble learning;LSTM","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Spatio-temporal Manifold Learning for Human Motions via Long-horizon Modeling","H. Wang; E. S. L. Ho; H. P. H. Shum; Z. Zhu","School of Computing, University of Leeds, 4468 Leeds, West Yorkshire United Kingdom of Great Britain and Northern Ireland (e-mail: realcrane@gmail.com); Computer and Information Sciences, Northumbria University, 5995 Newcastle upon Tyne, Tyne and Wear United Kingdom of Great Britain and Northern Ireland NE1 8ST (e-mail: e.ho@northumbria.ac.uk); Faculty of Engineering and Environment, Northumbria University, Newcastle, Tyne and Wear United Kingdom of Great Britain and Northern Ireland (e-mail: hubert.shum@northumbria.ac.uk); Center for Data Science, Peking University, Beijing, Beijing China (e-mail: zhanxing.zhu@pku.edu.cn)","IEEE Transactions on Visualization and Computer Graphics","","2019","PP","99","1","1","Data-driven modeling of human motions is ubiquitous in computer graphics and vision applications. Such problems can be approached by deep learning on a large amount data. However, existing methods can be sub-optimal for two reasons. First, skeletal information has not been fully utilized. Unlike images, it is difficult to define spatial proximity in skeletal motions in the way that deep networks can be applied for feature extraction. Second, motion is time-series data with strong multi-modal temporal correlations between frames. A frame could lead to different motions; on the other hand, long-range dependencies exist where a number of frames in the beginning correlate to a number of frames later. Ineffective temporal modeling would either under-estimate the multi-modality and variance. We propose a new deep network to tackle these challenges by creating a natural motion manifold that is versatile for many applications. The network has a new spatial component and is equipped with a new batch prediction model that predicts a large number of frames at once, such that long-term temporally-based objective functions can be employed to correctly learn the motion multi-modality and variances. We demonstrate that our system can create superior results comparing to existing work in multiple applications.","","","10.1109/TVCG.2019.2936810","Engineering and Physical Sciences Research Council; Royal Society; NVIDIA Corporation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8809754","Computer Graphics;Computer Animation;Character Animation;Deep Learning","Manifolds;Deep learning;Skeleton;Three-dimensional displays;Feature extraction;Dynamics;Animation","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Online Deep Fuzzy Learning for Control of Nonlinear Systems Using Expert Knowledge","A. Sarabakha; E. Kayacan","School of Mechanical and Aerospace Engineering, Nanyang Technological University, 54761 Singapore Singapore 639798 (e-mail: andriy001@e.ntu.edu.sg); Department of Engineering, Aarhus Universitet, 1006 Aarhus Denmark 8200 (e-mail: erdal@eng.au.dk)","IEEE Transactions on Fuzzy Systems","","2019","PP","99","1","1","This work presents an online learning method for improved control of nonlinear systems by combining deep learning and fuzzy logic. Given the ability of deep learning to generalise knowledge from training samples, the proposed method requires minimum amount of information about the system to be controlled. However, in robotics, particularly in aerial robotics where the operating conditions may vary, online learning is required. In this study, fuzzy logic is preferred to provide supervising feedback to the deep model for adapting to variations in the system dynamics as well as new operational conditions. The learning method is divided into two phases: offline pre-training and online post-training. In the former, the system is controlled by a conventional controller and a deep fuzzy neural network (DFNN) is pre-trained based on the recorded input-output dataset, in order to approximate the inverse dynamical model of the system. In the latter, only the pre-trained DFNN is used to control the system. In this phase, the fuzzy logic, which encodes the expert knowledge, is utilized to observe the behaviour of the system and to correct the action of DFNN instantaneously. The experimental results show that the proposed online learning-based approach improves the trajectory tracking performance of the unmanned aerial vehicle.","","","10.1109/TFUZZ.2019.2936787","Aarhus Universitet; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8809217","Deep learning;fuzzy logic;adaptive process control;nonlinear systems;aerial robotics","Control systems;Training;Fuzzy logic;Neurons;Nonlinear systems;Fuzzy neural networks;Noise measurement","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Stacking-Based Deep Neural Network: Deep Analytic Network for Pattern Classification","C. Low; J. Park; A. B. Teoh","School of Electrical and Electronic Engineering, College of Engineering, Yonsei University, Seoul 03722, South Korea. He is now with the Faculty of Information Science and Technology, Multimedia University, Melaka 75450, Malaysia.; School of Electrical and Electronic Engineering, College of Engineering, Yonsei University, Seoul 03722, South Korea.; School of Electrical and Electronic Engineering, College of Engineering, Yonsei University, Seoul 03722, South Korea (e-mail: bjteoh@yonsei.ac.kr).","IEEE Transactions on Cybernetics","","2019","PP","99","1","14","Stacking-based deep neural network (S-DNN) is aggregated with pluralities of basic learning modules, one after another, to synthesize a deep neural network (DNN) alternative for pattern classification. Contrary to the DNNs trained from end to end by backpropagation (BP), each S-DNN layer, that is, a self-learnable module, is to be trained decisively and independently without BP intervention. In this paper, a ridge regression-based S-DNN, dubbed deep analytic network (DAN), along with its kernelization (K-DAN), are devised for multilayer feature relearning from the pre-extracted baseline features and the structured features. Our theoretical formulation demonstrates that DAN/K-DAN relearn by perturbing the intra/interclass variations, apart from diminishing the prediction errors. We scrutinize the DAN/K-DAN performance for pattern classification on datasets of varying domains--faces, handwritten digits, generic objects, to name a few. Unlike the typical BP-optimized DNNs to be trained from gigantic datasets by GPU, we reveal that DAN/K-DAN are trainable using only CPU even for small-scale training sets. Our experimental results show that DAN/K-DAN outperform the present S-DNNs and also the BP-trained DNNs, including multiplayer perceptron, deep belief network, etc., without data augmentation applied.","","","10.1109/TCYB.2019.2908387","National Research Foundation of Korea NRF grant funded by the Korea Government MSIP; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8694849","Deep analytic network (DAN);face recognition;object recognition;pattern classification;stacking-based deep neural network (S-DNN)","Kernel;Training;Neural networks;Graphics processing units;Principal component analysis;Convolution;Cybernetics","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Generic Improvement to Deep Residual Networks Based on Gradient Flow","V. Santhanam; L. S. Davis","University of Maryland Institute for Advanced Computer Studies (UMIACS), College Park, MD 20742 USA (e-mail: venkai@cs.umd.edu).; University of Maryland Institute for Advanced Computer Studies (UMIACS), College Park, MD 20742 USA.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","10","Preactivation ResNets consistently outperforms the original postactivation ResNets on the CIFAR10/100 classification benchmark. However, these results surprisingly do not carry over to the standard ImageNet benchmark. First, we theoretically analyze this incongruity in terms of how the two variants differ in handling the propagation of gradients. Although identity shortcuts are critical in both variants for improving optimization and performance, we show that postactivation variants enable early layers to receive a diverse dynamic composition of gradients from effectively deeper paths in comparison to preactivation variants, enabling the network to make maximal use of its representational capacity. Second, we show that downsampling projections (while only a few in number) have a significantly detrimental effect on performance. We show that by simply replacing downsampling projections with identitylike dense-reshape shortcuts, the classification results of standard residual architectures such as ResNets, ResNeXts, and SE-Nets improve by up to 1.2% on ImageNet, without any increase in computational complexity (FLOPs).","","","10.1109/TNNLS.2019.2929198","Office of the Director of National Intelligence ODNI Intelligence Advanced Research Projects Activity IARPA through DOI IBC; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8804390","Deep residual networks;dense-reshape;gradient flow;ImageNet-classification;post-activation.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"SRGC-Nets: Sparse Repeated Group Convolutional Neural Networks","Y. Lu; G. Lu; R. Lin; J. Li; D. Zhang","Harbin Institute of Technology (Shenzhen), Shenzhen 518055, China.; Harbin Institute of Technology (Shenzhen), Shenzhen 518055, China (e-mail: luguangm@hit.edu.cn).; Harbin Institute of Technology (Shenzhen), Shenzhen 518055, China.; School of Science and Engineering, The Chinese University of Hong Kong (Shenzhen), Shenzhen 518172, China, and also with the College of Information Science and Technology, University of Science and Technology of China, Hefei 230052, China.; School of Science and Engineering, The Chinese University of Hong Kong (Shenzhen), Shenzhen 518172, China.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","14","Group convolution is widely used in many mobile networks to remove the filter's redundancy from the channel extent. In order to further reduce the redundancy of group convolution, this article proposes a novel repeated group convolutional (RGC) kernel, which has M primary groups, and each primary group includes N tiny groups. In every primary group, the same convolutional kernel is repeated in all the tiny groups. The RGC filter is the first kernel to remove the redundancy from group extent. Based on RGC, a sparse RGC (SRGC) kernel is also introduced in this article, and its corresponding network is called SRGC neural networks (SRGC-Net). The SRGC kernel is the summation of RGC kernel and pointwise group convolutional (PGC) kernel. The number of PGC's groups is M. Accordingly, in each primary group, besides the center locations in all channels, the values of parameters located in other N-1 tiny groups are all zero. Therefore, SRGC can significantly reduce the parameters. Moreover, it can also effectively retrieve spatial and channel-difference features by utilizing RGC and PGC to preserve the richness of produced features. Comparative experiments were performed on the benchmark classification data sets. Compared with the traditional popular networks, SRGC-Nets can perform better with timely reducing the model size and computational complexity. Furthermore, it can also achieve better performances than other latest state-of-the-art mobile networks on most of the databases and effectively decrease the test and training runtime.","","","10.1109/TNNLS.2019.2933665","National Natural Science Foundation of China; Shenzhen Science Technology and Innovation Commission through Shenzhen Fundamental Research Fund; Shenzhen Medical Biometrics Perception and Analysis Engineering Laboratory through the Post Doctoral Science Foundation; Shenzhen Research Institute of Big Data; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8827586","Convolutional neural networks (CNNs);deep learning;group convolution;sparse repeated group convolution (SRGC);SRGC neural networks (SRGC-Nets).","Convolution;Kernel;Redundancy;Convolutional neural networks;Learning systems","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Decision Tree Transfer Boosting","S. Jiang; H. Mao; Z. Ding; Y. Fu","Department of Electrical and Computer Engineering, College of Engineering, Northeastern University, Boston, MA 02115 USA (e-mail: shjiang@ece.neu.edu).; Khoury College of Computer and Information Sciences, Northeastern University, Boston, MA 02115 USA.; Department of Computer, Information and Technology, Indiana University--Purdue University Indianapolis, Indianapolis, IN 46202 USA.; Department of Electrical and Computer Engineering, College of Engineering, Northeastern University, Boston, MA 02115 USA, and also with the Khoury College of Computer and Information Sciences, Northeastern University, Boston, MA 02115 USA.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","13","Instance transfer approaches consider source and target data together during the training process, and borrow examples from the source domain to augment the training data, when there is limited or no label in the target domain. Among them, boosting-based transfer learning methods (e.g., TrAdaBoost) are most widely used. When dealing with more complex data, we may consider the more complex hypotheses (e.g., a decision tree with deeper layers). However, with the fixed and high complexity of the hypotheses, TrAdaBoost and its variants may face the overfitting problems. Even worse, in the transfer learning scenario, a decision tree with deep layers may overfit different distribution data in the source domain. In this paper, we propose a new instance transfer learning method, i.e., Deep Decision Tree Transfer Boosting (DTrBoost), whose weights are learned and assigned to base learners by minimizing the data-dependent learning bounds across both source and target domains in terms of the Rademacher complexities. This guarantees that we can learn decision trees with deep layers without overfitting. The theorem proof and experimental results indicate the effectiveness of our proposed method.","","","10.1109/TNNLS.2019.2901273","NSF IIS Award; US Army Research Office Award; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8674759","Decision tree;deep boosting (DeepBoost);instance transfer learning;transfer boosting.","Decision trees;Boosting;Complexity theory;Task analysis;Training data;Training","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Massive-scale Aesthetic Communities Learning using a Noise-tolerant Deep Architecture","L. Zhang; Y. Yao; X. Ju","Computer Science, Zhejiang Unversity, Hangzhou China 310027 (e-mail: zglumg@gmail.com); College of Computer Sciences, Zhejiang University, Hangzhou China 310027 (e-mail: yiyangyao1778@126.com); College of Computer Sciences, Zhejiang University, Hangzhou China (e-mail: xmju@sei.ecnu.edu.cn)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","Accurately categorizing million-scale Internet users (\textit{e.g.}, Flickr or Google Picasa) into multiple communities based on their aesthetic tastes is an indispensable technique in machine learning and multimedia. It can facilitate a series of applications, such as fashion recommendation and 3D non-realistic photo rendering. Conventional methods cannot handle this task appropriately because of the inherent contaminated image labels, which are produced by auxiliary image label predictors. In this work, we propose a noise-tolerant deep architecture which optimally encodes stable templates discovered from a collection of images with contaminated semantic labels. Specifically, we first construct a semantic space by encoding image labels using manifold embedding. Afterward, we observe that in the semantic space, the distribution of superpixels from images with the same label remains stable, regardless of the noises from image labels. According to this observation, a probabilistic generative model (Hidden Stable Analysis) is proposed to learn the stable templates toward each image label. To globally represent the composition of a user's images, a deep aggregation network is developed which statistically concatenates the CNN features learned from all its generated stable templates. Subsequently, an affinity graph is built where the aesthetic difference between users is determined by their deep features. Finally, we employ a dense subgraph mining algorithm which efficiently discovers the communities toward each aesthetic style. Experiments on an million-scale image set (> 1.4 million) compiled from Flickr have demonstrated the effectiveness of our method. Additionally, empirical study on the 33 SIFT-flow categories have shown that the detected stable templates maintain almost unchanged under nearly 32% contaminated image labels.","","","10.1109/TMM.2019.2955240","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8910462","Massive-scale;Aesthetic community;Contaminated;Stable templates;Aggregation network","Semantics;Visualization;Computer architecture;Clustering algorithms;Deep learning;Manifolds;Flickr","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Learning Neural Encoders for Motor Cortex","K. Liang; J. Kao","Electrical and Computer Engineering, University of California Los Angeles, 8783 Los Angeles, California United States (e-mail: kenfuliang@ucla.edu); Electrical and Computer Engineering, University of California Los Angeles, 8783 Los Angeles, California United States (e-mail: kao@seas.ucla.edu)","IEEE Transactions on Biomedical Engineering","","2019","PP","99","1","1","Intracortical brain-machine interfaces (BMIs) transform neural activity into control signals to drive a prosthesis or communication device, such as a robotic arm or computer cursor. To be clinically viable, BMI decoders must achieve high accuracy and robustness. Optimizing these decoders is expensive, traditionally requiring animal or human experiments spanning months to years. This is because BMIs are closed-loop systems, where the user updates his or her motor commands in response to an imperfectly decoded output. Decoder optimization using previously collected “offline” data will therefore not capture this closed-loop response. An alternative approach to significantly accelerate decoder optimization is to use a closed-loop experimental simulator. In simulation, motor cortical neural population activity is synthetically generated from kinematics, and subsequently used for non-invasive, closed-loop experiments. A key component of this system is the neural encoder, which synthetically generates neural population activity. Prior encoder models, based on velocity tuning models, fail to capture dynamic features in the neural population activity and reproduce heterogeneity in neuron peri-stimulus time histograms (PSTHs). To overcome these limitations, we use deep-learning neural encoders to generate synthetic neural population activity. We find these models significantly outperform tuning models in reproducing PSTH variability, dynamics in neural populations, and neural decoding results in “offline” data. We also find that deep learning encoding models better reproduce closed-loop experimental data. We anticipate these deep-learning encoding models will substantially improve simulators for BMIs, enabling faster evaluation, optimization, and characterization of BMI decoder algorithms.","","","10.1109/TBME.2019.2955722","UCLA Computational Medicine Amazon Web Services; UCLA Hellman Fellowship; Nvidia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8911512","","Decoding;Sociology;Statistics;Neural activity;Training;Deep learning;Animals","","","","","","","","","","IEEE","IEEE Early Access Articles"
"DeepVM: RNN-based Vehicle Mobility Prediction to Support Intelligent Vehicle Applications","W. Liu; Y. Shoji","Social-ICT Innovation Laboratory, National Institute of Information and Communications, Koganei, Tokyo Japan 1850011 (e-mail: wei_liu@nict.go.jp); National Institute of Information and Communications Technology, Tokyo Japan 184-8795 (e-mail: shoji@nict.go.jp)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","The recent advances in vehicle industry and vehicle-to-everything communications are creating a huge potential market of intelligent vehicle applications, and exploiting vehicle mobility is of great importance in this field. Hence, this paper proposes a novel vehicle mobility prediction algorithm to support intelligent vehicle applications. First, a theoretical analysis is given to quantitatively reveal the predictability of vehicle mobility. Based on the knowledge earned from theoretical analysis, a deep recurrent neural network (RNN)-based algorithm called DeepVM is proposed to predict vehicle mobility in a future period of several or tens of minutes. Comprehensive evaluations have been carried out based on the real taxi mobility data in Tokyo, Japan. The results have not only proved the correctness of our theoretical analysis, but also validated that DeepVM can significantly improve the quality of vehicle mobility prediction compared with other state-of-art algorithms.","","","10.1109/TII.2019.2936507","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8809218","vehicle mobility;vehicle-to-everything (V2X);recurrent neural network;deep learning","Prediction algorithms;Sensors;Public transportation;Vehicle-to-everything;Urban areas;Deep learning","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Deep Portrait Image Completion and Extrapolation","X. Wu; R. Li; F. Zhang; J. Liu; J. Wang; A. Shamir; S. Hu","Tsinghua University, Beijing.; Tsinghua University, Beijing.; School of Engineering and Computer Science, Victoria University of Wellington, New Zealand.; Tsinghua University, Beijing.; Megvii(Face++) Research USA.; Efi Arazi school of Computer Science at the Interdisciplinary Center, Israel.; Tsinghua University, Beijing.","IEEE Transactions on Image Processing","","2019","PP","99","1","1","General image completion and extrapolation methods often fail on portrait images where parts of the human body need to be recovered -a task that requires accurate human body structure and appearance synthesis. We present a twostage deep learning framework for tackling this problem. In the first stage, given a portrait image with an incomplete human body, we extract a complete, coherent human body structure through a human parsing network, which focuses on structure recovery inside the unknown region with the help of full-body pose estimation. In the second stage, we use an image completion network to fill the unknown region, guided by the structure map recovered in the first stage. For realistic synthesis the completion network is trained with both perceptual loss and conditional adversarial loss.We further propose a face refinement network to improve the fidelity of the synthesized face region. We evaluate our method on publicly-available portrait image datasets, and show that it outperforms other state-of-the-art general image completion methods. Our method enables new portrait image editing applications such as occlusion removal and portrait extrapolation. We further show that the proposed general learning framework can be applied to other types of images, e.g. animal images.","","","10.1109/TIP.2019.2945866","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8866746","image completion;portrait extrapolation;human parsing;deep learning","Face;Extrapolation;Pose estimation;Deep learning;Semantics;Heating systems;Three-dimensional displays","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Learning Diffuse Optical Tomography","J. Yoo; S. Sabir; D. Heo; K. H. Kim; A. Wahab; Y. Choi; S. Lee; E. Y. Chae; H. H. Kim; Y. M. Bae; Y. Choi; S. Cho; J. C. Ye","Korea Advanced Institute of Science and Technology (KAIST), Daejeon 34141, Republic of Korea and Clova AI Research, NAVER Corporation, Naver Green Factory, 6 Buljeong-ro, Bundang-gu, 13561, Republic of Korea.; Korea Advanced Institute of Science and Technology (KAIST), Daejeon 34141, Republic of Korea.; Korea Electrotechnology Research Institute (KERI), 111, Hanggaul-ro, Sangnok-gu, Ansan 15588, Republic of Korea.; Korea Electrotechnology Research Institute (KERI), 111, Hanggaul-ro, Sangnok-gu, Ansan 15588, Republic of Korea.; Korea Advanced Institute of Science and Technology (KAIST), Daejeon 34141, Republic of Korea and Department of Mathematics, University of Education, Attock Campus 43600, Attock, Pakistan.; Medical Research Institute, Gangneung Asan Hospital, 38, Bangdong-gil, Sacheon-myeon, Gangneung 210-711, Republic of Korea.; Asan Medical Center, University of Ulsan College of Medicine, 88, Olympic-ro 43-gil, Songpa-gu, Seoul 05505, Republic of Korea.; Asan Medical Center, University of Ulsan College of Medicine, 88, Olympic-ro 43-gil, Songpa-gu, Seoul 05505, Republic of Korea.; Asan Medical Center, University of Ulsan College of Medicine, 88, Olympic-ro 43-gil, Songpa-gu, Seoul 05505, Republic of Korea.; Korea Electrotechnology Research Institute (KERI), 111, Hanggaul-ro, Sangnok-gu, Ansan 15588, Republic of Korea.; Korea Electrotechnology Research Institute (KERI), 111, Hanggaul-ro, Sangnok-gu, Ansan 15588, Republic of Korea.; Korea Advanced Institute of Science and Technology (KAIST), Daejeon 34141, Republic of Korea.; Korea Advanced Institute of Science and Technology (KAIST), Daejeon 34141, Republic of Korea.","IEEE Transactions on Medical Imaging","","2019","PP","99","1","1","Diffuse optical tomography (DOT) has been investigated as an alternative imaging modality for breast cancer detection thanks to its excellent contrast to hemoglobin oxidization level. However, due to the complicated non-linear photon scattering physics and ill-posedness, the conventional reconstruction algorithms are sensitive to imaging parameters such as boundary conditions. To address this, here we propose a novel deep learning approach that learns non-linear photon scattering physics and obtains an accurate three dimensional (3D) distribution of optical anomalies. In contrast to the traditional black-box deep learning approaches, our deep network is designed to invert the Lippman-Schwinger integral equation using the recent mathematical theory of deep convolutional framelets. As an example of clinical relevance, we applied the method to our prototype DOT system. We show that our deep neural network, trained with only simulation data, can accurately recover the location of anomalies within biomimetic phantoms and live animals without the use of an exogenous contrast agent.","","","10.1109/TMI.2019.2936522","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8807273","Deep learning;Diffuse Optical Tomography;framelet denoising;convolutional neural network (CNN);convolution framelets","Optical imaging;Nonlinear optics;Optical scattering;Mathematical model;Neural networks;Photonics","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Thick Clouds Removal From Multitemporal ZY-3 Satellite Images Using Deep Learning","Y. Chen; L. Tang; X. Yang; R. Fan; M. Bilal; Q. Li","State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan 430079, China (e-mail: cy1017@whu.edu.cn).; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan 430079, China (e-mail: tll@whu.edu.cn).; School of Geography and Information Engineering, China University of Geosciences, Wuhan 430074, China (e-mail: yangxue@cug.edu.cn).; Chinese Academy of Surveying and Mapping, Beijing 100830, China (e-mail: fanrsh@casm.ac.cn).; School of Marine Sciences, Nanjing University of Information Science and Technology, Nanjing 210044, China (e-mail: muhammad.bilal@connect.polyu.hk).; Shenzhen Key Laboratory of Spatial Smart Sensing and Services, Shenzhen University, Shenzhen 518060, China (e-mail: liqq@szu.edu.cn).","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2019","PP","99","1","11","The presence of clouds greatly reduces the ground information of high-resolution satellite data. In order to improve the utilization of high-resolution satellite data, this article presents a cloud removal method based on deep learning. This is the first end-to-end architecture that has great potential to detect and remove clouds from high-resolution satellite data. For cloud detection, a convolution neural network (CNN) architecture is used to detect them. For cloud removal, the content generation network, the texture generation network, and the spectrum generation network based on traditional CNN are proposed. The proposed CNN architecture can use multisource data (content, texture, and spectral) as an input of the unified framework. The results of both the simulated and real image experiments demonstrate that the proposed method is robust and can effectively remove thick clouds, thin clouds, and cloud shadows. In addition, compared with some existing methods, the proposed method can recover land cover information accurately.","","","10.1109/JSTARS.2019.2954130","National Key Research and Development Plan of China; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8922793","Cloud detection;cloud removal;convolution neural networks (CNNs);deep learning","Clouds;Remote sensing;Satellites;Machine learning;Convolution;Neural networks;Training","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Two-Timescale Voltage Control in Distribution Grids Using Deep Reinforcement Learning","Q. Yang; G. Wang; A. Sadeghi; G. B. Giannakis; J. Sun","State Key Lab of Intelligent Control and Decision of Complex Systems, School of Automation, Beijing Institute of Technology, Beijing 100081, China.; Department of Electrical and Computer Engineering, University of Minnesota, Minneapolis, MN 55455, USA.; Department of Electrical and Computer Engineering, University of Minnesota, Minneapolis, MN 55455, USA.; Department of Electrical and Computer Engineering, University of Minnesota, Minneapolis, MN 55455, USA.; State Key Lab of Intelligent Control and Decision of Complex Systems, School of Automation, Beijing Institute of Technology, Beijing 100081, China.","IEEE Transactions on Smart Grid","","2019","PP","99","1","1","Modern distribution grids are currently being challenged by frequent and sizable voltage fluctuations, due mainly to the increasing deployment of electric vehicles and renewable generators. Existing approaches to maintaining bus voltage magnitudes within the desired region can cope with either traditional utility-owned devices (e.g., shunt capacitors), or contemporary smart inverters that come with distributed generation units (e.g., photovoltaic plants). The discrete on-off commitment of capacitor units is often configured on an hourly or daily basis, yet smart inverters can be controlled within milliseconds, thus challenging joint control of these two types of assets. In this context, a novel two-timescale voltage regulation scheme is developed for distribution grids by judiciously coupling data-driven with physics-based optimization. On a faster timescale, say every second, the optimal setpoints of smart inverters are obtained by minimizing instantaneous bus voltage deviations from their nominal values, based on either the exact alternating current power flow model or a linear approximant of it; whereas, on the slower timescale (e.g., every hour), shunt capacitors are configured to minimize the long-term discounted voltage deviations using a deep reinforcement learning algorithm. Extensive numerical tests on a real-world 47-bus distribution network as well as the IEEE 123-bus test feeder using real data corroborate the effectiveness of the novel scheme.","","","10.1109/TSG.2019.2951769","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8892476","Two timescales;voltage control;inverters;capacitors;deep reinforcement learning.","Inverters;Capacitors;Voltage control;Reactive power;Reinforcement learning;Solar power generation;Optimization","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Image-based Prognostics Using Deep Learning Approach","G. Aydemir; K. Paynabar","Electrical and Electronics Engineering Department, Bogazici University, 52949 Istanbul Turkey 34342 (e-mail: gurkan.aydemir@boun.edu.tr); Industrial and Systems Engineering, Georgia Institute of Technology College of Engineering, 115724 Atlanta, Georgia United States 30332-0360 (e-mail: kamran.paynabar@isye.gatech.edu)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","This paper proposes two methods based on deep learning for estimating time-to-failure (TTF) of an industrial system using its degradation image. This provides an effective tool for predictive maintenance practitioners toward digitization of maintenance processes in Industry 4.0 transformation. Both methods utilize the Long-Short Term Memory (LSTM) networks for capturing temporal information. First methodology consists of two convolutional layers preceding a single LSTM layer to extract compact information from the individual images and rescue LSTM network from curse of dimensionality. Then, LSTM layer estimates TTF value from the extracted features. In the second approach, dimension of the individual images are decreased by a fully connected neural network which is trained as an autoencoder. A separate LSTM network is trained and run over this lower dimensional space. The strength of suggested architectures is shown using simulation data and a data set of infrared image streams collected from rotating machinery. The performance comparison of proposed methods and other methods is also provided.","","","10.1109/TII.2019.2956220","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8915753","Industry 4.0;deep learning;image prognostics;predictive maintenance;remaining useful life (RUL) estimation","Streaming media;Feature extraction;Convolution;Degradation;Machine learning;Data mining;Neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Privacy-Preserving Framework based Blockchain and Deep Learning for Protecting Smart Power Networks","M. Keshk; B. Turnbull; N. Moustafa; D. Vatsalan; K. R. Choo","Palmetston, Australian Capital Territory Australia 2913 (e-mail: marwa.hassan@student.adfa.edu.au); University of New South Wales Canberra at ADFA, 155101 Canberra, Australian Capital Territory Australia 2610 (e-mail: benjamin.turnbull@unsw.edu.au); UNSW Canberra, 155101 Canberra, Australian Capital Territory Australia 2612 (e-mail: nour.moustafa@unsw.edu.au); Data61, 170512 Eveleigh, New South Wales Australia 2015 (e-mail: dinusha.vatsalan@data61.csiro.au); Department of Information Systems and Cyber Security, University of Texas at San Antonio, 12346 San Antonio, Texas United States 78249-1644 (e-mail: Raymond.Choo@fulbrightmail.org)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","his paper proposes a privacy-preserving framework for accomplishing the privacy and security aspects of smart power networks. The framework includes two main modules: a two-level privacy module and an anomaly detection module. In the two-level privacy module, an enhanced Proof of Work (ePoW) technique based blockchain is proposed for verifying data integrity and avoiding data poisoning attacks, and a Variational AutoEncoder (VAE) is simultaneously applied for transforming data into an encoded format for preventing inference attacks. In the anomaly detection module, a Long Short Term Memory (LSTM) deep learning technique is used for training and validating the outputs of the two-level privacy module using two public datasets. The results highlight that the proposed framework can efficiently protect data of smart power networks and discover abnormal behaviours compared with several state-of-the-art techniques.","","","10.1109/TII.2019.2957140","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8918446","Privacy preservation;blockchain;Proof-of-Work (PoW);deep learning;anomaly detection;CPS","Data privacy;Machine learning;Power systems;Anomaly detection;Privacy","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Learning for Fall Risk Assessment with Inertial Sensors: Utilizing Domain Knowledge in Spatio-Temporal Gait Parameters","C. Tunca; G. Salur; C. Ersoy","Bogazici Univ, Istanbul Turkey 34342 (e-mail: can.tunca@boun.edu.tr); Movement Disorders & Dementia Clinic, Istanbul Turkey (e-mail: gulustu@yaslihaklaridernegi.org); Computer Engineering, Bogazici University, Istanbul Turkey 34342 (e-mail: ersoy@boun.edu.tr)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","Fall risk assessment is essential to predict and prevent falls in geriatric populations, especially patients with life-long conditions like neurological disorders. Inertial sensor-based pervasive gait analysis systems have become viable means to facilitate continuous fall risk assessment in non-hospital settings. However, a gait analysis system is not sufficient to detect the characteristics leading to increased fall risk, and powerful inference models are required to detect the underlying factors specific to fall risk. Machine learning models and especially the recently proposed deep learning methods offer the needed predictive power. Deep neural networks have the potential to produce models that can operate directly on the raw data, thus alleviating the need for feature engineering. However, the domain knowledge inherent in the well-established spatio-temporal gait parameters are still valuable to help a model achieve high inference accuracies. In this study, we explore deep learning methods, specifically long short-term memory (LSTM) neural networks, for the problem of fall risk assessment. We utilize sequences of spatio-temporal gait parameters extracted by an inertial sensor-based gait analysis system as input features. To quantify the performance of the proposed approach, we compare it with more traditional machine learning methods. The proposed LSTM model, trained with a gait dataset collected from 60 neurological disorder patients, achieves a superior classification accuracy of 92.1% on a separate test dataset collected from 16 patients. This study serves as one of the first attempts to employ deep learning approaches in this domain and the results demonstrate their potential.","","","10.1109/JBHI.2019.2958879","Turkish Directorate of Strategy and Budget TAM Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8930949","Deep learning;fall prediction;fall risk assessment;gait analysis;inertial sensors;long short-term memory neural networks;spatio-temporal gait parameters","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Age from faces in the deep learning revolution","V. Carletti; A. Greco; G. Percannella; M. Vento","DIEM, Dipartimento di Ingegneria dell'Informazione e di Engegneria Elettrica, Fisciano, Italy Italy (e-mail: vcarletti@unisa.it); DIEM, Dipartimento di Ingegneria dell'Informazione e di Engegneria Elettrica, Fisciano, Italy Italy (e-mail: agreco@unisa.it); Dipartimento di Ingegneria dell'Informazione, Ingegneria Elettrica e Matematica Applicata, Università di Salerno, Fisciano, SA Italy 84084 (e-mail: pergen@unisa.it); DIEM, Dipartimento di Ingegneria dell'Informazione e di Engegneria Elettrica, Fisciano, Italy Italy (e-mail: mvento@unisa.it)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Face analysis includes a variety of specific problems as face detection, person identification, gender and ethnicity recognition; in the last two decades, significant research efforts have been devoted to the challenging task of age estimation from faces, as witnessed by the high number of published papers. The explosion of the deep learning paradigm, that is determining a spectacular increasing of the performance, is in the public eye; consequently, the number of approaches based on deep learning is impressively growing and this also happened for age estimation. The exciting results obtained have been recently surveyed on almost all the specific face analysis problems; the only exception stands for age estimation, whose last survey dates back to 2010 and does not include any deep learning based approach to the problem. This paper provides an analysis of the deep methods; these are analysed from different points of view: the network architecture together with the learning procedure, the used datasets, data preprocessing and augmentation, and the exploitation of additional data coming from gender, race and face expression. The review is completed by discussing the results obtained on public datasets, so as the impact of different aspects on system performance, together with still open issues.","","","10.1109/TPAMI.2019.2910522","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8686239","Age estimation;deep learning;face analysis;survey;review","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Towards Edge-Based Deep Learning in Industrial Internet of Things","F. Liang; W. Yu; X. Liu; D. Griffith; N. Golmie","Towson University, USA.; Towson University, USA.; Towson University, USA.; National Institute of Standards and Technology (NIST), USA.; National Institute of Standards and Technology (NIST), USA.","IEEE Internet of Things Journal","","2019","PP","99","1","1","As a typical application of the Internet of Things (IoT), the Industrial Internet of Things (IIoT) connects all the related IoT sensing and actuating devices ubiquitously so that the monitoring and control of numerous industrial systems can be realized. Deep learning, as one viable way to carry out big data-driven modeling and analysis, could be integrated in IIoT systems to aid the automation and intelligence of IIoT systems. As deep learning requires large computation power, it is commonly deployed in cloud servers. Thus, the data collected by IoT devices must be transmitted to the cloud for training process, contributing to network congestion and affecting the IoT network performance as well as the supported applications. To address this issue, in this paper we leverage fog/edge computing paradigm and propose an edge computing-based deep learning model, which utilizes edge computing to migrate the deep learning process from cloud servers to edge nodes, reducing data transmission demands in the IIoT network and mitigating network congestion. Since edge nodes have limited computation ability compared to servers, we design a mechanism to optimize the deep learning model so that its requirements for computational power can be reduced. To evaluate our proposed solution, we design a testbed implemented in the Google cloud and deploy the proposed Convolutional Neural Network (CNN) model, utilizing a real-world IIoT dataset to evaluate our approach1. Our experimental results confirm the effectiveness of our approach, which can not only reduce the network traffic overhead for IIoT, but also maintain the classification accuracy in comparison with several baseline schemes.","","","10.1109/JIOT.2019.2963635","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8948000","Industrial IoT;Edge Computing;Fog Computing;Distributed deep learning.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Scribble based 3D shape segmentation via weakly-supervised learning","Z. Shu; X. Shen; S. Xin; Q. Chang; J. Feng; L. Kavan; L. Liu","School of Computer and Data Engineering, Ningbo Institute of Technology, Zhejiang University, Ningbo, Zhejiang China (e-mail: shuzhenyu@gmail.com); Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hongkong, Hongkong China (e-mail: goodshenxy@gmail.com); School of Computer Science and Technology, Shandong University, 12589 Jinan, Shandong China (e-mail: xinshiqing@163.com); School of Computer and Data Engineering, Ningbo Institute of Technology, Zhejiang University, Ningbo, Zhejiang China (e-mail: cqj1994@foxmail.com); State key laboratory of CAD&CG, Zhejiang University, Hangzhou, Zhejiang China (e-mail: jqfeng@cad.zju.edu.cn); School of Computing, University of Utah, Salt Lake City, Utah United States (e-mail: ladislav.kavan@gmail.com); Department of Mathematics, Zhejiang University, Hangzhou, Zhejiang China 310027 (e-mail: lgliu@ustc.edu.cn)","IEEE Transactions on Visualization and Computer Graphics","","2019","PP","99","1","1","Shape segmentation is a fundamental problem in shape analysis. Previous research shows that prior knowledge helps to improve the segmentation accuracy and quality. However, completely labeling each 3D shape in a large training data set requires a heavy manual workload. In this paper, we propose a novel weakly-supervised algorithm for segmenting 3D shapes using deep learning. Our method jointly propagates information from scribbles to unlabeled faces and learns deep neural network parameters. Therefore, it does not rely on completely labeled training shapes and only needs a really simple and convenient scribble-based partially labeling process, instead of the extremely time-consuming and tedious fully labeling processes. Various experimental results demonstrate the proposed method's superior segmentation performance over the previous unsupervised approaches and comparable segmentation performance to the state-of-the-art fully supervised methods.","","","10.1109/TVCG.2019.2892076","the Open Project Program of the State Key Lab of CAD CG Zhejiang University; Ningbo Leader and Top-notch Talent Training Project; Ningbo Innovative Team: The intelligent big data engineering application for life and health; the Fundamental Research Funds of Shandong University; National Natural Science Foundation of China; National Science Foundation; Natural Science Foundation of Ningbo City; Natural Science Foundation of Zhejiang Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8607113","3D shapes;Segmentation;Scribble;Weakly-supervised;Deep learning","Shape;Three-dimensional displays;Training;Labeling;Training data;Solid modeling;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Inferring Salient Objects from Human Fixations","W. Wang; J. Shen; X. Dong; A. Borji; R. Yang","Statistics Department, University of California Los Angeles, 8783 Los Angeles, California United States 90095 (e-mail: wenguanwang.ai@gmail.com); Computer Science Department, University of California Los Angeles, Los Angeles, California United States 90095 (e-mail: shenjianbingcg@gmail.com); School of Computer Science, Beijing Institute of Technology, Beijing, Beijing China (e-mail: dongxingping@bit.edu.cn); Department of Computer Science, University of Central Florida, Orlando, Florida United States (e-mail: aborji@crcv.ucf.edu); Computer Science, University of Kentucky, Lexington, Kentucky United States 40507 (e-mail: ryang@cs.uky.edu)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Previous research in visual saliency focused on two major types of models namely fixation prediction and salient object detection. The relationship between the two, however, has been less explored. We propose to employ the former model type to identify salient objects. We build a novel Attentive Saliency Network (ASNet) that learns to detect salient objects from fixation maps. The fixation map, derived at the upper network layers, mimics human visual attention mechanisms and captures a high-level understanding of the scene from a global view. Salient object detection is then viewed as fine-grained object-level saliency segmentation and is progressively optimized with the guidance of the fixation map in a top-down manner. ASNet is based on a hierarchy of convLSTMs that offers an efficient recurrent mechanism to sequentially refine the saliency features over multiple steps. Several loss functions, derived from existing saliency evaluation metrics, are introduced for further boosting the performance. Extensive experiments on several challenging datasets show our ASNet outperforms existing methods and is capable of generating accurate segmentation maps with the help of the computed fixation prior. Our work offers a deeper insight into the mechanisms of attention and narrows the gap between salient object detection and fixation prediction.","","","10.1109/TPAMI.2019.2905607","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8668551","Image saliency;salient object detection;fixation prediction;deep learning","Visualization;Object detection;Task analysis;Predictive models;Deep learning;Biological system modeling;Measurement","","","","2","","","","","","IEEE","IEEE Early Access Articles"
"Deep Learning Benchmarks on L1000 Gene Expression Data","M. McDermott; J. Wang; W. N. Zhao; S. D. Sheridan; P. Szolovits; I. Kohane; S. J. Haggarty; R. H. Perlis","CSAIL, Massachusetts Institute of Technology, 2167 Cambridge, Massachusetts United States (e-mail: mmd@mit.edu); Center for Quantitative Health, Massachusetts General Hospital, Boston, Massachusetts United States (e-mail: jennifer.wang@mgh.harvard.edu); Chemical Neurobiology Laboratory, Massachusetts General Hospital, Boston, Massachusetts United States (e-mail: wnzhao@mgh.harvard.edu); Center for Quantitative Health, Massachusetts General Hospital, Boston, Massachusetts United States (e-mail: ssheridan2@partners.org); CSAIL, Massachusetts Institute of Technology, 2167 Cambridge, Massachusetts United States (e-mail: psz@mit.edu); Department of Biomedical Informatics, Harvard University, Cambridge, Massachusetts United States (e-mail: isaac_kohane@harvard.edu); Chemical Neurobiology Laboratory, Massachusetts General Hospital, Boston, Massachusetts United States (e-mail: shaggarty@mgh.harvard.edu); Center for Quantitative Health, Massachusetts General Hospital, Boston, Massachusetts United States (e-mail: rperlis@mgh.harvard.edu)","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2019","PP","99","1","1","Gene expression data can offer deep, physiological insights beyond the static coding of the genome alone. We believe that realizing this potential requires specialized, high-capacity machine learning methods capable of using underlying biological structure, but the development of such models is hampered by the lack of published benchmark tasks and well characterized baselines.","","","10.1109/TCBB.2019.2910061","National Human Genome Research Institute; National Institute of Mental Health; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8686113","Deep Learning;Gene Expression Data;Benchmarks;Machine Learning;Model Development","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Reinforcement Learning Approaches for Content Caching in Cache-Enabled D2D Networks","L. Li; Y. Xu; J. Yin; W. Liang; X. Li; W. Chen; Z. Han","School of Electronics and Information, Northwestern Polytechnical University, Xi’an 710129 China.; School of Electronics and Information, Northwestern Polytechnical University, Xi’an 710129 China.; Science and Technology on Electronic Information Control Laboratory, Chengdu 610036 China.; School of Electronics and Information, Northwestern Polytechnical University, Xi’an 710129 China.; School of Electronics and Information, Northwestern Polytechnical University, Xi’an 710129 China.; Department of Electronic Engineering and Tsinghua National Laboratory for Information Science and Technology, Tsinghua University, Beijing 100084 China.; University of Houston, Houston, TX 77004 USA, and also with the Department of Computer Science and Engineering, Kyung Hee University, Seoul, South Korea, 446-701.","IEEE Internet of Things Journal","","2019","PP","99","1","1","Internet of Things (IoT) technology suffers from the challenge that rare wireless network resources are difficult to meet the influx of a huge number of terminal devices. Cache-enabled Device-to-Device (D2D) communication technology is expected to relieve network pressure with the facts that the requesting contents can be easily obtained from nearby users. However, how to design an effective caching policy becomes very challenging due to the limited content storage capacity and the uncertainty of user mobility pattern. In this paper, we study the jointly cache content placement and delivery policy for the cache-enabled D2D networks. Specifically, two potential recurrent neural network approaches (the echo state network (ESN) and long-short term memory (LSTM) network) are employed to predict users’ mobility and content popularity, so as to determine which content to cache and where to cache. When the local cache of the user cannot satisfy its own request, the user may consider establishing a D2D link with the neighboring user to implement the content delivery. In order to decide which user will be selected to establish the D2D link, we propose the novel schemes based on deep reinforcement learning to implement the dynamic decision-making and optimization of the content delivery problems, aiming at improving the quality of experience of overall caching system. The simulation results suggest that the cache hit ratio of the system can be well improved by the proposed content placement strategy, and the proposed content delivery approaches can effectively reduce the request content delivery delay and energy consumption.","","","10.1109/JIOT.2019.2951509","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8891760","Caching;prediction;recurrent neural network;deep Q-learning network;actor-critic learning.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Very short-term spatial and temporal wind power forecasting: A deep learning approach","T. Hu; W. Wu; Q. Guo; H. Sun; L. Shi; X. Shen","Tsinghua-Berkeley Shenzhen Institute (TBSI), Shenzhen, Guangdong, China; Department of Electrical Engineering, State Key Laboratory of Power Systems, Tsinghua University, Beijing 100084, China; Department of Electrical Engineering, State Key Laboratory of Power Systems, Tsinghua University, Beijing 100084, China; Department of Electrical Engineering, State Key Laboratory of Power Systems, Tsinghua University, Beijing 100084, China; Graduate School at Shenzhen, Tsinghua University, Shenzhen 518055, China; Tsinghua-Berkeley Shenzhen Institute (TBSI), Shenzhen, Guangdong, China","CSEE Journal of Power and Energy Systems","","2019","PP","99","1","10","In power systems that experience high penetration of wind power generation, very short-term wind power forecast is an important prerequisite for look-ahead power dispatch. Conventional univariate wind power forecasting methods at present only utilize individual wind farm historical data. However, studies have shown that forecasting accuracy can be improved by exploring both spatial and temporal correlations among adjacent wind farms. Current research on spatial-temporal wind power forecasting is based on relatively shallow time series models that, to date, have demonstrated unsatisfactory performance. In this paper, a convolution operation is used to capture the spatial and temporal correlations among multiple wind farms. A novel convolution-based spatial-temporal wind power predictor (CSTWPP) is developed. Due to CSTWPP's high nonlinearity and deep architecture, wind power variation features and regularities included in the historical data can be more effectively extracted. Furthermore, the online training of CSTWPP enables incremental learning, which makes it non-stationary and rather accordant with real scenarios. Graphics processing units (GPU) is used to speed up the training process, validating the developed CSTWPP for real-time application. Case studies on 28 adjacent wind farms are conducted to show that the proposed model can achieve superior performance on 5–30 minutes ahead wind power forecasts.","","","10.17775/CSEEJPES.2018.00010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8779794","Convolution neural network;deep learning;incremental learning;short-term wind power forecast;spatial-temporal correlation","Wind power generation;Forecasting;Wind farms;Feature extraction;Wind forecasting;Correlation;Predictive models","","","","","","","","","","CSEE","CSEE Early Access Articles"
"Semi-Supervised Deep Learning Approach for Transportation Mode Identification Using GPS Trajectory Data","S. Dabiri; C. Lu; K. Heaslip; C. K. Reddy","Computer Science-Civil Engineering, Virginia Tech, Blacksburg, Virginia United States (e-mail: sina@vt.edu); Computer Science, Virginia Tech, Falls Church, Virginia United States 22043 (e-mail: ctlu@vt.edu); Civil Engineering, Virginia Polytechnic Institute and State University, 1757 Blacksburg, Virginia United States (e-mail: kheaslip@vt.edu); Computer Science, Virginia Tech, Arlington, Virginia United States (e-mail: reddy@cs.vt.edu)","IEEE Transactions on Knowledge and Data Engineering","","2019","PP","99","1","1","Identification of travelers' transportation modes is a fundamental step for various problems that arise in the domain of transportation such as travel demand analysis. In this study, we aim to identify users' transportation modes purely based on their GPS trajectories. A majority of studies have proposed mode detection models based on hand-crafted features using only labeled GPS trajectories. To address such shortcomings, we propose a deep SEmi-Supervised Convolutional Autoencoder (SECA) architecture that can not only automatically extract relevant features from GPS tracks but also exploit useful information in unlabeled data. The SECA integrates a convolutional-deconvolutional autoencoder and a convolutional neural network into a unified framework to concurrently perform supervised and unsupervised learning. The two components are simultaneously trained using both labeled and unlabeled GPS trajectories, which have already been converted into an efficient representation for the convolutional operation. An optimum schedule for varying the balancing parameters between reconstruction and classification errors are also implemented. Our experimental results demonstrate the superiority of the proposed model, the new representation for GPS trajectories, the hyperparameter schedule, and the model configuration over the state-of-the-art semi-supervised and supervised methods and alternative settings with respect to metrics such as accuracy and F-measure.","","","10.1109/TKDE.2019.2896985","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8632766","Deep learning;semi-supervised learning;convolutional neural network;convolutional autoencoder;GPS trajectory data;trip segmentation, transportation mode identification","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Incremental Learning in Deep Convolutional Neural Networks Using Partial Network Sharing","S. S. Sarwar; A. Ankit; K. Roy","Nanoelectronics Research Laboratory, Purdue University, School of Electrical and Computer Engineering, West Lafayette, IN, United States.; Nanoelectronics Research Laboratory, Purdue University, School of Electrical and Computer Engineering, West Lafayette, IN, United States.; Nanoelectronics Research Laboratory, Purdue University, School of Electrical and Computer Engineering, West Lafayette, IN, United States.","IEEE Access","","2019","PP","99","1","1","Deep convolutional neural network (DCNN) based supervised learning is a widely practiced approach for large-scale image classification. However, retraining these large networks to accommodate new, previously unseen data demands high computational time and energy requirements. Also, previously seen training samples may not be available at the time of retraining. We propose an efficient training methodology and incrementally growing DCNN to learn new tasks while sharing part of the base network. Our proposed methodology is inspired by transfer learning techniques, although it does not forget previously learned tasks. An updated network, for learning new set of classes, is formed using previously learned convolutional layers (shared from initial part of base network) with addition of few newly added convolutional kernels included in the later layers of the network. We employed a ‘clone-and-branch’ technique with calibration, which allows the network to learn new tasks (containing classes with similar features as old tasks) one after another without any performance loss in old tasks. We evaluated the proposed scheme on several recognition applications. The classification accuracy achieved by our approach is comparable to the regular incremental learning approach (where networks are updated with new training samples only, without any network sharing), while achieving energy efficiency, reduction in storage requirements, memory access and training time.","","","10.1109/ACCESS.2019.2963056","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8945358","Incremental learning;Catastrophic forgetting;Lifelong learning;Energy-efficient learning;Network sharing","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Multitask Learning of Height and Semantics From Aerial Images","M. Carvalho; B. Le Saux; P. Trouvé-Peloux; F. Champagnat; A. Almansa","DTIS, ONERA, Université Paris-Saclay, 91123 Palaiseau, France.; DTIS, ONERA, Université Paris-Saclay, 91123 Palaiseau, France (e-mail: bertrand.le_saux@onera.fr).; DTIS, ONERA, Université Paris-Saclay, 91123 Palaiseau, France.; DTIS, ONERA, Université Paris-Saclay, 91123 Palaiseau, France.; MAP5, Université Paris Descartes, 75006 Paris, France","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","Aerial or satellite imagery is a great source for land surface analysis, which might yield land-use maps or elevation models. In this letter, we present a neural network framework for learning semantics and local height together. We show how this joint multitask learning benefits to each task on the large data set of the 2018 Data Fusion Contest. Moreover, our framework also yields an uncertainty map that allows assessing the prediction of the model. Code is available at https://github.com/marcelampc/mtl_aerial_images","","","10.1109/LGRS.2019.2947783","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8891800","Aerial imagery;deep learning;multitask learning;neural networks;semantic segmentation;single view depth estimation.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Ensemble Capsule Network for Intelligent Compound Fault Diagnosis Using Multisensory Data","R. Huang; J. Li; W. Li; L. Cui","South China University of Technology, Guangzhou 510640, China.; South China University of Technology, Guangzhou 510640, China.; South China University of Technology, Guangzhou 510640, China.; Beijing Engineering Research Center of Precision Measurement Technology and Instruments, Beijing University of Technology, Beijing 100124, China.","IEEE Transactions on Instrumentation and Measurement","","2019","PP","99","1","1","With the manufacturing industry stepping into the emerging new era of big-data and intelligence, the amount of data collected from perception and monitoring systems with multiple smart sensors has increased tremendously. Such huge amount of multisensory data may not only power many aspects of fault diagnosis, but also bring great opportunities and challenges in modern manufacturing industry. In addition, with respect to intelligent fault diagnosis for machinery, few researches have been focused on the compound fault diagnosis under big-data circumstance. Therefore, a novel intelligent compound fault decoupling method based on deep capsule network and ensemble learning is developed for the compound fault decoupling and diagnosis using multisensory data. First, a decoupling capsule network (DCN) is constructed as the basic model. Second, taking the full advantage of multisensory data, the DCN model can be pre-trained with multiple sensor data, respectively, which can obtain various pre-trained DCN models. Finally, combining with ensemble learning skill, the pre-trained DCN models are integrated by a combination strategy to obtain the deep ensemble capsule network (DECN) model for intelligent compound fault decoupling and diagnosis. The performance of DECN model is validated by an automobile transmission dataset with two compound faults, and the experimental results illustrate that the DECN model obtains higher diagnosis accuracy and decouples the compound fault correctly.","","","10.1109/TIM.2019.2958010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8924777","Fault diagnosis;capsule network;ensemble learning;multisensory data;compound fault","Compounds;Fault diagnosis;Machinery;Data models;Heuristic algorithms;Machine learning;Convolutional neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"“Are You Playing a Shooter Again?!” Deep Representation Learning for Audio-based Video Game Genre Recognition","S. Amiriparian; N. Cummins; M. Gerczuk; S. Pugachevskiy; S. Ottl; B. Schuller","Chair of Embedded Intelligence for Health Care & Wellbeing, Univeristy of Augsburg, Augsburg Germany (e-mail: shahin.amiriparian@informatik.uni-augsburg.de); Computer Science, Chair of Embedded Intelligence for Health Care and Wellbeing, Augsburg, Bavaria Germany (e-mail: nicholas.cummins@ieee.org); Chair of Embedded Intelligence for Health Care & Wellbeing, Univeristy of Augsburg, Augsburg, Bavaria Germany (e-mail: maurice.gerczuk@informatik.uni-augsburg.de); Chair of Embedded Intelligence for Health Care & Wellbeing, Univeristy of Augsburg, Augsburg Germany (e-mail: sergey.pugachevskiy@informatik.uni-augsburg.de); Chair of Embedded Intelligence for Health Care & Wellbeing, Univeristy of Augsburg, Augsburg Germany (e-mail: sandra.ottl@informatik.uni-augsburg.de); Chair of Embedded Intelligence for Health Care & Wellbeing, Univeristy of Augsburg, Augsburg Germany (e-mail: schuller@tum.de)","IEEE Transactions on Games","","2019","PP","99","1","1","In this paper, we present a novel computer audition task; audio-based video game genre classification. The aim of this study is threefold: 1) to check the feasibility of the proposed task, 2) to introduce a new corpus: the Game Genre by Audio + Multimodal Extracts (G$^{2}$AME), collected entirely from social multimedia, and 3) to compare the efficacy of various acoustic feature spaces to classify the G$^{2}$AME corpus into 6 game genres using a linear support vector machine classifier. For the classification we extract three different feature representations from the game audio files: i) knowledge-based acoustic features, ii) DEEP SPECTRUM features, and iii) quantised DEEP SPECTRUM features using Bag-of-Audio-Words. The DEEP SPECTRUM features are a deep-learning based representation derived from forwarding the visual representations of the audio instances, in particular spectrograms, mel-spectrograms, chromagrams, and their deltas through deep task-independent pre-trained CNNs. Specifically, activations of fully connected layers from three common image classification CNNs, GoogLeNet, AlexNet, and VGG16 are used as feature vectors. Results for the 6-genre classification problem indicate the suitability of our deep learning approach for this task. Our best method achieves an accuracy of up to 66.9% unweighted average recall using 10-fold cross-validation.","","","10.1109/TG.2019.2894532","Seventh Framework Programme; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8620524","game genre classification;deep learning;convolutional neural network;audio classification","Games;Feature extraction;Task analysis;Acoustics;Monitoring;YouTube;Sports","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Deep Transfer Learning Approach to Reducing the Effect of Electrode Shift in EMG Pattern Recognition-based Control","A. Ameri; M. A. Akhaee; E. Scheme; K. Englehart","Department of Biomedical Engineering, Shahid Beheshti University of Medical Sciences, Tehran, Iran.; Department of Electrical Engineering, University of Tehran, Tehran, Iran.; Institute of Biomedical Engineering, University of New Brunswick, Fredericton, Canada.; Institute of Biomedical Engineering, University of New Brunswick, Fredericton, Canada.","IEEE Transactions on Neural Systems and Rehabilitation Engineering","","2019","PP","99","1","1","An important barrier to commercialization of pattern recognition myoelectric control of prostheses is the lack of robustness to confounding factors such as electrode shift, skin impedance variations, and learning effects. To overcome this challenge, a novel supervised adaptation approach based on transfer learning (TL) with convolutional neural networks (CNNs) is proposed which requires only a short training session (a few seconds for each class) to recalibrate the system. TL is proposed as a solution to the problem of insufficient calibration data due to short training times for both classification and regression-based control schemes. This approach was validated for electrode shift of roughly 2.5cm with 13 able-bodied subjects to estimate individual and combined wrist motions. With this method, the original CNN (trained before the shift) was fine-tuned with the calibration data from after shifting. The results show that the proposed technique outperforms training a CNN from scratch (random initialization of weights) or a support vector machine (SVM) using the minimal calibration data. Moreover, it demonstrates superior performance than previous LDA and QDA-based adaptation approaches. As the outcomes confirm, the proposed CNN TL method provides a practical solution for adaptation to external factors, improving the robustness of electromyogram (EMG) pattern recognition systems.","","","10.1109/TNSRE.2019.2962189","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8943097","myoelectric control;EMG;deep learning;transfer learning;convolutional neural network;electrode shift","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Imbalanced Learning for Face Recognition and Attribute Prediction","C. Huang; Y. Li; C. L. Chen; X. Tang","Robotics Institute, Carnegie Mellon University, 6612 Pittsburgh, Pennsylvania United States (e-mail: yach23@gmail.com); Information Engineering, The Chinese University of Hong Kong, Hong Kong, Hong Kong Hong Kong (e-mail: ly015@ie.cuhk.edu.hk); School of Computer Science and Engineering, Singapore, Singapore Singapore (e-mail: ccloy@ntu.edu.sg); Department of Information Engineering, The Chinese University of Hong Kong, Shatin, NT Hong Kong NT (e-mail: xtang@ie.cuhk.edu.hk)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Data for face analysis often exhibit highly-skewed class distribution, i.e., most data belong to a few majority classes, while the minority classes only contain a scarce amount of instances. To mitigate this issue, contemporary deep learning methods typically follow classic strategies such as class re-sampling or cost-sensitive training. In this paper, we conduct extensive and systematic experiments to validate the effectiveness of these classic schemes for representation learning on class-imbalanced data. We further demonstrate that more discriminative deep representation can be learned by enforcing a deep network to maintain inter-cluster margins both within and between classes. This tight constraint effectively reduces the class imbalance inherent in the local data neighborhood, thus carving much more balanced class boundaries locally. We show that it is easy to deploy angular margins between the cluster distributions on a hypersphere manifold. Such learned Cluster-based Large Margin Local Embedding (CLMLE), when combined with a simple k-nearest cluster algorithm, shows significant improvements in accuracy over existing methods on both face recognition and face attribute prediction tasks that exhibit imbalanced class distribution.","","","10.1109/TPAMI.2019.2914680","General Research Fund sponsored by the Research Grants Council of the Hong Kong SAR; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8708977","Imbalanced Learning;Deep Convolutional Neural Networks;Face Recognition;Attribute Prediction","Face;Face recognition;Training;Task analysis;Protocols;Semantics;Image segmentation","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Traffic Graph Convolutional Recurrent Neural Network: A Deep Learning Framework for Network-Scale Traffic Learning and Forecasting","Z. Cui; K. Henrickson; R. Ke; Y. Wang","Department of Civil and Environmental Engineering, University of Washington, Seattle, WA 98195 USA.; INRIX, Inc., Kirkland, WA 98033 USA.; Department of Civil and Environmental Engineering, University of Washington, Seattle, WA 98195 USA.; Department of Civil and Environmental Engineering, University of Washington, Seattle, WA 98195 USA (e-mail: yinhai@uw.edu).","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","12","Traffic forecasting is a particularly challenging application of spatiotemporal forecasting, due to the time-varying traffic patterns and the complicated spatial dependencies on road networks. To address this challenge, we learn the traffic network as a graph and propose a novel deep learning framework, Traffic Graph Convolutional Long Short-Term Memory Neural Network (TGC-LSTM), to learn the interactions between roadways in the traffic network and forecast the network-wide traffic state. We define the traffic graph convolution based on the physical network topology. The relationship between the proposed traffic graph convolution and the spectral graph convolution is also discussed. An L1-norm on graph convolution weights and an L2-norm on graph convolution features are added to the model's loss function to enhance the interpretability of the proposed model. Experimental results show that the proposed model outperforms baseline methods on two real-world traffic state datasets. The visualization of the graph convolution weights indicates that the proposed framework can recognize the most influential road segments in real-world traffic networks.","","","10.1109/TITS.2019.2950416","Pacific Northwest Transportation Consortium PacTrans USDOT University Transportation Center for Federal Region 10; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8917706","Traffic forecasting;spatial-temporal;graph convolution;LSTM;recurrent neural network.","Convolution;Forecasting;Predictive models;Roads;Machine learning;Feature extraction;Artificial neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Model Compression and Inference Speedup of Sum-Product Networks on Tensor Trains","C. Ko; C. Chen; Z. He; Y. Zhang; K. Batselier; N. Wong","Department of Electrical and Electronic Engineering, The University of Hong Kong, Hong Kong.; Department of Electrical and Electronic Engineering, The University of Hong Kong, Hong Kong.; Department of Electrical and Electronic Engineering, The University of Hong Kong, Hong Kong.; Ming Hsieh Department of Electrical and Computer Engineering, University of South Carolina, Columbia, SC 29208 USA.; Delft Center for Systems and Control, Delft University of Technology, 2628 CD Delft, The Netherlands.; Department of Electrical and Electronic Engineering, The University of Hong Kong, Hong Kong (e-mail: nwong@eee.hku.hk).","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","7","Sum-product networks (SPNs) constitute an emerging class of neural networks with clear probabilistic semantics and superior inference speed over other graphical models. This brief reveals an important connection between SPNs and tensor trains (TTs), leading to a new canonical form which we call tensor SPNs (tSPNs). Specifically, we demonstrate the intimate relationship between a valid SPN and a TT. For the first time, through mapping an SPN onto a tSPN and employing specially customized optimization techniques, we demonstrate improvements up to a factor of 100 on both model compression and inference speedup for various data sets with negligible loss in accuracy.","","","10.1109/TNNLS.2019.2928379","Hong Kong Research Grants Council; University Research Committee of The University of Hong Kong; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8793233","Model compression;sum-product network (SP);tensor train (TT).","Computational modeling;Brain modeling;Semantics;Probabilistic logic;Learning systems;Biological neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Riemannian Curvature of Deep Neural Networks","P. Kaul; B. Lall","Department of Electrical Engineering, IIT Delhi, New Delhi 110016, India (e-mail: eez157544@ee.iitd.ac.in).; Department of Electrical Engineering, IIT Delhi, New Delhi 110016, India.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","7","We analyze deep neural networks using the theory of Riemannian geometry and curvature. The objective is to gain insight into how Riemannian geometry can characterize and predict the trained behavior of neural networks. We define a method for calculating Riemann and Ricci curvature tensors, and Ricci scalar curvature values for a trained neural net, in such a way that the output classifier softmax values are related to the input transformations, through the curvature equations. We also measure these curvature tensors experimentally for different networks which are pretrained with stochastic gradient descent and offer a way of visualizing and understanding the measurements to gain insight into the effect curvature has on behavior the neural networks locally, and possibly predict their behavior for different transformations of the test data. We also analyze the effect of variation in depth of the neural networks as well as how it behaves for different choices of data set.","","","10.1109/TNNLS.2019.2919705","Bharti School of Telecommunication Technology and Management IIT Delhi; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8746812","Curvature;deep learning;machine learning;neural networks;Riemannian geometry.","Neural networks;Manifolds;Measurement;Geometry;Mathematical model;Indexes","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Metric Learning-Based Feature Embedding for Hyperspectral Image Classification","B. Deng; S. Jia; D. Shi","School of Electronic and Information Engineering, South China University of Technology, Guangzhou 510641, China.; Guangdong Laboratory of Artificial Intelligence and Digital Economy (SZ), Shenzhen University, Shenzhen 518060, China, with the SZU and Shenzhen Institute of Artificial Intelligence and Robotics for Society, Shenzhen University, Shenzhen 518060, China, and also with the College of Computer Science and Software Engineering, Shenzhen University, Shenzhen 518060, China (e-mail: senjia@szu.edu.cn).; College of Computer Science and Software Engineering, Shenzhen University, Shenzhen 518060, China.","IEEE Transactions on Geoscience and Remote Sensing","","2019","PP","99","1","14","Learning from a limited number of labeled samples (pixels) remains a key challenge in the hyperspectral image (HSI) classification. To address this issue, we propose a deep metric learning-based feature embedding model, which can meet the tasks both for same- and cross-scene HSI classifications. In the first task, when only a few labeled samples are available, we employ ideas from metric learning based on deep embedding features and make a similarity learning between pairs of samples. In this case, the proposed model can learn well to compare whether two samples belong to the same class. In another task, when an HSI image (target scene) that needs to be classified is not labeled at all, the embedding model can learn from another similar HSI image (source scene) with sufficient labeled samples and then transfer to the target model by using an unsupervised domain adaptation technique, which not only employs the adversarial approach to make the embedding features from the source and target samples indistinguishable but also encourages the target scene's embeddings to form similar clusters with the source scene one. After the domain adaptation between the HSIs of the two scenes is finished, any traditional HSI classifier can be used. In a simple manner, the nearest neighbor (NN) algorithm is selected as the classifier for the classification tasks throughout this article. The experimental results from a series of popular HSIs demonstrate the advantages of the proposed model both in the same- and cross-scene classification tasks.","","","10.1109/TGRS.2019.2946318","National Natural Science Foundation of China; Program for Guangdong Introducing Innovative and Enterpreneurial Teams; Shenzhen Scientific Research and Development Funding Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8887497","Cross-scene classification;deep metric learning;domain adaptation;hyperspectral image (HSI);small sample set (3S) classification.","Measurement;Training;Task analysis;Adaptation models;Feature extraction;Hyperspectral imaging","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Two-Stream Deep Hashing With Class-Specific Centers for Supervised Image Search","C. Deng; E. Yang; T. Liu; D. Tao","School of Electronic Engineering, Xidian University, Xi'an 710071, China.; School of Electronic Engineering, Xidian University, Xi'an 710071, China (e-mail: ekyang@stu.xidian.edu.cn).; UBTECH Sydney Artificial Intelligence Centre, Faculty of Engineering, University of Sydney, Darlington, NSW 2008, Australia, and also with the School of Computer Science, Faculty of Engineering, University of Sydney, Darlington, NSW 2008, Australia.; UBTECH Sydney Artificial Intelligence Centre, Faculty of Engineering, University of Sydney, Darlington, NSW 2008, Australia, and also with the School of Computer Science, Faculty of Engineering, University of Sydney, Darlington, NSW 2008, Australia.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","13","Hashing has been widely used for large-scale approximate nearest neighbor search due to its storage and search efficiency. Recent supervised hashing research has shown that deep learning-based methods can significantly outperform nondeep methods. Most existing supervised deep hashing methods exploit supervisory signals to generate similar and dissimilar image pairs for training. However, natural images can have large intraclass and small interclass variations, which may degrade the accuracy of hash codes. To address this problem, we propose a novel two-stream ConvNet architecture, which learns hash codes with class-specific representation centers. Our basic idea is that if we can learn a unified binary representation for each class as a center and encourage hash codes of images to be close to the corresponding centers, the intraclass variation will be greatly reduced. Accordingly, we design a neural network that leverages label information and outputs a unified binary representation for each class. Moreover, we also design an image network to learn hash codes from images and force these hash codes to be close to the corresponding class-specific centers. These two neural networks are then seamlessly incorporated to create a unified, end-to-end trainable framework. Extensive experiments on three popular benchmarks corroborate that our proposed method outperforms current state-of-the-art methods.","","","10.1109/TNNLS.2019.2929068","National Natural Science Foundation of China; Key Research and Development Program The Key Industry Innovation Chain of Shaanxi; National Key Research and Development Program of China; Australian Research Council Projects; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8833511","Deep learning;hashing;nearest neighbor search;two-stream ConvNet.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Real-Time ATC Safety Monitoring Framework Using a Deep Learning Approach","Y. Lin; L. Deng; Z. Chen; X. Wu; J. Zhang; B. Yang","National Key Laboratory of Fundamental Science on Synthetic Vision, Sichuan University, Chengdu 610000, China, and also with the Department of Civil and Environmental Engineering, University of Wisconsin-Madison, Madison, WI 53715 USA.; College of Electronic Engineering, University of Electronic Science and Technology of China, Chengdu 610000, China.; National Key Laboratory of Fundamental Science on Synthetic Vision, Sichuan University, Chengdu 610000, China.; National Key Laboratory of Fundamental Science on Synthetic Vision, Sichuan University, Chengdu 610000, China.; National Key Laboratory of Fundamental Science on Synthetic Vision, Sichuan University, Chengdu 610000, China.; National Key Laboratory of Fundamental Science on Synthetic Vision, Sichuan University, Chengdu 610000, China (e-mail: cdyangbo@163.com).","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","10","A deep learning-based safety monitoring framework for air traffic control (ATC) systems is proposed in this paper to reduce human errors and relieve the controllers' workload by regulating the controlling procedure, eliminating communication misunderstanding, monitoring flight conformance, and detecting potential conflicts. The framework comprises automatic speech recognition (ASR), controlling intent inference (CII), and control safety monitoring (CSM) subsystems. The pipeline of the proposed framework can be described as follows: the ASR subsystem translates the pilot-controller voice communications (PCVCs) into texts, which are then converted to the predefined data structure by the CII subsystem. Three types of air traffic safety measures, including repetition check, flight conformance verification, and potential conflict detection, are finally validated by the CSM subsystem. An improved end-to-end ASR model with convolutional, bidirectional long short-term memory (BLSTM) and fully connected (FC) layers is trained using the connectionist temporal classification loss function. The BLSTM and FC combined CII model is designed to infer the controlling intent and slot filling. A language model is also trained in this subsystem to improve the overall performance of the framework. After converting the PCVCs to ATC data, the CSM subsystem checks the given safety monitoring tasks and sends warnings to the current system. The experimental results show that the proposed ASR model obtains a better performance than that of other approaches, and the tasks in the CII subsystem are fulfilled with a high classification precision. The CSM subsystem is also tested to confirm its safety monitoring function by playing back the data and several simulated instructions. To the best of our knowledge, this is pioneering work in the safety monitoring of flight control by recognizing the PCVCs with deep learning-based methods.","","","10.1109/TITS.2019.2940992","National Natural Science Foundation of China; National Key Scientific Instrument and Equipment Development Projects of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8846596","Automatic speech recognition;pilot-controller voice communications;controlling intent inference;slot filling;control safety monitoring.","Safety;Monitoring;Hidden Markov models;Real-time systems;Task analysis;Neural networks;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Multimodal and multi-output deep learning architectures for the automatic assessment of voice quality using the GRB scale","J. D. Arias-Londono; J. A. Gomez-Garcia; J. I. Godino","Dpt. of Systems Engineering and Computer Science, Universidad de Antioquia, 27983 Medellin, Antioquia Colombia (e-mail: julian.ariasl@udea.edu.co); Escuela Ticnica Superior de Ingenieria y Sistemas de Telecomunicacion, Universidad Politicnica de Madrid, Madrid Spain (e-mail: jorge.gomez.garcia@upm.es); Centre for Biomedical Technology, Universidad Politecnica de Madrid, 16771 Madrid, Comunidad de Madrid Spain (e-mail: Ignacio.godino@upm.es)","IEEE Journal of Selected Topics in Signal Processing","","2019","PP","99","1","1","This paper addresses the automatic assessment of voice quality according to the GRB scale, based on the use of a variety of deep learning architectures for prediction purposes. The proposed architectures are multimodal, because they employ multiples sources of information; and also multi-output, because they simultaneously predict all the traits of the GRB scale. A feature engineering approach is followed, based on the use of deep neural networks and a set of well-established features such as MFCC, perturbation and complexity characteristics. Likewise, a representation learning is considered, using convolutional neural networks feed on modulation spectra extracted from voices. Finally, diverse loss functions are also investigated, including two surrogate ordinal classification, a conventional weighed categorical cross-entropy, and a mean square error function. Experiments are carried out in a dataset containing registers of the sustained phonation of three vowels. The best deep learning architecture provides a relative performance improvement of 6.25% for G, 14.1% for R and 18.1% for B, in comparison with recently published results using the same dataset.","","","10.1109/JSTSP.2019.2956410","Ministry of Economy and Competitiveness of Spain; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8917580","Automatic voice quality analysis;Perceptual voice assessment;GRB scale;Deep Neural Networks","Feature extraction;Mel frequency cepstral coefficient;Machine learning;Neural networks;Perturbation methods;Complexity theory;Correlation","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Tree-Based Deep Networks for Edge Devices","G. Muhammad; M. S. Hossain; A. Yassine","King Saud University College of Computer and Information Sciences, 48148 Riyadh Saudi Arabia 11543 (e-mail: ghulam@ksu.edu.sa); King Saud University, Riyadh Saudi Arabia 11543 (e-mail: mshossain@ksu.edu.sa); Department of Software Engineering, Lakehead University Faculty of Engineering, 157773 Thunder Bay, Ontario Canada P7B 5E1 (e-mail: ayassine@lakeheadu.ca)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","This paper proposes a tree-based deep model for effective load distribution to edge devices without much loss of accuracy. The input image is divided into groups of volumes and each volume is passed through a tree structure. The tree structure has many branches and levels, each of which is represented by a convolutional layer. The layers are independent of each other. Therefore, various edge devices can update the parameters of the layers in parallel independently. Experiments are performed using a benchmark dataset and a publicly available date fruits database. Experimental results show that the proposed model has a high information density by reducing the number of parameters without much loss of accuracy.","","","10.1109/TII.2019.2950326","the Research and Development Program Ministry of Education Riyadh Saudi Arabia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8886463","Deep neural network;edge computing;tree-based deep model;residual network","Computational modeling;Convolution;Deep learning;Image edge detection;Edge computing;Task analysis;Vegetation","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Learning Raw Image Reconstruction-Aware Deep Image Compressors","A. Punnappurath; M. S. Brown","Electrical Engineering and Computer Science, York University, Toronto, Ontario Canada M3J 1P3 (e-mail: jithuthatswho@gmail.com); Computer Science, National University of Singapore, Singapore, Singapore Singapore 117590 (e-mail: mbrown@eecs.yorku.ca)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Deep learning-based image compressors are actively being explored in an effort to supersede conventional image compression algorithms, such as JPEG. Conventional and deep learning-based compression algorithms focus on minimizing image fidelity errors in the nonlinear standard RGB (sRGB) color space. However, for many computer vision tasks, the sensor's linear raw-RGB image is desirable. Recent work has shown that the original raw-RGB image can be reconstructed using only small amounts of metadata embedded inside the JPEG image [1]. However, [1] relied on the conventional JPEG encoding that is unaware of the raw-RGB reconstruction task. In this paper, we examine the ability of deep image compressors to be ""aware"" of the additional objective of raw reconstruction. Towards this goal, we describe a general framework that enables deep networks targeting image compression to jointly consider both image fidelity errors and raw reconstruction errors. We describe this approach in two scenarios: (1) the network is trained from scratch using our proposed joint loss, and (2) a network originally trained only for sRGB fidelity loss is later fine-tuned to incorporate our raw reconstruction loss. When compared to sRGB fidelity-only compression, our combined loss leads to appreciable improvements in PSNR of the raw reconstruction with only minor impact on sRGB fidelity as measured by MS-SSIM.","","","10.1109/TPAMI.2019.2903062","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8658108","image compression;radiometric calibration;raw image reconstruction;deep learning-based image compression","Image reconstruction;Image coding;Table lookup;Compressors;Transform coding;Cameras;Calibration","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Analyze Informant-based Questionnaire for The Early Diagnosis of Senile Dementia Using Deep Learning","F. Zhu; X. Li; D. McGonigle; H. Tang; Z. He; C. Zhang; G. Hung; P. Chiu; W. Zhou","School of Computer and Communication Engineering, Zhengzhou University of Light Industry, Zhengzhou, Henan.; School of Computer and Communication Engineering, Zhengzhou University of Light Industry, Zhengzhou, Henan.; School of Computing Sciences and Computer Engineering, University of Southern Mississippi, Long Beach, MS.; School of Computing Sciences and Computer Engineering, University of Southern Mississippi, Long Beach, MS.; College of Computing, Michigan Technological University, Houghton, MI.; School of Computing Sciences and Computer Engineering, University of Southern Mississippi, Long Beach, MS.; Department of Nuclear Medicine, Chang Bing Show Chwan Memorial Hospital, Changhua, Taiwan.; Department of Neurology, Show Chwan Memorial Hospital, Changhua, Taiwan.; College of Computing, Michigan Technological University, Houghton, MI.","IEEE Journal of Translational Engineering in Health and Medicine","","2019","PP","99","1","1","Objective: This paper proposes a multiclass deep learning method for the classification of dementia using an informant-based questionnaire. Methods: A deep neural network classification model based on Keras framework is proposed in this paper. To evaluate the advantages of our proposed method, we compared the performance of our model with industry-standard machine learning approaches. We enrolled 6,701 individuals, which were randomly divided into training data sets (6030 participants) and test data sets (671 participants). We evaluated each diagnostic model in the test set using accuracy, precision, recall, and F1-Score. Results: Compared with the seven conventional machine learning algorithms, the DNN showed higher stability and achieved the best accuracy with 0.88, which also showed good results for identifying normal (F1-score=0.88), mild cognitive impairment (MCI) (F1-score=0.87), very mild dementia (VMD) (F1-score=0.77) and Severe dementia (F1-score=0.94). Conclusion: The deep neural network (DNN) classification model can effectively help doctors accurately screen patients who have normal cognitive function, mild cognitive impairment (MCI), very mild dementia (VMD), mild dementia (Mild), moderate dementia (Moderate), and severe dementia (Severe).","","","10.1109/JTEHM.2019.2959331","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933438","dementia;information gain;deep neural network;machine learning","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Affective EEG-Based Person Identification Using the Deep Learning Approach","T. Wilaiprasitporn; A. Ditthapron; K. Matchaparn; T. Tongbuasirilai; N. Banluesombatkul; E. Chuangsuwanich","Bio-inspired Robotics and Neural Engineering Lab, School of Information Science and Technology, Vidyasirimedhi Institute of Science & Engineering, Rayong, Thailand.; Computer Department, Worcester Polytechnic Institute, Worcester, MA, USA.; Computer Engineering Department, King Mongkut’s University of Technology Thonburi, Bangkok, Thailand.; Department of Science and Technology, Linköping University, Sweden.; Bio-inspired Robotics and Neural Engineering Lab, School of Information Science and Technology, Vidyasirimedhi Institute of Science & Engineering, Rayong, Thailand.; Computer Engineering Department, Chulalongkorn University, Bangkok, Thailand.","IEEE Transactions on Cognitive and Developmental Systems","","2019","PP","99","1","1","Electroencephalography (EEG) is another method for performing Person Identification (PI). Due to the nature of the EEG signals, EEG-based PI is typically done while a person is performing a mental task such as motor control. However, few studies used EEG-based PI while the person is in different mental states (affective EEG). The aim of this study is to improve the performance of affective EEG-based PI using a deep learning approach. We proposed a cascade of deep learning using a combination of Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs). CNNs are used to handle the spatial information from the EEG while RNNs extract the temporal information. We evaluated two types of RNNs, namely, Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU). The proposed method is evaluated on the state-of-the-art affective dataset DEAP. The results indicate that CNN-GRU and CNN-LSTM can perform PI from different affective states and reach up to 99.90–100% mean Correct Recognition Rate. This significantly outperformed a support vector machine baseline system that used power spectral density features. Notably, the 100% mean CRR came from 32 subjects in DEAP dataset. Even after the reduction of the number of EEG electrodes from thirty-two to five for more practical applications, the model could still maintain an optimal result obtained from the frontal region, reaching up to 99.17%. Amongst the two deep learning models, we found that CNN-GRU and CNN-LSTM performed similarly while CNN-GRU expended faster training time. In conclusion, the studied DL approaches overcame the influence of affective states in EEG-Based PI reported in the previous works.","","","10.1109/TCDS.2019.2924648","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8745473","Electroencephalography;Personal identification;Biometrics;Deep learning;Affective computing;Convolutional neural networks;Long short-term memory;Recurrent neural networks.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"BinDaaS: Blockchain-Based Deep-Learning as-a-Service in Healthcare 4.0 Applications","P. Bhattacharya; S. Tanwar; U. Bodke; S. Tyagi; N. Kumar","Nirma University of Science and Technology, 56953 Ahmedabad, Gujarat India (e-mail: pronoya.bhattacharya@nirmauni.ac.in); CSED, Nirma University of Science and Technology, 56953 Ahmedabad, Gujarat India (e-mail: sudeep.tanwar@nirmauni.ac.in); Nirma University of Science and Technology, 56953 Ahmedabad, Gujarat India (e-mail: umesh.bodkhe@nirmauni.ac.in); ECED, Thapar University, 29080 Patiala, Punjab India (e-mail: s.tyagi@thapar.edu); CSED, Thapar University, Patiala, Patiala, Punjab India (e-mail: neeraj.kumar@thapar.edu)","IEEE Transactions on Network Science and Engineering","","2019","PP","99","1","1","Electronic Health Records (EHRs) allows patients to control, share, and manage their health records among family members, friends, and healthcare service providers. Thus, pri- vacy, confidentiality, and data consistency are major challenges in such an environment. Although, cloud-based EHRs addresses the aforementioned issues, but these are prone to malicious attacks, trust management, and non-repudiation among servers. Hence, blockchain-based EHR systems are preferable to create the trust, security, and privacy among healthcare users. Motivated from the aforementioned discussions, we proposes a framework called as Blockchain-Based Deep Learning as-a-Service (BinDaaS). It integrates blockchain and deep-learning techniques for sharing EHR records among multiple healthcare users and operates in two phases. In the first phase, an authentication and signature scheme is proposed based on lattices-based cryptography to resist collusion attacks among N-1 healthcare authorities from N. In the second phase, Deep Learning as-a-Service (DaaS) is used on stored EHR datasets to accurately predict future diseases based on current indicators and features of patient. The obtained results are compared using various parameters such as accuracy, end-to- end latency, mining time, and computation and communication costs in comparison to the existing state-of-the-art proposals.","","","10.1109/TNSE.2019.2961932","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8943171","EHRs;Blockchain;Authentication;Deep-Learning","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Real-time inspection system for ballast railway fasteners based on point cloud deep learning","H. Cui; J. Li; Q. Hu; Q. Mao","School of Water Science and Engineering, Zhengzhou University, Zhengzhou 450001, China.; School of Geoscience and Technology, Zhengzhou University, Zhengzhou 450001, China.; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan 430079, China.; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan 430079, China.","IEEE Access","","2019","PP","99","1","1","Rail fasteners are the most numerous components in railways and they should be inspected periodically. Manual inspection is currently a common solution, which is laborious and low-efficient. Some automatic inspection approaches are proposed. But for ballast railway fasteners inspection, debris, especially ballast along tracks may cover the fasteners, which is still a tricky problem. In this paper, a real-time inspection system for ballast railway fasteners based on point cloud deep learning is developed. Dense and precise point cloud of fastener is obtained from the structured light sensors in the system. The point cloud of fastener is segmented into different parts to avoid the interference of debris on fasteners. A ballast fastener point cloud semantic segmentation dataset is created based on automatic annotation method. Several deep learning point cloud segmentation models are tested in this dataset and PointNet++ is selected to be deployed in the real-time deep learning module of the system. Field tests on ballast railways show excellent accuracy and efficiency of this system.","","","10.1109/ACCESS.2019.2961686","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8939392","Ballast railway fasteners;fastener inspection;deep learning;neural network;point cloud semantic segmentation","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Mitral Annulus Segmentation using Deep Learning in 3D Transesophageal Echocardiography","B. S. Andreassen; F. Veronesi; O. Gerard; A. H. S. Solberg; E. Samset","Department of Informatics, University of Oslo, 6305 Oslo Norway 0316 (e-mail: borgesan@ifi.uio.no); GE Vingmed Ultrasound AS, 168034 Oslo Norway (e-mail: federico.veronesi@ge.com); GE Vingmed Ultrasound AS, 168034 Oslo Norway (e-mail: olivier.gerard@ge.com); Department of Informatics, University of Oslo, 6305 Oslo Norway (e-mail: anne@ifi.uio.no); Department of Informatics, University of Oslo, 6305 Oslo Norway (e-mail: eigil.samset@ge.com)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","3D Transesophageal Echocardiography is an excellent tool for evaluating the mitral valve and is also well suited for guiding cardiac interventions. We introduce a fully automatic method for mitral annulus segmentation in 3D Transesophageal Echocardiography, which requires no manual input. One hundred eleven multi-frame 3D transesophageal echocardiography recordings were split into training, validation, and test sets. Each 3D recording was decomposed into a set of 2D planes, exploiting the symmetry around the centerline of the left ventricle. A deep 2D convolutional neural network was trained to predict the mitral annulus coordinates, and the predictions from neighboring planes were regularized by enforcing continuity around the annulus. Applying the final model and postprocessing to the test set data gave a mean error of 2.0 mm - with a standard deviation of 1.9 mm. Fully automatic segmentation of the mitral annulus can alleviate the need for manual interaction in the quantification of an array of mitral annular parameters and has the potential to eliminate inter-observer variability.","","","10.1109/JBHI.2019.2959430","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8931542","Deep learning;echocardiography;machine learning;mitral annulus segmentation;soft-argmax","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Exposing Fake Bitrate Videos Using Hybrid Deep-learning Network from Recompression Error","P. He; H. Li; B. Li; H. Wang; L. Liu","College of Cybersecurity, Sichuan University, Chengdu, China.; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore.; College of Information Engineering, Shenzhen University and Peng Cheng Laboratory, Shenzhen, China.; College of Cybersecurity, Sichuan University, Chengdu, China.; College of Cybersecurity, Sichuan University, Chengdu, China.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Bitrate is generally regarded as an important criterion of video quality. However, with sophisticated video editing software, forgers can create fake bitrate videos by up-converting the bitrate of original videos with lower video quality to attract more viewers on video sharing websites. In this work, we first model the generation process of fake bitrate videos and analyze the dominant sources of information loss. It is found that the recompression error generated by the proposed one-step-further recompression operation is an efficient measurement to expose distinguishable quality variation tendencies between true and fake bitrate videos. Based on this analysis, we propose a detection method for fake bitrate videos using a hybrid deep-learning network from recompression error. For an input video, the patch-wise recompression errors are first calculated to increase the learning capability of the network. To learn robust representations of recompression errors in local regions with different degrees of predictability, a hybrid deep-learning network that contains two branches with heterogeneous structures is designed. For noise-like recompression errors, the first branch has a shallow CNN structure initialized with an Inception-like module using multisize convolutional kernels. For zero-element clustered recompression errors, the second branch has a multi-layer perceptron structure equipped with a unique layer that extracts the histogram of zero-element clustered square regions. The output vectors of different branches are concatenated and then jointly optimized to obtain the patch-wise detection results. Finally, the majority voting (local-to-global) strategy is applied to obtain the final detection result. Extensive experiments are conducted to evaluate the detection performance under various coding parameter settings, such as different bitrates, rate-distortion optimization strategies and so on. The experimental results demonstrate the superiority of the proposed method compared with several state-of-the-art methods to provide more fine-grained forensic clues.","","","10.1109/TCSVT.2019.2951630","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8891709","Video forensics;Fake bitrate video;Recompression error;Hybrid deep-learning network","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Switchable Normalization for Learning-to-Normalize Deep Representation","P. Luo; R. Zhang; J. Ren; Z. Peng; J. Li","Computer Science, Hong Kong University, 25809 Hong Kong, Hong Kong China (e-mail: pluo@ie.cuhk.edu.hk); Department of Electronic Engineering, The Chinese University of Hong Kong, Hong Kong, Hong Kong Hong Kong (e-mail: r.m.zhang1989@gmail.com); N/A, Sensetime Research, N/A, N/A China (e-mail: renjiamin@sensetime.com); N/A, SenseTime Research, N/A, N/A China (e-mail: pengzhanglin@sensetime.com); Electronic Engineering, Chinese University of Hong Kong, 26451 Hong Kong, Hong Kong China (e-mail: jingyuli@cuhk.edu.hk)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","We address a learning-to-normalize problem by proposing Switchable Normalization (SN), which learns to select different normalizers for different normalization layers of a deep neural network. SN employs three distinct scopes to compute statistics (means and variances) including a channel, a layer, and a minibatch. SN switches between them by learning their importance weights in an end-to-end manner. It has several good properties. First, it adapts to various network architectures and tasks. Second, it is robust to a wide range of batch sizes, maintaining high performance even when small minibatch is presented (eg 2 images/GPU). Third, SN does not have sensitive hyper-parameter, unlike group normalization that searches the number of groups as a hyper-parameter. Without bells and whistles, SN outperforms its counterparts on various challenging benchmarks, such as ImageNet, COCO, CityScapes, ADE20K, MegaFace and Kinetics. Analyses of SN are also presented to answer the following three questions: (a) Is it useful to allow each normalization layer to select its own normalizer? (b) What impacts the choices of normalizers? (c) Do different tasks and datasets prefer different normalizers? We hope SN will help ease the usage and understand the normalization techniques in deep learning. The code of SN has been released at https://github.com/switchablenorms.","","","10.1109/TPAMI.2019.2932062","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8781758","Deep Learning;Normalization;Image/Video Classification;Object Detection;Semantic Segmentation and Face Verification","Task analysis;Training;Graphics processing units;Switches;Object detection;Image segmentation;Head","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Dynamic Deep Pixel Distribution Learning for Background Subtraction","C. Zhao; A. Basu","Department of Computing Science, University of Alberta, Edmonton, AB T6G 2E1, Canada.; Department of Computing Science, University of Alberta, Edmonton, AB T6G 2E1, Canada.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Previous approaches to background subtraction usually approximate the distribution of pixels with artificial models. In this paper, we focus on automatically learning the distribution, using a novel background subtraction model named Dynamic Deep Pixel Distribution Learning (D-DPDL). In our D-DPDL model, a distribution descriptor named Random Permutation of Temporal Pixels (RPoTP) is dynamically generated as the input to a convolutional neural network for learning the statistical distribution, and a Bayesian refinement model is tailored to handle the random noise introduced by the random permutation. Because the temporal pixels are randomly permutated to guarantee that only statistical information is retained in RPoTP features, the network is forced to learn the pixel distribution. Moreover, since the noise is random, the Bayesian theorem is naturally selected to propose an empirical model as a compensation based on the similarity between pixels. Evaluations using standard benchmark demonstrates the superiority of the proposed approach compared with the state-of-the-art, including traditional methods as well as deep learning methods.","","","10.1109/TCSVT.2019.2951778","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8892609","Background subtraction;Motion Detection;Deep Learning;Pixel Distribution;Random Permutation","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Significance of Softmax-based Features in Comparison to Distance Metric Learning-based Features","S. Horiguchi; D. Ikami; K. Aizawa","Dept. of Information and Communication Eng., University of Tokyo, 13143 Bunkyo-ku, Tokyo Japan (e-mail: horiguchi@hal.t.u-tokyo.ac.jp); Dept. of Information and Communication Eng., University of Tokyo, 13143 Bunkyo-ku, Tokyo Japan (e-mail: ikami@hal.t.u-tokyo.ac.jp); Department of Information and Communication Eng., University of Tokyo, 13143 Bunkyo-ku, Tokyo Japan (e-mail: aizawa@hal.t.u-tokyo.ac.jp)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","End-to-end distance metric learning (DML) has been applied to obtain features useful in many computer vision tasks. However, these DML studies have not provided equitable comparisons between features extracted from DML-based networks and softmax-based networks. In this paper, we present objective comparisons between these two approaches under the same network architecture.","","","10.1109/TPAMI.2019.2911075","JST; Japan Society for the Promotion of Science; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8691614","deep learning;distance metric learning;classification;retrieval","Feature extraction;Measurement;Principal component analysis;Dimensionality reduction;Network architecture;Automobiles;Task analysis","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Hyperspectral Image Classification With Transfer Learning and Markov Random Fields","X. Jiang; Y. Zhang; Y. Li; S. Li; Y. Zhang","School of Computer Science, Northwestern Polytechnical University, Xi'an 710072, China.; School of Computer Science, Northwestern Polytechnical University, Xi'an 710072, China.; School of Computer Science, Northwestern Polytechnical University, Xi'an 710072, China.; School of Automation, Xi'an University of Posts and Telecommunications, Xi'an 710121, China (e-mail: angle_lisy@163.com).; School of Computer Science, Northwestern Polytechnical University, Xi'an 710072, China.","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","This letter provides a brand new way of feature extraction, which can be applied in the supervised classification of hyperspectral image. The convolutional neural network (CNN) has been proven to be an effective method of image classification. However, due to its long training time, it requires a large amount of the labeled data to achieve the expected outcome. To decrease the training time and reduce the dependence on large labeled data set, we propose using the method of transfer learning by taking the advantage of Bayesian framework to integrate with spectrum and spatial information, making use of the Markov property of images to distinguish and separate the ones with class tags, and employing the CNN trained by band samples randomly selected from the data sets. The method of classification mentioned in our letter makes use of the real hyperspectral data sets to perform the experimental evaluation. The result demonstrates that our method is superior to the previous methods.","","","10.1109/LGRS.2019.2923647","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8758842","Convolutional neural network (CNN);deep learning;image classification;Markov random fields (MRF);transfer learning (TL).","Hyperspectral imaging;Training;Feature extraction;Markov processes;Convolutional neural networks;Convolution","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Discriminative Video Representation Learning Using Support Vector Classifiers","J. Wang; A. Cherian","Computer Vision Group, Australian National University College of Engineering and Computer Science, 213523 Canberra, Australian Capital Territory Australia 0200 (e-mail: jue.wang@anu.edu.au); LEAR, INRIA-Rhone Alpes, Grenoble, Rhone-Alpes France 38000 (e-mail: anoop.cherian@gmail.com)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Most popular deep models for action recognition in videos generate independent predictions for short clips, which are then pooled heuristically to assign an action label to the full video segment. As not all frames may characterize the underlying action, pooling schemes that impose equal importance on all frames might be unfavorable. To tackle this problem, we propose discriminative pooling, based on the notion that among the features generated on all short clips, there is at least one that characterizes the action. To identify useful features, we resort to a negative bag consisting of features that are known to be irrelevant. With the features from the video as a positive bag and the irrelevant features as the negative bag, we cast an objective to learn a (nonlinear) hyperplane that separates the unknown useful feature from the rest in a multiple instance learning formulation within a support vector machine setup. We use the parameters of this separating hyperplane as descriptors for the video. Since these parameters are directly related to the support vectors in a max-margin framework, they can be treated as weighted-average-pooling of the features from the bags. We report results from experiments on eight computer vision benchmarks demonstrating state-of-the-art performance across these tasks.","","","10.1109/TPAMI.2019.2937292","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812898","video representation;video data mining;discriminative pooling;action recognition;deep learning","Support vector machines;Feature extraction;Trajectory;Task analysis;Computer architecture;Image recognition;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Detection of Age-Induced Makeup Attacks on Face Recognition Systems Using Multi-Layer Deep Features","K. Kotwal; Z. Mostaani; S. Marcel","Idiap Research Institute, Martigny, Switzerland.; Idiap Research Institute, Martigny, Switzerland.; Idiap Research Institute, Martigny, Switzerland.","IEEE Transactions on Biometrics, Behavior, and Identity Science","","2019","PP","99","1","1","Makeup is a simple and easy instrument that can alter the appearance of a person’s face, and hence, create a presentation attack on face recognition (FR) systems. These attacks, especially the ones mimicking ageing, are difficult to detect due to their close resemblance with genuine (non-makeup) appearances. Makeups can also degrade the performance of recognition systems and of various algorithms that use human face as an input. The detection of facial makeups is an effective prohibitory measure to minimize these problems. This work proposes a deep learning-based presentation attack detection (PAD) method to identify facial makeups. We propose the use of a convolutional neural network (CNN) to extract features that can distinguish between presentations with age-induced facial makeups (attacks), and those without makeup (bona-fide). These feature descriptors, based on shape and texture cues, are constructed from multiple intermediate layers of a CNN. We introduce a new dataset AIM (Age Induced Makeups) consisting of 200+ video presentations of old-age makeups and bona-fide, each. Our experiments indicate makeups in AIM result in 14% decrease in the median matching scores of a recent CNN-based FR system. We demonstrate accuracy of the proposed PAD method where 93% presentations in the AIM dataset are correctly classified. In additional testing, it also outperforms existing methods of detection of generic makeups. A simple score-level fusion, performed on the classification scores of shape-and texture-based features, can further improve the accuracy of the proposed makeup detector.","","","10.1109/TBIOM.2019.2946175","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8863925","Biometrics;Face Presentation Attack Detection;Convolutional Neural Network;Deep Learning;CNN Embeddings;Texture Descriptor;Shape Descriptor;Score Fusion;Makeup Attacks;Makeup Attack Detection;Old-Age Makeups;AIM.","Face;Feature extraction;Shape;Face recognition;Aging;Detectors","","","","","","","","","","IEEE","IEEE Early Access Articles"
"No Radio Left Behind: Radio Fingerprinting Through Deep Learning of Physical-Layer Hardware Impairments","K. Sankhe; M. Belgiovine; F. Zhou; L. Angioloni; F. Restuccia; S. D’Oro; T. Melodia; S. Ioannidis; K. Chowdhury","Northeastern University, Boston, MA, USA.; Northeastern University, Boston, MA, USA.; Northeastern University, Boston, MA, USA.; Northeastern University, Boston, MA, USA.; Northeastern University, Boston, MA, USA.; Northeastern University, Boston, MA, USA.; Northeastern University, Boston, MA, USA.; Northeastern University, Boston, MA, USA.; Northeastern University, Boston, MA, USA.","IEEE Transactions on Cognitive Communications and Networking","","2019","PP","99","1","1","Due to the unprecedented scale of the Internet of Things, designing scalable, accurate, energy-efficient and tamper-proof authentication mechanisms has now become more important than ever. To this end, in this paper we present ORACLE, a novel system based on convolutional neural networks (CNNs) to “fingerprint” (i.e., identify) a unique radio from a large pool of devices by deep-learning the fine-grained hardware impairments imposed by radio circuitry on physical-layer I/Q samples. First, we show how hardware-specific imperfections are learned by the CNN framework. Then, we extensively evaluate the performance of ORACLE on several first-of-its-kind large-scale datasets of WiFi-transmissions collected “in the wild”, as well as a dataset of nominally-identical (i.e., equal baseband signals) WiFi devices, reaching 80-90% accuracy is many cases with the error gap arising due to channel-induced effects. Finally, we show through an experimental testbed, how this accuracy can reach over 99% by intentionally inserting and learning the effect of controlled impairments at the transmitter side, to completely remove the impact of the wireless channel. Furthermore, to scale this approach for classifying potential thousands of radios, we propose an impairment hopping spread spectrum (IHOP) technique that is resilient to spoofing attacks.","","","10.1109/TCCN.2019.2949308","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8882379","","Radio transmitters;Radio frequency;Hardware;Wireless communication;Feature extraction;Deep learning;Wireless fidelity","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Fuzzy Removing Redundancy Restricted Boltzmann Machine: improving learning speed and classification accuracy","X. Lü; L. Meng; C. Chen; P. Wang","School of Automation Engineering, Shanghai University of Electric Power, 12596 Shanghai China 200090 (e-mail: lvxueqin@shiep.edu.cn); School of Automation Engineering, Shanghai University of Electric Power, 12596 Shanghai China (e-mail: 1047502706@qq.com); School of Automation Engineering, Shanghai University of Electric Power, 12596 Shanghai China (e-mail: chenchao_shiep@163.com); School of Automation Engineering, Shanghai University of Electric Power, 12596 Shanghai China (e-mail: wangps0918@163.com)","IEEE Transactions on Fuzzy Systems","","2019","PP","99","1","1","To improve the feature extraction ability and shorten the learning time, Fuzzy Removing Redundancy Restricted Boltzmann Machine (F3RBM) is developed. The features extracted by F3RBM with unsupervised learning are imported into Support Vector Machine (SVM) to establish F3RBM-SVM model, which achieves fast and high-precision automatic classification of different samples. To expand the feature extraction capability of Restricted Boltzmann Machine (RBM), the deterministic parameters of control model are replaced by fuzzy numbers in view of the superiority of fuzzy idea. And the redundancy removal mechanism is introduced. Comparing the feature similarity of hidden units with the threshold value, if the similarity is greater than the threshold value, they are considered to be redundant units with the same features. And redundant units are removed to achieve further dimension reduction. Finally, the learning speed, feature extraction ability and classification accuracy of different models are compared in MINIST handwritten dataset, Fashion MNIST dataset and Olivetti Face dataset. The experimental results show that the feature extraction capability of FRBM and F3RBM is better than that of RBM. When there are a large number of hidden units, the learning speed of F3RBM is obviously faster than that of FRBM. The features extracted from F3RBM are imported into the SVM to build F3RBM-SVM model, which improves the classification accuracy and learning speed than general classifier. Compared with other types of classifiers based on fuzzy modeling, F3RBM-SVM shows advantages in classification ability. When adding other noises, F3RBM-SVM has better robustness than other models.","","","10.1109/TFUZZ.2019.2940415","National Natural Science Foundation of China; Shanghai Key Laboratory Power Station Automation Technology Laboratory; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8827632","Deep learning;feature extraction;fuzzy removing redundancy restricted boltzmann machine;RBM;SVM","Feature extraction;Support vector machines;Data mining;Redundancy;Deep learning;Robustness;Image recognition","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Channel Estimation in Massive MIMO under Hardware Non-Linearities: Bayesian Methods versus Deep Learning","Ö. T. Demir; E. Björnson","Department of Electrical Engineering (ISY), Linköping University, 581 83 Linköping, Sweden. (e-mail: ozlem.tugfe.demir@liu.se); Department of Electrical Engineering (ISY), Linköping University, 581 83 Linköping, Sweden.","IEEE Open Journal of the Communications Society","","2019","PP","99","1","1","This paper considers the joint impact of non-linear hardware impairments at the base station (BS) and user equipments (UEs) on the uplink performance of single-cell massive MIMO (multiple-input multiple-output) in practical Rician fading environments. First, Bussgang decomposition-based effective channels and distortion characteristics are analytically derived and the spectral efficiency (SE) achieved by several receivers are explored for third-order non-linearities. Next, two deep feedforward neural networks are designed and trained to estimate the effective channels and the distortion variance at each BS antenna, which are used in signal detection. We compare the performance of the proposed methods with state-of-the-art distortion-aware and -unaware Bayesian linear minimum mean-squared error (LMMSE) estimators. The proposed deep learning approach improves the estimation quality by exploiting impairment characteristics, while LMMSE methods treat distortion as noise. Using the data generated by the derived effective channels for general order of non-linearities at both the BS and UEs, it is shown that the deep learning-based estimator provides better estimates of the effective channels also for non-linearities more than order three.","","","10.1109/OJCOMS.2019.2959913","Knut och Alice Wallenbergs Stiftelse; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933050","Deep learning;hardware impairments;uplink spectral efficiency;distortion-aware receiver;channel estimation;Rician fading.","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Deep hybrid state network with feature reinforcement for intelligent fault diagnosis of delta 3D printers","S. Zhang; Z. Sun; C. Li; D. Cabrera; J. Long; Y. Bai","Dongguan China 523808 (e-mail: zhangsh@dgut.edu.cn); Dongguan China 523808 (e-mail: drzzsun@sina.com); Dongguan China 523808 (e-mail: chuanli@dgut.edu.cn); Universidad Politicnica Salesiana, Ecuador Portugal 523808 (e-mail: dcabrera@ups.edu.ec); Dongguan China 523808 (e-mail: longjy@dgut.edu.cn); Dongguan China 523808 (e-mail: baiyun@dgut.edu.cn)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","An echo state network (ESN) is a type of recurrent neural network that is good at processing time-series data with dynamic behavior. However, the use of ESNs to enhance fault-classification accuracy continues to be challenging when the condition signals are collected by low-cost sensors. In this paper, a deep network algorithm, called a deep hybrid state network (DHSN), is proposed for fault diagnosis of three-dimensional (3D) printers using attitude data with low measurement precision. In the DHSN, the output data of a sparse auto-encoder (SAE) are regarded as the abstract features of a double-structured echo state network (DESN). The DESN is designed for feature reinforcement and fault recognition, wherein the first function reinforces the features and the second is used for fault classification. More specifically, feature reinforcement is developed to improve the clustering performance and replace the traditional overall feedback fine-tuning in deep models. This strategy improves learning efficiency and overcomes the vanishing-gradient problem for deep learning. The forecasting performance of the proposed approach is evaluated in experiments, and its superiority is demonstrated through comparison with other intelligent fault diagnosis technologies.","","","10.1109/TII.2019.2920661","National Natural Science Foundation of China; Natural Science Foundation of Guangdong Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8728244","Deep hybrid state network;delta 3D printer;feature reinforcement;fault diagnosis","Fault diagnosis;Feature extraction;Three-dimensional displays;Printers;Sensors;Deep learning;Monitoring","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Information Losses in Neural Classifiers From Sampling","B. Foggo; N. Yu; J. Shi; Y. Gao","Department of Electrical and Computer Engineering, University of California at Riverside, Riverside, CA 92521 USA (e-mail: bfogg001@ucr.edu).; Department of Electrical and Computer Engineering, University of California at Riverside, Riverside, CA 92521 USA.; Department of Electrical and Computer Engineering, University of California at Riverside, Riverside, CA 92521 USA.; Department of Electrical and Computer Engineering, University of California at Riverside, Riverside, CA 92521 USA.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","11","This article considers the subject of information losses arising from the finite data sets used in the training of neural classifiers. It proves a relationship between such losses as the product of the expected total variation of the estimated neural model with the information about the feature space contained in the hidden representation of that model. It then bounds this expected total variation as a function of the size of randomly sampled data sets in a fairly general setting, and without bringing in any additional dependence on model complexity. It ultimately obtains bounds on information losses that are less sensitive to input compression and in general much smaller than existing bounds. This article then uses these bounds to explain some recent experimental findings of information compression in neural networks that cannot be explained by previous work. Finally, this article shows that not only are these bounds much smaller than existing ones, but they also correspond well with experiments.","","","10.1109/TNNLS.2019.2952029","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8920104","Deep learning;information theory;large deviations theory;mutual information;statistical learning theory.","Neural networks;Machine learning;Training;Random variables;Training data;Probability distribution;Learning systems","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Reinforced Learning Tree for Spatiotemporal Monitoring With Mobile Robotic Wireless Sensor Networks","J. Chen; T. Shu; T. Li; C. W. de Silva","Department of Mechanical Engineering, University of British Columbia, Vancouver, BC V6T 1Z4, Canada (e-mail: jhchen@mech.ubc.ca).; Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, BC V6T 1Z4, Canada.; Department of Mechanical Engineering, University of British Columbia, Vancouver, BC V6T 1Z4, Canada.; Department of Mechanical Engineering, University of British Columbia, Vancouver, BC V6T 1Z4, Canada.","IEEE Transactions on Systems, Man, and Cybernetics: Systems","","2019","PP","99","1","15","This paper concerns the deployment problem of wireless sensor networks (WSNs) with mobile robotic sensor nodes for spatiotemporal monitoring. The proposed approach, deep reinforced learning tree (DRLT), utilizes deep reinforcement learning (DRL) to improve the efficiency of searching the most informative sampling locations. The parameterized sampling locations in an infinite horizon space are modeled according to their spatiotemporal correlations and subject to various constraints, including field estimation error and information gain. And the model-based information gain can be calculated efficiently over an infinite horizon. In this manner, the effectiveness of the sampling locations is learned through DRLT during the exploration by the robotic sensors. Then DRLT can instruct the robotic sensors to avoid unnecessary sampling locations in future iterations. Also, it is proved in this paper that the proposed algorithm is capable of searching for the near-optimal sampling locations effectively and guaranteeing a minimum field estimation error. Simulation based on national oceanic and atmospheric administration (NOAA) datasets is presented, which demonstrates the significant enhancements made by the proposed algorithm. Compared with the traditional approaches, such as the information theory-based greedy approach or random sampling, the proposed method shows a superior performance with regard to both estimation error and planning efficiency.","","","10.1109/TSMC.2019.2920390","India Canada Centre for Innovative Multidisciplinary Partnership to Accelerate Community Transformation and Sustainability; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8737882","Deep reinforcement learning (DRL);environmental monitoring;Gaussian process;informative planning;mobile robotic wireless sensor networks (WSNs);persistent monitoring;spatial statistics","Robot sensing systems;Spatiotemporal phenomena;Monitoring;Estimation error;Wireless sensor networks;Computational modeling","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep-Learning Tracking for Autonomous Flying Systems Under Adversarial Inputs","L. R. G. Carrillo; K. G. Vamvoudakis","Unmanned Systems Laboratory, Department of Electrical Engineering, Texas A&M University - Corpus Christi, Corpus Christi, TX, 78412-5797, USA.; Daniel Guggenheim School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA 30332, USA.","IEEE Transactions on Aerospace and Electronic Systems","","2019","PP","99","1","1","We propose a game-theory based deep-learning tracking control scheme to enable a holonomic flying system to perform an autonomous trajectory tracking task, when considering saturating actuators, adversarial inputs, and non-quadratic cost functionals. The problem is formulated as a two-player zerosum game, whose online solution is computed by learning the saddle point strategies in real time. Three approximators, namely a critic and two actors, are tuned online using data generated in real-time along the system trajectories. The adaptive control character of the algorithm requires a persistence of excitation condition to be a priori validated, which is relaxed by using a deep-learning approach, based on experience replay with multiple layers. A robustifying control term is added to eliminate the effect of residual errors, leading to asymptotic stability of the equilibrium point of the closed-loop system. A simulation of a target tracking application where the measurements available to the aerial system are perturbed by persistent adversaries is performed to validate the effectiveness of the proposed approach.","","","10.1109/TAES.2019.2930017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8767968","Deep-learning tracking;autonomy;zero-sum game","Trajectory tracking;Task analysis;Games;Real-time systems;Trajectory;Approximation algorithms;Aerodynamics","","","","","","","","","","IEEE","IEEE Early Access Articles"
"An Enhanced Intelligent Diagnosis Method Based on Multi-Sensor Image Fusion via Improved Deep Learning Network","H. Wang; S. Li; L. Song; L. Cui; P. Wang","School of Mechanical & Electrical Engineering, Beijing University of Chemical Technology, Chao Yang District, Beijing, 100029, P.R. China.; School of Mechanical & Electrical Engineering, Beijing University of Chemical Technology, Chao Yang District, Beijing, 100029, P.R. China.; School of Mechanical & Electrical Engineering, Beijing University of Chemical Technology, Chao Yang District, Beijing, 100029, P.R. China.; Key Laboratory of Advanced Manufacturing Technology, Beijing University of Technology, Chao Yang District, Beijing 100124, P.R. China.; School of Mechanical & Electrical Engineering, Beijing University of Chemical Technology, Chao Yang District, Beijing, 100029, P.R. China.","IEEE Transactions on Instrumentation and Measurement","","2019","PP","99","1","1","An enhanced intelligent diagnosis method for rotary equipment is proposed based on multi-sensor data-fusion and an improved deep convolutional neural network (CNN) models. An improved CNN based on LeNet-5 is constructed that can enhance the features of the samples by stacking bottleneck layers without changing the size of the samples. A new conversion approaches are also proposed for converting multi-sensor vibration signals into color images, and it can refine features and enlarge the differences between different types of fault signals by the fused images transformed in red-green-blue (RGB) color space. In the last stage of network learning, visual clustering is realized with t-distributed stochastic neighbor embedding (t-SNE) to evaluate the performance of the network. To verify the effectiveness of the proposed method, examples in practice such as the diagnosis for the wind power test rigs and industrial fan system are provided with the prediction accuracies of 99.89% and 99.77%, respectively. In addition, the efficiency of other comparative baseline approaches such as the deep belief network (DBN) and support vector machine (SVM) is evaluated. In conclusion, the proposed intelligent diagnosis method based on multi-sensor data-fusion and CNN shows higher prediction accuracy and more obvious visualization clustering effects.","","","10.1109/TIM.2019.2928346","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8760507","Intelligent Diagnosis;Multi-sensor Data Fusion;Color-Image;Convolutional neural network","Convolution;Feature extraction;Fault diagnosis;Kernel;Deep learning;Vibrations;Data models","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Weighted Ensemble of Deep Convolution Neural Networks for a Single Trial Character Detection in Devanagari Script Based P300 Speller","G. B. Kshirsagar; N. D. Londhe","National Institute of Technology Raipur. Raipur, Chhattisgarh-492010, India.; National Institute of Technology Raipur, Raipur, Chhattisgarh-492010, India.","IEEE Transactions on Cognitive and Developmental Systems","","2019","PP","99","1","1","The existing Devanagari script (DS) input based P300 speller (DS-P3S) performs better mostly with 3-15 trials. This leads to poor information transfer rate (ITR) and a major concern in its real-time adaptation. In DS-P3S, the display paradigm is a matrix of 8x8 size which has 28 more characters than 6x6 English paradigm. The increased number of characters also leads to user related issues like crowding effect, double flashing, adjacency-distraction, task difficulty, and fatigue which increases the false detection rate. To tackle this, we proposed an efficient single trial character detection approach for DS-P3S using weighted ensemble of deep convolution neural networks (WE-DCNNs). The weighted strategy is constructed based on measured ensemble diversity to counter the instability by the individual classifier. Additionally, to reduce the false detection rate arising due to a single trial, a new channel dropout-based character detection approach is introduced first time in this paper. The ITR of 55.45 bits per minutes and an average P300 classification accuracy of 92.64% achieved is comparatively higher than existing methods of DS-P3S. The significant reduction in trade-off between bias and variance for the different subjects affirms the ease of applicability of the proposed model with just a single trial.","","","10.1109/TCDS.2019.2942437","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8844793","Brain-computer interface (BCI);Devanagari script (DS) based P300 speller;Single-trial;Ensemble learning;Deep convolution neural network (DCNN).","Convolution;Deep learning;Neural networks;Bagging;Task analysis;Data models","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Integration of Accelerated Deep Neural Network into Power Transformer Differential Protection","S. Afrasiabi; M. Afrasiabi; B. Parang; M. Mohammadi","School of Engineering, Ahvaz Iran (the Islamic Republic of) 7183656476 (e-mail: shpower77@yahoo.com); Department of power and control Eng., Shiraz University, 37551 Shiraz Iran (the Islamic Republic of) 71946-84636 (e-mail: musa.afra@shirazu.ac.ir); Department of power and control Eng., Shiraz University, 37551 Shiraz Iran (the Islamic Republic of) 71946-84636 (e-mail: benyamin.parang@shirazu.ac.ir); Department of power and control Eng., Shiraz University, 37551 Shiraz Iran (the Islamic Republic of) 71946-84636 (e-mail: m.mohammadi@shirazu.ac.ir)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","The differential protection is the main protection scheme of power transformers, which still holds the risk of sending false trips subject to inrush currents. This paper aims to develop a differential protection scheme to discriminate power transformer magnetizing current from internal faults to decrease the risk of false trips. In this paper, an accelerated convolutional neural network (CNN) based approach is designed for discrimination between internal faults and inrush current. The main competitive advantage of the proposed algorithm is its capability in fusing the feature extraction and fault detection blocks in to a single deep neural network(DNN) block by enabling the network to discover important features automatically. The result of this point is that the algorithm is more efficient in terms of speed, hardware usage and accuracy. The proposed method is applied to a simulated 230kV network and an experimental prototype. Different cases with various external factors are simulated to calculate reliability indexes. Comparison between the accelerated CNN, conventional CNN, and nine widely used methods demonstrates the faster and more reliable performance of the proposed algorithm.","","","10.1109/TII.2019.2929744","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8765806","Differential protection;Power transformers;Inrush current;Internal fault;Deep learning;Convolutional neural network (CNN);Accelerated CNN","Feature extraction;Acceleration;Power transformers;Surges;Surge protection;Deep learning;Circuit faults","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Bio-Inspired Representation Learning for Visual Attention Prediction","Y. Yuan; H. Ning; X. Lu","Center for Optical Imagery Analysis and Learning, School of Computer Science, Northwestern Polytechnical University, Xi'an 710072, China.; Key Laboratory of Spectral Imaging Technology CAS, Xi'an Institute of Optics and Precision Mechanics, Chinese Academy of Sciences, Xi'an 710119, China, and also with the University of Chinese Academy of Sciences, Beijing 100049, China.; Key Laboratory of Spectral Imaging Technology CAS, Xi'an Institute of Optics and Precision Mechanics, Chinese Academy of Sciences, Xi'an 710119, China (e-mail: luxq666666@gmail.com).","IEEE Transactions on Cybernetics","","2019","PP","99","1","14","Visual attention prediction (VAP) is a significant and imperative issue in the field of computer vision. Most of the existing VAP methods are based on deep learning. However, they do not fully take advantage of the low-level contrast features while generating the visual attention map. In this article, a novel VAP method is proposed to generate the visual attention map via bio-inspired representation learning. The bio-inspired representation learning combines both low-level contrast and high-level semantic features simultaneously, which are developed by the fact that the human eye is sensitive to the patches with high contrast and objects with high semantics. The proposed method is composed of three main steps: 1) feature extraction; 2) bio-inspired representation learning; and 3) visual attention map generation. First, the high-level semantic feature is extracted from the refined VGG16, while the low-level contrast feature is extracted by the proposed contrast feature extraction block in a deep network. Second, during bio-inspired representation learning, both the extracted low-level contrast and high-level semantic features are combined by the designed densely connected block, which is proposed to concatenate various features scale by scale. Finally, the weighted-fusion layer is exploited to generate the ultimate visual attention map based on the obtained representations after bio-inspired representation learning. Extensive experiments are performed to demonstrate the effectiveness of the proposed method.","","","10.1109/TCYB.2019.2931735","National Natural Science Foundation of China; Young Top Notch Talent Program of Chinese Academy of Sciences; National Key Research and Development Program of China; CAS Light of West China Program; National Natural Science Fund for Distinguished Young Scholars; State Key Program of National Natural Science of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8822602","Bio-inspired;center-bias prior;contrast features;densely connected;reduction-attention;semantic features;visual attention prediction (VAP)","Feature extraction;Semantics;Visualization;Object detection;Cybernetics;Computer vision;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Thorax-Net: An Attention Regularized Deep Neural Network for Classification of Thoracic Diseases on Chest Radiography","H. Wang; H. Jia; L. Lu; Y. Xia","School of Computer Science School of Computer Science Building Chang'an Campus Northwestern Polytechnical University, Xi'an, Shaanxi China (e-mail: hywang@mail.nwpu.edu.cn); School of Computer Science School of Computer Science Building Chang'an Campus Northwestern Polytechnical University, Xi'an, Shaanxi China (e-mail: haozhejia@mail.nwpu.edu.cn); Radiology and Imaging Science, National Institutes of Health, Bethesda, Maryland United States 20892 (e-mail: le.lu@nih.gov); School of Computer Science, Northwestern Polytechnical University, 26487 Xi'an, Shaanxi China 710072 (e-mail: yxia@ieee.org)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","Deep learning techniques have been increasingly used to provide more accurate and more accessible diagnosis of thorax diseases on chest radiographs. However, due to the lack of dense annotation of large-scale chest radiograph data, this computer-aided diagnosis task is intrinsically a weakly supervised learning problem and remains challenging. In this paper, we propose an attention regularized deep convolutional neural network called Thorax-Net to diagnose 14 thorax diseases using chest radiography. Thorax-Net consists of a classification branch and an attention branch. The classification branch serves as a uniform feature extraction-classification network to free users from the troublesome handcrafted feature extraction and classifier construction. The attention branch exploits the correlation between class labels and the locations of pathological abnormalities via analyzing the feature maps learned by the classification branch. Feeding a chest radiograph to the trained Thorax-Net, a diagnosis is obtained by averaging the outputs of two branches. The proposed Thorax-Net model has been evaluated against three state-of-the-art deep learning models using the patient-wise official split of the Chest X-ray 14 dataset [1] and against other five deep learning models using the image-wise random data split. Our results show that Thorax-Net achieves an average per-class AUC of 0.7876 and 0.896 in both experiments, respectively, which are higher than the AUC values obtained by other deep models when they were trained without using external data.","","","10.1109/JBHI.2019.2928369","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8760405","Thorax disease classification;deep learning;attention mechanism;weakly supervised learning","Diseases;Diagnostic radiography;Thorax;Pathology;Data models;Lung;Feature extraction","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Harnessing the Power of Machine Learning in Dementia Informatics Research: Issues, Opportunities and Challenges","G. Tsang; X. Xie; S. Zhou","Computer Science, Swansea University, 7759 Swansea United Kingdom of Great Britain and Northern Ireland SA2 8PP (e-mail: 658679@swansea.ac.uk); Department of Computer Science, University of Swansea, Swansea United Kingdom of Great Britain and Northern Ireland SA2 8PP (e-mail: x.xie@swansea.ac.uk); College of Medicine, Swansea University, Swansea United Kingdom of Great Britain and Northern Ireland SA2 8PP (e-mail: S.Zhou@swansea.ac.uk)","IEEE Reviews in Biomedical Engineering","","2019","PP","99","1","1","Dementia is a chronic and degenerative condition affecting millions globally. The care of patients with dementia presents an ever continuing challenge to healthcare systems in the 21st century. Medical and health sciences have generated unprecedented volumes of data related to health and wellbeing for patients with dementia due to advances in information technology, such as genetics, neuroimaging, cognitive assessment, free texts, routine electronic health records etc. Making the best use of these diverse and strategic resources will lead to high quality care of patients with dementia. As such, machine learning becomes a crucial factor in achieving this objective. The aim of this paper is to provide a state-of-the-art review of machine learning methods applied to health informatics for dementia care. We collate and review the existing scientific methodologies and identify the relevant issues and challenges when faced with big health data. Machine learning has demonstrated promising applications to neuroimaging data analysis for dementia care, while relatively less efforts have been made to make use of integrated heterogeneous data via advanced machine learning approaches. We further indicate the future potentials and research directions of applying advanced machine learning, such as deep learning, to dementia informatics.","","","10.1109/RBME.2019.2904488","Medical Research Council Canada; Health Data Research UK; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8665908","Alzheimer;Cognitive Assessment;Deep Learning;Dementia;Electronic Medical Records;Health Informatics;Machine Learning;NeuroImaging;NLP","Dementia;Neuroimaging;Machine learning;Support vector machines;Informatics;Prognostics and health management","","","","","","","","","","IEEE","IEEE Early Access Articles"
"DeepDSC: A Deep Learning Method to Predict Drug Sensitivity of Cancer Cell Lines","M. Li; Y. Wang; R. Zheng; X. Shi; y. li; F. Wu; J. Wang","Computer Science, Central South University, Changsha, Hunan China (e-mail: limin@mail.csu.edu.cn); Computer Science, Central South University, Changsha, Hunan China (e-mail: wangyk@csu.edu.cn); Computer Science, Central South University, Changsha, Hunan China (e-mail: rqzheng@csu.edu.cn); Bioinformatics and Genomics, University of North Carolina at Charlotte, Charlotte, North Carolina United States 28223 (e-mail: X.Shi@uncc.edu); Computer Science, Old Dominion University, Norfolk, Virginia United States 23508 (e-mail: yaohang@cs.odu.edu); Department of Mechanical Engineering, University of Saskatchewan, Saskatoon, Saskatchewan Canada S7N 5A9 (e-mail: faw341@mail.usask.ca); Computer Science, Central South University, ChangSha, Hunan China 410083 (e-mail: jxwang@mail.csu.edu.cn)","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2019","PP","99","1","1","High-throughput screening technologies have provided a large amount of drug sensitivity data for a panel of cancer cell lines and hundreds of compounds. Computational approaches to analyzing these data can benefit anticancer therapeutics by identifying molecular genomic determinants of drug sensitivity and developing new anticancer drugs. In this study, we have developed a deep learning architecture to improve the performance of drug sensitivity prediction based on these data. We integrated both genomic features of cell lines and chemical information of compounds to predict the half maximal inhibitory concentrations (IC50) on the Cancer Cell Line Encyclopedia (CCLE) and the Genomics of Drug Sensitivity in Cancer (GDSC) datasets using a deep neural network, which we called DeepDSC. Specifically, we first applied a stacked deep autoencoder to extract genomic features of cell lines from gene expression data, and then combined the compounds' chemical features to these genomic features to produce final response data. We conducted 10-fold cross-validation to demonstrate the performance of our deep model in terms of root-mean-square error (RMSE) and coefficient of determination R2 . We show that our model outperforms the previous approaches with RMSE of 0.23 and R2 of 0.78 on CCLE dataset, and RMSE of 0.52 and R2 of 0.78 on GDSC dataset, respectively. Moreover, to demonstrate the prediction ability of our models on novel cell lines or novel compounds, we left cell lines originating from the same tissue and each compound out as the test sets, respectively, and the rest as training sets. The performance was comparable to other methods.","","","10.1109/TCBB.2019.2919581","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8723620","Deep Learning;Cancer Cell Lines;Drug Sensitivity;Autoencoder;Predictive models","Drugs;Cancer;Compounds;Computer architecture;Bioinformatics;Sensitivity;Microprocessors","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Analysis-Synthesis Learning with Shared Features: Algorithms for Histology Image Classification","X. Li; V. Monga; U. A. Rao","Electrical Engineering, Pennsylvania State University, 8082 State College, Pennsylvania United States 16802 (e-mail: xul76@psu.edu); Electrical Engineering, Pennsylvania State University, 8082 University Park, Pennsylvania United States (e-mail: vmonga@engr.psu.edu); Department of Computational Medicine & Bioinformatics, as well as Radiation Oncology, University of Michigan, Ann Arbor, Michigan United States (e-mail: ukarvind@umich.edu)","IEEE Transactions on Biomedical Engineering","","2019","PP","99","1","1","Objective: The diversity of tissue structure in histopathological images makes feature extraction for classification a challenging task. Dictionary learning within a sparse representation-based classification (SRC) framework has been shown to be successful for feature discovery. However, there exist stiff practical challenges: 1) computational complexity of SRC can be onerous in the decision stage since it involves solving a sparsity constrained optimization problem and often over a large number of image patches, and 2) images from distinct classes continue to share several geometric features. We propose a novel Analysis-synthesis model Learning with Shared Features algorithm (ALSF) for classifying such images more effectively. Methods: In ALSF, a joint analysis and synthesis learning model is introduced to learn the classifier and the feature extractor at the same time. Unlike SRC, no explicit optimization is needed in the inference phase leading to much reduced computation. Crucially, we introduce the learning of a low rank shared dictionary and a shared analysis operator, which more accurately represents both similarities and differences in histopathological images from distinct classes. We also develop an extension of ALSF with a sparsity constraint, whose presence or absence facilitates a cost-performance trade-off. Results: ALSF is evaluated on three challenging and well-known datasets: (1) spleen tissue images, (2) brain tumor images, and (3) Breast Cancer Tissue dataset provided by different organizations. Conclusion: Experimental results demonstrate both complexity and performance benefits of ALSF over state-of-the-art alternatives. Significance: Modeling shared features with appropriate quantitative constraints leads to significantly improved classification in histopathology.","","","10.1109/TBME.2019.2928997","American Cancer Society Grant; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8764410","Histopathological image classification;Analysis and Synthesis learning model;Shared features learning","Feature extraction;Analytical models;Dictionaries;Optimization;Cancer;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"E-LSTM-D: A Deep Learning Framework for Dynamic Network Link Prediction","J. Chen; J. Zhang; X. Xu; C. Fu; D. Zhang; Q. Zhang; Q. Xuan","Institute of Cyberspace Security, College of Information Engineering, Zhejiang University of Technology, Hangzhou 310023, China, and also with the Big Search in Cyberspace Research Center, Zhejiang Laboratory, Hangzhou 311121, China.; Institute of Cyberspace Security, College of Information Engineering, Zhejiang University of Technology, Hangzhou 310023, China.; Institute of Cyberspace Security, College of Information Engineering, Zhejiang University of Technology, Hangzhou 310023, China.; Institute of Cyberspace Security, College of Information Engineering, Zhejiang University of Technology, Hangzhou 310023, China.; Institute of Cyberspace Security, College of Information Engineering, Zhejiang University of Technology, Hangzhou 310023, China.; School of Data Science, City University of Hong Kong, Hong Kong.; Big Search in Cyberspace Research Center, Zhejiang Laboratory, Hangzhou 311121, China, and also with the Institute of Cyberspace Security, College of Information Engineering, Zhejiang University of Technology, Hangzhou 310023, China (e-mail: xuanqi@zjut.edu.cn).","IEEE Transactions on Systems, Man, and Cybernetics: Systems","","2019","PP","99","1","14","Predicting the potential relations between nodes in networks, known as link prediction, has long been a challenge in network science. However, most studies just focused on link prediction of static network, while real-world networks always evolve over time with the occurrence and vanishing of nodes and links. Dynamic network link prediction (DNLP) thus has been attracting more and more attention since it can better capture the evolution nature of networks, but still most algorithms fail to achieve satisfied prediction accuracy. Motivated by the excellent performance of long short-term memory (LSTM) in processing time series, in this article, we propose a novel encoder-LSTM-decoder (E-LSTM-D) deep learning model to predict dynamic links end to end. It could handle long-term prediction problems, and suits the networks of different scales with fine-tuned structure. To the best of our knowledge, it is the first time that LSTM, together with an encoder-decoder architecture, is applied to link prediction in dynamic networks. This new model is able to automatically learn structural and temporal features in a unified framework, which can predict the links that never appear in the network before. The extensive experiments show that our E-LSTM-D model significantly outperforms newly proposed DNLP methods and obtain the state-of-the-art results.","","","10.1109/TSMC.2019.2932913","National Natural Science Foundation of China; Zhejiang Provincial Natural Science Foundation of China; Zhejiang Science and Technology Plan Project; Key Technologies System and Application of Cyberspace Big Search Major Project of Zhejiang Laboratory; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8809903","Dynamic network;encoder-decoder;link prediction;long short-term memory (LSTM);network embedding","Predictive models;Deep learning;Cyberspace;Heuristic algorithms;Decoding;Security;Matrix decomposition","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Research on Sea Clutter Reflectivity Using Deep Learning Model in Industry 4.0","L. Ma; J. Wu; J. Zhang; Z. Wu; G. Jeon; Y. Zhang; T. Wu","Xi'an China 710071 (e-mail: maliwnn@163.com); School of Electronic Engineering, Xidian University, 47905 Xian, Shaanxi China 710071 (e-mail: wujj@mail.xidian.edu.cn); School of Electronic Engineering, Xidian University, 47905 Xian, Shaanxi China 710071 (e-mail: Jinpeng.Zhang1@gmail.com); Xi;an China 710071 (e-mail: wuzhs@mail.xidian.edu.cn); Department of Embedded Systems Engineering, Incheon National University, Incheon Korea (the Republic of) 442709 (e-mail: ggjeon@gmail.com); School of Electronic Engineering, Xidian University, 47905 Xian, Shaanxi China 710071 (e-mail: Yushi.Zhang1@gmail.com); School of Electronic Engineering, Xidian University, 47905 Xian, Shaanxi China 710071 (e-mail: Tao.Wu1@gmail.com)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","The study of sea clutter reflectivity plays an essential role in radar performance evaluations in the military industry. The industrial bodies are trying to apply the sea clutter intelligent processing technology to the radar system with the form of the Internet of Things and Industry 4.0. Many sea clutter reflectivity models that have been proposed are difficult to fully adapt to the surrounding seas and different radar systems in China. This paper proposes a method named the NRL-based multi-source input neural network (NRL-MSINN) to predict sea clutter reflectivity on sea clutter data collected by UHF-band radar. The radar continuously acquires sea clutter data containing various disturbances, which provides a source of sea clutter reflectivity data for the training of the NRL-MSINN. In the face of the challenges of preprocessing and storage of measured sea clutter big data, this paper proposes a sea clutter preprocessing scheme based on the Yolov3-tiny model. Experimental results show that the average detection precision of sea clutter Range-Pulse images is 75.3% and the extraction time of effective region in sea clutter Range-Pulse image is 0.003642 seconds, which can meet the requirement of real-time detection and data requirement of predicting sea clutter reflectivity based on the NRL-MSINN. Compared with the traditional empirical model, the NRL-MSINN reduced the prediction error of sea clutter reflectivity by 1.82dB, which improves the prediction accuracy and is more suitable for the Yellow Sea in China.","","","10.1109/TII.2019.2957379","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8919977","Industry 4.0;sea clutter reflectivity;NRL-MSINN;Deep learning;Big data;Effective region detection","Clutter;Reflectivity;Radar clutter;Radar antennas;Electromagnetic scattering;Machine learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Reinforcement Learning Based Mobility–Aware Robust Proactive Resource Allocation in Heterogeneous Networks","J. Li; X. Zhang; J. Zhang; J. Wu; Q. Sun; Y. Xie","Wireless Signal Processing and Network Laboratory, Beijing University of Posts and Communications, Beijing, 100876, P.R.China.; Wireless Signal Processing and Network Laboratory, Beijing University of Posts and Communications, Beijing, 100876, P.R.China.; Wireless Signal Processing and Network Laboratory, Beijing University of Posts and Communications, Beijing, 100876, P.R.China.; Green Communication Research Center of the China Mobile Research Institute.; Green Communication Research Center of the China Mobile Research Institute.; Green Communication Research Center of the China Mobile Research Institute.","IEEE Transactions on Cognitive Communications and Networking","","2019","PP","99","1","1","Proactive resource allocation (PRA) is an essential technology boosting intelligent communication, as it can make full use of prediction and significantly improve network performance. However, most promising gains base on perfect prediction which is unrealistic. How to make PRA robust against prediction uncertainty and maximize benefits brought by prediction becomes an important issue. In this paper, we tackle this problem and propose a mobility–aware robust PRA approach (MRPRA) in heterogeneous networks. MRPRA pre–allocates resources in both time and frequency domains among mobile users with users’ trajectories predicted by hidden Markov model. The objective is to minimize service delay under constraints of different levels of quality–of–service (QoS) requirement and mobility intensity. MRPRA is robust against prediction uncertainty by exploiting probabilistic constraint programming to model QoS requirements in a probabilistic sense. To this end, the probabilistic distribution of achievable rate is derived. To flexibly coordinate resource allocation among multiple mobile users over time horizon, a deep reinforcement learning based multi–actor deep deterministic policy gradient algorithm is designed. It learns robust PRA policies by distributed acting and centralized criticizing. Extensive numerical simulations are performed to analyze performances of the proposed approach.","","","10.1109/TCCN.2019.2954396","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8906135","Heterogeneous networks;proactive resource allocation;mobility prediction;deep reinforcement learning;robustness.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Deep-Learning Approach for Automatic Counting of Soybean Insect Pests","E. C. Tetila; B. B. Machado; G. V. Menezes; N. A. de Souza Belete; G. Astolfi; H. Pistori","Faculdade de Ciências Exatas e Tecnologia, Universidade Federal da Grande Dourados, Dourados 79825-070, Brazil.; Department of Computer Science, Federal University of Mato Grosso do Sul, Campo Grande 79906032, Brazil.; College of Computing, Universidade Federal de Mato Grosso do Sul, Campo Grande 79070-900, Brazil.; Department of Production Engineering, Universidade Federal de Rondonia, Cacoal 76962384, Brazil.; College of Computing, Universidade Federal de Mato Grosso do Sul, Campo Grande 79070-900, Brazil.; INOVISÃO, Universidade Catolica Dom Bosco, Campo Grande 79117-900, Brazil.","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","The occurrence of insect pest attacks in soybean fields has worried farmers around the world. Early and automatic diagnosis of insect pests number could assess the infestation level of each plantation area to optimize the applications of pesticides in the crop and, consequently, reduce production costs and environmental impact. Recent research on insect count has adopted deep neural networks. However, researches have employed models trained to count only one species of insect, using images captured in a controlled environment, quite different from a real scenario. In order to obtain high accuracy, we evaluated three models of convolutional neural networks (CNNs) with three different training strategies: 100% fine-tuning with the weights obtained from ImageNet, a complete network with the weights initialized randomly and transfer learning with the weights obtained from ImageNet. Data augmentation and dropout were used during network training to reduce overfitting and increase generalization of the model. Our approach consists in segmenting an image from the plantation with the simple linear iterative clustering (SLIC) method and classifying each superpixel segment into a pest insect class using the CNN-trained classification model. The pest insect count is obtained by adding the insects of each superpixel class identified by our computer vision system. The results indicate that the deep-learning models can be used successfully to support specialists and farmers in the insect pest management in soybean fields.","","","10.1109/LGRS.2019.2954735","Scientific and Technological Development CNPq; Coordination for the Improvement of Higher Education Personnel CAPES; NVIDIA Corporation and Foundation to Support the Development of Teaching Science and Technology of the state of MS FUNDECT; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8926371","Deep-learning;precision agriculture;soybean insect pests.","Insects;Image segmentation;Training;Computer vision;Agriculture;Image color analysis;Inspection","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Urban Land Use and Land Cover Change Prediction via Self-Adaptive Cellular Based Deep Learning With Multisourced Data","L. Mu; L. Wang; Y. Wang; X. Chen; W. Han","College of Life Sciences and Oceanography, Shenzhen University, Shenzhen, Guangdong, China, and also with the Southern Marine Science and Engineering Guangdong Laboratory (Guangzhou), Guangzhou, China (e-mail: moulin1977@hotmail.com).; School of Computer Science, China University of Geosciences, Wuhan 430074, China (e-mail: lizhe.wang@gmail.com).; School of Computer Science, China University of Geosciences, Wuhan 430074, China (e-mail: yuewei.w@yahoo.com).; School of Computer Science, China University of Geosciences, Wuhan 430074, China (e-mail: cxdao@yahoo.com).; School of Computer Science, China University of Geosciences, Wuhan 430074, China (e-mail: weihan@cug.edu.cn).","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2019","PP","99","1","15","The urban sustainable development becomes an essential goal presented in “2030 Agenda for Sustainable development” by the United Nations. Urban land use and land cover (LULC) change prediction, which is a significant indicator to evaluate urban construction strategy, urges to be solved. Remote sensing technique and neural network, are two practical tools widely utilized in urban LULC change prediction. Because of the rapid improvement of remote sensing technique, urban data can be periodically captured in a short time interval. A large amount of data cause the conventional neural networks method having bad efficiency in dealing with it. Moreover, as human activities are in high intensity in the urban area, society related factors require to be taken into consideration in urban land change trend prediction. In this article, a self-adaptive cellular-based deep learning analysis method by utilizing the multisourced data is proposed for urban LULC change prediction. Multisourced data, including weather related data, economy related data, construction related data, and remote sensing data, are normalized and formalized by the proposed self-adaptive cellular-based method. Deep learning long short term memory neural network, which is an advanced model of recurrent neural network and has a strong ability in dealing with sequence data, is utilized to urban LULC change prediction. Remote sensing data captured from 1984 to 2016 are utilized to conduct experiments. Experiment results illustrate that the proposed method can effectively and efficiently make LULC change prediction, and the accuracy is up to $\text{93.1}\text{\%}$.","","","10.1109/JSTARS.2019.2956318","National Natural Science Foundation of China; National Key Research and Development Program of China; Shenzhen Science and Technology; Marine Economy Development; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8936894","Deep learning;long short term memory (LSTM) neural network;remote sensing;self-adaptive cellular-based method;urban land use and land cover (LULC) change prediction","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Robust Interpretable Deep Learning for Intelligent Fault Diagnosis of Induction Motors","F. B. Abid; M. Sallem; A. Braham","Matériaux, Mesures et Applications (MMA) laboratory, National Institute of Applied Sciences and Technology (INSAT), Tunis 1080, Tunisia.; Matériaux, Mesures et Applications (MMA) laboratory, National Institute of Applied Sciences and Technology (INSAT), Tunis 1080, Tunisia.; University of Carthage and the MMA laboratory, Tunis 1054, Tunisia.","IEEE Transactions on Instrumentation and Measurement","","2019","PP","99","1","1","In modern manufacturing processes, motivations for automatic Fault Diagnosis (FD) are increasingly growing as a result of the great trends toward achieving zero breakdowns. Induction Motors (IM) represent a critical part in most of the applications. Due to its high potential of automatic feature extraction, the Deep Learning (DL)-based FD of IM has recently been introduced, and has essentially emphasized on the diagnosis using the vibration analysis. However, this approach has not received considerable attention when using the current analysis, although it represents a cost-effective alternative. Moreover, the already implemented DL architectures are still suffering from lack of physical interpretability. In this paper, a new DL architecture called Deep-SincNet is implemented for a multi- FD task. The proposed end-to-end scheme automatically learns the fault features from the raw motor current and accordingly finalizes the FD process. A high accuracy for several separated and combined faults, a more physical interpretability, a high robustness against noisy environments and a significant gain in implementation cost prove the competitive performance of the proposed approach.","","","10.1109/TIM.2019.2932162","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8782837","Bearing Fault;Broken rotor bar;Combined Faults;Condition Monitoring;Convolutional Neural Network;Current Analysis;Deep Learning;Induction Motor","Feature extraction;Induction motors;Filter banks;Convolution;Rotors;Bars;Digital filters","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Identity-Preserving Face Hallucination via Deep Reinforcement Learning","X. Cheng; J. Lu; B. Yuan; J. Zhou","Graduate School at Shenzhen, Tsinghua University, Shenzhen, 518055.; State Key Lab of Intelligent Technologies and Systems, Beijing Research Center for Information Science and Technology (BNRist), Department of Automation, Tsinghua University, Beijing, 100084, China.; Graduate School at Shenzhen, Tsinghua University, Shenzhen, 518055.; State Key Lab of Intelligent Technologies and Systems, Beijing Research Center for Information Science and Technology (BNRist), Department of Automation, Tsinghua University, Beijing, 100084, China.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","In this paper, we propose an identity-preserving face hallucination (IPFH) method via deep reinforcement learning. Most existing methods ultra-resolve facial visual information in guidance of appearance similarity which rarely attend to recovering the semantic property, undermining further face analysis (e.g., recognition). We present a visualsemantic hallucinator relying on deep reinforcement learning to adaptively repair local details for the restoration of both identity and appearance characteristics. Specifically, we first capture the facial global topology structure to roughly recover the visual information with the pixel-wise similarity constraint. To super-resolve more photo-realistic faces, we explore the contextual interdependency to reconstruct facial local textural details (e.g., over-smoothed edges) with the constraints of visual and identity similarity. In terms of the visual similarity constraint, we develop the dual domain network with bidirectional consistency on both HR domain and LR domain to improve the appearance quality. Moreover, we introduce the identity constraint to encourage hallucinated faces to satisfy the identity property. Experimental results on several benchmarks demonstrate our method achieves promising performance on the recovery of visual and semantic information.","","","10.1109/TCSVT.2019.2961629","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8939465","Face hallucination;deep reinforcement learning;visual-semantic hallucinator;dual consistency;identity property","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Optimal VNF Placement via Deep Reinforcement Learning in SDN/NFV-Enabled Networks","J. Pei; P. Hong; M. Pan; J. Liu; J. Zhou","department of Electronic Engineering and Information Science, University of Science and Technology of China, Hefei 230027, China.; department of Electronic Engineering and Information Science, University of Science and Technology of China, Hefei 230027, China.; Department of Electrical and Computer Engineering, University of Houston, Houston, TX 77004, USA.; Department of Electrical and Computer Engineering, University of Alabama in Huntsville, Huntsville, AL 35899, USA.; department of Electronic Engineering and Information Science, University of Science and Technology of China, Hefei 230027, China.","IEEE Journal on Selected Areas in Communications","","2019","PP","99","1","1","The emerging paradigm - Software-Defined Networking (SDN) and Network Function Virtualization (NFV) - makes it feasible and scalable to run Virtual Network Functions (VNFs) in commercial-off-the-shelf devices, which provides a variety of network services with reduced cost. Benefitting from centralized network management, lots of information about network devices, traffic and resources can be collected in SDN/NFV-enabled networks. Using powerful machine learning tools, algorithms can be designed in a customized way according to the collected information to efficiently optimize network performance. In this paper, we study the VNF placement problem in SDN/NFV-enabled networks, which is naturally formulated as a Binary Integer Programming (BIP) problem. Using deep reinforcement learning, we propose a Double Deep Q Networkbased VNF Placement Algorithm (DDQN-VNFPA). Specifically, DDQN determines the optimal solution from a prohibitively large solution space and DDQN-VNFPA then places/releases VNF Instances (VNFIs) following a threshold-based policy. We evaluate DDQN-VNFPA with trace-driven simulations on a realworld network topology. Evaluation results show that DDQNVNFPA can get improved network performance in terms of the reject number and reject ratio of Service Function Chain Requests (SFCRs), throughput, end-to-end delay, VNFI running time and load balancing compared with the algorithms in existing literatures.","","","10.1109/JSAC.2019.2959181","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8932445","Software-Defined Networking;Network Function Virtualization;VNF Placement;Deep Reinforcement Learning","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"An Advanced Deep Generative Framework for Temporal Link Prediction in Dynamic Networks","M. Yang; J. Liu; L. Chen; Z. Zhao; X. Chen; Y. Shen","Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen 518055, China.; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen 518055, China, and also with the University of Chinese Academy of Sciences, Beijing 100049, China.; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen 518055, China, and also with the University of Chinese Academy of Sciences, Beijing 100049, China.; School of Computing Science, Zhejiang University, Hangzhou 310007, China.; College of Computer Science and Software, Shenzhen University, Shenzhen 518060, China.; School of Electronics and Computer Engineering, Peking University Shenzhen Graduate School, Shenzhen 518000, China (e-mail: shenying@pkusz.edu.cn).","IEEE Transactions on Cybernetics","","2019","PP","99","1","12","Temporal link prediction in dynamic networks has attracted increasing attention recently due to its valuable real-world applications. The primary challenge of temporal link prediction is to capture the spatial-temporal patterns and high nonlinearity of dynamic networks. Inspired by the success of image generation, we convert the dynamic network into a sequence of static images and formulate the temporal link prediction as a conditional image generation problem. We propose a novel deep generative framework, called NetworkGAN, to tackle the challenging temporal link prediction task efficiently, which simultaneously models the spatial and temporal features in the dynamic networks via deep learning techniques. The proposed NetworkGAN inherits the advantages of the graph convolutional network (GCN), the temporal matrix factorization (TMF), the long short-term memory network (LSTM), and the generative adversarial network (GAN). Specifically, an attentive GCN is first designed to automatically learn the spatial features of dynamic networks. Second, we propose a TMF enhanced attentive LSTM (TMF-LSTM) to capture the temporal dependencies and evolutionary patterns of dynamic networks, which predicts the network snapshot at next timestamp based on the network snapshots observed at previous timestamps. Furthermore, we employ a GAN framework to further refine the performance of temporal link prediction by using a discriminative model to guide the training of the deep generative model (i.e., TMF-LSTM) in an adversarial process. To verify the effectiveness of the proposed model, we conduct extensive experiments on five real-world datasets. Experimental results demonstrate the significant advantages of NetworkGAN compared to other strong competitors.","","","10.1109/TCYB.2019.2920268","Shenzhen Institutes of Advanced Technology SIAT Innovation Program for Excellent Young Researchers; Natural Science Foundation of Guangdong Province of China; CCF Tencent Open Research Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8736786","Deep generative model;generative adversarial network (GAN);temporal link prediction","Predictive models;Generative adversarial networks;Deep learning;Feature extraction;Gallium nitride;Complex networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"RFID-Driven Energy-Efficient Control Approach of CNC Machine Tools Using Deep Belief Networks","C. Zhang; P. Jiang","Department of State Key Laboratory for Manufacturing Systems Engineering, Xi'an Jiaotong University, Xi'an 710049, China.; Department of State Key Laboratory for Manufacturing Systems Engineering, Xi'an Jiaotong University, Xi'an 710049, China (e-mail: pjiang@mail.xjtu.edu.cn).","IEEE Transactions on Automation Science and Engineering","","2019","PP","99","1","13","Under the consideration of massive energy consumption of machine tools, many approaches have been proposed, and state control method of machine tools has proved its effectiveness. In order to satisfy the demand of real-time production control, a deep learning methodology for energy-efficient control of CNC machine tools is proposed in RFID-enabled ubiquitous environment. First, the energy-efficient control strategies for multiple machine tools are proposed to reduce the carbon emission of the machining process. Then, through evaluating the process progress in the RFID-enabled environment, a deep learning methodology for energy-efficient strategies selection of CNC machine tools using deep belief networks (DBNs) is established to realize the real-time and accurate control of machine tools. Finally, comparisons between the proposed approach and some state-of-the-art ones are given, and the experiment results indicate that the proposed method is effective and efficient for the energy-efficient control problem of machine tools. The proposed method can realize the real-time control of CNC machine tools based on the interaction information in Industrial 4.0. Furthermore, the machine tools will be converted to smart machines, which can complete self-perception and self-adjustment automatically.","","","10.1109/TASE.2019.2909043","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8694932","CNC machine tools;deep belief networks (DBNs);energy-efficient control strategies;RFID.","Machine tools;Radiofrequency identification;Deep learning;Real-time systems;Manufacturing;Process control","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Salient Object Detection via Multiple Instance Joint Re-Learning","G. Ma; C. Chen; S. Li; C. Peng; H. Qin; A. Hao","school of computer science and engineering, Beihang University, 12633 Beijing, Beijing China 100083 (e-mail: mgx@buaa.edu.cn); Computer Science, Beihang University, beijing China 100191 (e-mail: cclz123@163.com); Computer Science and Engineering School, Beihang University, Beijing China 100191 (e-mail: lishuai@buaa.edu.cn); College of Computer Science and Technology, Qingdao University, Qingdao, Shandong China 266000 (e-mail: pchong1991@163.com); Computer Science, Stony Brook University, 12301 Stony Brook, New York United States (e-mail: qin@cs.stonybrook.edu); Computer Science, State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing, Beijing China (e-mail: ham@buaa.edu.cn)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","In recent years deep neural networks have been widely applied to visual saliency detection tasks with remarkable detection performance improvements. As for the salient object detection in single image, the automatically computed convolutional features frequently demonstrate high discriminative power to distinguish salient foregrounds from its non-salient surroundings in most cases. Yet, the obstinate feature conflicts still persist, which naturally gives rise to the learning ambiguity, arriving at massive failure detections. To solve such problem, we propose to jointly re-learn common consistency of inter-image saliency and then use it to boost the detection performance. Its core rationale is to utilize the easy-to-detect cases to re-boost much harder ones. Compared with the conventional methods which focus on their problem domain within the single image scope, our method attempts to utilize those beyond-scope information to facilitate the current salient object detection. To validate our new approach, we have conducted a comprehensive quantitative comparisons between our approach and 13 state-of-the-art methods over 5 publicly available benchmarks, and all the results suggest the advantage of our approach in terms of accuracy, reliability, and versatility.","","","10.1109/TMM.2019.2929943","National Key R and D Program of China; National Science Foundation of USA; National Natural Science Foundation of China; Natural Science Foundation of Shandong Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8768013","Salient Object Detection;Inter-image Correspondence;Multiple Instance Learning;Joint Re-Learning","Feature extraction;Object detection;Saliency detection;Visualization;Deep learning;Correlation;Topology","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"An Incremental Construction of Deep Neuro Fuzzy System for Continual Learning of Non-stationary Data Streams","M. Pratama; W. Pedrycz; G. I. Webb","School of Computer Science and Engineering, Nanyang Technological University, 54761 Singapore Singapore 639798 (e-mail: pratama@ieee.org); Electrical and Computer Engineering Department, University of Alberta, Edmonton, Alberta Canada T6G 2G6 (e-mail: wpedrycz@ualberta.ca); Faculty of Information Technology, Monash University, Melbourne, Victoria Australia (e-mail: geoff.webb@monash.edu)","IEEE Transactions on Fuzzy Systems","","2019","PP","99","1","1","Existing fuzzy neural networks (FNNs) are mostly developed under a shallow network configuration having lower generalization power than those of deep structures. This paper proposes a novel self-organizing deep fuzzy neural network, namely deep evolving fuzzy neural networks (DEVFNN). Fuzzy rules can be automatically extracted from data streams or removed if they play little role during their lifespan. The structure of the network can be deepened on demand by stacking additional layers using a drift detection method which not only detects the covariate drift, variations of input space, but also accurately identifies the real drift, dynamic changes of both feature space and target space. DEVFNN is developed under the stacked generalization principle via the feature augmentation concept where a recently developed algorithm, namely Generic Classifier (gClass), drives the hidden layer. It is equipped by an automatic feature selection method which controls activation and deactivation of input attributes to induce varying subsets of input features. A deep network simplification procedure is put forward using the concept of hidden layer merging to prevent uncontrollable growth of input space dimension due to the nature of feature augmentation approach in building a deep network structure. DEVFNN works in the sample-wise fashion and is compatible for data stream applications. The efficacy of DEVFNN has been thoroughly evaluated using seven datasets with non-stationary properties under the prequential test-then-train protocol. It has been compared with four state-of-the art data stream methods and its shallow counterpart where DEVFNN demonstrates improvement of classification accuracy. Moreover, it is also shown that the concept drift detection method is an effective tool to control the depth of network structure while the hidden layer merging scenario is capable of simplifying the network complexity of a deep network with negligible compromise of generalization performance.","","","10.1109/TFUZZ.2019.2939993","Nanyang Technological University; Ministry of Education - Singapore; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8826232","Deep Neural Networks;Data Streams;Online Learning;Fuzzy Neural Network","Fuzzy neural networks;Merging;Feature extraction;Buildings;Complexity theory;Training;Network architecture","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Cross-Modal Material Perception for Novel Objects: A Deep Adversarial Learning Method","W. Zheng; H. Liu; B. Wang; F. Sun","State Key Laboratory of Reliability and Intelligence of Electrical Equipment, Key Laboratory of Electromagnetic Field and Electrical Apparatus Reliability of Hebei Province, School of Electrical Engineering, Hebei University of Technology, Tianjin 300130, China.; Department of Computer Science and Technology, State Key Laboratory of Intelligent Technology and Systems, Beijing National Research Center for Information Science and Technology, Tsinghua University, Beijing 100084, China (e-mail: hpliu@tsinghua.edu.cn).; State Key Laboratory of Reliability and Intelligence of Electrical Equipment, Key Laboratory of Electromagnetic Field and Electrical Apparatus Reliability of Hebei Province, School of Electrical Engineering, Hebei University of Technology, Tianjin 300130, China.; Department of Computer Science and Technology, State Key Laboratory of Intelligent Technology and Systems, Beijing National Research Center for Information Science and Technology, Tsinghua University, Beijing 100084, China.","IEEE Transactions on Automation Science and Engineering","","2019","PP","99","1","11","To more actively perform fine manipulation tasks in the real world, intelligent robots should be able to understand and communicate the physical attributes of the material during interaction with an object. Tactile and vision are two important sensing modalities in robotic perception system. In this article, we propose a cross-modal material perception framework for recognizing novel objects. Concretely, it first adopts an object-agnostic method to associate information from tactile and visual modalities. It then recognizes a novel object by using its tactile signal to retrieve perceptually similar surface material images through the learned cross-modal correlation. This problem exhibits a challenge because data from visual and tactile modalities are highly heterogeneous and weakly paired. Moreover, the framework should not only consider cross-modal pairwise relevance but also be discriminative and generalized for unseen objects. To this end, we propose a weakly paired cross-modal adversarial learning (WCMAL) model for the visual-tactile cross-modal retrieval, which combines the advantages of deep learning and adversarial learning. In particular, the model fully considers the weak pairing problem between the two modalities. Finally, we conduct verification experiments on a publicly available data set. The results demonstrate the effectiveness of the proposed method.","","","10.1109/TASE.2019.2941230","National Basic Research Program of China (973 Program); National Natural Science Foundation of China; Key Project of Natural Science Foundation of Hebei Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8863640","Cross-modal perception;deep adversarial learning;material recognition.","Material properties;Robot sensing systems;Visualization;Object recognition;Measurement","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Visual Object Tracking via Multi-Stream Deep Similarity Learning Networks","K. Li; Y. Kong; Y. Fu","Department of Electrical and Computer Engineering, College of Engineering, Northeastern University, Boston, MA, 02115.; B. Thomas Golisano College of Computing and Information Sciences, Rochester Institute of Technology, Rochester, NY, 14623.; Department of Electrical and Computer Engineering, College of Engineering, and Khoury College of Computer Science, Northeastern University, Boston, MA, 02115.","IEEE Transactions on Image Processing","","2019","PP","99","1","1","Visual tracking remains a challenging research problem because of appearance variations of the object over time, changing cluttered background and requirement for real-time speed. In this paper, we investigate the problem of real-time accurate tracking in a instance-level tracking-by-verification mechanism. We propose a multi-stream deep similarity learning network to learn a similarity comparison model purely off-line. Our loss function encourages the distance between a positive patch and the background patches to be larger than that between the positive patch and the target template. Then, the learned model is directly used to determine the patch in each frame that is most distinctive to the background context and similar to the target template. Within the learned feature space, even if the distance between positive patches becomes large caused by the interference of background clutter, impact from hard distractors from the same class or the appearance change of the target, our method can still distinguish the target robustly using the relative distance. Besides, we also propose a complete framework considering the recovery from failures and the template updating to further improve the tracking performance without taking too much computing resource. Experiments on visual tracking benchmarks show the effectiveness of the proposed tracker when comparing with several recent real-time-speed trackers as well as trackers already included in the benchmarks.","","","10.1109/TIP.2019.2959249","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8935511","Deep Learning;Visual Tracking","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Adaptive Online Decision Method for Initial Congestion Window in 5G Mobile Edge Computing using Deep Reinforcement Learning","R. Xie; X. Jia; K. Wu","College of Computer Science and Software Engineering, Shenzhen University, China.; College of Computer Science and Software Engineering, Shenzhen University, China and PCL Research Center of Networks and Communications, Peng Cheng Laboratory, Shenzhen, China.; Department of Computer Science, City University of Hong Kong, Hong Kong, China.","IEEE Journal on Selected Areas in Communications","","2019","PP","99","1","1","Mobile edge computing provides users with low response time and avoids unnecessary data transmission. Due to the deployment of 5G, the emerging edge systems can provide gigabit bandwidth. However, network protocols have not evolved together. In TCP, the initial congestion window (IW) is such a low value that most short flows still stay in slow start phase when finishing, and do not fully utilize available bandwidth. Naively increasing IW may result in congestion, which causes long latency. Moreover, since the network environment is dynamic, we have a challenging problem—how to adaptively adjust IW such that flow completion time is optimized, while congestion is minimized. In this paper, we propose an adaptive online decision method to solve the problem, which learns the best policy using deep reinforcement learning stably and fast. In addition, we propose an approach to further improve the performance by supervised learning, using data collected during online learning. We also propose to adopt SDN to address the challenges in implementing our method in MEC systems. To evaluate our method, we build an MEC simulator based on ns3. Our simulations demonstrate that our method performs better than existing methods. It can effectively reduce FCT with little congestion caused.","","","10.1109/JSAC.2019.2959187","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8944075","congestion control;initial congestion window;deep reinforcement learning;mobile edge computing;software-defined networking","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Metric Learning with Density Adaptivity","Y. Li; T. Yao; Y. Pan; H. Chao; T. Mei","School of Data Science and Computer, Sun Yat-Sen University, Guangzhou, GUANGDONG China 510275 (e-mail: yehaoli.sysu@gmail.com); Computer Vision and Multimedia Lab, JD AI Research, Beijing China (e-mail: tingyao.ustc@gmail.com); Computer Vision and Multimedia Lab, JD AI Research, Beijing China (e-mail: panyw.ustc@gmail.com); School of Data Science and Computer, Sun Yat-Sen University, Guangzhou, Guangdong China 510006 (e-mail: isschhy@mail.sysu.edu.cn); Computer Vision and Multimedia Lab, JD AI Research, Beijing, Beijing China 100105 (e-mail: tmei@live.com)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","The problem of distance metric learning is mostly considered from the perspective of learning an embedding space, where the distances between pairs of examples are in correspondence with a similarity metric. With the rise and success of Convolutional Neural Networks (CNN), deep metric learning (DML) involves training a network to learn a nonlinear transformation to the embedding space. Existing DML approaches often express the supervision through maximizing inter-class distance and minimizing intra-class variation. However, the results can suffer from overfitting problem, especially when the training examples of each class are embedded together tightly and the density of each class is very high. In this paper, we integrate density, i.e., the measure of data concentration in the representation, into the optimization of DML frameworks to adaptively balance inter-class similarity and intra-class variation by training the architecture in an end-to-end manner. Technically, the knowledge of density is employed as a regularizer, which is pluggable to any DML architecture with different objective functions such as contrastive loss, N-pair loss and triplet loss. Extensive experiments on three public datasets consistently demonstrate clear improvements by amending three types of embedding with the density adaptivity. More remarkably, our proposal increases Recall@1 from 67.95% to 77.62%, from 52.01% to 55.64% and from 68.20% to 70.56% on Cars196, CUB-200-2011 and Stanford Online Products dataset, respectively.","","","10.1109/TMM.2019.2939711","Guangzhou Science and Technology Program China; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8825545","Deep Metric Learning;Density Adaptation;Image Retrieval","Measurement;Training;Neural networks;Task analysis;Testing;Image retrieval;Adaptation models","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Transfer Deep Q-Learning Framework for Resource Competition in Virtual Mobile Networks With Energy-Harvesting Base Stations","Q. V. Do; I. Koo","School of Electrical Engineering, University of Ulsan, Ulsan 44610, South Korea (e-mail: vquang.do@gmail.com).; Electrical and Computer Engineering, University of Ulsan, Ulsan 689-749, South Korea (e-mail: iskoo@ulsan.ac.kr).","IEEE Systems Journal","","2019","PP","99","1","12","This article considers the problem of resource sharing in a virtual mobile network with energy-harvesting base stations (BSs), where several virtual mobile operators (VMOs) lease radio resources (e.g., radio channels and green BSs) from a mobile network owner (MNO). The VMOs want to provide subscribed users with the best performance while ensuring minimal leasing costs. We aim to find the optimal resource leasing scheme for a VMO in order to maximize utility within the uncertainties of harvested energy, request arrivals, and resource prices. We first formulate the problem as a Markov decision process, during which the VMOs compete with each other for the radio resources by dynamically announcing their resource requirements to the MNO. We, then, employ a deep Q-learning algorithm so the VMO can find the optimal solution by interacting with the environment. With this algorithm, artificial neural networks are used to approximate the Q-value function, which can work effectively with large state and action spaces. We further employ the idea of transfer learning, which exploits the strategies learned in historical periods to speed up the learning process of the target task. Finally, we present comprehensive simulations to evaluate the performance of the proposed scheme under various configurations.","","","10.1109/JSYST.2019.2958993","National Research Foundation of Korea; Korean Government; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8943313","Deep Q-learning (DQL);energy harvesting;resource sharing;wireless network virtualization (WNV)","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Fuzzy Fixed-Time Learning Control with Saturated Input, Nonlinear Switching Surface and Switching Gain to Achieve Null Tracking Error","C. Hwang; Y. Chen","Electrical Engineering, National Taiwan University of Science and Technology, Taipei Taiwan (e-mail: clhwang@mail.ntust.edu.tw); Mechanical Engineering, Georgia Institute of Technology, Atlanta, Georgia United States 30332 (e-mail: yehwa.chen@me.gatech.edu)","IEEE Transactions on Fuzzy Systems","","2019","PP","99","1","1","A class of generalized nonlinear dynamic systems is first approximated by N fuzzy-based linear subsystems using the identification of input-output data or the linearizing system with respect to suitable operating points. To obtain the null trajectory tracking error in fixed time, a fuzzy fixed-time control (FFTC) with nonlinear switching surface and switching gain is first designed. It can be said that the FFTC is based on a class of passive and distributive models with uncertainties. To compensate enormous uncertainties, a fuzzy fixed-time learning control (FFTLC) by learning two unknown coefficients for the upper bound of uncertainties in each subsystem is designed. As compared with radial basis function neural network, the computational complexity for the compensated uncertainties is much simple. It can be said that an FFTLC is based on a class of on-line active and distributive uncertain models. Due to the fixed-time control design, the transients often occur, particularly for the larger uncertainties or initial tracking error. Hence, the saturated input of nonlinear dynamic system is addressed and on-line compensated. Finally, the compared simulations and application to two-link robot manipulator confirm the effectiveness, robustness and less computation as compared with previous studies.","","","10.1109/TFUZZ.2019.2917121","Ministry of Science and Technology, Taiwan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8715413","Deep learning;fixed-time control;nonlinear switching surface and gain;Lyapunov stability theory;T-S fuzzy model","Computational modeling;Uncertainty;Switches;Nonlinear dynamical systems;Deep learning;Adaptation models","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Cuff-less Deep Learning-Based Blood Pressure Estimation for Smart Wristwatches","K. Song; K. Chung; J. Chang","Department of Electronics and Computer Engineering, Hanyang University, Seoul 04763, South Korea.; Department of Electronics and Computer Engineering, Hanyang University, Seoul 04763, South Korea.; Department of Electronics Engineering, Hanyang University, Seoul 04763, South Korea.","IEEE Transactions on Instrumentation and Measurement","","2019","PP","99","1","1","In this study, we propose a cuff-less blood pressure (BP) estimation technique based on deep learning for smart wristwatches. Photoplethysmography (PPG) and electrocardiography (ECG) signals are first collected from the sensors installed at a smart wristwatch. Ground truth systolic BP (SBP) and diastolic BP (DBP) measurements are then obtained by a reference device, a mercury sphygmomanometer. In order to estimate the SBP and DBP, we extract feature vectors and reconstruct them through a feature selection process. Next, we design two-stage system of a stacked deep neural network (DNN)-based SBP and DBP estimation models and compare our results to those obtained using estimation techniques in the previously reported algorithms such as the polynomial regression (PR), support vector machine (SVM), artificial neural network (ANN), and deep belief network (DBN)-DNN. In order to verify the proposed algorithm against the conventional algorithms, we quantitatively compare the results in terms of mean error (ME) with standard deviation, mean absolute error (MAE) with standard deviation, Pearson correlation, box plot, and Bland-Altman plot. For this, 110 subjects contributed to the database (DB), each of which is collected three times for 20 seconds. The quantitative errors turn out lower compared to the existing methods, which shows the superiority of our approach. To further enhance the BP estimation performance for each individual user, we devise the personal adaptation algorithm for the BP estimation algorithm that yields better the BP estimates.","","","10.1109/TIM.2019.2947103","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8868235","BP estimation;deep learning;smart wristwatch;PPG;ECG;mercury sphygmomanometer;electronic manometer for home","Feature extraction;Electrocardiography;Estimation;Blood pressure;Standards;Intelligent sensors","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Distributed Learning Solution for Uplink Traffic Control in Energy Harvesting Massive Machine-Type Communications","Y. Teng; M. Yan; D. Liu; Z. Han; M. Song","Beijing Key Laboratory of Space-Ground Interconnection and Convergence, BUPT, China.; Beijing Key Laboratory of Space-Ground Interconnection and Convergence, BUPT, China.; Instrumentation Technology and economy Institute, P.R. china.; department of Electrical and Computer Engineering and Computer Science at University of Houston, Houston, U.S.; Beijing Key Laboratory of Space-Ground Interconnection and Convergence, BUPT, China.","IEEE Wireless Communications Letters","","2019","PP","99","1","1","The rapid expansion of Machine Type Communication (MTC) has brought many challenges, such as sporadic uplink transmission congestion and energy consumption of battery limited nodes. To address these challenges, we consider a green energy harvesting massive MTC (mMTC) system that each device is equipped with a local cache and a rechargeable battery to store the collecting data and the green energy harvested from the environment, respectively. Then, an uplink power control method is proposed to regulate the transmission while simultaneously minimizing the system’s delay cost and the battery depreciation cost. The optimization problem with the duplex queueing structure is formulated as a Markov decision process (MDP), and we utilize the Deep Distributed Recurrent Q-networks (DDRQN) algorithm to manage the complex dynamic channel, data, and energy environment through the partially observable state. Our simulation results show that the proposed learning scheme can dramatically reduce the system cost, prolong the lifetime of the mMTC network, and approach the conventional centralized reinforcement learning method.","","","10.1109/LWC.2019.2959583","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8932448","mMTC;traffic control;Deep Distributed Recurrent Q-networks (DDRQN);multi-agent reinforcement learning.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Real-Time Object Detection With Reduced Region Proposal Network via Multi-Feature Concatenation","K. Shih; C. Chiu; J. Lin; Y. Bu","Department of Computer Science, National Tsing Hua University, Hsinchu 30000, Taiwan.; Department of Computer Science, National Tsing Hua University, Hsinchu 30000, Taiwan (e-mail: chiusms@cs.nthu.edu.tw).; Department of Computer Science, National Tsing Hua University, Hsinchu 30000, Taiwan.; Department of Computer Science, National Tsing Hua University, Hsinchu 30000, Taiwan.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","10","In recent years, object detection became more and more important following the successful results from studies in deep learning. Two types of neural network architectures are used for object detection: one-stage and two-stage. In this paper, we analyze a widely used two-stage architecture called Faster R-CNN to improve the inference time and achieve real-time object detection without compromising on accuracy. To increase the computation efficiency, pruning is first adopted to reduce the weights in convolutional and fully connected (FC) layers. However, this reduces the accuracy of detection. To address this loss in accuracy, we propose a reduced region proposal network (RRPN) with dilated convolution and concatenation of multi-scale features. In the assisted multi-feature concatenation, we propose the intra-layer concatenation and proposal refinement to efficiently integrate the feature maps from different convolutional layers; this is then provided as an input to the RRPN. Using the proposed method, the network can find object bounding boxes more accurately, thus compensating for the loss arising from compression. Finally, we test the proposed architecture using ZF-Net and VGG16 as a backbone network on the image sets in PASCAL VOC 2007 or VOC 2012. The results show that we can compress the parameters of the ZF-Net-based network by 81.2% and save 66% of computation. The parameters of VGG16-based network are compressed by 73% and save 77% of computation. Consequently, the inference speed is improved from 27 to 40 frames/s for ZF-Net and 9 to 27 frames/s for VGG16. Despite significant compression rates, the accuracy of ZF-Net is increased from 2.2% to 60.2% mean average precision (mAP) and that of VGG16 is increased from 2.6% to 69.1% mAP.","","","10.1109/TNNLS.2019.2929059","Ministry of Science and Technology MOST Taiwan Optimizing and Compressing Deep Learning Networks With Applications in Computer Vision Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8809351","Multi-feature concatenation;object detection;region proposal network (RPN);weight pruning.","Object detection;Proposals;Convolution;Computer architecture;Feature extraction;Real-time systems;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep CNN-based Real-time Traffic Light Detector for Self-driving Vehicles","J. Niu; Y. Liu; M. Guizani; Z. Ouyang","School of Computer Science, Beihang University, Beijing, Beijing China 100191 (e-mail: niujianwei@buaa.edu.cn); computer science, Beihang University, 12633 Beijing, Beijing China (e-mail: buaa_liuyu@buaa.edu.cn); ECE, University of Idaho, 5640 Moscow, Idaho United States 83844-1023 (e-mail: mguizani@ieee.org); computer science, Beihang University, 12633 Beijing, Beijing China 100083 (e-mail: ouyangkid@gmail.com)","IEEE Transactions on Mobile Computing","","2019","PP","99","1","1","Due to the unavailability of Vehicle-to-Infrastructure (V2I) communication in current transportation systems, Traffic Light Detection (TLD) still is considered an important module in autonomous vehicles and Driver Assistance Systems (DAS). Considering low flexibility and accuracy of vision-based heuristic algorithms and high power consumption of deep learning-based methods, we propose a lightweight and real-time traffic light detector for the autonomous vehicle platform on the basis of previous studies. Our model consists of a heuristic candidate region selection module to identify all possible traffic lights, and a lightweight Convolution Neural Network (CNN) classifier to classify the results obtained. Offline simulations on the GPU server with the collected dataset and several public datasets show that our model achieves higher average accuracy and less time consumption. By integrating our detector module on NVidia Jetson TX1/TX2, we conduct on-road tests on two full scale self-driving vehicle platforms (a car and a bus) in normal traffic conditions. The final model can achieve average detection accuracy of 99.3% (mRttld) and 99.7% (Rttld) at 10Hz on TX1 and TX2, respectively. The on-road tests also show that our traffic light detection module can achieve < ±1.5m errors at stop lines when working with other self-driving modules.","","","10.1109/TMC.2019.2892451","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8611202","Traffic light detection;autonomous vehicle;deep learning;machine learning;dataset","Computational modeling;Feature extraction;Heuristic algorithms;Hidden Markov models;Real-time systems;Machine learning;Detectors","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Non-Negative Matrix Factorization Architecture based on Underlying Basis Images Learning","Y. Zhao; H. Wang; J. Pei","College of Electronics and Information Engineering, Shenzhen University, 47890 Shenzhen, Guangdong China (e-mail: zhaoyangmaths@163.com); College of Mechatronics and Control Engineering, Shenzhen University, 47890 Shenzhen, Guangdong China 518060 (e-mail: 2130090503@email.szu.edu.cn); College of Electronics and Information Engineering, Shenzhen University, 47890 Shenzhen, Guangdong China (e-mail: jhpei@szu.edu.cn)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","The non-negative matrix factorization (NMF) algorithm represents the original image as a linear combination of a set of basis images. This image representation method is in line with the idea of ""parts constitute a whole"" in human thinking. The existing deep NMF performs deep factorization on the coefficient matrix. In these methods, the basis images used to represent the original image is essentially obtained by factorizing the original images once. To extract features reflecting the deep localization characteristics of images, a novel deep NMF architecture based on underlying basis images learning is proposed for the first time. The architecture learns the underlying basis images by deep factorization on the basis images matrix. The deep factorization architecture proposed in this paper has strong interpretability. To implement this architecture, this paper proposes a deep non-negative basis matrix factorization algorithm to obtain the underlying basis images. Then, the objective function is established with an added regularization term, which directly constrains the basis images matrix to obtain the basis images with good local characteristics, and a regularized deep non-negative basis matrix factorization algorithm is proposed. The regularized deep nonlinear non-negative basis matrix factorization algorithm is also proposed to handle pattern recognition tasks with complex data. This paper also theoretically proves the convergence of the algorithm. Finally, the experimental results show that the deep NMF architecture based on the underlying basis images learning proposed in this paper can obtain better recognition performance than the other state-of-the-art methods.","","","10.1109/TPAMI.2019.2962679","Shenzhen Science and Technology Projection; Guangdong Basic and Applied Basic Research Foundation; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8943941","Non-Negative Matrix Factorization;Underlying Basis Images;Deep Factorization Architecture;Face Recognition","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Controller Design for Electrical Drives by Deep Reinforcement Learning - a Proof of Concept","M. Schenke; W. Kirchgässner; O. Wallscheid","Paderborn Germany 33098 (e-mail: mschenke@mail.uni-paderborn.de); Paderborn Germany 33098 (e-mail: kirchgaessner@lea.uni-paderborn.de); Paderborn Germany 33098 (e-mail: wallscheid@lea.uni-paderborn.de)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","This contribution presents a controller design for electrical drives, which makes use of deep reinforcement learning. Despite conventional control methods may lead to solutions with robust and steady results, it can be often found that their performance heavily correlates with the experience of the engineer. Moreover, conventional methods strongly depend on the available knowledge of the system, which often causes the necessity for thorough identification. Real-time capability issues are also a present problem of sophisticated control approaches such as model predictive methods. On the contrary, deep reinforcement learning will not only enable to acquire a suitable controller structure, but moreover the procedure will tune itself, which will allow for a more abstract level of investigation. Hence, this contribution presents a first proof of concept by means of controlling the phase currents of a permanent magnet synchronous motor. The results found are promising and motivate further research.","","","10.1109/TII.2019.2948387","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8877848","Actor-critic;control design;current control;feedforward neural networks;nonlinear control systems;permanent magnet motors;reinforcement learning","Torque;Reinforcement learning;Optimal control;Informatics;Current control;Inverters","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Management and Orchestration of Virtual Network Functions via Deep Reinforcement Learning","J. S. P. Roig; D. M. Gutierrez-Estevez; D. Gündüz","Department of Electrical and Electronic Engineering at Imperial College London, UK.; Samsung Electronics R&D Institute UK, Surrey, TW18 4QE, UK.; Department of Electrical and Electronic Engineering at Imperial College London, UK.","IEEE Journal on Selected Areas in Communications","","2019","PP","99","1","1","Management and orchestration (MANO) of resources by virtual network functions (VNFs) represents one of the key challenges towards a fully virtualized network architecture as envisaged by 5G standards. Current threshold-based policies inefficiently over-provision network resources and under-utilize available hardware, incurring high cost for network operators, and consequently, the users. In this work, we present a MANO algorithm for VNFs allowing a central unit (CU) to learn to autonomously re-configure resources (processing power and storage), deploy new VNF instances, or offload them to the cloud, depending on the network conditions, available pool of resources, and the VNF requirements, with the goal of minimizing a cost function that takes into account the economical cost as well as latency and the quality-of-service (QoS) experienced by the users. First, we formulate the stochastic resource optimization problem as a parameterized action Markov decision process (PAMDP). Then, we propose a solution based on deep reinforcement learning (DRL). More precisely, we present a novel RL approach, called parameterized action twin (PAT) deterministic policy gradient, which leverages an actor-critic architecture to learn to provision resources to the VNFs in an online manner. Finally, we present numerical performance results, and map them to 5G key performance indicators (KPIs). To the best of our knowledge, this is the first work that considers DRL for MANO of VNFs’ physical resources.","","","10.1109/JSAC.2019.2959263","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8932565","Deep reinforcement learning;resource allocation;software defined networks;virtual network functions;wireless edge processing","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Intelligent emotion detection method based on deep learning in medical and health data","J. Xu; Z. Hu; J. Zou; A. Bi","School of Information Science and Engineering, East China University of Science and Technology, Shanghai, 200237, PR China.; School of Microelectronics, Fudan University, Shanghai, 201203, PR China.; School of Information Science and Engineering, East China University of Science and Technology, Shanghai, 200237, PR China.; School of Computer Science and Engineering, Changshu Institute of Technology, Suzhou, Jiangsu, 215500, PR China.","IEEE Access","","2019","PP","99","1","1","Emotional abnormality may be brought out by physiological fatigue. In order to solve the problem, an emotion detection method based on deep learning in medical and health data is proposed in this paper. First of all, the related content of emotional fatigue is studied. The concept and the classification of emotional fatigue are introduced. Then, a multi-modal data emotional fatigue detection system is designed. In the system, multi-channel convolutional aotoencoder neural network is used to extract electrocardiograms (ECG) data features and emotional text features for emotional fatigue detection. Secondly, the network structure of learning ECG features by multi-channel convolutional aotoencoder model is introduced in detail. And the network structure of learning emotional text features by convolutional aotoencoder model is also described in detail. Finally, multi-modal data features are combined for emotional detection. It is shown by the experimental results that the proposed model has an average accuracy of more than 85% in predicting emotional fatigue.","","","10.1109/ACCESS.2019.2961139","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8937486","Emotion detection model;Multi-channel convolutional aotoencoder (MCAE);Medical health;Deep learning;Emotional text features;Intelligent data analysis","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Energy Minimization in D2D-Assisted Cache-Enabled Internet of Things: A Deep Reinforcement Learning Approach","J. Tang; H. Tang; X. Zhang; K. Cumanan; G. Chen; K. Wong; J. Chambers","School of Electronic and Information Engineering, South China University of Technology, 26467 Guangzhou, Guangdong China 510641 (e-mail: eejtang@scut.edu.cn); School of Electronic and Information Engineering, South China University of Technology, 26467 Guangzhou, Guangdong China 510641 (e-mail: ido1194@outlook.com); Department of Electronic and Information Engineering, South China University of Technology, 26467 Guangzhou, Guangdong China 510640 (e-mail: zhangxiuyin@scut.edu.cn); Department of Electronics, University of York, York United Kingdom of Great Britain and Northern Ireland YO10 5DD (e-mail: kanapathippillai.cumanan@york.ac.uk); Department of Engineering, University of Leicester, 4488 Leicester, Leicestershire United Kingdom of Great Britain and Northern Ireland LE1 7RH (e-mail: gaojie.chen@leicester.ac.uk); Department of Electronic and Electrical Engineering, University College London, 4919 London, London United Kingdom of Great Britain and Northern Ireland WC1E 6BT (e-mail: kai-kit.wong@ucl.ac.uk); Department of Engineering, University of Leicester, 4488 Leicester, Leicestershire United Kingdom of Great Britain and Northern Ireland LE1 7RH (e-mail: jonathon.chambers@leicester.ac.uk)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","Mobile edge caching (MEC) and device to device (D2D) communications are two potential technologies to resolve traffic overload problems in internet of things (IoT). Previous works usually investigate them separately with MEC for traffic offloading and D2D for information transmission. In this paper, a joint framework consisting of MEC and cache-enabled D2D communications is proposed to minimize the energy cost of systematic traffic transmission, where file popularity and user preference are the critical criteria for small base stations (SBSs) and user devices, respectively. Under this framework, we propose a novel caching strategy where Markov decision process (MDP) is applied to model the requesting behaviours. A novel scheme based on reinforcement learning (RL) is proposed to reveal the popularity of files as well as users' preference. In particular, Q-learning (QL) algorithm and deep Q-network (DQN) algorithm are respectively applied to user devices and SBS due to different complexities of status. To save the energy cost of systematic traffic transmission, users acquire partial traffic through D2D communications based on the cached contents and user distribution. Taking the memory limits, D2D available files and status changing into consideration, the proposed RL algorithm enables user devices and SBS to prefetch the optimal files while learning, which can reduce the energy cost significantly. Simulation results demonstrate the superior energy saving performance of the proposed RL-based algorithm over other existing methods under various conditions.","","","10.1109/TII.2019.2954127","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8903546","Content caching;D2D communications;internet of things (IoT);Q-learning (QL);deep Q-network (DQN)","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Spatio-Temporal Deep Learning-Based Undersampling Artefact Reduction for 2D Radial Cine MRI with Limited Training Data","A. Kofler; M. Dewey; T. Schaeffter; C. Wald; C. Kolbitsch","Department of Radiology, Charité -Universitätsmedizin Berlin, Berlin, Germany.; Department of Radiology, Charité -Universitätsmedizin Berlin, Berlin, Germany and the Berlin Institute of Health, Berlin, Germany.; Physikalisch-Technische Bundesanstalt (PTB), Braunschweig and Berlin, Germany and King’s College London, London, UK.; NA; NA","IEEE Transactions on Medical Imaging","","2019","PP","99","1","1","In this work we reduce undersampling artefacts in two-dimensional (2D) golden-angle radial cine cardiac MRI by applying a modified version of the U-net. The network is trained on 2D spatio-temporal slices which are previously extracted from the image sequences. We compare our approach to two 2D and a 3D Deep Learning-based post processing methods, three iterative reconstruction methods and two recently proposed methods for dynamic cardiac MRI based on 2D and 3D cascaded networks. Our method outperforms the 2D spatially trained U-net and the 2D spatio-temporal U-net. Compared to the 3D spatiotemporal U-net, our method delivers comparable results, but requiring shorter training times and less training data. Compared to the Compressed Sensing-based methods kt-FOCUSS and a total variation regularized reconstruction approach, our method improves image quality with respect to all reported metrics. Further, it achieves competitive results when compared to the iterative reconstruction method based on adaptive regularization with Dictionary Learning and total variation and when compared to the methods based on cascaded networks, while only requiring a small fraction of the computational and training time. A persistent homology analysis demonstrates that the data manifold of the spatio-temporal domain has a lower complexity than the one of the spatial domain and therefore, the learning of a projection-like mapping is facilitated. Even when trained on only one single subject without data-augmentation, our approach yields results which are similar to the ones obtained on a large training dataset. This makes the method particularly suitable for training a network on limited training data. Finally, in contrast to the spatial 2D U-net, our proposed method is shown to be naturally robust with respect to image rotation in image space and almost achieves rotation-equivariance where neither dataaugmentation nor a particular network design are required.","","","10.1109/TMI.2019.2930318","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8793147","Deep Learning;Neural Networks;Dynamic MRI;Image Processing;Compressed Sensing;Persistent Homology Analysis","Two dimensional displays;Magnetic resonance imaging;Image reconstruction;Image sequences;Training;Biomedical imaging;Three-dimensional displays","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"An End-to-End Calibration Method for Welding Robot Laser Vision Systems with Deep Reinforcement Learning","Y. Zou; R. Lan","NA; NA","IEEE Transactions on Instrumentation and Measurement","","2019","PP","99","1","1","Structured light calibration and robot handeye calibration are two of the most crucial parts in welding robot laser vision systems. The main aspect of this calibration is accuracy. To reduce the impact of errors in the calibration process and improve accuracy, an end-to-end calibration method for laser vision systems based on deep reinforcement learning is proposed. The proposed method involves two dual learning tasks: a pixel-to-point module and a point-to-wrist transformation. The pixel-to-point module predicts the locations of the feature points in the welding image, while the point-to-wrist transformation establishes an accurate conversion relationship from the pixel frame to the wrist frame of the robot. Point-to-wrist transformation consists of two major components: ‘actor’ and ‘critic’. The ‘actor’ model aims to infer the coordinates of the feature points in the wrist frame of the robot. In offline training, the ‘critic’ model is introduced to guide the learning process of the ‘actor’ model by maintaining geometric consistency between the image coordinate and robot coordinate. According to experimental results from the welding robot with continuous motion and changing poses, the proposed method significantly reduces the impact of errors in the calibration process and establishes a more accurate conversion relationship.","","","10.1109/TIM.2019.2942533","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8848859","Structured light calibration;hand-eye calibration;laser vision system;deep reinforcement learning","Calibration;Welding;Robot kinematics;Lasers;Machine vision;Cameras","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Adaptive Input Normalization for Time Series Forecasting","N. Passalis; A. Tefas; J. Kanniainen; M. Gabbouj; A. Iosifidis","Faculty of Information Technology and Communication, Tampere University, 33100 Tampere, Finland (e-mail: nikolaos.passalis@tuni.fi).; School of Informatics, Aristotle University of Thessaloniki, 541 24 Thessaloniki, Greece.; Faculty of Information Technology and Communication, Tampere University, 33100 Tampere, Finland.; Faculty of Information Technology and Communication, Tampere University, 33100 Tampere, Finland.; Department of Engineering, Electrical and Computer Engineering, Aarhus University, 8000 Aarhus, Denmark.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","6","Deep learning (DL) models can be used to tackle time series analysis tasks with great success. However, the performance of DL models can degenerate rapidly if the data are not appropriately normalized. This issue is even more apparent when DL is used for financial time series forecasting tasks, where the nonstationary and multimodal nature of the data pose significant challenges and severely affect the performance of DL models. In this brief, a simple, yet effective, neural layer that is capable of adaptively normalizing the input time series, while taking into account the distribution of the data, is proposed. The proposed layer is trained in an end-to-end fashion using backpropagation and leads to significant performance improvements compared to other evaluated normalization schemes. The proposed method differs from traditional normalization methods since it learns how to perform normalization for a given task instead of using a fixed normalization scheme. At the same time, it can be directly applied to any new time series without requiring retraining. The effectiveness of the proposed method is demonstrated using a large-scale limit order book data set, as well as a load forecasting data set.","","","10.1109/TNNLS.2019.2944933","H2020 Project BigDataFinance; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8936546","Data normalization;deep learning (DL);limit order book data;time series forecasting.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A 3D Probabilistic Deep Learning System for Detection and Diagnosis of Lung Cancer Using Low-Dose CT Scans","O. Ozdemir; R. L. Russell; A. A. Berlin","NA; Draper, 555 Technology Square, Cambridge, MA, 02139.; Draper, 555 Technology Square, Cambridge, MA, 02139.","IEEE Transactions on Medical Imaging","","2019","PP","99","1","1","We introduce a new computer aided detection and diagnosis system for lung cancer screening with low-dose CT scans that produces meaningful probability assessments. Our system is based entirely on 3D convolutional neural networks and achieves state-of-the-art performance for both lung nodule detection and malignancy classification tasks on the publicly available LUNA16 and Kaggle Data Science Bowl challenges. While nodule detection systems are typically designed and optimized on their own, we find that it is important to consider the coupling between detection and diagnosis components. Exploiting this coupling allows us to develop an end-to-end system that has higher and more robust performance and eliminates the need for a nodule detection false positive reduction stage. Furthermore, we characterize model uncertainty in our deep learning systems, a first for lung CT analysis, and show that we can use this to provide well-calibrated classification probabilities for both nodule detection and patient malignancy diagnosis. These calibrated probabilities informed by model uncertainty can be used for subsequent risk-based decision making towards diagnostic interventions or disease treatments, as we demonstrate using a probability-based patient referral strategy to further improve our results.","","","10.1109/TMI.2019.2947595","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8886352","","Solid modeling;Lung;Three-dimensional displays;Cancer;Computed tomography;Deep learning;Uncertainty","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"DeepChannel: Wireless Channel Quality Prediction using Deep Learning","A. Kulkarni; A. Seetharam; A. Ramesh; J. D. Herath","Binghamton, New York United States 13905 (e-mail: akulka17@binghamton.edu); Binghamton University, 14787 Binghamton, New York United States 13902 (e-mail: aseethar@binghamton.edu); Binghamton, New York United States (e-mail: artir@binghamton.edu); Computer Science, Binghamton University, 14787 Binghamton, New York United States 13902-4600 (e-mail: jherath1@binghamton.edu)","IEEE Transactions on Vehicular Technology","","2019","PP","99","1","1","Accurately modeling and predicting wireless channel quality variations is essential for a number of networking applications such as scheduling and improved video streaming over 4G LTE networks and bit rate adaptation for improved performance in WiFi networks. In this paper, we design DeepChannel, an encoder-decoder based sequence-to-sequence deep learning model that is capable of predicting future wireless signal strength variations based on past signal strength data. We consider two different versions of DeepChannel; the first and second versions use LSTM and GRU as their basic cell structure, respectively. In contrast to prior work that is primarily focused on designing models for particular network settings, DeepChannel is highly adaptable and can predict future channel conditions for different networks, sampling rates, mobility patterns, and communication standards. We compare the performance (i.e., the root mean squared error, mean absolute error and relative error of future predictions) of DeepChannel with respect to two baselines— i) linear regression, and ii) ARIMA for multiple networks and communication standards. In particular, we consider 4G LTE, WiFi, WiMAX, an industrial network operating in the 5.8 GHz range, and Zigbee networks operating under varying levels of user mobility and observe that DeepChannel provides significantly superior performance. Finally, we provide a detailed discussion of the key design decisions including insights into hyper-parameter tuning and the applicability of our model in other networking scenarios.","","","10.1109/TVT.2019.2949954","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8884240","","Wireless communication;Predictive models;Wireless sensor networks;Data models;Deep learning;Computational modeling;Wireless fidelity","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Learning Based RF Fingerprint Identification Using Differential Constellation Trace Figure","L. Peng; J. Zhang; M. Liu; A. Hu","School of Cyber Science and Engineering, Southeast University, 12579 Nanjing, Jiangsu China (e-mail: pengln@seu.edu.cn); Department of Electrical Engineering and Electronics, University of Liverpool, Liverpool, Liverpool United Kingdom of Great Britain and Northern Ireland L69 3GJ (e-mail: junqing.zhang@liverpool.ac.uk); Beijing Key Lab of Transportation Data Analysis and Mining, Beijing Jiaotong University, 47829 Beijing, Beijing China (e-mail: mingliu@bjtu.edu.cn); School of Cyber Science and Engineering, Southeast University, Nanjing, Jiangsu China (e-mail: aqhu@seu.edu.cn)","IEEE Transactions on Vehicular Technology","","2019","PP","99","1","1","This paper proposes a novel deep learning-based radio frequency fingerprint (RFF) identification method for internet of things (IoT) terminal authentications. Differential constellation trace figure (DCTF), a two-dimensional (2D) representation of differential relationship of signal time series, is utilized to extract RFF features without requiring any synchronization. A convolutional neural network (CNN) is then designed to identify different devices using DCTF features. Compared to the existing CNN-based RFF identification methods, the proposed DCTF-CNN possesses the merits of high identification accuracy, zero prior information and low complexity. Experimental results have demonstrated that the proposed DCTF-CNN can achieve an identification accuracy as high as 99.1% and 93.8% under SNR levels of 30 dB and 15 dB, respectively, when classifying 54 target ZigBee devices, which significantly outperforms the existing RFF identification methods.","","","10.1109/TVT.2019.2950670","National Natural Science Foundation of China; Purple Mountain Laboratories for Network and Communication Security; Royal Society Research Grants; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8888209","Physical layer security;radio frequency fingerprint;differential constellation trace figure;convolutional neural network","Feature extraction;Zigbee;Radio frequency;Deep learning;Synchronization;Complexity theory;Training","","","","","","","","","","IEEE","IEEE Early Access Articles"
"An Improved Bayesian Combination Model for Short-Term Traffic Prediction With Deep Learning","Y. Gu; W. Lu; X. Xu; L. Qin; Z. Shao; H. Zhang","Key Laboratory of Transport Industry of Big Data Application Technologies for Comprehensive Transport, Ministry of Transport, Beijing Jiaotong University, Beijing 100044, China.; School of Transportation, Southeast University, Nanjing 211189, China.; State Key Laboratory of Rail Traffic Control and Safety, Beijing Jiaotong University, Beijing 100044, China (e-mail: xxy_1983@163.com).; Traffic Operations and Safety Laboratory, Department of Civil and Environmental Engineering, University of Wisconsin-Madison, Madison, WI 53706 USA.; Key Laboratory of Transport Industry of Big Data Application Technologies for Comprehensive Transport, Ministry of Transport, Beijing Jiaotong University, Beijing 100044, China.; State Key Laboratory of Rail Traffic Control and Safety, Beijing Jiaotong University, Beijing 100044, China.","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","11","Short-term traffic volume prediction, which can assist road users in choosing appropriate routes and reducing travel time cost, is a significant topic of intelligent transportation system. To overcome the error magnification phenomena of traditional combination methods and to improve prediction performance, this paper proposes an improved Bayesian combination model with deep learning (IBCM-DL) for traffic flow prediction. First, an IBCM framework is established based on the new BCM framework proposed by Wang. Then, correlation analysis is used to analyze the relevance between the historical traffic flow and the traffic flow within the current interval. Three sub-predictors including the gated recurrent unit neural network (GRUNN), autoregressive integrated moving average (ARIMA), and radial basis function neural network (RBFNN) are incorporated into the IBCM framework to take advantage of each method. The real-world traffic volume data captured by microwave sensors located on the expressways of Beijing was used to validate the proposed model in multiple scenarios. The overall results illustrate that the IBCM-DL model outperforms the other state-of-the-art methods in terms of accuracy and stability.","","","10.1109/TITS.2019.2939290","Science and Technology Program of Beijing; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8842618","Urban road;short-term traffic flow prediction;improved Bayesian combination method;gated recurrent unit neural network;microwave data.","Predictive models;Deep learning;Correlation;Neural networks;Bayes methods;Data models;Roads","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Communication Profiling and Characterization of Deep Learning Workloads on Clusters with High-Performance Interconnects","A. A. Awan; A. Jain; C. Chu; H. Subramoni; D. K. Panda","Computer Science and Engineering, Ohio State University, 2647 Columbus, Ohio United States (e-mail: awan.10@osu.edu); Computer Science and Engineering, Ohio State University, 2647 Columbus, Ohio United States (e-mail: jain.575@osu.edu); Computer Science and Engineering, Ohio State University, 2647 Columbus, Ohio United States (e-mail: chu.368@osu.edu); Computer Science and Engineering, The Ohio State University, 2647 Columbus, Ohio United States (e-mail: subramon@cse.ohio-state.edu); Computer Science and Engineering, The Ohio State University, 2647 Columbus, Ohio United States (e-mail: panda@cse.ohio-state.edu)","IEEE Micro","","2019","PP","99","1","1","Heterogeneous HPC systems with GPUs are equipped with high-performance interconnects like InfiniBand, Omni-Path, PCIe, and NVLink. However, little exists in the literature that captures the performance impact of these interconnects on distributed Deep Learning (DL). In this paper, we choose Horovod; a distributed training middleware, to analyze and profile various DNN training workloads using TensorFlow and PyTorch in addition to standard MPI micro-benchmarks. We use a wide variety of systems with CPUs like Intel Xeon and IBM POWER9, GPUs like Volta V100, and various interconnects to analyze the following metrics: 1) Message-size with Horovod's tensor-fusion, 2) Message-size without tensor-fusion, 3) Number of MPI/NCCL calls, and 4) Time taken by each MPI/NCCL call. We observed extreme performance variations for non-power-of-two message sizes on different platforms. To address this, we design a message-padding scheme for Horovod, illustrate significantly smoother allreduce latency profiles, and report cases where we observed improvement for end-to-end training.","","","10.1109/MM.2019.2949986","US National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8887216","InfiniBand;Omni-Path;NVLink;PCIe;TensorFlow;Horovod;MVAPICH2 MPI;Performance Analysis;Profiling;Communication Libraries","Training;Libraries;Measurement;Middleware;Deep learning;Graphics processing units;Performance analysis","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Physical Features and Deep Learning-based Appearance Features for Vehicle Classification from Rear View Videos","R. Theagarajan; N. S. Thakoor; B. Bhanu","Center for Research in Intelligent Systems, University of California at Riverside, Riverside, CA 92521 USA (e-mail: rthea001@ucr.edu).; Center for Research in Intelligent Systems, University of California at Riverside, Riverside, CA 92521 USA. He is now with Cognex Corporation, Natick, MA 01760 USA.; Center for Research in Intelligent Systems, University of California at Riverside, Riverside, CA 92521 USA.","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","13","Currently, there are many approaches for vehicle classification, but there is no specific study on automated, rear view, and video-based robust vehicle classification. The rear view is important for intelligent transportation systems since not all states in the United States require a frontal license plate on a vehicle. The classification of vehicles, from their rear views, is challenging since vehicles have only subtle appearance differences and there are changing illumination conditions and the presence of moving shadows. In this paper, we present a novel multi-class vehicle classification system that classifies a vehicle into one of four possible classes (sedan, minivan, SUV, and a pickup truck) from its rear view video, using physical and visual features. For a given geometric setup of the camera on highways, we make physical measurements on a vehicle. These measurements include visual rear ground clearance, the height of the vehicle, and the distance between the license plate and the rear bumper. We call these distances as the physical features. The visual features, also called appearance-based features, are extracted using convolutional neural networks from the input images. We achieve a classification accuracy of 93.22% and 91.52% using physical and visual features, respectively. Furthermore, we achieve a higher classification accuracy of 94.81% by fusing both the features together. The results are shown on a dataset consisting of 1831 rear view videos of vehicles and they are compared with various approaches, including deep learning techniques.","","","10.1109/TITS.2019.2902312","NSF; PIPS 3M; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8672926","Convolutional neural networks;feature level fusion;multi-frame analysis;physical features;visual features;vehicle classification on highways/freeways.","Visualization;Licenses;Feature extraction;Cameras;Videos;Deep learning;Traffic control","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Adaptive Self-paced Deep Clustering with Data Augmentation","X. Guo; X. Liu; E. Zhu; X. Zhu; M. Li; X. Xu; J. Yin","College of Computer, National University of Defense Technology, 58294 Changsha, Hunan China 410073 (e-mail: guoxifeng1990@163.com); College of Computer, National University of Defense Technology, 58294 Changsha, Hunan China (e-mail: xinwangliu@nudt.edu.cn); College of Computer, National University of Defense Technology, 58294 Changsha, Hunan China (e-mail: enzhu@nudt.edu.cn); College of Mathematics, Physics and Information Engineering, Zhejiang Normal University, 66344 Jinhua, Zhejiang China (e-mail: zxz@zjnu.edu.cn); College of Computer, National University of Defense Technology, 58294 Changsha, Hunan China (e-mail: miaomiaolinudt@gmail.com); Institute of Automation, National University of Defense Technology, Changsha, Hunan China 410073 (e-mail: xinxu@nudt.edu.cn); School of Computer Science, Dongguan University of Technology, 74549 Dongguan, Guangdong China (e-mail: jpyin@dgut.edu.cn)","IEEE Transactions on Knowledge and Data Engineering","","2019","PP","99","1","1","Deep clustering gains superior performance than conventional clustering by jointly performing feature learning and cluster assignment. Although numerous deep clustering algorithms have emerged in various applications, most of them fail to learn robust cluster-oriented features which in turn hurts the final clustering performance. To solve this problem, we propose a two-stage deep clustering algorithm by incorporating data augmentation and self-paced learning. Specifically, in the first stage, we learn robust features by training an autoencoder with examples that are augmented by random shifting and rotating the given clean examples. Then in the second stage, we encourage the learned features to be cluster-oriented by alternatively finetuning the encoder with the augmented examples and updating the cluster assignments of the clean examples. During finetuning the encoder, the target of each augmented example in the loss function is the center of the cluster to which the clean example is assigned. The targets may be computed incorrectly, and the examples with incorrect targets could mislead the encoder network. To stabilize the network training, we select most confident examples in each iteration by utilizing the adaptive self-paced learning. Extensive experiments validate that our algorithm outperforms the state of the arts on four image datasets.","","","10.1109/TKDE.2019.2911833","National Natural Science Foundation of China; National Key R D Program of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8693526","deep clustering;self-paced learning;data augmentation;unsupervised feature learning","Clustering algorithms;Training;Task analysis;Gallium nitride;Gaussian mixture model;Feature extraction","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Whole Process Monitoring Based on Unstable Neuron Output Information in Hidden Layers of Deep Belief Network","J. Yu; X. Yan","Key Laboratory of Advanced Control and Optimization for Chemical Processes of Ministry of Education, East China University of Science and Technology, Shanghai 200237, China.; Key Laboratory of Advanced Control and Optimization for Chemical Processes of Ministry of Education, East China University of Science and Technology, Shanghai 200237, China (e-mail: xfyan@ecust.edu.cn).","IEEE Transactions on Cybernetics","","2019","PP","99","1","10","Process monitoring based on deep learning has attracted considerable attention. Generally, several hidden layers exist in the deep-learning model, and only the output information of the last hidden layer neurons extracted by deep learning is applied. Considering that each hidden layer is a kind of information representation of the original data, the information of different hidden layers may contain positive elements for process monitoring. In this article, we found that when a fault occurs, there are some neurons in each hidden layer that the information they output are different, compared with the normal condition. These neurons are called unstable neurons. Obviously, the information they output are beneficial for process monitoring. Motivated by theoretical analysis and experimental studies on unstable neurons, a novel method (UN-DBN) based on the unstable neurons in hidden layers is proposed to integrate the useful information for process monitoring, the Euclidean metric, the moving average filter, and the kernel density estimation technique are employed to provide an intuitionistic expression of the working state. The comparable result applied on a mathematic simulation process and the TE process with other advanced monitoring methods confirms the superiority and feasibility of the proposed method UN-DBN in this article.","","","10.1109/TCYB.2019.2948202","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; Program of Introducing Talents of Discipline to Universities the 111 Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8936538","Deep belief network (DBN);deep learning;process monitoring;unstable neuron","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Joint Motion Information Extraction and Human Behavior Recognition in Video Based on Deep Learning","K. Zhang; W. Ling","Sports Institute, Xinxiang Medical University, Xinxiang, Henan 453003, China.; Sports Institute, Xinxiang Medical University, Xinxiang, Henan 453003, China.","IEEE Sensors Journal","","2019","PP","99","1","1","Video surveillance has played a huge role in the safety and security tasks of various places for many years, and its application range is also expanding. The core problem that needs to be addressed in intelligent video surveillance is the identification and analysis of human behavior in video. In this paper, the structure and joint motion feature extraction of the twochannel deep convolutional neural network model are studied and designed. In the design of the network structure, the ventral and dorsal channels used in the processing of visual signals by the brain visual cortex were simulated. The spatial channel network and the time channel network are used to process static information and dynamic information respectively, and the two types of features are separately extracted. The superiority of the dual-channel structure is verified by comparing the recognition effects of the two-channel model with the single-channel model. Finally, experiments were performed on the KTH behavioral dataset. The results show that the human behavior recognition algorithm based on deep learning can achieve high recognition accuracy based on the good extraction of joint motion information.","","","10.1109/JSEN.2019.2959582","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8932388","Joint Motion;Information Extraction;Human Behavior Recognition;Deep Learning","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Data-Driven 2D Deep Correlated Representation Learning for Nonlinear Batch Process Monitoring","Q. Jiang; S. Yan; X. Yan; H. Yi; F. Gao","Key Laboratory of Advanced Control and Optimization for Chemical Processes of Ministry of Education, East China University of Science and Technology, 47860 Shanghai, Shanghai China 200237 (e-mail: qchjiang@ecust.edu.cn); Automation, Key Laboratory of Advanced Control and Optimization for Chemical Processes of Ministry of Education, East China University of Science and Technology, Shanghai 200237, P. R. China, Shanghai China 200237 (e-mail: yanshifu@mail.ecust.edu.cn); Automation, Key Laboratory of Advanced Control and Optimization for Chemical Processes of Ministry of Education, East China University of Science and Technology, Shanghai 200237, P. R. China, Shanghai China 200237 (e-mail: xfyan@ecust.edu.cn); College of Electronic Engineering and Control Science, Nanjing University of Technology, Nanjing China 211816 (e-mail: jsyihui@126.com); Chemical and Biomolecular Engineering, Hong Kong University of Science and Technology, 58207 Kowloon Hong Kong 221116 (e-mail: kefgao@ust.hk)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","Dynamics and nonlinearity may exist in time and batch directions for batch processes, thereby complicating the monitoring of these processes. This paper proposes a two-dimensional deep correlated representation learning (2D-DCRL) method to achieve efficient fault detection and isolation of nonlinear batch processes. Three-way historical data are first unfolded as two-way time-slice data. Second, a stacked autoencoder-based deep neural network is constructed to characterize the correlation among process variables. Considering that the time and batch directions may be dynamic, for each time-slice measurement, a constructed 2D measurement containing samples from previous time instants and batches is then obtained. Subsequently, DCRL is performed between the current running-batch measurements and the constructed 2D measurements to characterize the two-dimensional dynamics and nonlinearity. 2D-DCRL-based monitoring examines the status of a sample by considering the 2D nonlinear and dynamic information, providing improved monitoring performance. Applications on two typical batch processes demonstrate the effectiveness of the proposed 2D-DCRL monitoring scheme.","","","10.1109/TII.2019.2952931","Shanghai Pujiang Program; Fundamental Research Funds for the Central Universities; Open Research Project of the State Key Laboratory of Industrial Control Technology Zhejiang University; Programme of Introducing Talents of Discipline to Universities; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8896001","Deep correlated representation learning;two-dimensional modeling;batch process monitoring;data-driven fault detection","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Cyber-Attack Recovery Strategy for Smart Grid Based on Deep Reinforcement Learning","F. Wei; Z. Wan; H. He","Department of Electrical, Computer and Biomedical Engineering, University of Rhode Island, Kingston, RI 02881 USA.; Department of Electrical, Computer and Biomedical Engineering, University of Rhode Island, Kingston, RI 02881 USA.; Department of Electrical, Computer and Biomedical Engineering, University of Rhode Island, Kingston, RI 02881 USA.","IEEE Transactions on Smart Grid","","2019","PP","99","1","1","The integration of cyber-physical system increases the vulnerabilities of critical power infrastructures. Once the malicious attackers take the substation control authorities, they can trip all the transmission lines to block the power transfer. As a consequence, asynchrony will emerge between the separated regions which had been interconnected by these transmission lines. In order to recover from the attack, a straightforward way is to reclose these transmission lines once we detect the attack. However, this may cause severe impacts on the power system, such as current inrush and power swing. Therefore, it is critical to properly choose the reclosing time to mitigate these impacts. In this paper, we propose a recovery strategy to reclose the tripped transmission lines at the optimal reclosing time. In particular, a deep reinforcement learning (RL) framework is adopted to endow the strategy with the adaptability of uncertain cyber-attack scenarios and the ability of real-time decision-making. In this framework, an environment is established to simulate the power system dynamics during the attack-recovery process and generate the training data. With these data, the deep RL based strategy can be trained to determine the optimal reclosing time. Numerical results show that the proposed strategy can minimize the cyber-attack impacts under different scenarios.","","","10.1109/TSG.2019.2956161","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8915727","Cyber-attack;recovery strategy;deep reinforcement learning (RL);optimal reclosing time.","Power transmission lines;Power system stability;Power system dynamics;Rotors;Substations;Real-time systems","","","","","","","","","","IEEE","IEEE Early Access Articles"
"GluNet: A Deep Learning Framework For Accurate Glucose Forecasting","K. Li; C. Liu; T. Zhu; P. Herrero; P. Georgiou","Department of Electronic and Electrical Engineering, Imperial College London, London SW7 2AZ, UK (e-mail: kezhi.li@imperial.ac.uk); Department of Electronic and Electrical Engineering, Imperial College London, London SW7 2AZ, UK (e-mail: chengyuan.liu@nottingham.ac.uk); Department of Electronic and Electrical Engineering, Imperial College London, London SW7 2AZ, UK (e-mail: taiyu.zhu17@imperial.ac.uk); Department of Electronic and Electrical Engineering, Imperial College London, London SW7 2AZ, UK (e-mail: p.herrero-vinias@imperial.ac.uk); Department of Electronic and Electrical Engineering, Imperial College London, London SW7 2AZ, UK (e-mail: pantelis@imperial.ac.uk)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","For people with Type 1 diabetes (T1D), forecasting of \red{blood glucose (BG)} can be used to effectively avoid hyperglycemia, hypoglycemia and associated complications. The latest continuous glucose monitoring (CGM) technology allows people to observe glucose in real-time. However, an accurate glucose forecast remains a challenge. In this work, we introduce GluNet, a framework that leverages on a personalized deep neural network to predict the probabilistic distribution of short-term (30-60 minutes) future CGM measurements for subjects with T1D based on their historical data including glucose measurements, meal information, insulin doses, and other factors. It adopts the latest deep learning techniques consisting of four components: data pre-processing, label transform/recover, multi-layers of dilated convolution neural network (CNN), and post-processing. The method is evaluated $in-silico$ for both adult and adolescent subjects. The results show significant improvements over existing methods in the literature through a comprehensive comparison in terms of root mean square error (RMSE) (8.88 ± 0.77 mg/dL) with short time lag (0.83 ± 0.40 minutes) for prediction horizons (PH) = 30 mins (minutes), and RMSE (19.90 ± 3.17 mg/dL) with time lag (16.43 ± 4.07 mins) for PH = 60 mins for virtual adult subjects. In addition, GluNet is also tested on two clinical data sets. Results show that it achieves an RMSE (19.28 ± 2.76 mg/dL) with time lag (8.03 ± 4.07 mins) for PH = 30 mins and an RMSE (31.83 ± 3.49 mg/dL) with time lag (17.78 ± 8.00 mins) for PH = 60 mins. These are the best reported results for glucose forecasting when compared with other methods including the neural network for predicting glucose (NNPG), the support vector regression (SVR), the latent variable with exogenous input (LVX), and the auto regression with exogenous input (ARX) algorithm.","","","10.1109/JBHI.2019.2931842","Engineering and Physical Sciences Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8779644","Deep learning;dilated convolutions;glucose forecasting;continuous glucose monitoring (CGM);diabetes","Sugar;Forecasting;Insulin;Convolution;Predictive models;Neural networks;Transforms","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Polynomial Kernel Induced Distance Metric to Improve Deep Transfer Learning for Fault Diagnosis of Machines","B. Yang; Y. Lei; F. Jia; N. Li; Z. Du","School of Mechanical Engineering, Xian Jiaotong University, 12480 Xian, Shaanxi China (e-mail: chdsy_yb@163.com); School of Mechanical Engineering, Xian Jiaotong University, 12480 Xian, Shaanxi China (e-mail: yaguolei@mail.xjtu.edu.cn); Xian Jiaotong University, 12480 Xian, Shaanxi China (e-mail: jiafeng1237@sina.com); Xian Jiaotong University, 12480 Xian, Shaanxi China (e-mail: li3112001096@stu.xjtu.edu.cn); Xian Jiaotong University, 12480 Xian, Shaanxi China (e-mail: duzhaojun@stu.xjtu.edu.cn)","IEEE Transactions on Industrial Electronics","","2019","PP","99","1","1","Deep transfer-learning-based diagnosis models are promising to apply diagnosis knowledge across related machines, but from which the collected data follow different distribution. To reduce the distribution discrepancy, Gaussian kernel induced maximum mean discrepancy (GK-MMD) is a widely used distance metric to impose constraints on the training of diagnosis models. However, the models using GK-MMD have three weaknesses: 1) GK-MMD may not accurately estimate distribution discrepancy because it ignores the high-order moment distances of data; 2) the time complexity of GK-MMD is high to require much computation cost; 3) the transfer performance of GK-MMD-based diagnosis models is sensitive to the selected kernel parameters. In order to overcome the weaknesses, a distance metric named polynomial kernel induced MMD (PK-MMD) is proposed in this paper. Combined with PK-MMD, a diagnosis model is constructed to reuse diagnosis knowledge from one machine to the other. The proposed methods are verified by two transfer learning cases, in which the health states of locomotive bearings are identified with the help of data respectively from motor bearings and gearbox bearings in laboratories. The results show that PK-MMD enables to improve the inefficient computation of GK-MMD, and the PK-MMD-based diagnosis model presents better transfer results than other methods.","","","10.1109/TIE.2019.2953010","National Key R and D Program of China; NSFC-Zhejiang Joint Fund for the Integration of Industrialization and Informatization; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8903539","Intelligent fault diagnosis;Deep transfer learning;Domain adaptation;Maximum mean discrepancy","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Situation-Aware Deep Reinforcement Learning Link Prediction Model for Evolving Criminal Networks","M. Lim; A. Abdullah; N. Jhanjhi; M. K. Khan","School of Computing and IT (SoCIT), Taylor’s University, Malaysia.; School of Computing and IT (SoCIT), Taylor’s University, Malaysia.; School of Computing and IT (SoCIT), Taylor’s University, Malaysia.; Center of Excellence in Information Assurance, King Saud University, Kingdom of Saudi Arabia.","IEEE Access","","2019","PP","99","1","1","Evidently, criminal network activities have shown an increasing trend in terms of complexity and frequency, particularly with the advent of social media and modern telecommunication systems. In these circumstances, law enforcement agencies have to be armed with advance criminal network analysis (CNA) tools capable of uncovering with speed, probable key hidden relationships (links/edges) and players (nodes) in order to anticipate, undermine and cripple organised crime syndicates and activities. The development of link prediction models for network orientated domains is based on Social Network Analysis (SNA) methods and models. The key objective of this research is to develop a link prediction model that incorporates a fusion of metadata (i.e. environment data sources such as arrest warrants, judicial judgement, wiretap records and police station proximity) with a time-evolving criminal dataset in order to be aware of real-world situations to improve the quality of link prediction. Based on the review of related work, most of the models are constructed by leveraging on classical machine learning (ML) techniques such as support vector machine (SVM) without metadata fusion. The problem with the use of classical ML techniques is the lack of available domain dataset which is sufficiently large for training purpose. Compared to sociaI network, criminal network dataset by nature tends to relatively much smaller. In view of this, deep reinforcement learning (DRL) technique which could improve the training of models with the self-generated dataset is leveraged upon to construct the model. In this research, a purely time-evolving DRL model (TDRL-CNA) without metadata fusion is designed as a baseline for comparison with the metadata fusion model (FDRL-CNA). The experimental results show that the predictive accuracy of new and recurrent links by the FDRL-CNA model is higher than the baseline TDRL-CNA model that does not factor data fusion from different data sources.","","","10.1109/ACCESS.2019.2961805","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8939364","Data Fusion;Time-evolving network;Criminal Network Analysis;Deep reinforcement Learning;Node similarity","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Beamforming Design for Large-Scale Antenna Arrays Using Deep Learning","T. Lin; Y. Zhu","State Key Laboratory of ASIC and System, Department of Communication Science and Engineering, Fudan University, Shanghai 200433, China.; State Key Laboratory of ASIC and System, Department of Communication Science and Engineering, Fudan University, Shanghai 200433, China.","IEEE Wireless Communications Letters","","2019","PP","99","1","1","Beamforming (BF) design for large-scale antenna arrays with limited radio frequency chains and the phase-shifter-based analog BF architecture, has been recognized as a key issue in millimeter wave communication systems. It becomes more challenging with imperfect channel state information (CSI). In this letter, we propose a deep learning based BF design approach and develop a BF neural network (BFNN) which can be trained to learn how to optimize the beamformer for maximizing the spectral efficiency with hardware limitation and imperfect CSI. Simulation results show that the proposed BFNN achieves significant performance improvement and strong robustness to imperfect CSI over the traditional BF algorithms.","","","10.1109/LWC.2019.2943466","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8847377","Deep learning (DL);millimeter wave (mmWave);beamforming (BF) design;large-scale antenna arrays;neural network (NN);beamforming neural network (BFNN).","Antenna arrays;Radio frequency;Channel estimation;Signal to noise ratio;Training;Array signal processing;Optimization","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Learning-Based System for Automatic Melanoma Detection","A. A. Adegun; S. Viriri","School of Mathematics, Statistics and Computer Science, University of KwaZulu-Natal, Durban, South Africa.; School of Mathematics, Statistics and Computer Science, University of KwaZulu-Natal, Durban, South Africa.","IEEE Access","","2019","PP","99","1","1","Melanoma is the deadliest form of skin cancer. Distinguishing melanoma lesions from non-melanoma lesions has however been a challenging task. Many Computer Aided Diagnosis and Detection Systems have been developed in the past for this task. They have been limited in performance due to the complex visual characteristics of the skin lesion images which consists of inhomogeneous features and fuzzy boundaries. In this paper, we propose a deep learning-based method that overcomes these limitations for automatic melanoma lesion detection and segmentation. An enhanced encoder-decoder network with encoder and decoder sub-networks connected through a series of skip pathways which brings the semantic level of the encoder feature maps closer to that of the decoder feature maps is proposed for efficient learning and feature extraction. The system employs multi-stage and multi-scale approach and utilizes softmax classifier for pixel-wise classification of melanoma lesions. We devise a new method called Lesion-classifier that performs the classification of skin lesions into melanoma and non-melanoma based on results derived from pixel-wise classification. Our experiments on two well-established public benchmark skin lesion datasets, International Symposium on Biomedical Imaging(ISBI)2017 and Hospital Pedro Hispano (PH2), demonstrate that our method is more effective than some state-of-the-art methods. We achieved accuracy and dice coefficient of 95% and 92% on ISIC 2017 dataset and accuracy and dice coefficient of 95% and 93% on PH2 datasets.","","","10.1109/ACCESS.2019.2962812","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8945133","Deep Learning-Based;Encoding-Decoding Network;Pixel-wise classification;Melanoma;Skin Lesion;Segmentation","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Destination Prediction A Deep Learning based Approach","J. Xu; J. Zhao; R. Zhou; C. Liu; P. Zhao; L. Zhao","School of Computer Science and Technology, Soochow University, Suzhou, Jiangsu China (e-mail: xujj@suda.edu.cn); Computer Science and Technology, Soochow University, 12582 Suzhou, Jiangsu China 215000 (e-mail: 20175227005@stu.suda.edu.cn); Computer Science, Swinburne University of Technology, 3783 Hawthorn, Victoria Australia 3122 (e-mail: rzhou@swin.edu.au); Faculty of ICT, Swinburne University of Technology, Melbourne, Victoria Australia 3122 (e-mail: cliu@swin.edu.au); Institute of Intelligent Information Processing and Application, Soochow University, Suzhou, Jiangsu China (e-mail: ppzhao@suda.edu.cn); Computer Science, Soochow University, Suzhou, Jiangsu China (e-mail: zhaol@suda.edu.cn)","IEEE Transactions on Knowledge and Data Engineering","","2019","PP","99","1","1","Destination prediction is known as an important problem for many location based services (LBSs). Existing solutions generally apply probabilistic models or neural network models to predict destinations over a sub-trajectory, and adopt the standard attention mechanism to improve the prediction accuracy. However, the standard attention mechanism uses fixed feature representations, and has a limited ability to represent distinct features of locations. Besides, existing methods rarely take the impact of spatial and temporal characteristics of the trajectory into account. Their accuracies in fine-granularity prediction are always not satisfactory due to the data sparsity problem. Thus, in this paper, a carefully designed deep learning model called LATL model is presented. It not only adopts an adaptive attention network to model the distinct features of locations, but also implements time gates and distance gates into the Long Short-Term Memory (LSTM) network to capture the spatial-temporal relation between consecutive locations. Furthermore, to better understand the mobility patterns in different spatial granularities, and explore the fusion of multi-granularity learning capability, a hierarchical model that utilizes tailored combination of different neural networks under multiple spatial granularities is further proposed. Extensive empirical studies verify that the newly proposed models perform effectively and settle the problem nicely.","","","10.1109/TKDE.2019.2932984","Australian Research Council discovery project; Open Program of State Key Laboratory of Software Architecture; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8787889","trajectory prediction;trajectory embedding;deep learning","Trajectory;Predictive models;Adaptation models;Standards;Neural networks;Logic gates;Data models","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Deep Reinforcement Learning for Partially Observable Data Poisoning Attack in Crowdsensing Systems","M. Li; Y. Sun; H. Lu; S. Maharjan; Z. Tian","Cyberspace Institute of Advanced Technology, Guangzhou University, Guangzhou 510006, China.; Cyberspace Institute of Advanced Technology, Guangzhou University, Guangzhou 510006, China.; Cyberspace Institute of Advanced Technology, Guangzhou University, Guangzhou 510006, China.; Simula Metropolitan Center for Digital Engineering, Norway and University of Oslo, Oslo, Norway.; Cyberspace Institute of Advanced Technology, Guangzhou University, Guangzhou 510006, China.","IEEE Internet of Things Journal","","2019","PP","99","1","1","Crowdsensing systems collect various types of data from sensors embedded on mobile devices owned by individuals. These individuals are commonly referred to as workers that complete tasks published by crowdsensing systems. Because of the relative lack of control over worker identities, crowdsensing systems are susceptible to data poisoning attacks which interfering with data analysis results by injecting fake data conflicting with ground truth. Frameworks like TruthFinder can resolve data conflicts by evaluating the trustworthiness of the data providers. These frameworks somehow make crowdsensing systems more robust since they can limit the impact of dirty data by reducing the value of unreliable workers. However, previous work has shown that TruthFinder may also be affected by data poisoning attack when the malicious workers have access to global information. In this paper, we focus on partially observable data poisoning attacks in crowdsensing systems. We show that even if the malicious workers only have access to local information, they can find effective data poisoning attack strategies to interfere with crowd sensing systems with TruthFinder. First, we formally model the problem of partially observable data poisoning attack against crowdsensing systems. Then, we propose a data poisoning attack method based on deep reinforcement learning, which helps malicious workers jeopardize with TruthFinder while hiding themselves. Based on the method, the malicious workers can learn from their attack attempts and evolve the poisoning strategies continuously. Finally, we conduct experiments on real-life data sets to verify the effectiveness of the proposed method.","","","10.1109/JIOT.2019.2962914","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8945245","crowdsensing systems;data poisoning attack;deep reinforcement learning;truth discovery.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Reinforcement Learning for EV Charging Navigation by Coordinating Smart Grid and Intelligent Transportation System","T. Qian; C. Shao; X. Wang; M. Shahidehpour","School of Electrical Engineering and Shaanxi Key Laboratory of Smart Grid, Xi’an Jiaotong University, Xi’an 710049, China.; School of Electrical Engineering and Shaanxi Key Laboratory of Smart Grid, Xi’an Jiaotong University, Xi’an 710049, China.; School of Electrical Engineering and Shaanxi Key Laboratory of Smart Grid, Xi’an Jiaotong University, Xi’an 710049, China.; Robert W. Galvin Center for Electricity Innovation, Illinois Institute of Technology in Chicago.","IEEE Transactions on Smart Grid","","2019","PP","99","1","1","A coordinated operation of smart grid (SG) and intelligent transportation system (ITS) provides electric vehicle (EV) owners with a myriad of power and transportation network data for EV charging navigation. However, the optimal charging navigation would be a challenging task owing to the randomness of traffic conditions, charging prices and waiting time at EV charging station (EVCS). In this paper, we propose a deep reinforcement learning (DRL)-based EV charging navigation, aiming at minimizing the total travel time and the charging cost at EVCS. First, we utilize the deterministic shortest charging route model (DSCRM) to extract feature states out of collected stochastic data and then formulate EV charging navigation as a Markov Decision Process (MDP) with an unknown transition probability. The proposed DRL-based approach will approximate the solution, which can adaptively learn the optimal strategy without any prior knowledge of uncertainties. Case studies are carried out within a practical zone in Xi’an city, China. Numerous experimental results verity the effectiveness of the proposed approach and illustrate its adaptation to EV driver preferences. The coordination effect of SG and ITS on reducing the waiting time and the charging cost in EV charging navigations is also analyzed.","","","10.1109/TSG.2019.2942593","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8845652","Intelligent transportation system;deep reinforcement learning;EV charging navigation;Markov decision process;smart grid.","Electric vehicle charging;Roads;Navigation;Feature extraction;Uncertainty;Batteries","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Motor Current Signal Based Bearing Fault Diagnosis Using Deep Learning And Information Fusion","D. T. Hoang; H. J. Kang","Electrical Engineering Department, University of Ulsan, Ulsan, South Korea.; Electrical Engineering Department, University of Ulsan, Ulsan, South Korea.","IEEE Transactions on Instrumentation and Measurement","","2019","PP","99","1","1","Bearing fault diagnosis has extensively exploited vibration signals because of their rich information about bearing health conditions. However, this approach is expensive because the measurement of vibration signals requires external accelerometers. Moreover, in machine systems that are inaccessible or unable to be installed external sensors, the vibration signal-based approach is impracticable. Otherwise, motor current signals are easily measured by the inverters which are available components of those systems. Therefore, the motor current-signal-based bearing fault diagnosis approach has attracted considerable attention from researchers. However, the performance of this approach is still not good as the vibration signal-based approach, especially in the case of fault diagnosis for external bearings (the bearings which installed outside of the electric motors). Accordingly, this paper proposes a motor current-signal-based fault diagnosis method utilizing deep learning and information fusion that can be applied to external bearings in rotary machine systems. The proposed method uses raw signals from multiple phases of the motor current as direct input, features are extracted from the current signals of each phase. Then each feature set is classified separately by a convolutional neural network. To enhance the classification accuracy, a novel decision-level information fusion technique is introduced to fuse information from all of the utilized convolutional neural networks. The problem of decision-level information fusion is transformed into a simple pattern classification task, which can be solved effectively by familiar supervised learning algorithms. The effectiveness of the proposed fault diagnosis method is verified through experiments carried out with actual bearing fault signals.","","","10.1109/TIM.2019.2933119","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8788665","Bearing fault diagnosis;convolutional neural network;deep learning;decision-level information fusion;signal-based fault diagnosis","Feature extraction;Fault diagnosis;Induction motors;Vibrations;Sensors;Kernel;Convolutional neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Battlefield Image Situational Awareness Application Based on Deep Learning","H. Peng; Y. Zhang; S. Yang; B. Song","School of Electrical Engineering and Automation, Wuhan University, 12390 Wuhan, Hubei China (e-mail: hpeng@whu.edu.cn); School of Electrical Engineering and Automation, Wuhan University, 12390 Wuhan, Hubei China (e-mail: 2015302540050@whu.edu.cn); School of Electrical Engineering and Automation, Wuhan University, 12390 Wuhan, Hubei China (e-mail: 2011302540054@whu.edu.cn); School of Electrical Engineering and Automation, Wuhan University, 12390 Wuhan, Hubei China (e-mail: 289004577@qq.com)","IEEE Intelligent Systems","","2019","PP","99","1","1","Information technology and the explosive growth of information amount is to construct a situational awareness system that can not only autonomously mine data information but also have certain perception ability of environmental situation by using deep learning theory. The situational awareness system needs to perceive the category, position and other attributes of objects and objects in the current environment, and then analyze the state of each situation element by integrating all kinds of sensor information, and make a certain degree of prediction and estimation of its development situation. In the whole situational awareness system, the discovery, category and location analysis of situational elements, namely object objects, are the basis and key to realize the overall function of the system. Based on this, this paper established a model based on YOLO battlefield situational awareness model, respectively on the five kinds of common objects: armed helicopters, missiles, tanks, guns and soldiers for category and location awareness, using convolution neural network inference to the input image, and then directly to get all the objects in the image location, category and the corresponding confidence probability, to realize the end-to-end learning.","","","10.1109/MIS.2019.2953685","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8903625","Deep learning;Convolution neural network;YOLO;Situational awareness","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"CTBRNN: A Novel Deep-Learning Based Signal Sequence Detector for Communications Systems","L. Sun; Y. Wang","Department of Information and Communication Engineering, Xi'an Jiaotong University, Xi'an, Shaanxi China 710049 (e-mail: lisun@mail.xjtu.edu.cn); Department of Information and Communication Engineering, Xi'an Jiaotong University, Xi'an, Shaanxi China (e-mail: yuweiwang1126@gmail.com)","IEEE Signal Processing Letters","","2019","PP","99","1","1","In many emerging communications systems such as molecular communications and cross-medium communications, the channel models are extremely difficult to be analytically formulated, which makes it impossible for the receivers to perform signal detection using traditional approaches. To address this issue, we propose a deep-learning based method for signal sequence detection. In particular, a novel neural network (NN) architecture, called Cooperative and Time-varying Bidirectional Recurrent Neural Network (CTBRNN), is developed, which learns from the training data and estimates the transmitted signal sequence without knowing the underlying channel model. Furthermore, we develop a chemical communication experimental platform to collect real data, which is used to train the NN and evaluate the performance of the developed detector. Experimental results demonstrate that, the proposed detection method outperforms the existing NN-based and NN-free candidate solutions in terms of the detection accuracy.","","","10.1109/LSP.2019.2953673","Key Research and Development Program of Shaanxi Province; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8902109","Sequence detection;deep-learning;recurrent neural networks;molecular communications","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Towards Accurate Prediction for High-Dimensional and Highly-Variable Cloud Workloads with Deep Learning","Z. Chen; J. Hu; G. Min; A. Zomaya; T. El-Ghazawi","Computer Science, University of Exeter College of Engineering Mathematics and Physical Sciences, 151756 Exeter, Devon United Kingdom of Great Britain and Northern Ireland EX4 4QF (e-mail: zc300@exeter.ac.uk); CS, Exeter, exeter, devon United Kingdom of Great Britain and Northern Ireland (e-mail: J.Hu@exeter.ac.uk); Department of Mathematics and Computer Science, University of Exeter, Exeter, Exeter United Kingdom of Great Britain and Northern Ireland (e-mail: G.Min@exeter.ac.uk); School of Information Technologies, The University of Sydney, Sydney, New South Wales Australia 2006 (e-mail: albert.zomaya@sydney.edu.au); Department of Electrical and Computer Engineering, The George Washington University, Washington, DC, District of Columbia United States 20052 (e-mail: tarek@gwu.edu)","IEEE Transactions on Parallel and Distributed Systems","","2019","PP","99","1","1","Resource provisioning for cloud computing necessitates the adaptive and accurate prediction of cloud workloads. However, the existing methods cannot effectively predict the high-dimensional and highly-variable cloud workloads. This results in resource wasting and inability to satisfy service level agreements (SLAs). Since recurrent neural network (RNN) is naturally suitable for sequential data analysis, it has been recently used to tackle the problem of workload prediction. However, RNN often performs poorly on learning long-term memory dependencies, and thus cannot make the accurate prediction of workloads. To address these important challenges, we propose a deep Learning based Prediction Algorithm for cloud Workloads (L-PAW). First, a top-sparse auto-encoder (TSA) is designed to effectively extract the essential representations of workloads from the original high-dimensional workload data. Next, we integrate TSA and gated recurrent unit (GRU) block into RNN to achieve the adaptive and accurate prediction for highly-variable workloads. Using real-world workload traces from Google and Alibaba cloud data centers and the DUX-based cluster, extensive experiments are conducted to demonstrate the effectiveness and adaptability of the L-PAW for different types of workloads with various prediction lengths. Moreover, the performance results show that the L-PAW achieves superior prediction accuracy compared to the classic RNN-based and other workload prediction methods for high-dimensional and highly-variable real-world cloud workloads.","","","10.1109/TPDS.2019.2953745","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8902077","Cloud computing;workload prediction;resource provisioning;sequential data analysis;deep learning","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Attention by Selection: A Deep Selective Attention Approach to Breast Cancer Classification","B. Xu; J. Liu; X. Hou; B. Liu; J. Garibaldi; I. O. Ellis; A. Green; L. Shen; G. Qiu","College of Information Engineering, Shenzhen University, Shenzhen 518060, China and Guangdong Key Laboratory of Intelligent Information Processing, Shenzhen 518060, China and Shenzhen Institute of Artificial Intelligence and Robotics for Society, Shenzhen, China.; College of Information Engineering, Shenzhen University, Shenzhen 518060, China and Guangdong Key Laboratory of Intelligent Information Processing, Shenzhen 518060, China and Shenzhen Institute of Artificial Intelligence and Robotics for Society, Shenzhen, China and Histo Pathology Diagnostic Center, Shanghai, China.; College of Information Engineering, Shenzhen University, Shenzhen 518060, China and Guangdong Key Laboratory of Intelligent Information Processing, Shenzhen 518060, China and Shenzhen Institute of Artificial Intelligence and Robotics for Society, Shenzhen, China.; College of Information Engineering, Shenzhen University, Shenzhen 518060, China and Guangdong Key Laboratory of Intelligent Information Processing, Shenzhen 518060, China and Shenzhen Institute of Artificial Intelligence and Robotics for Society, Shenzhen, China and Histo Pathology Diagnostic Center, Shanghai, China.; School of Computer Science, University of Nottingham, Nottingham NG7 2RD, U.K.; Faculty of Medicine & Health Sciences, University of Nottingham, Nottingham NG7 2RD, U.K.; Faculty of Medicine & Health Sciences, University of Nottingham, Nottingham NG7 2RD, U.K.; Computer Vision Institute, School of Computer Science and Software Engineering, National Engineering Laboratory for Big Data System Computing Technology, Shenzhen University, Shenzhen 518060, China and Guangdong Key Laboratory of Intelligent Information Processing, Shenzhen University, Shenzhen 518060, China.; College of Information Engineering, Shenzhen University, Shenzhen 518060, China Guangdong Key Laboratory of Intelligent Information Processing, Shenzhen 518060, China and School of Computer Science, University of Nottingham, Nottingham NG7 2RD, U.K.","IEEE Transactions on Medical Imaging","","2019","PP","99","1","1","Deep learning approaches are widely applied to histopathological image analysis due to the impressive levels of performance achieved. However, when dealing with high-resolution histopathological images, utilizing the original image as input to the deep learning model is computationally expensive, while resizing the original image to achieve low resolution incurs information loss. Some hard-attention based approaches have emerged to select possible lesion regions from images to avoid processing the original image. However, these hard-attention based approaches usually take a long time to converge with weak guidance, and valueless patches may be trained by the classifier. To overcome this problem, we propose a deep selective attention approach that aims to select valuable regions in the original images for classification. In our approach, a decision network is developed to decide where to crop and whether the cropped patch is necessary for classification. These selected patches are then trained by the classification network, which then provides feedback to the decision network to update its selection policy. With such a co-evolution training strategy, we show that our approach can achieve a fast convergence rate and high classification accuracy. Our approach is evaluated on a public breast cancer histopathological image database, where it demonstrates superior performance compared to state-of-the-art deep learning approaches, achieving approximately 98% classification accuracy while only taking 50% of the training time of the previous hard-attention approach.","","","10.1109/TMI.2019.2962013","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8941117","Histopathological image;reinforcement learning;breast cancer classification;deep learning","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Skip-Connected Covariance Network for Remote Sensing Scene Classification","N. He; L. Fang; S. Li; J. Plaza; A. Plaza","College of Electrical and Information Engineering, Hunan University, Changsha 410082, China, and also with the Key Laboratory of Visual Perception and Artificial Intelligence of Hunan Province, Hunan University, Changsha 410082, China.; College of Electrical and Information Engineering, Hunan University, Changsha 410082, China, and also with the Key Laboratory of Visual Perception and Artificial Intelligence of Hunan Province, Hunan University, Changsha 410082, China (e-mail: fangleyuan@gmail.com).; College of Electrical and Information Engineering, Hunan University, Changsha 410082, China, and also with the Key Laboratory of Visual Perception and Artificial Intelligence of Hunan Province, Hunan University, Changsha 410082, China.; Hyperspectral Computing Laboratory, Department of Technology of Computers and Communications, Escuela Politécnica, University of Extremadura, E-10003 Cáceres, Spain.; Hyperspectral Computing Laboratory, Department of Technology of Computers and Communications, Escuela Politécnica, University of Extremadura, E-10003 Cáceres, Spain.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","14","This paper proposes a novel end-to-end learning model, called skip-connected covariance (SCCov) network, for remote sensing scene classification (RSSC). The innovative contribution of this paper is to embed two novel modules into the traditional convolutional neural network (CNN) model, i.e., skip connections and covariance pooling. The advantages of newly developed SCCov are twofold. First, by means of the skip connections, the multi-resolution feature maps produced by the CNN are combined together, which provides important benefits to address the presence of large-scale variance in RSSC data sets. Second, by using covariance pooling, we can fully exploit the second-order information contained in such multi-resolution feature maps. This allows the CNN to achieve more representative feature learning when dealing with RSSC problems. Experimental results, conducted using three large-scale benchmark data sets, demonstrate that our newly proposed SCCov network exhibits very competitive or superior classification performance when compared with the current state-of-the-art RSSC techniques, using a much lower amount of parameters. Specifically, our SCCov only needs 10% of the parameters used by its counterparts.","","","10.1109/TNNLS.2019.2920374","National Natural Science Foundation of China; Science and Technology Plan Project Fund of Hunan Province; Science and Technology Talents Program of Hunan Association for Science and Technology; National Key R and D Program of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8759970","Covariance pooling;deep neural network;multi-layer feature;scene recognition.","Feature extraction;Learning systems;Neural networks;Training;Aggregates;Computational modeling;Remote sensing","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Fuzzy Membership Functional Analysis for Nonparametric Deep Models of Image Features","M. Kumar; B. Freudenthaler","Fakultit for Informatik und Elektrotechnik, Institut for Automatisierungstechnik, Rostock, M.V. Germany 18059 (e-mail: mohit.kumar@uni-rostock.de); Data Analysis Systems, Software Competence Center Hagenberg GmbH, 319797 Hagenberg, Oberosterreich Austria (e-mail: bernhard.freudenthaler@scch.at)","IEEE Transactions on Fuzzy Systems","","2019","PP","99","1","1","The application of fuzzy theory to deep learning is limited 1) under the realm of deep neural networks; 2) to the parametric form of modeling; and 3) relying on gradient-descent based numerical algorithms for optimization because of lack of analytical solutions. This study fills this gap by providing an analytical nonparametric deep modeling solution based on the mathematical analysis of membership functions assigned to model variables. The nonparametric approach is based on the concept of representing the unknown mappings (between input and output variables) through a fuzzy set with Student-t type membership function such that the dimension of membership function increases with an increasing data size. This concept of function representation is referred to as “Student-t fuzzy-mapping” in this study. The most significant feature of this paper is to analytically derive the mathematical expressions for membership functions (which quantify uncertainties regarding the values of variables) using variational optimization such that the degree-of-belongingness of given data to the considered data-model is maximized. The study focuses on the modeling of image features where a layer of the deep-model first projects the feature vector onto a lower dimensional subspace and then construct the output feature vector through Student-t fuzzy-mappings. Numerous image classification experiments are provided to support the proposed approach.","","","10.1109/TFUZZ.2019.2950636","Bundesministerium for Verkehr Innovation und Technologie; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8888203","Fuzzy;membership function;nonparametric model;learning;variational optimization","Deep learning;Uncertainty;Analytical models;Numerical models;Mathematical model;Neural networks;Fuzzy sets","","","","","","","","","","IEEE","IEEE Early Access Articles"
"From W-Net to CDGAN: Bitemporal Change Detection via Deep Learning Techniques","B. Hou; Q. Liu; H. Wang; Y. Wang","State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing 100191 China, and also with the National Computer Network Emergency Response Technical Team, Coordination Center of China, Beijing 100029, China.; State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing 100191 China (e-mail: qingjie.liu@buaa.edu.cn).; State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing 100191 China.; State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing 100191 China.","IEEE Transactions on Geoscience and Remote Sensing","","2019","PP","99","1","13","Traditional change detection methods usually follow the image differencing, change feature extraction, and classification framework, and their performance is limited by such simple image domain differencing and also the hand-crafted features. Recently, the success of deep convolutional neural networks (CNNs) has widely spread across the whole field of computer vision for their powerful representation abilities. Therefore, in this article, we address the remote sensing image change detection problem with deep learning techniques. We first propose an end-to-end dual-branch architecture, termed the W-Net, with each branch taking as input one of the two bitemporal images as in the traditional change detection models. In this way, CNN features with more powerful representative abilities can be obtained to boost the final detection performance. In addition, W-Net performs differencing in the feature domain rather than in the traditional image domain, which greatly alleviates loss of useful information for determining the changes. Furthermore, by reformulating change detection as an image translation problem, we apply the recently popular generative adversarial network (GAN) in which our W-Net serves as the generator, leading to a new GAN architecture for change detection which we call CDGAN. To train our networks and also facilitate future research, we construct a large scale data set by collecting images from Google Earth and provide carefully manually annotated ground truths. Experiments show that our proposed methods can provide fine-grained change detection results superior to the existing state-of-the-art baselines.","","","10.1109/TGRS.2019.2948659","Natural Science Foundation of China NSFC; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8891676","Change detection;change detection generative adversarial network (CDGAN);convolutional neural network (CNN);remote sensing;W-Net.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Combining Planning and Deep Reinforcement Learning in Tactical Decision Making for Autonomous Driving","C. Hoel; K. Driggs-Campbell; K. Wolff; L. Laine; M. Kochenderfer","Department of Mechanics and Maritime Sciences, Chalmers University of Technology, 11248 Gothenburg, Vastra Gotaland Sweden (e-mail: carl-johan.hoel@volvo.com); Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, 14589 Urbana, Illinois United States (e-mail: krdc@illinois.edu); Department of Mechanics and Maritime Sciences, Chalmers University of Technology, 11248 Gothenburg, Vastra Gotaland Sweden (e-mail: krister.wolff@chalmers.se); Department of Mechanics and Maritime Sciences, Chalmers University of Technology, 11248 Gothenburg, Vastra Gotaland Sweden (e-mail: leo.laine@volvo.com); Aeronautics and Astronautics Department, Stanford University, 6429 Stanford, California United States (e-mail: mykel@standford.edu)","IEEE Transactions on Intelligent Vehicles","","2019","PP","99","1","1","Tactical decision making for autonomous driving is challenging due to the diversity of environments, the uncertainty in the sensor information, and the complex interaction with other road users. This paper introduces a general framework for tactical decision making, which combines the concepts of planning and learning, in the form of Monte Carlo tree search and deep reinforcement learning. The method is based on the AlphaGo Zero algorithm, which is extended to a domain with a continuous state space where self-play cannot be used. The framework is applied to two different highway driving cases in a simulated environment and it is shown to perform better than a commonly used baseline method. The strength of combining planning and learning is also illustrated by a comparison to using the Monte Carlo tree search or the neural network policy separately.","","","10.1109/TIV.2019.2955905","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8911507","Autonomous driving;tactical decision making;reinforcement learning;Monte Carlo tree search","Planning;Decision making;Autonomous vehicles;Monte Carlo methods;Reinforcement learning;Road transportation;Neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"On Modelling Label Uncertainty in Deep Neural Networks: Automatic Estimation of Intra-observer Variability in 2D Echocardiography Quality Assessment","Z. Liao; H. Girgis; A. Abdi; H. Vaseli; J. Hetherington; R. Rohling; K. Gin; T. Tsang; P. Abolmaesumi","Department of Electrical and Computer Engineering, The University of British Columbia, Vancouver, BC V6T 1Z4, Canada.; Vancouver General Hospital Echocardiography Laboratory, Division of Cardiology, Department of Medicine, The University of British Columbia, Vancouver, BC V5Z 1M9, Canada.; Department of Electrical and Computer Engineering, The University of British Columbia, Vancouver, BC V6T 1Z4, Canada.; Department of Electrical and Computer Engineering, The University of British Columbia, Vancouver, BC V6T 1Z4, Canada.; Department of Electrical and Computer Engineering, The University of British Columbia, Vancouver, BC V6T 1Z4, Canada.; Department of Electrical and Computer Engineering and the Department of Mechanical Engineering, The University of British Columbia, Vancouver, BC V6T 1Z4, Canada.; Vancouver General Hospital Echocardiography Laboratory, Division of Cardiology, Department of Medicine, The University of British Columbia, Vancouver, BC V5Z 1M9, Canada.; Vancouver General Hospital Echocardiography Laboratory, Division of Cardiology, Department of Medicine, The University of British Columbia, Vancouver, BC V5Z 1M9, Canada and Director of the Vancouver General Hospital and University of British Columbia Echocardiography Laboratories.; Department of Electrical and Computer Engineering, The University of British Columbia, Vancouver, BC V6T 1Z4, Canada.","IEEE Transactions on Medical Imaging","","2019","PP","99","1","1","Uncertainty of labels in clinical data resulting from intra-observer variability can have direct impact on the reliability of assessments made by deep neural networks. In this paper, we propose a method for modelling such uncertainty in the context of 2D echocardiography (echo), which is a routine procedure for detecting cardiovascular disease at point-of-care. Echo imaging quality and acquisition time is highly dependent on the operator’s experience level. Recent developments have shown the possibility of automating echo image quality quantification by mapping an expert’s assessment of quality to the echo image via deep learning techniques. Nevertheless, the observer variability in the expert’s assessment can impact the quality quantification accuracy. Here, we aim to model the intra-observer variability in echo quality assessment as an aleatoric uncertainty modelling regression problem with the introduction of a novel method that handles the regression problem with categorical labels. A key feature of our design is that only a single forward pass is sufficient to estimate the level of uncertainty for the network output. Compared to the 0.11±0.09 absolute error (in a scale from 0 to 1) archived by the conventional regression method, the proposed method brings the error down to 0.09±0.08, where the improvement is statistically significant and equivalents to 5.7% test accuracy improvement. The simplicity of the proposed approach means that it could be generalized to other applications of deep learning in medical imaging, where there is often uncertainty in clinical labels.","","","10.1109/TMI.2019.2959209","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8932548","Label uncertainty;Modelling;2D echocardiography;Quality assessment;Cross-entropy;Loss regularization;Deep learning;DenseNet;LSTM;Deep neural networks","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Improved Deep Belief Network for Short-Term Load Forecasting Considering Demand-Side Management","X. Kong; C. Li; F. Zheng; C. Wang","School of Electrical Engineering and Automation, tianjin University, Tianjin China 300072 (e-mail: eekongxy@tju.edu.cn); Tianjin University, Tianjin China (e-mail: lchuangsky@tju.edu.cn); Tianjin China (e-mail: zhengfeng6_6@163.com); school of eleltrical engineering and automation, Tianjin University, Tianjin China 300072 (e-mail: cswang@tju.edu.cn)","IEEE Transactions on Power Systems","","2019","PP","99","1","1","Demand-side management (DSM) increases the complexity of the forecasting environment, which makes traditional forecasting methods difficult to meet the firm's need for predictive accuracy. Since deep learning can comprehensively consider various factors to improve the prediction results, this paper improves the deep belief network from three aspects of input data, model and performance, and uses it to solve the short-term load forecasting problem in DSM. In the data optimization stage, the Hankel matrix is constructed to increase the input weight of DSM data, and the gray relational analysis is used to select strongly correlated data from other data. In the model optimization stage, the Gauss-Bernoulli restricted Boltzmann machine is used as the first restricted Boltzmann machine of the deep network to transform the continuity features of the input data into binomial distribution features. In the performance optimization stage, a pre-training method combining error constraint and unsupervised learning is proposed to provide good initial parameters, and the global fine-tuning of network parameters is realized based on genetic algorithm. Based on the actual data of Tianjin Power Grid in China, the experimental results show that the proposed method is superior to other methods.","","","10.1109/TPWRS.2019.2943972","National Basic Research Program of China (973 Program); National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8854896","Short-term load forecasting;deep belief network;restricted Boltzmann machine;deep learning;demand-side management","Load modeling;Predictive models;Data models;Load forecasting;Optimization;Training;Autoregressive processes","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Pothole Detection Using Computer Vision and Learning","A. Dhiman; R. Klette","School of Engineering, Computer and Mathematical Sciences, EEE Department, Auckland University of Technology, Auckland 1010, New Zealand.; School of Engineering, Computer and Mathematical Sciences, EEE Department, Auckland University of Technology, Auckland 1010, New Zealand (e-mail: reinhard.klette@aut.ac.nz).","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","15","Techniques for identifying potholes on road surfaces aim at developing strategies for real-time or offline identification of potholes, to support real-time control of a vehicle (for driver assistance or autonomous driving) or offline data collection for road maintenance. For these reasons, research around the world has comprehensively explored strategies for the identification of potholes on roads. This paper starts with a brief review of the field; it classifies developed strategies into several categories. We, then, present our contributions to this field by implementing strategies for automatic identification of potholes. We developed and studied two techniques based on stereo-vision analysis of road environments ahead of the vehicle; we also designed two models for deep-learning-based pothole detection. An experimental evaluation of those four designed methods is provided, and conclusions are drawn about particular benefits of these methods.","","","10.1109/TITS.2019.2931297","PhD Scholarship from Aukland University of Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8788687","Pothole detection;stereo vision;deep learning.","Roads;Three-dimensional displays;Image reconstruction;Shape;Two dimensional displays;Accelerometers;Cameras","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Semantic Labeling of ALS Point Cloud via Learning Voxel and Pixel Representations","N. Qin; X. Hu; P. Wang; J. Shan; Y. Li","School of Remote Sensing and Information Engineering, Wuhan University, Wuhan 430079, China.; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan 430079, China, and also with the School of Civil Engineering, Purdue University, West Lafayette, IN 47907 USA (e-mail: huxy@whu.edu.cn).; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan 430079, China.; School of Civil Engineering, Purdue University, West Lafayette, IN 47907 USA.; School of Civil Engineering and Architecture, Nanchang University, Nanchang 330031, China.","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","Semantic labeling is a fundamental task that can provide useful semantics for many other 3-D processing tasks. To tackle the challenge of airborne laser scanning (ALS) point cloud classification, current state-of-the-art methods leverage the capabilities of deep learning. However, they are limited due to the weaknesses of the isolated use of individual representations of point clouds. To address this issue, this letter presents a novel network, VPNet, which ensembles voxel and pixel representation-based networks, to predict class probabilities for each light detection and ranging (LiDAR) point. A fully connected conditional random field-based global refinement is then performed over each point in the point cloud to produce a fine-grained classification result. On the ISPRS 3-D Semantic Labeling Contest, our solution sets a new state of the art by improving the highest average F1-score and the highest average per-class accuracy from 69.3% to 73.9%, and 69.0% to 74.9%, respectively. The overall accuracy of our approach is 84.0%.","","","10.1109/LGRS.2019.2931119","National Basic Research Program of China (973 Program); National Natural Science Foundation of China; National Basic Research Program of China (973 Program); National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8801942","Airborne laser scanning (ALS);deep learning;global refinement;semantic labeling.","Three-dimensional displays;Semantics;Training;Computer architecture;Labeling;Remote sensing;Measurement","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Blind Realistic Blur Assessment Based on Discrepancy Learning","L. Li; Y. Zhou; K. Gu; Y. Yang; Y. Fang","School of Artificial Intelligence, Xidian University, Xi’an 710071, China.; School of Information and Control Engineering, China University of Mining and Technology, Xuzhou 221116, China.; BJUT Faculty of Information Technology, Beijing University of Technology, Beijing 100124, China.; School of Electronics and Computer Science, the University of Southampton, Southampton, SO17 1BJ, United Kingdom.; School of Information Technology, Jiangxi University of Finance and Economics, Nanchang 330032, China.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Blur is one of the most common distortions that degrade natural images. This stimulates the blossom of sharpness assessment metrics. Existing sharpness metrics possess good performance for evaluating simulated blur, but are limited for the more common realistic blur that are introduced during image capture and processing in real life. To this end, we propose an effective Realistic Blur Assessment method (RBA) based on discrepancy learning. First, motivated by the fact that the distortion-free reference images are usually unavailable in practice, but the Human Visual System (HVS) can still accurately perceive image sharpness by quantifying the perceptual discrepancy between the distorted image and the hallucinated reference image in mind, we propose to train a discrepancy generation model to automatically generate the discrepancy map from the distorted image analogous to the HVS. This is achieved by using a deep neural network with rich training images. With the discrepancy map, two sharpness-aware features, i.e. sparse representation based entropy of primitive and content-guided variation of power, are then extracted to severally quantify spatial visual information amount and spectral power. Finally, the two features are integrated to produce the overall sharpness score. Extensive experiments demonstrate the superiority of the proposed method over the state-of-the-arts.","","","10.1109/TCSVT.2019.2947450","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8869739","Realistic blur assessment;Discrepancy learning;Deep convolutional network;Entropy of primitive;Variation of powerx","Measurement;Training;Feature extraction;Databases;Entropy;Image edge detection;Image capture","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Hybrid deep neural networks for detection of non-technical losses in electricity smart meters","M. Buzau; J. Tejedor-Aguilera; P. Cruz-Romero; A. Gómez-Expósito","Electrical Engineering, Universidad de Sevilla Escuela Tecnica Superior de Ingenieria de Sevilla, 83037 Sevilla, Andalucia Spain 41092 (e-mail: madalina.buzau@gmail.com); Non-technical losses detection, Endesa SA, 67807 Seville Spain (e-mail: javier.tejedor@enel.com); Universidad De Seville, Sevilla Spain 41092 (e-mail: plcruz@us.es); University of Sevilla Spain, Sevilla Spain 41092 (e-mail: age@us.es)","IEEE Transactions on Power Systems","","2019","PP","99","1","1","Non-technical losses in electricity utilities are responsible for major revenue losses. In this paper, we propose a novel end-to-end solution to self-learn the features for detecting anomalies and frauds in smart meters using a hybrid deep neural network. The network is fed with simple raw data, removing the need of handcrafted feature engineering. The proposed architecture consists of a long short-term memory network and a multi-layer perceptrons network. The first network analyses the raw daily energy consumption history whilst the second one integrates non-sequential data such as its contracted power or geographical information. The results show that the hybrid neural network significantly outperforms state-of-the-art classifiers as well as previous deep learning models used in non-technical losses detection. The model has been trained and tested with real smart meter data of Endesa, the largest electricity utility in Spain.","","","10.1109/TPWRS.2019.2943115","Endesa S.A.; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8846082","Supervised learning;hybrid neural networks;non-technical losses;smart meter data","Inspection;Neural networks;Smart meters;History;Deep learning;Energy consumption;Data models","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Learning-Based Classification of Liver Cancer Histopathology Images Using Only Global Labels","C. Sun; A. Xu; D. Liu; Z. Xiong; F. Zhao; W. Ding","Center for Biomedical Engineering, University of Science and Technology of China, 12652 Hefei, Anhui China (e-mail: cls118@mail.ustc.edu.cn); First Affiliated Hospital of USTC, Division of Life Sciences and Medicine, University of Science and Technology of China, 12652 Hefei, Anhui China (e-mail: aoxuhf@163.com); Department of Electronic Engineering and Information Science, University of Science and Technology of China, 12652 Hefei, Anhui China (e-mail: dongeliu@ustc.edu.cn); Department of Electronic Engineering and Information Science, University of Science and Technology of China, 12652 Hefei, Anhui China (e-mail: zwxiong@ustc.edu.cn); Department of Automation, University of Science and Technology of China, 12652 Hefei, Anhui China (e-mail: fzhao956@ustc.edu.cn); Center for Biomedical Engineering, University of Science and Technology of China, 12652 Hefei, Anhui China (e-mail: wpdings@ustc.edu.cn)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","Liver cancer is a leading cause of cancer deaths worldwide due to its high morbidity and mortality. Histopathological image analysis (HIA) is a crucial step in the early diagnosis of liver cancer and is routinely performed manually. However, this process is time-consuming, error-prone, and easily affected by the expertise of pathologists. Recently, computer-aided methods have been widely applied to medical image analysis; however, the current medical image analysis studies have not yet focused on the histopathological morphology of liver cancer due to its complex features and the insufficiency of training images with detailed annotations. This paper proposes a deep learning method for liver cancer histopathological image classification using only global labels. To compensate for the lack of detailed cancer region annotations in those images, patch features are extracted and fully utilized. Transfer learning is used to obtain the patch-level features and then combined with multiple-instance learning to acquire the image-level features for classification. The method proposed here solves the processing of large-scale images and training sample insufficiency in liver cancer histopathological images for image classification. The proposed method can distinguish and classify liver histopathological images as abnormal or normal with high accuracy, thus providing support for the early diagnosis of liver cancer.","","","10.1109/JBHI.2019.2949837","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8884135","Global labels;histopathological image analysis;liver cancer;multiple instance learning;transfer learning","Liver;Cancer;Feature extraction;Image analysis;Image color analysis;Training;Biomedical imaging","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Knowledge-Augmented Multimodal Deep Regression Bayesian Networks for Emotion Video Tagging","S. Wang; L. Hao; Q. Ji","School of Computer Science and Technology, University of Science and Technology of China, Hefei China 230027 (e-mail: sfwang@ustc.edu.cn); School of Computer Science and Technology, University of Science and Technology of China, 12652 Hefei China 230026 (e-mail: hlf101@mail.ustc.edu.cn); Department of Electrical, Computer, and Systems Engineering, Rensselaer Polytechnic Institute, Troy, New York United States 12180-3590 (e-mail: qji@ecse.rpi.edu)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","The immanent dependencies between audio and visual modalities extracted from video content and the well-established film grammar (i.e., domain knowledge) are important for emotion video recognition and regression. However, these tools have yet to be exploited successfully. Therefore, we propose a multimodal deep regression Bayesian network (MMDRBN) to capture the relationship between audio and visual modalities for emotion video tagging. We then modify the structure of the MMDRBN to incorporate domain knowledge. A regression Bayesian network (RBN) is formed from one latent layer, one visible layer and directed links from the latent layer to the visible layer. RBN is able to fully represent the data, since it captures the dependencies not only among the visible variables but also among the latent variables given visible variables. For the MMDRBN, first, we learn several layers of RBNs using audio and visual modalities, and then stacked these RBNs to form two deep networks. A joint representation is obtained from the top layers of the two deep networks, capturing the deep dependencies between audio and visual modalities. We also summarize the main audio and visual elements used by filmmakers to convey emotions and formulate them as semantical meaningful middle-level representation, i.e., attributes. Through these attributes, we construct the knowledge-augmented MMDRBN, which learns a hybrid middle-level video representation using video data and the summarized attributes. Experimental results of both emotion recognition and regression from videos on the LIRIS-ACCEDE database demonstrate that the proposed model can successfully capture the intrinsic connections between audio and visual modalities, and integrate the middle-level representation learning from video data and semantical attributes summarized from film grammar. Thus, it achieves superior performance on emotion video tagging compared to state-of-the-art methods.","","","10.1109/TMM.2019.2934824","National Natural Science Foundation of China; Anhui Science and Technology Agency; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8794750","Regression Bayesian network;Multi-modal deep network;Domain knowledge;Emotion video tagging","Visualization;Tagging;Bayes methods;Feature extraction;Grammar;Emotion recognition;Knowledge engineering","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Extracting Relational Explanations From Deep Neural Networks: A Survey From a Neural-Symbolic Perspective","J. Townsend; T. Chaton; J. M. Monteiro","Trusted Technology Research Division, Fujitsu Laboratories of Europe Ltd., London UB4 8FE, U.K. (e-mail: joseph.townsend@u.k.fujitsu.com).; Artificial Intelligence Research Division, Fujitsu Laboratories of Europe Ltd., London UB4 8FE, U.K.; Artificial Intelligence Research Division, Fujitsu Laboratories of Europe Ltd., London UB4 8FE, U.K.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","15","The term ``explainable AI'' refers to the goal of producing artificially intelligent agents that are capable of providing explanations for their decisions. Some models (e.g., rule-based systems) are designed to be explainable, while others are less explicit ``black boxes'' for which their reasoning remains a mystery. One example of the latter is the neural network, and over the past few decades, researchers in the field of neural-symbolic integration (NSI) have sought to extract relational knowledge from such networks. Extraction from deep neural networks, however, has remained a challenge until recent years in which many methods of extracting distinct, salient features from input or hidden feature spaces of deep neural networks have been proposed. Furthermore, methods of identifying relationships between these features have also emerged. This article presents examples of old and new developments in extracting relational explanations in order to argue that the latter have analogies in the former and, as such, can be described in terms of long-established taxonomies and frameworks presented in early neural-symbolic literature. We also outline potential future research directions that come to light from this refreshed perspective.","","","10.1109/TNNLS.2019.2944672","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8889997","Explainable artificial intelligence;knowledge extraction;neural networks;neural-symbolic integration (NSI).","Feature extraction;Knowledge engineering;Biological neural networks;Neurons;Market research","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Development of an Efficient Coral-Coverage Estimation Method Using a Towed Optical Camera Array System [Speedy Sea Scanner (SSS)] and Deep-Learning-Based Segmentation: A Sea Trial at the Kujuku-Shima Islands","K. Mizuno; K. Terayama; S. Tabeta; S. Sakamoto; Y. Matsumoto; Y. Sugimoto; T. Ogawa; K. Sugimoto; H. Fukami; M. Sakagami; M. Deki; A. Kawakubo","Department of Environment Systems, Graduate School of Frontier Sciences, The University of Tokyo, Kashiwa 277-8561, Japan (e-mail: kmizuno@edu.k.u-tokyo.ac.jp).; RIKEN Center for Advanced Intelligence Project, Chuo-ku 103-0027, Japan, and also with the Graduate School of Medicine, Kyoto University, Kyoto 277-8501, Japan (e-mail: terayama.kei.8e@kyoto-u.ac.jp).; Department of Environment Systems, Graduate School of Frontier Sciences, The University of Tokyo, Kashiwa 277-8561, Japan (e-mail: tabeta@edu.k.u-tokyo.ac.jp).; Windy Network Corporation, Shizuoka 422-8006, Japan (e-mail: s-sakamoto@windy-net.co.jp).; Windy Network Corporation, Shizuoka 422-8006, Japan (e-mail: y-matsumoto@windy-net.co.jp).; Windy Network Corporation, Shizuoka 422-8006, Japan (e-mail: y-sugimoto@windy-net.co.jp).; Windy Network Corporation, Shizuoka 422-8006, Japan (e-mail: ogawa@windy-net.co.jp).; Windy Network Corporation, Shizuoka 422-8006, Japan (e-mail: sugimoto@windy-net.co.jp).; Faculty of Agriculture, University of Miyazaki, Miyazaki 889-2192, Japan (e-mail: hirofukami@cc.miyazaki-u.ac.jp).; Graduate School of Human and Environmental Studies, Kyoto University, Kyoto 606-8501, Japan (e-mail: sakagami.masaaki.6x@kyoto-u.ac.jp).; Saikai National Park Kujukushima Aquarium, Sasebo 858-0922, Japan (e-mail: m-deki@pearlsea.jp).; Saikai National Park Kujukushima Aquarium, Sasebo 858-0922, Japan (e-mail: a-kawakubo@pearlsea.jp).","IEEE Journal of Oceanic Engineering","","2019","PP","99","1","10","Various methods have been developed and used for monitoring marine benthic habitats, such as coral reefs and seagrass meadows. However, the efficiency of general survey methods [e.g., line intercept transects and autonomous underwater vehicles (AUVs)] still is not high. In this article, we propose a practical coral-coverage estimation method combining an effective survey system [Speedy Sea Scanner (SSS)] and a deep-learning-based estimation method. The SSS is a towed-type system with six cameras arrayed on the platform. The depth rating of the system in our trial was 50 m. The length of the array baseline was 4.4 m, and six cameras were placed on the platform with equal spacing. The sea trial was conducted at Kujuku-Shima, Japan, on September 30, 2017. We successfully generated 3-D models and high-quality orthophotos of the seafloor with high resolution of about 1.5 mm/pixel. The survey efficiency of the SSS was about 7000 m2/h. In addition, the experimental results of coral-coverage estimation showed that the corals can be distinguished with accuracy of about 80% in places with relatively high transparency, and the error of coverage estimation was 10% or less. The proposed coral-coverage estimation method is more efficient than other survey techniques and costs less than AUV surveying; therefore, it is expected to become a promising tool for marine environmental surveying.","","","10.1109/JOE.2019.2938717","Aid for Young Scientists A; Society for the Promotion of Science JSPS; Japan Science and Technology Agency JSPS; Kurita Water and Environment Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8862868","Coral;deep learning;optical camera array;structure from motion (SfM)","Cameras;Estimation;Image color analysis;Optical arrays;Boats;Global Positioning System;Monitoring","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Posting Techniques in Indoor Environments Based on Deep Learning for Intelligent Building Lighting System","X. Lin; P. Duan; Y. Zheng; W. Cai; X. Zhang","School of Information Science and Engineering, Shandong Normal University, Jinan, 250358, China.; School of Information Science and Engineering, Shandong Normal University, Jinan, 250358, China.; Key Lab of Intelligent Computing and Information Security in Universities of Shandong, Shandong Normal University, Jinan, 250358, China and Shandong Provincial Key Laboratory for Novel Distributed Computer Software Technology, Shandong Normal University, Jinan, 250358, China and Institute of Biomedical Sciences, Shandong Normal University, Jinan, 250358, China.; School of Electrical and Electronic Engineering, Nanyang Technological University, 639798, Singapore.; School of Electrical and Electronic Engineering, Nanyang Technological University, 639798, Singapore.","IEEE Access","","2019","PP","99","1","1","Recently, with the rapid development of society, solutions to reduce energy consumption in the world have attracted a lot of attention, especial electric energy. In this regard, a system that can control light on and off by determining the location of the person to reduce the waste of electricity used in public buildings, called intelligent building lighting system. Following the practical requirements of the intelligent building lighting system, a technique for positioning in indoor environments is proposed, supporting the design of a positioning system based on deep learning and the Cerebellar Model Articulation Controller (CMAC), called Y-CMAC.This technique adopts YOLOv3 (the method in the paper of YOLOv3: An Incremental Improvement) for object detections and makes the coordinate of a person in the image. On the other hand, using CMAC to calculate the actual position of the person in the indoor environment. Moreover, massive surveillance video is used to reduce the cost of equipment and facilitate the promotion of applications. The average positioning error is controlled at around 1m in this paper.","","","10.1109/ACCESS.2019.2959667","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933329","Intelligent building lighting system;Indoor positioning;Monitor Identification;CMAC;Deep learning","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Deep Learning for Plasma Tomography and Disruption Prediction From Bolometer Data","D. R. Ferreira; P. J. Carvalho; H. Fernandes","Institute for Plasmas and Nuclear Fusion (IPFN), Instituto Superior Técnico (IST), University of Lisbon, 1049-001 Lisbon, Portugal (e-mail: diogo.ferreira@tecnico.ulisboa.pt).; JET, Culham Science Centre, Abingdon OX14 3DB, U.K.; Institute for Plasmas and Nuclear Fusion (IPFN), Instituto Superior Técnico (IST), University of Lisbon, 1049-001 Lisbon, Portugal.","IEEE Transactions on Plasma Science","","2019","PP","99","1","10","The use of deep learning is facilitating a wide range of data processing tasks in many areas. The analysis of fusion data is no exception since there is a need to process large amounts of data collected from the diagnostic systems attached to a fusion device. Fusion data involve images and time series and are a natural candidate for the use of convolutional and recurrent neural networks. In this article, we describe how convolutional neural networks can be used to reconstruct the plasma radiation profile, and we discuss the potential of using RNNs for disruption prediction based on the same input data. Both approaches have been applied at the Joint European Torus (JET) using data from a multichannel diagnostic system. Similar approaches can be applied to other fusion devices and diagnostics.","","","10.1109/TPS.2019.2947304","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8882311","Deep learning;graphics processing unit (GPU) computing;nuclear fusion;plasma diagnostics.","Plasmas;Bolometers;Tomography;Image reconstruction;Cameras;Temperature measurement;Convolution","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Hotness- and Lifetime-Aware Data Placement and Migration for High-Performance Deep Learning on Heterogeneous Memory Systems","M. Han; J. Hyun; S. Park; W. Baek","School of ECE, Ulsan National Institute of Science and Technology, 131639 Ulsan, Ulsan Korea (the Republic of) 44919 (e-mail: hmg0228@unist.ac.kr); School of ECE, Ulsan National Institute of Science and Technology, 131639 Ulsan, Ulsan Korea (the Republic of) (e-mail: jhyun0812@unist.ac.kr); School of ECE, Ulsan National Institute of Science and Technology, 131639 Ulsan, Ulsan Korea (the Republic of) (e-mail: amita90@unist.ac.kr); School of ECE, Ulsan National Institute of Science and Technology, 131639 Ulsan, Ulsan Korea (the Republic of) 689-805 (e-mail: wbaek@unist.ac.kr)","IEEE Transactions on Computers","","2019","PP","99","1","1","Heterogeneous memory systems that comprise memory nodes with disparate architectural characteristics (e.g., DRAM and high-bandwidth memory (HBM)) have surfaced as a promising solution in a variety of computing domains ranging from embedded to high-performance computing. Since deep learning (DL) is one of the most widely-used workloads in various computing domains, it is crucial to explore efficient memory management techniques for DL applications that execute on heterogeneous memory systems. Despite extensive prior works on system software and architectural support for efficient DL, it still remains unexplored to investigate heterogeneity-aware memory management techniques for high-performance DL on heterogeneous memory systems. To bridge this gap, we analyze the characteristics of representative DL workloads on a real heterogeneous memory system. Guided by the characterization results, we propose HALO, hotness- and lifetime-aware data placement and migration for high-performance DL on heterogeneous memory systems. Through quantitative evaluation, we demonstrate the effectiveness of HALO in that it significantly outperforms various memory management policies (e.g., 28.2% higher performance than the HBM-Preferred policy) supported by the underlying system software and hardware, achieves the performance comparable to the ideal case with infinite HBM, incurs small performance overheads, and delivers high performance across a wide range of application working-set sizes.","","","10.1109/TC.2019.2949408","Institute of Information and Communications Technology Planning and Evaluation; National Research Foundation of Korea; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8883082","Hotness- and lifetime-aware data placement and migration;high-performance deep learning;heterogeneous memory systems","Memory management;Network architecture;Random access memory;Hardware;System software","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Detecting Trees in Street Images via Deep Learning with Attention Module","Q. Xie; D. Li; Z. Yu; J. Zhou; J. Wang","College of Mechanical and Electrical Engineering, Nanjing University of Aeronautics and Astronautics, China.; College of Mechanical and Electrical Engineering, Nanjing University of Aeronautics and Astronautics, China.; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, China.; College of Mechanical and Electrical Engineering, Nanjing University of Aeronautics and Astronautics, China.; College of Mechanical and Electrical Engineering, Nanjing University of Aeronautics and Astronautics, China.","IEEE Transactions on Instrumentation and Measurement","","2019","PP","99","1","1","Although object detection techniques have been widely employed in various practical applications, automatic tree detection is still a difficult challenge, especially for street view images. In this paper, we propose a unified end-to-end trainable network for automatic street tree detection, based on a state-of-the-art deep learning based object detector. We tackle low illumination and heavy occlusion conditions in tree detection, which have not been extensively studied until now, due to clear challenges. Existing generic object detectors cannot be directly applied to this task due to aforementioned challenges. To address these issues, we first present a simple, yet effective image brightness adjustment method to handle low illuminance cases. Moreover, we propose a novel loss and a tree part-attention module to reduce false detections caused by heavy occlusion, inspired by the previously proposed occlusion-aware R-CNN work. We train and evaluate several versions of the proposed network and validate the importance of each component. It is demonstrated that the resulting framework, Part Attention Network for Tree Detection (PANTD), can efficiently detect trees in street view images. Experimental results show that our approach achieves high accuracy and robustness under various conditions.","","","10.1109/TIM.2019.2958580","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8930566","Tree detection;convolutional neural network;deep learning;part attention;occlusion","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Dynamic Service Function Chain Embedding for NFV-Enabled IoT: A Deep Reinforcement Learning Approach","X. Fu; F. R. Yu; J. Wang; Q. Qi; J. Liao","State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, 100876, China.; Department of Systems and Computer Engineering, Carleton University, Ottawa, ON K1S 5B6, Canada.; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, 100876, China.; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, 100876, China.; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, 100876, China.","IEEE Transactions on Wireless Communications","","2019","PP","99","1","1","The Internet of things (IoT) is becoming more and more flexible and economical with the advancement in information and communication technologies. However, IoT networks will be ultra-dense with the explosive growth of IoT devices. Network function virtualization (NFV) emerges to provide flexible network frameworks and efficient resource management for the performance of IoT networks. In NFV-enabled IoT infrastructure, service function chain (SFC) is an ordered combination of virtual network functions (VNFs) that are related to each other based on the logic of IoT applications. However, the embedding process of SFC to IoT networks is becoming a big challenge due to the dynamic nature of IoT networks and the abundance of IoT terminals. In this paper, we decompose the complex VNFs into smaller virtual network function components (VNFCs) to make more effective decisions since VNF nodes and IoT network devices are usually heterogeneous. In addition, a deep reinforcement learning (DRL) based scheme with experience replay and target network is proposed as a solution that can efficiently handle complex and dynamic SFC embedding scenarios in IoT. Our simulations consider different types of IoT network topologies. The simulation results present the efficiency of the proposed dynamic SFC embedding scheme.","","","10.1109/TWC.2019.2946797","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8874993","IoT;NFV;SFC embedding;Deep Q-Learning","Internet of Things;Resource management;Wireless communication;Task analysis;Network function virtualization;Servers;Computational modeling","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Localizing B-lines in Lung Ultrasonography by Weakly-Supervised Deep Learning, in-vivo results","R. J. van Sloun; L. Demi","Electrical Engineering, Eindhoven University of Technology, Eindhoven Netherlands 5612 AZ (e-mail: R.J.G.v.Sloun@tue.nl); Information Engineering and Computer Science, Universita degli Studi di Trento, 19034 Trento Italy 38100 (e-mail: libertario.demi@unitn.it)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","Lung ultrasound (LUS) is nowadays gaining growing attention from both the clinical and technical world. Of particular interest are several imaging-artifacts, e.g., A- and B- line artifacts. While A-lines are a visual pattern which essentially represent a healthy lung surface, B-line artifacts correlate with a wide range of pathological conditions affecting the lung parenchyma. In fact, the appearance of B-lines correlates to an increase in extravascular lung water, interstitial lung diseases, cardiogenic and non-cardiogenic lung edema, interstitial pneumonia and lung contusion. Detection and localization of B-lines in a LUS video are therefore tasks of great clinical interest, with accurate, objective and timely evaluation being critical. This is particularly true in environments such as the emergency units, where timely decision may be crucial. In this work, we present and describe a method aimed at supporting clinicians by automatically detecting and localizing B-lines in an ultrasound scan. To this end, we employ modern deep learning strategies and train a fully convolutional neural network to perform this task on B-mode images of dedicated ultrasound phantoms in-vitro, and on patients in-vivo. An accuracy, sensitivity, specificity, negative and positive predictive value equal to 0.917, 0.915, 0.918, 0.950 and 0.864 were achieved in-vitro, respectively. Using a clinical system in-vivo, these statistics were 0.892, 0.871, 0.930, 0.798 and 0.958, respectively. We moreover calculate neural attention maps that visualize which components in the image triggered the network, thereby offering simultaneous weakly-supervised localization. These promising results confirm the capability of the proposed method to identify and localize the presence of B-lines in clinical lung ultrasonography.","","","10.1109/JBHI.2019.2936151","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8805336","Lung Ultrasound Imaging;B-lines;Deep Learning;Class Activation Mapping","Lung;Ultrasonic imaging;Training;Phantoms;Diseases;Imaging phantoms;Feature extraction","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Distributed and Energy-Efficient Mobile Crowdsensing with Charging Stations by Deep Reinforcement Learning","C. H. Liu; Z. Dai; Y. Zhao; J. Crowcroft; D. O. Wu; K. Leung","School of Computer Science and Technology, Beijing Institute of Technology, 47833 Beijing, Beijing China 100081 (e-mail: liuchi02@gmail.com); School of Computer Science and Technology, Beijing Institute of Technology, 47833 Beijing, Beijing China (e-mail: 604896160@qq.com); School of Computer Science and Technology, Beijing Institute of Technology, 47833 Beijing, Beijing China (e-mail: 769572294@qq.com); Computer Lab, University of Cambridge, 2152 Cambridge, Cambridgeshire United Kingdom of Great Britain and Northern Ireland (e-mail: jon.crowcroft@cl.cam.ac.uk); Department of Electrical and Computer Engineering, University of Florida, 3463 Gainesville, Florida United States (e-mail: dpwu@ufl.edu); EEE and Computing, Imperial College, London, London, London United Kingdom of Great Britain and Northern Ireland (e-mail: kin.leung@imperial.ac.uk)","IEEE Transactions on Mobile Computing","","2019","PP","99","1","1","Mobile crowdsensing (MCS) represents a new sensing paradigm that utilizes the smart mobile devices to collect and share data. With the popularity of unmanned vehicles like UAVs and driverless cars, they can provide much more reliable, accurate and cost-efficient sensing services. In this paper, we propose a distributed control framework for energy-efficient and DIstributed VEhicle navigation with chaRging sTations, called Re-Divert"". It is a distributed multi-agent deep reinforcement learning (DRL) solution, which uses a CNN to extract useful spatial features as the input to the actor-critic network to produce a real-time action. Also, e-Divert incorporates a distributed prioritized experience replay for better exploration and exploitation, and an LSTM enabled N-step temporal sequence modeling. The solution maximizes the energy efficiency, data collection ratio, geographic fairness, and minimize the energy consumption simultaneously. We find an appropriate set of hyperparameters that achieve the best performance, i.e., 5 actors in Ape-X architecture, priority exponent 0.5, and LSTM sequence length 3. Finally, we compare with three baselines including one state-of-the-art approach MADDPG and results show that our proposed e-Divert significantly improves the energy efficiency, as compared to MADDPG, by 3.62 and 2.36 times on average when varying different numbers of vehicles and charging stations, respectively.","","","10.1109/TMC.2019.2938509","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8821415","Mobile crowdsensing;charging stations;deep reinforcement learning","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Joint Antenna Selection and Hybrid Beamformer Design using Unquantized and Quantized Deep Learning Networks","A. M. Elbir; K. V. Mishra","Department of Electrical and Electronics Engineering, Duzce University, Duzce, Turkey.; University of Iowa, Iowa City, IA 52242 USA.","IEEE Transactions on Wireless Communications","","2019","PP","99","1","1","In millimeter-wave communications, multiple-input-multiple-output (MIMO) systems use large antenna arrays to achieve high gain and spectral efficiency. These massive MIMO systems employ hybrid beamformers to reduce power consumption associated with fully digital beamforming in large arrays. Further savings in cost and power are possible through the use of subarrays. Unlike prior works that resort to large latency methods such as optimization and greedy search for subarray selection, we propose a deep-learning-based approach in order to overcome the complexity issue without causing significant performance loss. We formulate antenna selection and hybrid beamformer design as a classification/prediction problem for convolutional neural networks (CNNs). For antenna selection, the CNN accepts the channel matrix as input and outputs a subarray with optimal spectral efficiency. The resultant subarray channel matrix is then again fed to a CNN to obtain analog and baseband beamformers. We train the CNNs with several noisy channel matrices that have different channel statistics in order to achieve a robust performance at the network output. Numerical experiments show that our CNN framework provides an order better spectral efficiency and is 10 times faster than the conventional techniques. Further investigations with quantized-CNNs show that the proposed network, saved in no more than 5 bits, is also suited for digital mobile devices.","","","10.1109/TWC.2019.2956146","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8924932","Antenna selection;CNN;deep learning;hybrid beamforming;massive MIMO","Antenna arrays;Phase shifters;Radio frequency;MIMO communication;Receiving antennas;Optimization","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Facial Expression Recognition by Jointly Partial Image and Deep Metric Learning","N. Yu; D. Bai","School of Artificial Intelligence and Automation, Department of Informatics, Beijing University of Technology and Beijing Key Laboratory of Computational Intelligence and Intelligent Systems and Digital Community Ministry of Education Engineering Research Center, Beijing.; School of Artificial Intelligence and Automation, Department of Informatics, Beijing University of Technology and Beijing Key Laboratory of Computational Intelligence and Intelligent Systems and Digital Community Ministry of Education Engineering Research Center, Beijing.","IEEE Access","","2019","PP","99","1","1","The performance of facial expression recognition (FER) tends to deteriorate due to high intraclass variations and high interclass similarities. To address this problem, an expression recognition model based on a joint partial image and deep metric learning method (PI&DML) is proposed. First, we propose cropping the active units (AU) that are most closely related to the expression to generate a partial image for feature extraction, which is conducive to mitigating the negative impact of the abovementioned problems to some extent. Second, a novel expression metric loss function (EMLF) is suggested to enhance the intraclass similarities and interclass variations. Finally, superior performance is achieved by jointly optimizing the expression metric loss and classification loss. As demonstrated by the visualization results, the proposed EMLF is effective at increasing the distance between various expressions and reducing the distance between the same expressions. The evaluations on three public expression databases have demonstrated that our method is capable of achieving better results than the state-of-the-art methods.","","","10.1109/ACCESS.2019.2963201","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8946513","facial expression recognition;deep metric learning;metric loss function;partial images;jointly optimizing;high intraclass variations;high interclass similarities","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"JointRec: A Deep Learning-based Joint Cloud Video Recommendation Framework for Mobile IoTs","S. Duan; D. Zhang; Y. Wang; L. Li; Y. Zhang","School of Computer Science and Engineering, Central South University, Changsha, 410083, China.; School of Computer Science and Engineering, Central South University, Changsha, 410083, China.; School of Computer Science and Engineering, Central South University, Changsha, 410083, China.; School of Computer Science and Engineering, Central South University, Changsha, 410083, China.; School of Computer Science and Engineering, Central South University, Changsha, 410083, China.","IEEE Internet of Things Journal","","2019","PP","99","1","1","In the era of Internet of Things (IoTs), watching videos on mobile devices has been a popular applications in our daily life. How to recommend videos to users is one of the most concerned problem for Internet Video Service Providers (IVSPs). In order to provide better recommendation service to users, they deploy cloud servers in a Geo-distributed manner. Each server is responsible for analyzing a local area of user data. Therefore, these cloud servers form information islands and the characteristics of data present non-independent and identically distribution (non-i.i.d). In this scenario, it is difficult to provide accurate video recommendation service to the minority of users in each area. To tackle this issue, we propose JointRec, a deep learning-based joint cloud video recommendation framework. JointRec integrates the JointCloud architecture into mobile IoTs and achieves federated training among distributed cloud servers. Specifically, we first design a Dual-Convolutional Probabilistic Matrix Factorization (Dual-CPMF) model to conduct video recommendation. Based on this model, each cloud can recommend videos by exploiting the user’s profiles and description of videos that users rate, thereby providing more accurate video recommendation services. Then we present a federated recommendation algorithm which enables each cloud to share their weights and train a model cooperatively. Furthermore, considering the heavy communication costs in the process of federated training, we combine low rank matrix factorization and 8-bit quantization method to reduce uplink communication costs and network bandwidth. We validate the proposed approach on the real-world dataset, the experimental results indicate the effectiveness of our proposed approach.","","","10.1109/JIOT.2019.2944889","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8854245","JointCloud Computing;Mobile Internet of Things;Deep Learning;Video Recommendation System;Non-IID data setting;Federated Training.","Cloud computing;Servers;Training;Internet of Things;Feature extraction;Distributed databases;Data models","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Skin Lesion Segmentation in Dermoscopic Images with Ensemble Deep Learning Methods","M. Goyal; A. Oakley; P. Bansal; D. Dancey; M. H. Yap","Department of Computing and Mathematics, Manchester Metropolitan University, UK.; Waikato Clinical School, University of Auckland, Hamilton, New Zealand.; Department of Computing and Mathematics, Manchester Metropolitan University, UK.; Department of Computing and Mathematics, Manchester Metropolitan University, UK.; Department of Computing and Mathematics, Manchester Metropolitan University, UK.","IEEE Access","","2019","PP","99","1","1","Early detection of skin cancer, particularly melanoma, is crucial to enable advanced treatment. Due to the rapid growth in the number of skin cancers, there is a growing need of computerised analysis for skin lesions. The state-of-the-art public available datasets for skin lesions are often accompanied with a very limited amount of segmentation ground truth labeling. Also, the available segmentation datasets consist of noisy expert annotations reflecting the fact that precise annotations to represent the boundary of skin lesions are laborious and expensive. The lesion boundary segmentation is vital to locate the lesion accurately in dermoscopic images and lesion diagnosis of different skin lesion types. In this work, we propose the fully automated deep learning ensemble methods to achieve high sensitivity and high specificity in lesion boundary segmentation. We trained the ensemble methods based on Mask RCNN and DeeplabV3+ methods on ISIC-2017 segmentation training set and evaluate the performance of the ensemble networks on ISIC-2017 testing set and PH2 dataset. Our results showed that the proposed ensemble methods segmented the skin lesions with Sensitivity of 89.93% and Specificity of 97.94% for the ISIC-2017 testing set. The proposed ensemble method Ensemble-A outperformed FrCN, FCNs, U-Net, and SegNet in Sensitivity by 4.4%, 8.8%, 22.7%, and 9.8% respectively. Furthermore, the proposed ensemble method Ensemble-S achieved a specificity score of 97.98% for clinically benign cases, 97.30% for the melanoma cases, and 98.58% for the seborrhoeic keratosis cases on ISIC-2017 testing set, exhibiting better performance than FrCN, FCNs, U-Net, and SegNet.","","","10.1109/ACCESS.2019.2960504","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8936444","Skin Cancer;Skin lesion segmentation;Ensemble segmentation methods;Deep learning;Melanoma;Instance segmentation;Semantic segmentation","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Deep Learning Classification of Neuro-Emotional Phase Domain Complexity Levels Induced by Affective Video Film Clips","S. Aydin","Biophysics, Hacettepe Universitesi Tip Fakultesi, 64005 Ankara Turkey 06100 (e-mail: drserapaydin@hotmail.com)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","In the present study, a new methodology is proposed for recognition of emotional state mediated by affective video film clips. Principal Component Analysis (PCA) is applied to full-band specific Phase Space Trajectory Matrix extracted from short emotional EEG segment of 6 s, then the first Principal Component is used as emotional feature in terms of neuro-cortical complexity levels in discriminating nine discrete emotions (fear, anger, happiness, sadness, amusement, surprise, excitement, calmness, disgust) from baseline through Convolutional Neural Networks (CNNs). In tests, the performance of CNNs is compared to another deep learning application called Long-Short term Memory Networks and Support Vector Machine classifiers with different kernels as well as Naive Bayes classifier. In applications, two concepts (gender classification and emotion classification) have been considered with respect to both instants (single feature extracted from single epoch) and subjects (large number of features extracted from single subject in an emotional state). The resulting performance of the proposed method has also been examined for longer segment statement of 12 s. Experimental data was downloaded from an internationally publicly available dataset called DREAMER. The results show that healthy young females differ from males in amusement such that the difference becomes higher when subject classification is performed. Regarding the combined features extracted from females and males, the other emotional states are clearly discriminated from baseline with considerably high accuracy levels by using CNNs in both instant and subject classification manners. The results reveal that emotion formation is mostly influenced by individual experiences rather than gender. In detail, local neuronal complexity is mostly sensitive to the affective valance rating. PCA can be proposed as secondary process on phase domain EEG space in order to obtain useful emotional features. CNN provides high performance for emotion recognition.","","","10.1109/JBHI.2019.2959843","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933102","brain biophysics;emotion recognition;affective neuroscience;deep learning","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Hierarchical Deep Learning Machine for Power System Online Transient Stability Prediction","L. Zhu; D. Hill; C. Lu","Department of Electrical and Electronic Engineering, University of Hong Kong, 25809 Hong Kong Hong Kong (e-mail: zhulpwhu@126.com); Department of Electrical and Electronic Engineering, University of Hong Kong, 25809 Hong Kong Hong Kong (e-mail: dhill@eee.hku.hk); Department of Electrical Engineering, Tsinghua University, 12442 Beijing, Beijing China (e-mail: luchao@tsinghua.edu.cn)","IEEE Transactions on Power Systems","","2019","PP","99","1","1","This paper develops a hierarchical deep learning machine (HDLM) to efficiently achieve both quantitative and qualitative online transient stability prediction (TSP). For the sake of improving its online efficiency, multiple generators' fault-on trajectories as well as the two closest data-points in pre-/post-fault stages are acquired by PMUs to form its raw inputs. An anti-noise graphical transient characterization technique is tactfully designed to transform multiplex trajectories into 2-D images, within which system-wide transients are concisely described. Then, following the divide-and-conquer philosophy, the HDLM trains a two-level convolutional neural network (CNN) based regression model. With stability margin regressions hierarchically refined, it manages to perform reliable and adaptive online TSP almost immediately after fault clearance. Test results on the IEEE 39-bus test system and the real-world Guangdong Power Grid in South China demonstrate the HDLM's superior performances on both stability status and stability margin predictions.","","","10.1109/TPWRS.2019.2957377","Theme-based Research Scheme of Research Grants Council in Hong Kong; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8920121","Convolutional neural networks;deep learning;phasor measurements;trajectories;transient stability","Transient analysis;Power system stability;Stability analysis;Trajectory;Thermal stability","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Industrial IoT for Intelligent Steelmaking with Converter Mouth Flame Spectrum Information Processed by Deep Learning","Y. Han; C. J. Zhang; L. Wang; Y. C. Zhang","College of Metallurgy and Energy, North China University of Science and Technology, 128790 Tangshan, Hebei China 063009 (e-mail: hanyang@ncst.edu.cn); College of Metallurgy and Energy, North China University of Science and Technology, 128790 Tangshan, Hebei China 063009 (e-mail: zhangcaijun_ncst@163.com); North China University of Science and Technology, 128790 Tangshan, Hebei China 063009 (e-mail: xwb@ncst.edu.cn); College of Metallurgy and Energy, North China University of Science and Technology, 128790 Tangshan, Hebei China 063009 (e-mail: xkb@ncst.edu.cn)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","Based on the fact that the converter mouth flame is the comprehensive external appearance of the physical and chemical reactions in the converter during the steelmaking process, the continuous spectrum information of the converter mouth flame was obtained by USB4000 spectrometer. In the framework of the Internet of Things (IoT), a bidirectional recursive multi-scale convolution depth neural network algorithm, which can take into account the characteristics of frequency domain structure and time domain dynamic sequence. It is applied to the deep-learning of the converter mouth flame spectrum information. The dynamic prediction model of carbon content and temperature value in molten steel at the later stage of steelmaking is constructed. The static control system and dynamic prediction model of automatic steelmaking are intelligently fused to realize one-key steelmaking control. The results show that the average hit rate of carbon content, temperature and carbon temperature at the end of steelmaking is 94.78%, 98.41% and 93.43%, which makes the end-point control of steelmaking more stable and the blowing rate less than 1%.","","","10.1109/TII.2019.2948100","National Natural Science Foundation of China; Natural Science Foundation of Hebei Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8873680","IoT;Deep-learning;Bidirectional Recursive;Multiscale Convolution;Steelmaking end-point","Fires;Steel;Mouth;Carbon;Process control;Smelting;Neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Contract-Based Computing Resource Management via Deep Reinforcement Learning in Vehicular Fog Computing","J. Zhao; M. Kong; Q. Li; X. Sun","School of Information Engineering, East China Jiaotong University, Nanchang 330013, China.; School of Information Engineering, East China Jiaotong University, Nanchang 330013, China and School of Electronic and Information Engineering, Beijing Jiaotong University, Beijing 100044, China.; School of Information Engineering, East China Jiaotong University, Nanchang 330013, China and School of Electronic and Information Engineering, Beijing Jiaotong University, Beijing 100044, China.; School of Information Engineering, East China Jiaotong University, Nanchang 330013, China and School of Electronic and Information Engineering, Beijing Jiaotong University, Beijing 100044, China.","IEEE Access","","2019","PP","99","1","1","Vehicle fog computing (VFC) is proposed as a solution that can significantly reduce the task processing overload of base station during the peak time, where the vehicle as a fog node contributes idle computing resource for task processing. However, there are still many challenges in the deployment of VFC, such as the lack of specific incentives of resource contribution, high system complexity, and offloading collisions between vehicles when the vehicles are offloading tasks simultaneously. In this paper, we first propose a novel contract-based incentive mechanism that combines resource contribution and resource utilization. Based on that, we propose to use distributed deep reinforcement learning to allocate resources and reduce system complexity. Task offloading method based on the queuing model is also proposed to avoid decision collisions in multi-vehicles task offloading. Numerical experiment results demonstrate that our proposed scheme has achieved a significant improvement in task offloading and resource allocation performance.","","","10.1109/ACCESS.2019.2963051","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8945368","Vehicular fog computing;contract theory;deep reinforcement learning;resource allocation;task offloading","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Learning deep representations for video-based intake gesture detection","P. V. Rouast; M. Adam","School of Electrical Engineering and Computing, The University of Newcastle, 5982 Callaghan, New South Wales Australia 2308 (e-mail: philipp.rouast@uon.edu.au); School of Electrical Engineering and Computing, The University of Newcastle, 5982 Callaghan, New South Wales Australia (e-mail: marc.adam@newcastle.edu.au)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","Automatic detection of individual intake gestures during eating occasions has the potential to improve dietary monitoring and support dietary recommendations. Existing studies typically make use of on-body solutions such as inertial and audio sensors, while video is used as ground truth. Intake gesture detection directly based on video has rarely been attempted. In this study, we address this gap and show that deep learning architectures can successfully be applied to the problem of video-based detection of intake gestures. For this purpose, we collect and label video data of eating occasions using 360-degree video of 102 participants. Applying state-of-the-art approaches from video action recognition, our results show that (1) the best model achieves an F1 score of 0.858, (2) appearance features contribute more than motion features, and (3) temporal context in form of multiple video frames is essential for top model performance.","","","10.1109/JBHI.2019.2942845","Bill and Melinda Gates Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8853283","Deep learning;intake gesture detection;dietary monitoring;video-based","Three-dimensional displays;Monitoring;Sensors;Two dimensional displays;Context modeling;Estimation;Visualization","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"A Smart Dental Health-IoT Platform Based on Intelligent Hardware, Deep Learning and Mobile Terminal","L. Liu; J. Xu; Y. Huan; Z. Zou; S. Yeh; L. Zheng","School of Information Science and Technology, Shanghai, Shanghai China 200433 (e-mail: isreason@126.com); School of Information Science and Technology, Fudan University, 12478 Shanghai, Shanghai China (e-mail: jwxu16@fudan.edu.cn); School of Information Science and Technology, Fudan University, 12478 Shanghai, Shanghai China (e-mail: yxhuan@kth.se); Shanghai China (e-mail: zhuo@fudan.edu.cn); School of Information Science and Technology, Fudan University, 12478 Shanghai China 200433 (e-mail: yeshiqing@fudan.edu.cn); Fudan University, 12478 Shanghai, Shanghai China (e-mail: lrzheng@fudan.edu.cn)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","The dental disease is a common disease for a human. Screening and visual diagnosis which are currently performed in clinics possibly cost a lot in various manners. Along with the progress of the Internet of Things (IoT) and Articial Intelligence (AI), the internet-based intelligent system have shown great potential in applying home-based healthcare. Therefore, a smart dental Health-IoT system based on intelligent hardware, deep learning and mobile terminal is proposed in this paper, aiming at exploring the feasibility of its application on In-home dental healthcare. Moreover, a smart dental device is designed and developed in this study to perform the image acquisition of teeth. Based on the data set of 12, 600 clinical images collected by the proposed device from 10 private dental clinics, an automatic diagnosis model trained by MASK R-CNN is developed for the detection and classication of 7 different dental diseases including decayed tooth, dental plaque, uorosis and periodontal disease, with the diagnosis accuracy of them reaching up to 90%, along with high sensitivity and high specicity. Following the one-month test in 10 clinics, compared with that last month when the platform is not used, the mean diagnosis time reduces by 37.5% for each patient, helping explain the increase of the number of treated patients by 18.4%. Furthermore, application software (App) on mobile terminal for client-side and for dentist-side are implemented to provide service of pre-examination, consultation, appointment, and evaluation.","","","10.1109/JBHI.2019.2919916","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8733209","Health-IoT;MASK R-CNN;deep learning;artificial intelligence;intelligent hardware;mobile terminal","Dentistry;Diseases;Teeth;Hardware;Artificial intelligence;Biomedical monitoring","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Adaptive Video Streaming with Edge Caching and Video Transcoding over Software-defined Mobile Networks: A Deep Reinforcement Learning Approach","J. Luo; F. R. Yu; Q. Chen; L. Tang","Key Lab of Mobile Communications Technology, Chongqing University of Posts and Telecommunication, Chongqing, 400065, China.; Department of Systems and Computer Engineering, Carleton University, Ottawa, ON K1S 5B6, Canada.; Key Lab of Mobile Communications Technology, Chongqing University of Posts and Telecommunication, Chongqing, 400065, China.; Key Lab of Mobile Communications Technology, Chongqing University of Posts and Telecommunication, Chongqing, 400065, China.","IEEE Transactions on Wireless Communications","","2019","PP","99","1","1","Both mobile edge cloud (MEC) and software-defined networking (SDN) are technologies for next generation mobile networks. In this paper, we propose to simultaneously optimize energy consumption and quality of experience (QoE) metrics in video streaming over software-defined mobile networks (SDMN) combined with MEC. Specifically, we propose a novel mechanism to jointly consider buffer dynamics, video quality adaption, edge caching, video transcoding and transmission. First, we assume that the time-varying channel is a discrete-time Markov chain (DTMC). Then, based on this assumption, we formulate two optimization problems which can be depicted as a constrained Markov decision process (CMDP) and a Markov decision process (MDP). Then, we transform the CMDP problem into regular MDP by deploying Lyapunov technique. We utilize asynchronous advantage actor-critic (A3C) algorithm, one of the model-free deep reinforcement learning (DRL) methods, to solve the corresponding MDP issues. Simulation results are presented to show that the proposed scheme can achieve the goal of energy saving and QoE enhancement with the corresponding constraints satisfied.","","","10.1109/TWC.2019.2955129","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8920208","Software defined mobile networks;mobile edge cloud;adaptive video streaming;Lyapunov technique;deep reinforcement learning","Streaming media;Quality of experience;Transcoding;Adaptation models;Bit rate;Markov processes;Cloud computing","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Deep Learning Approach to Universal Binary Visible Light Communication Transceiver","H. Lee; T. Q. S. Quek; S. H. Lee","Department of Information and Communications Engineering, Pukyong National University, Busan 48513, South Korea; Singapore University of Technology and Design, Singapore 487372, and also with the Department of Electronic Engineering, Kyung Hee University, Yongin 17104, South Korea; School of Electrical Engineering, Korea University, Seoul 02841, South Korea","IEEE Transactions on Wireless Communications","","2019","PP","99","1","1","This paper studies a deep learning (DL) framework for the design of binary modulated visible light communication (VLC) transceiver with universal dimming support. The dimming control for the optical binary signal boils down to a combinatorial codebook design so that the average Hamming weight of binary codewords matches with arbitrary dimming target. An unsupervised DL technique is employed for obtaining a neural network to replace the encoder-decoder pair that recovers the message from the optically transmitted signal. In such a task, a novel stochastic binarization method is developed to generate the set of binary codewords from continuous-valued neural network outputs. For universal support of arbitrary dimming target, the DL-based VLC transceiver is trained with multiple dimming constraints, which turns out to be a constrained training optimization that is very challenging to handle with existing DL methods. We develop a new training algorithm that addresses the dimming constraints through a dual formulation of the optimization. Based on the developed algorithm, the resulting VLC transceiver can be optimized via the end-to-end training procedure. Numerical results verify that the proposed codebook outperforms theoretically best constant weight codebooks under various VLC setups.","","","10.1109/TWC.2019.2950026","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8891920","Visible light communication;deep learning;dimming support;primal-dual method","Training;Transceivers;Optical transmitters;Optical pulses;Light emitting diodes;Receivers;Neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"When Deep Reinforcement Learning Meets 5G Vehicular Networks: A Distributed Offloading Framework for Traffic Big Data","Z. Ning; P. Dong; X. Wang; M. S. Obaidat; X. Hu; L. Guo; Y. Guo; J. Huang; B. Hu; Y. Li","Dalian, Liaoning China CN116620 (e-mail: zhaolongning@dlut.edu.cn); Dalian China 116620 (e-mail: peiran_dong@outlook.com); Dalian China 116620 (e-mail: wangxj1988@mail.dlut.edu.cn); monmouth university, w. long BRANCH United States 07664 (e-mail: msobaidat@gmail.com); Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen China 518055 (e-mail: xp.hu@siat.ac.cn); Chongqing University of Posts and Telecommunications, 12419 Chongqing China 400065 (e-mail: guolei@cqupt.edu.cn); The Second Clinical Medical College of Jinan University, Guangzhou China 518000 (e-mail: xuanyi_guo@163.com); Chongqing University of Posts and Telecommunications, 12419 Chongqing China 400065 (e-mail: xiaoniuadmin@gmail.com); school of information science & engineering, Lanzhou University, 12426 Lanzhou China 730000 (e-mail: bh@lzu.edu.cn); Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen China 518055 (e-mail: ye.li@siat.ac.cn)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","The emerging 5G vehicular networks can satisfy various requirements of vehicles by traffic offloading. However, limited cellular spectrum and energy supplies restrict the development of 5G-enabled applications in vehicular networks. In this paper, we construct an intelligent offloading framework for 5G vehicular networks, by jointly utilizing licensed cellular spectrum and unlicensed channels. An optimization problem aiming at minimizing the offloading cost is formulated, and further decomposed into two subproblems due to its complexity. For the first subproblem, a two-sided matching algorithm is proposed to schedule the unlicensed spectrum while satisfying the latency constraint of users. Then, a deep reinforcement learning based method is investigated for the second one, where the system state is simplified to realize distributed offloading. Performance analyses based on real-world traces of taxies demonstrate the effectiveness of our solution.","","","10.1109/TII.2019.2937079","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8809673","5G-enabled vehicular networks;distributed offloading;deep reinforcement learning;traffic big data","Task analysis;Servers;Resource management;Informatics;Big Data;Wireless communication;Quality of service","","","","10","","","","","","IEEE","IEEE Early Access Articles"
"Deep Reinforcement Learning based QoS-aware Secure Routing for SDN-IoT","X. Guo; H. Lin; Z. Li; M. Peng","College of Mathematics and Informatics, Fujian Normal University, Fuzhou, 350117, China.; College of Mathematics and Informatics, Fujian Normal University, Fuzhou, 350117, China.; Information Science and Technology College, Dalian Maritime University, Dalian, 116000, China.; College of Mathematics and Informatics, Fujian Normal University, Fuzhou, 350117, China.","IEEE Internet of Things Journal","","2019","PP","99","1","1","Nowadays, with the proliferation of communication devices, Internet of Things (IoT) has become an emerging technology which facilitates massive devices to be enabled with connectivity by heterogeneous networks. However, it is usually a technical challenge for traditional networks to handle such a huge number of devices in an efficient manner. Recently, software defined network (SDN) technique with its agility and elasticity, has been incorporated into IoT to meet the potential scale and flexibility requirements, and forms a novel IoT architecture aka SDN-IoT. As the size of SDN-IoT increases, efficient routing protocols with low latency and high security are required, while the default routing protocols of SDN are still vulnerable to dynamic change of flow control rules especially when the network is under attack. To address the above issues, a Deep reinforcement learning based QoS-aware Secure routing Protocol (DQSP) is proposed in this paper. While guaranteeing the quality-of-service (QoS), our method can extract knowledge from history traffic demands by interacting with the underlying network environment, and dynamically optimize the routing policy. Extensive simulation experiments have been conducted with respect to several network performance metrics, demonstrating that our DQSP has good convergence and high effectiveness. Moreover, DQSP outperforms the traditional OSPF routing protocol, at least 10% relative performance gains in most cases.","","","10.1109/JIOT.2019.2960033","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8935210","Deep reinforcement learning;Routing;Data security;Soft defined network;Internet of things.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"An Enhanced Deep Learning-Based Fusion Prognostic Method for RUL Prediction","C. Huang; X. Yin; H. Huang; Y. Li","School of Mechanical and Electrical Engineering, University of Electronic Science and Technology of China, Chengdu 611731, China, and also with the Center for System Reliability and Safety, University of Electronic Science and Technology of China, Chengdu 611731, China (e-mail: cheng-geng.huang@hotmail.com).; College of Management & Economics, Tianjin University, Tianjin 300072, China (e-mail: yinxianhui@tju.edu.cn).; School of Mechanical and Electrical Engineering, University of Electronic Science and Technology of China, Chengdu 611731, China, and also with the Center for System Reliability and Safety, University of Electronic Science and Technology of China, Chengdu 611731, China (e-mail: hzhuang@uestc.edu.cn).; School of Mechanical and Electrical Engineering, University of Electronic Science and Technology of China, Chengdu 611731, China, and also with the Center for System Reliability and Safety, University of Electronic Science and Technology of China, Chengdu 611731, China (e-mail: yanfengli@uestc.edu.cn).","IEEE Transactions on Reliability","","2019","PP","99","1","13","This article proposes a novel deep learning based fusion prognostic method for remaining useful life (RUL) prediction of engineering systems. The proposed framework strategically combines the advantages of bidirectional long short-term memory (BLSTM) networks and particle filter (PF) method and meanwhile mitigates their limitations. In the proposed framework, BLSTM networks are applied for further extracting, selecting, and fusing discriminative features to form predicted measurements of the identified degradation indicator. Simultaneously, PF is utilized to estimate system state and identify unknown parameters of the degradation model for RUL prediction. Hence, the proposed fusion prognostic framework has two innovative features: first, the preprocessed features from raw multisensor data can be intelligently extracted, selected, and fused by the BLSTM networks without specific domain knowledge of feature engineering; second, the predicted measurements with uncertainties obtained from the BLSTM networks will be properly represented by the PF in a transparent manner. Moreover, the developed approach is experimentally validated with machining tool wear tests on a computer numerical control (CNC) milling machine. In addition, the popular techniques employed in this field are also investigated to compare with the proposed method.","","","10.1109/TR.2019.2948705","National Natural Science Foundation of China; China Scholarship Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8894694","Bidirectional long short-term memory (BLSTM);deep learning (DL);fusion prognostic approach;particle filter (PF);prognostic and health management;tool wear","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Faster single model vigilance detection based on deep learning","W. Wu; W. Sun; Q. M. J. Wu; C. Zhang; Y. Yang; H. Yu; B. Lu","College of Electrical and Information Engineering, Hunan University, the State Key Laboratory of Advanced Design and Manufacturing for Vehicle Body, Hunan University, and the Hunan Key Laboratory of Intelligent Robot Technology in Electronic Manufacturing, Hunan University, Changsha 410082, China.; College of Electrical and Information Engineering, Hunan University, the State Key Laboratory of Advanced Design and Manufacturing for Vehicle Body, Hunan University, and the Hunan Key Laboratory of Intelligent Robot Technology in Electronic Manufacturing, Hunan University, Changsha 410082, China.; Department of Electrical and Computer Engineering, University of Windsor, Windsor N9B 3P4, Canada.; College of Electrical and Information Engineering, Hunan University of Technology, Zhuzhou 412007, China.; Computer Science Department, Lakehead University, Thunder Bay P7B 5E1, Canada.; College of Electrical and Information Engineering, Hunan University, the State Key Laboratory of Advanced Design and Manufacturing for Vehicle Body, Hunan University, and the Hunan Key Laboratory of Intelligent Robot Technology in Electronic Manufacturing, Hunan University, Changsha 410082, China.; Department of Computer Science and Engineering, Shanghai Jiao Tong University and the Key Laboratory of Shanghai Education Commission for Intelligent Interaction and Cognitive Engineering, Shanghai Jiao Tong University, Shanghai 200240, China.","IEEE Transactions on Cognitive and Developmental Systems","","2019","PP","99","1","1","Various reports have shown that the rate of road traffic accidents has increased due to reduced driver vigilance. Therefore, an accurate estimation of the driver’s alertness status plays an important part. To estimate vigilance, we adopt a novel strategy that is a deep autoencoder with subnetwork nodes (DAESN). The proposed network model is designed not only for sparse representation but also for dimension reduction. Some hidden layers are not calculated by randomly acquired, but by replacement technologies. Unlike traditional EOG signals, the forehead EOG signals are collected through forehead electrodes that do not have to surround the eyes, which has a convenient and effective practical application. The root-mean-square error (RMSE) and correlation coefficient (COR) while separately using three forehead EOG features improved to 0.11/0.79, 0.10/0.83, and 0.11/0.80, respectively. Implemented in an experimental environment, PERCLOS is calculated in real-time through SMI eye-tracking-glasses, up to 120 frames per second. In addition, the time to extract features from the raw signal and display the prediction is only 34ms, that is the level of the driver’s fatigue can be detected quickly. The experimental study shows that the proposed model for vigilance analysis has better robustness and learning capability.","","","10.1109/TCDS.2019.2963073","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8946740","deep learning;dimension reduction;single model;vigilance detection.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"EMS-Net: A Deep Learning Method for Autodetecting Epileptic Magnetoencephalography Spikes","L. Zheng; P. Liao; L. Shen; J. Sheng; P. Teng; G. Luan; J. Gao","Department of Biomedical Engineering, College of Engineering, Peking University, Beijing 100871, China.; Beijing Intelligent Brain Cloud Inc, Beijing 100871, China.; Beijing City Key Lab for Medical Physics and Engineering, Institution of Heavy Ion Physics, School of Physics, Peking University, Beijing 100871, China.; Beijing Quanmag Biomedicine Research Institute, Beijing 102627, China.; Beijing Key Laboratory of Epilepsy, Sanbo Brain Hospital, Capital Medical University, Beijing 100093, China.; Beijing Key Laboratory of Epilepsy, Sanbo Brain Hospital, Capital Medical University, Beijing 100093, China.; Beijing City Key Lab for Medical Physics and Engineering, Institution of Heavy Ion Physics, School of Physics, and Center for MRI Research, Peking University, Beijing 100871, China.","IEEE Transactions on Medical Imaging","","2019","PP","99","1","1","Epilepsy is a neurological disorder characterized by sudden and unpredictable epileptic seizures, which incurs significant negative impacts on patients’ physical, psychological and social health. A practical approach to assist with the clinical assessment and treatment planning for patients is to process magnetoencephalography (MEG) data to identify epileptogenic zones. As a widely accepted biomarker of epileptic foci, epileptic MEG spikes need to be precisely detected. Given that the visual inspection of spikes is time consuming, an automatic and efficient system with adequate accuracy for spike detection is valuable in clinical practice. However, current approaches for MEG spike autodetection are dependent on hand-engineered features. Here, we propose a novel multiview Epileptic MEG Spikes detection algorithm based on a deep learning Network (EMS-Net) to accurately and efficiently recognize the spike events from MEG raw data. The results of the leave-k-subject-out validation tests for multiple datasets (i.e., balanced and realistic datasets) showed that EMS-Net achieved state-of-the-art classification performance (i.e., accuracy: 91.82% -99.89%; precision: 91.90% -99.45%; sensitivity: 91.61% -99.53%; specificity: 91.60% -99.96%; f1 score: 91.70% -99.48%; and area under the curve: 0.9688 -0.9998).","","","10.1109/TMI.2019.2958699","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8930587","Deep learning;Convolutional neural network;Epilepsy;Magnetoencephalography;Spike detection","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Reinforcement Learning for Social-Aware Edge Computing and Caching in Urban Informatics","Y. Zhang; K. Zhang; J. Cao; H. Liu; S. Maharjan","Department of Informatics, University of Oslo, Oslo Norway 0111 (e-mail: yanzhang@ieee.org); School of Information and Communication Engineering, University of Electronic Science and Technology of China, 12599 Chengdu China 611731 (e-mail: zhangke@uestc.edu.cn); School of Information and Communication Engineering, University of Electronic Science and Technology of China, 12599 Chengdu China 611731 (e-mail: liuda945@163.com); Tongji University, 12476 Shanghai, Shanghai China 200092 (e-mail: liuhongler@ieee.org); Simula Research Laboratory, Oslo Norway 1325 (e-mail: sabita@simula.no)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","Empowered with urban informatics, transportation industry has witnessed a paradigm shift. These developments lead to the need of content processing and sharing between vehicles under strict delay constraints. Mobile edge services can help meet these demands through computation offloading and edge caching empowered transmission, while cache-enabled smart vehicles may also work as carriers for content dispatch. However, diverse capacities of edge servers and smart vehicles as well as unpredictable vehicle routes make efficient and time content distribution a challenge. To cope with this challenge, we exploit the relations between vehicles and road side units in content dispatch, and develop a social-aware mobile edge computing and caching mechanism. By leveraging deep reinforcement learning approach, we propose optimal content processing and caching schemes that maximize the dispatch utility in an urban environment with diverse vehicular social characteristics. Numerical results based on real urban traffic datasets demonstrate the efficiency of our proposed schemes.","","","10.1109/TII.2019.2953189","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8896914","Social-aware;deep reinforcement learning;vehicular edge computing","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Detection and Analysis of Behavior Trajectory for Sea Cucumbers based on Deep Learning (August 2019)","J. Li; C. Xu; L. Jiang; Y. Xiao; L. Deng; Z. Han","College of Mechanical and Electrical Engineering, Qingdao Agricultural University, Qingdao Shandong, China.; College of Mechanical and Electrical Engineering, Qingdao Agricultural University, Qingdao Shandong, China.; College of Marine science and engineering, Qingdao Agricultural University, Qingdao Shandong, China.; Chengyang No.1 High School of Qingdao, Qingdao Shandong, China.; College of Science and Information, Qingdao Agricultural University, Qingdao Shandong, China.; College of Science and Information, Qingdao Agricultural University, Qingdao Shandong, China.","IEEE Access","","2019","PP","99","1","1","The motion trajectory of sea cucumbers reflects the behavior of sea cucumbers, and the behavior of sea cucumbers reflects the status of the feeding and individual health, which provides the important information for the culture, status detection and early disease warning. Different from the traditional manual observation and sensor-based automatic detection methods, this paper proposes a detection, location and analysis approach of behavior trajectory based on Faster R-CNN for sea cucumbers under the deep learning framework. The designed detection system consists of a RGB camera to collect the sea cucumbers’ images and a corresponding sea cucumber identification software. The experimental results show that the proposed approach can accurately detect and locate sea cucumbers. According to the experimental results, the following conclusions are drawn: (1) Sea cucumbers have an adaptation time for the new environment. When sea cucumbers enter a new environment, the adaptation time is about 30 minutes. Sea cucumbers hardly move within 30 minutes and begin to move after about 30 minutes. (2) Sea cucumbers have the negative phototaxis and prefers to move in the shadows. (3) Sea cucumbers have a tendency to the edge. They like to move along the edge of the aquarium. When the sea cucumber is in the middle of the aquarium, the sea cucumber will look for the edge of the aquarium. (4) Sea cucumbers have unidirectional topotaxis. They move along the same direction with the initial motion direction. The proposed approach will be extended to the detection and behavioral analysis of the other marine organisms in the marine ranching.","","","10.1109/ACCESS.2019.2962823","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8945222","Artificial Intelligence (AI);animal behavior;deep learning;object detection;Faster R-CNN;marine ranching;sea cucumber","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Deep Multimodality Learning for UAV Video Aesthetic Quality Assessment","Q. Kuang; X. Jin; Q. Zhao; B. Zhou","State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, 12633 Beijing China (e-mail: kuangqi@buaa.edu.cn); School of Computer Science and Technology, Beijing Electronics Science and Technology Institute, 12503 Beijing, Beijing China (e-mail: jinxinbesti@foxmail.com); State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, 12633 Beijing China (e-mail: zhaoqp@buaa.edu.cn); State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, 12633 Beijing China (e-mail: zhoubin@buaa.edu.cn)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","Despite the growing number of unmanned aerial vehicles (UAVs) and aerial videos, there is a paucity of studies focusing on the aesthetics of aerial videos that can provide valuable information for improving the aesthetic quality of aerial photography. In this article, we present a method of deep multimodality learning for UAV video aesthetic quality assessment. More specifically, a multistream framework is designed to exploit aesthetic attributes from multiple modalities, including spatial appearance, drone camera motion, and scene structure. A novel specially designed motion stream network is proposed for this new multistream framework. We construct a dataset with 6,000 UAV video shots captured by drone cameras. Our model can judge whether a UAV video was shot by professional photographers or amateurs together with the scene type classification. The experimental results reveal that our method outperforms the video classification methods and traditional SVM-based methods for video aesthetics. In addition, we present three application examples of UAV video grading, professional segment detection and aesthetic-based UAV path planning using the proposed method.","","","10.1109/TMM.2019.2960656","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8936378","Aesthetic quality assessment;aerial video aesthetic;deep multimodality learning","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Hybrid Precoding for Multi-User Millimeter Wave Massive MIMO Systems: A Deep Learning Approach","A. M. Elbir; A. Papazafeiropoulos","Dept. of electrical and electronics engineering, Duzce Universitesi, 121595 Duzce, Duzce Turkey 81620 (e-mail: ahmetmelbir@gmail.com); Electrical & Electronic Engineering, Imperial College London, London, UK United Kingdom of Great Britain and Northern Ireland SW7 2AZ (e-mail: tapapazaf@gmail.com)","IEEE Transactions on Vehicular Technology","","2019","PP","99","1","1","In multi-user millimeter wave (mmWave) multiple-input-multiple-output (MIMO) systems, hybrid precoding is a crucial task to lower the complexity and cost while achieving a sufficient sum-rate. Previous works on hybrid precoding were usually based on optimization or greedy approaches. These methods either provide higher complexity or have sub-optimum performance. Moreover, the performance of these methods mostly relies on the quality of the channel data. In this work, we propose a deep learning (DL) framework to improve the performance and provide less computation time as compared to the conventional techniques. In fact, we design a convolutional neural network for MIMO (CNN-MIMO) that accepts as input an imperfect channel matrix and gives the analog precoder and combiners at the output. The procedure includes two main stages. First, we develop an exhaustive search algorithm to select the analog precoder and combiners from a predefined codebook maximizing the achievable sum-rate. Then, the selected precoder and combiners are used as output labels in the training stage of CNN-MIMO where the input-output pairs are obtained. We evaluate the performance of the proposed method through numerous and extensive simulations and show that the proposed DL framework outperforms the conventional techniques. Overall, CNN-MIMO provides a robust hybrid precoding scheme in the presence of imperfections regarding the channel matrix. On top of this, the proposed approach exhibits less computation time with comparison to the optimization and codebook based approaches.","","","10.1109/TVT.2019.2951501","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8890805","Hybrid precoding;mmWave systems;multiuser MIMO transmission;deep learning;convolutional neural networks","Precoding;MIMO communication;Radio frequency;Training;Antennas;Phase shifters;Channel estimation","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Handover Management for mmWave Networks with Proactive Performance Prediction Using Camera Images and Deep Reinforcement Learning","Y. Koda; K. Nakashima; K. Yamamoto; T. Nishio; M. Morikura","Graduate School of Informatics, Kyoto University, Yoshida-honmachi, Sakyo-ku, Kyoto 606-8501, Japan.; Graduate School of Informatics, Kyoto University, Yoshida-honmachi, Sakyo-ku, Kyoto 606-8501, Japan.; Graduate School of Informatics, Kyoto University, Yoshida-honmachi, Sakyo-ku, Kyoto 606-8501, Japan.; Graduate School of Informatics, Kyoto University, Yoshida-honmachi, Sakyo-ku, Kyoto 606-8501, Japan.; Graduate School of Informatics, Kyoto University, Yoshida-honmachi, Sakyo-ku, Kyoto 606-8501, Japan.","IEEE Transactions on Cognitive Communications and Networking","","2019","PP","99","1","1","For millimeter-wave networks, this paper presents a paradigm shift for leveraging time-consecutive camera images in handover decision problems. While making handover decisions, it is important to predict future long-term performance—e.g., the cumulative sum of time-varying data rates—proactively to avoid making myopic decisions. However, this study experimentally notices that a time-variation in the received powers is not necessarily informative for proactively predicting the rapid degradation of data rates caused by moving obstacles. To overcome this challenge, this study proposes a proactive framework wherein handover timings are optimized while obstacle-caused data rate degradations are predicted before the degradations occur. The key idea is to expand a state space to involve time-consecutive camera images, which comprises informative features for predicting such data rate degradations. To overcome the difficulty in handling the large dimensionality of the expanded state space, we use a deep reinforcement learning for deciding the handover timings. The evaluations performed based on the experimentally obtained camera images and received powers demonstrate that the expanded state space facilitates (i) the prediction of obstacle-caused data rate degradations from 500 ms before the degradations occur and (ii) superior performance to a handover framework without the state space expansion.","","","10.1109/TCCN.2019.2961655","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8941039","Millimeter-wave communication;deep reinforcement learning;handover management;proactive prediction;camera image.","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Classification of 3D Terracotta Warrior Fragments Based on Deep Learning and Template Guidance","H. Gao; G. Geng","School of Information Science & Technology, Northwest University, Xi’an, 710127, China and Xinhua College, Ningxia University, 750021, Yinchuan, China.; School of Information Science & Technology, Northwest University, Xi’an, 710127, China.","IEEE Access","","2019","PP","99","1","1","The Terracotta Warriors are terracotta sculptures created for China’s first emperor more than 2,000 years ago. They are among the most precious unearthed cultural relics of China. However, these relics have been predominantly found in fragments. Fragment classification is currently performed manually on enormous quantities of fragments, which is a time-consuming, inaccurate, and subjective task for archaeologists and conservators. In this study, an automatic method based on a deep learning network combined with template guidance is proposed to classify 3D fragments of the Terracotta Warriors. The fragments are initially classified using PointNet. Then, misclassified fragments are secondly categorized based on their best match to a complete Terracotta Warrior model. Extensive experiments were performed to verify the effectiveness of the proposed method. The promising results demonstrate that the method is the most accurate technique for classifying 3D Terracotta Warrior fragments to date. Moreover, the proposed method can significantly increase the efficiency of future fragment reassembly for the Terracotta Warriors.","","","10.1109/ACCESS.2019.2962791","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8945188","Data preprocessing;Deep learning;3D Fragments classification;Intrinsic Shape Signatures;Point cloud;Random Sample Consensus;Signature of Histograms of Orientations;Terracotta warriors","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Surrogate-Assisted Evolutionary Deep Learning Using an End-to-End Random Forest-based Performance Predictor","Y. Sun; H. Wang; B. Xue; Y. Jin; G. G. Yen; M. Zhang","College of Computer Science, Sichuan University, Chengdu 610065, China, and also with the School of Engineering and Computer Science, Victoria University of Wellington, Wellington 6140, New Zealand.; School of Artificial Intelligence, Xidian University, Xi’an 710071, China.; School of Engineering and Computer Science, Victoria University of Wellington, PO Box 600, Wellington 6140, New Zealand.; Department of Computer Science, University of Surrey, Guildford GU2 7XH, U.K.; School of Electrical and Computer Engineering, Oklahoma State University, Stillwater, OK 74078 USA.; School of Engineering and Computer Science, Victoria University of Wellington, PO Box 600, Wellington 6140, New Zealand.","IEEE Transactions on Evolutionary Computation","","2019","PP","99","1","1","Convolutional neural networks (CNNs) have shown remarkable performance in various real-world applications. Unfortunately, the promising performance of CNNs can be achieved only when their architectures are optimally constructed. The architectures of state-of-the-art CNNs are typically hand-crafted with extensive expertise in both CNNs and the investigated data, which consequently hampers the widespread adoption of CNNs for less experienced users. Evolutionary deep learning (EDL) is able to automatically design the best CNN architectures without much expertise. However, existing EDL algorithms generally evaluate the fitness of a new architecture by training from scratch, resulting in the prohibitive computational cost even operated on high-performance computers. In this paper, an end-to-end offline performance predictor based on the random forest is proposed to accelerate the fitness evaluation in EDL. The proposed performance predictor shows promising performance in term of the classification accuracy and the consumed computational resources when compared with 18 state-of-the-art peer competitors by integrating it into an existing EDL algorithm as a case study. The proposed performance predictor is also compared with the other two representatives of existing performance predictors. The experimental results show the proposed performance predictor not only significantly speeds up the fitness evaluations, but also achieves the best prediction among the peer performance predictors.","","","10.1109/TEVC.2019.2924461","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8744404","evolutionary deep learning;performance predictor;surrogate model;random forest;convolutional neural network.","Computer architecture;Training;Prediction algorithms;Optimization;Sociology;Statistics","","","","","","","","","","IEEE","IEEE Early Access Articles"
"PolSARNet: A Deep Fully Convolutional Network for Polarimetric SAR Image Classification","A. G. Mullissa; C. Persello; A. Stein","Laboratory of Geo-Information Science and Remote Sensing, Wageningen University, Wageningen, 6700AA, The Netherlands (e-mail: adugna.mullissa@wur.nl).; Department of Earth Observation Science, Faculty of Geoinformation Science and Earth Observation, University of Twente, Enschede, 7514AE, The Netherlands (e-mail: c.persello@utwente.nl).; Department of Earth Observation Science, Faculty of Geoinformation Science and Earth Observation, University of Twente, Enschede, 7514AE, The Netherlands (e-mail: a.stein@utwente.nl).","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2019","PP","99","1","10","Deep learning has successfully improved the classification accuracy of optical remote sensing images. Recent works attempted to transfer the success of these techniques to the microwave domain to classify Polarimetric SAR data. So far, most deep learning networks separate amplitude and phase as separate input images. In this article, we present a deep fully convolutional network that uses real-valued weight kernels to perform pixel-wise classification of complex-valued images. We evaluated the performance of this network by comparing it with support vector machine, Random Forest, complex-valued convolutional neural network (CV-CNN), and a network that uses amplitude and phase information separately as real channels. The evaluation was done on a quad-polarized AIRSAR image and a dual-polarimetric multitemporal Sentinel-1 data acquired over Flevoland, the Netherlands. The proposed method achieved higher accuracy compared to all other networks with the same architecture.","","","10.1109/JSTARS.2019.2956650","Faculty of Geo-information Science and Earth Observation; University of Twente research fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8936481","Convolutional neural network (CNN);deep learning;image classification;machine learning;polarimetric SAR (PolSAR)","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Feature Clustering for Remote Sensing Imagery Land Cover Analysis","R. S. Gargees; G. J. Scott","Department of Electrical Engineering and Computer Science, University of Missouri, Columbia, MO 65211 USA (e-mail: rsgt3b@mail.missouri.edu).; Department of Electrical Engineering and Computer Science, University of Missouri, Columbia, MO 65211 USA.","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","In this letter, we propose a chip-based technique for large-scale, automatic land cover clustering of high-resolution remote sensing imagery (HR-RSI) using deep visual features from a deep convolutional neural network (DCNN) along with the fuzzy c-means algorithm. The proposed method, unlike traditional methods, facilitates utilizing transfer learning techniques for deep neural models that are fined-tuned to satellite imagery for feature extraction. Then, a large conterminous region of imagery is acquired from HR-RSI data providers and scanned to extract visual features utilizing the transfer learned model. Broad-area thematic and contextual understanding of the geographic land cover is efficiently achieved using feature reduction, chip-based clustering analysis, and geospatial rendering of the clusters. We explore a variety of fuzzy clusterings and their resulting utility for spatial analysis. The spatial densities of the clusters, numerical analysis, and geographic aggregations show that our proposed approach is effective in examining the land cover of the earth.","","","10.1109/LGRS.2019.2948799","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8887293","Deep learning;fuzzy clustering;geospatial information;large-scale data;transfer learning.","Feature extraction;Visualization;Principal component analysis;Remote sensing;Data models;Geospatial analysis;Training","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Machine Learning Approach for Beamforming in Ultra Dense Network Considering Selfish and Altruistic Strategy","C. Sun; Z. Shi; F. Jiang","Shaanxi Key Laboratory of Information Communication Network and Security, Xi’an University of Posts and Telecommunications, Xi’an 710121, China.; Shaanxi Key Laboratory of Information Communication Network and Security, Xi’an University of Posts and Telecommunications, Xi’an 710121, China.; Shaanxi Key Laboratory of Information Communication Network and Security, Xi’an University of Posts and Telecommunications, Xi’an 710121, China.","IEEE Access","","2019","PP","99","1","1","Coordinated beamforming is very efficient at managing interference in ultra dense network. However, the optimal strategy remains as a challenge task to obtain due to the coupled nature among densely and autonomously deployed cells. In this paper, the deep reinforcement learning is investigated for predicting coordinated beamforming strategy. Formulated as a sum-rate maximization problem, the optimal solution turns out as a balanced combination of selfish and altruistic beamforming. As the balancing coefficients depend on the beamforming vectors of all the cells, iterations are inevitable to get the final solution. To address this problem and improve efficiency, deep reinforcement learning (DL) is proposed to predict the balancing coefficients. Specifically, the agent, on behalf of a base station-user pair, will rely on Deep Q-network to learn the highly complex mapping between the balancing coefficients and signal-interference environment of each user. Subsequently, the beamforming vectors are obtained efficiently through the learned balancing coefficients. Due to the distinguished feature in exploration of the beamforming parameterization, the complexity problem brought by predicting the beamforming matrix directly is avoided. The performance of the proposed scheme is investigated by experiments with arguments regarding multiple input and multiple output configuration, shadow fading and state design. Simulation results indicate the facts that: 1) the theoretically infinite strategy space can be discretized with limited levels and granularity;2)it is feasible to approximate the complex mapping by Q-learning for wireless channel consisting both the large and small scale fading, 3) the balancing coefficients only concerns large scale fading, so the coordinated beamforming can be decomposed to two sub-problems with different time scales: parameterization at large time scales and instant beamforming based on balancing coefficients.","","","10.1109/ACCESS.2019.2963468","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8947959","Deep learning;Beamforming;Ultra dense network(UDN);Q-learning;Interference management","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Future Intelligent and Secure Vehicular Network Toward 6G: Machine-Learning Approaches","F. Tang; Y. Kawamoto; N. Kato; J. Liu","Graduate School of Information Sciences (GSIS), Tohoku University, Sendai 980-8579, Japan (e-mail: fengxiao.tang@it.is.tohoku.ac.jp).; Graduate School of Information Sciences (GSIS), Tohoku University, Sendai 980-8579, Japan.; Graduate School of Information Sciences (GSIS), Tohoku University, Sendai 980-8579, Japan.; School of Cyberspace Security, Northwestern Polytechnical University, Xi'an 710072, China.","Proceedings of the IEEE","","2019","PP","99","1","16","As a powerful tool, the vehicular network has been built to connect human communication and transportation around the world for many years to come. However, with the rapid growth of vehicles, the vehicular network becomes heterogeneous, dynamic, and large scaled, which makes it difficult to meet the strict requirements, such as ultralow latency, high reliability, high security, and massive connections of the next-generation (6G) network. Recently, machine learning (ML) has emerged as a powerful artificial intelligence (AI) technique to make both the vehicle and wireless communication highly efficient and adaptable. Naturally, employing ML into vehicular communication and network becomes a hot topic and is being widely studied in both academia and industry, paving the way for the future intelligentization in 6G vehicular networks. In this article, we provide a survey on various ML techniques applied to communication, networking, and security parts in vehicular networks and envision the ways of enabling AI toward a future 6G vehicular network, including the evolution of intelligent radio (IR), network intelligentization, and self-learning with proactive exploration.","","","10.1109/JPROC.2019.2954595","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8926369","6G;deep learning;intelligent radio (IR);intelligentization;Internet of Vehicles (IoV);machine learning (ML);resource allocation;routing;security;space-air-ground;traffic control;vehicle-to-everything (V2X);vehicle-to-vehicle (V2V);vehicular network.","Vehicle dynamics;Resource management;Security;Array signal processing;Machine learning;OFDM","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Revisiting Video Saliency Prediction in the Deep Learning Era","W. Wang; J. Shen; J. Xie; M. Cheng; H. Ling; A. Borji","Statistics Department, University of California Los Angeles, 8783 Los Angeles, California United States 90095 (e-mail: wenguanwang.ai@gmail.com); Department of Information Technology and Electrical Engineering, ETH Zurich, Zurich, Zurich Switzerland CH-8092 (e-mail: shenjianbingcv@gmail.com); Statistics, University of California Los Angeles, 8783 Los Angeles, California United States 90095 (e-mail: jianwen@ucla.edu); College of Computer and Control, Nankai University, Tianjin, Tianjin China (e-mail: cmm@nankai.edu.cn); Department of Computer and Information Sciences, Temple University, Philadelphia, Pennsylvania United States (e-mail: hbling@temple.edu); Department of Computer Science, University of Central Florida, Orlando, Florida United States (e-mail: aborji@crcv.ucf.edu)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Predicting where people look in static scenes, a.k.a visual saliency, has received significant research interests recently. However, relatively less effort has been spent in understanding visual attention over dynamic scenes. This work makes three contributions to video saliency research. First, we introduce a new benchmark, called DHF1K, for predicting fixations during dynamic scene free-viewing, which is a long-time need in this field. DHF1K consists of 1K high-quality, elaborately selected videos annotated by 17 observers using an eye tracker. The videos span a wide range of scenes, motions, object types and backgrounds. Second, we propose a novel video saliency model, called ACLNet, that augments the CNN-LSTM network with a supervised attention mechanism to enable fast end-to-end learning. The attention mechanism explicitly encodes static saliency information, thus allowing LSTM to focus on learning a more flexible temporal saliency representation. Such a design leverages existing large-scale static fixation datasets, avoids overfitting, and significantly improves training efficiency and testing performance. Third, we perform an extensive evaluation of state-of-the-art saliency models on three current datasets (i.e., DHF1K, Hollywood2, UCF sports). Experimental results over more than 1.2K testing videos containing 400K frames demonstrate that ACLNet outperforms other contenders and has a fast processing speed (40fps).","","","10.1109/TPAMI.2019.2924417","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8744328","Video saliency;dynamic visual attention prediction;benchmark;deep learning","Visualization;Benchmark testing;Sports;Predictive models;Analytical models;Computational modeling;Task analysis","","","","2","","","","","","IEEE","IEEE Early Access Articles"
"Clinical Interpretable Deep Learning Model for Glaucoma Diagnosis","W. Liao; B. Zou; R. Zhao; Y. Chen; Z. He; M. Zhou","School of Computer Science and Engineering, Central South University, 12570 Changsha, Hunan China (e-mail: 0909123117@csu.edu.cn); School of Computer Science and Engineering, Central South University, 12570 Changsha, Hunan China (e-mail: bjzou@csu.edu.cn); School of Computer Science and Engineering, Central South University, 12570 Changsha, Hunan China (e-mail: byrons.zhao@gmail.com); School of Computer Science and Engineering, Central South University, 12570 Changsha, Hunan China (e-mail: yqchen@vip.163.com); School of Computer Science and Engineering, Central South University, 12570 Changsha, Hunan China (e-mail: freehe@csu.edu.cn); School of Computer Science and Engineering, Central South University, 12570 Changsha, Hunan China (e-mail: 13017384616@163.com)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","Despite the potential to revolutionize disease diagnosis by performing data-driven classification, clinical interpretability of ConvNet remains challenging. In this paper, a novel clinical interpretable ConvNet architecture is proposed not only for accurate glaucoma diagnosis but also for the more transparent interpretation by highlighting the distinguished regions recognized by the network. To the best of our knowledge, this is the first work of providing the interpretable diagnosis of glaucoma with the popular deep learning model. We propose a novel scheme for aggregating features from different scales to promote the performance of glaucoma diagnosis, which we refer to as MLAP. Moreover, by modeling the correspondence from binary diagnosis information to the spatial pixels, the proposed scheme generates glaucoma activations, which bridge the gap between global semantical diagnosis and precise location. In contrast to previous works, it can discover the distinguish local regions in fundus images as evidence for clinical interpretable glaucoma diagnosis. Experimental results, performed on the challenging ORIGA datasets, show that our method on glaucoma diagnosis outperforms state-of-the-art methods with the highest AUC (0.88). Remarkably, the extensive results, optic disc segmentation (Dice of 0.9) and local disease focus localization based on the evidence map, demonstrate the effectiveness of our methods on clinical interpretability.","","","10.1109/JBHI.2019.2949075","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8880490","glaucoma diagnosis;clinical interpretation;medical image processing","Feature extraction;Semantics;Biomedical optical imaging;Optical imaging;Lesions;Convolution;Computer architecture","","","","","","","","","","IEEE","IEEE Early Access Articles"
"CRowNet : Deep network for Crop row detection in UAV images","M. D. Bah; A. Hafiane; R. Canals","Univ. Orléans, PRISME, EA 4229, F45072, Orléans, France.; INSA-CVL, PRISME, EA 4229, F18020, Bourges, France.; Univ. Orléans, PRISME, EA 4229, F45072, Orléans, France.","IEEE Access","","2019","PP","99","1","1","Nowadays, the development of robots and smart tractors for the automation of sowing, harvesting, weeding etc. is transforming agriculture. Farmers are moving from an agriculture where everything is applied uniformly to a much more targeted farming. This new kind of farming is commonly referred to as precision agriculture. However for autonomous guidance of these agricultural machines and even sometimes for weed detection an accurate detection of crop rows is required. In this paper we propose a new method called CRowNet which uses a convolutional neural network (CNN) and the Hough transform to detect crop rows in images taken by an unmanned aerial vehicle (UAV). The method consists of a model formed with SegNet (S-SegNet) and a CNN based Hough transform (HoughCNet). The performance of the proposed method was quantitatively compared to traditional approaches and it showed the best and most robust result. A good crop row detection rate of 93.58% was obtained with an IoU score per crop row above 70%. Moreover the model trained on a given crop field is able to detect rows in images of different types of crops.","","","10.1109/ACCESS.2019.2960873","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8936895","Crop row detection;Deep learning;Weed detection;Hough transform;Image processing","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"A Deep Reinforcement Learning Based D2D Relay Selection and Power Level Allocation in mmWave Vehicular Networks","H. Zhang; S. Chong; X. Zhang; N. Lin","School of Computer Science and Technology, University of Science and Technology of China, Hefei 230027, China, and also with the National Mobile Communications Research Laboratory, Southeast University, Nanjing 210096, China.; School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, 34141, Korea.; School of Computer Science and Technology, University of Science and Technology of China, Hefei 230027, China, and also with the National Mobile Communications Research Laboratory, Southeast University, Nanjing 210096, China.; School of Computer Science and Technology, University of Science and Technology of China, Hefei 230027, China, and also with the National Mobile Communications Research Laboratory, Southeast University, Nanjing 210096, China.","IEEE Wireless Communications Letters","","2019","PP","99","1","1","5G millimeter wave (mmWave) communication is an efficient technique for low delay and high data rate transmission in vehicular networks. Due to the high path loss in 5G mmWave band, 5G base stations need to be densely deployed, which may result in great deployment expenditures. In this letter, we jointly consider a relay selection problem in multihop 5G mmWave deveice to device (D2D) transmissions and a power level allocation problem of mmWave D2D links. We propose a centralized hierarchical deep reinforcement learning based method to find an optimal solution for the problem. The proposed method does not rely on the information of links, and it tries to find an optimal solution based on the information of vehicles. Simulation results show that the convergence of the proposed method, and the transmission delay performance of proposed method is better than a link-quality-prediction based method, and close to a link-quality-known method.","","","10.1109/LWC.2019.2958814","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8930580","5G vehicular communications;Multihop D2D transmission;Relay selection.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Automatic Identification of Breast Ultrasound Image Based on Supervised Block-Based Region Segmentation Algorithm and Features Combination Migration Deep Learning Model","W. Liao; P. He; J. Hao; X. Wang; R. Yang; D. An; L. Cui","College of Information and Electrical Engineering, China Agricultural University, 34752 Beijing China (e-mail: vane@cau.edu.cn); Department of Ultrasound, Peking University Third Hospital, 66482 Beijing China (e-mail: heping198679@163.com); College of Information and Electrical Engineering, China Agricultural University, 34752 Beijing China (e-mail: haojin@bjfu.edu.cn); College of Information and Electrical Engineering, China Agricultural University, 34752 Beijing China (e-mail: wangxuanyu@cau.edu.cn); Department of Ultrasound, Peking University Third Hospital, 66482 Beijing China (e-mail: yruolin@163.com); College of Information and Electrical Engineering, China Agricultural University, 34752 Beijing China 100083 (e-mail: andongcau@163.com); Department of Ultrasound, Peking University Third Hospital, 66482 Beijing China (e-mail: cuijuegang@126.com)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","Breast cancer is a high-incidence type of cancer for women. Early diagnosis plays a crucial role in the successful treatment of the disease and the effective reduction of deaths. In this paper, deep learning technology combined with ultrasound imaging diagnosis was used to identify and determine whether the tumors were benign or malignant. First, the tumor regions were segmented from the breast ultrasound (BUS) images using the supervised block-based region segmentation algorithm. Then, a VGG-19 network pretrained on the ImageNet dataset was applied to the segmented BUS images to predict whether the breast tumor was benign or malignant. The benchmark data for bio-validation were obtained from 141 patients with 199 breast tumors, including 69 cases of malignancy and 130 cases of benign tumors. The experiment showed that the accuracy of the supervised block-based region segmentation algorithm was almost the same as that of manual segmentation; therefore, it can replace manual work. The diagnostic effect of the combination feature model established based on the depth feature of the B-mode ultrasonic imaging and strain elastography was better than that of the model established based on these two images alone. The correct recognition rate was 92.95%, and the AUC was 0.98 for the combination feature model.","","","10.1109/JBHI.2019.2960821","the national key research and development program the wireless probe type handheld intelligent ultrasound imager; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8936948","Breast tumor;Elastography;Ultrasound images;Convolutional neural network;identification","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Multistage Deep Residual Network for Biomedical Cyber-Physical Systems","A. Pandey; R. Sequeria; P. Kumar; S. Kumar","Department of Electrical Engineering, Indian Institute of Technology Patna, Patna, 801106Bihar, India (e-mail: 1821ee12@iitp.ac.in).; Department of Computer Science, Indian Institute of Technology Patna, Patna, 801106Bihar, India (e-mail: sequeria.mtcs16@iitp.ac.in).; Department of Electrical Engineering, Indian Institute of Technology Patna, Patna, 801106Bihar, India (e-mail: pkumar@iitp.ac.in).; Department of Electrical Engineering, Indian Institute of Technology Patna, Patna, 801106Bihar, India (e-mail: sudhir@iitp.ac.in).","IEEE Systems Journal","","2019","PP","99","1","10","In this paper, we propose a novel biomedical cyber-physical system for automated and efficient arrhythmia and seizure detection in the time-series biomedical signals such as electrocardiogram (ECG) and electroencephalography (EEG). We use a novel multilayer, automated, and multistage deep residual network for the anomaly detection in the biomedical signals. Generally, the biomedical datasets have class imbalance problem; hence, we leverage the concepts of undersampling techniques to address this issue. The proposed algorithm is validated on the publicly available benchmark MIT-BIH Arrhythmia and CHB-MIT Scalp databases. The results show a significant improvement in terms of the sensitivity of $90 \%$ and $97.1 \%$ for supraventricular and ventricular beats for best fold, respectively. The accuracy obtained is at par with most of the state-of-the-art methods, and in particular, for the supraventricular beats, the proposed method outperforms all but one state-of-the-art method. The advantage of the proposed method is that it gives reliable results with EEG samples of small duration and, as opposed to other state-of-the-art methods, it does not involve any preprocessing, hence computationally efficient. Additionally, the proposed algorithm provides $81 \%$ sensitivity for seizure detection in EEG signals, which is comparable to existing deep learning methods.","","","10.1109/JSYST.2019.2923670","Science and Engineering Research Board; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8759031","Anomaly detection;biomedical monitoring;cyber-physical systems (CPS);electrocardiogram (ECG);electroencephalography (EEG);residual learning","Electroencephalography;Electrocardiography;Convolution;Deep learning;Cyber-physical systems;Sensors;Neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Memory Augmented Deep Recurrent Neural Network for Video Question Answering","C. Yin; J. Tang; Z. Xu; Y. Wang","Department of Electrical Engineering and Computer Science, Syracuse University, Syracuse, NY 13244 USA.; Department of Electrical Engineering and Computer Science, Syracuse University, Syracuse, NY 13244 USA, and also with DiDi AI Labs, Beijing 100193, China (e-mail: jtang02@syr.edu).; Department of Electrical Engineering and Computer Science, Syracuse University, Syracuse, NY 13244 USA.; Department of Electrical and Engineering, Northeastern University, Boston, MA 02115 USA.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","9","Video question answering (VideoQA) is a very important but challenging multimedia task, which automatically analyzes questions and videos and generates accurate answers. However, research on VideoQA is still in its infancy. In this article, we propose a novel memory augmented deep recurrent neural network (MA-DRNN) model for VideoQA, which features a new method for encoding videos and questions, and memory augmentation using the emerging differentiable neural computer (DNC). Specifically, we encode textual (questions) information before visual (videos) information, which leads to better visual-textual representations. Moreover, we leverage DNC (with an external memory) for storing and retrieving useful information in questions and videos, and modeling the long-term visual-textual dependence. To evaluate the proposed model, we conducted extensive experiments using the VTW data set and MSVD-QA data set, which are both Widely used large-scale video data sets for language-level understanding. The experimental results have well validated the proposed model and showed that it outperforms the state-of-the-art in terms of various accuracy-related metrics.","","","10.1109/TNNLS.2019.2938015","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8845771","Deep learning;differentiable neural computer (DNC);memory augmented neural network;recurrent neural network (RNN);video question answering (VideoQA)","Task analysis;Knowledge discovery;Computational modeling;Recurrent neural networks;Data models;Semantics","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Windows malware detector using convolutional neural network based on visualization images","S. D. S.L; J. CD","Information Technology, National Institute of Technology Karnataka, 119680 Mangalore, Karnataka India (e-mail: it15f02.shivadarshan@nitk.edu.in); Information Technology, National Institute of Technology Karnataka, 119680 Surathkal, Karnataka India (e-mail: jaidharcd@nitk.edu.in)","IEEE Transactions on Emerging Topics in Computing","","2019","PP","99","1","1","The evolution of malware is continuing at an alarming rate, despite the efforts made towards detecting and mitigating them. Malware analysis is needed to defend against its sophisticated behaviour. However, the manual heuristic inspection is no longer effective or efficient. To cope with these critical issues, behaviour-based malware detection approaches with machine learning techniques have been widely adopted as a solution. It involves supervised classifiers to appraise their predictive performance on gaining the most relevant features from the original features' set and the trade-off between high detection rate and low computation overhead. Though machine learning-based malware detection techniques have exhibited success in detecting malware, their shallow learning architecture is still deficient in identifying sophisticated malware. Therefore, in this paper, a Convolutional Neural Network (CNN) based Windows malware detector has been proposed that uses the execution time behavioural features of the Portable Executable (PE) files to detect and classify obscure malware. The 10-fold cross-validation tests were conducted to assess the proficiency of the proposed approach. The experimental results showed that the proposed approach was effective in uncovering malware PE files by utilizing significant behavioural features suggested by the Relief Feature Selection Technique. It attained detection accuracy of 97.968%.","","","10.1109/TETC.2019.2910086","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8685181","Behaviour Analysis;Convolutional Neural Network;Deep Learning;Feature Selection Technique;Machine Learning;Windows Malware Detection","Malware;Feature extraction;Microsoft Windows;Visualization;Deep learning;Detectors;Runtime","","","","","","","","","","IEEE","IEEE Early Access Articles"
"sEnDec: An Improved Image to Image CNN for Foreground Localization","T. Akilan; Q. M. J. Wu","Department of Computer Science, Lakehead University, Thunder Bay, ON P7B 5E1, Canada.; Centre for Computer Vision and Deep Learning, Department of Electrical and Computer Engineering, University of Windsor, Windsor, ON N9B 2P4, Canada (e-mail: jwu@uwindsor.ca).","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","9","Although it is not immediately intuitive that Deep Convolutional Neural Networks (DCNNs) can yield adequate feature representation for a Foreground Localization (FGL) task, recent architectural and algorithmic advancements in Deep Learning (DL) have shown that the DCNNs have become forefront methodology for this pixel-level classification problem. In FGL, the DCNNs face an inherent trade-off between moving objects, i.e., the foreground (FG) and the non-static background (BG) scenes, through learning from local- and global-level features. Driven by the latest success of the innovative structures for image classification and semantic segmentation, this work introduces a novel architecture, called Slow Encoder-Decoder (sEnDec) that aims to improve the learning capacity of a traditional image-to-image DCNN. The proposed model subsumes two subnets for contraction (encoding) and expansion (decoding), wherein both phases, it employs an intermediate feature map up-sampling and residual connections. In this way, the lost structural details due to spatial subsampling are recovered. It helps to get a more delineated FG region. The experimental study is carried out with two variants of the proposed model: one with strided convolution (conv) and the other with max pooling for spatial subsampling. A comparative analysis on sixteen benchmark video sequences, including baseline, dynamic background, camera jitter, shadow effects, intermittent object motion, night videos, and bad weather show that the proposed sEnDec model performs very competitively against the prior- and state-of-the-art approaches.","","","10.1109/TITS.2019.2940547","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8854330","Foreground localization;DCNN;encoder-decoder network.","Computational modeling;Computer architecture;Encoding;Image segmentation;Image color analysis;Decoding;Visualization","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Visual Genealogy of Deep Neural Networks","Q. Wang; J. Yuan; S. Chen; H. Su; H. Qu; S. Liu","Electronic and Computer Engineering, Hong Kong University of Science and Technology, Kowloon, Kowloon Hong Kong (e-mail: qwangbb@connect.ust.hk); School of Software, Tsinghua University, Beijing, Beijing China (e-mail: yuan-j15@mails.tsinghua.edu.cn); School of Software, Tsinghua University, Beijing, Beijing China (e-mail: thss15_chensx@163.com); Computer Science, Tsinghua University, Beijing, Beijing China (e-mail: suhangss@gmail.com); The Department of Computer Science and Engineering, he Hong Kong University of Science and Technology, Hong Kong, HK Hong Kong (e-mail: huamin@cse.ust.hk); School of Software, Tsinghua University, Beijing, Beijing China 100190 (e-mail: liushixia@gmail.com)","IEEE Transactions on Visualization and Computer Graphics","","2019","PP","99","1","1","A comprehensive and comprehensible summary of existing deep neural networks (DNNs) helps practitioners understand the behaviour and evolution of DNNs, offers insights for architecture optimization, and sheds light on the working mechanisms of DNNs.However, this summary is hard to obtain because of the complexity and diversity of DNN architectures. To address this issue, we develop DNN Genealogy, an interactive visualization tool, to offer a visual summary of representative DNNs and their evolutionary relationships.DNN Genealogy enables users to learn DNNs from multiple aspects, including architecture, performance, and evolutionary relationships. Central to this tool is a systematic analysis and visualization of 66 representative DNNs based on our analysis of 140 papers. A directed acyclic graph is used to illustrate the evolutionary relationships among these DNNs and highlight the representative DNNs. A focus +context visualization is developed to orient users during their exploration. A set of network glyphs is used in the graph to facilitate the understanding and comparing of DNNs in the context of the evolution. Case studies demonstrate that DNN Genealogy provides helpful guidance in understanding, applying, and optimizing DNNs. DNN Genealogy is extensible and will continue to be updated to reflect future advances in DNNs.","","","10.1109/TVCG.2019.2921323","National Key RD Program of China; HongKong RGC GRF; HongKong TRS grant; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8732351","Interactive Visual Summary;Information Visualization;Educational Tool;Deep Neural Networks","Visualization;Computer architecture;Tools;Neural networks;Interviews;Task analysis;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Unified Deep Metric Representation for Mesh Saliency Detection and Non-rigid Shape Matching","S. Hu; H. Shum; N. Aslam; F. W. B. Li; X. Liang","Engineering and Environment, Northumbria University, 5995 Newcastle upon Tyne United Kingdom of Great Britain and Northern Ireland NE1 8ST (e-mail: shanfeng.hu@northumbria.ac.uk); Engineering and Environment, Northumbria University, 5995 Newcastle upon Tyne United Kingdom of Great Britain and Northern Ireland NE1 8ST (e-mail: hubert.shum@northumbria.ac.uk); Engineering and Environment, Northumbria University, 5995 Newcastle upon Tyne United Kingdom of Great Britain and Northern Ireland (e-mail: nauman.aslam@northumbria.ac.uk); Department of Computer Science, University of Durham, Durham City United Kingdom of Great Britain and Northern Ireland DH1 3LE (e-mail: frederick.li@durham.ac.uk); school of computer science and engineering, Beihang University, 12633 Beijing China (e-mail: liang_xiaohui@buaa.edu.cn)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","In this paper, we propose a deep metric for unifying the representation of mesh saliency detection and non-rigid shape matching. While saliency detection and shape matching are two closely related and fundamental tasks in shape analysis, previous methods approach them separately and independently, failing to exploit their mutually beneficial underlying relationship. In view of the existing gap between saliency and matching, we propose to solve them together using a unified metric representation of surface meshes. We show that saliency and matching can be rigorously derived from our representation as the principal eigenvector and the smoothed Laplacian eigenvectors respectively. Learning the representation jointly allows matching to improve the deformation-invariance of saliency while allowing saliency to improve the feature localization of matching. To parameterize the representation from a mesh, we also propose a deep recurrent neural network (RNN) for effectively integrating multi-scale shape features and a soft-thresholding operator for adaptively enhancing the sparsity of saliency. Results show that by jointly learning from a pair of saliency and matching datasets, matching improves the accuracy of detected salient regions on meshes, which is especially obvious for small-scale saliency datasets, such as those having one to two meshes. At the same time, saliency improves the accuracy of shape matchings among meshes with reduced matching errors on surfaces.","","","10.1109/TMM.2019.2952983","Defence and Security Accelerator; National Basic Research Program of China (973 Program); National Natural Science Foundation of China; Royal Society; Erasmus Mundus Action 2 Programme; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8896033","mesh saliency;non-rigid shape matching;metric learning;deep learning;recurrent neural network","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Transfer Bug Localization","X. Huo; F. Thung; M. Li; D. Lo; S. Shi","Computer Science, Nanjing University, Nanjing, Jiangsu China (e-mail: huox@lamda.nju.edu.cn); School of Information Systems, Singapore Management University, Singapore, Singapore Singapore (e-mail: ferdiant.2013@phdis.smu.edu.sg); Nanjing University, Nantional key Lab for Novel Software Technology, Nanjing, Jiangsu China 210093 (e-mail: lim@nju.edu.cn); School of Information Systems, Singapore Management University, Singapore, Singapore Singapore 17890 (e-mail: davidlo@smu.edu.sg); Computer Science, Nanjing University, Nanjing, Jiangsu China (e-mail: shist@lamda.nju.edu.cn)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Many projects often receive more bug reports than what they can handle. To help debug and close bug reports, a number of bug localization techniques have been proposed. These techniques analyze a bug report and return a ranked list of potentially buggy source code files. Recent development on bug localization has resulted in the construction of effective supervised approaches that use historical data of manually localized bugs to boost performance. Unfortunately, as highlighted by Zimmermann et al., sufficient bug data is often unavailable for many projects and companies. This raises the need for cross-project bug localization -- the use of data from a project to help locate bugs in another project. To fill this need, we propose a deep transfer learning approach for cross-project bug localization. Our proposed approach named TRANP-CNN extracts transferable semantic features from source project and fully exploits labeled data from target project for effective cross-project bug localization. We have evaluated TRANP-CNN on curated high-quality bug datasets and our experimental results show that TRANP-CNN can locate buggy files correctly at top 1, top 5, and top 10 positions for 29.9%, 51.7%, 61.3% of the bugs respectively, which significantly outperform state-of-the-art bug localization solution based on deep learning and several other advanced alternative solutions considering various standard evaluation metrics.","","","10.1109/TSE.2019.2920771","National Key Research and Development Program; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8736995","Cross-project bug localization;transfer learning;deep learning","Computer bugs;Feature extraction;Task analysis;Encoding;Computer languages;Semantics;Data models","","","","","","","","","","IEEE","IEEE Early Access Articles"
"GENPass: A Multi-Source Deep Learning Model for Password Guessing","Z. Xia; P. Yi; Y. Liu; B. Jiang; W. Wang; T. Zhu","School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai China (e-mail: 416782738@qq.com); School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai China 200240 (e-mail: yiping@sjtu.edu.cn); School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai China (e-mail: 291666792@qq.com); School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai China (e-mail: bjiang@sjtu.edu.cn); Department of Computer Science and Electrical Engineering, University of Maryland, Baltimore County, MD, 21250, USA, Maryland United States (e-mail: ax29092@umbc.edu); Department of Computer Science and Electrical Engineering, University of Maryland, Baltimore County, MD, 21250, USA, Maryland United States (e-mail: zt@umbc.edu)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","The password has become today's dominant method of authentication. While brute-force attack methods such as HashCat and John the Ripper have proven unpractical, the research then switches to password guessing. State-of-the-art approaches such as the Markov Model and probabilistic context-free grammar (PCFG) are all based on statistical probability. These approaches require a large amount of calculation, which is time-consuming. Neural networks have proven more accurate and practical in password guessing than traditional methods. However, a raw neural network model is not qualified for cross-site attacks because each dataset has its own features. Our work aims to generalize those leaked passwords and improves the performance in cross-site attacks.","","","10.1109/TMM.2019.2940877","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8832180","","Password;Neural networks;Deep learning;Gallium nitride;Training;Computational modeling;Markov processes","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Software Vulnerability Discovery via Learning Multi-domain Knowledge Bases","G. Lin; J. Zhang; W. Luo; L. Pan; O. De Vel; P. Montague; Y. Xiang","Department of Computer Science and Software Engineering, Swinburne University of Technology, 3783 Hawthorn, Victoria Australia (e-mail: glin@swin.edu.au); School of Software & Electrical Engineering, Swinburne University of Technology, 3783 Hawthorn, Victoria Australia (e-mail: junzhang@swin.edu.au); Centre for Pattern Recognition and Data Analytics, Deakin University, Waurn Ponds, Victoria Australia (e-mail: wei.luo@deakin.edu.au); School of IT, Deakin University, Burwood, Victoria Australia 3125 (e-mail: l.pan@deakin.edu.au); Defence Science & Technology Group, Defence Science & Technology Group, Edinburgh, South Australia Australia (e-mail: olivier.devel@dst.defence.gov.au); Defence Science & Technology Group, Defence Science & Technology Group, Edinburgh, South Australia Australia (e-mail: paul.montague@dst.defence.gov.au); Faculty of Science, Engineering and Technology, Swinburne University of Technology, Hawthorn, Victoria Australia (e-mail: yxiang@swin.edu.au)","IEEE Transactions on Dependable and Secure Computing","","2019","PP","99","1","1","Machine learning (ML) has great potential in automated code vulnerability discovery. However, automated discovery application driven by off-the-shelf machine learning tools often performs poorly due to the shortage of high-quality training data. The scarceness of vulnerability data is almost always a problem for any developing software project during its early stages, which is referred to as the cold-start problem. This paper proposes a framework that utilizes transferable knowledge from pre-existing data sources. In order to improve the detection performance, multiple vulnerability-relevant data sources were selected to form a broader base for learning transferable knowledge. The selected vulnerability-relevant data sources are cross-domain, including historical vulnerability data from different software projects and data from the Software Assurance Reference Database (SARD) consisting of synthetic vulnerability examples and proof-of-concept test cases. To extract the information applicable in vulnerability detection from the cross-domain data sets, we designed a deep-learning-based framework with Long-short Term Memory (LSTM) cells. Our framework combines the heterogeneous data sources to learn unified representations of the patterns of the vulnerable source codes. Empirical studies showed that the unified representations generated by the proposed deep learning networks are feasible and effective, and are transferable for real-world vulnerability detection. Our experiments demonstrated that by leveraging two heterogeneous data sources, the performance of our vulnerability detection outperformed the static vulnerability discovery tool Flawfinder. The findings of this paper may stimulate further research in ML-based vulnerability detection using heterogeneous data sources.","","","10.1109/TDSC.2019.2954088","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8906156","Vulnerability detection;Representation Learning;Deep learning","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Detecting Social Signals in User-shared Images for Connection Discovery using Deep Learning","M. Cheung; J. She","ECE, HKUST, Hong Kong Hong Kong 000 (e-mail: cpming@connect.ust.hk); ECE, HKUST, Clear Water Bay Hong Kong (e-mail: eejames@ust.hk)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","With the advance of mobile technology and social media, image sharing has become part of our daily lives. For many applications, such as follower/followee recommendation, shared images are an excellent source to discover connections among users who shared them. Shared images on social media are like invitations for user interactions, such as comment, like and more. Social signals are in those images, and those signals can be objects that interest related users such that they will start to interact. Conventionally, connections among users are discovered through recognizing objects among those shared images, such as a using convolutional neural network (CNN) to extract features that are sensitive to object recognition. However, social signals are not limited to object, they can be colour, textual, or even a concept that may not be captured effectively by conventional CNN. This paper proposes a CNN-based analytic framework to detect social signals among users. The CNN is optimised using a triplet network with user-shared images, and the relationships among users who upload them. It is observed that images from 2 users with a connection have a shorter distance after encoding, than 2 users without a connection. A framework is implemented, which is verified with over 1.7 million images by over 2000 users from two image-oriented social networks (SNs), Skyrock and Flickr. It is proven that the proposed analytic framework shows an up to 89% improvement on approaches using object recognition for follower/followee recommendation. To the best of our knowledge, this work is the first to propose an analytic framework to detect social signals from visual features for connection discovery.","","","10.1109/TMM.2019.2930043","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8777287","big data system;user-shared images;connection;discovery;recommendation;social network analysis;convolutional neural network","Social networking (online);Feature extraction;Visualization;Deep learning;Object recognition;Image recognition;Image coding","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Feature-Based Multitask Joint Sparse Representation for Hyperspectral Image Classification","M. Liang; L. Jiao; C. Xu","School of Information Engineering, Jiangxi University of Science and Technology, Ganzhou 341000, China.; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, School of Artificial Intelligence, Xidian University, Xi'an 710071, China.; School of Information Engineering, Jiangxi University of Science and Technology, Ganzhou 341000, China (e-mail: 9120000101@jxust.edu.cn).","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","Deep multiscale features extracted from diverse perspectives present a more powerful ability than shallow ones for hyperspectral image (HIS) classification. In this letter, we proposed a deep feature-based multitask joint sparse representation (D-MJSR) method. First, filter banks transferred from the pretrained VGG16 network are utilized to extract multiscale features of HSI. Then, features from each scale layer are respectively and collaboratively fused with the raw spectral feature and then upsampled by bilinear interpolation to reach the input size. Finally, with the advantages of feature distribution at different scales, JSR under multitask dictionaries is introduced to achieve the final classification, where samples are represented by dictionaries with different scale spaces independently, and neighborhood samples in each scale are represented by the same atoms wherever possible. We evaluate the proposed method D-MJSR by two public hyperspectral data sets quantitatively. Compared with existing feature extraction and SR-based methods, our method presents some significant improvement in classification accuracy.","","","10.1109/LGRS.2019.2950095","National Natural Science Foundation of China; Doctoral Scientific Research Foundation of the Jiangxi University of Science and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8894033","Convolutional neural network (CNN);hyperspectral images classification (HSIC);joint sparse representation (JSR);multitask learning;transfer learning.","Feature extraction;Data mining;Training;Hyperspectral imaging;Task analysis;Dictionaries","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Large-scale Nodes Classification with Deep Aggregation Network","J. Li; J. Wu; W. He; P. Zhou","School of Artificial Intelligence, Xidian University, 47905 Xian, Shaanxi China (e-mail: jt_li@stu.xidian.edu.cn); school of artificial intelligence, Xidian University, Xi'an, Shaanxi China (e-mail: jianshewu@126.com); School of Electronic Engineering, Xidian University, 47905 Xian, Shaanxi China (e-mail: weiquan-he@stu.xidian.edu.cn); School of Artificial intelligence, Xidian University, 47905 Xian, Shaanxi China (e-mail: 2857806893@qq.com)","IEEE Transactions on Knowledge and Data Engineering","","2019","PP","99","1","1","The most fundamental task of network representation learning (NRL) is nodes classification which requires an algorithm to map nodes to vectors and use machine learning models to predict nodes' labels. Recently, many methods based on neighborhood aggregation have achieved brilliant results in this task. However, the recursive expansion of neighborhood aggregation poses scalability and efficiency problems for deep models. Existing methods are limited to shallow architectures and cannot capture the high order proximity in networks. In this paper, we propose the deep aggregation network (DAN). DAN uses a layer-wise greedy optimization strategy which stacks several sequential trained base models to form the final deep model. The high order neighborhood aggregation is performed in a dynamic programming manner, which allows the recursion nature of neighborhood aggregation to be eliminated. The reverse random walk is also proposed, and combined with the classic random walk in formulating a novel sampling strategy that allows DAN to flexibly adapt to different tasks related to communities or structural roles. DAN is more efficient and effective than previous neighborhood aggregation based methods, especially when it is intended to handle large-scale networks with dense connections. Extensive experiments are conducted on both synthetic and real-world networks to empirically demonstrate the effectiveness and efficiency of the proposed method.","","","10.1109/TKDE.2019.2955502","Natural Science Basic Research Program of Shaanxi Province China; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8911261","Graph neural network;network representation learning;node embedding;node classification;semisupervised learning","Task analysis;Optimization;Scalability;Machine learning;Convolution;Neural networks;Collaboration","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Tree-gated Deep Mixture-of-Experts For Pose-robust Face Alignment","E. Arnaud; A. Dapogny; K. Bailly","Sorbonne Universitè, CNRS, Institut des Systèmes Intelligents et de Robotique, ISIR, F.-75005 Paris, France, and also with the Datakalab, Paris, France.; Datakalab, Paris, France.; Sorbonne Universitè, CNRS, Institut des Systèmes Intelligents et de Robotique, ISIR, F.-75005 Paris, France, and also with the Datakalab, Paris, France.","IEEE Transactions on Biometrics, Behavior, and Identity Science","","2019","PP","99","1","1","Face alignment consists of aligning a shape model on a face image. It is an active domain in computer vision as it is a preprocessing for a number of face analysis and synthesis applications. Current state-of-the-art methods already perform well on ""easy"" datasets, with moderate head pose variations, but may not be robust for ""in-the-wild"" data with poses up to 90∘. In order to increase robustness to an ensemble of factors of variations (e.g. head pose or occlusions), a given layer (e.g. a regressor or an upstream CNN layer) can be replaced by a Mixture of Experts (MoE) layer that uses an ensemble of experts instead of a single one. The weights of this mixture can be learned as gating functions to jointly learn the experts and the corresponding weights. In this paper, we propose to use tree-structured gates which allows a hierarchical weighting of the experts (Tree-MoE). We investigate the use of Tree-MoE layers in different contexts in the frame of face alignment with cascaded regression, firstly for emphasizing relevant, more specialized feature extractors depending of a high-level semantic information such as head pose (Pose-Tree-MoE), and secondly as an overall more robust regression layer. We perform extensive experiments on several challenging face alignment datasets, demonstrating that our approach outperforms the state-of-the-art methods.","","","10.1109/TBIOM.2019.2950032","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8887227","Face Alignment;Cascaded Regression;Ensemble methods;Deep Mixture-of-Experts;Head Pose Estimation.","Face;Feature extraction;Logic gates;Robustness;Deep learning;Biometrics (access control)","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Mesh Saliency via Weakly Supervised Classification-for-Saliency CNN","R. Song; Y. Liu; P. Rosin","Computing, Engineering and Mathematics, University of Brighton, Brighton, Brighton United Kingdom of Great Britain and Northern Ireland (e-mail: r.song@brighton.ac.uk); Department of Computer Science, Edge Hill University, 6249 Ormskirk, Lancashire United Kingdom of Great Britain and Northern Ireland (e-mail: Liuyo@edgehill.ac.uk); Computer Science and Informatics, Cardiff University, Cardiff, South Glamorgan United Kingdom of Great Britain and Northern Ireland (e-mail: rosinpl@cardiff.ac.uk)","IEEE Transactions on Visualization and Computer Graphics","","2019","PP","99","1","1","Recently, effort has been made to apply deep learning to the detection of mesh saliency. However, one major barrier is to collect a large amount of vertex-level annotation as saliency ground truth for training the neural networks. Quite a few pilot studies showed that this task is quite difficult. In this work, we solve this problem by developing a novel network trained in a weakly supervised manner. The training is end-to-end and does not require any saliency ground truth but only the class membership of meshes. Our Classification-for-Saliency CNN (CfS-CNN) employs a multi-view setup and contains a newly designed two-channel structure which integrates view-based features of both classification and saliency. It essentially transfers knowledge from 3D object classification to mesh saliency. Our approach significantly outperforms the existing state-of-the-art methods according to extensive experimental results. Also, the CfS-CNN can be directly used for scene saliency. We showcase two novel applications based on scene saliency to demonstrate its utility.","","","10.1109/TVCG.2019.2928794","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8765747","Mesh saliency;deep learning;transfer learning;weak supervision","Three-dimensional displays;Training;Two dimensional displays;Neural networks;Deep learning;Task analysis;Solid modeling","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Irregular Convolutional Residual LSTM for Urban Traffic Passenger Flows Prediction","B. Du; H. Peng; S. Wang; M. Z. A. Bhuiyan; L. Wang; Q. Gong; L. Liu; J. Li","State Key Laboratory of Software Development Environment, Beihang University, Beijing 100083, China, and also with the Beijing Advanced Innovation Center for Big Data and Brain Computing, Beihang University, Beijing 100083, China.; State Key Laboratory of Software Development Environment, Beihang University, Beijing 100083, China, and also with the Beijing Advanced Innovation Center for Big Data and Brain Computing, Beihang University, Beijing 100083, China (e-mail: penghao@act.buaa.edu.cn).; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing 211106, China.; Department of Computer and Information Sciences, Fordham University, New York, NY 10458 USA.; National Computer Network Emergency Response Technical Team/Coordination Center of China, Beijing 100029, China.; State Key Laboratory of Software Development Environment, Beihang University, Beijing 100083, China, and also with the Beijing Advanced Innovation Center for Big Data and Brain Computing, Beihang University, Beijing 100083, China.; State Key Laboratory of Software Development Environment, Beihang University, Beijing 100083, China, and also with the Beijing Advanced Innovation Center for Big Data and Brain Computing, Beihang University, Beijing 100083, China.; State Key Laboratory of Software Development Environment, Beihang University, Beijing 100083, China, and also with the Beijing Advanced Innovation Center for Big Data and Brain Computing, Beihang University, Beijing 100083, China.","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","14","Urban traffic passenger flows prediction is practically important to facilitate many real applications including transportation management and public safety. Recently, deep learning based approaches are proposed to learn the spatio-temporal characteristics of the traffic passenger flows. However, it is still very challenging to handle some complex factors such as hybrid transportation lines, mixed traffic, transfer stations, and some extreme weathers. Considering the multi-channel and irregularity properties of urban traffic passenger flows in different transportation lines, a more efficient and fine-grained deep spatio-temporal feature learning model is necessary. In this paper, we propose a deep irregular convolutional residual LSTM network model called DST-ICRL for urban traffic passenger flows prediction. We first model the passenger flows among different traffic lines in a transportation network into multi-channel matrices analogous to the RGB pixel matrices of an image. Then, we propose a deep learning framework that integrates irregular convolutional residential network and LSTM units to learn the spatial-temporal feature representations. To fully utilize the historical passenger flows, we sample both the short-term and long-term historical traffic data, which can capture the periodicity and trend of the traffic passenger flows. In addition, we also fuse other external factors further to facilitate a real-time prediction. We conduct extensive experiments on different types of traffic passenger flows datasets including subway, taxi and bus flows in Beijing as well as bike flows in New York. The results show that the proposed DST-ICRL significantly outperforms both traditional and deep learning based urban traffic passenger flows prediction methods.","","","10.1109/TITS.2019.2900481","National Natural Science Foundation of China; Beijing Advanced Innovation Center for Big Data and Brain Computing; Natural Science Foundation of Jiangsu Province of China; Fordham University Faculty Startup Grant; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8664646","Traffic passenger flows prediction;irregular convolutional neural network;LSTM;importance sampling;urban computing.","Predictive models;Deep learning;Market research;Data models;Convolution;Public transportation","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Reinforcement Learning for Smart Home Energy Management","L. Yu; W. Xie; D. Xie; Y. Zou; D. Zhang; Z. Sun; L. Zhang; Y. Zhang; T. Jiang","Key Laboratory of Broadband Wireless Communication and Sensor Network Technology of Ministry of Education, Nanjing University of Posts and Telecommunications, Nanjing 210003, P. R. China.; Key Laboratory of Broadband Wireless Communication and Sensor Network Technology of Ministry of Education, Nanjing University of Posts and Telecommunications, Nanjing 210003, P. R. China.; Key Laboratory of Broadband Wireless Communication and Sensor Network Technology of Ministry of Education, Nanjing University of Posts and Telecommunications, Nanjing 210003, P. R. China.; Key Laboratory of Broadband Wireless Communication and Sensor Network Technology of Ministry of Education, Nanjing University of Posts and Telecommunications, Nanjing 210003, P. R. China.; Jiangsu Key Laboratory of Broadband Wireless Communication and Internet of Things, School of Internet of Things, Nanjing University of Posts and Telecommunications, Nanjing 210003, P. R. China.; Key Laboratory of Broadband Wireless Communication and Sensor Network Technology of Ministry of Education, Nanjing University of Posts and Telecommunications, Nanjing 210003, P. R. China.; Key Laboratory of Broadband Wireless Communication and Sensor Network Technology of Ministry of Education, Nanjing University of Posts and Telecommunications, Nanjing 210003, P. R. China.; Department of Engineering, University of Leicester, Leicester LE1 7RH, U.K.; Wuhan National Laboratory for Optoelectronics, School of Electronics Information and Communications, Huazhong University of Science and Technology, Wuhan 430074, P. R. China.","IEEE Internet of Things Journal","","2019","PP","99","1","1","In this paper, we investigate an energy cost minimization problem for a smart home in the absence of a building thermal dynamics model with the consideration of a comfortable temperature range. Due to the existence of model uncertainty, parameter uncertainty (e.g., renewable generation output, non-shiftable power demand, outdoor temperature, and electricity price) and temporally-coupled operational constraints, it is very challenging to design an optimal energy management algorithm for scheduling Heating, Ventilation, and Air Conditioning (HVAC) systems and energy storage systems in the smart home. To address the challenge, we first formulate the above problem as a Markov decision process, and then propose an energy management algorithm based on Deep Deterministic Policy Gradients (DDPG). It is worth mentioning that the proposed algorithm does not require the prior knowledge of uncertain parameters and building thermal dynamics model. Simulation results based on real-world traces demonstrate the effectiveness and robustness of the proposed algorithm.","","","10.1109/JIOT.2019.2957289","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8919976","Smart home;energy management;deep reinforcement learning;energy cost;thermal comfort;energy storage systems;HVAC systems.","Smart homes;Energy management;Temperature distribution;Internet of Things;Heuristic algorithms;Load modeling","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Learning-based Driving Maneuver Prediction System","C. Ou; F. Karray","ECE, University of Waterloo, 8430 Waterloo, Ontario Canada N2L 3G1 (e-mail: c9ou@uwaterloo.ca); Electrical and Computer Engineering, University of Waterloo, Waterloo, Ontario Canada N2L3G1 (e-mail: karray@uwaterloo.ca)","IEEE Transactions on Vehicular Technology","","2019","PP","99","1","1","Many of todays vehicles are equipped with Advanced Driver Assistance Systems (ADAS). Proactive ADAS have the ability to predict short term driving situations. This provides drivers more time to take adequate actions to avoid or mitigate driving risks. In this work, we address the question of predicting drivers' imminent maneuvers before they perform an actual steering operation. The proposed system uses deep recurrent neural networks to fuse the information regarding driver observation actions and the driving environment. With new data labeling methods and effective sequential modeling approaches, the system is able to predict with high accuracy driving maneuvers shortly before the actual steering operations. A set of experiments show that the proposed approach anticipates lane change maneuvers 1.50 seconds before cars start to yaw with an accuracy improved to 90.52% and anticipates turn maneuvers at intersections with green lights 2.53 seconds before cars start to yaw with an accuracy improved to 78.59%. We also show in this work how the system can be adapted for driving proficiency assessment.","","","10.1109/TVT.2019.2958622","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8930040","Driver;maneuver prediction;driving safety;driving proficiency;deep learning","Predictive models;Automobiles;Hidden Markov models;Recurrent neural networks;Trajectory;Acceleration","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep learning analysis of coronary arteries in cardiac CT angiography for detection of patients requiring invasive coronary angiography","M. Zreik; R. W. van Hamersvelt; N. Khalili; J. M. Wolterink; M. Voskuil; M. A. Viergever; T. Leiner; I. Išgum","Image Sciences Institute, University Medical Center Utrecht, The Netherlands.; Department of Radiology, University Medical Center Utrecht, The Netherlands.; Image Sciences Institute, University Medical Center Utrecht, The Netherlands.; Image Sciences Institute, University Medical Center Utrecht, The Netherlands and the Department of Biomedical Engineering and Physics, Amsterdam University Medical Center.; Department of Cardiology, University Medical Center Utrecht and Utrecht University, The Netherlands.; Image Sciences Institute, University Medical Center Utrecht and Utrecht University, The Netherlands.; Department of Radiology, University Medical Center Utrecht and Utrecht University, The Netherlands.; Image Sciences Institute, University Medical Center Utrecht, The Netherlands, the Department of Biomedical Engineering and Physics, Amsterdam University Medical Center, and the Department of Radiology and Nuclear Medicine, Amsterdam University Medical Center.","IEEE Transactions on Medical Imaging","","2019","PP","99","1","1","In patients with obstructive coronary artery disease, the functional significance of a coronary artery stenosis needs to be determined to guide treatment. This is typically established through fractional flow reserve (FFR) measurement, performed during invasive coronary angiography (ICA). We present a method for automatic and non-invasive detection of patients requiring ICA, employing deep unsupervised analysis of complete coronary arteries in cardiac CT angiography (CCTA) images. We retrospectively collected CCTA scans of 187 patients, 137 of them underwent invasive FFR measurement in 192 different coronary arteries. These FFR measurements served as a reference standard for the functional significance of the coronary stenosis. The centerlines of the coronary arteries were extracted and used to reconstruct straightened multi-planar reformatted (MPR) volumes. To automatically identify arteries with functionally significant stenosis that require ICA, each MPR volume was encoded into a fixed number of encodings using two disjoint 3D and 1D convolutional autoencoders performing spatial and sequential encodings, respectively. Thereafter, these encodings were employed to classify arteries using a support vector machine classifier. The detection of coronary arteries requiring invasive evaluation, evaluated using repeated cross-validation experiments, resulted in an area under the receiver operating characteristic curve of 0.81±0.02 on the artery-level, and 0.87±0.02 on the patient-level. The results demonstrate the feasibility of automatic non-invasive detection of patients that require ICA and possibly subsequent coronary artery intervention. This could potentially reduce the number of patients that unnecessarily undergo ICA.","","","10.1109/TMI.2019.2953054","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8896989","Functionally significant coronary artery stenosis;Convolutional autoencoder;Convolutional neural network;Fractional flow reserve;Coronary CT angiography;Deep learning","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Siamese Visual Tracking with Deep Features and Robust Feature Fusion","D. Li; X. Wang; Y. Yu","Changchun Institute of Optics, Fine Mechanics and Physics, Chinese Academy of Science, 3888 Dongnanhu Road, Changchun 130033, China and University of Chinese Academy of Science, 19 Yuquan Road, Beijing 100049, China.; Israel Institute of Technology, Technion City, Haifa 3200003, Israel.; Changchun Institute of Optics, Fine Mechanics and Physics, Chinese Academy of Science, 3888 Dongnanhu Road, Changchun 130033, China.","IEEE Access","","2019","PP","99","1","1","Trackers based on fully-convolutional Siamese networks regard tracking as a process of learning a similarity function. By utilizing shallow networks and off-line training, Siamese trackers can achieve high tracking speed and perform well in some simple scenes. However, due to the less semantic information and the invariant template, Siamese trackers still have a gap compared with the state-of-the-art methods in complex scenes and other challenging problems (Occlusion, Deformation, etc.). In this paper, we propose a Siamese tracking algorithm with deep features and robust feature fusion (SiamDF). The improved ResNet-18 network is utilized to replace the traditional shallow network and extract the deep features with more semantic information. For eliminating the negative effect of padding and making better use of the deep network, the proposed algorithm adopts the spatial aware sampling strategy to overcome the strict translation invariance. Meanwhile, a final response map with high quality can be obtained by using the multi-layer feature fusion. Thus, the tracker can significantly reduce the impact of the distractors in complex scenes. In addition, an adaptive feature information fusion is adopted to update the template, so that the algorithm can adapt to various changes of the target appearance. Objective evaluation on the OTB100 dataset shows that the precision and the overlap success can reach 0.852 and 0.658 respectively. Moreover, the EAO value evaluated on the VOT2016 database can reach 0.336. These results demonstrate that our algorithm can effectively improve the tracking performance and perform favorably in both robustness and accuracy.","","","10.1109/ACCESS.2019.2962388","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8943391","Visual tracking;Siamese networks;deep features;feature fusion","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Energy-Efficient Mobile Crowdsensing by Unmanned Vehicles: A Sequential Deep Reinforcement Learning Approach","C. Piao; C. H. Liu","Computer Science and Technology, Beijing Institute of Technology, Beijing 100081, China.; Computer Science and Technology, Beijing Institute of Technology, Beijing 100081, China.","IEEE Internet of Things Journal","","2019","PP","99","1","1","Mobile crowdsensing (MCS) is an attractive and innovative paradigm in which a crowd of users equipped with smart mobile devices (such as smartphones, iPads), and more recently unmanned vehicles (UVs, e.g., driverless cars and drones) conduct sensing tasks in mobile social networks by fully exploiting their carried diverse embedded sensors. These devices, especially UVs, are usually constrained by limited sensing range and energy reserve of devices, which contribute to the restriction of one single UV task performance, and thus UV collaborations are fully favored. In this paper, we explicitly consider navigating a group of UVs to collect different kinds of data in a city, with the presence of multiple charging stations. Different from existing approaches that solve the problem by forming a constrained optimization problem, we propose a novel sequential deep model called “PPO+LSTM"", which contains a sequential model LSTM and is trained with proximal policy optimization (PPO), for assigning tasks and planning route. We evaluate our model in different network settings when comparing with other state-of-the-art solutions, and we also show the impact of important hyperparameters of our model. Results show that our solution outperforms all others in terms of energy efficiency, data collection ratio, and geographic fairness.","","","10.1109/JIOT.2019.2962545","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8944303","Mobile crowdsensing;deep reinforcement learning;sequential modeling.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"An Online Deep Convolutional Model of Gross Primary Productivity and Net Ecosystem Exchange Estimation for Global Forests","W. Wu; C. Gong; X. Li; H. Guo; L. Zhang","Key Laboratory of Digital Earth Sciences, Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing 100094, China (e-mail: wenjin.wu.happy@gmail.com).; Key Laboratory of Digital Earth Sciences, Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing 100094, China (e-mail: gongchen@radi.ac.cn).; Key Laboratory of Digital Earth Sciences, Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing 100094, China (e-mail: lixw@radi.ac.cn).; Key Laboratory of Digital Earth Sciences, Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing 100094, China (e-mail: hdguo@radi.ac.cn).; Key Laboratory of Digital Earth Sciences, Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing 100094, China (e-mail: zhanglu@radi.ac.cn).","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2019","PP","99","1","11","In this article, we propose a universal data-driven model to acquire FLUXNET-consistent annual forest gross primary productivity and net ecosystem exchange globally. The model is developed based on a deep-learning network with a time series of seven ecological and climatic parameters as inputs. To avoid tedious data downloading for large-area studies, we build this model on the Google earth engine platform with all of the input data available online. A multidimensional convolutional block is adopted to detect meaningful variation patterns between forest growth and the environment. The patterns are then encoded and adjusted with forest attributes to obtain the final estimation through a multilayer perceptron. This special working mechanism enables the model to understand and adapt to different modes of forest carbon dynamics. The new model behaves more like a human than conventional machine-learning models, which directly retrieve estimations from raw input variables. Multistep transfer learning is implemented to make the model robust to a large portion of data gaps and to obtain a balanced performance for different climates and ecological zones. The experimental results demonstrate that the model can achieve estimations that are highly consistent with the FLUXNET records. By visualizing the activation outputs of intermediate layers in the convolutional block, we show that the model can reasonably reflect key influence factors in different periods of a year for various forest types. This result means that we may be able to better understand forest carbon absorption by learning how this model works to obtain correct estimations.","","","10.1109/JSTARS.2019.2954556","National Basic Research Program of China (973 Program); National Natural Science Foundation of China; Key Research and Development Program of Hainan Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8920232","Deep learning (DL);forest carbon flux;Google earth engine (GEE);gross primary productivity (GPP);net ecosystem exchange (NEE);transfer learning","Forestry;Biological system modeling;Estimation;Carbon;Ecosystems;Productivity;Data models","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Transfer Learning for Non-Intrusive Load Monitoring","M. D’Incecco; S. Squartini; M. Zhong","Dipartimento di Ingegneria dell’Informazione-Universit C Politecnica delle Marche, Via Brecce Bianche 12, 60131 Ancona, Italy.; Dipartimento di Ingegneria dell’Informazione-Universit C Politecnica delle Marche, Via Brecce Bianche 12, 60131 Ancona, Italy.; School of Computer Science in the University of Lincoln, Lincoln LN6 7TS, UK.","IEEE Transactions on Smart Grid","","2019","PP","99","1","1","Non-intrusive load monitoring (NILM) is a technique to recover source appliances from only the recorded mains in a household. NILM is unidentifiable and thus a challenge problem because the inferred power value of an appliance given only the mains could not be unique. To mitigate the unidentifiable problem, various methods incorporating domain knowledge into NILM have been proposed and shown effective experimentally. Recently, among these methods, deep neural networks are shown performing best. Arguably, the recently proposed sequence-to-point (seq2point) learning is promising for NILM. However, the results were only carried out on the same data domain. It is not clear if the method could be generalised or transferred to different domains, e.g., the test data were drawn from a different country comparing to the training data. We address this issue in the paper, and two transfer learning schemes are proposed, i.e., appliance transfer learning (ATL) and cross-domain transfer learning (CTL). For ATL, our results show that the latent features learnt by a ‘complex’ appliance, e.g., washing machine, can be transferred to a ‘simple’ appliance, e.g., kettle. For CTL, our conclusion is that the seq2point learning is transferable. Precisely, when the training and test data are in a similar domain, seq2point learning can be directly applied to the test data without fine tuning; when the training and test data are in different domains, seq2point learning needs fine tuning before applying to the test data. Interestingly, we show that only the fully connected layers need fine tuning for transfer learning. Source code can be found at https://github.com/MingjunZhong/transferNILM.","","","10.1109/TSG.2019.2938068","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8818314","NILM;Non-Intrusive Load Monitoring;Energy Disaggregation;Deep Neural Networks;Transfer Learning;Sequence-to-point Learning.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Neural Networks Improve Radiologists’ Performance in Breast Cancer Screening","N. Wu; J. Phang; J. Park; Y. Shen; Z. Huang; M. Zorin; S. Jastrzębski; T. Févry; J. Katsnelson; E. Kim; S. Wolfson; U. Parikh; S. Gaddam; L. L. Y. Lin; K. Ho; J. D. Weinstein; B. Reig; Y. Gao; H. T. K. Pysarenko; A. Lewin; J. Lee; K. Airola; E. Mema; S. Chung; E. Hwang; N. Samreen; S. G. Kim; L. Heacock; L. Moy; K. Cho; K. J. Geras","Center for Data Science, New York University, 60 5th Ave, New York, NY 10011, USA.; Center for Data Science, New York University, 60 5th Ave, New York, NY 10011, USA.; Center for Data Science, New York University, 60 5th Ave, New York, NY 10011, USA.; Center for Data Science, New York University, 60 5th Ave, New York, NY 10011, USA.; Center for Data Science, New York University, 60 5th Ave, New York, NY 10011, USA.; Department of Computer Science and Technology, University of Cambridge, William Gates Building, 15 JJ Thomson Ave, Cambridge CB3 0FD, UK.; Faculty of Mathematics and Information Technologies, Jagiellonian University, Łojasiewicza 6, 30-348 Kraków, Poland.; Department of Computer Science and Technology, University of Cambridge, William Gates Building, 15 JJ Thomson Ave, Cambridge CB3 0FD, UK.; Department of Radiology, New York University School of Medicine, 660 First Ave, New York, NY 10016, USA.; Department of Radiology, New York University School of Medicine, 660 First Ave, New York, NY 10016, USA.; Department of Radiology, New York University School of Medicine, 660 First Ave, New York, NY 10016, USA.; Department of Radiology, New York University School of Medicine, 660 First Ave, New York, NY 10016, USA.; Department of Radiology, New York University School of Medicine, 660 First Ave, New York, NY 10016, USA.; Department of Radiology, New York University School of Medicine, 660 First Ave, New York, NY 10016, USA.; SUNY Downstate College of Medicine, 450 Clarkson Ave, New York, NY 11203, USA.; Department of Radiology, New York University School of Medicine, 660 First Ave, New York, NY 10016, USA.; Department of Radiology, New York University School of Medicine, 660 First Ave, New York, NY 10016, USA and Perlmutter Cancer Center, NYU Langone Health, 160 E 34th St, New York, NY 10016, USA.; Department of Radiology, New York University School of Medicine, 660 First Ave, New York, NY 10016, USA and Perlmutter Cancer Center, NYU Langone Health, 160 E 34th St, New York, NY 10016, USA.; Department of Radiology, New York University School of Medicine, 660 First Ave, New York, NY 10016, USA and Perlmutter Cancer Center, NYU Langone Health, 160 E 34th St, New York, NY 10016, USA.; Department of Radiology, New York University School of Medicine, 660 First Ave, New York, NY 10016, USA and Perlmutter Cancer Center, NYU Langone Health, 160 E 34th St, New York, NY 10016, USA.; Department of Radiology, New York University School of Medicine, 660 First Ave, New York, NY 10016, USA and Perlmutter Cancer Center, NYU Langone Health, 160 E 34th St, New York, NY 10016, USA.; Department of Radiology, New York University School of Medicine, 660 First Ave, New York, NY 10016, USA.; Department of Radiology, New York University School of Medicine, 660 First Ave, New York, NY 10016, USA.; Department of Radiology, New York University School of Medicine, 660 First Ave, New York, NY 10016, USA.; Department of Radiology, New York University School of Medicine, 660 First Ave, New York, NY 10016, USA.; Department of Radiology, New York University School of Medicine, 660 First Ave, New York, NY 10016, USA.; Department of Radiology, New York University School of Medicine, 660 First Ave, New York, NY 10016, USA and 4Perlmutter Cancer Center, NYU Langone Health, 160 E 34th St, New York, NY 10016, USA and Center for Advanced Imaging Innovation and Research, NYU Langone Health, 660 First Ave, New York, NY 10016, USA.; Department of Radiology, New York University School of Medicine, 660 First Ave, New York, NY 10016, USA and Perlmutter Cancer Center, NYU Langone Health, 160 E 34th St, New York, NY 10016, USA.; Department of Radiology, New York University School of Medicine, 660 First Ave, New York, NY 10016, USA and 4Perlmutter Cancer Center, NYU Langone Health, 160 E 34th St, New York, NY 10016, USA and Center for Advanced Imaging Innovation and Research, NYU Langone Health, 660 First Ave, New York, NY 10016, USA.; Center for Data Science, New York University, 60 5th Ave, New York, NY 10011, USA and Courant Institute of Mathematical Sciences, New York University, 251 Mercer St, New York, NY 10012, USA.; Department of Radiology, New York University School of Medicine, 660 First Ave, New York, NY 10016, USA Center for Data Science, New York University, 60 5th Ave, New York, NY 10011, USA and Center for Advanced Imaging Innovation and Research, NYU Langone Health, 660 First Ave, New York, NY 10016, USA.","IEEE Transactions on Medical Imaging","","2019","PP","99","1","1","We present a deep convolutional neural network for breast cancer screening exam classification, trained and evaluated on over 200,000 exams (over 1,000,000 images). Our network achieves an AUC of 0.895 in predicting the presence of cancer in the breast, when tested on the screening population. We attribute the high accuracy to a few technical advances. (i) Our network’s novel two-stage architecture and training procedure, which allows us to use a high-capacity patch-level network to learn from pixel-level labels alongside a network learning from macroscopic breast-level labels. (ii) A custom ResNet-based network used as a building block of our model, whose balance of depth and width is optimized for high-resolution medical images. (iii) Pretraining the network on screening BI-RADS classification, a related task with more noisy labels. (iv) Combining multiple input views in an optimal way among a number of possible choices. To validate our model, we conducted a reader study with 14 readers, each reading 720 screening mammogram exams, and show that our model is as accurate as experienced radiologists when presented with the same data. We also show that a hybrid model, averaging the probability of malignancy predicted by a radiologist with a prediction of our neural network, is more accurate than either of the two separately. To further understand our results, we conduct a thorough analysis of our network’s performance on different subpopulations of the screening population, the model’s design, training procedure, errors, and properties of its internal representations. Our best models are publicly available at https://github.com/nyukat/breastcancerclassifier.","","","10.1109/TMI.2019.2945514","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8861376","deep learning;deep convolutional neural networks;breast cancer screening;mammography","Breast cancer;Task analysis;Biomedical imaging;Predictive models;Training","","","","3","","CCBY","","","","IEEE","IEEE Early Access Articles"
"ASCENT: Active Supervision for Semi-supervised Learning","Y. Li; Y. l. Wang; D. Yu; Y. Ning; P. Hu; R. Zhao","College of Information Science and Technology, Nanjing Forestry University, 74584 Nanjing, Jiangsu China (e-mail: yanchao.cs@gmail.com); Department of computer science, Nanjing University of science and technology, NanJing, Jiangsu China (e-mail: yongliwang@mail.njust.edu.cn); School of Computer Science and Engineering, Nanjing University of Science and Technology, 12436 Nanjing, Jiangsu China (e-mail: njyudj@njust.edu.cn); College of Information Science and Technology, Nanjing Forestry University, 74584 Nanjing, Jiangsu China (e-mail: yening@njfu.edu.cn); School of Computer Science and Engineering, Nanjing University of Science and Technology, 12436 Nanjing, Jiangsu China (e-mail: hupeng1117@163.com); School of Computer Science and Engineering, Nanjing University of Science and Technology, 12436 Nanjing, Jiangsu China (e-mail: nnzhaoms@126.com)","IEEE Transactions on Knowledge and Data Engineering","","2019","PP","99","1","1","Active learning algorithms attempt to overcome the labeling bottleneck by asking queries from large collection of unlabeled examples. Existing batch mode active learning algorithms suffer from three limitations: (1) The methods that are based on similarity function or optimizing certain diversity measurement, in which may lead to suboptimal performance and produce the selected set with redundant examples; (2) The models with assumption on data are hard in finding images that are both informative and representative; (3) The problem of noise labels has been an obstacle for algorithms. In this paper, we propose a novel active learning method that makes embeddings of labeled examples to those of unlabeled ones and back via deep neural networks. The active scheme makes correct association cycles that end up at the same class from that the association was started, which considers both the informativeness and representativeness of examples, as well as being robust to noise labels. We apply our active learning method to semi-supervised classification and clustering. The submodular function is designed to reduce the redundancy of the selected examples. Specifically, we incorporate our batch mode active scheme into the classification approaches, in which the generalization ability is improved. For semi-supervised clustering, we try to use our active scheme for constraints to make fast convergence and perform better than unsupervised clustering. Finally, we apply our active learning method to data filtering. To validate the effectiveness of the proposed algorithms, extensive experiments are conducted on diversity benchmark datasets for different tasks, i.e., classification, clustering, and data filtering, and the experimental results demonstrate consistent and substantial improvements over the state-of-the-art approaches.","","","10.1109/TKDE.2019.2897307","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; Nanjing Science and Technology Development Plan Project; 13th Five-Year equipment field fund; China Scholarship Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8633423","Active Learning;Semi-supervised Learning;Iterative Learning;Clustering;Classification;Data Filtering","Task analysis;Clustering algorithms;Data models;Redundancy;Uncertainty;Semisupervised learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Learning to Generate Radar Image Sequences Using Two-Stage Generative Adversarial Networks","C. Zhang; X. Yang; Y. Tang; W. Zhang","Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China, and also with the University of Chinese Academy of Sciences, Beijing 101408, China.; Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China.; Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China, and also with the University of Chinese Academy of Sciences, Beijing 101408, China.; Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China (e-mail: zhangwenshengia@hotmail.com).","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","While quantitative precipitation estimation (QPE) using weather radar is widely adopted in operation, precipitation data sets are often highly imbalanced. In particular, extreme precipitation usually lacks representation, which may introduce the bottleneck for radar QPE with machine learning models. Discovering the intrinsic characteristic of extreme precipitation with few samples is challenging. In this letter, we focus on the radar reflectivity data and aim to generate synthetic radar image sequences with respect to extreme precipitation. Considering the relatively long interval between continuous radar images due to radar volume scan, traditional methods in video generation are not suitable. In this letter, we propose Two-stage Generative Adversarial Networks (TsGANs) to address the above-mentioned problem. In general, our TsGAN constructs adversarial process between generators and discriminators: the generator produces samples similar to real data, while the discriminator determines whether or not a sample is eligible. In Stage I, we generate an image sequence containing content and motion features. In Stage II, we design an enhanced net structure to enrich the adversarial processes and further improve the motion features. Experimental testing is performed within the radar coverage in Shenzhen, China, on rainfall events in 2014-2016. Results show that our TsGAN is superior to previous works.","","","10.1109/LGRS.2019.2922326","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8754756","Deep learning;extreme precipitation;generative adversarial networks (GANs);radar image sequences.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Ensemble Hierarchical Extreme Learning Machine for Speech Dereverberation","T. Hussain; S. M. Siniscalchi; H. S. Wang; Y. Tsao; S. V. Mario; W. Liao","Taiwan International Graduate Program, Social Network and Human Centered Computing (SNHCC) Program, Institute of Information Science, Academia Sinica, Taiwan and Department of Computer Science, National Chengchi University, Taipei, Taiwan.; Department of Computer Engineering, Kore University of Enna, Enna, Italy, and Department of Electrical Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA.; Department of Special Education, National Taiwan Normal University, Taipei, Taiwan.; Research Center for Information Technology Innovation (CITI) at Academia Sinica, Taipei, Taiwan.; Faculty of Engineering and Architecure, Kore University of Enna, Italy.; Department of Computer Science, National Chengchi University, Taipei, Taiwan.","IEEE Transactions on Cognitive and Developmental Systems","","2019","PP","99","1","1","Data-driven deep learning solutions, which are gradient-based neural architectures, have proven useful in overcoming some limitations of traditional signal processing techniques. However, a large number of reverberated-anechoic training utterance pairs covering as many environmental conditions as possible is required to achieve robust performance in unseen testing conditions. In this study, we propose to address the data requirement issue while preserving the advantages of deep neural structures leveraging upon hierarchical extreme learning machines (HELMs), which are not gradient-based neural architectures. In particular, an ensemble HELM learning framework is established to effectively recover anechoic speech from a reverberated one based on a spectral mapping. In addition to the ensemble learning framework, we further derive two novel HELM models, namely highway HELM, termed HELM(Hwy), and residual HELM, termed HELM(Res), both incorporating low-level features to enrich the information for spectral mapping. We evaluated the proposed ensemble learning framework using simulated and measured impulse responses by employing TIMIT, MHINT, and REVERB corpora. Experimental results show that the proposed framework outperforms both traditional methods and a recently proposed integrated deep and ensemble learning algorithm in terms of standardized objective and subjective evaluations under matched and mismatched testing conditions for simulated and measured impulse responses.","","","10.1109/TCDS.2019.2953620","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8906014","Speech Dereverberation;Ensemble Learning;Hierarchical Extreme Learning Machines;Highway Extreme Learning Machine;Residual Extreme Learning Machine.","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Deep Residual Network with Adaptive Learning Framework for Fingerprint Liveness Detection","C. Yuan; Z. Xia; X. Sun; Q. M. J. Wu","School of Computer and Software, Nanjing University of Information Science and Technology, Nanjing, 210044, China, and with the Jiangsu Engineering Center of Network Monitoring, Nanjing, 210044, China, and also with the Department of Electrical and Computer Engineering, University of Windsor, Windsor, ON N9B 3P4, Canada.; School of Computer and Software, Nanjing University of Information Science and Technology, Nanjing, 210044, China, and also with the Jiangsu Engineering Center of Network Monitoring, Nanjing, 210044, China.; School of Computer and Software, Nanjing University of Information Science and Technology, Nanjing, 210044, China, and also with the Jiangsu Engineering Center of Network Monitoring, Nanjing, 210044, China.; Department of Electrical and Computer Engineering, University of Windsor, Windsor, ON N9B 3P4, Canada.","IEEE Transactions on Cognitive and Developmental Systems","","2019","PP","99","1","1","Nowadays, fingerprint recognition technology has aroused wide attention in the society, especially in the application of identity authentication with smart phone as the carrier. However, the disadvantage of these devices is that the identification sensors are vulnerable to spoofing attacks from artificial replicas made from clay, gelatin, silicon, etc. To resolve it, a feasible anti-deception countermeasure, called fingerprint liveness detection (FLD), has been proposed. Different from most shallow feature methods, the deep convolutional neural network (DCNN) based FLD methods have been widely explored with the properties of fast operation, few parameters and end-to-end feature self-learning. But DCNN is confronted with a contradictory problem, on the one hand, the testing or training result will keep rising with the increasement of multilayer perceptron (MLP), finally tends to a stable value, and continue to increase MLP results will decline. Much research, on the other hand, shows that the number of MLP is the foundation of realizing a high performance detection. Hereby, we apply Deep Residual Network (DRN) to FLD for the first time to solve the contradiction mentioned in this paper. Next, to eliminate the interference of invalid regions of given images, a region of interest (ROI) extraction algorithm has been put forward. Afterwards, to avoid the parameters learned plunging into local optimization, an adaptive learning based deep residual networks (ALDRN), which automatically adjust learning rate if those monitoring parameters (verification accuracy) are stable, has been explored. Finally, we propose a novel texture enhancement based on local gradient pattern (LGP) method to improve the generalization of model classifier as well. Experimental results on three benchmarks Datasets: LivDet 2011, 2013 and 2015, show that our results outperform the state-of-the-art FLD methods.","","","10.1109/TCDS.2019.2920364","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8727907","DCNN;multilayer perceptron;local gradient pattern;ROI;LivDet;Fingerprint liveness detection.","Authentication;Feature extraction;Adaptation models;Adaptive learning;Sensors;Training;Interference","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Gesture Video Generation with Learning on Regions of Interest","R. Cui; Z. Cao; W. Pan; C. Zhang; J. Wang","Department of Automation, Tsinghua University, 12442 Beijing, Beijing China (e-mail: cuirunpeng@mail.tsinghua.edu.cn); Department of Automation, Tsinghua University, 12442 Beijing China (e-mail: caozhong14@mails.tsinghua.edu.cn); Department of Automation, Tsinghua University, 12442 Beijing China (e-mail: pws15@mails.tsinghua.edu.cn); Department of Automation, Tsinghua University, 12442 Beijing, Beijing China (e-mail: zcs@mail.tsinghua.edu.cn); School of Vehicle and Mobility, Tsinghua University, 12442 Beijing, Beijing China (e-mail: wjqlws@tsinghua.edu.cn)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","Generating videos with semantic meaning, such as gestures in sign language, is a challenging problem. The model should not only learn to generate videos with realistic appearance, but also take notice of crucial details in frames to convey precise information. In this paper, we focus on the problem of generating long-term gesture videos containing precise and complete semantic meanings. We develop a novel architecture to learn the temporal and spatial transforms in regions of interest, i.e., gesticulating hands or face in our case. We adopt a hierarchical approach for generating gesture videos, by first making predictions on future pose configurations, and then using the encoder-decoder architecture to synthesize future frames based on the predicted pose structures. We develop the scheme of action progress in our architecture to represent how far the action has been performed during its expected execution, and to instruct our model to synthesize actions with various paces. Our approach is evaluated on two challenging datasets for the task of gesture video generation. Experimental results show that our method can produce gesture videos with more realistic appearance and precise meaning than the state-of-the-art video generation approaches.","","","10.1109/TMM.2019.2960700","China National Funds for Distinguished Young Scientists; Beijing Academy of Artificial Intelligence; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8936484","video generation;action progress;regions of interest","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Digital Holographic reconstruction based on deep learning framework with unpaired data","D. Yin; Z. Gu; Y. Zhang; F. Gu; S. Nie; J. Ma; C. Yuan","Nanjing Normal University, 12534 Nanjing, Jiangsu China (e-mail: 15651617612@163.com); Nanjing Normal University, 12534 Nanjing, Jiangsu China (e-mail: guzhongzheng1994@163.com); Nanjing Normal University, 12534 Nanjing, Jiangsu China (e-mail: zhangyanran1994@163.com); Nanjing Normal University, 12534 Nanjing, Jiangsu China (e-mail: lolfda@163.com); Nanjing Normal University, 12534 Nanjing, Jiangsu China (e-mail: nieshouping@njnu.edu.cn); Nanjing University of Science and Technology, 12436 Nanjing, Jiangsu China (e-mail: majun@njust.edu.cn); Nanjing Normal University, 12534 Nanjing, Jiangsu China 210000 (e-mail: yuancj@njnu.edu.cn)","IEEE Photonics Journal","","2019","PP","99","1","1","Convolutional neural network (CNN) has great potentials in holographic reconstruction. Although excellent results can be achieved by using this technique, the number of training and label data must be the same and strict paired relationship is required. Here, we present a new end-to-end learning-based framework to reconstruct noise-free images in absence of any paired training data and prior knowledge of object real distribution. The algorithm uses the cycle consistency loss and generative adversarial network to implement unpaired training method. It is demonstrated by the experiments that high accuracy reconstruction images can be obtained by using unpaired training and label data. Moreover, the unpaired feature of the algorithm makes the system robust to displacement aberration and defocusing effect.","","","10.1109/JPHOT.2019.2961137","National Natural Science Foundation of China; National key research and development program; Open Foundation of Key Lab of Virtual Geographic Environment Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8937798","Holography;Deep Learning;Phase recovery;Aberration","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"A Wave-shaped Deep Neural Network for Smoke Density Estimation","F. Yuan; L. Zhang; X. Xia; Q. Huang; X. Li","College of Information, Mechanical and Electrical Engineering, Shanghai Normal University, Shanghai 201418, China.; School of Information Technology, Jiangxi University of Finance and Economics, Nanchang, Jiangxi, 330032, China and School of Mathematics and Computer Science, Jiangxi Science and Technology Normal University, Nanchang 330038, China.; School of Information Technology, Jiangxi University of Finance and Economics, Nanchang, Jiangxi, 330032, China.; School of Computer Science and Center for OPTical IMagery Analysis and Learning (OPTIMAL), Northwestern Polytechnical University, Xi’an, Shaanxi 710072, China.; School of Computer Science and Center for OPTical IMagery Analysis and Learning (OPTIMAL), Northwestern Polytechnical University, Xi’an, Shaanxi 710072, China.","IEEE Transactions on Image Processing","","2019","PP","99","1","1","Smoke density estimation from a single image is a totally new but highly ill-posed problem. To solve the problem, we stack several convolutional encoder-decoder structures together to propose a wave-shaped neural network, termed W-Net. Stacking encoder-decoders directly increases the network depth, leading to the enlargement of receptive fields for encoding more semantic information. To maximize the degrees of feature re-usage, we copy and resize the outputs of encoding layers to corresponding decoding layers, and then concatenate them to implement short-cut connections for improving spatial accuracy. The crests and troughs of W-Net are special structures containing abundant localization and semantic information, so we also use short-cut connections between these structures and decoding layers. Estimated smoke density is useful in many applications, such as smoke segmentation, smoke detection, disaster simulation. Experimental results show that our method outperforms existing methods on both smoke density estimation and segmentation. It also achieves satisfying results in visual detection of auto exhausts.","","","10.1109/TIP.2019.2946126","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8868104","Deep neural network;W-Net;smoke density estimation;smoke segmentation;smoke simulation","Estimation;Image segmentation;Feature extraction;Semantics;Image color analysis;Decoding;Visualization","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Modern Machine Learning for Cyber-defense and Distributed Denial of Service Attacks","R. Paffenroth; C. Zhou","Data Science, Worcester Polytechnic Institute, 8718 Worcester, Massachusetts United States 01609-2247 (e-mail: rcpaffenroth@wpi.edu); Data Science, Worcester Polytechnic Institute, 8718 Worcester, Massachusetts United States (e-mail: czhou2@wpi.edu)","IEEE Engineering Management Review","","2019","PP","99","1","1","In computer networks, Denial-of-Service (DoS) attacks attempt to make computers or network resources unavailable for their intended use. DoS attacks are difficult to detect and mitigate since they normally do not attempt to access the private data of their intended victim, but rather intend to disrupt the publicly available resources their victims provide. This paper discusses methods for detecting and mitigating DoS attacks with a focus on techniques that leverage machine learning algorithms. Such algorithms promise to: (a) detect when computer services are being used in an adversarial fashion, (b) separate network traffic into nominal and anomalous components, and (c) provide opportunities for mitigating the attacks while maintaining the integrity of the effected services. The key ingredient of the ideas presented here is the use of correlations and dependencies in computer access patterns, and the larger context in which they exist, to separate the ""wheat"" -- the real users of the services -- from the ""chaff"" --the perpetrators who are attempting to disrupt the services.","","","10.1109/EMR.2019.2950183","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8886351","Cyber defense;Anomaly detection;DDoS;Machine Learning;Deep Learning","Internet;Computer crime;Denial-of-service attack;Machine learning;Servers;Business","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Novel Approach for ECG-based Human Identification using Spectral Correlation and Deep Learning","S. S. Abdeldayem; T. Bourlai","MILab, Lane Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, WV 2650, USA.; MILab, Lane Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, WV 2650, USA.","IEEE Transactions on Biometrics, Behavior, and Identity Science","","2019","PP","99","1","1","In this paper, we utilize the electrocardiogram (ECG) as a primary biometric modality in human identification. The design steps of the proposed approach are the following: first, we segment the ECG signal and utilize its cyclostationarity and spectral correlation to enrich the signal’s original informational content. Then, we generate spectral correlation images. During this process, we disregard the time-consuming algorithmic step, typically used in other similar ECG-based machine learning approaches, namely the fiducial points detection and noise removal steps. Next, our spectral correlation images are fed into two convolutional neural network (CNN) architectures, which we fine-tune, test and evaluate, before we suggest a final architecture that demonstrates improved ECG-based human identification accuracy. To evaluate the efficiency of the proposed approach, we perform cross-validation on nine, small and large scale, ECG databases that encompass both normal and abnormal ECG signals. Experimental results show that independent of the database used, our approach results in improved system performance (compared to state-of-art approaches), yielding an identification accuracy, false acceptance and false rejection rates of 95.6%, 0.2%, and 0.1% respectively.","","","10.1109/TBIOM.2019.2947434","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8869904","Biometrics;Convolutional Neural Networks;Deep learning;Electrocardiogram (ECG);Human Identification;Spectral Correlation.","Electrocardiography;Biometrics (access control);Heart;Correlation;Databases;Feature extraction;Physiology","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Crawling in Rogue's dungeons with deep reinforcement techniques","A. Asperti; D. Cortesi; C. de Pieri; G. Pedrini; F. Sovrano","University of Bologna, Department of Informatics, Bologna, Bologna Italy 40127 (e-mail: andrea.asperti@unibo.it); University of Bologna, Department of Informatics, Bologna, Bologna Italy (e-mail: daniele.cortesi2@studio.unibo.it); University of Bologna, Department of Informatics, Bologna, Bologna Italy (e-mail: carlo.depieri@studio.unibo.it); University of Bologna, Department of Informatics, Bologna, Bologna Italy (e-mail: gianmariapedrini@gmail.com); University of Bologna, Department of Informatics, Bologna, Bologna Italy (e-mail: francesco.sovrano@studio.unibo.it)","IEEE Transactions on Games","","2019","PP","99","1","1","This article is a report of our extensive experimentation, during the last two years,of deep reinforcement techniques for training an agent to move in the dungeons of the famous Rogue video-game. The challenging nature of the problem is tightly related the procedural, random generation of new dungeon maps at each level, that forbids any form of level-specific learning, and forces to address the navigation problem in its full generality. Other interesting aspects of the game from the point of view of automatic learning are the partially observable nature of the problem, since maps are initially not visible and get discovered during exploration, and the problem of sparse rewards, requiring the acquisition of complex, non-reactive behaviors involving memory and planning. In this article, we develop on previous works to make a more systematic comparison of different learning techniques, focusing in particular on Asynchronous Advantage Actor-Critic (A3C) and Actor-Critic with Experience Replay (ACER). In a game like Rogue, sparsity of rewards is mitigated by the variability of the dungeon configurations (sometimes, by luck, exit is at hand); if this variability can be tamed - as ACER, better than other algorithms, seems able to do - the problem of sparse rewards can be overcome without any need of intrinsic motivations.","","","10.1109/TG.2019.2899159","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8641337","Deep Reinforcement Learning;Rogue;Dungeon;Maze;Labyrinth;Asynchronous Advantage Actor-Critic;Experience Replay;A3C;ACER;Partially Observable Markov Decision;Process;Sparsity of Rewards;Experience Replay;Attention","Games;Training;Reinforcement learning;Libraries;Focusing;Navigation;Planning","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Inter-Patient ECG Classification with Symbolic Representations and Multi-Perspective Convolutional Neural Networks","J. Niu; Y. Tang; Z. Sun; W. Zhang","University of the Chinese Academy of Sciences, 74519 Beijing China (e-mail: niujinghao2015@ia.ac.cn); University of the Chinese Academy of Sciences, 74519 Beijing China (e-mail: tangyongqiang2014@ia.ac.cn); Institute of Automation Chinese Academy of Sciences, 74522 Beijing China (e-mail: zhengya.sun@ia.ac.cn); Institute of Automation Chinese Academy of Sciences, 74522 Beijing China 100080 (e-mail: zhangwenshengia@hotmail.com)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","This paper presents a novel deep learning framework for the inter-patient electrocardiogram (ECG) heartbeat classification. A symbolization approach especially designed for ECG is introduced, which can jointly represent the morphology and rhythm of the heartbeat and alleviate the influence of inter-patient variation through baseline correction. The symbolic representation of the heartbeat is used by a multi-perspective convolutional neural network (MPCNN) to learn features automatically and classify the heartbeat. We evaluate our method for the detection of the supraventricular ectopic beat (SVEB) and ventricular ectopic beat (VEB) on MIT-BIH arrhythmia dataset. Compared with the state-of-the-art methods based on manual features or deep learning models, our method shows superior performance: the overall accuracy of 96.4%, F1 scores for SVEB and VEB of 76.6% and 89.7%, respectively. The ablation study on our method validates the effectiveness of the proposed symbolization approach and joint representation architecture, which can help the deep learning model to learn more general features and improve the ability of generalization for unseen patients. Because our method achieves a competitive inter-patient heartbeat classification performance without complex handcrafted features or the intervention of the human expert, it can also be adjusted to handle various other tasks relative to ECG classification.","","","10.1109/JBHI.2019.2942938","National Key R and D Program of China; National Natural Science Foundation of China; Natural Science Foundation of Beijing Municipality; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8846016","ECG classification;biomedical monitoring;convolutional neural network;deep learning","Heart beat;Electrocardiography;Heart rate variability;Deep learning;Feature extraction;Task analysis;Informatics","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Acoustic Scene Clustering Using Joint Optimization of Deep Embedding Learning and Clustering Iteration","Y. Li; M. Liu; W. Wang; Y. Zhang; Q. He","School of Electronic and Information Engineering, South China University of Technology, 26467 Guangzhou, Guangdong China (e-mail: eeyxli@scut.edu.cn); School of Electronic and Information Engineering, South China University of Technology, 26467 Guangzhou, Guangdong China (e-mail: mlliu123@163.com); School of Electronic and Information Engineering, South China University of Technology, 26467 Guangzhou, Guangdong China (e-mail: wcwang123@163.com); School of Electronic and Information Engineering, South China University of Technology, 26467 Guangzhou, Guangdong China (e-mail: yhzhang123@163.com); School of Electronic and Information Engineering, South China University of Technology, 26467 Guangzhou, Guangdong China (e-mail: qhhe123@163.com)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","Recent efforts have been made on acoustic scene classification in the audio signal processing community. In contrast, few studies have been conducted on acoustic scene clustering, which is a newly emerging problem. Acoustic scene clustering aims at merging the audio recordings of the same class of acoustic scene into a single cluster without using prior information and training classifiers. In this study, we propose a method for acoustic scene clustering that jointly optimizes the procedures of feature learning and clustering iteration. In the proposed method, the learned feature is a deep embedding that is extracted from a deep convolutional neural network (CNN), while the clustering algorithm is the agglomerative hierarchical clustering (AHC). We formulate a unified loss function for integrating and optimizing these two procedures. Various features and methods are compared. The experimental results demonstrate that the proposed method outperforms other unsupervised methods in terms of the normalized mutual information and the clustering accuracy. In addition, the deep embedding outperforms many state-of-the-art features.","","","10.1109/TMM.2019.2947199","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8867864","Acoustic scene clustering;deep embedding;agglomerative hierarchical clustering;audio content analysis","Acoustics;Audio recording;Feature extraction;Clustering algorithms;Image analysis;Classification algorithms;Optimization","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Residual Learning for Boosting the Accuracy of Hyperspectral Pansharpening","Y. Zheng; J. Li; Y. Li; K. Cao; K. Wang","State Key Laboratory of Integrated Services Networks, School of Telecommunications Engineering, Xidian University, Xi'an 710071, China.; State Key Laboratory of Integrated Services Networks, School of Telecommunications Engineering, Xidian University, Xi'an 710071, China (e-mail: jjli@xidian.edu.cn).; State Key Laboratory of Integrated Services Networks, School of Telecommunications Engineering, Xidian University, Xi'an 710071, China (e-mail: ysli@mail.xidian.edu.cn).; State Key Laboratory of Integrated Services Networks, School of Telecommunications Engineering, Xidian University, Xi'an 710071, China.; State Key Laboratory of Integrated Services Networks, School of Telecommunications Engineering, Xidian University, Xi'an 710071, China.","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","Recently, deep learning (DL) has gained impressive achievements in the field of remote sensing image fusion. However, most of the previous DL-based fusion methods are originally designed for multispectral pansharpening, which cannot be readily employed to hyperspectral pansharpening due to the much wider spectral range and lower spatial resolution of a hyperspectral image (HSI). In this letter, a novel framework based on deep residual learning is proposed for hyperspectral pansharpening. The proposed framework consists mainly of two parts. First, the initialized HSI with the enhanced spatial resolution is generated through contrast limited adaptive histogram equalization (CLAHE) and guided filter. Then, a deep residual convolutional neural network (DRCNN) is introduced to map the residuals between the initialized HSI and the reference HSI for further boosting the fusion accuracy. Experimental results demonstrate that the proposed framework can achieve superior performance compared with the existing state-of-the-art pansharpening methods, especially in terms of edge details enhancement.","","","10.1109/LGRS.2019.2945424","China Postdoctoral Science Foundation; China Postdoctoral Science Foundation; National Natural Science Foundation of China; Higher Education Discipline Innovation Project; Open Research Fund of CAS Key Laboratory of Spectral Imaging Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8874962","Contrast limited adaptive histogram equalization (CLAHE);deep residual convolutional neural network (DRCNN);guided filter;hyperspectral pansharpening.","Hyperspectral imaging;Image edge detection;Spatial resolution;Histograms;Training","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Meta-learning Framework for Learning Multi-User Preferences in QoE Optimization of DASH","L. Huo; Z. Wang; M. Xu; Y. Li; Z. Ding; H. Wang","School of Electronic and Information Engineering, Beihang University, Beijing, China.; School of Electronic and Information Engineering, Beihang University, Beijing, China.; School of Electronic and Information Engineering, Beihang University, Beijing, China.; Beijing National Research Center for Information Science and Technology, Department of Electronic Engineering, Tsinghua University, Beijing 100084, China.; School of Electrical and Electronic Engineering, The University of Manchester, Manchester, M13 9PL, UK.; School of Electronic and Information Engineering, Beihang University, Beijing, China.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Dynamic adaptive video streaming over hypertext transfer protocol (DASH) plays a key role in video transmission over the Internet. The conventional DASH adaptation approaches mainly focus on optimizing the overall quality of experience (QoE) for all client sides, neglecting the QoE diversity of different users. In this paper, we propose a meta-learning framework for multi-user preferences (MLMP) as a new DASH adaptation approach, which is able to optimize the diverse QoE of different users. Specifically, we first design a subjective experiment to analyze the difference of QoE preferences across users, in which QoE refers to the metrics of visual quality, fluctuation, and rebuffering events. Based on our findings, we formulate the QoE optimization of multi-user preferences as a multi-task deep reinforcement learning (DRL) problem. In our formulation, the QoE preference of each user is modeled in the overall QoE calculation via assigning the weights to the three QoE metrics. Then, the MLMP framework is developed to solve the proposed multi-task DRL problem, such that the preferences regarding visual quality, fluctuation, and rebuffering events can be optimized for different users in DASH adaptation. Finally, the simulation results show that the proposed approach outperforms state-of-the-art DASH adaptation approaches in satisfying the different users’ QoE preferences regarding visual quality, fluctuation, and rebuffering events.","","","10.1109/TCSVT.2019.2939282","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8823029","DASH;adaptation approaches;user preferences;meta-learning;reinforcement learning","Quality of experience;Streaming media;Optimization;Task analysis;Measurement;Adaptation models;Throughput","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Learning Kernel for Conditional Moment-Matching Discrepancy-Based Image Classification","C. Ren; P. Ge; D. Dai; H. Yan","School of Mathematics, Sun Yat-sen University, Guangzhou 510275, China (e-mail: rchuanx@mail.sysu.edu.cn).; School of Mathematics, Sun Yat-sen University, Guangzhou 510275, China.; School of Mathematics, Sun Yat-sen University, Guangzhou 510275, China.; Department of Electronic Engineering, City University of Hong Kong, Hong Kong.","IEEE Transactions on Cybernetics","","2019","PP","99","1","13","Conditional maximum mean discrepancy (CMMD) can capture the discrepancy between conditional distributions by drawing support from nonlinear kernel functions; thus, it has been successfully used for pattern classification. However, CMMD does not work well on complex distributions, especially when the kernel function fails to correctly characterize the difference between intraclass similarity and interclass similarity. In this paper, a new kernel learning method is proposed to improve the discrimination performance of CMMD. It can be operated with deep network features iteratively and thus denoted as KLN for abbreviation. The CMMD loss and an autoencoder (AE) are used to learn an injective function. By considering the compound kernel, that is, the injective function with a characteristic kernel, the effectiveness of CMMD for data category description is enhanced. KLN can simultaneously learn a more expressive kernel and label prediction distribution; thus, it can be used to improve the classification performance in both supervised and semisupervised learning scenarios. In particular, the kernel-based similarities are iteratively learned on the deep network features, and the algorithm can be implemented in an end-to-end manner. Extensive experiments are conducted on four benchmark datasets, including MNIST, SVHN, CIFAR-10, and CIFAR-100. The results indicate that KLN achieves the state-of-the-art classification performance.","","","10.1109/TCYB.2019.2916198","National Natural Science Foundation of China; Science and Technology Program of Guangzhou; Hong Kong Research Grants Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8725912","Autoencoder (AE);conditional distribution discrepancy;kernel mappings;moment-matching network;semisupervised learning;supervised learning","Kernel;Task analysis;Training;Learning systems;Prediction algorithms;Germanium;Computational modeling","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Detecting Fatigue Status of Pilots Based on Deep Learning Network Using EEG Signals","E. Q. Wu; P. Deng; X. Qu; Z. Tang; W. Zhang; L. Zhu; H. Ren; G. Zhou; R. S. F. Sheng","Key Laboratory of System Control and Information Processing, Ministry of Education, Shanghai Jiao Tong University, China, and also with Science and Technology on Avionics Integration Laboratory, China National Aeronautical Radio Electronics Research Institute, Shanghai, China.; Science and Technology on Avionics Integration Laboratory, China National Aeronautical Radio Electronics Research Institute, Shanghai, China.; Science and Technology on Avionics Integration Laboratory, China National Aeronautical Radio Electronics Research Institute, Shanghai, China.; Department of Computer Science, City University of Hong Kong, China.; State Key Laboratory of Mechanical System and Vibration, School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai 200240, China.; State Key Laboratory of Mechanical System and Vibration, School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai 200240, China.; COMAC Shanghai Aircraft Design and Research Institute (SADRI).; COMAC Shanghai Aircraft Design and Research Institute (SADRI).; COMAC Shanghai Aircraft Design and Research Institute (SADRI).","IEEE Transactions on Cognitive and Developmental Systems","","2019","PP","99","1","1","This work presents a solution for fatigue recognition through a new deep learning model that has a characteristic input of the power spectrum of an electroencephalogram (EEG) signal. Firstly, four rhythms are obtained through the designed FIR filters, and the curve areas of their power spectrum density are coupled into four fatigue indicators. Secondly, a deep sparse contractive autoencoder network is proposed to learn more local fatigue characteristics, and the recognition results of pilots mental fatigue status are given. Compared with the state-of-the-art models, the results show that our model has good learning performance in extracting local features and fatigue status detection.","","","10.1109/TCDS.2019.2963476","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8948246","Pilots fatigue;EEG signals;deep network;fatigue characteristics.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Spatio-temporal deep Q-networks for human activity localization","W. Xu; J. Yu; Z. Miao; L. Wan; Q. Ji","Institute of Information Science, Beijing Jiaotong University, and Beijing Key Laboratory of Advanced Information Science and Network Technology, China.; School of Computer and Information Technology, Beijing Jiaotong University, China.; Institute of Information Science, Beijing Jiaotong University, and Beijing Key Laboratory of Advanced Information Science and Network Technology, China.; Institute of Information Science, Beijing Jiaotong University, and Beijing Key Laboratory of Advanced Information Science and Network Technology, China.; Department of Electrical & Computer Engineering, Rensselaer Polytechnic Institute, USA.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Human activity localization aims to recognize category labels and detect the spatio-temporal locations of activities in video sequences. Existing activity localization methods suffer from three major limitations. First, the search space is too large for three-dimensional (3D) activity localization, which requires the generation of a large number of proposals. Second, contextual relations are often ignored in these target-centred methods. Third, locating each frame independently fails to capture the temporal dynamics of human activity. To address the above issues, we propose a unified spatio-temporal deep Q-network (ST-DQN), consisting of a temporal Q-network and a spatial Q-network, to learn an optimized search strategy. Specifically, the spatial Q-network is a novel two-branch sequence-to-sequence deep Q-network, called TBSS-DQN. The network makes a sequence of decisions to search the bounding box for each frame simultaneously and accounts for temporal dependencies between neighbouring frames. Additionally, TBSS-DQN incorporates both the target branch and context branch to exploit contextual relations. The experimental results on the UCF-Sports, UCF-101, ActivityNet, JHMDB and sub-JHMDB datasets demonstrate that our ST-DQN achieves promising localization performance with a very small number of proposals. The results also demonstrate that exploiting contextual information and temporal dependencies contributes to accurate detection of the spatio-temporal boundary.","","","10.1109/TCSVT.2019.2919064","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8723163","Activity localization;deep reinforcement learning;spatial context;temporal dependency;seq-to-seq model","Proposals;Reinforcement learning;Activity recognition;Three-dimensional displays;Context modeling;Electron tubes;Computational modeling","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Learning Approach for Epileptic Focus Localization","H. Daoud; M. Bayoumi","The Center for Advanced Computer Studies, University of Louisiana at Lafayette, 4365 Lafayette, Louisiana United States 70504 (e-mail: hgamalm@gmail.com); The Center for Advanced Computer Studies, University of Louisiana at Lafayette, 4365 Lafayette, Louisiana United States (e-mail: mab0778@louisiana.edu)","IEEE Transactions on Biomedical Circuits and Systems","","2019","PP","99","1","1","The task of epileptic focus localization receives great attention due to its role in an effective epileptic surgery. The clinicians highly depend on the intracranial EEG data to make a surgical decision related to epileptic subjects suffering from uncontrollable seizures. This surgery usually aims to remove the epileptogenic region which requires precise characterization of that area using the EEG recordings. In this paper, we propose two methods based on deep learning targeting accurate automatic epileptic focus localization using the non-stationary EEG recordings. Our first proposed method is based on semi-supervised learning, in which a deep convolutional autoencoder is trained and then the pre-trained encoder is used with multi-layer perceptron as a classifier. The goal is to determine the location of the EEG signal that is responsible for the epileptic activity. In the second proposed method, unsupervised learning scheme is implemented by merging deep convolutional variational autoencoder and K-means algorithm for clustering the iEEG signals into two distinct clusters based on the seizure source. The proposed methods automate and integrate the features extraction and classification processes instead of manually extracting the features as done in the previous studies. Dimensionality reduction is achieved using the autoencoder, while the important spatio-temporal features are extracted from the EEG recordings using the convolutional layers. Moreover, We implemented the inference network of the semi-supervised model on FPGA. The results of our experiments demonstrate high classification accuracy and clustering performance in localizing the epileptic focus compared with the state of the art.","","","10.1109/TBCAS.2019.2957087","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8918409","classification;clustering;convolutional autoencoder;EEG;epileptic focus localization;variational autoencoder","Electroencephalography;Feature extraction;Training;Surgery;Machine learning;Convolution;Brain modeling","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Channel-Correlation Network for Motor Imagery Decoding from Same Limb","X. Ma; S. Qiu; W. Wei; S. Wang; H. He","Research Center for Brain-Inspired Intelligence, Institute of Automation, Chinese Academy of Sciences (CASIA), Beijing 100190, China and University of Chinese Academy of Sciences (UCAS), Beijing 100049, China.; Research Center for Brain-Inspired Intelligence, Institute of Automation, Chinese Academy of Sciences (CASIA), Beijing 100190, China.; Research Center for Brain-Inspired Intelligence, Institute of Automation, Chinese Academy of Sciences (CASIA), Beijing 100190, China and University of Chinese Academy of Sciences (UCAS), Beijing 100049, China.; Research Center for Brain-Inspired Intelligence, Institute of Automation, Chinese Academy of Sciences (CASIA), Beijing 100190, China and University of Chinese Academy of Sciences (UCAS), Beijing 100049, China.; Research Center for Brain-Inspired Intelligence, Institute of Automation, Chinese Academy of Sciences (CASIA), Beijing 100190, China and Center for Excellence in Brain Science and Intelligence Technology, CAS, Beijing, China and University of Chinese Academy of Sciences (UCAS), Beijing 100049, China.","IEEE Transactions on Neural Systems and Rehabilitation Engineering","","2019","PP","99","1","1","Motor imagery (MI) is an important brain-computer interface (BCI) paradigm, which can be applied without external stimulus. Imagining different joint movements from the same limb allows intuitive control of the outer devices. However, few researches focused on this field, and the decoding accuracy limited the applications for practical use. In this study, we aim to use deep learning methods to explore the ceiling of the decoding performance of three tasks: the resting state, the MI of right hand and right elbow. To represent the brain functional relationships, the correlation matrix that consists of correlation coefficients between electrodes (channels) was calculated as features. We proposed the Channel-Correlation Network to learn the overall representation among channels for classification. Ensemble learning was applied to integrate the output of multiple Channel-Correlation Networks. Our proposed method achieved the decoding accuracy of up to 87.03% in the 3-class scenario. The results demonstrated the effectiveness of deep learning method for decoding MI of different joints from the same limb and the potential of this fine paradigm to be applied in practice.","","","10.1109/TNSRE.2019.2953121","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8896928","Channel-Correlation Network;Electroencephalography (EEG);Ensemble Learning;Fine Motor Imagery;Same Limb","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Use of a Tracer-specific Deep Artificial Neural Net to Denoise Dynamic PET Images","I. S. Klyuzhin; J. Cheng; C. Bevington; V. Sossi","Department of Medicine, University of British Columbia, Vancouver, BC, V6T 1Z3 Canada.; Department of Physics and Astronomy, University of British Columbia, Vancouver, BC, V6T 1Z4 Canada.; Department of Physics and Astronomy, University of British Columbia, Vancouver, BC, V6T 1Z4 Canada.; Department of Physics and Astronomy, University of British Columbia, Vancouver, BC, V6T 1Z4 Canada.","IEEE Transactions on Medical Imaging","","2019","PP","99","1","1","Application of kinetic modeling (KM) on a voxel level in dynamic PET images frequently suffers from high levels of noise, drastically reducing the precision of parametric image analysis. In this work we investigate the use of machine learning and artificial neural networks to denoise dynamic PET images.We train a deep denoising autoencoder (DAE) using noisy and noise-free spatiotemporal image patches, extracted from simulated images of 11Craclopride, a dopamine D2 receptor agonist. DAE-processed dynamic and corresponding parametric images (simulated and acquired) are compared to those obtained with conventional denoising techniques, including temporal and spatial Gaussian smoothing, iterative spatiotemporal smoothing/ deconvolution, and the highly-constrained backprojection processing (HYPR). The simulated (acquired) parametric image non-uniformity was 7.75% (19.49%) with temporal and 5.90% (14.50%) with spatial smoothing, 5.82% (16.21%) with smoothing/ deconvolution, 5.49% (13.38%) with HYPR, and 3.52% (11.41%) with DAE. The DAE also produced the best results in terms of the coefficient of variation of voxel values and structural similarity index. Denoising-induced bias in the regional mean binding potential was 7.8% with temporal and 26.31% with spatial smoothing, 28.61% with smoothing/deconvolution, 27.63% with HYPR, and 14.8% with DAE. When the test data did not match the training data erroneous outcomes were obtained. Our results demonstrate that a deep DAE can provide a substantial reduction in the voxel-level noise compared to the conventional spatiotemporal denoising methods, while introducing a similar or lower amount of bias. The better DAE performance comes at the cost of lower generality and requiring appropriate training data.","","","10.1109/TMI.2019.2927199","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8756077","Dynamic PET;denoising;neural network;machine learning;deep learning;kinetic modeling","Noise reduction;Training;Kinetic theory;Spatiotemporal phenomena;Positron emission tomography;Noise measurement;Image reconstruction","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Unsupervised Learning of 3D Point Clouds via Graph Topology Inference and Filtering","S. Chen; C. Duan; Y. Yang; D. Li; C. Feng; D. Tian","Mitsubishi Electric Research Laboratories (MERL), Cambridge, MA, USA.; Departments of Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, PA, USA. Emails: and.; Departments of Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, PA, USA. Emails: and.; InterDigital, Princeton, NJ, USA.:18.; New York University, New York City, NY, USA.; InterDigital, Princeton, NJ, USA.:18.","IEEE Transactions on Image Processing","","2019","PP","99","1","1","We propose a deep autoencoder with graph topology inference and filtering to achieve compact representations of unorganized 3D point clouds in an unsupervised manner. Many previous works discretize 3D points to voxels and then use lattice-based methods to process and learn 3D spatial information; however, this leads to inevitable discretization errors. In this work, we try to handle raw 3D points without such compromise. The proposed networks follow the autoencoder framework with a focus on designing the decoder. The encoder of the proposed networks adopts similar architectures as in PointNet, which is a well-acknowledged method for supervised learning of 3D point clouds. The decoder of the proposed networks involves three novel modules: the folding module, the graph-topology-inference module, and the graph-filtering module. The folding module folds a canonical 2D lattice to the underlying surface of a 3D point cloud, achieving coarse reconstruction; the graph-topology-inference module learns a graph topology to represent pairwise relationships between 3D points, pushing the latent code to preserve both coordinates and pairwise relationships of points in 3D point clouds; and the graph-filtering module couples the above two modules, refining the coarse reconstruction through a learnt graph topology to obtain the final reconstruction. The proposed decoder leverages a learnable graph topology to push the codeword to preserve representative features and further improve the unsupervised-learning performance. We further provide theoretical analyses of the proposed architecture. We provide an upper bound for the reconstruction loss and further show the superiority of graph smoothness over spatial smoothness as a prior to model 3D point clouds. In the experiments, we validate the proposed networks in three tasks, including 3D point cloud reconstruction, visualization, and transfer classification. The experimental results show that (1) the proposed networks outperform the state-of-the-art methods in various tasks, including reconstruction and transfer classification; (2) a graph topology can be inferred as auxiliary information without specific supervision on graph topology inference; (3) graph filtering refines the reconstruction, leading to better performances; and (4) designing a powerful decoder could improve the unsupervised-learning performance, just like a powerful encoder.","","","10.1109/TIP.2019.2957935","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8931245","3D point cloud;deep autoencoder;graph filtering;graph topology inference","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Learning to Branch: Accelerating Resource Allocation in Wireless Networks","M. Lee; G. Yu; Y. Li","Zhejiang University, 12377 Hangzhou, Zhejiang China (e-mail: mengyuan_lee@zju.edu.cn); Zhejiang University, 12377 Hangzhou, Zhejiang China (e-mail: yuguanding@zju.edu.cn); School of ECE, Georgia Institute of Technology, Atlanta, Georgia United States 30332-0250 (e-mail: liye@ece.gatech.edu)","IEEE Transactions on Vehicular Technology","","2019","PP","99","1","1","Resource allocation in wireless networks, such as device-to-device (D2D) communications, is usually formulated as mixed integer nonlinear programming (MINLP) problems, which are generally NP-hard and difficult to get the optimal solutions. Traditional methods to solve these MINLP problems are all based on mathematical optimization techniques, such as the branch-and-bound (B\&B) algorithm that converges slowly and has forbidding complexity for real-time implementation. Therefore, machine leaning (ML) has been used recently to address the MINLP problems in wireless communications. In this paper, we use imitation learning method to accelerate the B\&B algorithm. With invariant problem-independent features and appropriate problem-dependent feature selection for D2D communications, a good auxiliary prune policy can be learned in a supervised manner to speed up the most time-consuming branch process of the B\&B algorithm. Moreover, we develop a mixed training strategy to further reinforce the generalization ability and a deep neural network (DNN) with a novel loss function to achieve better dynamic control over optimality and computational complexity. Extensive simulation demonstrates that the proposed method can achieve good optimality and reduce computational complexity simultaneously.","","","10.1109/TVT.2019.2953724","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8901995","Machine learning;device-to-device communications;resource allocation;mixed integer nonlinear programming;imitation learning;branch-and-bound algorithm","","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"A Streaming Cloud Platform for Real-Time Video Processing on Embedded Devices","W. Zhang; H. Sun; D. Zhao; L. Xu; X. Liu; J. Zhou; H. Ning; Y. Guo; S. Yang","Department of Software Engineering, China University of Petroleum, Qingdao, Shandong China (e-mail: zhangws@upc.edu.cn); Computer Applications, China University of Petroleum Huadong - Qingdao Campus, 74591 Qingdao, Shandong China (e-mail: 1197724861@qq.com); Science, ANU Research School of Physics and Engineering, 111119 Canberra, Australian Capital Territory Australia (e-mail: 525044691@qq.com); Computer Sciecne, University of Science and Technology Beijing Dongling School of Economics and Management, 198185 Haidian, Beijing China (e-mail: 879010479@qq.com); Department of Software Engineering, China University of Petroleum, Qingdao, Shandong China (e-mail: lx@upc.edu.cn); software engineering, Oulun Yliopisto Luonnontieteellinen Tiedekunta, 101226 Oulu, Oulu Finland (e-mail: jiehan.zhou@oulu.fi); Computer and Communication, University of Science and Technology Beijing, Beijing, Beijing China 100083 (e-mail: ninghuansheng@ustb.edu.cn); Department of Software Engineering, China University of Petroleum, Qingdao, Shandong China (e-mail: 1026840588@qq.com); Department of Computer Science, Fudan University, Shanghai, ShangHai China 200433 (e-mail: suyang@fudan.edu.cn)","IEEE Transactions on Cloud Computing","","2019","PP","99","1","1","Real-time intelligent video processing on embedded devices with low power consumption can be useful for applications like drone surveillance, smart cars, and more. However, the limited resources of embedded devices is a challenging issue for effective embedded computing. Most of the existing work on this topic focuses on single device based solutions, without the use of cloud computing mechanisms for parallel processing to boost performance. In this paper, we propose a cloud platform for real-time video processing based on embedded devices. Eight NVIDIA Jetson TX1 and three Jetson TX2 GPUs are used to construct a streaming embedded cloud platform (SECP), on which Apache Storm is deployed as the cloud computing environment for deep learning algorithms (Convolutional Neural Networks - CNNs) to process video streams. Additionally, self-managing services are designed to ensure that this platform can run smoothly and stably, in the form of a metric sensor, a bottleneck detector and a scheduler. This platform is evaluated in terms of processing speed, power consumption, and network throughput by running various deep learning algorithms for object detection. The results show the proposed platform can run deep learning algorithms on embedded devices while meeting the high scalability and fault tolerance required for real-time video processing.","","","10.1109/TCC.2019.2894621","National Natural Science Foundation of China; Key Research Program of Shandong Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8624373","embedded devices;low power consumption;deep learning;video processing;convolutional neural networks","Streaming media;Cloud computing;Real-time systems;Deep learning;Storms;Fasteners;Object detection","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"An Adaptive Deep Belief Network With Sparse Restricted Boltzmann Machines","G. Wang; J. Qiao; J. Bi; Q. Jia; M. Zhou","Center for Intelligent and Networked Systems, Department of Automation, Tsinghua University, Beijing 100084, China.; Faculty of Information Technology, Beijing University of Technology, Beijing 100124, China (e-mail: junfeiq@bjut.edu.cn).; Faculty of Information Technology, Beijing University of Technology, Beijing 100124, China.; Center for Intelligent and Networked Systems, Department of Automation, Tsinghua University, Beijing 100084, China.; Department of Electrical and Computer Engineering, New Jersey Institute of Technology, Newark, NJ 07102 USA, and also with the Institute of Systems Engineering, Macao University of Science and Technology, Macao 999078, China.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","12","Deep belief network (DBN) is an efficient learning model for unknown data representation, especially nonlinear systems. However, it is extremely hard to design a satisfactory DBN with a robust structure because of traditional dense representation. In addition, backpropagation algorithm-based fine-tuning tends to yield poor performance since its ease of being trapped into local optima. In this article, we propose a novel DBN model based on adaptive sparse restricted Boltzmann machines (AS-RBM) and partial least square (PLS) regression fine-tuning, abbreviated as ARP-DBN, to obtain a more robust and accurate model than the existing ones. First, the adaptive learning step size is designed to accelerate an RBM training process, and two regularization terms are introduced into such a process to realize sparse representation. Second, initial weight derived from AS-RBM is further optimized via layer-by-layer PLS modeling starting from the output layer to input one. Third, we present the convergence and stability analysis of the proposed method. Finally, our approach is tested on Mackey-Glass time-series prediction, 2-D function approximation, and unknown system identification. Simulation results demonstrate that it has higher learning accuracy and faster learning speed. It can be used to build a more robust model than the existing ones.","","","10.1109/TNNLS.2019.2952864","Key Project of National Natural Science Foundation of China; National Natural Science Foundation of China; Major Project for New Generation Artificial Intelligence; National Science and Technology Major Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8941264","Adaptive-sparse restricted Boltzmann machine (RBM);convergence analysis;deep belief network (DBN);partial least square (PLS)-based regression fine-tuning;robust structure.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Spatial-Temporal Deep Tensor Neural Networks for Large-Scale Urban Network Speed Prediction","L. Zhou; S. Zhang; J. Yu; X. Chen","Institute of Intelligent Transportation Systems, College of Civil Engineering and Architecture, Zhejiang University, Hangzhou 310058, China.; Institute of Intelligent Transportation Systems, College of Civil Engineering and Architecture, Zhejiang University, Hangzhou 310058, China.; Institute of Intelligent Transportation Systems, College of Civil Engineering and Architecture, Zhejiang University, Hangzhou 310058, China.; Institute of Intelligent Transportation Systems, College of Civil Engineering and Architecture, Zhejiang University, Hangzhou 310058, China (e-mail: chenxiqun@zju.edu.cn).","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","12","Real-time traffic speed prediction is an essential component of intelligent transportation systems applications on large-scale urban networks, e.g., proactive traffic management, advanced information provision, and prompt incident response. The family of traffic prediction models (e.g., convolutional neural networks) based on multi-detector speed diagrams in the time-space plane has been one of the most frequently used approaches for individual roads and the entire network. However, the predefined stacking sequence of traffic detectors along the spatial dimension of the speed diagram has a significant influence on the prediction performance, which makes network-wide speed prediction more challenging. To tackle the above challenge and better capture complicated traffic dynamics, we propose a novel speed prediction approach, named spatial-temporal deep tensor neural networks (ST-DTNN), for a large-scale urban network with mixed road types. Spatial and temporal dependencies of different road segments are simultaneously taken into account to improve the network-wide prediction accuracy. A scalable deep tensor is constructed for the ST-DTNN to eliminate the potentially negative impact caused by the manually stacking sequence of speed time series collected at different locations. Multi-step ahead traffic speeds can be simultaneously predicted based on probe data for a real-world large-scale urban network with hundreds of detectors installed on freeways, highways, and major/minor arterials. The results demonstrate the capability and effectiveness of the proposed ST-DTNN approach. Compared with the benchmark models, the ST-DTNN performs higher prediction accuracy during either peak or off-peak periods within an acceptable training time and has more stable prediction performance on the spatial scale. The proposed approach can be extended to develop network-wide traffic state monitoring, optimize routing in navigation services, and support congestion mitigation.","","","10.1109/TITS.2019.2932038","National Basic Research Program of China (973 Program); Zhejiang Provincial Natural Science Foundation of China; National Natural Science Foundation of China; Young Elite Scientists Sponsorship Program by the China Association for Science and Technology CAST; Key Research and Development Program of Zhejiang; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8792396","Speed prediction;urban road network;spatial-temporal deep tensor neural networks (ST-DTNN);deep learning.","Roads;Predictive models;Stacking;Neural networks;Time series analysis;Detectors","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Knowledge-based Analysis for Mortality Prediction from CT Images","H. Guo; U. Kruger; G. Wang; M. K. Kalra; P. Yan","Biomedical Engineering, Rensselaer Polytechnic Institute, 8024 Troy, New York United States (e-mail: guoh9@rpi.edu); Biomedical engineering, Rensselaer Polytechnic Institute, 8024 Troy, New York United States (e-mail: krugeu@rpi.edu); Biomedical Engineering, Rensselaer Polytechnic Institute, Troy, New York United States (e-mail: wangg6@rpi.edu); Massachusetts Gen Hosp, Boston, Massachusetts United States (e-mail: mkalra@mgh.harvard.edu); Biomedical Engineering, Rensselaer Polytechnic Institute, 8024 Troy, New York United States 12180-3522 (e-mail: yanp2@rpi.edu)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","Low-Dose CT (LDCT) can significantly improve the accuracy of lung cancer diagnosis and thus reduce cancer deaths compared to chest X-ray. The lung cancer risk population is also at high risk of other deadly diseases, for instance, cardiovascular diseases. Therefore, predicting the all-cause mortality risks of this population is of great importance. This paper introduces a knowledge-based analytical method using deep convolutional neural network (CNN) for all-cause mortality prediction. The underlying approach combines structural image features extracted from CNNs, based on LDCT volume in different scales, and clinical knowledge obtained from quantitative measurements, to predict the mortality risk of lung cancer screening subjects. The proposed method is referred as Knowledge-based Analysis of Mortality Prediction Network (KAMP-Net). It constitutes a collaborative framework that utilizes both imaging features and anatomical information, instead of completely relying on automatic feature extraction. Our work demonstrates the feasibility of incorporating quantitative clinical measurements to assist CNNs in all-cause mortality prediction from chest LDCT images. The results of this study confirm that radiologist defined features can complement CNNs in performance improvement. The experiments demonstrate that KAMP-Net can achieve a superior performance when compared to other methods.","","","10.1109/JBHI.2019.2946066","National Heart, Lung, and Blood Institute; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8861325","Lung cancer;low-dose CT;mortality risk;machine learning and deep learning;convolutional neural network;clinical knowledge","Feature extraction;Lung;Cancer;Computed tomography;Biomedical measurement;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Completely Automated CNN Architecture Design Based on Blocks","Y. Sun; B. Xue; M. Zhang; G. G. Yen","College of Computer Science, Sichuan University, Chengdu 610065, China, and also with the School of Engineering and Computer Science, Victoria University of Wellington, Wellington 6140, New Zealand.; School of Engineering and Computer Science, Victoria University of Wellington, Wellington 6140, New Zealand.; School of Engineering and Computer Science, Victoria University of Wellington, Wellington 6140, New Zealand.; School of Electrical and Computer Engineering, Oklahoma State University, Stillwater, OK 74078 USA (e-mail: gyen@okstate.edu).","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","13","The performance of convolutional neural networks (CNNs) highly relies on their architectures. In order to design a CNN with promising performance, extensive expertise in both CNNs and the investigated problem domain is required, which is not necessarily available to every interested user. To address this problem, we propose to automatically evolve CNN architectures by using a genetic algorithm (GA) based on ResNet and DenseNet blocks. The proposed algorithm is completely automatic in designing CNN architectures. In particular, neither preprocessing before it starts nor postprocessing in terms of CNNs is needed. Furthermore, the proposed algorithm does not require users with domain knowledge on CNNs, the investigated problem, or even GAs. The proposed algorithm is evaluated on the CIFAR10 and CIFAR100 benchmark data sets against 18 state-of-the-art peer competitors. Experimental results show that the proposed algorithm outperforms the state-of-the-art CNNs hand-crafted and the CNNs designed by automatic peer competitors in terms of the classification performance and achieves a competitive classification accuracy against semiautomatic peer competitors. In addition, the proposed algorithm consumes much less computational resource than most peer competitors in finding the best CNN architectures.","","","10.1109/TNNLS.2019.2919608","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; National Natural Science Fund of China for Distinguished Young Scholar; Marsden Fund of New Zealand Government; Huawei Industry Fund; University Research Fund at the Victoria University of Wellington; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8742788","Automatic architecture design;convolutional neural networks (CNNs);evolutionary deep learning;genetic algorithms (GAs);neural networks.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Multi-Level Policy and Reward-Based Deep Reinforcement Learning Framework for Image Captioning","N. Xu; H. Zhang; A. Liu; W. Nie; Y. Su; J. Nie; Y. Zhang","Tianjin University, School of Electrical and Information Engineering, Tianjin China 300072 (e-mail: ningxu@tju.edu.cn); School of Computer Science and Engineering, Nanyang Technological University, Singapore Singapore (e-mail: hanwangzhang@ntu.edu.sg); Electronic Information Engineering, Tianjin University, 12605 Tianjin China 300072 (e-mail: anan0422@gmail.com); Tianjin University, School of Electronic Information Engineering, Tianjin China 300072 (e-mail: weizhinie@tju.edu.cn); Electronic Information Engineering, Tianjin University, Tianjin China 300072 (e-mail: ytsu@tju.edu.cn); Ocean University of China, Ocean University of China, QIngdao China (e-mail: niejie@ouc.edu.cn); School of Information Science and Technology, University of Science and Technology of China, Hefei, Anhui China 230027 (e-mail: zhyd73@ustc.edu.cn)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","Image captioning is one of the most challenging tasks in AI because it requires an understanding of both complex visuals and natural language. Because image captioning is essentially a sequential prediction task, recent advances in image captioning have used reinforcement learning (RL) to better explore the dynamics of word-by-word generation. However, the existing RL-based image captioning methods rely primarily on a single policy network and reward function–an approach that is not well matched to the multi-level (word and sentence) and multi-modal (vision and language) nature of the task. To solve this problem, we propose a novel multi-level policy and reward RL framework for image captioning that can be easily integrated with RNN-based captioning models, language metrics, or visual-semantic functions for optimization. Specifically, the proposed framework includes two modules: 1) a multi-level policy network that jointly updates the word- and sentence-level policies for word generation; and 2) a multi-level reward function that collaboratively leverages both a vision-language reward and a language-language reward to guide the policy. Furthermore, we propose a guidance term to bridge the policy and the reward for RL optimization. The extensive experiments on the MSCOCO and Flickr30k datasets and the analyses show that the proposed framework achieves competitive performances on a variety of evaluation metrics. In addition, we conduct ablation studies on multiple variants of the proposed framework and explore several representative image captioning models and metrics for the word-level policy network and the language-language reward function to evaluate the generalization ability of the proposed framework.","","","10.1109/TMM.2019.2941820","National Natural Science Foundation of China; The 2018 grant of Tianjin New Generation Artificial Intelligence Major Program; The 2019 grant of Tianjin New Generation Artificial Intelligence Major Program; The grant of Elite Scholar Program of Tianjin University; National Key Research and Development Program of China; The Open Project Program of the State Key Lab of CAD and CG Zhejiang University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8844130","Multi-Level Policy;Multi-Level Reward;Reinforcement Learning;Image Captioning","Visualization;Measurement;Task analysis;Reinforcement learning;Optimization;Adaptation models;Semantics","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Quintuple-media Joint Correlation Learning with Deep Compression and Regularization","Y. Peng; J. Qi","Institute of Computer Science and Technology, Peking University, Beijing 100871, China. Corresponding author: Yuxin Peng.; Institute of Computer Science and Technology, Peking University, Beijing 100871, China. Corresponding author: Yuxin Peng.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Multi-media data including image, video, text, audio and 3D model, has been fast emerging on the Internet. Jointly correlating the data of various media types is a challenging task. With the considerable learning ability of deep network, existing works mainly construct multi-pathway network to learn cross-media correlation, where each pathway is for one media type. However, with number of media types increasing, existing methods face the problems of high repetition and complexity, leading to overfitting and poor generalization ability, which makes adverse effect on correlation learning. For addressing the above issues, we propose Cross-media Deep Compression and Regularization (CDCR) approach for quintuple-media joint correlation learning: (1) Cross-media partial weight-sharing networks is proposed, where a part of parameters are commonly shared among multiple pathways, to exploit common characteristics across different media types for capturing intrinsic cross-media correlation. (2) We propose media-adaptive network pruning to drop connections between weakly-correlated neurons, which can emphasize media-specific characteristics adaptively. (3) Cross-media network regularization is proposed to utilize relationships among quintuple-media data, which can guarantee generalization ability and enhance intra-media and inter-media correlation. Experiments verify the effectiveness of our approach, which outperforms state-of-the-art methods on 2 very challenging datasets, including a large-scale dataset PKU XMediaNet with more than 100,000 quintuple-media instances.","","","10.1109/TCSVT.2019.2927295","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8756206","Cross-media retrieval;quintuple-media;joint correlation learning;network compression;network regularization","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Rotated Sphere Haar Wavelet and Deep Contractive Auto-Encoder Network With Fuzzy Gaussian SVM for Pilot's Pupil Center Detection","E. Q. Wu; G. Zhou; L. Zhu; C. Wei; H. Ren; R. S. F. Sheng","Key Laboratory of System Control and Information Processing, Ministry of Education, Shanghai Jiao Tong University, Shanghai 200240, China, and also with the Science and Technology on Avionics Integration Laboratory, China National Aeronautical Radio Electronics Research Institute, Shanghai 200233, China. (e-mail: edmondqwu@163.com).; Department of Avionics Systems, COMAC Shanghai Aircraft Design and Research Institute, Shanghai 201210, China.; Department of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai 200240, China.; Human Space-Flight System Engineering Division, Institute of Manned Space System Engineering, CAST, Beijing 100029, China.; Department of Automation, Shanghai Engineering Research Center of Civil Aircraft Health Monitoring, Shanghai, China.; Department of Avionics Systems, COMAC Shanghai Aircraft Design and Research Institute, Shanghai 201210, China.","IEEE Transactions on Cybernetics","","2019","PP","99","1","14","How to track the attention of the pilot is a huge challenge. We are able to capture the pupil status of the pilot and analyze their anomalies and judge the attention of the pilot. This paper proposes a new approach to solve this problem through the integration of spherical Haar wavelet transform and deep learning methods. First, considering the application limitations of Haar wavelet and other wavelets in spherical signal decomposition and reconstruction, a feature learning method based on the spherical Haar wavelet is proposed. In order to obtain the salient features of the spherical signal, a rotating spherical Haar wavelet is also proposed, which has a consistent scale in the same direction between the reconstructed image and the original image. Second, in order to find a better characteristic representation of the spherical signal, a higher contractive autoencoder (HCAE) is designed for the potential representation of the spherical Haar wavelet coefficients, which has two penalty items, respectively, from Jacobian and two order items from Taylor expansion of the point x for the contract learning of sample space. Third, in order to improve the classification performance, this paper proposes a fuzzy Gaussian support vector machine (FGSVM) as the top classification tool of the deep learning model, which can punish some Gaussian noise from the output of the deep HCAE network (DHCAEN). Finally, a DHCAEN-FGSVM classifier is proposed to identify the location of the pupil center. The experimental results of the public data set and actual data show that our model is an effective method for spherical signal detection.","","","10.1109/TCYB.2018.2886012","National Natural Science Foundation of China; Chinese Military Commission Equipment Development Department; Open Project Program of the State Key Laboratory of CAD and CG Zhejiang University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8610016","Auto-encoder (AE);fuzzy Gaussian support vector machine (FGSVM);pupil detection;rotation;sphere Haar wavelets","Wavelet transforms;Fatigue;Support vector machines;Deep learning;Image reconstruction;Aerospace electronics;Monitoring","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Recent Advances in 3D Object Detection in the Era of Deep Neural Networks: A Survey","M. M. Rahman; Y. Tan; J. Xue; K. Lu","School of Engineering Sciences, University of Chinese Academy of Sciences, No.19A Yuquan Road, Beijing 100049, China, and Department of Computer Science and Engineering, Islamic University, Kushtia, Bangladesh.; School of Engineering Sciences, University of Chinese Academy of Sciences, No.19A Yuquan Road, Beijing 100049, China.; School of Engineering Sciences, University of Chinese Academy of Sciences, No.19A Yuquan Road, Beijing 100049, China.; School of Engineering Sciences, University of Chinese Academy of Sciences, No.19A Yuquan Road, Beijing 100049, China.","IEEE Transactions on Image Processing","","2019","PP","99","1","1","With the rapid development of deep learning technology and other powerful tools, 3D object detection has made great progress and become one of the fastest growing field in computer vision. Many automated applications such as robotic navigation, autonomous driving, and virtual or augmented reality system require estimation of accurate 3D object location and detection. Under this requirement, many methods have been proposed to improve the performance of 3D object localization and detection. Despite recent efforts, 3D object detection is still a very challenging task due to occlusion, viewpoint variations, scale changes, and limited information in 3D scenes. In this paper, we present a comprehensive review of recent state-of-the-art approaches in 3D object detection technology. We start with some basic concepts, then describe some of the available datasets that are designed to facilitate the performance evaluation of 3D object detection algorithms. Next, we will review the state-of-the-art technologies in this area, highlighting their contributions, importance, and limitations as a guide for future research. Finally, we provide a quantitative comparison of the results of the state-of-the-art methods on the popular public datasets.","","","10.1109/TIP.2019.2955239","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8917824","3D object detection;deep neural networks;RGB-D data;LiDAR data;point cloud;deep learning","Three-dimensional displays;Object detection;Cameras;Sensors;Two dimensional displays;Laser radar;Task analysis","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Hierarchical Lifelong Learning by Sharing Representations and Integrating Hypothesis","T. Zhang; G. Su; C. Qing; X. Xu; B. Cai; X. Xing","School of Electronics and Information, South China University of Technology, Guangzhou 510640, China.; School of Electronics and Information, South China University of Technology, Guangzhou 510640, China.; School of Electronics and Information, South China University of Technology, Guangzhou 510640, China.; School of Electronics and Information, South China University of Technology, Guangzhou 510640, China (e-mail: xmxu@scut.edu.cn).; School of Electronics and Information, South China University of Technology, Guangzhou 510640, China.; School of Electronics and Information, South China University of Technology, Guangzhou 510640, China.","IEEE Transactions on Systems, Man, and Cybernetics: Systems","","2019","PP","99","1","11","In lifelong machine learning (LML) systems, consecutive new tasks from changing circumstances are learned and added to the system. However, sufficiently labeled data are indispensable for extracting intertask relationships before transferring knowledge in classical supervised LML systems. Inadequate labels may deteriorate the performance due to the poor initial approximation. In order to extend the typical LML system, we propose a novel hierarchical lifelong learning algorithm (HLLA) consisting of two following layers: 1) the knowledge layer consisted of shared representations and integrated knowledge basis at the bottom and 2) parameterized hypothesis functions with features at the top. Unlabeled data is leveraged in HLLA for pretraining of the shared representations. We also have considered a selective inherited updating method to deal with intertask distribution shifting. Experiments show that our HLLA method outperforms many other recent LML algorithms, especially when dealing with higher dimensional, lower correlation, and fewer labeled data problems.","","","10.1109/TSMC.2018.2884996","National Natural Science Foundation of China; Guangzhou Key Laboratory of Body Data Science; Science and Technology Program of Guangzhou of China; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8654015","Deep learning;image processing;lifelong machine learning (LML);representations learning","Task analysis;Training;Feature extraction;Boosting;Neural networks;Correlation","","","","3","","","","","","IEEE","IEEE Early Access Articles"
"Adversarial Examples: Opportunities and Challenges","J. Zhang; C. Li","College of Computer Science and Electronic Engineering, Hunan University, Changsha 410082, China, and also with the Cyberspace Security Research Center, Peng Cheng Laboratory, Shenzhen 518000, China (e-mail: zhangjiliang@hnu.edu.cn).; College of Computer Science and Electronic Engineering, Hunan University, Changsha 410082, China, and also with the Cyberspace Security Research Center, Peng Cheng Laboratory, Shenzhen 518000, China.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","16","Deep neural networks (DNNs) have shown huge superiority over humans in image recognition, speech processing, autonomous vehicles, and medical diagnosis. However, recent studies indicate that DNNs are vulnerable to adversarial examples (AEs), which are designed by attackers to fool deep learning models. Different from real examples, AEs can mislead the model to predict incorrect outputs while hardly be distinguished by human eyes, therefore threaten security-critical deep-learning applications. In recent years, the generation and defense of AEs have become a research hotspot in the field of artificial intelligence (AI) security. This article reviews the latest research progress of AEs. First, we introduce the concept, cause, characteristics, and evaluation metrics of AEs, then give a survey on the state-of-the-art AE generation methods with the discussion of advantages and disadvantages. After that, we review the existing defenses and discuss their limitations. Finally, future research opportunities and challenges on AEs are prospected.","","","10.1109/TNNLS.2019.2933524","National Natural Science Foundation of China; Key Research and Development Program of Hunan Province; Hu Xiang Youth Talent Program; Peng Cheng Laboratory Project of Guangdong Province; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8842604","Adversarial examples (AEs);artificial intelligence (AI);deep neural networks (DNNs).","Artificial intelligence;Biological neural networks;Neurons;Robots;Perturbation methods;Security;Training","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Globalized Model for Mapping Wearable Seismocardiogram Signals to Whole-Body Ballistocardiogram Signals Based on Deep Learning","S. Hersek; B. Semiz; M. M. H. Shandhi; L. Orlandic; O. T. Inan","School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, 30332 USA (e-mail: shersek3@gatech.edu); School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, 30332 USA (e-mail: bsemiz@gatech.edu); School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, 30332 USA (e-mail: mobashir.shandhi@gatech.edu); School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, 30332 USA (e-mail: lorlandic3@gatech.edu); School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, 30332 USA (e-mail: omer.inan@ece.gatech.edu)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","The ballistocardiography (BCG) signal is a measurement of the vibrations of the center of mass of the body due to the cardiac cycle and can be used for noninvasive hemodynamic monitoring. The seismocardiography (SCG) signals measure the local vibrations of the chest wall due to the cardiac cycle. While BCG is a more well known modality, it requires the use of a modified bathroom scale or a force plate and cannot be measured in a wearable setting, whereas SCG signals can be measured using wearable accelerometers placed on the sternum. In this work we explore the idea of finding a mapping between zero mean and unit $\ell_2$-norm SCG and BCG signal segments such that, the BCG signal can be acquired using wearable accelerometers (without retaining amplitude information). We use neural networks to find such a mapping and make use of the recently introduced UNet architecture. We trained our models on 26 healthy subjects and tested them on 10 subjects. Our results show that we can estimate the aforementioned segments of the BCG signal with a median Pearson correlation coefficient of 0.71 and a median absolute deviation (MAD) of 0.17. Furthermore, our model can estimate the R-I, R-J and R-K timing intervals with median absolute errors (and MAD) of 10.00 (8.90), 6.00 (5.93) and 8.00 (5.93), respectively. We show that using all three axis of the SCG accelerometer produces the best results while the head-to-foot SCG signal produces the best results when a single SCG axis is used.","","","10.1109/JBHI.2019.2931872","Pediatric Technology Center Georgia Tech and Childrens Healthcare of Atlanta; National Science Foundation; National Institute of Biomedical Imaging and Bioengineering; Marcus Foundation Inc. Atlanta GA the National Institutes of Health; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8779609","Accelerometer;cardiovascular monitoring;wearable sensors;deep learning;convolutional neural networks","Sensors;Accelerometers;Biomedical monitoring;Vibrations;Neural networks;Correlation","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Learning based Small Surface Defect Detection via Exaggerated Local Variation-based Generative Adversarial Network","J. Lian; W. Jia; M. Zareapoor; Y. Zheng; R. Luo; D. K. Jain; N. Kumar","Jinan China 250031 (e-mail: lianjianlianjian@163.com); Shandong Normal University, 47856 Jinan China 250014 (e-mail: wkjia@sdnu.edu.cn); Shanghai China 200240 (e-mail: mzarea@sjtu.edu.cn); Jinan China 250358 (e-mail: wenkudaidai@163.com); Jinan China 250353 (e-mail: lrcity@qlu.edu.cn); Chongqing China 400065 (e-mail: deepak@cqupt.edu.cn); CSE Department, Patiala, Punjab India 147004 (e-mail: neeraj.kumar@thapar.edu)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","Surface detection of small defects plays a vital role in manufacturing and has attracted broad interest. It remains challenging primarily due to the small size of the defect relative to the large surface and the rare occurrence of defects. To address this problem, we propose a novel machine vision approach for automatically identifying the tiny flaws that may appear in a single image. First, the presented defect exaggeration approach produces both the flawless image and the corresponding exaggerated version of the defect by taking the variations in the image as regularization terms. Second, an adversarial generative network (GAN) in conjunction with a convolutional neural network (CNN) is proposed to guarantee the accuracy of tiny surface defect detection by producing exaggerated defect image samples. Furthermore, the limited dataset of the training samples for defect detection is enlarged by exploiting the generative adversarial network technique with the variation exaggerated images. To evaluate the performance of our proposed method, we conduct comparison experiments between the state-of-the-art techniques with and without the proposed algorithm as well as comparison experiments between the state-of-the-art techniques and our method. The experimental results on different types of surface image samples demonstrate that the proposed method can significantly improve the performance of the state-of-the-art approaches while achieving a defect detection accuracy of 99.2%.","","","10.1109/TII.2019.2945403","National Natural Science Foundation of China; Natural Science Foundation of Shandong Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8859390","Surface defect detection;deep learning;generative adversarial network;machine vision;data analytics","Gallium nitride;Image color analysis;Generative adversarial networks;Pipelines;Informatics;Inspection;Rough surfaces","","","","","","","","","","IEEE","IEEE Early Access Articles"
"DeepReS: A Deep Learning-based Video Summarization Strategy for Resource-Constrained Industrial Surveillance Scenarios","K. Muhammad; H. Tanveer; J. Del Ser; V. Palade; V. H. C. De Albuquerque","Software, Sejong University, 35006 Gwangjin-gu, Seoul Korea (the Republic of) 143-747 (e-mail: khan.muhammad@ieee.org); Gwangjin-gu Korea (the Republic of) 05000 (e-mail: tanveerkhattak143@gmail.com); TECNALIA, 203273 Derio Spain 48160 (e-mail: javier.delser@tecnalia.com); Coventry University Faculty of Engineering and Computing, 231310 Coventry, West Midlands United Kingdom of Great Britain and Northern Ireland CV1 5FB. (e-mail: ab5839@coventry.ac.uk); Computer Science, Universidade de Fortaleza, 28128 Fortaleza Brazil 60811-905 (e-mail: victor.albuquerque@unifor.br)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","The exponential growth in production of video contents in industries reaps an extreme need of Video Summarization (VS) techniques for optimal storage and preservation of key information for detailed analysis. Compared to other domains, industrial videos are more challenging to process due to their diverse nature with complex events, which make its online processing a difficult task. In this paper, we introduce an online system for intelligent video capturing, coarse and fine redundancy removal, and summary generation. First, we capture video data through resource-constrained device in Industrial Internet of Things (IIoT) network equipped with vision sensor and apply coarse redundancy removal through comparison of low-level features. Second, we transmit the resultant frames to cloud for detailed analysis, where sequential features are extracted for selection of candidate keyframes. Finally, we refine the candidate keyframes to choose the frames with maximum information as part of the summary. The key contributions include coarse and fine refining of video data implemented over resource restricted devices and presentation of important data in the form of summary. Experiments over publicly available datasets prove 0.3-unit increase in the F1 score compared to state-of-the-art with reduced time complexity. Furthermore, we provide convincing results on our newly created dataset in industrial environment, which will be publicly available for research community along with the labelled ground truth.","","","10.1109/TII.2019.2960536","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8936419","Big Data;Computer Vision;Deep Learning;Video Summarization;IIoT;Resource-Constrained Devices","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Automatic Analysis of Facial Expressions Based on Deep Covariance Trajectories","N. Otberdout; A. Kacem; M. Daoudi; L. Ballihi; S. Berretti","LRIT, CNRST URAC 29, Faculty of Sciences, Mohammed V University of Rabat, Rabat 10000, Morocco (e-mail: naima.otberdout@um5s.net.ma).; IMT Lille-Douai, 59500 Douai, France. He is now with the SnT - Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg, 4365 Luxembourg City, Luxembourg.; IMT Lille-Douai, CNRS, UMR 9189 CRIStAL, University of Lille, 59000 Lille, France.; LRIT, CNRST URAC 29, Faculty of Sciences, Mohammed V University of Rabat, Rabat 10000, Morocco.; Department of Information Engineering, University of Florence, 50121 Florence, Italy.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","14","In this article, we propose a new approach for facial expression recognition (FER) using deep covariance descriptors. The solution is based on the idea of encoding local and global deep convolutional neural network (DCNN) features extracted from still images, in compact local and global covariance descriptors. The space geometry of the covariance matrices is that of symmetric positive definite (SPD) matrices. By conducting the classification of static facial expressions using a support vector machine (SVM) with a valid Gaussian kernel on the SPD manifold, we show that deep covariance descriptors are more effective than the standard classification with fully connected layers and softmax. Besides, we propose a completely new and original solution to model the temporal dynamic of facial expressions as deep trajectories on the SPD manifold. As an extension of the classification pipeline of covariance descriptors, we apply SVM with valid positive definite kernels derived from global alignment for deep covariance trajectories classification. By performing extensive experiments on the Oulu-CASIA, CK+, static facial expression in the wild (SFEW), and acted facial expressions in the wild (AFEW) data sets, we show that both the proposed static and dynamic approaches achieve the state-of-the-art performance for FER outperforming many recent approaches.","","","10.1109/TNNLS.2019.2947244","Scholarship of Excellence from the National Center for Scientific and Technical Research CNRST of Morocco; CAMPUS FRANCE PHC TOUBKAL 2019 French-Morocco Bilateral Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8901420","Convolutional neural networks;covariance matrix;deep trajectory;facial expression recognition (FER);symmetric positive definite (SPD) manifold.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Learning a Fixed-Length Fingerprint Representation","J. J. Engelsma; K. Cao; A. K. Jain","Computer Science, Michigan State University College of Engineering, 143262 East Lansing, Michigan United States 48824-1226 (e-mail: engelsm7@msu.edu); Computer Science and Engineering, Michigan State University, East Lansing, Michigan United States (e-mail: kaicao@cse.msu.edu); Computer Science & Engineering, Michigan State University, East Lansing, Michigan United States 48824-1226 (e-mail: jain@cse.msu.edu)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","We present DeepPrint, a deep network, which learns to extract fixed-length fingerprint representations of only 200 bytes. DeepPrint incorporates fingerprint domain knowledge, including alignment and minutiae detection, into the deep network architecture to maximize the discriminative power of its representation. The compact, DeepPrint representation has several advantages over the prevailing variable length minutiae representation which (i) requires computationally expensive graph matching techniques, (ii) is difficult to secure using strong encryption schemes (e.g. homomorphic encryption), and (iii) has low discriminative power in poor quality fingerprints where minutiae extraction is unreliable. We benchmark DeepPrint against two top performing COTS SDKs (Verifinger and Innovatrics) from the NIST and FVC evaluations. Coupled with a re-ranking scheme, the DeepPrint rank-1 search accuracy on the NIST SD4 dataset against a gallery of 1.1 million fingerprints is comparable to the top COTS matcher, but it is significantly faster (DeepPrint: 98.80% in 0.3 seconds vs. COTS A: 98.85% in 27 seconds). To the best of our knowledge, the DeepPrint representation is the most compact and discriminative fixed-length fingerprint representation reported in the academic literature.","","","10.1109/TPAMI.2019.2961349","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8937828","Fingerprint Matching;Minutiae Representation;Fixed-Length Representation;Representation Learning;Deep Networks;Large-scale Search;Domain Knowledge in Deep Networks","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Toward Compact ConvNets via Structure-Sparsity Regularized Filter Pruning","S. Lin; R. Ji; Y. Li; C. Deng; X. Li","Fujian Key Laboratory of Sensing and Computing for Smart City, School of Information Science and Engineering, Xiamen University, Xiamen 361005, China.; Fujian Key Laboratory of Sensing and Computing for Smart City, School of Information Science and Engineering, Xiamen University, Xiamen 361005, China, and also with the Peng Cheng Laboratory, Shenzhen 518055, China (e-mail: rrji@xmu.edu.cn).; Fujian Key Laboratory of Sensing and Computing for Smart City, School of Information Science and Engineering, Xiamen University, Xiamen 361005, China.; School of Electronic Engineering, Xidian University, Xi'an 710071, China.; School of Computer Science, Northwestern Polytechnical University, Xi'an 710072, China, and also with the Center for OPTical IMagery Analysis and Learning (OPTIMAL), Northwestern Polytechnical University, Xi'an 710072, China.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","15","The success of convolutional neural networks (CNNs) in computer vision applications has been accompanied by a significant increase of computation and memory costs, which prohibits their usage on resource-limited environments, such as mobile systems or embedded devices. To this end, the research of CNN compression has recently become emerging. In this paper, we propose a novel filter pruning scheme, termed structured sparsity regularization (SSR), to simultaneously speed up the computation and reduce the memory overhead of CNNs, which can be well supported by various off-the-shelf deep learning libraries. Concretely, the proposed scheme incorporates two different regularizers of structured sparsity into the original objective function of filter pruning, which fully coordinates the global output and local pruning operations to adaptively prune filters. We further propose an alternative updating with Lagrange multipliers (AULM) scheme to efficiently solve its optimization. AULM follows the principle of alternating direction method of multipliers (ADMM) and alternates between promoting the structured sparsity of CNNs and optimizing the recognition loss, which leads to a very efficient solver (2.5x to the most recent work that directly solves the group sparsity-based regularization). Moreover, by imposing the structured sparsity, the online inference is extremely memory-light since the number of filters and the output feature maps are simultaneously reduced. The proposed scheme has been deployed to a variety of state-of-the-art CNN structures, including LeNet, AlexNet, VGGNet, ResNet, and GoogLeNet, over different data sets. Quantitative results demonstrate that the proposed scheme achieves superior performance over the state-of-the-art methods. We further demonstrate the proposed compression scheme for the task of transfer learning, including domain adaptation and object detection, which also show exciting performance gains over the state-of-the-art filter pruning methods.","","","10.1109/TNNLS.2019.2906563","National Key R and D Program of China; Natural Science Foundation of China; Postdoctoral Innovative Talent Support Program; China Postdoctoral Science Foundation; Natural Science Foundation of Fujian Province China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8689357","Convolutional neural networks (CNNs);CNN acceleration;CNN compression;structured sparsity.","","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"MDMaaS: Medical-assisted Diagnosis Model as a Service with Artificial Intelligence and Trust","K. Guo; S. Ren; M. Z. A. Bhuiyan; T. Li; D. Liu; Z. Liang; X. Chen","Central South University, 12570 Changsha, Hunan China 410083 (e-mail: guokehua@csu.edu.cn); Central South University, 12570 Changsha China 410083 (e-mail: rensheng@csu.edu.cn); Department of Computer and Information Sciences, Fordham University, 5923 Bronx, New York United States 10458 (e-mail: zakirulalam@gmail.com); Central South University, 12570 Changsha China 410083 (e-mail: liting0218@csu.edu.cn); Central South University, 12570 Changsha China 410083 (e-mail: 164611143@csu.edu.cn); Central South University, 12570 Changsha China 410083 (e-mail: zhliang@csu.edu.cn); Central South University, 12570 Changsha, Hunan China 410083 (e-mail: chenxiangck@126.com)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","Artificial intelligence has achieved great success in the field of medical-assisted diagnosis, and deep learning technology plays a very important role in medical image recognition. However, it usually takes medical institutions extra time, energy and cost to obtain a credible and efficient deep learning model. In this paper, we propose a novel medical-assisted diagnosis model as a service (MDMaaS). Medical institutions can obtain and use medical-assisted diagnosis models from service providers directly; model training and model application in machine learning are assigned to a service provider and a consumer, respectively. We designed a model acquisition method based on conventional samples and small samples for MDMaaS providers, and we also developed a trustworthy model-based recommendation method for MDMaaS consumers, which would help medical institutions obtain reliable medical-assisted diagnosis models quickly and efficiently. Based on the MDMaaS, extensive experiments were performed to verify the effectiveness of the proposed method.","","","10.1109/TII.2019.2937547","National Natural Science Foundation of China; National Science Foundation of Hunan Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8815887","medical-assisted diagnosis;deep learning;variational auto-encoder;trust recommendation","Medical diagnostic imaging;Computational modeling;Deep learning;Cloud computing;Training;Medical services","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Learning for Classification of the Chemical Composition of Particle Defects on Semiconductor Wafers","J. O’Leary; K. Sawlani; A. Mesbah","Department of Chemical and Biomolecular Engineering, University of California, Berkeley, CA 94720 USA.; Lam Research Corporation, 4650 Cushing Pkway, Fremont, CA 94538 USA.; Department of Chemical and Biomolecular Engineering, University of California, Berkeley, CA 94720 USA.","IEEE Transactions on Semiconductor Manufacturing","","2019","PP","99","1","1","Manual classification of particle defects on semiconductor wafers is labor-intensive, which leads to slow solutions and longer learning curves on product failures while being prone to human error. This work explores the promise of deep learning for the classification of the chemical composition of these defects to reduce analysis time and inconsistencies due to human error, which in turn can result in systematic root cause analysis for sources of semiconductor defects. We investigate a deep convolutional neural network (CNN) for defect classification based on a combination of scanning electron microscopy (SEM) images and energy-dispersive x-ray (EDX) spectroscopy data. SEM images of sections of semiconductor wafers that contain particle defects are fed into a CNN in which the defects’ EDX spectroscopy data is merged directly with the CNN’s fully connected layer. The proposed CNN classifies the chemical composition of industrial semiconductor wafer particle defects with an industrially pragmatic accuracy. We also demonstrate that merging spectral data with the CNN’s fully connected layer significantly improves classification performance over CNNs that only take either SEM image data or EDX spectral data as an input. The impact of training data collection and augmentation on CNN performance is explored and the promise of transfer learning for improving training speed and testing accuracy is investigated.","","","10.1109/TSM.2019.2963656","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8948013","Convolutional Neural Networks;Defect Classification;Semiconductor Manufacturing;Particle Defects;Chemical Composition;Transfer Learning;Data Augmentation.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Fast and precise positioning in PCBs using deep neural network regression","D. Tsai; Y. Chou","NA; NA","IEEE Transactions on Instrumentation and Measurement","","2019","PP","99","1","1","Precision positioning is a very important task for automatic assembly and inspection in the manufacturing process. The conventional image processing for image alignment has been relied on template matching, which is computationally intensive for objects in arbitrary locations and orientations. In this paper, we propose deep neural network regressors for fast and accurate image alignment. They are especially applied to positioning of Printed Circuit Boards (PCBs). The simple Multilayer Perceptron (MLP), the Convolutional Neural Network (CNN), and the CNN models incorporated with Support Vector Regression (SVR) are proposed and evaluated for the PCB positioning task. The proposed deep neural networks require only one single reference sample with a manually marked template window. All training images and the ground-true geometric parameters are automatically generated for the model training. The effect of illumination changes and the strategies to cope with lighting variations are analyzed and proposed for robust positioning. Experimental results indicate the proposed regressors can achieve a subpixel accuracy in translation and yield a rotation error less than 1° with 1-millisecond evaluation time for PCB positioning.","","","10.1109/TIM.2019.2957866","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8930039","Deep learning;Convolutional neural network;Positioning;Vision-based measurement;Printed circuit boards","Computational modeling;Inspection;Neural networks;Feature extraction;Machine learning;Training;Image registration","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Retinal Image Segmentation with Regularization Under Geometric Priors","V. Cherukuri; V. K. B. G; R. Bala; V. Monga","Dept. of Electrical Engineering, The Pennsylvania State University, University Park, USA and Palo Alto Research Center, Palo Alto, USA.; Palo Alto Research Center, Palo Alto, USA; Palo Alto Research Center, Palo Alto, USA; Dept. of Electrical Engineering, The Pennsylvania State University, University Park, USA.","IEEE Transactions on Image Processing","","2019","PP","99","1","1","Vessel segmentation of retinal images is a key diagnostic capability in ophthalmology. This problem faces several challenges including low contrast, variable vessel size and thickness, and presence of interfering pathology such as micro-aneurysms and hemorrhages. Early approaches addressing this problem employed hand-crafted filters to capture vessel structures, accompanied by morphological post-processing. More recently, deep learning techniques have been employed with significantly enhanced segmentation accuracy. We propose a novel domain enriched deep network that consists of two components: 1) a representation network that learns geometric features specific to retinal images, and 2) a custom designed computationally efficient residual task network that utilizes the features obtained from the representation layer to perform pixel-level segmentation. The representation and task networks are jointly learned for any given training set. To obtain physically meaningful and practically effective representation filters, we propose two new constraints that are inspired by expected prior structure on these filters: 1) orientation constraint that promotes geometric diversity of curvilinear features, and 2) a data adaptive noise regularizer that penalizes false positives. Multi-scale extensions are developed to enable accurate detection of thin vessels. Experiments performed on three challenging benchmark databases under a variety of training scenarios show that the proposed prior guided deep network outperforms state of the art alternatives as measured by common evaluation metrics, while being more economical in network size and inference time.","","","10.1109/TIP.2019.2946078","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8868109","","Image segmentation;Task analysis;Retinal vessels;Deep learning;Training;Feature extraction","","","","","","","","","","IEEE","IEEE Early Access Articles"
"GraphInception: Convolutional Neural Networks for Collective Classification in Heterogeneous Information Networks","Y. Xiong; Y. Zhang; X. Kong; H. Chen; Y. Zhu","Computer Science, Fudan University, Shanghai, Shanghai China (e-mail: yunx@fudan.edu.cn); School of Computer Science, Fudan University, 12478 Shanghai, Shanghai China (e-mail: yizhouzhang14@fudan.edu.cn); Department of Computer Science, WPI, Worcester, Massachusetts United States (e-mail: xkong@wpi.edu); School of Computer Science, Fudan University, 12478 Shanghai, Shanghai China (e-mail: jjj96178@163.com); School of Computer Science, Fudan University, Shanghai, Shanghai China (e-mail: yyzhu@fudan.edu.cn)","IEEE Transactions on Knowledge and Data Engineering","","2019","PP","99","1","1","Collective classification has attracted considerable attention, where the labels within a group of instances are correlated and should be inferred collectively. Conventional approaches on collective classification mainly focus on exploiting simple relational features. However, many applications involve complex dependencies among the instances, which are obscure/hidden in the networks. To capture these dependencies, we need to go beyond simple relational features and extract deep dependencies between the instances. In this paper, we study the problem of deep collective classification in Heterogeneous Information Networks(HINs). Different from conventional autocorrelations, which are given explicitly by the links in the network, complex autocorrelations are obscure/hidden in HINs, and should be inferred from existing links in a hierarchical order. This problem is highly challenging due to multiple types of dependencies among the nodes and complexity of the relational features. We proposed a deep convolutional collective classification method, called GraphInception, to learn the deep relational features in HINs. And we presented two versions of the models with different inference styles. The proposed methods can automatically generate a hierarchy of relational features with different complexities. Extensive experiments on real-world networks demonstrate that our approach can improve the collective classification performance by considering deep relational features in HINs.","","","10.1109/TKDE.2019.2947458","National Science Foundation; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8869937","Collective Classification;Graph Convolution;Heterogeneous Information Networks;Graph Mining;Deep Learning","Convolution;Complexity theory;Correlation;Deep learning;Feature extraction;Task analysis;Training","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Survey of Optimization Methods From a Machine Learning Perspective","S. Sun; Z. Cao; H. Zhu; J. Zhao","School of Computer Science and Technology, East China Normal University, Shanghai 200062, China.; School of Computer Science and Technology, East China Normal University, Shanghai 200062, China.; School of Computer Science and Technology, East China Normal University, Shanghai 200062, China.; School of Computer Science and Technology, East China Normal University, Shanghai 200062, China (e-mail: jzhao@cs.ecnu.edu.cn).","IEEE Transactions on Cybernetics","","2019","PP","99","1","14","Machine learning develops rapidly, which has made many theoretical breakthroughs and is widely applied in various fields. Optimization, as an important part of machine learning, has attracted much attention of researchers. With the exponential growth of data amount and the increase of model complexity, optimization methods in machine learning face more and more challenges. A lot of work on solving optimization problems or improving optimization methods in machine learning has been proposed successively. The systematic retrospect and summary of the optimization methods from the perspective of machine learning are of great significance, which can offer guidance for both developments of optimization and machine learning research. In this article, we first describe the optimization problems in machine learning. Then, we introduce the principles and progresses of commonly used optimization methods. Finally, we explore and give some challenges and open problems for the optimization in machine learning.","","","10.1109/TCYB.2019.2950779","NSFC; Shanghai Sailing Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8903465","Approximate Bayesian inference;deep neural network (DNN);machine learning;optimization method;reinforcement learning (RL)","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"The Structure Transfer Machine Theory and Applications","B. Zhang; W. Yang; Z. Wang; L. Zhuo; J. Han; X. Zhen","Beihang University, Beijing, China and Shenzhen Academy of Aerospace Technology, Shenzhen 100083, China.; School of Automation, Southeast University, Nanjing 210096, China.; Beihang University, Beijing, China.; Beihang University, Beijing, China.; Department of Computer Science and Digital Technologies at Northumbria University, Newcastle, UK. Correspondence.; Beihang University, Beijing, China.","IEEE Transactions on Image Processing","","2019","PP","99","1","1","Representation learning is a fundamental but challenging problem, especially when the distribution of data is unknown. In this paper, we propose a new representation learning method, named Structure Transfer Machine (STM), which enables feature learning process to converge at the representation expectation in a probabilistic way. We theoretically show that such an expected value of the representation (mean) is achievable if the manifold structure can be transferred from the data space to the feature space. The resulting structure regularization term, named manifold loss, is incorporated into the loss function of the typical deep learning pipeline. The STM architecture is constructed to enforce the learned deep representation to satisfy the intrinsic manifold structure from the data, which results in robust features that suit various application scenarios, such as digit recognition, image classification and object tracking. Compared with state-of-the-art CNN architectures, we achieve better results on several commonly used public benchmarks.","","","10.1109/TIP.2019.2954178","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8911371","Transfer learning;convolutional neural networks;manifold loss;learning theory","Manifolds;Deep learning;Training;Probabilistic logic;Object tracking;Task analysis","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Prediction of FMN Binding Sites in Electron Transport Chains based on 2-D CNN and PSSM Profiles","N. Le; B. P. Nguyen","School of Humanities, Nanyang Technological University, 54761 Singapore, Singapore Singapore (e-mail: khanhle@ntu.edu.sg); School of Mathematics and Statistics, Victoria University of Wellington, 8491 Wellington, Wellington New Zealand 6140 (e-mail: b.nguyen@vuw.ac.nz)","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2019","PP","99","1","1","Flavin mono-nucleotides (FMNs) are cofactors that hold responsibility for carrying and transferring electrons in the electron transport chain stage of cellular respiration. Without being facilitated by FMNs, energy production is stagnant due to the interruption in most of the cellular processes. Investigation on FMN's functions, therefore, can gain holistic understanding about human diseases and molecular information on drug targets. We proposed a deep learning model using a two-dimensional convolutional neural network and position specific scoring matrices that could identify FMN interacting residues with the sensitivity of 83.7%, specificity of 99.2%, accuracy of 98.2%, and Matthews correlation coefficients of 0.85 for an independent dataset containing 141 FMN binding sites and 1,920 non-FMN binding sites. The proposed method outperformed other previous studies using similar evaluation metrics. Our positive outcome can also promote the utilization of deep learning in dealing with various problems in bioinformatics and computational biology.","","","10.1109/TCBB.2019.2932416","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8784173","FMN binding site;electron transport chains;position specific scoring matrix;convolutional neural networks;deep learning","Proteins;Deep learning;Neural networks;Bioinformatics;Microsoft Windows;Computer architecture;Feature extraction","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Image-to-Video Adaptation and Fusion Networks for Action Recognition","Y. Liu; Z. Lu; J. Li; T. Yang; C. Yao","School of Data and Computer Science, Sun Yat-Sen University, Guangzhou 510006, China, and also with the School of Telecommunications Engineering, Xidian University, Xi’an 710071, China.; School of Telecommunications Engineering, Xidian University, Xi’an 710071, China.; School of Telecommunications Engineering, Xidian University, Xi’an 710071, China.; School of Computer Science, Northwestern Polytechnical University, Xi’an 710072, China.; School of Automation, Northwestern Polytechnical University, Xi’an 710072, China.","IEEE Transactions on Image Processing","","2019","PP","99","1","1","Existing deep learning methods for action recognition in videos require a large number of labeled videos for training, which is labor-intensive and time-consuming. For the same action, the knowledge learned from different media types, e.g., videos and images, may be related and complementary. However, due to the domain shifts and heterogeneous feature representations between videos and images, the performance of classifiers trained on images may be dramatically degraded when directly deployed to videos. In this paper, we propose a novel method, named Deep Image-to-Video Adaptation and Fusion Networks (DIVAFN), to enhance action recognition in videos by transferring knowledge from images using video keyframes as a bridge. The DIVAFN is a unified deep learning model, which integrates domain-invariant representations learning and cross-modal feature fusion into a unified optimization framework. Specifically, we design an efficient cross-modal similarities metric to reduce the modality shift among images, keyframes and videos. Then, we adopt an autoencoder architecture, whose hidden layer is constrained to be the semantic representations of the action class names. In this way, when the autoencoder is adopted to project the learned features from different domains to the same space, more compact, informative and discriminative representations can be obtained. Finally, the concatenation of the learned semantic feature representations from these three autoencoders are used to train the classifier for action recognition in videos. Comprehensive experiments on four real-world datasets show that our method outperforms some state-of-the-art domain adaptation and action recognition methods.","","","10.1109/TIP.2019.2957930","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8931264","Action recognition;adaptation;deep learning;fusion","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"DeepSTD: Mining Spatio-Temporal Disturbances of Multiple Context Factors for Citywide Traffic Flow Prediction","C. Zheng; X. Fan; C. Wen; L. Chen; C. Wang; J. Li","Fujian Key Laboratory of Sensing and Computing for Smart Cities, School of Informatics, Digital Fujian Institute of Urban Traffic Big Data Research, Xiamen University, Xiamen 361005, China.; Fujian Key Laboratory of Sensing and Computing for Smart Cities, School of Informatics, Digital Fujian Institute of Urban Traffic Big Data Research, Xiamen University, Xiamen 361005, China (e-mail: fanxiaoliang@xmu.edu.cn).; Fujian Key Laboratory of Sensing and Computing for Smart Cities, School of Informatics, Digital Fujian Institute of Urban Traffic Big Data Research, Xiamen University, Xiamen 361005, China.; Fujian Key Laboratory of Sensing and Computing for Smart Cities, School of Informatics, Digital Fujian Institute of Urban Traffic Big Data Research, Xiamen University, Xiamen 361005, China.; Fujian Key Laboratory of Sensing and Computing for Smart Cities, School of Informatics, Digital Fujian Institute of Urban Traffic Big Data Research, Xiamen University, Xiamen 361005, China.; Fujian Key Laboratory of Sensing and Computing for Smart Cities, School of Informatics, Digital Fujian Institute of Urban Traffic Big Data Research, Xiamen University, Xiamen 361005, China, and also with the Department of Geography and Environmental Management, Department of Systems Design Engineering, University of Waterloo, Waterloo, ON N2L 3G1, Canada (e-mail: junli@xmu.edu.cn).","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","12","Deep learning techniques have been widely applied to traffic flow prediction, considering underlying routine patterns, and multiple context factors (e.g., time and weather). However, the complex spatio-temporal dependencies between inherent traffic patterns and multiple disturbances have not been fully addressed. In this paper, we propose a two-phase end-to-end deep learning framework, namely DeepSTD to uncover the spatio-temporal disturbances (STD) to predict the citywide traffic flow. In the STD Modeling phase, we propose an STD modeling method to model both the different regional disturbances caused by various region functions and the spatio-temporal propagating effects. In the Prediction phase, we eliminate the STD from the historical traffic flow to enhance the leaning of inherent traffic patterns and combine the STD at the prediction time interval to consider the future disturbances. The experimental results on two real-world datasets demonstrate that DeepSTD outperforms the state-of-the-art methods.","","","10.1109/TITS.2019.2932785","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8793226","Traffic flow prediction;spatio-temporal disturbances;deep learning;intelligent transportation systems.","Neural networks;Meteorology;Predictive models;Deep learning;Urban areas;Intelligent transportation systems;Three-dimensional displays","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Spatial Pyramid-Enhanced NetVLAD With Weighted Triplet Loss for Place Recognition","J. Yu; C. Zhu; J. Zhang; Q. Huang; D. Tao","School of Computer Science, Hangzhou Dianzi University, Hangzhou 310018, China.; School of Computer Science, Hangzhou Dianzi University, Hangzhou 310018, China.; School of Science and Technology, Zhejiang International Studies University, Hangzhou 310012, China (e-mail: jeyzhang@outlook.com).; School of Computer and Control Engineering, University of Chinese Academy of Sciences, Beijing 101408, China.; UBTECH Sydney Artificial Intelligence Centre, The University of Sydney, Darlington, NSW 2008, Australia, and also with the School of Computer Science, Faculty of Engineering and Information Technologies, The University of Sydney, Darlington, NSW 2008, Australia.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","14","We propose an end-to-end place recognition model based on a novel deep neural network. First, we propose to exploit the spatial pyramid structure of the images to enhance the vector of locally aggregated descriptors (VLAD) such that the enhanced VLAD features can reflect the structural information of the images. To encode this feature extraction into the deep learning method, we build a spatial pyramid-enhanced VLAD (SPE-VLAD) layer. Next, we impose weight constraints on the terms of the traditional triplet loss (T-loss) function such that the weighted T-loss (WT-loss) function avoids the suboptimal convergence of the learning process. The loss function can work well under weakly supervised scenarios in that it determines the semantically positive and negative samples of each query through not only the GPS tags but also the Euclidean distance between the image representations. The SPE-VLAD layer and the WT-loss layer are integrated with the VGG-16 network or ResNet-18 network to form a novel end-to-end deep neural network that can be easily trained via the standard backpropagation method. We conduct experiments on three benchmark data sets, and the results demonstrate that the proposed model defeats the state-of-the-art deep learning approaches applied to place recognition.","","","10.1109/TNNLS.2019.2908982","National Natural Science Foundation of China; Zhejiang Provincial Natural Science Foundation of China; Australian Research Council Projects; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8700608","Place recognition;spatial pyramid pooling;triplet loss (T-loss);vector of locally aggregated descriptors (VLAD).","Feature extraction;Global Positioning System;Image recognition;Training;Deep learning;Vocabulary;Optimization","","","","7","","","","","","IEEE","IEEE Early Access Articles"
"Siamese Dilated Inception Hashing With Intra-Group Correlation Enhancement for Image Retrieval","X. Lu; Y. Chen; X. Li","Key Laboratory of Spectral Imaging Technology CAS, Xi'an Institute of Optics and Precision Mechanics, Chinese Academy of Sciences, Xi'an 710119, China (e-mail: luxq666666@gmail.com).; Key Laboratory of Spectral Imaging Technology CAS, Xi'an Institute of Optics and Precision Mechanics, Chinese Academy of Sciences, Xi'an 710119, China, and also with the University of Chinese Academy of Sciences, Beijing 100049, China.; School of Computer Science and Center for OPTical IMagery Analysis and Learning (OPTIMAL), Northwestern Polytechnical University, Xi'an 710072, China.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","15","For large-scale image retrieval, hashing has been extensively explored in approximate nearest neighbor search methods due to its low storage and high computational efficiency. With the development of deep learning, deep hashing methods have made great progress in image retrieval. Most existing deep hashing methods cannot fully consider the intra-group correlation of hash codes, which leads to the correlation decrease problem of similar hash codes and ultimately affects the retrieval results. In this article, we propose an end-to-end siamese dilated inception hashing (SDIH) method that takes full advantage of multi-scale contextual information and category-level semantics to enhance the intra-group correlation of hash codes for hash codes learning. First, a novel siamese inception dilated network architecture is presented to generate hash codes with the intra-group correlation enhancement by exploiting multi-scale contextual information and category-level semantics simultaneously. Second, we propose a new regularized term, which can force the continuous values to approximate discrete values in hash codes learning and eventually reduces the discrepancy between the Hamming distance and the Euclidean distance. Finally, experimental results in five public data sets demonstrate that SDIH can outperform other state-of-the-art hashing algorithms.","","","10.1109/TNNLS.2019.2935118","National Natural Science Foundation of China; Key Research Program of Frontier Sciences Chinese Academy of Sciences CAS; Young Top notch Talent Program of Chinese Academy of Sciences; National Key R and D Program of China; CAS Light of West China Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8833507","Category-level semantics;deep hashing;image retrieval;multi-scale contextual information.","Correlation;Hash functions;Semantics;Training;Approximation algorithms;Convolution;Image retrieval","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Learning Based Joint Resource Scheduling Algorithms for Hybrid MEC Networks","F. Jiang; K. Wang; L. Dong; C. Pan; W. Xu; K. Yang","Hunan Provincial Key Laboratory of Intelligent Computing and Language Information Processing, Hunan Normal University, Changsha, China.; department of Computer and Information Sciences, Northumbria University, UK.; Key Laboratory of Hunan Province for New Retail Virtual Reality Technology, Hunan University of Technology and Business, Changsha, China.; School of Electronic Engineering and Computer Science, Queen Mary University of London, London, E1 4NS, UK.; NCRL, Southeast University, Nanjing, China.; School of Computer Technology and Engineering, Changchun Institute of Technology, Changchun, China and also with the School of Computer Sciences and Electrical Engineering, University of Essex, CO4 3SQ, Colchester, UK.","IEEE Internet of Things Journal","","2019","PP","99","1","1","In this paper, we consider a hybrid mobile edge computing (H-MEC) platform, which includes ground stations (GSs), ground vehicles (GVs) and unmanned aerial vehicle (UAVs), all with mobile edge cloud installed to enable user equipments (UEs) or Internet of thing (IoT) devices with intensive computing tasks to offload. Our objective is to obtain an online offloading algorithm to minimize the energy consumption of all the UEs, by jointly optimizing the positions of GVs and UAVs, user association and resource allocation in real-time, while considering the dynamic environment. To this end, we propose a hybrid deep learning based online offloading (H2O) framework where a large-scale path-loss fuzzy c-means (LSFCM) algorithm is first proposed and used to predict the optimal positions of GVs and UAVs. Secondly, a fuzzy membership matrix U-based particle swarm optimization (U-PSO) algorithm is applied to solve the mixed integer nonlinear programming (MINLP) problems and generate the sample datasets for the deep neural network (DNN) where the fuzzy membership matrix can capture the small-scale fading effects and the information of mutual interference. Thirdly, a DNN with the scheduling layer is introduced to provide user association and computing resource allocation under the practical latency requirement of the tasks and limited available computing resource of H-MEC. In addition, different from traditional DNN predictor, we only input one UE’s information to the DNN at one time, which will be suitable for the scenarios where the number of UE is varying and avoid the curse of dimensionality in DNN.","","","10.1109/JIOT.2019.2954503","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8907406","Mobile edge computing;resource allocation;UAV;fuzzy c-means;particle swarm optimization;deep neural network.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Exploring Deep Learning Models for Overhead View Multiple Object Detection","I. Ahmed; S. Din; G. Jeon; F. Piccialli","Center of excellence in Information Technology, Institute Of Management Sciences,Pakistan.; School of Computer Science and Engineering, Kyungpook National University, Daegu, Korea.; Department of Embedded Systems Engineering, Incheon National University, Incheon, Korea.; University of Naples, Federico II, Department of Electrical Engineering and Information Technologies, Italy.","IEEE Internet of Things Journal","","2019","PP","99","1","1","IoT (Internet of Things), with smart sensors, collects and generates big data streams for wide range of applications. One of the important applications in this regard is video analytics which includes object detection. It has been considered as an important research area particularly after the development of Deep Neural Networks. We demonstrate the applications, effectiveness, and efciency of convolutional neural network algorithms i.e. Faster-RCNN and Mask-RCNN to facilitate video analytics in IoT domain, for overhead view multiple object detection and segmentation. We used Faster-RCNN and Mask-RCNN models trained on frontal view data set. To evaluate the performance of both algorithms, we used newly recorded overhead view data set containing images of different objects having variation in field of view, background, illumination condition, poses, scales, sizes, angles, height, aspect ratio, and camera resolutions. Although from the overhead view appearance of an object is significantly different as compared to a frontal view, even then experimental results show the potential of deep learning models by achieving promising results. For Faster-RCNN, we achieved TPR (True Positive Rate) of 94% with FPR (False Positive Rate) of 0.4% for overhead view person images, while for other objects the maximum obtained TPR is 92%. The Mask-RCNN model produced TPR of 93% with FPR of 0.5% for person images and maximum TPR of 92% for other objects. Furthermore, the detailed discussion is made on output results which highlights challenges and possible future directions.","","","10.1109/JIOT.2019.2951365","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8891768","Deep Neural Networks;Object Detection;Overhead View;Faster-RCNN;Mask-RCNN.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Patent Value Analysis Using Deep Learning Models—The Case of IoT Technology Mining for the Manufacturing Industry","A. J. C. Trappey; C. V. Trappey; U. H. Govindarajan; J. J. H. Sun","Department of Industrial Engineering and Engineering Management, National Tsing Hua University, Hsinchu 30013, Taiwan (e-mail: trappey@ie.nthu.edu.tw).; Department of Management Science, National Chiao Tung University, Hsinchu 30010, Taiwan (e-mail: trappey@faculty.nctu.edu.tw).; Sino US Global Logistics Institute, Antai College of Economics and Management, Shanghai Jiao Tong University, Shanghai 200030, China (e-mail: hareesh.pillai@sjtu.edu.cn).; Department of Industrial Engineering and Engineering Management, National Tsing Hua University, Hsinchu 30013, Taiwan (e-mail: t34988@gmail.com).","IEEE Transactions on Engineering Management","","2019","PP","99","1","13","The R&D output and global commercialization of intellectual properties (IPs), especially patents filed in many countries, have increased dramatically over the past decade. The overwhelming growth in research and IP activities has led to a major challenge to understand and forecast technology development insights and trends. Evidence-based data analytics is essential for technology mining. The assessment of patent values is a critical aspect of technology mining, which remains a highly subjective task performed by domain experts. As businesses become globalized, subjectivity in underlying assessments of large volumes of patent documents leads to overpriced or undervalued IP sales or licensing that exposes stakeholders to legal and financial risks. Thus, the development of intelligent methods for patent valuation requires new research emphasis. This article applies a deep learning analytical method for automatic and intelligent patent value estimation. Principal component analysis (PCA) is used to identify significant patent value indicators from the given patent dataset. Then, deep neural networks (DNN) for value prediction are modeled and trained using the training set. A detailed case study of 6466 manufacturing Internet of Things (IoT) patents is analyzed to demonstrate the improved results of building PCA-preprocessed DNN models to perform patent valuations. Finally, selected higher value IoT patents owned by leading Taiwan assignees are identified and analyzed to verify the technological competitive intelligence.","","","10.1109/TEM.2019.2957842","Ministry of Science and Technology, Taiwan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8941278","Business intelligence;deep neural network (DNN);dynamic indicator selection;Internet of Things (IoT);patent valuation","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Frame Prediction for Video Coding","H. Choi; I. V. Bajić","School of Engineering Science, Simon Fraser University, BC, V5A 1S6, Canada.; School of Engineering Science, Simon Fraser University, BC, V5A 1S6, Canada.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","We propose a novel frame prediction method using a deep neural network (DNN), with the goal of improving video coding efficiency. The proposed DNN makes use of decoded frames, at both encoder and decoder, to predict textures of the current coding block. Unlike conventional inter-prediction, the proposed method does not require any motion information to be transferred between the encoder and the decoder. Still, both uni-directional and bi-directional prediction are possible using the proposed DNN, which is enabled by the use of the temporal index channel, in addition to color channels. In this study, we developed a jointly trained DNN for both uniand bi-directional prediction, as well as separate networks for uni-and bi-directional prediction, and compared the efficacy of both approaches. The proposed DNNs were compared with the conventional motion-compensated prediction in the latest video coding standard, HEVC, in terms of BD-Bitrate. The experiments show that the proposed joint DNN (for both uniand bi-directional prediction) reduces the luminance bitrate by about 4.4%, 2.4%, and 2.3% in the Low delay P, Low delay, and Random access configurations, respectively. In addition, using the separately trained DNNs brings further bit savings of about 0.3%–0.5%.","","","10.1109/TCSVT.2019.2924657","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8744618","Video compression;frame prediction;texture prediction;deep neural network;deep learning","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"PEMFC residual life prediction using sparse autoencoder-based deep neural network","J. Liu; Q. Li; Y. Han; G. Zhang; X. Meng; J. Yu; W. Chen","School of Electrical Engineering, Southwest Jiaotong University, Chengdu 611756, China.; School of Electrical Engineering, Southwest Jiaotong University, Chengdu 611756, China.; School of Electrical Engineering, Southwest Jiaotong University, Chengdu 611756, China.; School of Electrical Engineering, Southwest Jiaotong University, Chengdu 611756, China.; School of Electrical Engineering, Southwest Jiaotong University, Chengdu 611756, China.; School of Electrical Engineering, Southwest Jiaotong University, Chengdu 611756, China.; School of Electrical Engineering, Southwest Jiaotong University, Chengdu 611756, China.","IEEE Transactions on Transportation Electrification","","2019","PP","99","1","1","In the cause of working out the challenge of remaining life prediction (RUL) of proton exchange membrane fuel cell (PEMFC) under dynamic operating conditions, this paper proposes a PEMFC RUL forecast technique based-on sparse autoencoder (SAE) and deep neural network (DNN). The method extracts the data set from the original experimental data at intervals periods of one hour to realize datum reconstruction. The Gaussian weighted moving average filter is used to smooth noisy data (voltage and current). The smoothed filtered power output signal of the stack is extracted as an aging indicator. The SAE is used to extract the prediction features automatically, and the DNN is applied to realize the RUL prediction. The proposed method is experimentally verified using 127369 experimental data. The effectiveness of the novel method is verified by three different training sets and test set configurations. The experimental results reveal that the novel approach has the best prediction effectiveness when the training set length is set to 500 hours. At this point, the prediction accuracy can reach 99.68%. The mean absolute error (MAE), mean square error (MSE), and root mean square error (RMSE) are minimum values, which are 0.2035, 0.1121, and 0.3348, respectively. The superiority and effectiveness of the proposed approach are further validated by comparison with K-nearest neighbor and support vector regression machine. The proposed approach can be appropriate for the prediction of the RUL of PEMFC under dynamic conditions.","","","10.1109/TTE.2019.2946065","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8867923","Deep neural network;proton exchange membrane fuel cell;feature extraction;residual service life prediction;deep learning;sparse autoencoder","Aging;Feature extraction;Predictive models;Fuel cells;Load modeling;Prediction algorithms;Neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"End-to-end Active Object Tracking and Its Real-world Deployment via Reinforcement Learning","W. Luo; P. Sun; F. Zhong; W. Liu; T. Zhang; Y. Wang","Computer Vision Center, Tencent AI Lab, Shenzhen, Guangdong China (e-mail: whluo.china@gmail.com); Reinforcement Learning Center, Tencent AI Lab, Shenzhen, Guangdong China (e-mail: pengsun000@gmail.com); Computer Science Department, Peking University, Beijing, Beijing China (e-mail: zfw@pku.edu.cn); Electrical Engineering, Columbia University, New York, New York United States 10027 (e-mail: wl2223@columbia.edu); Tencent AI Lab, Tencent AI Lab, Shenzhen, Guangdong China (e-mail: tongzhang@tongzhang-ml.org); Computer Science Department, Peking University, Beijing, Beijing China (e-mail: Yizhou.Wang@pku.edu.cn)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","We study active object tracking, where a tracker takes visual observations (i.e., frame sequences) as inputs and produces the corresponding camera control signals as outputs (e.g., move forward, turn left, etc.). Conventional methods tackle tracking and camera control tasks separately, and the resulting system is difficult to tune jointly. Such an approach also requires significant human efforts for image labeling and expensive trial-and-error system tuning in real-world. To address these issues, we propose, in this paper, an end-to-end solution via deep reinforcement learning. A ConvNet-LSTM function approximator is adopted for the direct frame-to-action prediction. We further propose environment augmentation techniques and a customized reward function which are crucial for successful training. The tracker trained in simulators (ViZDoom, Unreal Engine) demonstrates good generalization behaviors in the case of unseen object moving paths, unseen object appearances, unseen backgrounds, and distracting objects. The system is robust and can restore tracking after occasional lost of the target being tracked. We also find that the tracking ability, obtained solely from simulators, can potentially transfer to real-world scenarios. We demonstrate successful examples of such transfer, via experiments over the VOT dataset and the deployment of a real-world robot using the proposed active tracker trained in simulation.","","","10.1109/TPAMI.2019.2899570","Ministry of Science and Technology of the Peoples Republic of China; National Natural Science Foundation of China; Tencent AI Lab; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8642452","Active Object Tracking;Reinforcement Learning;Environment Augmentation","Object tracking;Cameras;Target tracking;Reinforcement learning;Robot vision systems","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Volumetric Isosurface Rendering with Deep Learning-Based Super-Resolution","S. Weiss; M. Chu; N. Thuerey; R. Westermann","Computer Science, Technical University of Munich, 9184 Munchen, Bavaria Germany 80333 (e-mail: sebastian.weiss@in.tum.de); I 15, Technische Universitat Munchen Fakultat fur Informatik, 163258 Garching, Bavaria Germany 85748 (e-mail: mengyu.chu@tum.de); ScanlineVFX, ScanlineVFX, Munich, Bavaria Germany (e-mail: nils.thuerey@tum.de); Informatik 15 (Computer Graphik & Visualisierung), Technische Universität München, Garching bei München, Bavaria Germany 85748 (e-mail: westermann@tum.de)","IEEE Transactions on Visualization and Computer Graphics","","2019","PP","99","1","1","Rendering an accurate image of an isosurface in a volumetric field typically requires large numbers of data samples. Reducing this number lies at the core of research in volume rendering. With the advent of deep learning networks, a number of architectures have been proposed recently to infer missing samples in multi-dimensional fields, for applications such as image super-resolution. In this paper, we investigate the use of such architectures for learning the upscaling of a low-resolution sampling of an isosurface to a higher resolution, with reconstruction of spatial detail and shading. We introduce a fully convolutional neural network, to learn a latent representation generating smooth, edge-aware depth and normal fields as well as ambient occlusions from a low-resolution depth and normal field. By adding a frame-to-frame motion loss into the learning stage, upscaling can consider temporal variations and achieves improved frame-to-frame coherence. We assess the quality of inferred results and compare it to bi-linear and -cubic upscaling. We do this for isosurfaces which were never seen during training, and investigate the improvements when the network can train on the same or similar isosurfaces. We discuss remote visualization and foveated rendering as potential applications.","","","10.1109/TVCG.2019.2956697","ERC Starting Grant realFlow; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8918030","Machine Learning;Extraction of Surfaces (Isosurfaces, Material Boundaries);Volume Rendering","Isosurfaces;Image reconstruction;Spatial resolution;Signal resolution;Rendering (computer graphics);Training","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Cycle-IR: Deep Cyclic Image Retargeting","W. Tan; B. Yan; C. Lin; X. Niu","School of Computer Science, Fudan University, 12478 Shanghai, Shanghai China (e-mail: 14110240025@fudan.edu.cn); School of Computer Science, Fudan University, 12478 Shanghai China 200433 (e-mail: boyan6@gmail.com); School of Computer Science, Fudan University, 12478 Shanghai, Shanghai China (e-mail: cmlin17@fudan.edu.cn); School of Computer Science, Fudan University, 12478 Shanghai, Shanghai China (e-mail: 17210240176@fudan.edu.cn)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","Supervised deep learning techniques have achieved great success in various fields due to getting rid of the limitation of handcrafted representations. However, most previous image retargeting algorithms still employ fixed design principles such as using gradient map or handcrafted features to compute saliency map, which inevitably restricts its generality. Deep learning techniques may help to address this issue, but the challenging problem is that we need to build a large-scale image retargeting dataset for the training of deep retargeting models. However, building such a dataset requires huge human efforts. In this paper, we propose a novel deep cyclic image retargeting approach, called Cycle-IR, to firstly implement image retargeting with a single deep model, without relying on any explicit user annotations. Our idea is built on the reverse mapping from the retargeted images to the given images. If the retargeted image has serious distortion or excessive loss of important visual information, the reverse mapping is unlikely to restore the input image well. We constrain this forward-reverse consistency by introducing a cyclic perception coherence loss. In addition, we propose a simple yet effective image retargeting network (IRNet) to implement the image retargeting process. Our IRNet contains a spatial and channel attention layer, which is able to discriminate visually important regions of input images effectively, especially in cluttered images. Given arbitrary sizes of input images and desired aspect ratios, our Cycle-IR can produce visually pleasing target images directly. Extensive experiments on the standard RetargetMe dataset show the superiority of our Cycle-IR. Code is available at https://github.com/mintanwei/Cycle-IR.","","","10.1109/TMM.2019.2959925","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8943352","image retargeting;deep learning;cycle consistency","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Self-Supervised Correspondence in Visuomotor Policy Learning","P. Florence; L. Manuelli; R. Tedrake","CSAIL, MIT, Cambridge, Massachusetts United States of America 02139 (e-mail: peteflo@mit.edu); Electrical Engineering and Computer Science, Massachusetts Institute of Technology, Cambridge, MA United States of America 02139 (e-mail: manuelli@mit.edu); Electrical Engineering and Computer Science, Massachusetts Institute of Technology, Cambridge, MA United States of America 02139 (e-mail: russt@mit.edu)","IEEE Robotics and Automation Letters","","2019","PP","99","1","1","In this paper we explore using self-supervised correspondence for improving the generalization performance and sample efficiency of visuomotor policy learning. Prior work has primarily used approaches such as autoencoding, pose-based losses, and end-to-end policy optimization in order to train the visual portion of visuomotor policies. We instead propose an approach using self-supervised dense visual correspondence training, and show this enables visuomotor policy learning with surprisingly high generalization performance with modest amounts of data: using imitation learning, we demonstrate extensive hardware validation on challenging manipulation tasks with as few as 50 demonstrations. Our learned policies can generalize across classes of objects, react to deformable object configurations, and manipulate textureless symmetrical objects in a variety of backgrounds, all with closed-loop, real-time vision-based policies. Simulated imitation learning experiments suggest that correspondence training offers sample complexity and generalization benefits compared to autoencoding and end-to-end training.","","","10.1109/LRA.2019.2956365","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8917583","Visual Learning;Deep Learning in Robotics and Automation;Perception for Grasping andManipulation","Visualization;Training;Task analysis;Robots;Hardware;Complexity theory;Feature extraction","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Object Detection from Scratch with Deep Supervision","Z. Shen; Z. Liu; J. Li; Y. Jiang; Y. Chen; X. Xue","Department of Electrical and Computer Engineering, CMU, 6612 Pittsburgh, Pennsylvania United States (e-mail: zhiqiangshen0214@gmail.com); EECS, University of California Berkeley, 1438 Berkeley, California United States (e-mail: zhuangl@berkeley.edu); Intel Corporation, Intel China Research Center, Beijing, Beijing China (e-mail: jianguo.li@intel.com); School of Computer Science, Fudan University, Shanghai, Shanghai China (e-mail: ygj@fudan.edu.cn); Intel China Research Center, Intel Corporation, Beijing, Beijing China (e-mail: yurong.chen@intel.com); School of Computer Science, Fudan University, Shanghai, Shanghai China (e-mail: xyxue@fudan.edu.cn)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","We propose Deeply Supervised Object Detectors (DSOD), an object detection framework that can be trained from scratch. Recent advances in object detection heavily depend on the off-the-shelf models pre-trained on large-scale classification datasets like ImageNet and OpenImage. However, one problem is that adopting pre-trained models from classification to detection task may incur learning bias due to the different objective function and diverse distributions of object categories. Techniques like fine-tuning on detection task could alleviate this issue to some extent but are still not fundamental. Furthermore, transferring these pre-trained models cross discrepant domains will be more difficult (e.g., from RGB to depth images). Thus, a better solution to handle these critical problems is to train object detectors from scratch, which motivates our proposed method. In DSOD, we contribute a set of design principles for learning object detectors from scratch. One of the key principles is the deep supervision, enabled by layer-wise dense connections in both backbone networks and prediction layers, plays a critical role in learning good detectors from scratch. We evaluate our method on PASCAL VOC 2007, 2012 and COCO datasets. DSOD achieves consistently better results than the state-of-the-art methods with much more compact models.","","","10.1109/TPAMI.2019.2922181","Science and Technology Commission of Shanghai Municipality; NSF China; Shanghai Municipal Science and Technology Major Projects; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8734700","Object Detection;Deeply Supervised Networks;Learning from Scratch;Densely Connected Layers","Object detection;Detectors;Task analysis;Training;Computational modeling;Linear programming;Data models","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Fuzzy Deep Model Based on Fuzzy Restricted Boltzmann Machines for High-dimensional Data Classification","S. Feng; C. L. P. Chen; C. Zhang","School of Applied Mathematics, Beijing Normal University - Zhuhai Campus, 162664 Zhuhai China 519085 (e-mail: fengshuang@bnuz.edu.cn); Dept of Computer and Information Science, University of Macau, Macau China 99999 (e-mail: philip.chen@ieee.org); School of Mathematics and Computer Science, Fuzhou University, 12423 Fuzhou China 350002 (e-mail: zhangcy@fzu.edu.cn)","IEEE Transactions on Fuzzy Systems","","2019","PP","99","1","1","We establish a fuzzy deep model called the Fuzzy Deep Belief Net (FDBN) based on Fuzzy Restricted Boltzmann Machines (FRBMs) due to their excellent generative and discriminative properties. The learning procedure of a Fuzzy DBN is divided into a pre-training phase and a subsequent fine-tuning phase. In the pre-training phase, a group of FRBMs is trained in a greedy layer-wise way: the first FRBM is trained by original samples, and the average values of the left and right probabilities produced by its hidden units are treated as the training data for subsequent FRBM. The resulting Fuzzy DBN is either a generative or a discriminative model depending on the choice of training a generative or a discriminative type of FRBM on top. Then, a hybrid learning approach is proposed to fine-tune this novel fuzzy deep model: the well pre-trained fuzzy parameters are first defuzzified, and the Fuzzy DBN with defuzzified parameters is fine-tuned by the wake-sleep or SGD algorithm. This hybrid strategy not only avoids learning an intractable fuzzy neural network, but also greatly improves the classification capability of Fuzzy DBN. The experimental results on MNIST, NORB and 15 Scene databases indicate that the Fuzzy DBN with the hybrid learning approach can handle high-dimensional raw images directly. It inherits the fine nature of FRBM and outperforms some state-of-the-art discriminative models in classification accuracy. Moreover, it shows better capability of robustness than DBN when encountering noisy data.","","","10.1109/TFUZZ.2019.2902111","Fundo para o Desenvolvimento das Ciencias e da Tecnologia; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8653841","Fuzzy deep model;FRBM;hybrid learning;classification","Data models;Training;Training data;Fuzzy neural networks;Databases;Neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Rough-Wavelet Feature Space, Deep Autoencoder, and Hyperspectral Image Classification","S. K. Meher","Systems Science and Informatics Unit (SSIU), Indian Statistical Institute, Bangalore Centre, Bengaluru 560059, India (e-mail: saroj.meher@isibang.ac.in).","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","Prime objective of this letter is to select the most relevant features from the original set and perform two steps of feature extraction operations on those selected set, for the classification of hyperspectral remote sensing (HSRS) images. Neighborhood rough sets (NRSs)-based method is used for feature selection because of its excellent neighboring information capturing ability. On these selected features, two steps of extraction operations are performed using the stationary wavelet transform (WT) and stacked deep autoencoder (SDAE). Stationary WT extracts the features by exploiting the spectral-spatial information and stacked DAE extracts through representative learning of input information. The wavelet features and the original input spectral features are cascaded to feed as input to the stacks DAE for feature extraction and classification tasks. The proposed classification model with these operational steps possesses the ability to capture more informative features with improved spectral-spatial information that are highly beneficial for the classification of complex data sets, like HSRS images. Simulation results with two HSRS images justified the efficacy of the proposed model compared to other similar methods in terms of different performance measurement indexes.","","","10.1109/LGRS.2019.2923540","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8758889","Deep autoencoder (DAE);land use/covers classification;remote sensing (RS) image;rough sets;wavelet transform (WT)","Feature extraction;Rough sets;Wavelet transforms;Task analysis;Principal component analysis;Hyperspectral imaging","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Scene Images Diversity Improvement Generative Adversarial Network for Remote Sensing Image Scene Classification","X. Pan; J. Zhao; J. Xu","School of Computer Technology and Engineering, Changchun Institute of Technology, Changchun 130012, China (e-mail: panxinpc@163.com).; School of Computer Technology and Engineering, Changchun Institute of Technology, Changchun 130012, China.; Key Laboratory of Changbai Mountain Historical Culture and VR Technology Reconfiguration, Changchun Institute of Technology, Changchun 130012, China.","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","To achieve good remote sensing image scene classification, deep learning models usually require a large number of samples in the training stage. Unfortunately, collecting a large number of training scene images usually involves large acquisition and processing costs. In contrast, after training a generative adversarial network (GAN), scene samples can subsequently be generated automatically by the generator at a low cost. Then, the generated images can be added to the training set. A model with better classification ability will be obtained when these samples include more diverse scene structures and essential features than the original real images. In this letter, we propose the scene images diversity improvement GAN (diversity-GAN). Diversity-GAN has two important advantages. 1) The training process is designed in a progressive manner: the GAN's generator and discriminator progress from coarse- to fine-resolution scene images. This characteristic can guarantee the diversity of generated samples. In particular, it guarantees the diversity of the structure of the generated scene images. 2) The training progress is controllable: by introducing control parameters, diversity-GAN can directly determine the scene image resolution on which the training process should focus. This characteristic allows diversity-GAN to achieve scene image structure diversity at the coarse-resolution training stage with a few iterations. In the experiments, the UC-Merced and AID data sets are introduced. The results show that the samples generated by diversity-GAN can effectively improve the diversity of the sample set, and these generated samples can grant convolutional neural networks (CNNs) better classification ability in the training stage.","","","10.1109/LGRS.2019.2953192","National Natural Science Foundation of China; Foundation of Jilin Provincial Science and Technology Department; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8915710","Deep learning;diversity improvement;generative adversarial network (GAN);sample generation;scene classification.","Training;Gallium nitride;Switches;Generative adversarial networks;Remote sensing;Generators;Machine learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Leader-based Multi-Scale Attention Deep Architecture for Person Re-identification","X. Qian; Y. Fu; T. Xiang; Y. Jiang; X. Xue","Computer Science, Fudan University, 12478 Shanghai, Shanghai China 200433 (e-mail: xuelinq92@gmail.com); School of Data Science, Fudan University, 12478 Shanghai, Shanghai China (e-mail: yanweifu@fudan.edu.cn); the School of Electric and Electronic Engineering, University of Surrey, 3660 Guildford, Surrey United Kingdom of Great Britain and Northern Ireland (e-mail: t.xiang@qmul.ac.uk); School of Computer Science, Fudan University, 12478 Shanghai, Shanghai China (e-mail: ygj@fudan.edu.cn); School of Computer Science, Fudan University, 12478 Shanghai, Shanghai China (e-mail: xyxue@fudan.edu.cn)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Person Re-identification (re-id) aims to match people across non-overlapping camera views in a public space. It is a challenging problem because many people captured in surveillance videos often wear similar clothes. Consequently, the differences in their appearance are typically subtle and only detectable at the right locations and scales. In this paper, a deep re-id network is proposed consisting of two novel components: a multi-scale deep learning layer and a leader-based attention learning layer. With these components, our model is able to learn deep discriminative feature representations at different scales and automatically determine the optimal weightings for each scale when combining them. The importance of different spatial locations for extracting discriminative features is also learned explicitly via our leader-based attention module. Extensive experiments are carried out to demonstrate that the proposed model outperforms the state-of-the-art on a number of benchmarks, and has a better generalization ability under a domain generalization setting.","","","10.1109/TPAMI.2019.2928294","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8762210","Person re-identification;multi-scale deep learning;self-attention;domain generalization","Feature extraction;Cameras;Task analysis;Computer architecture;Computational modeling;Adaptation models;Clothing","","","","","","","","","","IEEE","IEEE Early Access Articles"
"The Next Generation Heterogeneous Satellite Communication Networks: Integration of Resource Management and Deep Reinforcement Learning","B. Deng; C. Jiang; H. Yao; S. Guo; S. Zhao","NA; NA; NA; NA; NA","IEEE Wireless Communications","","2019","PP","99","1","7","This article proposes an innovative resource management framework for the next generation heterogeneous satellite networks (HSNs), which can achieve cooperation between independent satellite systems and maximizing resource utilization. The key points of the proposed design lie in the architecture that supports the intercommunication between different satellite systems, and the SDN/NFV-based management offering the matching between resources and services. Based on the framework, we then apply deep reinforcement learning (DRL) into the system due to its strong ability in optimal matching. The two problems of multiobjective reinforcement learning and multiagent reinforcement learning are studied to adapt the development of the HSN. The combination of the DRL and resource allocation achieves integrated resource management across different satellite systems and achieves resource allocation in the HSN which can be implemented more flexibly and efficiently.","","","10.1109/MWC.001.1900178","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8910638","","Satellites;Feature extraction;Computer architecture;Reinforcement learning;Protocols;Resource virtualization","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Optimizing Throughput Performance in Distributed MIMO Wi-Fi Networks Using Deep Reinforcement Learning","N. N. Krishnan; E. Torkildson; N. B. Mandayam; D. Raychaudhuri; E. Rantala; K. Doppler","Wireless Information Network Laboratory (WINLAB), Department of Electrical and Computer Engineering, Rutgers University, North Brunswick, NJ, USA.; Nokia Bell Labs, Sunnyvale, CA, USA.; Wireless Information Network Laboratory (WINLAB), Department of Electrical and Computer Engineering, Rutgers University, North Brunswick, NJ, USA.; Wireless Information Network Laboratory (WINLAB), Department of Electrical and Computer Engineering, Rutgers University, North Brunswick, NJ, USA.; Nokia Bell Labs, Sunnyvale, CA, USA.; Nokia Bell Labs, Sunnyvale, CA, USA.","IEEE Transactions on Cognitive Communications and Networking","","2019","PP","99","1","1","This paper explores the feasibility of leveraging deep reinforcement learning (DRL) to enable dynamic resource management in Wi-Fi networks implementing distributed multi-user MIMO (D-MIMO). D-MIMO is a technique by which a set of wireless access points are synchronized and grouped together to jointly serve multiple users simultaneously. This paper addresses two dynamic resource management problems germane to D-MIMO Wi-Fi networks: (i) channel assignment of D-MIMO groups, and (ii) deciding how to cluster access points to form D-MIMO groups, in order to maximize user throughput performance. These problems are known to be NP-Hard and only heuristic solutions exist in literature. We construct a DRL framework through which a learning agent interacts with a D-MIMO Wi-Fi network, learns about the network environment, and successfully converges to policies which address the aforementioned problems. Through extensive simulations and on-line training based on D-MIMO Wi-Fi networks, this paper demonstrates the efficacy of DRL agents in achieving an improvement of 20% in user throughput performance compared to heuristic solutions, particularly when network conditions are dynamic. This work also showcases the effectiveness of DRL agents in meeting multiple network objectives simultaneously, for instance, maximizing throughput of users as well as fairness of throughput among them.","","","10.1109/TCCN.2019.2942917","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8846066","Wireless LAN;MIMO systems;Artificial intelligence.","Wireless fidelity;Throughput;Channel allocation;MIMO communication;Reinforcement learning;Dynamic scheduling;Training","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Relative Afferent Pupillary Defect Screening through Transfer Learning","D. Temel; M. J. Mathew; G. AlRegib; Y. M. Khalifa","ECE, Georgia Institute of Technology College of Engineering, 115724 Atlanta, Georgia United States 30332-0250 (e-mail: cantemel@gatech.edu); ECE, Georgia Institute of Technology College of Engineering, 115724 Atlanta, Georgia United States (e-mail: mmathew31@gatech.edu); ECE, Georgia Institute of Technology College of Engineering, 115724 Atlanta, Georgia United States (e-mail: alregib@gatech.edu); Emory Eye Center, 43897 Atlanta, Georgia United States (e-mail: yousuf.khalifa@emoryhealthcare.org)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","Abnormalities in pupillary light reflex can indicate optic nerve disorders that may lead to permanent visual loss if not diagnosed in an early stage. In this study, we focus on relative afferent pupillary defect (RAPD), which is based on the difference between the reactions of the eyes when they are exposed to light stimuli. Incumbent RAPD assessment methods are based on subjective practices that can lead to unreliable measurements. To eliminate subjectivity and obtain reliable measurements, we introduce an automated framework to detect RAPD. For validation, we conducted a clinical study with lab-on-a-headset, which can perform automated light reflex test. In addition to benchmarking handcrafted algorithms, we proposed a transfer learning-based approach that transformed a deep learning-based generic object recognition algorithm into a pupil detector. Based on the conducted experiments, proposed algorithm RAPDNet can achieve a sensitivity and a specificity of 90.6% over 64 test cases in a balanced set, which corresponds to an AUC of 0.929 in ROC analysis. According to our benchmark with three handcrafted algorithms and nine performance metrics, RAPDNet outperforms all other algorithms in every performance category.","","","10.1109/JBHI.2019.2933773","Georgia Research Alliance; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8790783","Pupillary light reflex video dataset;relative afferent pupillary defect (RAPD);pupil detection;deep learning;transfer learning","Benchmark testing;Visualization;Detection algorithms;Informatics;Target tracking;Indexes;Metadata","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Neural Architectures for Highly Imbalanced Data in Bioinformatics","L. A. Bugnon; C. Yones; D. H. Milone; G. Stegmayer","Research Institute for Signals, Systems and Computational Intelligence [sinc(i)], National Scientific and Technical Research Council (CONICET), Universidad Nacional del Litoral (UNL), Santa Fe 3000, Argentina.; Research Institute for Signals, Systems and Computational Intelligence [sinc(i)], National Scientific and Technical Research Council (CONICET), Universidad Nacional del Litoral (UNL), Santa Fe 3000, Argentina.; Research Institute for Signals, Systems and Computational Intelligence [sinc(i)], National Scientific and Technical Research Council (CONICET), Universidad Nacional del Litoral (UNL), Santa Fe 3000, Argentina.; Research Institute for Signals, Systems and Computational Intelligence [sinc(i)], National Scientific and Technical Research Council (CONICET), Universidad Nacional del Litoral (UNL), Santa Fe 3000, Argentina (e-mail: gstegmayer@sinc.unl.edu.ar).","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","11","In the postgenome era, many problems in bioinformatics have arisen due to the generation of large amounts of imbalanced data. In particular, the computational classification of precursor microRNA (pre-miRNA) involves a high imbalance in the classes. For this task, a classifier is trained to identify RNA sequences having the highest chance of being miRNA precursors. The big issue is that well-known pre-miRNAs are usually just a few in comparison to the hundreds of thousands of candidate sequences in a genome, which results in highly imbalanced data. This imbalance has a strong influence on most standard classifiers and, if not properly addressed, the classifier is not able to work properly in a real-life scenario. This work provides a comparative assessment of recent deep neural architectures for dealing with the large imbalanced data issue in the classification of pre-miRNAs. We present and analyze recent architectures in a benchmark framework with genomes of animals and plants, with increasing imbalance ratios up to 1:2000. We also propose a new graphical way for comparing classifiers performance in the context of high-class imbalance. The comparative results obtained show that, at a very high imbalance, deep belief neural networks can provide the best performance.","","","10.1109/TNNLS.2019.2914471","National University of Litoral; Agencia Nacional de Promocion Cientifica y Tecnologica ANPCyT; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8728181","Bioinformatics;deep neural architectures;high-class imbalance;precursor microRNA (pre-miRNA) classification.","Neurons;Self-organizing feature maps;Bioinformatics;Training;Genomics;Computer architecture;Task analysis","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Guided Learning for Fast Multi-Exposure Image Fusion","K. Ma; Z. Duanmu; H. Zhu; Y. Fang; Z. Wang","Center for Neural Science, New York University, New York, NY 10013, USA.; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON N2L 3G1, Canada.; School of Information Management, Jiangxi University of Finance and Economics, Nanchang 330032, Jiangxi, China.; School of Information Management, Jiangxi University of Finance and Economics, Nanchang 330032, Jiangxi, China.; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON N2L 3G1, Canada.","IEEE Transactions on Image Processing","","2019","PP","99","1","1","We propose a fast multi-exposure image fusion (MEF) method, namely MEF-Net, for static image sequences of arbitrary spatial resolution and exposure number. We first feed a low-resolution version of the input sequence to a fully convolutional network for weight map prediction. We then jointly upsample the weight maps using a guided filter. The final image is computed by a weighted fusion. Unlike conventional MEF methods, MEF-Net is trained end-to-end by optimizing the perceptually calibrated MEF structural similarity (MEF-SSIM) index over a database of training sequences at full resolution. Across an independent set of test sequences, we find that the optimized MEF-Net achieves consistent improvement in visual quality for most sequences, and runs 10 to 1000 times faster than state-of-the-art methods. The code is made publicly available at.","","","10.1109/TIP.2019.2952716","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8906233","Multi-exposure image fusion;convolutional neural networks;guided filtering;computational photography","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"BBC Net: Bounding-Box Critic Network for Occlusion-Robust Object Detection","J. U. Kim; J. Kwon; H. G. Kim; Y. M. Ro","Image and Video Systems Lab., School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), 291 Daehak-ro, Yuseong-gu, Daejeon, 34141, Republic of Korea.; Image and Video Systems Lab., School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), 291 Daehak-ro, Yuseong-gu, Daejeon, 34141, Republic of Korea.; Image and Video Systems Lab., School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), 291 Daehak-ro, Yuseong-gu, Daejeon, 34141, Republic of Korea.; Image and Video Systems Lab., School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), 291 Daehak-ro, Yuseong-gu, Daejeon, 34141, Republic of Korea.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Object detection has received significant interest in the research field of computer vision and widely used in human-centric applications. The occlusion problem is a frequent obstacle that degrades detection quality. In this paper, we propose a novel object detection framework targeting robust object detection in occlusion. The proposed deep learning based network consists mainly of two parts; 1) Object detection framework which classifies the object categories and localizes the object location, 2) Plug-in Bounding-Box (BB) estimator which estimates object and occlusion region from feature map of the backbone network and corresponding critic net-work for evaluating the predicted BB map. The BB estimator and the critic network are the plug-in modules added to object detection framework and learned competitively with adversarial manner. As the plug-in BB estimator is learned to estimate the BB map con-taining object and occlusion pattern information, the backbone network can embed this information to enable robust detection under occlusion in the test phase. Comprehensive experimental results on the PASCAL VOC and KITTI datasets showed that performance are improved with plug-in BB-Critic network by predicting and criticizing object and occlusion in general generic object detection frame-work.","","","10.1109/TCSVT.2019.2900709","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8649739","Object detection;occlusion;deep learning;actor-critic network","Object detection;Feature extraction;Deep learning;Encoding;Object recognition;Detectors;Proposals","","","","2","","","","","","IEEE","IEEE Early Access Articles"
"Learning Simple Thresholded Features with Sparse Support Recovery","H. Xu; Z. Wang; H. Yang; D. Liu; J. Liu","Electrical and Computer Engineering, University of Maryland, College Park, MD, USA.; Department of Computer Science and Engineering, Texas A&M University, College Station, TX, USA.; Department of Computer Science, University of Rochester, Rochester, NY, USA.; Beckman Institute, University of Illinois at Urbana- Champaign, Urbana, IL, USA.; Department of Computer Science, University of Rochester, Rochester, NY, USA.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","The thresholded feature has recently emerged as an extremely efficient, yet rough empirical approximation, of the time-consuming sparse coding inference process. Such an approximation has not yet been rigorously examined, and standard dictionaries often lead to non-optimal performance when used for computing thresholded features. In this paper, we first present two theoretical recovery guarantees for the thresholded feature to exactly recover the nonzero support of the sparse code. Motivated by them, we then formulate the Dictionary Learning for Thresholded Features (DLTF) model, which learns an optimized dictionary for applying the thresholded feature. In particular, for the (k; 2) norm involved, a novel proximal operator with log-linear time complexity O(mlogm) is derived. We evaluate the performance of DLTF on a vast range of synthetic and real-data tasks, where DLTF demonstrates remarkable efficiency, effectiveness and robustness in all experiments. In addition, we briefly discuss the potential link between DLTF and deep learning building blocks.","","","10.1109/TCSVT.2019.2901713","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8653305","sparse representation;feature learning;optimization;unsupervised learning","Encoding;Dictionaries;Machine learning;Standards;Time complexity;Task analysis","","","","","","","","","","IEEE","IEEE Early Access Articles"
"D3M: A deep domain decomposition method for partial differential equations","K. Li; K. Tang; T. Wu; Q. Liao","School of Information Science and Technology, ShanghaiTech University, Shanghai 201210, China and Shanghai Institute of Microsystem and Information Technology, Chinese Academy of Sciences, Shanghai 200050, China and University of Chinese Academy of Sciences, Beijing 100049, China.; School of Information Science and Technology, ShanghaiTech University, Shanghai 201210, China and Shanghai Institute of Microsystem and Information Technology, Chinese Academy of Sciences, Shanghai 200050, China and University of Chinese Academy of Sciences, Beijing 100049, China.; Viterbi School of Engineering, University of Southern California, Los Angeles, CA 90089, USA.; School of Information Science and Technology, ShanghaiTech University, Shanghai 201210, China.","IEEE Access","","2019","PP","99","1","1","A state-of-the-art deep domain decomposition method (D3M) based on the variational principle is proposed for partial differential equations (PDEs). The solution of PDEs can be formulated as the solution of a constrained optimization problem, and we design a hierarchical neural network framework to solve this optimization problem. Our contribution is to develop a systematical computational procedure for the underlying problem in parallel with domain decomposition. Our analysis shows that the D3M approximation solution converges to the exact solution of the underlying PDEs. The accuracy and the efficiency of D3M are validated and demonstrated with numerical experiments.","","","10.1109/ACCESS.2019.2957200","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8918421","Domain decomposition;Deep learning;Mesh-free;Parallel computation;PDEs;Physicsconstrained","Optimization;Machine learning;Poisson equations;Biological neural networks;Handheld computers","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Learning with privileged information via adversarial discriminative modality distillation","N. C. Garcia; P. Morerio; V. Murino","Pattern Analysis and Computer Vision (PAVIS), Istituto Italiano di Tecnologia, 121451 Genova, Genova Italy (e-mail: nuno@cruz-garcia.net); Pattern Analysis and Computer Vision (PAVIS), Istituto Italiano di Tecnologia, 121451 Genova, Genova Italy (e-mail: pietro.morerio@iit.it); Pattern Analysis and Computer Vision, Italian Institute of Technology, Genova, Genova Italy (e-mail: vittorio.murino@iit.it)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Heterogeneous data modalities can provide complementary cues for several tasks, usually leading to more robust algorithms and better performance. However, while training data can be accurately collected to include a variety of sensory modalities, it is often the case that not all of them are available in real life (testing) scenarios, where a model has to be deployed. This raises the challenge of how to extract information from multimodal data in the training stage, in a form that can be exploited at test time, considering limitations such as noisy or missing modalities. This paper presents a new approach in this direction for RGB-D vision tasks, developed within the adversarial learning and privileged information frameworks. We consider the practical case of learning representations from depth and RGB videos, while relying only on RGB data at test time. We propose a new approach to train a hallucination network that learns to distill depth information via adversarial learning, resulting in a clean approach without several losses to balance or hyperparameters. We report state-of-the-art results for object classification on the NYUD dataset, and video action recognition on the largest multimodal dataset available for this task, the NTU RGB+D, as well as on the Northwestern-UCLA.","","","10.1109/TPAMI.2019.2929038","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8764498","Multimodal deep learning;adversarial learning;privileged information;network distillation;modality hallucination","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Efficient Incremental Learning using Dynamic Correction Vector","Y. Xiang; Y. Miao; J. Chen; Q. Xuan","Institute of Cyberspace Security, Zhejiang University of Technology, Hangzhou 310023, China and College of Information Engineering, Zhejiang University of Technology, Hangzhou 310023, China.; Institute of Cyberspace Security, Zhejiang University of Technology, Hangzhou 310023, China and College of Information Engineering, Zhejiang University of Technology, Hangzhou 310023, China.; Institute of Cyberspace Security, Zhejiang University of Technology, Hangzhou 310023, China and College of Information Engineering, Zhejiang University of Technology, Hangzhou 310023, China and Big Search in Cyberspace Research Center, Zhejiang Lab, Hangzhou 311121, China.; Institute of Cyberspace Security, Zhejiang University of Technology, Hangzhou 310023, China and College of Information Engineering, Zhejiang University of Technology, Hangzhou 310023, China and Big Search in Cyberspace Research Center, Zhejiang Lab, Hangzhou 311121, China.","IEEE Access","","2019","PP","99","1","1","One major challenge for modern artificial neural networks (ANNs) is that they typically does not handle incremental learning well. In other words, while learning the new features, the performances of existing features usually deteriorate. This phenomenon is called catastrophic forgetting, which causes great problems for continuous, incremental, and intelligent learning. In this work, we propose a dynamic correction vector based algorithm to address both the bias problem from knowledge distillation and the overfitting problem. Specifically, we have made the following contributions: 1) we have designed a novel dynamic correction vector based algorithm; 2) we have proposed new loss functions accordingly. Experimental results on MNIST and CIFAR-100 datasets demonstrate that our technique can outperform state-of-the-art incremental learning methods by 4% on large datasets.","","","10.1109/ACCESS.2019.2963461","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8948028","Incremental learning;convolutional neural network;deep learning","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Deep Depth from Uncalibrated Small Motion Clip","S. Im; H. Ha; H. Jeon; S. Lin; I. S. Kweon","Information and Communication Engineering, Daegu Gyeongbuk Institute of Science and Technology, 235496 Daegu, Daegu Korea (the Republic of) (e-mail: sunghoonim27@gmail.com); Electrical Engineering, Korea Advanced Institute of Science and Technology, 34968 Daejeon, Daejeon Korea (the Republic of) (e-mail: hwha@rcv.kaist.ac.kr); Artificial Intelligence Graduate School, Gwangju Institute of Science and Technology, 65419 Gwangju, Gwangju Korea (the Republic of) (e-mail: haegonj@gist.ac.kr); Internet Graphics group, Microsoft Research Asia, Beijing, Beijing China 100080 (e-mail: stevelin@microsoft.com); The School of Electrical Engineering, KAIST, Daejeon, Daejeon Korea (the Republic of) (e-mail: iskweon77@kaist.ac.kr)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","We propose a novel approach to infer a high-quality depth map from a set of images with small viewpoint variations. In general, techniques for depth estimation from small motion consist of camera pose estimation and dense reconstruction. In contrast to prior approaches that recover scene geometry and camera motions using pre-calibrated cameras, we introduce a self-calibrating bundle adjustment method tailored for small motion which enables computation of camera poses without the need for camera calibration. For dense depth reconstruction, we present a convolutional neural network called DPSNet (Deep Plane Sweep Network) whose design is inspired by best practices of traditional geometry-based approaches. Rather than directly estimating depth or optical flow correspondence from image pairs as done in many previous deep learning methods, DPSNet takes a plane sweep approach that involves building a cost volume from deep features using the plane sweep algorithm, regularizing the cost volume, and regressing the depth map from the cost volume. The cost volume is constructed using a differentiable warping process that allows for end-to-end training of the network. Through the effective incorporation of conventional multiview stereo concepts within a deep learning framework, the proposed method achieves state-of-the-art results on a variety of challenging datasets.","","","10.1109/TPAMI.2019.2946806","Daegu Gyeongbuk Institute of Science and Technology; Gwangju Institute of Science and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8865619","3D reconstruction;geometry;deep learning;structure from motion;bundle adjustment;plane sweeping algorithm","Cameras;Bundle adjustment;Geometry;Image reconstruction;Estimation;Calibration","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Visual Semantic Information Pursuit: A Survey","D. Liu; M. Bober; J. Kittler","Centre for Vision Speech and Signal Processing (CVSSP), University of Surrey, 3660 Guildford, Surrey United Kingdom of Great Britain and Northern Ireland (e-mail: daqi.liu@surrey.ac.uk); Centre for Vision Speech and Signal Processing (CVSSP), Faculty of Engineering and Physical Sciences, University of Surrey, Guildford, Surrey United Kingdom of Great Britain and Northern Ireland (e-mail: m.bober@surrey.ac.uk); Centre for Vision, Speech and Signal Processing, University of Surrey, Guildford, Surrey United Kingdom of Great Britain and Northern Ireland GU2 7XH (e-mail: j.kittler@surrey.ac.uk)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Visual semantic information comprises two important parts: the meaning of each visual semantic unit and the coherent visual semantic relation conveyed by these visual semantic units. Essentially, the former one is a visual perception task while the latter one corresponds to visual context reasoning. Remarkable advances in visual perception have been achieved due to the success of deep learning. In contrast, visual semantic information pursuit, a visual scene semantic interpretation task combining visual perception and visual context reasoning, is still in its early stage. It is the core task of many different computer vision applications, such as object detection, visual semantic segmentation, visual relationship detection or scene graph generation. Since it helps to enhance the accuracy and the consistency of the resulting interpretation, visual context reasoning is often incorporated with visual perception in current deep end-to-end visual semantic information pursuit methods. Surprisingly, a comprehensive review for this exciting area is still lacking. In this survey, we present a unified theoretical paradigm for all these methods, followed by an overview of the major developments and the future trends in each potential direction. The common benchmark datasets, the evaluation metrics and the comparisons of the corresponding methods are also introduced.","","","10.1109/TPAMI.2019.2950025","Engineering and Physical Sciences Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8887285","Semantic Scene Understanding;Visual Perception;Visual Context Reasoning;Deep Learning;Variational Free Energy Minimization;Message Passing","Visualization;Semantics;Task analysis;Visual perception;Cognition;Object detection;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Multi-view Learning to Rank","G. Cao; A. Iosifidis; M. Gabbouj; V. Raghavan; R. Gottumukkala","Signal Processing, Tampereen Teknillinen yliopisto, 7839 Tampere, Tampere Finland 33101 (e-mail: guanqun.cao@ieee.org); Engineering, Aarhus Universitet, 1006 Aarhus, Denmark Denmark (e-mail: alexandros.iosifidis@eng.au.dk); Signal Processing, Tampere University, Tampere, Tampere Finland (e-mail: moncef.gabbouj@tut.fi); Center for Advanced Computer Studies, University of Louisiana at Lafayette, Lafayette, Louisiana United States (e-mail: raghavan@louisiana.edu); Informatics Research Institute, University of Louisiana at Lafayette, Lafayette, Louisiana United States (e-mail: raju@louisiana.edu)","IEEE Transactions on Knowledge and Data Engineering","","2019","PP","99","1","1","We study the problem of learning to rank from multiple information sources. Though multi-view learning and learning to rank have been studied extensively leading to a wide range of applications, multi-view learning to rank as a synergy of both topics has received little attention. The aim of the paper is to propose a composite ranking method while keeping a close correlation with the individual rankings simultaneously. We present a generic framework for multi-view subspace learning to rank (MvSL2R), and two novel solutions are introduced under the framework. The first solution captures information of feature mappings from within each view as well as across views using autoencoder-like networks. Novel feature embedding methods are formulated in the optimization of multi-view unsupervised and discriminant autoencoders. Moreover, we introduce an end-to-end solution to learning towards both the joint ranking objective and the individual rankings. The proposed solution enhances the joint ranking with minimum view-specific ranking loss, so that it can achieve the maximum global view agreements in a single optimization process. The proposed method is evaluated on three different ranking problems, i.e. university ranking, multi-view lingual text ranking and image data ranking, providing superior results compared to related methods.","","","10.1109/TKDE.2019.2942590","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8845659","Learning to rank;multi-view data analysis;ranking","Correlation;Transforms;Neural networks;Training;Optimization;Data models;Data mining","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Separating the Structural Components of Maize for Field Phenotyping Using Terrestrial LiDAR Data and Deep Convolutional Neural Networks","S. Jin; Y. Su; S. Gao; F. Wu; K. Xu; Q. Ma; T. Hu; J. Liu; S. Pang; H. Guan; J. Zhang; Q. Guo","State Key Laboratory of Vegetation and Environmental Change, Institute of Botany, Chinese Academy of Sciences, Beijing 100093, China, and also with the University of Chinese Academy of Sciences, Beijing 100049, China; State Key Laboratory of Vegetation and Environmental Change, Institute of Botany, Chinese Academy of Sciences, Beijing 100093, China, and also with the University of Chinese Academy of Sciences, Beijing 100049, China (e-mail: suyanjun1987@gmail.com).; State Key Laboratory of Vegetation and Environmental Change, Institute of Botany, Chinese Academy of Sciences, Beijing 100093, China, and also with the University of Chinese Academy of Sciences, Beijing 100049, China; State Key Laboratory of Vegetation and Environmental Change, Institute of Botany, Chinese Academy of Sciences, Beijing 100093, China, and also with the University of Chinese Academy of Sciences, Beijing 100049, China; State Key Laboratory of Vegetation and Environmental Change, Institute of Botany, Chinese Academy of Sciences, Beijing 100093, China, and also with the University of Chinese Academy of Sciences, Beijing 100049, China; Department of Forestry, Mississippi State University, Starkville, MS 39762 USA; State Key Laboratory of Vegetation and Environmental Change, Institute of Botany, Chinese Academy of Sciences, Beijing 100093, China, and also with the University of Chinese Academy of Sciences, Beijing 100049, China; State Key Laboratory of Vegetation and Environmental Change, Institute of Botany, Chinese Academy of Sciences, Beijing 100093, China, and also with the University of Chinese Academy of Sciences, Beijing 100049, China; State Key Laboratory of Vegetation and Environmental Change, Institute of Botany, Chinese Academy of Sciences, Beijing 100093, China, and also with the University of Chinese Academy of Sciences, Beijing 100049, China; State Key Laboratory of Vegetation and Environmental Change, Institute of Botany, Chinese Academy of Sciences, Beijing 100093, China, and also with the University of Chinese Academy of Sciences, Beijing 100049, China; State Key Laboratory of Vegetation and Environmental Change, Institute of Botany, Chinese Academy of Sciences, Beijing 100093, China, and also with the University of Chinese Academy of Sciences, Beijing 100049, China; State Key Laboratory of Vegetation and Environmental Change, Institute of Botany, Chinese Academy of Sciences, Beijing 100093, China, and also with the University of Chinese Academy of Sciences, Beijing 100049, China (e-mail: guo.qinghua@gmail.com).","IEEE Transactions on Geoscience and Remote Sensing","","2019","PP","99","1","15","Separating structural components is important but also challenging for plant phenotyping and precision agriculture. Light detection and ranging (LiDAR) technology can potentially overcome these difficulties by providing high quality data. However, there are difficulties in automatically classifying and segmenting components of interest. Deep learning can extract complex features, but it is mostly used with images. Here, we propose a voxel-based convolutional neural network (VCNN) for maize stem and leaf classification and segmentation. Maize plants at three different growth stages were scanned with a terrestrial LiDAR and the voxelized LiDAR data were used as inputs. A total of 3000 individual plants (22 004 leaves and 3000 stems) were prepared for training through data augmentation, and 103 maize plants were used to evaluate the accuracy of classification and segmentation at both instance and point levels. The VCNN was compared with traditional clustering methods (K-means and density-based spatial clustering of applications with noise), a geometry-based segmentation method, and state-of-the-art deep learning methods (PointNet and PointNet++). The results showed that: 1) at the instance level, the mean accuracy of classification and segmentation (F-score) were 1.00 and 0.96, respectively; 2) at the point level, the mean accuracy of classification and segmentation (F-score) were 0.91 and 0.89, respectively; 3) the VCNN method outperformed traditional clustering methods; and 4) the VCNN was on par with PointNet and PointNet++ in classification, and performed the best in segmentation. The proposed method demonstrated LiDAR's ability to separate structural components for crop phenotyping using deep learning, which can be useful for other fields.","","","10.1109/TGRS.2019.2953092","National Basic Research Program of China (973 Program); National Natural Science Foundation of China; Strategic Priority Research Program of the Chinese Academy of Sciences; CAS Pioneer Hundred Talents Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8931235","Classification;deep learning;LiDAR;phenotype;segmentation;structural components.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"MsCNN: A Deep Learning Framework for P300 Based Brain-Computer Interface Speller","S. Kundu; S. Ari","Department of Electronics and Communication Engineering, National Institute of Technology, Rourkela, 769008, India.; Department of Electronics and Communication Engineering, National Institute of Technology, Rourkela, 769008, India.","IEEE Transactions on Medical Robotics and Bionics","","2019","PP","99","1","1","In this paper, a novel multiscale convolutional neural network (MsCNN) architecture is proposed for P300 based BCI speller. Major limitation of BCI system is that it requires a large number of data to train the system. However, collection of large amount of data from a single subject makes the task tedious for the subject and this will affect the quality of the acquired electroencephalogram (EEG) signal. To cope with this issues, a MsCNN model with transfer learning (MsCNN-TL) technique is proposed in this work for improvement of the P300 based character recognition performance with limited amount of training data. The multi-resolution deep features are extracted from the fully connected layer of the trained MsCNN-TL architecture. These deep features are optimized using Fisher ratio (F-ratio) based feature selection technique and the optimal features are applied to the ensemble of support vector machines (ESVMs) for P300 detection. The proposed method is tested on BCI competition datasets and it achieves better performance compared to the other state-of-the-art techniques for limited training dataset.","","","10.1109/TMRB.2019.2959559","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8932567","Brain-computer interface (BCI);Fisher ratio (F-ratio);multiscale convolutional neural network (MsCNN);P300;transfer learning.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Path planning for intelligent robots based on deep Q-learning with experience replay and heuristic knowledge","L. Jiang; H. Huang; Z. Ding","Laboratory of Intelligent Computing and Software Engineering, Zhejiang Sci-Tech University, Hangzhou 310018, China; Center of Multi-Media Big Data of Library, Zhejiang Sci-Tech University, Hangzhou 310018, China; Laboratory of Intelligent Computing and Software Engineering, Zhejiang Sci-Tech University, Hangzhou 310018, China","IEEE/CAA Journal of Automatica Sinica","","2019","PP","99","1","11","Path planning and obstacle avoidance are two challenging problems in the study of intelligent robots. In this paper, we develop a new method to alleviate these problems based on deep Q-learning with experience replay and heuristic knowledge. In this method, a neural network has been used to resolve the curse of dimensionality issue of the Q-table in reinforcement learning. When a robot is walking in an unknown environment, it collects experience data which is used for training a neural network; such a process is called experience replay. Heuristic knowledge helps the robot avoid blind exploration and provides more effective data for training the neural network. The simulation results show that in comparison with the existing methods, our method can converge to an optimal action strategy with less time and can explore a path in an unknown environment with fewer steps and larger average reward.","","","10.1109/JAS.2019.1911732","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8853432","","Neural networks;Collision avoidance;Reinforcement learning;Path planning;Training;Intelligent robots","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Classification of Hand Movements from EEG using a Deep Attention-based LSTM Network","G. Zhang; V. Davoodnia; A. Sepas-Moghaddam; Y. Zhang; A. Etemad","Department of Electrical and Computer Engineering, Queen’s University, Kingston, ON, Canada.; Department of Electrical and Computer Engineering, Queen’s University, Kingston, ON, Canada.; Department of Electrical and Computer Engineering, Queen’s University, Kingston, ON, Canada.; Department of Computer Science and Technology, Tsinghua University, Beijing, China.; Department of Electrical and Computer Engineering, Queen’s University, Kingston, ON, Canada.","IEEE Sensors Journal","","2019","PP","99","1","1","Classifying limb movements using brain activity is an important task in Brain-computer Interfaces (BCI) that has been successfully used in multiple application domains, ranging from human-computer interaction to medical and biomedical applications. This paper proposes a novel solution for classification of left/right hand movement by exploiting a Long Short-Term Memory (LSTM) network with attention mechanism to learn the electroencephalogram (EEG) time-series information. To this end, a wide range of time and frequency domain features are extracted from the EEG signals and used to train an LSTM network to perform the classification task. We conduct extensive experiments with the EEG Movement dataset and show that our proposed solution our method achieves improvements over several benchmarks and state-of-the-art methods in both intra-subject and cross-subject validation schemes. Moreover, we utilize the proposed framework to analyze the information as received by the sensors and monitor the activated regions of the brain by tracking EEG topography throughout the experiments.","","","10.1109/JSEN.2019.2956998","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8918347","Brain-Computer Interfaces;Electroencephalogram;Deep Learning;Long Short-Term Memory;Attention Mechanism","Electroencephalography;Feature extraction;Task analysis;Machine learning;Frequency-domain analysis;Sensors;Brain","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Learning-based SDN Model for Internet of Things: An Incremental Tensor Train Approach","A. Singh; G. S. Aujla; S. Garg; G. Kaddoum; G. Singh","Computer Science & Engineering Department, Chandigarh University, Mohali (Punjab), India.; Computer Science & Engineering Department, Chandigarh University, Mohali (Punjab), India, and also with the School of Computing, Newcastle University, Newcastle Upon Tyne, UK, NE1 7RU.; Electrical Engineering Department, École de technologie supérieure, Université du Québec, Montréal, QC H3C 1K3, Canada.; Electrical Engineering Department, École de technologie supérieure, Université du Québec, Montréal, QC H3C 1K3, Canada.; Computer Science & Engineering Department, Chandigarh University, Mohali (Punjab), India.","IEEE Internet of Things Journal","","2019","PP","99","1","1","The Internet of Thing has emerged as a revolution for the design of smart applications like, intelligent transportation systems, smart grid, healthcare 4.0, Industry 4.0 and many more. However, this multi-attribute or multi-dimensional data generated by IoT devices must be evaluated or analyzed closer to their location (at edge of the network) for an enhanced performance. The smart applications are dependent on the faster delivery of data which can be used to extract their inherent patterns for further decision making. However, the enormous data generated by IoT devices is sufficient to choke the entire underlying network infrastructure. Most of the data attributes present little or no relevance to the prospective relationships and associations with the projected benefits foreseen. Therefore, an order-based generalization mechanisms known as tensor, can be used to represent this multi-dimensional data, thereby minimizing the flow table lookup time and reducing the storage occupancy. So, a novel IoT-Train-Deep approach for intelligent software defined networking is designed in this article. The proposed approach works in four phases, 1) tensor representation, 2) deep boltzmann machine-based classification, 3) sub-tensor-based flow matching process, and 4) incremental tensor train network for flow table synchronization. The proposed model has been extensively tested and it illustrates significant improvements with respect to delay, throughput, storage space and accuracy.","","","10.1109/JIOT.2019.2953537","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8901221","Deep Boltzman Machine;Network Intelligence;Software Defined Networking;Tensor Train Decomposition.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Bipartite Differential Neural Network for Unsupervised Image Change Detection","J. Liu; M. Gong; A. K. Qin; K. C. Tan","Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, School of Electronic Engineering, Xidian University, Xi'an 710071, China.; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, School of Electronic Engineering, Xidian University, Xi'an 710071, China (e-mail: gong@ieee.org).; Department of Computer Science and Software Engineering, Swinburne University of Technology, Melbourne, VIC 3122, Australia.; Department of Computer Science, City University of Hong Kong, Hong Kong.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","15","Image change detection detects the regions of change in multiple images of the same scene taken at different times, which plays a crucial role in many applications. The two most popular image change detection techniques are as follows: pixel-based methods heavily rely on accurate image coregistration while object-based approaches can tolerate coregistration errors to some extent but are sensitive to image segmentation or classification errors. To address these issues, we propose an unsupervised image change detection approach based on a novel bipartite differential neural network (BDNN). The BDNN is a deep neural network with two input ends, which can extract the holistic features from the unchanged regions in the two input images, where two learnable change disguise maps (CDMs) are used to disguise the changed regions in the two input images, respectively, and thus demarcate the unchanged regions therein. The network parameters and CDMs will be learned by optimizing an objective function, which combines a loss function defined as the likelihood of the given input image pair over all possible input image pairs and two constraints imposed on CDMs. Compared with the pixel-based and object-based techniques, the BDNN is less sensitive to inaccurate image coregistration and does not involve image segmentation or classification. In fact, it can even skip over coregistration if the degree of transformation (due to the different view angles and/or positions of the camera) between the two input images is not that large. We compare the proposed approach with several state-of-the-art image change detection methods on various homogeneous and heterogeneous image pairs with and without coregistration. The results demonstrate the superiority of the proposed approach.","","","10.1109/TNNLS.2019.2910571","National Natural Science Foundation of China; Key Research and Development Program of Shaanxi Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8716679","Change detection;convolutional neural networks (CNNs);deep learning;image coregistration;unsupervised learning.","Feature extraction;Buildings;Image segmentation;Neural networks;Image resolution;Geology;Imaging","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Anatomical Attention Guided Deep Networks for ROI Segmentation of Brain MR Images","L. Sun; W. Shao; D. Zhang; M. Liu","College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, MIIT Key Laboratory of Pattern Analysis and Machine Intelligence, Nanjing 211106, China.; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, MIIT Key Laboratory of Pattern Analysis and Machine Intelligence, Nanjing 211106, China.; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, MIIT Key Laboratory of Pattern Analysis and Machine Intelligence, Nanjing 211106, China.; Department of Information Science and Technology, Taishan University, Taian 271000, China.","IEEE Transactions on Medical Imaging","","2019","PP","99","1","1","Brain region-of-interest (ROI) segmentation based on structural magnetic resonance imaging (MRI) scans is an essential step for many computer-aid medical image analysis applications. Due to low intensity contrast around ROI boundary and large inter-subject variance, it has been remaining a challenging task to effectively segment brain ROIs from structural MR images. Even though several deep learning methods for brain MR image segmentation have been developed, most of them do not incorporate shape priors to take advantage of the regularity of brain structures, thus leading to sub-optimal performance. To address this issue, we propose an anatomical attention guided deep learning framework for brain ROI segmentation of structural MR images, containing two subnetworks. The first one is a segmentation subnetwork, used to simultaneously extract discriminative image representation and segment ROIs for each input MR image. The second one is an anatomical attention subnetwork, designed to capture the anatomical structure information of the brain from a set of labeled atlases. To utilize the anatomical attention knowledge learned from atlases, we develop an anatomical gate architecture to fuse feature maps derived from a set of atlas label maps and those from the to-be-segmented image for brain ROI segmentation. In this way, the anatomical prior learned from atlases can be explicitly employed to guide the segmentation process for performance improvement. Within this framework, we develop two anatomical attention guided segmentation models, denoted as anatomical gated fully convolutional network (AG-FCN) and anatomical gated U-Net (AG-UNet), respectively. Experimental results on both ADNI and LONI-LPBA40 datasets suggest that the proposed AG-FCN and AG-UNet methods achieve superior performance in ROI segmentation of brain MR images, compared with several state-of-the-art methods.","","","10.1109/TMI.2019.2962792","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8945235","Anatomical Attention;Deep Learning;ROI Segmentation;Brain MR Image","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Visual-Texual Emotion Analysis with Deep Coupled Video and Danmu Neural Networks","C. Li; J. Wang; H. Wang; M. Zhao; W. Li; X. Deng","Computer Science, Shanghai Jiao Tong University, 12474 Shanghai United States 200240 (e-mail: lcc1992@sjtu.edu.cn); Department of Computing, Hong Kong Polytechnic University, 26680 Kowloon Hong Kong (e-mail: wangjialin@hust.edu.cn); Department of Computer Science, Shanghai Jiao Tong University, 12474 Shanghai China (e-mail: wanghongwei55@gmail.com); Department of Computing, Hong Kong Polytechnic University, 26680 Kowloon Hong Kong (e-mail: mzhao.ny@gmail.com); Department of Computing, Hong Kong Polytechnic University, 26680 Kowloon Hong Kong (e-mail: cswjli@comp.polyu.edu.hk); School of Electronics Engineering and Computer Science, Peking University, 12465 Beijing China (e-mail: xiaotie@pku.edu.cn)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","User emotion analysis toward videos is to automatically recognize the general emotional status of viewers from the multimedia content embedded in the online video stream. Existing works fall in two categories: 1) $visual \text{-} based$ methods, which focus on visual content and extract a specific set of features of videos. However, it is generally hard to learn a mapping function from low-level video pixels to high-level emotion space due to great intra-class variance. 2) $textual \text{-} based$ methods, which focus on the investigation of user-generated comments associated with videos. The learned word representations by traditional linguistic approaches typically lack emotion information and the global comments usually reflect viewers' high-level understandings rather than instantaneous emotions. To address these limitations, in this paper, we propose to jointly utilize video content and user-generated texts simultaneously for emotion analysis. In particular, we introduce exploiting a new type of user-generated texts, i.e., “danmu”, which are real-time comments floating on the video and contain rich information to convey viewers' emotional opinions. To enhance the emotion discriminativeness of words in textual feature extraction, we propose $Emotional\ Word\ Embedding$ (EWE) to learn text representations by jointly considering their semantics and emotions. Afterwards, we propose a novel visual-textual emotion analysis model with $Deep\ Coupled\ Video\ and\ Danmu\ Neural\ networks$ (DCVDN), in which visual and textual features are synchronously extracted and fused to form a comprehensive representation by deep-canonically-correlated-autoencoder-based multi-view learning. Through extensive experiments on self-crawled real-world video-danmu dataset, we prove that DCVDN significantly outperforms the state-of-the-art baselines.","","","10.1109/TMM.2019.2946477","National Basic Research Program of China (973 Program); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8863380","Danmu;Deep Multimodal Learning;Emotion Analysis","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Zero-shot Classification Based on Multi-task Mixed Attribute Relations and Attribute-Specific Features","P. Gong; X. Wang; Y. Cheng; Z. J. Wang; Q. Yu","School of Information and Control Engineering, China University of Mining and Technology, Xuzhou 221116, China and also with an associate professor in the School of Medical Imaging, Xuzhou Medical University, Xuzhou 221004, China.; School of Information and Control Engineering, China University of Mining and Technology, Xuzhou 221116, China.; School of Information and Control Engineering, China University of Mining and Technology, Xuzhou 221116, China.; professor in the Electrical and Computer Engineering Department, University of British Columbia, V6T 1Z4, Vancouver, BC, Canada.; Associate professor in the School of Electrical and Power Engineering, China University of Mining and Technology, Xuzhou, 221116 China.","IEEE Transactions on Cognitive and Developmental Systems","","2019","PP","99","1","1","Zero-shot classification is a hot topic in computer vision and pattern recognition. Most zero-shot classification methods are based on the intermediate level representation of attributes to achieve knowledge transfer from the training classes to the unseen test classes. Recently, multi-task learning (MTL) has been shown as one of state-of-the-art approaches for attribute learning and zero-shot classification. Aiming at the attribute relation learning, features shared by attributes learning and attribute heterogeneity, we propose a zero-shot classification based on multi-task mixed attribute relations and attribute-specific features (ZSC-MTMAR-ASF). Firstly, considering the relationship between attribute-attribute and attribute-features, a second-order attribute relation and attribute-specific features learning model is constructed from training samples based on MTL. Secondly, second-order attribute relation is extended to high-order attribute relation and multiple attribute classifiers are learned. Finally, zero-shot classification is completed based on the maximum posterior probability. Experimental results on AWA and PubFig datasets show that, the proposed method can yield more accurate attribute prediction and zero-shot classification compared with several multi-task attribute learning methods.","","","10.1109/TCDS.2019.2902250","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8654670","Zero-shot classification;Multi-task;Attribute relation learning;Attribute-specific features.","Training;Semantics;Task analysis;Deep learning;Sparse matrices;Learning systems;Computer vision","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Promotion of Answer Value Measurement With Domain Effects in Community Question Answering Systems","B. Jin; E. Chen; H. Zhao; Z. Huang; Q. Liu; H. Zhu; S. Yu","School of Computer Science and Technology, University of Science and Technology of China, Hefei 230026, China.; School of Computer Science and Technology, University of Science and Technology of China, Hefei 230026, China (e-mail: cheneh@ustc.edu.cn).; College of Management and Economics, Tianjin University, Tianjin 300072, China.; School of Computer Science and Technology, University of Science and Technology of China, Hefei 230026, China.; School of Computer Science and Technology, University of Science and Technology of China, Hefei 230026, China.; Baidu Talent Intelligence Center, Baidu, Inc., Beijing 100085, China.; School of Computer Science, University of Technology Sydney, Sydney, NSW 2007, Australia.","IEEE Transactions on Systems, Man, and Cybernetics: Systems","","2019","PP","99","1","12","In the area of community question answering (CQA), answer selection and answer ranking are two tasks which are applied to help users quickly access valuable answers. Existing solutions mainly exploit the syntactic or semantic correlation between a question and its related answers (Q&A), where the multifacet domain effects in CQA are still underexplored. In this paper, we propose a unified model, enhanced attentive recurrent neural network (EARNN), for both answer selection and answer ranking tasks by taking full advantages of both Q&A semantics and multifacet domain effects (i.e., topic effects and timeliness). Specifically, we develop a serialized long short-term memory to learn the unified representations of Q&A, where two attention mechanisms at either sentence level or word level are designed for capturing the deep effects of topics. Meanwhile, the emphasis of Q&A can be automatically distinguished. Furthermore, we design a time-sensitive ranking function to model the timeliness in CQA. To effectively train EARNN, a question-dependent pairwise learning strategy is also developed. Finally, we conduct extensive experiments on a real-world dataset from Quora. Experimental results validate the effectiveness and interpretability of our proposed EARNN model.","","","10.1109/TSMC.2019.2917673","National Key Research and Development Program of China; National Natural Science Foundation of China; Youth Innovation Promotion Association of Chinese Academy of Sciences; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8736313","Answer selection/ranking;community question answering (CQA);deep learning;timeliness;topic effects","Semantics;Task analysis;Recurrent neural networks;Feature extraction;Knowledge discovery;Syntactics;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"NTU RGB+D 120: A Large-Scale Benchmark for 3D Human Activity Understanding","J. Liu; A. Shahroudy; M. L. Perez; G. Wang; L. Duan; A. Kot Chichung","School of Electrical and Electronic Engineering, Nanyang Technological University, 54761 Singapore, Singapore Singapore 639798 (e-mail: jliu029@ntu.edu.sg); School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore, Singapore Singapore 637553 (e-mail: amir3@ntu.edu.sg); School of EEE, Nanyang Technological University, 54761 Singapore, Singapore Singapore (e-mail: mauricio001@ntu.edu.sg); School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore, Singapore Singapore (e-mail: gangwang6@gmail.com); Peking University, Peking University, Beijing, Beijing China (e-mail: lingyu@pku.edu.cn); School of EEE, Nanyang Technological University, 54761 Singapore, Singapore Singapore (e-mail: eackot@ntu.edu.sg)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Research on depth-based human activity analysis achieved outstanding performance and demonstrated the effectiveness of 3D representation for action recognition. The existing depth-based and RGB+D-based action recognition benchmarks have a number of limitations, including the lack of large-scale training samples, realistic number of distinct class categories, diversity in camera views, varied environmental conditions, and variety of human subjects. In this work, we introduce a large-scale dataset for RGB+D human action recognition, which is collected from 106 distinct subjects and contains more than 114 thousand video samples and 8 million frames. This dataset contains 120 different action classes including daily, mutual, and health-related activities. We evaluate the performance of a series of existing 3D activity analysis methods on this dataset, and show the advantage of applying deep learning methods for 3D-based human action recognition. Furthermore, we investigate a novel one-shot 3D activity recognition problem on our dataset, and a simple yet effective Action-Part Semantic Relevance-aware (APSR) framework is proposed for this task, which yields promising results for recognition of the novel action classes. We believe the introduction of this large-scale dataset will enable the community to apply, adapt, and develop various data-hungry learning techniques for depth-based and RGB+D-based human activity understanding.","","","10.1109/TPAMI.2019.2916873","National Natural Science Foundation of China; National Research Foundation Singapore; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8713892","Activity Understanding;Video Analysis;3D Action Recognition;RGB+D Vision;Deep Learning;Large-Scale Benchmark","Three-dimensional displays;Benchmark testing;Cameras;Deep learning;Semantics;Lighting;Skeleton","","","","2","","","","","","IEEE","IEEE Early Access Articles"
"Deep Unfolded Robust PCA with Application to Clutter Suppression in Ultrasound","O. Solomon; R. Cohen; Y. Zhang; Y. Yang; Q. He; J. Luo; R. J. G. van Sloun; Y. C. Eldar","Department of Electrical Engineering, Technion-Israel Institute of Technology, Haifa 32000, Israel.; Department of Electrical Engineering, Technion-Israel Institute of Technology, Haifa 32000, Israel.; Department of Electrical Engineering, Tsinghua University, Beijing 100084, China.; Department of Biomedical Engineering, Tsinghua University, Beijing 100084, China.; Department of Biomedical Engineering, Tsinghua University, Beijing 100084, China.; Department of Biomedical Engineering, Tsinghua University, Beijing 100084, China.; Department of Electrical Engineering, Eindhoven University of Technology, Eindhoven, The Netherlands.; Faculty of Math and Computer Science, Weizmann Institute of Science, Rehovot, Israel.","IEEE Transactions on Medical Imaging","","2019","PP","99","1","1","Contrast enhanced ultrasound is a radiation-free imaging modality which uses encapsulated gas microbubbles for improved visualization of the vascular bed deep within the tissue. It has recently been used to enable imaging with unprecedented subwavelength spatial resolution by relying on super-resolution techniques. A typical preprocessing step in super-resolution ultrasound is to separate the microbubble signal from the cluttering tissue signal. This step has a crucial impact on the final image quality. Here, we propose a new approach to clutter removal based on robust principle component analysis (PCA) and deep learning. We begin by modeling the acquired contrast enhanced ultrasound signal as a combination of low rank and sparse components. This model is used in robust PCA and was previously suggested in the context of ultrasound Doppler processing and dynamic magnetic resonance imaging. We then illustrate that an iterative algorithm based on this model exhibits improved separation of microbubble signal from the tissue signal over commonly practiced methods. Next, we apply the concept of deep unfolding to suggest a deep network architecture tailored to our clutter filtering problem which exhibits improved convergence speed and accuracy with respect to its iterative counterpart. We compare the performance of the suggested deep network on both simulations and in-vivo rat brain scans, with a commonly practiced deep-network architecture and with the fast iterative shrinkage algorithm. We show that our architecture exhibits better image quality and contrast.","","","10.1109/TMI.2019.2941271","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8836615","Deep unfolding;inverse problems;machine learning;neural network;robust PCA;ultrasound imaging","Imaging;Ultrasonic imaging;Iterative methods;Blood;Clutter;Sparse matrices;Principal component analysis","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Mimicking Short-Term Memory in Shape-Reconstruction Task Using an EEG-Induced Type-2 Fuzzy Deep Brain Learning Network","L. Ghosh; A. Konar; P. Rakshit; A. K. Nagar","Department Electronics and Telecommunication Engineering, Jadavpur University, Kolkata 700032, India (e-mail: lidiaghosh.bits@gmail.com).; Department Electronics and Telecommunication Engineering, Jadavpur University, Kolkata 700032, India (e-mail: konaramit@yahoo.co.in).; Department Electronics and Telecommunication Engineering, Jadavpur University, Kolkata 700032, India (e-mail: pratyushar1@gmail.com).; Mathematics and Computer Science Deparment, Liverpool Hope University, Liverpool, L16 9JDMerseyside, U.K. (e-mail: nagara@hope.ac.uk).","IEEE Transactions on Emerging Topics in Computational Intelligence","","2019","PP","99","1","18","The paper attempts to model short-term memory (STM) for shape-reconstruction tasks by employing a 4-stage deep brain leaning network (DBLN), where the first two stages are built with Hebbian learning and the last two stages with Type-2 Fuzzy logic. The model is trained stage-wise independently with visual stimulus of the object-geometry as the input of the first stage, EEG acquired from different cortical regions as input and output of respective intermediate stages, and recalled object-geometry as the output of the last stage. Two error feedback loops are employed to train the proposed DBLN. The inner loop adapts the weights of the STM based on a measure of error in model-predicted response with respect to the object-shape recalled by the subject. The outer loop adapts the weights of the iconic (visual) memory based on a measure of error of the model predicted response with respect to the desired object-shape. In the test phase, the DBLN model reproduces the recalled object shape from the given input object geometry. The motivation of the paper is to test the consistency in STM encoding (in terms of similarity in network weights) for repeated visual stimulation with the same geometric object. Experiments undertaken on healthy subjects, yield high similarity in network weights, whereas patients with pre-frontal lobe Amnesia yield significant discrepancy in the trained weights for any two trials with the same training object. This justifies the importance of the proposed DBLN model in automated diagnosis of patients with learning difficulty. The novelty of the paper lies in the overall design of the DBLN model with special emphasis to the last two stages of the network, built with vertical slice based type-2 fuzzy logic, to handle uncertainty in function approximation (with noisy EEG data). The proposed technique outperforms the state-of-the-art functional mapping algorithms with respect to the (pre-defined outer loop) error metric, computational complexity and runtime.","","","10.1109/TETCI.2019.2937566","UPE II Project in Cognitive Science; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8848806","Short-term memory;iconic memory;Hebbian learning;type-2 fuzzy set;shape reconstruction;memory failure and N400","Brain modeling;Electroencephalography;Task analysis;Encoding;Fuzzy sets;Feature extraction;Parietal lobe","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Rethinking Online Action Detection in Untrimmed Videos: A Novel Online Evaluation Protocol","M. Baptista-Ríos; R. J. López-Sastre; F. C. Heilbron; J. C. Van Gemert; F. J. Acevedo-Rodríguez; S. Maldonado-Bascón","GRAM, Department of Signal Theory and Communications, University of Alcalá, Alcalá de Henares, Spain.; GRAM, Department of Signal Theory and Communications, University of Alcalá, Alcalá de Henares, Spain.; Adobe Research, Media Intelligence Lab, Deep Learning Group.; Faculty of Electrical Engineering, Mathematics and Computer Science, Delft University of Technology, Delft, The Netherlands.; GRAM, Department of Signal Theory and Communications, University of Alcalá, Alcalá de Henares, Spain.; GRAM, Department of Signal Theory and Communications, University of Alcalá, Alcalá de Henares, Spain.","IEEE Access","","2019","PP","99","1","1","The Online Action Detection (OAD) problem needs to be revisited. Unlike traditional offline action detection approaches, where the evaluation metrics are clear and well established, in the OAD setting we find very few works and no consensus on the evaluation protocols to be used. In this work we propose to rethink the OAD scenario, clearly defining the problem itself and the main characteristics that the models which are considered online must comply with. We also introduce a novel metric: the Instantaneous Accuracy (IA). This new metric exhibits an online nature and solves most of the limitations of the previous metrics. We conduct a thorough experimental evaluation on 3 challenging datasets, where the performance of various baseline methods is compared to that of the state-of-the-art. Our results confirm the problems of the previous evaluation protocols, and suggest that an IA-based protocol is more adequate to the online scenario. The baselines models and a development kit with the novel evaluation protocol will be made publicly available.","","","10.1109/ACCESS.2019.2961789","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8939455","computer vision;deep learning;evaluation;instantaneous accuracy;online action detection","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"iART: Learning from Demonstration for Assisted Robotic Therapy Using LSTM","S. Pareek; T. Kesavadas","Systems Engineering, University of Illinois at Urbana Champaign, Urbana, IL United States of America 61801 (e-mail: shreypareek1991@gmail.com); CSL-Health Care Engineering Systems Center, University of Illinois at Urbana-Champaign, Urbana, Illinois United States of America 61801 (e-mail: kesh@illinois.edu)","IEEE Robotics and Automation Letters","","2019","PP","99","1","1","In this paper, we present an intelligent Assistant for Robotic Therapy (iART), that provides robotic assistance during 3D trajectory tracking tasks. We propose a novel LSTM-based robot learning from demonstration (LfD) paradigm to mimic a therapist's assistance behavior. iART presents a trajectory agnostic LfD routine that can generalize learned behavior from a single trajectory to any 3D shape. Once the therapist's behavior has been learned, iART enables the patient to modify this behavior as per their preference. The system requires only a single demonstration of 2 minutes and exhibits a mean accuracy of 91.41% in predicting, and hence mimicking a therapist's assistance behavior. The system delivers stable assistance in realtime and successfully reproduces different types of assistance behaviors.","","","10.1109/LRA.2019.2961845","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8939469","Rehabilitation Robotics;Deep Learning in Robotics and Automation;Learning from Demonstration;AIBased Methods","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Energy-Efficient Power Control in Wireless Networks with Spatial Deep Neural Networks","T. Zhang; S. Mao","Department of Electrical and Computer Engineering, Auburn University, Auburn, AL 36849-5201, USA.; Department of Electrical and Computer Engineering, Auburn University, Auburn, AL 36849-5201, USA.","IEEE Transactions on Cognitive Communications and Networking","","2019","PP","99","1","1","The energy-efficient power control of interfering links in a large wireless network is a challenging task. In this paper, we propose a deep learning based power control scheme, termed PowerNet, that uses the devices’ geographical location information (GLI). We show that it is possible to bypass the complex channel estimation process and directly perform power control with GLI when the channel state information (CSI) can be viewed as a function of distance dependent path-loss. The time consuming and complex channel estimation process can thus be avoided. Moreover, with a proper training, PowerNet transforms the on-line complexity to off-line training, and is amenable for real-time services. Different from conventional deep neural network (DNN) that adopts fully connected structure, the proposed PowerNet leverages convolutional layers to better capture the interference pattern across different links in large wireless networks and utilizes deep residual learning to further enhance its robustness. Simulation results demonstrate that PowerNet can achieve a near-optimal performance at a remarkably high speed without explicit channel estimation. PowerNet also exhibits a great generalization ability in terms of problem sizes and channel fading types.","","","10.1109/TCCN.2019.2945774","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8861118","Deep learning;Energy efficiency;Power control;Interference networks.","Power control;Channel estimation;Complexity theory;Real-time systems;Fading channels;Approximation algorithms;Wireless communication","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Location-Aware Deep Collaborative Filtering for Service Recommendation","Y. Zhang; C. Yin; Q. Wu; Q. He; H. Zhu","School of Computer Science and Technology, Anhui University, Hefei 230039, China.; School of Computer Science and Technology, Anhui University, Hefei 230039, China.; School of Information Engineering, Chaohu University, Chaohu 238000, China, and also with the School of Management and Engineering, Nanjing University, Nanjing 210093, China (e-mail: lingqiw@126.com).; School of Software and Electrical Engineering, Swinburne University of Technology, Melbourne, VIC 3122, Australia.; Department of Control and System Engineering, Nanjing University, Nanjing 210093, China, and also with the Department of Computer Science and Mathematics, Nipissing University, North Bay, ON P1B 8L7, Canada.","IEEE Transactions on Systems, Man, and Cybernetics: Systems","","2019","PP","99","1","12","With the widespread application of service-oriented architecture (SOA), a flood of similarly functioning services have been deployed online. How to recommend services to users to meet their individual needs becomes the key issue in service recommendation. In recent years, methods based on collaborative filtering (CF) have been widely proposed for service recommendation. However, traditional CF typically exploits only low-dimensional and linear interactions between users and services and is challenged by the problem of data sparsity in the real world. To address these issues, inspired by deep learning, this article proposes a new deep CF model for service recommendation, named location-aware deep CF (LDCF). This model offers the following innovations: 1) the location features are mapped into high-dimensional dense embedding vectors; 2) the multilayer-perceptron (MLP) captures the high-dimensional and nonlinear characteristics; and 3) the similarity adaptive corrector (AC) is first embedded in the output layer to correct the predictive quality of service. Equipped with these, LDCF can not only learn the high-dimensional and nonlinear interactions between users and services but also significantly alleviate the data sparsity problem. Through substantial experiments conducted on a real-world Web service dataset, results indicate that LDCF's recommendation performance obviously outperforms nine state-of-the-art service recommendation methods.","","","10.1109/TSMC.2019.2931723","National Natural Science Foundation of China; Australian Research Council Discovery Project; Anhui Key Research and Development Plan; Natural Science Foundation of Anhui Province of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8805172","Collaborative filtering (CF);deep learning;service recommendation;similarity adaptive corrector (AC)","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Learning Representations for Neural Network-Based Classification Using the Information Bottleneck Principle","R. A. Amjad; B. C. Geiger","Institute for Communications Engineering, Technical University of Munich, Munich, Bavaria Germany (e-mail: ranaali.amjad@tum.de); Knowledge Discovery, Know-Center GmbH, Graz, Styria Austria (e-mail: geiger@ieee.org)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","In this theory paper, we investigate training deep neural networks (DNNs) for classification via minimizing the information bottleneck (IB) functional. We show that the resulting optimization problem suffers from two severe issues: First, for deterministic DNNs, either the IB functional is infinite for almost all values of network parameters, making the optimization problem ill-posed, or it is piecewise constant, hence not admitting gradient-based optimization methods. Second, the invariance of the IB functional under bijections prevents it from capturing properties of the learned representation that are desirable for classification, such as robustness and simplicity. We argue that these issues are partly resolved for stochastic DNNs, DNNs that include a (hard or soft) decision rule, or by replacing the IB functional with related, but more well-behaved cost functions. We conclude that recent successes reported about training DNNs using the IB framework must be attributed to such solutions. As a side effect, our results indicate limitations of the IB framework for the analysis of DNNs. We also note that rather than trying to repair the inherent problems in the IB functional, a better approach may be to design regularizers on latent representation enforcing the desired properties directly.","","","10.1109/TPAMI.2019.2909031","German Federal Ministry of Education and Research; Austrian Science Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8680020","deep learning;information bottleneck;representation learning;regularization;classification;neural networks;stochastic neural networks","Training;Task analysis;Robustness;Cost function;Neurons;Neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Synthesizing Supervision for Learning Deep Saliency Network without Human Annotation","D. Zhang; J. Han; Y. Zhang; D. Xu","School of Mechano-Electronic Engineering, Xidian University, 47905 Xian, Shaanxi China (e-mail: zdw2006yyy@mail.nwpu.edu.cn); School of Automation, Northwestern Polytechnical University, Xi'an, Shaanxi China (e-mail: junweihan2010@gmail.com); School of Automation, Xi'an, Shaanxi China (e-mail: zhangyuygss@mail.nwpu.edu.cn); School of Electrical and Information Engineering, The University of Sydney, Sydney, New South Wales Australia 2006 (e-mail: dong.xu@sydney.edu.au)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Salient object detection is undergoing a remarkable development along with the wide usage of deep neural networks. Being trained with a large number of images annotated with strong pixel-level ground-truth masks, deep salient object detectors have achieved state-of-the-art performance. However, it is expensive and time-consuming to provide pixel-level ground-truth masks for each training image. To address this problem, we propose a framework to learn deep salient object detectors without requiring any human annotation. The supervisory signals used in our learning framework are generated through a novel supervision synthesis scheme, in which the key insights are ""knowledge source transition"" and ""supervision by fusion"". In the proposed learning framework, both the external knowledge source and the internal knowledge source are explored to provide informative cues for synthesizing supervision required in our approach, while a two-stream fusion mechanism is established to implement the supervision synthesis process. Experiments on four datasets demonstrate that the deep salient object detector trained by our proposed learning framework works well without requiring any human annotated masks, which even approaches to its upper-bound obtained under the fully supervised learning fashion. Besides, we apply the salient object detector learnt with our proposed framework to weakly supervised semantic segmentation task.","","","10.1109/TPAMI.2019.2900649","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8645692","Salient object detection;Supervision synthesis;Annotation-free;Weakly supervised semantic segmentation","Object detection;Detectors;Training;Knowledge engineering;Task analysis;Semantics;Feature extraction","","","","","","","","","","IEEE","IEEE Early Access Articles"
"RFAL: Adversarial Learning for RF Transmitter Identification and Classification","D. Roy; T. Mukherjee; M. Chatterjee; E. Blasch; E. Pasiliao","Computer Science University of Central Florida Orlando, FL 32826.; Computer Science University of Alabama Huntsville, AL 35899.; Computer Science University of Central Florida Orlando, FL 32826.; NA; Munitions Directorate Air Force Research Laboratory Eglin AFB, FL, 32542.","IEEE Transactions on Cognitive Communications and Networking","","2019","PP","99","1","1","Recent advances in wireless technologies have led to several autonomous deployments of such networks. As nodes across distributed networks must co-exist, it is important that all transmitters and receivers are aware of their radio frequency (RF) surroundings so that they can adapt their transmission and reception parameters to best suit their needs. To this end, machine learning techniques have become popular as they can learn, analyze and predict the RF signals and associated parameters that characterize the RF environment. However, in the presence of adversaries, malicious activities such as jamming and spoofing are inevitable, making most machine learning techniques ineffective in such environments. In this paper we propose the Radio Frequency Adversarial Learning (RFAL) framework for building a robust system to identify rogue RF transmitters by designing and implementing a generative adversarial net (GAN). We hope to exploit transmitter specific “signatures” like the the in-phase (I) and quadrature (Q) imbalance (i.e., the I/Q imbalance) present in all transmitters for this task, by learning feature representations using a deep neural network that uses the I/Q data from received signals as input. After detection and elimination of the adversarial transmitters RFAL further uses this learned feature embedding as “fingerprints” for categorizing the trusted transmitters. More specifically, we implement a generative model that learns the sample space of the I/Q values of known transmitters and uses the learned representation to generate signals that imitate the transmissions of these transmitters. We program 8 universal software radio peripheral (USRP) software defined radios (SDRs) as trusted transmitters and collect “over-the-air” raw I/Q data from them using a Realtek Software Defined Radio (RTL-SDR), in a laboratory setting. We also implement a discriminator model that discriminates between the trusted transmitters and the counterfeit ones with 99.9% accuracy and is trained in the GAN framework using data from the generator. Finally, after elimination of the adversarial transmitters, the trusted transmitters are classified using a convolutional neural network (CNN), a fully connected deep neural network (DNN) and a recurrent neural network (RNN) to demonstrate building of an end-to-end robust transmitter identification system with RFAL. Experimental results reveal that the CNN, DNN, and RNN are able to correctly distinguish between the 8 trusted transmitters with 81.6%, 94.6% and 97% accuracy respectively. We also show that better “trusted transmission” classification accuracy is achieved for all three types of neural networks when data from two different types of transmitters (different manufacturers) are used rather than when using the same type of transmitter (same manufacturer).","","","10.1109/TCCN.2019.2948919","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8879545","RF fingerprinting;GAN;machine learning;convolutional neural network;deep neural network;recurrent neural network;I/Q imbalance;software defined radios.","Radio transmitters;Radio frequency;Gallium nitride;Data models;Generators;Artificial neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Person Re-identification with Deep Kronecker-Product Matching and Group-shuffling Random Walk","Y. Shen; T. Xiao; S. Yi; D. Chen; X. Wang; H. Li","Electronic Engineering, The Chinese University of Hong Kong, Hong Kong, Hong Kong Hong Kong (e-mail: ytshen@ee.cuhk.edu.hk); Facebook Oculus, San Jose, California United States (e-mail: tong.xiao.work@gmail.com); Electronic Engineering, The Chinese University of Hong Kong, hong kong, Hong Kong Hong Kong (e-mail: syi@ee.cuhk.edu.hk); SenseTime Research, Hong Kong, Hong Kong Hong Kong (e-mail: dpchen@ee.cuhk.edu.hk); Department of Electronic Engineering, The Chinese University of Hong Kong, Shatin, Hong Kong Hong Kong (e-mail: xgwang@ee.cuhk.edu.hk); Electronic Engineering, The Chinese University of Hong Kong, Shatin, N.T. Hong Kong (e-mail: hsli@ee.cuhk.edu.hk)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Person re-identification (re-ID) aims to robustly measure visual affinities between person images. It has wide applications in intelligent surveillance by associating same persons' images across multiple cameras. It is generally treated as an image retrieval problem: given a probe person image, the affinities between the probe image and gallery images (P2G affinities) are used to rank the retrieved gallery images. There exist two main challenges for effectively solving this problem. 1) Person images usually show significant variations because of different person poses and viewing angles. The spatial layouts and correspondences between person images are therefore vital information for tackling this problem. State-of-the-art methods either ignore such spatial variation or utilize extra pose information for handling the challenge. 2) Most existing person re-ID methods rank gallery images considering only P2G affinities but ignore the affinities between the gallery images (G2G affinity). Such affinities could provide important clues for accurate gallery image ranking but were only utilized in post-processing stages by current methods. In this paper, we propose a unified end-to-end deep learning framework to tackle the two challenges. For handling viewpoint and pose variations between compared person images, we propose a novel Kronecker Product Matching operation to match and warp feature maps of different persons. Comparing warped feature maps results in more accurate P2G affinities. To fully utilize all available P2G and G2G affinities for accurately ranking gallery person images, a novel group-shuffling random walk operation is proposed. Both Kronecker Product Matching and Group-shuffling Random Walk operations are end-to-end trainable and are shown to improve the learned visual features if integrated in the deep learning framework. The proposed approach outperforms state-of-the-art methods on Market-1501, CUHK03 and DukeMTMC datasets, which demonstrates the effectiveness and generalization ability of our proposed approach. Code is available at https://github.com/YantaoShen/kpm rw person reid.","","","10.1109/TPAMI.2019.2954313","General Research Fund of the Research Grants Council of Hong Kong; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8906139","Computer Vision;Deep Learning;Person Re-identification","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Audio Metric Learning by Using Siamese Autoencoders for One-Shot Human Fall Detection","D. Droghini; S. Squartini; E. Principi; L. Gabrielli; F. Piazza","Department of Information Engineering, Università Politecnica delle Marche, 60131, Ancona, Italy (e-mail: d.droghini@pm.univpm.it).; Department of Information Engineering, Università Politecnica delle Marche, 60131, Ancona, Italy (e-mail: s.squartini@univpm.it).; Department of Information Engineering, Università Politecnica delle Marche, 60131, Ancona, Italy (e-mail: e.principi@univpm.it).; Department of Information Engineering, Università Politecnica delle Marche, 60131, Ancona, Italy (e-mail: l.gabrielli@univpm.it).; Department of Information Engineering, Università Politecnica delle Marche, 60131, Ancona, Italy (e-mail: f.piazza@univpm.it).","IEEE Transactions on Emerging Topics in Computational Intelligence","","2019","PP","99","1","11","In the recent years, several supervised and unsupervised approaches to fall detection have been presented in the literature. These are generally based on a corpus of examples of human falls that are, though, hard to collect. For this reason, fall detection algorithms should be designed to gather as much information as possible from the few available data related to the type of events to be detected. The one-shot learning paradigm for expert systems training seems to naturally match these constraints, and this inspired the novel Siamese Neural Network (SNN) architecture for human fall detection proposed in this contribution. Acoustic data are employed as input, and the twin convolutional autoencoders composing the SNN are trained to perform a suitable metric learning in the audio domain and, thus, extract robust features to be used in the final classification stage. A large acoustic dataset has been recorded in three real rooms with different floor types and human falls performed by four volunteers, and then adopted for experiments. Obtained results show that the proposed approach, which only relies on two real human fall events in the training phase, achieves a F$_1$-Measure of 93.58% during testing, remarkably outperforming the recent supervised and unsupervised state-of-art techniques selected for comparison.","","","10.1109/TETCI.2019.2948151","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8891779","Human fall detection;Siamese neural networks (SNN);one-shot learning;deep learning;computational audio processing","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Learning-Based Mobile Edge Computing Resource Management to Support Public Blockchain Networks","A. Asheralieva; D. Niyato","Computer Science and Engineering, South University of Science and Technology, 255310 Shenzhen, Guangdong China (e-mail: aasheralieva@gmail.com); School of Computer Engineering, Nanyang Technological University, Singapore, Singapore Singapore 639798 (e-mail: dniyato@ntu.edu.sg)","IEEE Transactions on Mobile Computing","","2019","PP","99","1","1","We consider a public blockchain realized in the mobile edge computing (MEC) network, where the blockchain miners compete against each other to solve the proof-of-work puzzle and win a mining reward. Due to limited computing capabilities of their mobile terminals, miners offload computations to the MEC servers. The MEC servers are maintained by the service provider (SP) that sells its computing resources to the miners. The SP aims at maximizing its long-term profit subject to miners' budget constraints. The miners decide on their hash rates, i.e., computing powers, simultaneously and independently, to maximize their payoffs without revealing their decisions to other miners. As such, the interactions between the SP and miners are modeled as a stochastic Stackelberg game under private information, where the SP assigns the price per unit hash rate, and miners select their actions, i.e., hash rate decisions, without observing actions of other miners. We develop a hierarchical learning framework for this game based on fully- and partially-observable Markov decision models of the decision processes of the SP and miners. We show that the proposed learning algorithms converge to stable states in which miners' actions are the best responses to the optimal price assigned by the SP.","","","10.1109/TMC.2019.2959772","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933071","Blockchain;deep learning;game theory;incomplete information;Markov decision process;mining;mobile edge computing;partially-observable Markov decision process;reinforcement learning;resource management","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Classification of Isolated Volcano-Seismic Events Based on Inductive Transfer Learning","M. Titos; A. Bueno; L. García; C. Benítez; J. C. Segura","Teor ía de la señal, Telemática y Comunicaciones, Universidad de Granada, 18071 Granada, Spain (e-mail: mmtitos@ugr.es).; Teor ía de la señal, Telemática y Comunicaciones, Universidad de Granada, 18071 Granada, Spain.; Teor ía de la señal, Telemática y Comunicaciones, Universidad de Granada, 18071 Granada, Spain.; Teor ía de la señal, Telemática y Comunicaciones, Universidad de Granada, 18071 Granada, Spain.; Teor ía de la señal, Telemática y Comunicaciones, Universidad de Granada, 18071 Granada, Spain.","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","Domain-specific problems where data collection is an expensive task are often represented by scarce or incomplete data. From a machine learning perspective, this type of problems has been addressed using models trained in different specific domains as the starting point for the final objective-model. The transfer of knowledge between domains, known as transfer learning (TL), helps to speed up training and improve the performance of the models in problems with limited amounts of data. In this letter, we introduce a TL approach to classify isolated volcano-seismic signals at ``Volcán de Fuego'', Colima (Mexico). Using the well-known convolutional architecture (LeNet) as a feature extractor and a representative data set containing regional earthquakes, volcano-tectonic earthquakes, long-period events, volcanic tremors, explosions, and collapses, our proposal compares the generalization capabilities of the models when we only fine-tune the upper layers and fine-tune overall of them. Compared with the other state-of-the-art techniques, classification systems based on TL approaches provide good generalization capabilities (attaining nearly 94% of events correctly classified) and decreasing computational time resources.","","","10.1109/LGRS.2019.2931063","Ministerio de Economía y Empresa MINECO Fondo Europeo de Desarrollo Regional FEDER; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798707","Classification of isolated events;deep learning;transfer learning (TL);volcano-seismic signals.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Evolutionary Compression of Deep Neural Networks for Biomedical Image Segmentation","Y. Zhou; G. G. Yen; Z. Yi","College of Computer Science, Sichuan University, Chengdu 610065, China.; School of Electrical and Computer Engineering, Oklahoma State University, Stillwater, OK 74078 USA (e-mail: gyen@okstate.edu).; College of Computer Science, Sichuan University, Chengdu 610065, China.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","14","Biomedical image segmentation is lately dominated by deep neural networks (DNNs) due to their surpassing expert-level performance. However, the existing DNN models for biomedical image segmentation are generally highly parameterized, which severely impede their deployment on real-time platforms and portable devices. To tackle this difficulty, we propose an evolutionary compression method (ECDNN) to automatically discover efficient DNN architectures for biomedical image segmentation. Different from the existing studies, ECDNN can optimize network loss and number of parameters simultaneously during the evolution, and search for a set of Pareto-optimal solutions in a single run, which is useful for quantifying the tradeoff in satisfying different objectives, and flexible for compressing DNN when preference information is uncertain. In particular, a set of novel genetic operators is proposed for automatically identifying less important filters over the whole network. Moreover, a pruning operator is designed for eliminating convolutional filters from layers involved in feature map concatenation, which is commonly adopted in DNN architectures for capturing multi-level features from biomedical images. Experiments carried out on compressing DNN for retinal vessel and neuronal membrane segmentation tasks show that ECDNN can not only improve the performance without any retraining but also discover efficient network architectures that well maintain the performance. The superiority of the proposed method is further validated by comparison with the state-of-the-art methods.","","","10.1109/TNNLS.2019.2933879","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8836098","Biomedical image segmentation;deep neural networks (DNNs);evolutionary algorithm (EA);multiobjective optimization.","Biomedical imaging;Image segmentation;Image coding;Biological system modeling;Task analysis;Computer architecture;Biological neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Six-DOF Spacecraft Optimal Trajectory Planning and Real-Time Attitude Control: A Deep Neural Network-Based Approach","R. Chai; A. Tsourdos; A. Savvaris; S. Chai; Y. Xia; C. L. P. Chen","School of Aerospace, Transport and Manufacturing, Cranfield University, Bedford MK43 0AL, U.K. (e-mail: r.chai@cranfield.ac.uk).; School of Aerospace, Transport and Manufacturing, Cranfield University, Bedford MK43 0AL, U.K..; School of Aerospace, Transport and Manufacturing, Cranfield University, Bedford MK43 0AL, U.K..; School of Automation, Beijing Institute of Technology, Beijing 100811, China.; School of Automation, Beijing Institute of Technology, Beijing 100811, China.; Faculty of Science and Technology, University of Macau, Macau 999078, China, also with the Department of Navigation, Dalian Maritime University, Dalian 116026, China, and also with the State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing 100080, China.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","9","This brief presents an integrated trajectory planning and attitude control framework for six-degree-of-freedom (6-DOF) hypersonic vehicle (HV) reentry flight. The proposed framework utilizes a bilevel structure incorporating desensitized trajectory optimization and deep neural network (DNN)-based control. In the upper level, a trajectory data set containing optimal system control and state trajectories is generated, while in the lower level control system, DNNs are constructed and trained using the pregenerated trajectory ensemble in order to represent the functional relationship between the optimized system states and controls. These well-trained networks are then used to produce optimal feedback actions online. A detailed simulation analysis was performed to validate the real-time applicability and the optimality of the designed bilevel framework. Moreover, a comparative analysis was also carried out between the proposed DNN-driven controller and other optimization-based techniques existing in related works. Our results verify the reliability of using the proposed bilevel design for the control of HV reentry flight in real time.","","","10.1109/TNNLS.2019.2955400","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8939337","Attitude control;bilevel structure;deep neural network (DNN);six-degree-of-freedom (6-DOF) hypersonic vehicle (HV);trajectory planning.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Comprehensive Analysis of Deep Regression","S. Lathuiliére; P. Mesejo; X. Alameda-Pineda; R. Horaud","perception, Inria Centre de Recherche Grenoble Rhone-Alpes, 56521 Montbonnot, isère France 38334 (e-mail: stephane.lathuiliere@inria.fr); Perception, Inria Centre de Recherche Grenoble Rhone-Alpes, 56521 Montbonnot, Rhône-Alpes France (e-mail: pablo.mesejo-santiago@inria.fr); INRIA Grenoble Rhone-Alpes, INRIA, Monbonnot Saint-Martin, Isere France (e-mail: Xavier.Alameda-Pineda@inria.fr); INRIA Rhone-Alpes, INRIA, Montbonnot Saint-Martin, Rhone-Alpes France 38330 (e-mail: radu.horaud@inria.fr)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Deep learning revolutionized data science, and recently its popularity has grown exponentially, as did the amount of papers employing deep networks. Vision tasks, such as human pose estimation, did not escape from this trend. There is a large number of deep models, where small changes in the network architecture, or in the data pre-processing, together with the stochastic nature of the optimization procedures, produce notably different results, making extremely difficult to sift methods that significantly outperform others. This situation motivates the current study, in which we perform a systematic evaluation and statistical analysis of vanilla deep regression, i.e. convolutional neural networks with a linear regression top layer. This is the first comprehensive analysis of deep regression techniques. We perform experiments on four vision problems, and report confidence intervals for the median performance as well as the statistical significance of the results, if any. Surprisingly, the variability due to different data pre-processing procedures generally eclipses the variability due to modifications in the network architecture. Our results reinforce the hypothesis according to which, in general, a general-purpose network (e.g. VGG-16 or ResNet-50) adequately tuned can yield results close to the state-of-the-art without having to resort to more complex and ad-hoc regression models.","","","10.1109/TPAMI.2019.2910523","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8686063","Deep Learning;Regression;Computer Vision;Convolutional Neural Networks;Statistical Significance;Empirical and Systematic Evaluation;Head-Pose Estimation;Full-Body Pose Estimation;Facial Landmark Detection","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Human Action Recognition Using Deep Multilevel Multimodal (M2) Fusion of Depth and Inertial Sensors","Z. Ahmad; N. Khan","NA; NA","IEEE Sensors Journal","","2019","PP","99","1","1","Multimodal fusion frameworks for Human Action Recognition (HAR) using depth and inertial sensor data have been proposed over the years. In most of the existing works, fusion is performed at a single level (feature level or decision level), missing the opportunity to fuse rich mid-level features necessary for better classification. To address this shortcoming, in this paper, we propose three novel deep multilevel multimodal (M2) fusion frameworks to capitalize on different fusion strategies at various stages and to leverage the superiority of multilevel fusion. At input, we transform the depth data into depth images called sequential front view images (SFIs) and inertial sensor data into signal images. Each input modality, depth and inertial, is further made multimodal by taking convolution with the Prewitt filter. Creating “modality within modality” enables further complementary and discriminative feature extraction through Convolutional Neural Networks (CNNs). CNNs are trained on input images of each modality to learn low-level, high-level and complex features. Learned features are extracted and fused at different stages of the proposed frameworks to combine discriminative and complementary information. These highly informative features are served as input to a multi-class Support Vector Machine (SVM). We evaluate the proposed frameworks on three publicly available multimodal HAR datasets, namely, UTD Multimodal Human Action Dataset (MHAD), Berkeley MHAD, and UTD-MHAD Kinect V2. Experimental results show the supremacy of the proposed fusion frameworks over existing methods.","","","10.1109/JSEN.2019.2947446","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8869853","Canonical correlation analysis;fusion of depth and inertial sensors;human action recognition;multimodal fusion","Feature extraction;Sensor fusion;Deep learning;Image sensors;Cameras;Wearable sensors","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Vision-based Freezing of Gait Detection with Anatomic Directed Graph Representation","K. Hu; Z. Wang; S. Mei; K. Ehgoetz; T. Yao; S. Lewis; D. Feng","School of Computer Science, The University of Sydney, Sydney, New South Wales Australia 2006 (e-mail: hukun_sdu@hotmail.com); School of Computer Science, The University of Sydney, Sydney, New South Wales Australia (e-mail: zhiyong.wang@sydney.edu.au); School of Electronics and Information, Northwestern Polytech Univ, Xi'an China 710072 (e-mail: meish@nwpu.edu.cn); Parkinson's Disease Research Clinic, Brain and Mind Centre, The University of Sydney, Sydney, New South Wales Australia (e-mail: kaylena.ehgoetzmartens@sydney.edu.au); College of Information Science and Technology, Dalian Maritime University, Dalian China (e-mail: ytt1030@dlmu.edu.cn); Parkinson's Disease Research Clinic, Brain and Mind Centre, The University of Sydney, Sydney, New South Wales Australia (e-mail: simon.lewis@sydney.edu.au); School of Computer Science, The University of Sydney, Sydney, New South Wales Australia (e-mail: dagan.feng@sydney.edu.au)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","Parkinson's disease significantly impacts the life quality of millions of people around the world. While freezing of gait (FoG) is one of the most common symptoms of the disease, it is time-consuming and subjective to assess FoG for well-trained experts. Therefore, it is highly desirable to devise computer-aided FoG detection methods for the purpose of objective and time-efficient assessment. In this study, in line with the gold standard of FoG clinical assessment which requires video or direct observation, we propose one of the first vision-based methods for automatic FoG detection. To better characterize FoG patterns, instead of learning an overall representation of a video, we propose a novel architecture of graph convolution neural network and represent each video as a directed graph where FoG related candidate regions are the vertices. A weakly-supervised learning strategy and a weighted adjacency matrix estimation layer are proposed to eliminate the resource expensive data annotation required for fully supervised learning. As a result, the interference of visual information irrelevant to FoG, such as gait motion of supporting staff involved in clinical assessments, has been reduced to improve FoG detection performance by identifying the vertices contributing to FoG events. To further improve the performance, the global context of a clinical video is also considered and several fusion strategies with graph predictions are investigated. Experimental results on more than 100 videos collected from 45 patients during a clinical assessment demonstrated promising performance of our proposed method with an AUC of 0.887.","","","10.1109/JBHI.2019.2923209","NHMRC-ARC Dementia Fellowship; Sydney Research Excellence Initiative 2020; Australian Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8737782","Parkinson's disease;freezing of gait detection;deep learning;graph convolution neural network","Deep learning;Convolution;Feature extraction;Diseases;Task analysis;Computer architecture;Estimation","","","","","","","","","","IEEE","IEEE Early Access Articles"
"First Arrival Time Identification Using Transfer Learning With Continuous Wavelet Transform Feature Images","X. Liao; J. Cao; J. Hu; J. You; X. Jiang; Z. Liu","State Key Laboratory of Oil and Gas Reservoir Geology and Exploitation, Chengdu University of Technology, Chengdu 610059, China.; State Key Laboratory of Oil and Gas Reservoir Geology and Exploitation, Chengdu University of Technology, Chengdu 610059, China (e-mail: caojx@cdut.edu.cn).; State Key Laboratory of Oil and Gas Reservoir Geology and Exploitation, Chengdu University of Technology, Chengdu 610059, China.; State Key Laboratory of Oil and Gas Reservoir Geology and Exploitation, Chengdu University of Technology, Chengdu 610059, China.; State Key Laboratory of Oil and Gas Reservoir Geology and Exploitation, Chengdu University of Technology, Chengdu 610059, China.; State Key Laboratory of Oil and Gas Reservoir Geology and Exploitation, Chengdu University of Technology, Chengdu 610059, China.","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","In our work, the deep learning technique has been used to develop an automatic method for identifying the first arrival times of seismic waves. This method introduces transfer learning to train a deep neural network, given a limited number of continuous wavelet transform (CWT) feature images as input. The application of the CWT for feature extraction, aimed at detecting abrupt changes in the amplitude, phase, and frequency produced by first arrivals as a whole rather than any single characteristic, provides the most informative images. First, we apply the CWT to each seismic trace to obtain the CWT feature images and split them into a set of subimages. Then, a pretrained convolutional neural network (CNN) is fine-tuned with limited labeled subimages. The resulting model can be used to predict probability distributions of noise, first-break, and post first-break. Finally, the first arrival times are extracted from the peaks of the probability distributions. We have tested the performance of the method using vibroseis, dynamite, and air gun shot records, which include various types of seismic waves and noise. More accurate and robust results can be obtained with the proposed method compared with the short-time and long-time average (STA/LTA) algorithm and the adaptive multiband picking algorithm (AMPA).","","","10.1109/LGRS.2019.2955950","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8936510","Continuous wavelet transform (CWT);first arrival time;transfer learning.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Graph Embedded Convolutional Neural Networks in Human Crowd Detection for Drone Flight Safety","M. Tzelepi; A. Tefas","Department of Informatics, Aristotle University of Thessaloniki, Thessaloniki 54124, Greece (e-mail: mtzelepi@csd.auth.gr).; Department of Informatics, Aristotle University of Thessaloniki, Thessaloniki 54124, Greece (e-mail: tefas@csd.auth.gr).","IEEE Transactions on Emerging Topics in Computational Intelligence","","2019","PP","99","1","14","In this paper, we propose a novel human crowd detection method that uses deep convolutional neural networks for drone flight safety purposes. The first contribution of this paper is to provide lightweight architectures, as restricted by the computational capacity of the specific application, capable of effectively distinguishing between crowded and non-crowded scenes from drone-captured images, and provide crowd heatmaps which can be used to semantically enrich the flight maps by defining no-fly zones. The second contribution of this paper is to propose a novel generic regularization technique, based on the graph embedding framework, applicable to different deep architectures for generic classification problems. The experimental validation is performed on a new dataset constructed for the task of human crowd detection from drone-captured images, and indicates the effectiveness of the proposed detector, as well as of the proposed regularizers in terms of classification accuracy. Finally, since the proposed regularization scheme is applicable in generic classification problems, we have also conducted experiments on two additional datasets, where the enhanced performance of the regularizers is also validated.","","","10.1109/TETCI.2019.2897815","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8657776","Drones;crowd detection;deep learning;regularization;graph embedding;convolutional neural networks","Drones;Deep learning;Task analysis;Safety;Computational modeling;Germanium;Convolutional neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Cooperative Management for PV/ESS-Enabled Electric-Vehicle Charging Stations: A Multi-Agent Deep Reinforcement Learning Approach","M. Shin; D. Choi; J. Kim","Chung-Ang University, 26729 Seoul, Seoul Korea (the Republic of) 06974 (e-mail: mjshin.cau@gmail.com); Department of Electronic and Electrical Engineering, Chung-Ang University, 26729 Seoul, Seoul Korea (the Republic of) 06974 (e-mail: dhchoi@cau.ac.kr); School of Electrical Engineering, Korea University, 34973 Seongbuk-gu, Seoul Korea (the Republic of) 02841 (e-mail: joongheon@korea.ac.kr)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","This paper proposes a novel multi-agent deep reinforcement learning method for the energy management of distributed electric vehicle charging stations with a solar photovoltaic system and energy storage system. In the literature, the conventional method is to calculate the optimal electric vehicle charging schedule in a centralized manner. However, in general, the centralized approach is not realistic under certain environments where the system operators for multiple electric vehicle charging stations handle dynamically varying data, such as the status of the energy storage system and electric vehicle-related information. Therefore, this paper proposes a method that can compute the scheduling solutions of multiple electric vehicle charging stations in a distributed manner while handling run-time time-varying dynamic data. As shown in the data-intensive performance evaluation, it can be observed that the proposed method achieves a desirable performance in terms of reducing the operation costs of electric vehicle charging stations.","","","10.1109/TII.2019.2944183","Korea government Ministry of Trade Industry and Energy; National Research Foundation of Korea; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8851270","","Electric vehicle charging;Optimization;Reinforcement learning;Companies;Energy management;Multi-agent systems;Planning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Adaptive Image Sampling using Deep Learning and its Application on X-Ray Fluorescence Image Reconstruction","Q. Dai; H. Chopp; E. Pouyet; O. Cossairt; M. Walton; A. Katsaggelos","Electrical Engineering and Computer Science, Northwestern University, Evanston, Illinois United States (e-mail: qiqindai2012@u.northwestern.edu); Electrical Engineering and Computer Science, Northwestern University, Chicago, Illinois United States (e-mail: HenryChopp2017@u.northwestern.edu); Center For Scientific Studies In The Arts, Northwestern University, Chicago, Illinois United States (e-mail: emeline.pouyet@northwestern.edu); Electrical Engineering and Computer Science, Northwestern University, Chicago, Illinois United States (e-mail: ollie@eecs.northwestern.edu); Mccormick School of Engineering and Applied Science - Materials Science, Northwestern University, Chicago, Illinois United States (e-mail: marc.walton@northwestern.edu); Electrical Engineering and Computer Science, Northwestern University, Chicago, Illinois United States (e-mail: aggk@eecs.northwestern.edu)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","This paper presents an adaptive image sampling algorithm based on Deep Learning (DL). It consists of an adaptive sampling mask generation network which is jointly trained with an image inpainting network. The sampling rate is controlled by the mask generation network, and a binarization strategy is investigated to make the sampling mask binary. In addition to the image sampling and reconstruction process, we show how it can be extended and used to speed up raster scanning such as the X-Ray fluorescence (XRF) image scanning process. Recently XRF laboratory-based systems have evolved into lightweight and portable instruments thanks to technological advancements in both X-Ray generation and detection. However, the scanning time of an XRF image is usually long due to the long exposure requirements (e.g., ${100 \mu s-1ms}$ per point). We propose an XRF image inpainting approach to address the long scanning times, thus speeding up the scanning process, while being able to reconstruct a high quality XRF image. The proposed adaptive image sampling algorithm is applied to the RGB image of the scanning target to generate the sampling mask. The XRF scanner is then driven according to the sampling mask to scan a subset of the total image pixels. Finally, we inpaint the scanned XRF image by fusing the RGB image to reconstruct the full scan XRF image. The experiments show that the proposed adaptive sampling algorithm is able to effectively sample the image and achieve a better reconstruction accuracy than that of existing methods.","","","10.1109/TMM.2019.2958760","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8930037","Adaptive sampling;convolutional neural network;X-Ray fluorescence;inpainting","Image reconstruction;Image sampling;Imaging;X-ray imaging;Machine learning;Spatial resolution","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Semi-Supervised Multi-Modal Multi-Instance Multi-Label Deep Network with Optimal Transport","Y. Yang; Z. Fu; D. Zhan; Z. Liu; Y. Jiang","National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, JIANGSU China 210023 (e-mail: yangy@lamda.nju.edu.cn); Computer Science and Technology, Nanjing University, Nanjing, Jiangsu China (e-mail: fuzy@lamda.nju.edu.cn); Computer Science Department, Nanjing University, Nanjing, Jiangsu China 210093 (e-mail: zhandc@nju.edu.cn); WXG, Tecent, Shenzhen, Guangdong China (e-mail: lewiszbliu@tencent.com); Department of Computer Science & Technology, Nanjing University, Nanjing, Jiangsu China 210046 (e-mail: jiangy@lamda.nju.edu.cn)","IEEE Transactions on Knowledge and Data Engineering","","2019","PP","99","1","1","Complex objects are usually with multiple labels, and can be represented by multiple modal representations, e.g., the complex articles contain text and image information as well as multiple annotations. Previous methods assume that the homogeneous multi-modal data are consistent, while in real applications, the raw data are disordered, e.g., the article constitutes with variable number of inconsistent text and image instances. Therefore, Multi-modal Multi-instance Multi-label (M3) learning provides a framework for handling such task and has exhibited excellent performance. However, M3 learning is facing two main challenges: 1) how to effectively utilize label correlation; 2) how to take advantage of multi-modal learning to process unlabeled instances. To solve these problems, we first propose a novel Multi-modal Multi-instance Multi-label Deep Network (M3DN), which considers M3 learning in an end-to-end multi-modal deep network and utilizes consistency principle among different modal bag-level predictions. Based on the M3DN, we learn the latent ground label metric with the optimal transport. Moreover, we introduce the extrinsic unlabeled multi-modal multi-instance data, and propose the M3DNS, which considers the instance-level auto-encoder for single modality and modified bag-level optimal transport to strengthen the consistency among modalities. Thereby M3DNS can better predict label and exploit label correlation simultaneously.","","","10.1109/TKDE.2019.2932666","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8786171","Semi-supervised Learning;Multi-Modal Multi-Instance Multi-label Learning;Modal consistency;Optimal Transport","Correlation;Measurement;Games;Task analysis;Bayes methods;Acceleration;Data models","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Practical Device-Free Gesture Recognition Using WiFi Signals Based on Meta-Learning","X. Ma; Y. Zhao; L. Zhang; Q. Gao; M. Pan; J. Wang","School of Electronic Science and Technology, DaLian University of Technology, Dalian China 116024 (e-mail: maxr@dlut.edu.cn); School of Electronic Science and Technology, DaLian University of Technology, Dalian China 116024 (e-mail: zhaoyunong@mail.dlut.edu.cn); School of Electronic Science and Technology, DaLian University of Technology, Dalian China 116024 (e-mail: zhangliang123@mail.dlut.edu.cn); School of Electronic Science and Technology, Dalian University of Technology, Dalian, Liaoning China 116023 (e-mail: qhgao@dlut.edu.cn); Department of Electrical and Computer Engineering, University of Houston, Houston United States 77004 (e-mail: mpan2@uh.edu); School of Information Science and Technology, Dalian Maritime University, 12421 Dalian, Liaoning China 116021 (e-mail: wangjie@dlut.edu.cn)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","Device-free gesture recognition (DFGR) is a promising sensing technique which could recognize a gesture by analyzing its influence on surrounding wireless signals. Most of DFGR systems are designed based on machine learning. However, the recognition performance will drop dramatically when the testing condition is different with the training one. Inspired by the transferrable knowledge learning ability of humans, this paper develops a practical DFGR system based on meta-learning to solve the aforementioned problem. Specifically, we design a deep network which could not only learn discriminative deep features, but also learn a transferrable similarity evaluation ability from the training set and apply the learned knowledge to the new testing conditions. Extensive experiments conducted by four users in two scenarios demonstrate that the proposed system could recognize new types of gestures, or gestures performed in new conditions, with an accuracy of more than 90%, using very few number of new samples.","","","10.1109/TII.2019.2909877","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8684900","Device-free;wireless sensing;gesture recognition;deep network;machine learning","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"TrafficGAN: Network-Scale Deep Traffic Prediction With Generative Adversarial Nets","Y. Zhang; S. Wang; B. Chen; J. Cao; Z. Huang","College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing 211106, China.; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing 211106, China, and also with the Department of Computing, The Hong Kong Polytechnic University, Hong Kong, China (e-mail: szwang@nuaa.edu.cn).; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing 211106, China.; Department of Computing, The Hong Kong Polytechnic University, Hong Kong, China.; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing 211106, China.","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","12","Traffic flow prediction has received rising research interest recently since it is a key step to prevent and relieve traffic congestion in urban areas. Existing methods mostly focus on road-level or region-level traffic prediction, and fail to deeply capture the high-order spatial-temporal correlations among the road links to perform a road network-level prediction. In this paper, we propose a network-scale deep traffic prediction model called TrafficGAN, in which Generative Adversarial Nets (GAN) is utilized to predict traffic flows under an adversarial learning framework. To capture the spatial-temporal correlations among the road links of a road network, both Convolutional Neural Nets (CNN) and Long-Short Term Memory (LSTM) models are embedded into TrafficGAN. In addition, we also design a deformable convolution kernel for CNN to make it better handle the input road network data. We extensively evaluate our proposal over two large GPS probe datasets in the arterial road network of downtown Chicago and Bay Area of California. The results show that TrafficGAN significantly outperforms both traditional statistical models and state-of-the-art deep learning models in network-scale short-term traffic flow prediction.","","","10.1109/TITS.2019.2955794","National Key Research and Development Program of China; Hong Kong Innovation and Technology Fund; National Natural Science Foundation of China; Natural Science Foundation of Jiangsu Province of China; China Computer Federation CCF-Tencent Open Research Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8935152","Traffic prediction;generative adversarial nets;deep learning.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"View-based 3D CAD Model Retrieval with Deep Residual Networks","C. Zhang; G. Zhou; H. Yang; Z. Xiao; X. Yang","School of Mechanical Engineering, Xi'an Jiaotong University, Xi'an China 710049 (e-mail: superzc@stu.xjtu.edu.cn); School of Mechanical Engineering, Xi'an Jiaotong University, Xi'an, Shaanxi China 710049 (e-mail: ghzhou@mail.xjtu.edu.cn); School of Electromechanical Engineering, Guangdong University of Technology, 47870 Guangzhou, Guangdong China 510006 (e-mail: yanghd@gdut.edu.cn); School of Management, Xi'an Jiaotong University, Xi'an China 710049 (e-mail: xzd@mail.xjtu.edu.cn); School of Mechanical Engineering, Xi'an Jiaotong University, Xi'an China 710049 (e-mail: yxj199512@stu.xjtu.edu.cn)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","In industrial enterprises, effective retrieval and reuse of three-dimensional (3D) computer-aided design (CAD) models could greatly save time and cost in new product development and manufacturing. Consequently, this paper proposes a novel view-based approach for 3D CAD model retrieval enabled by deep learning. The paper constructs a multi-view model dataset in industrial domain that collects solid and line views of database models. Since views contain rich information for differentiating these models, the problem of model retrieval is defined as a view recognition problem. Then, the extended deep residual networks (ResNets) are successfully trained to facilitate the model retrieval. With the learned networks, engineers could take a group of views, an engineering drawing or even a hand-drawn sketch that represents their query intents as input and acquire the relevant 3D CAD models and embedded knowledge for product lifecycle reuse. The experimental results demonstrate the effectiveness and efficiency of the approach.","","","10.1109/TII.2019.2943195","Fundamental Research Funds for the Central Universities; Natural Science Basic Research Plan in Shaanxi Province of China; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8846765","Three-dimensional (3D) CAD model;deep learning;view-based approach;residual networks;model retrieval","Solid modeling;Three-dimensional displays;Computational modeling;Semantics;Design automation;Manufacturing","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Follow the Sound of Children’s Heart: A Deep Learning-based Computer-aided Pediatric CHDs Diagnosis System","B. Xiao; Y. Xu; X. Bi; W. Li; Z. Ma; J. Zhang; X. Ma","Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, China.; Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, China.; Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, China.; Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, China.; School of Cybernetics, Xidian University, China.; First Affiliated Hospital of Chongqing Medical University.; Human Genetics Resource Center, National Research Institute for Family Planning, China.","IEEE Internet of Things Journal","","2019","PP","99","1","1","Auscultation of heart sounds is a non-invasive and less costly way for congenital heart disease diagnosis, especially for pediatric individuals. The deep learning-based computer-aided heart sound analysis has been widely studied and developed in recent years. In this paper, we develop a deep learning-based computer-aided system for pediatric congenital heart diseases (CHDs) diagnosis using two novel light-weight convolution neural networks (CNNs). One key issue of most existing deep learning-based systems is the scarcity of large-scale datasets for CNN learning. To this end, we collect heart sounds from newborns and children with physicians’ annotations to construct a pediatric heart sound dataset that contains 528 high quality recordings (nearly 4 hours in total) from 137 subjects. With the constructed dataset, deep CNN models can be easily trained as classifiers in computer-aided CHDs diagnosis systems. Experimental results demonstrate the superiority of our proposed methods in terms of diagnosis performance and parameter consumption in the application of internet of things.","","","10.1109/JIOT.2019.2961132","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8937772","Pediatric congenital heart diseases;heart sound;computer aided diagnosis;convolution neural networks.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Efficient and Privacy-enhanced Federated Learning for Industrial Artificial Intelligence","M. Hao; H. Li; X. Luo; G. Xu; H. Yang; S. Liu","Chengdu, sichuan province China 611731 (e-mail: menghao_0303@foxmail.com); UESTC, Chengdu China 611731 (e-mail: hongweili@uestc.edu.cn); Suzhou China 215006 (e-mail: xzluo@suda.edu.cn); Chengdu China 611731 (e-mail: guowen.xu@foxmail.com); University of Electronic Science and Technology of China, 12599 Chengdu China 611731 (e-mail: haomyang@uestc.edu.cn); Chengdu China 611731 (e-mail: senliu95@163.com)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","By leveraging deep learning-based technologies, industrial artificial intelligence (IAI) has been applied to solve various industrial challenging problems in Industry 4.0. However, for privacy reasons, traditional centralized training may be unsuitable for sensitive data-driven industrial scenarios, such as healthcare and autopilot. Recently, federated learning (FL) has received widespread attention since it enables participants to collaboratively learn a shared model without revealing their local data. However, studies have shown that, by exploiting the shared parameters adversaries can still compromise industrial applications such as auto-driving navigation systems, medical data in wearable devices and industrial robots' decision-making. To solve this problem, we propose an efficient and Privacy-Enhanced Federated Learning (PEFL) scheme for IAI. Compared with existing solutions, PEFL is non-interactive, and can prevent private data from being leaked even if multiple entities collude with each other. Moreover, extensive experiments with real-world data demonstrate the superiority of PEFL in terms of accuracy and efficiency.","","","10.1109/TII.2019.2945367","National Natural Science Foundation of China; National Key R and D Program of China; Guangxi Key Laboratory of Cryptography and Information Security; Peng Cheng Laboratory Project of Guangdong Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8859260","Industrial Artificial Intelligence;Federated Learning;Privacy Protection","Training;Privacy;Cloud computing;Servers;Differential privacy;Informatics","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Multialgorithm Fusion Image Processing for High Speed Railway Dropper Failure-Defect Detection","P. Tan; X. Li; Z. Wu; J. Ding; J. Ma; Y. Chen; Y. Fang; Y. Ning","School of Automation and Electrical Engineering, Zhejiang University of Science and Technology, Hangzhou 310023, China.; School of Mechanical and Energy Engineering, Zhejiang University of Science and Technology, Hangzhou 310023, China.; College of Control Science and Engineering, Zhejiang University, Hangzhou 310027, China (e-mail: nashwzhg@zju.edu.cn).; School of Automation and Electrical Engineering, Zhejiang University of Science and Technology, Hangzhou 310023, China.; Research Institute of Western China Development, Zhejiang University, Hangzhou 310027, China (e-mail: majien@zju.edu.cn).; Research Center for High Speed Railway, Zhejiang University, Hangzhou 310027, China.; College of Electrical Engineering, Zhejiang University, Hangzhou 310027, China.; School of Automation and Electrical Engineering, Zhejiang University of Science and Technology, Hangzhou 310023, China.","IEEE Transactions on Systems, Man, and Cybernetics: Systems","","2019","PP","99","1","13","The dropper is one of the core components of the high speed railway catenary and dropper failure will lead to serious transportation accidents. It is very important to carry out dropper failure and defect detection. There are a large number of droppers installed in the catenary. The dropper images are collected by the high-definition camera installed on the top of the moving catenary inspection vehicles. The image quality and image consistency are poor, and it is very difficult to identify dropper defects automatically. The railway department and companies lack efficient and intelligent detection methods. This article innovatively proposes a multialgorithm fusion image processing technology, and builds a dropper recognition and failure-defect detection model based on a deep learning algorithm and subpixel level dropper defect detection model, and achieves high accuracy dropper failure and defect detection. The detection model based on the Faster R-CNN algorithm is studied to realize the positioning and recognition of the dropper and the failure detection of bending slack and broken dropper. The subpixel level dropper defect detection algorithm is based on the fusion of the image preprocessing, dropper fine positioning algorithm, edge fitting and bending zoom algorithms, the Hough transform algorithm, and so on. These can be used to realize detection of defects, such as microdeformation, dropper-strands loosened, dropper-strands broken, and foreign body adhesions. The test is verified by the catenary images taken from a practical high speed railway. The detection accuracy, real-time performance, and stability of the algorithm meet the needs of inspection and maintenance for a high speed railway.","","","10.1109/TSMC.2019.2938684","National Natural Science Foundation of China; Natural Science Foundation of Zhejiang Province China; National Key Research and Development Program of China; China Scholarship Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8842615","Deep learning;failure and defect detection;faster R-CNN;high speed railway dropper;image process;multialgorithm fusion","Rail transportation;Inspection;Maintenance engineering;Wires;Deep learning;Feature extraction","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Feature Pyramid and Hierarchical Boosting Network for Pavement Crack Detection","F. Yang; L. Zhang; S. Yu; D. Prokhorov; X. Mei; H. Ling","Department of Computer and Information Sciences, Temple University, Philadelphia, PA 19122 USA.; Department of Radiology, University of Pittsburgh, Pittsburgh, PA 15213 USA.; Department of Computer and Information Sciences, Temple University, Philadelphia, PA 19122 USA.; Toyota Research Institute, Ann Arbor, MI 48105 USA.; Toyota Technical Center Division, Department of Future Mobility Research, Toyota Research Institute, Ann Arbor, MI 48105 USA.; Department of Computer and Information Sciences, Temple University, Philadelphia, PA 19122 USA (e-mail: hbling@temple.edu).","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","11","Pavement crack detection is a critical task for insuring road safety. Manual crack detection is extremely time-consuming. Therefore, an automatic road crack detection method is required to boost this progress. However, it remains a challenging task due to the intensity inhomogeneity of cracks and complexity of the background, e.g., the low contrast with surrounding pavements and possible shadows with a similar intensity. Inspired by recent advances of deep learning in computer vision, we propose a novel network architecture, named feature pyramid and hierarchical boosting network (FPHBN), for pavement crack detection. The proposed network integrates context information to low-level features for crack detection in a feature pyramid way, and it balances the contributions of both easy and hard samples to loss by nested sample reweighting in a hierarchical way during training. In addition, we propose a novel measurement for crack detection named average intersection over union (AIU). To demonstrate the superiority and generalizability of the proposed method, we evaluate it on five crack datasets and compare it with the state-of-the-art crack detection, edge detection, and semantic segmentation methods. The extensive experiments show that the proposed method outperforms these methods in terms of accuracy and generalizability. Code and data can be found in https://github.com/fyangneil/pavement-crack-detection.","","","10.1109/TITS.2019.2910595","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8694955","Pavement crack detection;deep learning;feature pyramid;hierarchical boosting.","Feature extraction;Image edge detection;Deep learning;Boosting;Task analysis;Semantics;Wavelet transforms","","","","3","","","","","","IEEE","IEEE Early Access Articles"
"A Convolutional Neural Network System to Discriminate Drug-Target Interactions","S. Hu; D. Xia; B. Su; P. Chen; B. Wang; J. Li","Hefei, Anhui China (e-mail: pchen78@163.com); Hefei, Anhui China (e-mail: 79052693@qq.com); Computer and Information, Anqing Normal University, 118432 Anqing, Anhui China (e-mail: bysu@aqnu.edu.cn); Chinese Academy of Sciences, Institute of Intelligent Machines, Hefei, Anhui China 230031 (e-mail: pchen.ustc10@foxmail.com); Computer science, Tongji University, Shanghai, Shanghai China (e-mail: wangbing@ustc.edu); Advanced Analytics Institute, University of Technology, Sydney, -Broadway, New South Wales Australia 2007 (e-mail: jinyan.li@uts.edu.au)","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2019","PP","99","1","1","Biological targets are most commonly proteins such as enzymes, ion channels, and receptors. They are anything within a living organism to bind with some other entities (like an endogenous ligand or a drug), resulting in change in their behaviors or functions. Exploring potential drug-target interactions (DTIs) are crucial for drug discovery and effective drug development. Computational methods were widely applied in drug-target interactions, since experimental methods are extremely time-consuming and resource-intensive. In this paper, we proposed a novel deep learning-based prediction system, with a new negative instance generation, to identify DTIs. As a result, our method achieved an accuracy of 0.9800 on our created dataset. Another dataset derived from DrugBank was used to further assess the generalization of the model, which yielded a good performance with accuracy of 0.8814 and AUC value of 0.9527 on the dataset. The outcome of our experimental results indicated that the proposed method, involving the credible negative generation, can be employed to discriminate the interactions between drugs and targets.","","","10.1109/TCBB.2019.2940187","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8827927","Drug-target interactions;Negative instance Generation;Convolutional neural networks;Deep learning;Majority voting technique","Drugs;Proteins;Feature extraction;Neural networks;Deep learning;Predictive models","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Compact Hash Code Learning with Binary Deep Neural Network","T. Do; T. N. A. Hoang; K. Le; D. Doan; N. Cheung","Computer Science, University of Liverpool, 4591 Liverpool, Merseyside United Kingdom of Great Britain and Northern Ireland (e-mail: thanh-toan.do@liverpool.ac.uk); ISTD, Singapore University of Technology and Design, 233793 Singapore Singapore 487372 (e-mail: nguyenanhtuan_hoang@mymail.sutd.edu.sg); ISTD, Singapore University of Technology and Design, 233793 Singapore Singapore (e-mail: letandang_khoa@sutd.edu.sg); Computer Science, The University of Adelaide, 1066 Adelaide, South Australia Australia (e-mail: dung.doan@adelaide.edu.au); ISTD, Singapore University of Technology and Design, 233793 Singapore Singapore (e-mail: ngaiman_cheung@sutd.edu.sg)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","Learning compact binary codes for image retrieval problem using deep neural networks has recently attracted increasing attention. However, training deep hashing networks is challenging due to the binary constraints on the hash codes. In this paper, we propose deep network models and learning algorithms for learning binary hash codes given image representations under both unsupervised and supervised manners. The novelty of our network design is that we constrain one hidden layer to directly output the binary codes. This design has overcome a challenging problem in some previous works: optimizing non-smooth objective functions because of binarization. In addition, we propose to incorporate independence and balance properties in the direct and strict forms into the learning schemes. We also include a similarity preserving property in our objective functions. The resulting optimizations involving these binary, independence, and balance constraints are difficult to solve. To tackle this difficulty, we propose to learn the networks with alternating optimization and careful relaxation. Furthermore, by leveraging the powerful capacity of convolutional neural networks, we propose an end-to-end architecture that jointly learns to extract visual features and produce binary hash codes. Experimental results for the benchmark datasets show that the proposed methods compare favorably or outperform the state of the art.","","","10.1109/TMM.2019.2935680","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8801918","","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Modeling and Demonstration of Oxygen Vacancy-Based RRAM as Probabilistic Device for Sequence Learning","J. Doevenspeck; R. Degraeve; A. Fantini; P. Debacker; D. Verkest; R. Lauwereins; W. Dehaene","Departement Elektrotechniek (ESAT), Katholieke Universiteit (KU) Leuven, 3001 Leuven, Belgium, and also with imec, 3001 Leuven, Belgium (e-mail: jonas.doevenspeck@imec.be).; imec, 3001 Leuven, Belgium.; imec, 3001 Leuven, Belgium.; imec, 3001 Leuven, Belgium.; imec, 3001 Leuven, Belgium.; Departement Elektrotechniek (ESAT), Katholieke Universiteit (KU) Leuven, 3001 Leuven, Belgium, and also with imec, 3001 Leuven, Belgium.; Departement Elektrotechniek (ESAT), Katholieke Universiteit (KU) Leuven, 3001 Leuven, Belgium, and also with imec, 3001 Leuven, Belgium.","IEEE Transactions on Electron Devices","","2019","PP","99","1","7","The joint device-algorithm development of a resistive RAM (RRAM)-based sequence learning system is presented. The low-voltage gradual RESET of oxygen-vacancy-based RRAM was characterized and modeled by kinetic Monte Carlo simulations based on the hourglass model. In the low-voltage regime, the RESET becomes stochastic and depends on the SET-history of the device. The stochastic RESET is detrimental to deep neural network training, which requires precise weight updates. However, this intrinsic RRAM effect can be employed as a local learning rule for brain-inspired computing. Therefore, a novel and non-deep learning sequence learning approach that employs RRAM as active computational elements is proposed. Two applications using this algorithm are explored in both simulations, employing a parameterized learning rule and a hardware demonstration: sequence denoising and gait authentication. This article shows promise for the applicability of RRAM in non-deep learning applications targeting low-power online learning at the edge.","","","10.1109/TED.2019.2957067","imec Industrial Affiliation Program IIAP Machine Learning; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8946878","Neuromorphic computing;resistive RAM (RRAM);sequence learning.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"DeSVig: Decentralized Swift Vigilance Against Adversarial Attacks in Industrial Artificial Intelligence Systems","G. Li; K. Ota; M. Dong; J. Wu; J. Li","Shanghai China 200240 (e-mail: gaolei_li@sjtu.edu.cn); Department of Information and Electronic Engineering, Muroran Insitute of Technology, Muroran Japan 050-8585 (e-mail: ota@csse.muroran-it.ac.jp); Muroran Institute of Technology, 13317 Muroran Japan 0508585 (e-mail: mx.dong@csse.muroran-it.ac.jp); Shanghai China 200240 (e-mail: junwuhn@sjtu.edu.cn); Shanghai China 200240 (e-mail: lijh888@sjtu.edu.cn)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","Individually reinforcing the robustness of a single deep learning model only gives limited security guarantees especially when facing adversarial examples. In this paper, we propose DeSVig, a Decentralized Swift Vigilance framework to identify adversarial attacks in an industrial artificial intelligence systems (IAISs), which enables IAISs to correct the mistake in a few seconds. DeSVig is highly decentralized, which improves the effectiveness of recognizing abnormal inputs. We try to overcome the challenges on ultra-low latency caused by dynamics in industries using peculiarly-designated mobile edge computing and generative adversarial networks (GANs). The most important advantage of our work is that it can significantly reduce the failure risks of being deceived by adversarial examples, which is critical for safety-prioritized and delay-sensitive environments. In our experiments, adversarial examples of industrial electronic components are generated by several classical attacking models. Experimental results demonstrate the DeSVig is more robust, efficient, and scalable than some state-of-art defences.","","","10.1109/TII.2019.2951766","Leading Initiative for Excellent Young Researchers MEXT Japan; KDDI Foundation; Japan Society for the Promotion of Science; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8892628","Deep learning;adversarial examples;industrial artificial intelligence systems;mobile edge computing;generative adversarial networks","Deep learning;Computational modeling;Edge computing;Data models;Informatics;Robustness;5G mobile communication","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Oriented Spatial Transformer Network for Pedestrian Detection Using Fish-Eye Camera","Y. Qian; M. Yang; X. Zhao; C. Wang; B. Wang","Department of Automation, Shanghai Jiao Tong University, 12474 Shanghai China (e-mail: qianyeqiang@sjtu.edu.cn); Department of Automation, Shanghai Jiao Tong University, 12474 Shanghai China 200240 (e-mail: mingyang@sjtu.edu.cn); Automation, Shanghai Jiao Tong University, Shanghai China 200240 (e-mail: zhaoxu@sjtu.edu.cn); Department of Automation, Shanghai Jiao Tong University, 12474 Shanghai China (e-mail: wangcx@sjtu.edu.cn); Department of Automation, Shanghai Jiao Tong University, 12474 Shanghai China (e-mail: bingwang@sjtu.edu.cn)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","Pedestrian detection using fish-eye cameras is a principal research focus in computer vision. Lack of pedestrian datasets of fish-eye images and pedestrian distortion in fish-eye images are two primary challenges. In this paper, two approaches are proposed to deal with these two challenges respectively. On the one hand, the Projective Model Transformation (PMT) algorithm is proposed, which can transform normal images into fish-eye images. The PMT can be applied to most pedestrian datasets and generates corresponding fish-eye image datasets. In this way, enough training data can be provided through the PMT. On the other hand, the Oriented Spatial Transformer Network (OSTN) is designed to rectify warped pedestrian features using CNNs, so that pedestrians in fish-eye images are easier for detectors to recognize. The OSTN can be embedded into universal deep learning based detectors easily. Moreover, the new pedestrian detector, where the OSTN is embedded, can be trained end to end. Finally, the OSTN based fish-eye pedestrian detectors can be trained using fish-eye images, which are generated using the PMT. Experiments on ETH, KITTI and real pedestrian datasets show the effectiveness of the PMT and accuracy improvement of pedestrian detection in fish-eye images using the OSTN.","","","10.1109/TMM.2019.2929949","International Chair on automated driving of ground vehicle; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8772168","pedestrian detection;deep learning;Projective Model Transformation;Oriented Spatial Transformer Network;fish-eye image dataset","Cameras;Detectors;Feature extraction;Distortion;Deep learning;Lenses;Training","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Multi-Faceted Surrogate Model for Search-based Procedural Content Generation","D. Karavolos; A. Liapis; G. N. Yannakakis","Institute of Digital Games, University of Malta, Msida Malta 2080 MSD (e-mail: daniel.karavolos@um.edu.mt); Institute of Digital Games, University of Malta, Msida Malta 2080 (e-mail: antonios.liapis@um.edu.mt); Institute of Digital Games, University of Malta, Msida Malta 2080 (e-mail: georgios.yannakakis@um.edu.mt)","IEEE Transactions on Games","","2019","PP","99","1","1","This paper proposes a framework for the procedural generation of level and ruleset components of games via a surrogate model that assesses their quality and complementarity. The surrogate model combines level and ruleset elements as input and gameplay outcomes as output, thus constructing a mapping between three different facets of games. Using this model as a surrogate for expensive gameplay simulations, a search-based generator can adapt content towards a target gameplay outcome. Using a shooter game as the target domain, this paper explores how parameters of the players' character classes can be mapped to both the level's representation and the gameplay outcomes of balance and match duration. The surrogate model is built on a deep learning architecture, trained on a large corpus of randomly generated sets of levels, classes and simulations from gameplaying agents. Results show that a search-based generative approach can adapt character classes, levels, or both towards designer-specified targets. The model can thus act as a design assistant or be integrated in a mixed-initiative tool. Most importantly, the combination of three game facets into the model allows it to identify the synergies between levels, rules and gameplay and orchestrate the generation of the former two towards desired outcomes.","","","10.1109/TG.2019.2931044","H2020 European Institute of Innovation and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8778792","Procedural Content Generation;Search-based PCG;Surrogate Model;Deep Learning;Shooter Games","Games;Adaptation models;Generators;Computational modeling;Deep learning;Weapons;Measurement","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Generative Adversarial Networks and Conditional Random Fields for Hyperspectral Image Classification","Z. Zhong; J. Li; D. A. Clausi; A. Wong","Department of Systems Design Engineering, University of Waterloo, Waterloo, ON N2L 3G1, Canada.; Department of Geography and Environmental Management, University of Waterloo, Waterloo, ON N2L 3G1, Canada, and also with the Fujian Key Laboratory of Sensing and Computing for Smart City, Xiamen University, Xiamen 361005, China (e-mail: junli@uwaterloo.ca).; Department of Systems Design Engineering, University of Waterloo, Waterloo, ON N2L 3G1, Canada.; Department of Systems Design Engineering, University of Waterloo, Waterloo, ON N2L 3G1, Canada.","IEEE Transactions on Cybernetics","","2019","PP","99","1","12","In this paper, we address the hyperspectral image (HSI) classification task with a generative adversarial network and conditional random field (GAN-CRF)-based framework, which integrates a semisupervised deep learning and a probabilistic graphical model, and make three contributions. First, we design four types of convolutional and transposed convolutional layers that consider the characteristics of HSIs to help with extracting discriminative features from limited numbers of labeled HSI samples. Second, we construct semisupervised generative adversarial networks (GANs) to alleviate the shortage of training samples by adding labels to them and implicitly reconstructing real HSI data distribution through adversarial training. Third, we build dense conditional random fields (CRFs) on top of the random variables that are initialized to the softmax predictions of the trained GANs and are conditioned on HSIs to refine classification maps. This semisupervised framework leverages the merits of discriminative and generative models through a game-theoretical approach. Moreover, even though we used very small numbers of labeled training HSI samples from the two most challenging and extensively studied datasets, the experimental results demonstrated that spectral-spatial GAN-CRF (SS-GAN-CRF) models achieved top-ranking accuracy for semisupervised HSI classification.","","","10.1109/TCYB.2019.2915094","Canada Research Chairs Program; Natural Sciences Engineering Research Council of Canada; China Scholarship Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8726302","Conditional random fields (CRFs);generative adversarial networks (GANs);hyperspectral image (HSI) classification;semisupervised deep learning","Gallium nitride;Deep learning;Training;Generators;Generative adversarial networks;Data models;Hyperspectral imaging","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Point2Volume: A Vision-based Dietary Assessment Approach using View Synthesis","P. W. Lo; Y. Sun; J. Qiu; B. Lo","Surgery and Cancer, Imperial College London, 4615 London United Kingdom of Great Britain and Northern Ireland SW7 2AZ (e-mail: po.lo15@imperial.ac.uk); Department of Computing, Imperial College London, 4615 London, London United Kingdom of Great Britain and Northern Ireland SW7 2AZ (e-mail: y.sun16@imperial.ac.uk); Imperial College London, 4615 London, London United Kingdom of Great Britain and Northern Ireland SW7 2AZ (e-mail: jianing.qiu17@imperial.ac.uk); Imperial College London, 4615 London, London United Kingdom of Great Britain and Northern Ireland SW7 2AZ (e-mail: benny.lo@imperial.ac.uk)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","Dietary assessment is an important tool for nutritional epidemiology studies. To assess the dietary intake, the common approach is to carry out 24-hour dietary recall (24HR), a structured interview conducted by experienced dietitians. Due to the unconscious biases in such self-reporting method, many research works have proposed the use of vision-based approaches to provide accurate and objective assessments. In this paper, a novel vision-based method based on real-time 3D reconstruction and deep learning view synthesis is proposed to enable accurate portion size estimation of food items consumed. A point completion neural network is developed to complete partial point cloud of food items based on a single depth image or video captured from any convenient viewing position. Once 3D models of food items are reconstructed, the food volume can be estimated through meshing. Compared to previous methods, our method has addressed several major challenges in vision-based dietary assessment, such as view occlusion and scale ambiguity, and it outperforms previous approaches in accurate portion size estimation.","","","10.1109/TII.2019.2942831","Bill and Melinda Gates Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8853329","Deep learning;point cloud completion;3D reconstruction;volume estimation;dietary assessment","Three-dimensional displays;Solid modeling;Volume measurement;Deep learning;Cameras;Estimation;Data models","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Application of reinforcement learning to deep brain stimulation in a computational model of Parkinson’s disease","M. Lu; X. Wei; Y. Che; J. Wang; K. A. Loparo","School of Information Technology Engineering, Tianjin University of Technology and Education, Tianjin, 300222, China.; School of Information Technology Engineering, Tianjin University of Technology and Education, Tianjin, 300222, China.; School of Information Technology Engineering, Tianjin University of Technology and Education, Tianjin, 300222, China.; School of Information Technology Engineering, Tianjin University of Technology and Education, Tianjin, 300222, China.; Department of Electrical Engineering and Computer Science, Case Western Reserve University, Cleveland, Ohio, 44106, USA.","IEEE Transactions on Neural Systems and Rehabilitation Engineering","","2019","PP","99","1","1","Deep brain stimulation (DBS) has been proven to be an effective treatment to deal with the symptoms of Parkinson’s disease (PD). Currently, the DBS is in an open-loop pattern with which the stimulation parameters remain constant regardless of fluctuations in the disease state, and adjustments of parameters rely mostly on trial and error of experienced clinicians. This could bring adverse effects to patients due to possible overstimulation. Thus closed-loop DBS of which stimulation parameters are automatically adjusted based on variations in the ongoing neurophysiological signals is desired. In this paper, we present a closed-loop DBS method based on reinforcement learning (RL) to regulate stimulation parameters based on a computational model. The network model consists of interconnected biophysically-based spiking neurons, and the PD state is described as distorted relay reliability of thalamus (TH). Results show that the RL-based closed-loop control strategy can effectively restore the distorted relay reliability of the TH but with less DBS energy expenditure.","","","10.1109/TNSRE.2019.2952637","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8895773","Closed-loop DBS;Reinforcement learning;Relay reliability;Basal ganglia network;Parkinson’s disease","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Deep Transfer Learning Solution for Automating Food Material Procurement using Electronic Scales","G. Xiao; Q. Wu; H. Chen; D. Cao; J. Guo; Z. Gong","Information Engineering, Changsha, Hunan China 410082 (e-mail: gyxiao@hnu.edu.cn); Information Engineering, Changsha, Hunan China 410082 (e-mail: winck.wu@gmail.com); Hunan University, 12569 Changsha, --Choose-- China 430082 (e-mail: chenhao@hnu.edu.cn); Information Engineering, Changsha, Hunan China 410082 (e-mail: caoda@hnu.edu.cn); University of Macau, 59193 Macao, Macau Macao 999078 (e-mail: jzguo@umac.mo); University of Macau, 59193 Macao, Macau Macao 999078 (e-mail: fstzgg@umac.mo)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","We present a novel solution to automating procurement of food materials using electronic scales, which can automatically identify the food materials along weighing them. Though CNN model is regarded as one of the most effective solutions to image recognition, the traditional techniques cannot handle the mismatch problem between the lab training data and the real world data. To solve the problem, we propose to embed a partial-and-imbalanced domain adaptation technique (Tree Adaptation Network) in the deep learning model, which can borrow knowledge from sibling classes, to overcome the imbalance problem, and transfer knowledge from the source domain to the target domain, to fight the mismatch problem between the lab training data and the real world data. Experiments show that the proposed approach outperforms the state-of-the-art algorithms. Furthermore, the proposed techniques have already been used in practice.","","","10.1109/TII.2019.2931148","Universidade de Macau; Guangzhou Science and Technology Innovation and Development; Fund of Science and Technology Development of Macau Government; Natural Science Foundation of Hunan Province; National Natural Science Foundation of China; Science and Technology Key Projects of Hunan Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8772151","CNN Network;Food Material Recognition;Transfer Learning;Lab-to-Reality Transition;Imbalance","Training data;Adaptation models;Informatics;Procurement;Consumer electronics;Task analysis;Fasteners","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Offline SLA-Constrained Deep Learning for 5G Networks Reliable and Dynamic End-to-End Slicing","H. Chergui; C. Verikoukis","CTTC, Barcelona, Spain.; CTTC, Barcelona, Spain.","IEEE Journal on Selected Areas in Communications","","2019","PP","99","1","1","In this paper, we address the issue of resource provisioning as an enabler for end-to-end dynamic slicing in software defined networking/network function virtualization (SDN/NFV)-based fifth generation (5G) networks. The different slices’ tenants (i.e. logical operators) are dynamically allocated isolated portions of physical resource blocks (PRBs), baseband processing resources, backhaul capacity as well as data forwarding elements (DFE) and SDN controller connections. By invoking massive key performance indicators (KPIs) datasets stemming from a live cellular network endowed with traffic probes, we first introduce a low-complexity slices’ traffics predictor based on a soft gated recurrent unit (GRU). We then build—at each virtual network function—joint multi-slice deep neural networks (DNNs) and train them to estimate the required resources based on the traffic per slice, while not violating two service level agreement (SLA), namely, violation rate-based SLA and resource bounds-based SLA. This is achieved by integrating dataset-dependent generalized non-convex constraints into the DNN offline optimization tasks that are solved via a non-zero sum two-player game strategy. In this respect, we highlight the role of the underlying hyperparameters in the trade-off between overprovisioning and slices’ isolation. Finally, using reliability theory, we provide a closed-form analysis for the lower bound of the so-called reliable convergence probability and showcase the effect of the violation rate on it.","","","10.1109/JSAC.2019.2959186","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8931583","5G;deep neural networks;dynamic slicing;non-convex optimization;reliability theory;SDN/NFV;SLA;violation rate","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Path-Integral-Based Reinforcement Learning Algorithm for Path Following of an Autoassembly Mobile Robot","W. Zhu; X. Guo; Y. Fang; X. Zhang","Institute of Robotics and Automatic Information System, Nankai University, Tianjin 300071, China.; Institute of Robotics and Automatic Information System, Nankai University, Tianjin 300071, China.; Institute of Robotics and Automatic Information System, Nankai University, Tianjin 300071, China (e-mail: fangyc@nankai.edu.cn).; Institute of Robotics and Automatic Information System, Nankai University, Tianjin 300071, China.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","13","Reinforcement learning (RL) combined with deep neural networks has led to a number of great achievements for robot control in virtual computer environments, where sufficient data can be obtained without any difficulty to train various models. However, thus far, only few and relatively simple tasks have been accomplished for practical robots, which is mainly caused by the following two reasons. First, training with real robots, especially with dynamic systems, is too complicated to be fully and accurately represented in simulations. Second, it is very costly to obtain training data from real systems. To address these two problems effectively, in this article, a path-integral-based RL algorithm is proposed for the task of path following of an autoassembly mobile robot, wherein three kernel techniques are introduced. First, a generalized path-integral-control approach is proposed to obtain the numerical solution of a stochastic dynamical system, wherein the calculation of the gradient and kinematics inverse is avoided to ensure fast and reliable training convergence. Second, a novel parameterization method using Lyapunov techniques is introduced into the RL algorithm to ensure good performance of the system when directly transferring simulation results into practical systems. Third, the optimal parameters for all discrete initial states are first learned offline and then tuned online to improve the generalization and real-time performance. In addition to the optimization control for the mobile robot, the proposed method also possesses general applicability for a class of nonlinear systems such as crane systems. Simulation and experimental results are included and analyzed to illustrate the superior performance of the proposed algorithm.","","","10.1109/TNNLS.2019.2955699","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8941307","Autoassembly mobile robot;Lyapunov techniques;path following;path integral;reinforcement learning (RL).","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Learning Semisupervised Multilabel Fully Convolutional Network for Hierarchical Object Parsing","X. Liu; Q. Xu; G. Adkins; E. Medwedeff; L. Lin; S. Yan","Department of Computer Science, San Diego State University, San Diego, CA 92150 USA (e-mail: xiaobai.liu@mail.sdsu.edu).; Xrelab Inc., San Diego, CA 92128 USA, and also with the Department of Computer Science, San Diego State University, San Diego, CA 92150 USA.; Department of Computer Science, San Diego State University, San Diego, CA 92150 USA.; Department of Computer Science, San Diego State University, San Diego, CA 92150 USA, and also with the Computational Science Research Center (CSRC), San Diego State University, San Diego, CA 92150 USA.; Human Cyber Physical Intelligence Integration Laboratory, Sun Yat-sen University, Guangzhou 510275, China.; Department of Computer and Electrical Engineering, National University of Singapore, Singapore 119077.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","10","This article presents a semisupervised multilabel fully convolutional network (FCN) for hierarchical object parsing of images. We consider each object part (e.g., eye and head) as a class label and learn to assign every image pixel to multiple coherent part labels. Different from previous methods that consider part labels as independent classes, our method explicitly models the internal relationships between object parts, e.g., that a pixel highly scored for eyes should be highly scored for heads as well. Such relationships directly reflect the structure of the semantic space and thus should be respected while learning the deep representation. We achieve this objective by introducing a multilabel softmax loss function over both labeled and unlabeled images and regularizing it with two pairwise ranking constraints. The first constraint is based on a manifold assumption that image pixels being visually and spatially close to each other should be collaboratively classified as the same part label. The other constraint is used to enforce that no pixel receives significant scores from more than one label that are semantically conflicting with each other. The proposed loss function is differentiable with respect to network parameters and hence can be optimized by standard stochastic gradient methods. We evaluate the proposed method on two public image data sets for hierarchical object parsing and compare it with the alternative parsing methods. Extensive comparisons showed that our method can achieve state-of-the-art performance while using 50% less labeled training samples than the alternatives.","","","10.1109/TNNLS.2019.2931183","National Science Foundation; Office of Naval Research ONR; San Diego State University Presidential Leadership Funds; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8939323","Fully convolutional network (FCN);hierarchical models;semisupervised learning.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Enabling Timing Error Resilience for Low-Power Systolic-Array Based Deep Learning Accelerators","J. Zhang; Z. Ghodsi; K. Rangineni; S. Garg","Electrical and Computer Engineering, New York University, NY 11201.; Electrical and Computer Engineering, New York University, NY 11201.; Intel India, Bangalore, Karnataka 560103.; Electrical and Computer Engineering, New York University, NY 11201.","IEEE Design & Test","","2019","PP","99","1","1","Hardware accelerators are being increasingly deployed to boost the performance and energy efficiency of deep neural network (DNN) inference. In this paper we propose Thundervolt, a new framework that enables aggressive voltage underscaling for energy-efficient, systolic array (SA) based DNN accelerators without compromising classification accuracy even in the presence of high timing error rates. Using post-synthesis timing simulations of two commonly used SA accelerator architectures, we show that Thundervolt enables between 45%-50% energy savings on state-of-the-art speech and image recognition benchmarks with less than 1% loss in classification accuracy and no performance loss. Additionally, Thundervolt is robust against the impact of process variations. Finally, we show that Thundervolt is synergistic with and can further increase the energy efficiency of commonly used run-time DNN pruning techniques like Zero-Skip.","","","10.1109/MDAT.2019.2947271","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8868188","Deep Neural Network;Hardware Accelerator;Systolic Arrays;Timing Speculation;Energy Efficiency;Timing Error","Timing;Clocks;Computer architecture;Error analysis;Speech recognition;Hardware;Neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Progressive Sub-band Residual-Learning Network for MR Image Super Resolution","X. Xue; Y. Wang; J. Li; Z. Jiao; Z. Ren; X. Gao","School of Electronic Engineering, Xidian University, 47905 Xian, Shaanxi China (e-mail: xuexuetong1993@gmail.com); Video & Image Processing System Lab, Xidian University, 47905 Xian China 710071 (e-mail: yingwang@xidian.edu.cn); School of Electronic Engineering, Xidian University, 47905 Xian, Shaanxi China (e-mail: leejie@mail.xidian.edu.cn); School of Medicine, University of North Carolina at Chapel Hill, 2331 Chapel Hill, North Carolina United States (e-mail: jzc.xidian@outlook.com); School of Electronic Engineering, Xidian University, 47905 Xian, Shaanxi China (e-mail: ziqiren1214@gmail.com); Xidian University, Xi'an China 710071 (e-mail: xbgao@mail.xidian.edu.cn)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","High-resolution (HR) magnetic resonance images (MRI) provide more detailed information for clinical application. However, HR MRI is less available because of the longer scan time and lower signal-to-noise ratio. Spatial resolution is one of the key parameters of MRI. The image post-processing technique super-resolution (SR) is an alternative approach to improve the spatial resolution of MR images. Inspired by advanced deep learning based SR methods, we propose an MRI SR model named progressive sub-band residual learning SR network (PSR-SRN). The proposed model contains two parallel progressive learning streams, where one stream learns on missed high-frequency residuals by sub-band residual learning unit (ISRL) and the other focuses on reconstructing refined MR image. These two streams complement each other and enable to learn complex mappings between “Low-” and “High-” resolution MR images. Besides, we introduce brain-like mechanisms (in-depth supervision and local feedback mechanism) and progressive sub-band learning strategy to emphasize variant textures of MRI. Compared with traditional and deep learning MRI SR methods, our PSR-SRN model shows superior performance.","","","10.1109/JBHI.2019.2945373","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8859355","Magnetic resonance imaging (MRI);Super resolution (SR);CNN;Local feedback;Residual learning network","Magnetic resonance imaging;Image reconstruction;Spatial resolution;Machine learning;Deconvolution;Biomedical imaging","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Disentangled Spectrum Variations Networks for NIR-VIS Face Recognition","W. Hu; H. Hu","School of Information Science and Technology, Sun Yat-sen University, Guangzhou China (e-mail: huwp5@mail2.sysu.edu.cn); School of Electronic and Information Engineering, Sun Yat-sen University, Guangzhou China 510275 (e-mail: huhaif@mail.sysu.edu.cn)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","Surveillance cameras often capture near infrared images since it provides a low-cost and effective solution to acquire high-quality images under low-light environments. However, visual versus near infrared (VIS-NIR) heterogeneous face recognition (HFR) is still a challenging issue in computer vision community due to the gap between sensing patterns of different spectrums as well as the lack of sufficient training samples. To solve the above problem, in this paper, we present an efficient Disentangled Spectrum Variations Networks (DSVNs) for VIS-NIR HFR. Two key strategies are introduced to the DSVNs for disentangling spectrum variations between two domains: Spectrum-adversarial Discriminative Feature Learning (SaDFL) and Step-wise Spectrum Orthogonal Decomposition (SSOD). The SaDFL consists of Identity-Discriminative subnetwork (IDNet) and Auxiliary Spectrum Adversarial subnetwork (ASANet). On the one hand, the IDNet is composed of a generator $G_H$ and a discriminator $D_U$ for extracting identity-discriminative feature. On the other hand, the ASANet is built by a generator $G_H$ and a discriminator $D_M$ for eliminating modality-variant spectrum information under the guidance of the discriminator $D_M$. The IDNet is trained using identity-label HFR dataset with triplet loss, while the ASANet is trained using modality-label HFR dataset. Both IDNet and ASANet can jointly enhance the domain-invariant feature representations via an adversarial learning. Furthermore, to disentangle spectrum variations effectively as well as making identity information and modality information unrelated to each other, we present a new topology of connection block called Disentangled Spectrum Variations (DSV). An orthogonality constraint is imposed to DSV at the convolution level for channel-wise orthogonal decomposition between the modality-invariant identity information and modality-variant spectrum information. In particular, the SSOD is built by stacking multiple modularized mirco-block DSV, and thereby enjoys the benefits of disentangling spectrum variation step by step. Moreover, we investigate the similarity calculation method to further improve the HFR performance. To sum up, the designed DSVNs leads to a purification of identity information as well as an elimination of modality information. Extensive experiments are carried out on two challenging NIR-VIS HFR datasets CASIA NIR-VIS 2.0 and Oulu-CASIA NIR-VIS, demonstrating the superiority of the proposed method.","","","10.1109/TMM.2019.2938685","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8821416","NIR-VIS face recognition;Deep learning;Adversarial training;Disentangled spectrum variations;Orthogonality constraint","Feature extraction;Face;Face recognition;Deep learning;Task analysis;Generators;Stacking","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Perception-Inspired Deep Learning Framework for Predicting Perceptual Texture Similarity","Y. Gao; Y. Gan; L. Qi; H. Zhou; X. Dong; J. Dong","Department of Information Science and Technology, Ocean University of China, 238 Songling Road, Qingdao, China.; Department of Information Science and Technology, Ocean University of China, 238 Songling Road, Qingdao, China.; Department of Information Science and Technology, Ocean University of China, 238 Songling Road, Qingdao, China.; Department of Informatics, University of Leicester, LE1 7RH, United Kingdom.; Centre for Imaging Sciences, the University of Manchester, M13 9PT, United Kingdom.; Department of Information Science and Technology, Ocean University of China, 238 Songling Road, Qingdao, China.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Similarity learning plays a fundamental role in the fields of multimedia retrieval and pattern recognition. Prediction of perceptual similarity is a challenging task as in most cases we lack human labeled ground-truth data and robust models to mimic human visual perception. Although in the literature, some studies have been dedicated to similarity learning, they mainly focus on the evaluation of whether or not two images are similar, rather than prediction of perceptual similarity which is consistent with human perception. Inspired by the human visual perception mechanism, we here propose a novel framework in order to predict perceptual similarity between two texture images. Our proposed framework is built on the top of Convolutional Neural Networks (CNNs). The proposed framework considers both powerful features and perceptual characteristics of contours extracted from the images. The similarity value is computed by aggregating resemblances between the corresponding convolutional layer activations of the two texture maps. Experimental results show that the predicted similarity values are consistent with the human-perceived similarity data.","","","10.1109/TCSVT.2019.2944569","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8853308","Similarity learning;perceptual similarity;texture similarity;convolutional neural networks.","Visualization;Feature extraction;Visual perception;Pattern recognition;Task analysis;Convolutional neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Improving Deep Binary Embedding Networks by Order-aware Reweighting of Triplets","H. Lai; J. Chen; L. Geng; Y. Pan; X. Liang; J. Yin","School of Data and Computer Science, Sun Yat-Sen University, China and Guangdong Key Laboratory of Big Data Analysis and Processing.; School of Data and Computer Science, Sun Yat-Sen University, China.; School of Data and Computer Science, Sun Yat-Sen University, China.; School of Data and Computer Science, Sun Yat-Sen University, China.; School of Computer Science, Carnegie Mellon University.; School of Data and Computer Science, Sun Yat-Sen University, China.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","In this paper, we focus on triplet-based deep binary embedding networks for image retrieval task. The triplet loss has been shown to be effective for hashing retrieval. However, most of the triplet-based deep networks treat the triplets equally or select the hard triplets based on the loss. Such strategies do not consider the order relations of the binary codes and ignore the hash encoding when learning the feature representations. To this end, we propose an order-aware reweighting method to effectively train the triplet-based deep networks, which up-weights the important triplets and down-weights the uninformative triplets via the rank lists of the binary codes. First, we present the order-aware weighting factors to indicate the importance of the triplets, which depend on the rank order of binary codes. Then, we reshape the triplet loss to the squared triplet loss such that the loss function will put more weights on the important triplets. Extensive evaluations on several benchmark datasets show that the proposed method achieves significant performance compared with the state-of-the-art baselines.","","","10.1109/TCSVT.2019.2899055","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8640819","Image Retrieval;Triplet Ranking Loss;Deep Learning;Nearest Neighbor Search","Binary codes;Training;Hash functions;Image retrieval;Semantics;Quantization (signal);Dogs","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Learning Regional Attraction for Line Segment Detection","N. Xue; S. Bai; F. Wang; G. Xia; T. Wu; L. Zhang; P. H. S. Torr","State Key Laboratory of Inormation Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan, Hubei China (e-mail: xuenan@whu.edu.cn); Department of Engineering Science, University of Oxford, Oxford, Oxford United Kingdom of Great Britain and Northern Ireland (e-mail: songbai.site@gmail.com); LIESMARS, Wuhan University, 12390 Wuhan, Hubei China (e-mail: fudong-wang@whu.edu.cn); State Key Lab. of LIESMARS, Wuhan University, 12390 Wuhan, Hubei China (e-mail: guisong.xia@whu.edu.cn); Statistics, University of California, Los Angeles, Los Angeles, California United States 90095 (e-mail: tianfu_wu@ncsu.edu); LIESMARS, Wuhan University, Wuhan, Hubei China (e-mail: zlp62@whu.edu.cn); Department of Computing, Oxford Brookes University, Oxford, Oxfordshire United Kingdom of Great Britain and Northern Ireland (e-mail: philip.torr@eng.ox.ac.uk)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","This paper presents regional attraction of line segment maps, and hereby poses the problem of line segment detection (LSD) as a problem of region coloring. Given a line segment map, the proposed regional attraction first establishes the relationship between line segments and regions in the image lattice. Based on this, the line segment map is equivalently transformed to an attraction field map (AFM), which can be remapped to a set of line segments without loss of information. Accordingly, we develop an end-to-end framework to learn attraction field maps for raw input images, followed by a squeeze module to detect line segments. Apart from existing works, the proposed detector properly handles the local ambiguity and does not rely on the accurate identification of edge pixels. Comprehensive experiments on the Wireframe dataset and the YorkUrban dataset demonstrate the superiority of our method. In particular, we achieve an F-measure of 0.831 on the Wireframe dataset, advancing the state-of-the-art performance by 10.3 percent.","","","10.1109/TPAMI.2019.2958642","China Scholarship Council; National Science Foundation; National Natural Science Foundation of China; Army Research Office; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8930083","Line Segment Detection;Low-level Vision;Deep Learning","Image segmentation;Image edge detection;Detectors;Lattices;Machine learning;Electronic mail;Training","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Learning Energy-based Spatial-Temporal Generative ConvNets for Dynamic Patterns","J. Xie; S. Zhu; Y. N. Wu","Machine Learning, Hikvision Research Institute, Santa Clara, California United States (e-mail: jianwen@ucla.edu); Statistics and Computer Science, University of California, Los Angeles, Los Angeles, California United States 90095 (e-mail: sczhu@stat.ucla.edu); Statistics, UCLA, Los Angeles, California United States 90095 (e-mail: ywu@stat.ucla.edu)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Video sequences contain rich dynamic patterns, such as dynamic texture patterns that exhibit stationarity in the temporal domain, and action patterns that are non-stationary in either spatial or temporal domain. We show that an energy-based spatial-temporal generative ConvNet can be used to model and synthesize dynamic patterns. The model defines a probability distribution on the video sequence, and the log probability is defined by a spatial-temporal ConvNet that consists of multiple layers of spatial-temporal filters to capture spatial-temporal patterns of different scales. The model can be learned from the training video sequences by an ""analysis by synthesis"" learning algorithm that iterates the following two steps. Step 1 synthesizes video sequences from the currently learned model. Step 2 then updates the model parameters based on the difference between the synthesized video sequences and the observed training sequences. We show that the learning algorithm can synthesize realistic dynamic patterns. We also show that it is possible to learn the model from incomplete training sequences with either occluded pixels or missing frames, so that model learning and pattern completion can be accomplished simultaneously.","","","10.1109/TPAMI.2019.2934852","Defense Advanced Research Projects Agency; Office of Naval Research Global; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798892","Deep generative models;Energy-based models;Dynamic textures;Generative ConvNet;Spatial-temporal ConvNet","Data models;Heuristic algorithms;Solid modeling;Generators;Three-dimensional displays;Video sequences;Dynamics","","","","","","","","","","IEEE","IEEE Early Access Articles"
"I-Keyboard: Fully Imaginary Keyboard on Touch Devices Empowered by Deep Neural Decoder","U. Kim; S. Yoo; J. Kim","School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon 34141, South Korea.; School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon 34141, South Korea.; School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon 34141, South Korea (e-mail: johnkim@rit.kaist.ac.kr).","IEEE Transactions on Cybernetics","","2019","PP","99","1","12","Text entry aims to provide an effective and efficient pathway for humans to deliver their messages to computers. With the advent of mobile computing, the recent focus of text-entry research has moved from physical keyboards to soft keyboards. Current soft keyboards, however, increase the typo rate due to a lack of tactile feedback and degrade the usability of mobile devices due to their large portion on screens. To tackle these limitations, we propose a fully imaginary keyboard (I-Keyboard) with a deep neural decoder (DND). The invisibility of I-Keyboard maximizes the usability of mobile devices and DND empowered by a deep neural architecture allows users to start typing from any position on the touch screens at any angle. To the best of our knowledge, the eyes-free ten-finger typing scenario of I-Keyboard which does not necessitate both a calibration step and a predefined region for typing is first explored in this article. For the purpose of training DND, we collected the largest user data in the process of developing I-Keyboard. We verified the performance of the proposed I-Keyboard and DND by conducting a series of comprehensive simulations and experiments under various conditions. I-Keyboard showed 18.95% and 4.06% increases in typing speed (45.57 words per minute) and accuracy (95.84%), respectively, over the baseline.","","","10.1109/TCYB.2019.2952391","Institute for Information and Communications Technology Promotion grant funded by the Korea Government MSIT Research on Adaptive Machine Learning Technology Development for Intelligent Autonomous Digital Companion; National Research Foundation of Korea NRF grant funded by the Korea Government MSIT; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8917709","Decoding;eyes-free;human-computer interaction (HCI);imaginary keyboard (I-Keyboard);soft keyboard;text entry;user experience;user interfaces (UIs);virtual keyboard.","Keyboards;Decoding;Mobile handsets;Calibration;Data collection;Tactile sensors;Usability","","","","","","","","","","IEEE","IEEE Early Access Articles"
"PatchNet: Hierarchical Deep Learning-Based Stable Patch Identification for the Linux Kernel","T. Hoang; J. Lawall; Y. Tian; R. J. Oentaryo; D. Lo","School of Information System, Singapore Management University, 54756 Singapore, Singapore Singapore 188065 (e-mail: vdthoang.2016@smu.edu.sg); Computer Science, Inria/LIP6/UPMC/Sorbonne University-Regal, Paris, France France 75005 (e-mail: julia.lawall@lip6.fr); School of Computing, Queen's University, 4257 Kingston, Ontario Canada (e-mail: yuan.tian@cs.queensu.ca); McLaren Applied Technologies, McLaren, Singapore, Singapore Singapore (e-mail: richard.oentaryo@mclaren.com); School of Information Systems, Singapore Management University, Singapore, Singapore Singapore 17890 (e-mail: davidlo@smu.edu.sg)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Linux kernel stable versions serve the needs of users who value stability of the kernel over new features. The quality of such stable versions depends on the initiative of kernel developers and maintainers to propagate bug fixing patches to the stable versions. Thus, it is desirable to consider to what extent this process can be automated. A previous approach relies on words from commit messages and a small set of manually constructed code features. This approach, however, shows only moderate accuracy. In this paper, we investigate whether deep learning can provide a more accurate solution. We propose PatchNet, a hierarchical deep learning-based approach capable of automatically extracting features from commit messages and commit code and using them to identify stable patches. PatchNet contains a deep hierarchical structure that mirrors the hierarchical and sequential structure of commit code, making it distinctive from the existing deep learning models on source code. Experiments on 82,403 recent Linux patches confirm the superiority of PatchNet against various state-of-the-art baselines, including the one recently-adopted by Linux kernel maintainers.","","","10.1109/TSE.2019.2952614","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8896061","","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Progressive Fusion for Unsupervised Binocular Depth Estimation using Cycled Networks","A. Pilzer; S. Lathuilière; D. Xu; M. M. Puscas; E. Ricci; N. Sebe","DISI, University of Trento, Povo, Trento, Trento Italy 38123 (e-mail: andrea.pilzer@unitn.it); perception, Inria Centre de Recherche Grenoble Rhone-Alpes, 56521 Montbonnot, isère France 38334 (e-mail: stephane.lathuiliere@unitn.it); Department of Engineering Science, University of Oxford, Oxford, Oxford United Kingdom of Great Britain and Northern Ireland Ox1 3PJ (e-mail: danxu@robots.ox.ac.uk); Dipartimento di Ingegneria e Scienza dell'Informazione, Universita degli Studi di Trento Dipartimento di Ingegneria e Scienza dell'Informazione, 387454 Povo, Trento Italy 38123 (e-mail: mihaimarian.puscas@unitn.it); Technologies of Vision, Fondazione Bruno Kessler, 18466 Trento, Trentino-Alto Adige Italy (e-mail: eliricci@fbk.eu); Multimodal Human Understanding Group, University of Trento, Trento, Trentino Italy (e-mail: niculae.sebe@unitn.it)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Recent deep monocular depth estimation approaches based on supervised regression have achieved remarkable performance. However, they require costly ground truth annotations during training. To cope with this issue, in this paper we present a novel unsupervised deep learning approach for predicting depth maps. We introduce a new network architecture, named Progressive Fusion Network (PFN), that is specifically designed for stereo depth estimation. This network is based on a multi-scale refinement strategy that combines the information provided by both images. In addition, we propose to stack twice this network in order to form a cycle. This cycle approach can be interpreted as a form of data-augmentation since, at training time, the network learns both from the training set images (in the forward half-cycle) but also from the synthesized images (in the backward half-cycle). The architecture is jointly trained with adversarial learning. Extensive experiments on the publicly available datasets KITTI, Cityscapes and ApolloScape demonstrate the effectiveness of the proposed model which outperforms previous unsupervised deep learning methods for depth prediction.","","","10.1109/TPAMI.2019.2942928","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8846077","Stereo Depth Estimation;Convolutional Neural Networks (ConvNet);Deep Multi-Scale Fusion;Cycle network","Estimation;Training;Deep learning;Cameras;Solid modeling;Predictive models;Network architecture","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Reinforcement Learning Based Downlink Interference Control for Ultra-Dense Small Cells","L. Xiao; H. Zhang; Y. Xiao; X. Wan; S. Liu; L. Wang; H. V. Poor","Department of Information and Communication Engineering & Key Laboratory of Digital Fujian on IoT Communication, Architecture and Security Technology, Xiamen University, Xiamen 361005, P. R. China and National Mobile Communications Research Laboratory, Southeast University, Nanjing 211189, P. R. China.; Department of Information and Communication Engineering & Key Laboratory of Digital Fujian on Io T Communication, Architecture and Security Technology, Xiamen University, Xiamen 361005, P. R. China.; Department of Information and Communication Engineering & Key Laboratory of Digital Fujian on Io T Communication, Architecture and Security Technology, Xiamen University, Xiamen 361005, P. R. China.; Department of Information and Communication Engineering & Key Laboratory of Digital Fujian on Io T Communication, Architecture and Security Technology, Xiamen University, Xiamen 361005, P. R. China.; Department of Information and Communication Engineering & Key Laboratory of Digital Fujian on Io T Communication, Architecture and Security Technology, Xiamen University, Xiamen 361005, P. R. China.; Department of Electrical and Computer Engineering, National Chiao Tung University, Hsinchu 300, Taiwan.; Department of Electrical Engineering, Princeton University, Princeton, NJ 08544 USA.","IEEE Transactions on Wireless Communications","","2019","PP","99","1","1","The dense deployment of small cells in 5G cellular networks has to control the downlink inter-cell interference under time-varying channel states. In this paper, we propose a reinforcement learning based power control scheme to suppress the downlink inter-cell interference and save energy for ultra-dense small cells. This scheme enables base stations to schedule the downlink transmit power without knowing the interference distribution and the channel states of the neighboring small cells. A deep reinforcement learning based interference control algorithm is designed to further accelerate the learning speed for the ultra-dense small cells with a large number of active users. Theoretical convergence performance bounds including throughput, energy consumption, inter-cell interference, and the utility of base stations are provided and the computational complexity of our proposed schemes is discussed. Simulation results show that this scheme optimizes the downlink interference control performance after sufficient power control experiences and significantly increases the network throughput with less energy consumption compared with the benchmark.","","","10.1109/TWC.2019.2945951","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8868117","Ultra-dense small cells;interference control;power control;reinforcement learning","Power control;Downlink;Throughput;Microcell networks;Signal to noise ratio","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Multi-Level Information Fusion-based Deep Leaning Method for Vision-based Defect Recognition","Y. Gao; L. Gao; X. Li; X. V. Wang","State Key Laboratory of Digital Manufacturing Equipment & Technology, School of Mechanical Science and Engineering, Huazhong University of Science and Technology, Wuhan, 430074, China.; State Key Laboratory of Digital Manufacturing Equipment & Technology, School of Mechanical Science and Engineering, Huazhong University of Science and Technology, Wuhan, 430074, China.; State Key Laboratory of Digital Manufacturing Equipment & Technology, School of Mechanical Science and Engineering, Huazhong University of Science and Technology, Wuhan, 430074, China.; Department of Production Engineering, KTH Royal Institute of Technology, Stockholm, Sweden.","IEEE Transactions on Instrumentation and Measurement","","2019","PP","99","1","1","Vision-based defect recognition is an important technology to guarantee quality in modern manufacturing systems. And deep learning (DL) becomes a research hotspot in vision-based defect recognition due to the outstanding performances. However, most of the DL methods require a large sample to learn the defect information. While in some real-world cases, it is difficult and costly for data collecting, and only a small sample is available. Generally, a small sample contains less information, which may mislead the DL models, so that they cannot work as expected. Therefore, this requirement impedes the wide applications of DL in vision-based defect recognition. To overcome this problem, this paper proposes a multi-level information fusion-based DL method for vision-based defect recognition. In the proposed method, a three-level Gaussian pyramid is introduced to generate multi-level information of the defect, so that more information is available for model training. After the Gaussian pyramid, three VGG16 networks are built to learn the information and the outputs are fused for the final recognition result. The experimental results show that the proposed method can extract more useful information and achieve better performances on small-sample tasks, compared with the conventional DL methods and defect recognition methods. Furthermore, the analysis results of the robustness and response time also indicate that the proposed method is robust for the noise input, and it is fast for defect recognition, which takes 13.74ms to handle a defect image.","","","10.1109/TIM.2019.2947800","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8871213","Defect recognition;multi-level information fusion;deep learning;small sample","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Asynchronous Episodic Deep Deterministic Policy Gradient: Toward Continuous Control in Computationally Complex Environments","Z. Zhang; J. Chen; Z. Chen; W. Li","CAS Key Laboratory of Technology in Geo-Spatial Information Processing and Application System, University of Science and Technology of China, Hefei 230026, China.; CAS Key Laboratory of Technology in Geo-Spatial Information Processing and Application System, University of Science and Technology of China, Hefei 230026, China.; CAS Key Laboratory of Technology in Geo-Spatial Information Processing and Application System, University of Science and Technology of China, Hefei 230026, China (e-mail: chenzhibo@ustc.edu.cn).; CAS Key Laboratory of Technology in Geo-Spatial Information Processing and Application System, University of Science and Technology of China, Hefei 230026, China.","IEEE Transactions on Cybernetics","","2019","PP","99","1","10","Deep deterministic policy gradient (DDPG) has been proved to be a successful reinforcement learning (RL) algorithm for continuous control tasks. However, DDPG still suffers from data insufficiency and training inefficiency, especially, in computationally complex environments. In this article, we propose asynchronous episodic DDPG (AE-DDPG), as an expansion of DDPG, which can achieve more effective learning with less training time required. First, we design a modified scheme for data collection in an asynchronous fashion. Generally, for asynchronous RL algorithms, sample efficiency or/and training stability diminish as the degree of parallelism increases. We consider this problem from the perspectives of both data generation and data utilization. In detail, we redesign experience replay by introducing the idea of episodic control so that the agent can latch on good trajectories rapidly. In addition, we also inject a new type of noise in action space to enrich the exploration behaviors. Experiments demonstrate that our AE-DDPG achieves higher rewards and requires less time consumption than most popular RL algorithms in learning to run task which has a computationally complex environment. Not limited to the control tasks in the computationally complex environments, AE-DDPG also achieves higher rewards and two-fold to four-fold improvement in sample efficiency on average compared with other variants of DDPG in MuJoCo environments. Furthermore, we verify the effectiveness of each proposed technique component through abundant ablation study.","","","10.1109/TCYB.2019.2939174","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8946888","Continuous control;deep deterministic policy gradient (DDPG);episodic control;reinforcement learning (RL)","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Unsupervised Deep Contrast Enhancement with Power Constraint for OLED Displays","Y. Shin; S. Park; Y. Yeo; M. Yoo; S. Ko","School of Electrical Engineering, Korea University, Seoul 136-713, Republic of Korea.; School of Electrical Engineering, Korea University, Seoul 136-713, Republic of Korea.; School of Electrical Engineering, Korea University, Seoul 136-713, Republic of Korea.; LG Display, Magok-dong, Gangseo-gu, Seoul, 07796, Rep. of Korea.; School of Electrical Engineering, Korea University, Seoul 136-713, Republic of Korea.","IEEE Transactions on Image Processing","","2019","PP","99","1","1","Various power-constrained contrast enhance-ment (PCCE) techniques have been applied to an organic light emitting diode (OLED) display for reducing the pow-er demands of the display while preserving the image qual-ity. In this paper, we propose a new deep learning-based PCCE scheme that constrains the power consumption of the OLED displays while enhancing the contrast of the displayed image. In the proposed method, the power con-sumption is constrained by simply reducing the brightness a certain ratio, whereas the perceived visual quality is pre-served as much as possible by enhancing the contrast of the image using a convolutional neural network (CNN). Furthermore, our CNN can learn the PCCE technique without a reference image by unsupervised learning. Ex-perimental results show that the proposed method is supe-rior to conventional ones in terms of image quality assess-ment metrics such as a visual saliency-induced index (VSI) and a measure of enhancement (EME).1.","","","10.1109/TIP.2019.2953352","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8906230","Convolutional neural network;deep learning;energy efficiency;image enhancement","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Flickr Image Community Analytics by Deep Noise-refined Matrix Factorization","L. Zhang; J. Yin; P. Li; Y. Shang; R. Zimmermann; L. Shao","College of Computer Sciences, Zhejiang University, Hangzhou, China.; College of Computer Sciences, Zhejiang University, Hangzhou, China.; School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China.; School of Aeronautic and Astronautic, Zhejiang University, Hangzhou, China; School of Computing, National University of Singapore, Singapore.; University of East Anglia, School of Computing Sciences Norwich, Norfolk, UK.","IEEE Transactions on Multimedia","","2019","PP","99","1","1","Accurately categorizing Flickr images into multiple pre-defined communities (e.g., “architecture” and “peaceful”) is an indispensable technique in multimedia analysis, graphic design, fashion recommendation, etc. In practice, these communities are constructed and updated manually, which is subjective and intolerably time consuming. To alleviate these shortcomings, a noise-refined deep matrix factorization (MF) framework is proposed to intelligently discover communities from million-scale Flickr users, wherein the semantic tag correlations and community correlations are simultaneously encoded. More specifically, it is believable that Flickr communities are high-level clues on the basis of human visual semantic perception. There by, a MF algorithm is employed to approximate the community label matrix by the product of pairwise factor matrices, which represent the latent representations of user-provided tags and the corresponding basis matrix respectively. Subsequently, an end-to-end deep model is formulated to hierarchically derive the latent deep representation from raw image pixels to semantic tags. To robustly handle contaminated image semantic tags and community labels, an l1 norm constraint is encoded to enhance the MF. Meanwhile, to optimally exploit the rich context information of Flickr images, the intrinsic structure between image semantic tags and between communities are collaboratively captured. Finally, the upgraded MF and the deep model are seamlessly combined into a unified framework, which is solved by an iterative algorithm. Experiments on 2M Flickr images have demonstrated the superiority of our approach. Besides, the discovered Flickr communities can improve photo retargeting and visual aesthetics assessment significantly.","","","10.1109/TMM.2019.2938664","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8821403","Machine learning;Deep model;Noise-refined;Matrix factorization;Community","Flickr;Semantics;Visualization;Correlation;Task analysis;Matrix decomposition","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Intelligent Fault Diagnosis for Rotary Machinery Using Transferable Convolutional Neural Network","Z. Chen; K. Gryllias; W. Li","School of Mechanical and Automotive Engineering, South China University of Technology, 26467 Guangzhou, Guangdong China 510640 (e-mail: mezychen@gmail.com); Mechanical Engineering, KU Leuven Science Engineering and Technology Group, 129039 Leuven, Flanders Belgium 3000 (e-mail: konstantinos.gryllias@kuleuven.be); School of Mechanical & Automotive Engineering, South China University of Technology, 26467 Guangzhou, Guangdong China 510640 (e-mail: whlee@scut.edu.cn)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","Deep neural networks present very competitive results in mechanical fault diagnosis. However, training deep models require high computing power while the performances of deep models often suffer from the lack of sufficient training data. In this paper, a transferable convolutional neural network (TCNN) is proposed to improve the learning of target tasks. Firstly, one-dimension CNN is constructed and pre-trained based on large source task datasets. Then a transfer learning strategy is adopted to build a deep model on target tasks by reusing the pre-trained network. Thus, the proposed method not only utilizes the learning power of deep network but also leverages the prior knowledge from the source task. Four case studies are performed, and the effects of transfer layers and training sample size on classification effectiveness are investigated. Results show that the proposed method exhibits better performance compared with other algorithms.","","","10.1109/TII.2019.2917233","National Key R and D Program of China; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8716596","Fault diagnosis;Transfer learning;Convolutional Neural Network;Rotary machinery","Task analysis;Fault diagnosis;Feature extraction;Kernel;Training;Training data;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Robust Lane Detection from Continuous Driving Scenes Using Deep Neural Networks","Q. Zou; H. Jiang; Q. Dai; Y. Yue; L. Chen; Q. Wang","School of Computer Science, Wuhan University, Wuhan, Hubei China (e-mail: qzou@whu.edu.cn); School of Electronic Information, Wuhan University, Wuhan, Hubei China (e-mail: hwjiang@whu.edu.cn); School of Power and Mechanical Engineering, Wuhan University, Wuhan, Hubei China (e-mail: qiyudai@whu.edu.cn); School of Computer Science, Wuhan University, Wuhan, Hubei China (e-mail: yhyue@whu.edu.cn); School of Data and Computer Science, Sun Yat-Sen University, 26469 Guangzhou, Guangdong China 510006 (e-mail: chenl46@mail.sysu.edu.cn); School of Computer Science, Wuhan University, Wuhan, Hubei China (e-mail: qianwang@whu.edu.cn)","IEEE Transactions on Vehicular Technology","","2019","PP","99","1","1","Lane detection in driving scenes is an important module for autonomous vehicles and advanced driver assistance systems. In recent years, many sophisticated lane detection methods have been proposed. However, most methods focus on detecting the lane from one single image, and often lead to unsatisfactory performance in handling some extremely-bad situations such as heavy shadow, severe mark degradation, serious vehicle occlusion, and so on. In fact, lanes are continuous line structures on the road. Consequently, the lane that cannot be accurately detected in one current frame may potentially be inferred out by incorporating information of previous frames. To this end, we investigate lane detection by using multiple frames of a continuous driving scene, and propose a hybrid deep architecture by combining the convolutional neural network (CNN) and the recurrent neural network (RNN). Specifically, information of each frame is abstracted by a CNN block, and the CNN features of multiple continuous frames, holding the property of time-series, are then fed into the RNN block for feature learning and lane prediction. Extensive experiments on two large-scale datasets demonstrate that, the proposed method outperforms the competing methods in lane detection, especially in handling difficult situations.","","","10.1109/TVT.2019.2949603","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8883072","Convolutional neural network;LSTM;lane detection;semantic segmentation;autonomous driving","Roads;Neural networks;Image segmentation;Minimization;Deep learning;Decoding;Image color analysis","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Body Symmetry and Part Locality Guided Direct Nonparametric Deep Feature Enhancement for Person Re-identification","J. Zhu; H. Zeng; J. Huang; X. Zhu; Z. Lei; C. Cai; L. Zheng","College of Engineering, Huaqiao University, Quanzhou, 362021, China and Fujian Provincial Academic Engineering Research Centre in Industrial Intellectual Techniques and Systems (.; College of Information Science and Engineering, Huaqiao University, Xiamen, 361021, China.; Shanghai Institute of Micro-system and Information Technology, Chinese Academy of Sciences, China.; School of Computer and Communication Engineering, University of Science and Technology Beijing, China.; Center for Biometrics and Security Research and National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China.; College of Engineering, Huaqiao University, Quanzhou, 362021, China and Fujian Provincial Academic Engineering Research Centre in Industrial Intellectual Techniques and Systems (.; College of Engineering, Huaqiao University, Quanzhou, 362021, China and Fujian Provincial Academic Engineering Research Centre in Industrial Intellectual Techniques and Systems (.","IEEE Internet of Things Journal","","2019","PP","99","1","1","In recent years, deep learning has been successfully and widely applied in the person re-identification (Re-ID). However, the deep learning based person Re-ID methods face a bottleneck that the scales of most existing person Re-ID databases are not large enough for training very deep models. To address this problem, a body symmetry and part locality guided direct nonparametric deep feature enhancement (DNDFE) method is proposed in this paper. Based on the observation that the body symmetry and part locality are two important appearance properties inherited in the upright walking persons, the proposed method designs two nonparametric layers, namely, the body symmetry average pooling and local normalization layers, to construct a direct nonparametric deep feature enhancement module to well explore the body symmetry and part locality properties. The proposed DNDFE module could be directly embedded between the traditional deep feature learning module and similarity learning module to enhance the deep learning features so as to improve the person Re-ID performance. Experimental results have shown that the proposed DNDFE method is superior to multiple state-of-the-art person Re-ID methods in term of accuracy and efficiency.","","","10.1109/JIOT.2019.2960549","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8936431","Person re-identification (Re-ID);body symmetry;part locality;convolution neural network;direct nonparametric deep feature enhancement module.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Fusion Learning Model for Mobile Face Safe Detection and Facial Gesture Analysis","Z. Ni; Q. Li","School of Information Engineering, Nanjing Xiaozhuang University, Nanjing, 211171, China and Intelligent Manufacturing Department, Wuyi University, Jiangmen, 529020, China and School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, 210094, China.; School of Information Engineering, Nanjing Xiaozhuang University, Nanjing, 211171, China and Intelligent Manufacturing Department, Wuyi University, Jiangmen, 529020, China and Taizhou Data Industry Park, Taizhou Pharmaceutical High-tech Industrial Development Zone, Taizhou, 225300, China.","IEEE Access","","2019","PP","99","1","1","Face pose analysis has a very broad application prospect in the fields of public safety monitoring, human-computer interaction. Traditional deep learning methods are mostly based on public dataset training, and the robustness is poor in specific application scenarios. Secondly, most models need to crop the facial region during analysis, which is not only slow but also loses facial context in the natural environment. In response to these problems, this paper proposes a joint learning network model for Mobile Face Safe Detection and pose analysis. This method first proposes a cloud-service assisted semi-automated image annotation method. The image of the driver’s pose in road traffic monitoring scenes is marked for, which provides additional training data for subsequent joint learning. Secondly, through the cascaded multi-task network, the problem of face pose analysis relying on Mobile Face Safe Detection is solved. At the same time, the fusion loss function, classified training data and Online Hard Example Mining (OHEM) training strategies are used to improve the robustness of the model in complex environments. In the end, the FDDB, AFLW and Prima data sets are used to verify the superiority of our model by comparing with other algorithms.","","","10.1109/ACCESS.2019.2948714","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8878077","Face pose analysis;Joint detection and analysis;Semi-automated annotation","Face;Labeling;Analytical models;Computational modeling;Data models;Deep learning;Feature extraction","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"A Unified Smart Chinese Medicine Framework for Healthcare and Medical Services","Q. Zhang; C. Bai; L. T. Yang; Z. Chen; P. Li; H. Yu","Computer Science, St. Francis Xavier University, Antigonish, Nova Scotia Canada (e-mail: qzhang@stfx.ca); Dalian Hospital of Traditional Chinese Medicine, Dalian, Liaoning China (e-mail: bcc_clinic@163.com); Computer Science, St Francis Xavier University, Antigonish, Nova Scotia Canada (e-mail: ltyang@gmail.com); software school, Network communications and database technology, Dalian, Liaoning Province China 116620 (e-mail: zkchen@dlut.edu.cn); School of Software Technology, Dalian University of Technology, 12399 Dalian, Liaoning China (e-mail: lipeng2015@mail.dlut.edu.cn); St. Francis Xavier University, Antigonish, Nova Scotia Canada (e-mail: x2018ujw@stfx.ca)","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2019","PP","99","1","1","Smart Chinese medicine has emerged to contribute to the evolution of healthcare and medical services by applying machine learning together with advanced computing techniques like cloud computing to computer-aided diagnosis and treatment in the health engineering and informatics. Specially, smart Chinese medicine is considered to be potential to treat the difficult and complicated diseases such as diabetes and cancers. Unfortunately, smart Chinese medicine has made very limited progress in the past few years. In this paper, we present a unified smart Chinese medicine framework based on the edge-cloud computing system. The objective of the framework is to achieve computer-aided syndrome differentiation and prescription recommendation, and thus to provide pervasive, personalized and patient-centralized services in healthcare and medicine. To accomplish this objective, we integrate deep learning and deep reinforcement learning into the traditional Chinese medicine. Furthermore, we propose a multi-modal deep computation model for syndrome recognition that is a crucial part of syndrome differentiation. Finally, we conduct experiments to validate the proposed model by comparing with the staked auto-encoder and multi-modal deep learning model for syndrome recognition of hypertension and cold.","","","10.1109/TCBB.2019.2914447","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8704881","Healthcare and medical services;Smart Chinese medicine;Machine learning;Cloud computing;Syndrome differentiation and prescription recommendation","Tongue;Computational modeling;Diseases;Inspection;Deep learning;Hypertension","","","","","","","","","","IEEE","IEEE Early Access Articles"
"DeepLog: Identify Tight Gas Reservoir Using Multi-Log Signals by a Fully Convolutional Network","K. Zhu; L. Wang; Y. Du; C. Jiang; Z. Sun","School of Information and Control Engineering, Qingdao University of Technology, Qingdao 266033, China (e-mail: zhu_kaicom@163.com).; School of Geoscience and Technology, Southwest Petroleum University, Chengdu 610500, China (e-mail: wangliang_swpu@163.com).; Research Institute of Natural Gas, Shaanxi Yanchang Petroleum Group Company Ltd., Xi'an 710075, China.; No. 1 Research Institute of Exploitation, China National Offshore Oil Corporation, Tianjin 710075, China.; School of Information and Control Engineering, Qingdao University of Technology, Qingdao 266033, China.","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","4","In most cases, reservoir properties at one certain depth in the layer can be explicated by logging signals at just this depth point. In fact, the properties of complex reservoirs are often implicated in logging signals from the whole adjacent region of this certain depth point. So far, there is no effective way to solve this problem completely. For the first time, this letter tried to build a fully convolutional neural network (FCNN) to detect hydrocarbon from logging signals for the tight gas reservoir of Ordos Basin. The FCNN was based on a well-designed VGG-net. The prediction comparison between the empirical approach (EMA) and FCNN was implemented on 48 layers. The accuracy of FCNN was about 87.5%, which was higher than that of the EMA (75.0%). FCNN provided more reliable gas testing recommendations, especially when thin layers led to complex reservoir conditions. Deep learning (DL) has been proven to be an automatic feature extraction and direct hydrocarbon detection approach from logging signals. We are looking forward to its improvement and development in geophysics.","","","10.1109/LGRS.2019.2930587","Shandong Provincial Natural Science Foundation of China; National Science and Technology Major Project of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8834866","Automatic feature extraction;deep learning (DL);fully convolutional neural network (FCNN);hydrocarbon detection;logging signal;machine learning (ML);reservoir recognition;signal processing;tight gas reservoir.","Reservoirs;Convolution;Feature extraction;Convolutional neural networks;Conductivity;Seismic measurements","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Unsupervised Stereo Matching Using Confidential Correspondence Consistency","S. Joung; S. Kim; K. Park; K. Sohn","School of Electrical and Electronic Engineering, Yonsei University, Seoul 03722, South Korea.; School of Computer and Communication Sciences, École Polytechnique Fédérale de Lausanne, 1015 Lausanne, Switzerland.; School of Electrical and Electronic Engineering, Yonsei University, Seoul 03722, South Korea.; School of Electrical and Electronic Engineering, Yonsei University, Seoul 03722, South Korea (e-mail: khsohn@yonsei.ac.kr).","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","14","Stereo matching aims to perceive the 3D geometric configuration of scenes and facilitates a variety of computer vision in advanced driver assistance systems (ADAS) applications. Recently, deep convolutional neural networks (CNNs) have shown dramatic performance improvements for computing the matching cost in the stereo matching. However, the performance of CNN-based approaches relies heavily on datasets, requiring a large number of ground truth data which needs tremendous works. To overcome this limitation, we present a novel framework to learn CNNs for matching cost computation in an unsupervised manner. Our method leverages an image domain learning combined with stereo epipolar constraints. By exploiting the correspondence consistency between stereo images, our method selects putative positive samples in each training iteration and utilizes them to train the networks. We further propose a positive sample propagation scheme to leverage additional training samples. Our unsupervised learning method is evaluated with two kinds of network architectures, simple and precise CNNs, and shows comparable performance to that of the state-of-the-art methods including both supervised and unsupervised learning approaches on KITTI, Middlebury, HCI, and Yonsei datasets. This extensive evaluation demonstrates that the proposed learning framework can be applied to deal with various real driving conditions.","","","10.1109/TITS.2019.2917538","Ministry of Science and ICT; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8721668","Stereo matching;matching cost;similarity learning;unsupervised learning;convolutional neural networks.","Training;Unsupervised learning;Benchmark testing;Lighting;Supervised learning;Three-dimensional displays;Image reconstruction","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Neural Network Based Inertial Odometry Using Low-cost Inertial Measurement Units","C. Chen; X. Lu; J. Wahlstrom; A. Markham; N. Trigoni","Department of Computer Science, University of Oxford, 6396 Oxford, Oxfordshire United Kingdom of Great Britain and Northern Ireland OX1 2JD (e-mail: changhao.chen@cs.ox.ac.uk); Department of Computer Science, University of Oxford, 6396 Oxford, Oxfordshire United Kingdom of Great Britain and Northern Ireland (e-mail: xiaoxuan.lu@cs.ox.ac.uk); Computer Science, University of Oxford, Oxford, Oxfordshire United Kingdom of Great Britain and Northern Ireland (e-mail: johan.wahlstrom@cs.ox.ac.uk); Department of Computer Science, University of Oxford, Oxford, Oxfordshire United Kingdom of Great Britain and Northern Ireland (e-mail: andrew.markham@cs.ox.ac.uk); Department of Computer Science, University of Oxford, Oxford, Oxfordshire United Kingdom of Great Britain and Northern Ireland (e-mail: Niki.Trigoni@cs.ox.ac.uk)","IEEE Transactions on Mobile Computing","","2019","PP","99","1","1","Inertial measurement units (IMUs) have emerged as an essential component in many of today's indoor navigation solutions due to their low cost and ease of use. However, despite many attempts for reducing the error growth of navigation systems based on commercial-grade inertial sensors, there is still no satisfactory solution that produces navigation estimates with long-time stability in widely differing conditions. This paper proposes to break the cycle of continuous integration used in traditional inertial algorithms, formulate it as an optimization problem, and explore the use of deep recurrent neural networks for estimating the displacement of a user over a specified time window. By training the deep neural network using inertial measurements and ground truth displacement data, it is possible to learn both motion characteristics and systematic error drift. As opposed to established context-aided inertial solutions, the proposed method is not dependent on either fixed sensor positions or periodic motion patterns. It can reconstruct accurate trajectories directly from raw inertial measurements, and predict the corresponding uncertainty to show model confidence. Extensive experimental evaluations demonstrate that the neural network produces position estimates with high accuracy for several different attachments, users, sensors, and motion types. Further more, it works in highly dynamic conditions, such as running, remaining extremely challenging for current techniques.","","","10.1109/TMC.2019.2960780","National Institute of Standards and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8937008","Pedestrian Navigation;Inertial Indoor Localization;Deep Neural Network;Learning from Mobile Sensor Data;Inertial Measurement Units","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Automatic Recognition of Soybean Leaf Diseases Using UAV Images and Deep Convolutional Neural Networks","E. Castelão Tetila; B. Brandoli Machado; G. K. Menezes; A. d. S. Oliveira; M. Alvarez; W. P. Amorim; N. A. de Souza Belete; G. G. da Silva; H. Pistori","Faculty of Exact Sciences and Technology, Federal University of Grande Dourados, Dourados 79825-070, Brazil, and also with the Postgraduate Program in Local Development, Dom Bosco Catholic University, Campo Grande 79117-010, Brazil (e-mail: evertontetila@ufgd.edu.br).; Faculty of Computing, Federal University of Mato Grosso do Sul, Campo Grande 79070-900, Brazil, and also with the Postgraduate Program in Local Development, Dom Bosco Catholic University, Campo Grande 79117-010, Brazil.; Faculty of Computing, Federal University of Mato Grosso do Sul, Campo Grande 79070-900, Brazil, and also with the Postgraduate Program in Local Development, Dom Bosco Catholic University, Campo Grande 79117-010, Brazil.; Faculty of Computing, Federal University of Mato Grosso do Sul, Campo Grande 79070-900, Brazil, and also with the Postgraduate Program in Local Development, Dom Bosco Catholic University, Campo Grande 79117-010, Brazil.; Department of Computer Science and Statistics, University of Rhode Island, Kingston, RI 02881 USA.; Faculty of Exact Sciences and Technology, Federal University of Grande Dourados, Dourados 79825-070, Brazil.; Postgraduate Program in Local Development, Dom Bosco Catholic University, Campo Grande 79117-010, Brazil, with the Production Engineering Department, Federal University of Rondônia, Cacoal 76801-016, Brazil, and also with the Faculty of Engineering, University of Porto, 4099-002 Porto, Portugal.; Faculty of Computing, Federal University of Mato Grosso do Sul, Campo Grande 79070-900, Brazil, and also with the Postgraduate Program in Local Development, Dom Bosco Catholic University, Campo Grande 79117-010, Brazil.; Faculty of Computing, Federal University of Mato Grosso do Sul, Campo Grande 79070-900, Brazil, and also with the Postgraduate Program in Local Development, Dom Bosco Catholic University, Campo Grande 79117-010, Brazil.","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","Plant diseases are a crucial issue in agriculture. An accurate and automatic identification of leaf diseases could help to develop an early response to reduce economic losses. Recent research in plant diseases has adopted deep neural networks. However, such research has used the models as a black-box passing the labeled images through the networks. This letter presents an analysis of the network weights for the automatic recognition of soybean leaf diseases applied to images taken straight from a small and cheap unmanned aerial vehicle (UAV). To achieve high accuracy, we evaluated four deep neural network models trained with different parameters for fine-tuning (FT) and transfer learning. Data augmentation and dropout were used during the network training to avoid overfitting. Our methodology consists of using the SLIC method to segment the plant leaves in the top-view images obtained during the flight. We tested our data set created from real flight inspections in an end-to-end computer vision approach. Results strongly suggest that the FT of parameters substantially improves the identification accuracy.","","","10.1109/LGRS.2019.2932385","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8805152","Aerial imagery;deep learning;precision agriculture;soybean leaf diseases;unmanned aerial vehicle (UAV)-based remote sensing.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Training Deep Photonic Convolutional Neural Networks With Sinusoidal Activations","N. Passalis; G. Mourgias-Alexandris; A. Tsakyridis; N. Pleros; A. Tefas","Artificial Intelligence and Information Analysis Laboratory, Aristotle University of Thessaloniki, 541 24 Thessaloniki, Greece. He is now with the Faculty of Information Technology and Communication Sciences, Tampere University, 33800 Tampere, Finland (e-mail: passalis@csd.auth.gr).; Photonic Systems and Networks Research Group, Aristotle University of Thessaloniki, 541 24 Thessaloniki, Greece (e-mail: mourgias@csd.auth.gr).; Photonic Systems and Networks Research Group, Aristotle University of Thessaloniki, 541 24 Thessaloniki, Greece (e-mail: atsakyrid@csd.auth.gr).; Photonic Systems and Networks Research Group, Aristotle University of Thessaloniki, 541 24 Thessaloniki, Greece (e-mail: npleros@csd.auth.gr).; Artificial Intelligence and Information Analysis Laboratory, Aristotle University of Thessaloniki, 541 24 Thessaloniki, Greece (e-mail: tefas@csd.auth.gr).","IEEE Transactions on Emerging Topics in Computational Intelligence","","2019","PP","99","1","10","Deep learning (DL) has achieved state-of-the-art performance in many challenging problems. However, DL requires powerful hardware for both training and deployment, increasing the cost and energy requirements and rendering large-scale applications especially difficult. Recognizing these difficulties, several neuromorphic hardware solutions have been proposed, including photonic hardware that can process information close to the speed of light and can benefit from the enormous bandwidth available on photonic systems. However, the effect of using these photonic-based neuromorphic architectures, which impose additional constraints that are not usually considered when training DL models, is not yet fully understood and studied. The main contribution of this paper is an extensive study on the feasibility of training deep neural networks that can be deployed on photonic hardware that employ sinusoidal activation elements, along with the development of methods that allow for successfully training these networks, while taking into account the physical limitations of the employed hardware. Different DL architectures and four datasets of varying complexity were used for extensively evaluating the proposed method.","","","10.1109/TETCI.2019.2923001","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8750996","Photonic neural networks;sinusoidal activations;deep learning","","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Boosting Occluded Image Classification via Subspace Decomposition-Based Estimation of Deep Features","F. Cen; G. Wang","Department of Control Science and Engineering, College of Electronics and Information Engineering, Tongji University, Shanghai 201804, China (e-mail: feng.cen@tongji.edu.cn).; Department of Electrical Engineering and Computer Science, University of Kansas, Lawrence, KS 66045 USA.","IEEE Transactions on Cybernetics","","2019","PP","99","1","14","Classification of partially occluded images is a highly challenging computer vision problem even for the cutting-edge deep learning technologies. To achieve a robust image classification for occluded images, this article proposes a novel scheme using the subspace decomposition-based estimation (SDBE). The proposed SDBE-based classification scheme first employs a base convolutional neural network to extract the deep feature vector (DFV) and then utilizes the SDBE to compute the DFV of the original occlusion-free image for classification. The SDBE is performed by projecting the DFV of the occluded image onto the linear span of a class dictionary (CD) along the linear span of an occlusion error dictionary (OED). The CD and OED are constructed, respectively, by concatenating the DFVs of a training set and the occlusion error vectors of an extra set of image pairs. Two implementations of the SDBE are studied in this article: 1) the l₁-norm and 2) the squared l₂-norm regularized least-squares estimates. By employing the ResNet-152, pretrained on the ImageNet Large-Scale Visual Recognition Challenge 2012 (ILSVRC2012) training set, as the base network, the proposed SBDE-based classification scheme is extensively evaluated on the Caltech-101 and ILSVRC2012 datasets. Extensive experimental results demonstrate that the proposed SDBE-based scheme dramatically boosts the classification accuracy for occluded images, and achieves around 22.25% increase in classification accuracy under 20% occlusion on the ILSVRC2012 dataset.","","","10.1109/TCYB.2019.2931067","Shanghai Agriculture Applied Technology Development Program China; NSF National Robotics Initiative and United States Department of Agriculture National Institute of Food and Agriculture; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8794588","Convolutional neural networks (CNNs);deep learning;image classification;occluded image;subspace decomposition","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Resources Sharing in 5G Networks: Learning-Enabled Incentives and Coalitional Games","L. Yu; Z. Li; J. Liu; R. Zhou","School of Computer Science, Wuhan University, Hubei 430072, China (e-mail: shileyyu@126.com).; School of Computer Science, Wuhan University, Hubei 430072, China (e-mail: zongpeng@whu.edu.cn).; School of Computing Science, Simon Fraser University, Burnaby(Metro-Vancouver), BC V5A1S6, Canada (e-mail: jcliu@cs.sfu.ca).; School of Cyber Science and Engineering, Wuhan University, Hubei 430072, China (e-mail: ruitingzhou@whu.edu.cn).","IEEE Systems Journal","","2019","PP","99","1","12","Smart systems are often battery-constrained, and compete for resources from remote clouds, which results in high delay. Collaboratively sharing resource among neighbors in proximity is promising to control such delay for time-sensitive applications. Rather few existing studies focus on the design between ubiquitous cooperation and competition with learning-enable incentives. In this article, intelligent algorithms are introduced in a distributed fashion, which encapsulates cooperation and competition to coordinate the overall goal of the cellular system with individual goals of Internet of Things (IoT) devices. First, the utility function of the cell and IoT users are designed, respectively. For the former, an incentive mechanism is constructed, where a novel deep actor-critic learning algorithm is developed with a prioritized queue for continuous action space in the differentiated decision-making procedure. For the latter, the energy model is taken into account. Furthermore, the coalition game combined with deep Q-learning framework is explored so as to model and incentivize the cooperation and competition process. Theoretical analysis and simulation studies demonstrate that the improved algorithms perform better than the original version, and they can converge to a Nash-stable optimal or asymptotically optimal solution.","","","10.1109/JSYST.2019.2958890","National Natural Science Foundation of China; Nature Science Foundation of Hubei Province; Technological Innovation Major Projects of Hubei Province; Science and Technology Program of Wuhan City; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8946696","Coalition game;deep learning;decision-making control;resources sharing;smart Internet of Things (IoT)","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Neural Ordinary Differential Equations for Hyperspectral Image Classification","M. E. Paoletti; J. M. Haut; J. Plaza; A. Plaza","Hyperspectral Computing Laboratory, Department of Technology of Computers and Communications, Escuela Politécnica, University of Extremadura, 10003 Cáceres, Spain. (e-mail: mpaoletti@unex.es).; Hyperspectral Computing Laboratory, Department of Technology of Computers and Communications, Escuela Politécnica, University of Extremadura, 10003 Cáceres, Spain.; Hyperspectral Computing Laboratory, Department of Technology of Computers and Communications, Escuela Politécnica, University of Extremadura, 10003 Cáceres, Spain.; Hyperspectral Computing Laboratory, Department of Technology of Computers and Communications, Escuela Politécnica, University of Extremadura, 10003 Cáceres, Spain.","IEEE Transactions on Geoscience and Remote Sensing","","2019","PP","99","1","17","Advances in deep learning (DL) have allowed for the development of more complex and powerful neural architectures. The adoption of deep convolutional-based architectures with residual learning [residual networks (ResNets)] has reached the state-of-the-art performance in hyperspectral image (HSI) classification. Traditionally, ResNets have been considered as stacks of discrete layers, where each one obtains a hidden state of the input data. This formulation must deal with very deep networks, which suffer from an important data degradation as they become deeper. Moreover, these complex models exhibit significant requirements in terms of memory due to the amount of parameters that need to be fine tuned. This leads to inadequate generalization and loss of accuracy. In order to address these issues, this article redesigns the ResNet as a continuous-time evolving model, where hidden representations (or states) are obtained with respect to time (understood as the depth of the network) through the evaluation of an ordinary differential equation (ODE), which is combined with a deep neural architecture. Our experimental results, conducted with four well-known HSI data sets, indicate that redefining deep networks as continuous systems through ODEs offers flexibility when processing and classifying these kinds of remotely sensed data, achieving significant performance even when a very few training samples are available.","","","10.1109/TGRS.2019.2948031","Ministerio de Educacion Resolucion de 26 de diciembre de 2014 y de 19 de noviembre de 2015 de la Secretaria de Estado de Educacion Formacion Profesional y Universidades por la que se convocan ayudas para la formacion de profesorado universitario de los subprogramas de Formacion y de Movilidad incluidos en el Programa Estatal de Promocion del Talento y su Empleabilidad and en el marco del Plan Estatal de Investigacion Cientifica y Tecnica y de Innovacion 2013 2016; Junta de Extremadura Decreto 14 2018 de 6 de febrero por el que se establecen las bases reguladoras de las ayudas para la realizacion de actividades de investigacion y desarrollo tecnologico and de divulgacion y de transferencia de conocimiento por los Grupos de Investigacion de Extremadura; European Unions Horizon 2020 Research and Innovation Programme; Ministerio de Economia y Empresa MINECO Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8892510","Deep learning (DL);hyperspectral images (HSIs);ordinary differential equations (ODEs);residual networks (ResNets).","Neurons;Data models;Hyperspectral imaging;Feature extraction;Data mining;Visualization","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Voice of Charity: Prospecting the Donation Recurrence & Donor Retention in Crowdfunding","H. Zhao; B. Jin; Q. Liu; Y. Ge; E. Chen; X. Zhang; T. Xu","College of Management and Economics, Tianjin University, 12605 Tianjin, Tianjin China (e-mail: hongkehanqing@163.com); School of Computer Science and Technology, University of Science and Technology of China, Hefei, Anhui China (e-mail: bb0725@mail.ustc.edu.cn); School of Computer Science and Technology, University of Science and Technology of China, 12652 Hefei, Anhui China (e-mail: qiliuql@ustc.edu.cn); Eller College of Management, University of Arizona, 8041 Tucson, Arizona United States (e-mail: yongge@email.arizona.edu); School of Computer Science, University of Science and Technology of China, Hefei, Anhui China (e-mail: cheneh@ustc.edu.cn); College of Management and Economics, College of Management and Economics, Tianjin University, Tianjin, Tianjin China (e-mail: jackyzhang@tju.edu.cn); School of Data Science, University of Science and Technology of China, Hefei, Anhui China (e-mail: tongxu@ustc.edu.cn)","IEEE Transactions on Knowledge and Data Engineering","","2019","PP","99","1","1","Online donation-based crowdfunding has brought new life to charity by soliciting small monetary contributions from crowd donors to help others in trouble or with dreams. However, a crucial issue for crowdfunding platforms as well as traditional charities is the problem of high donor attrition, i.e., many donors donate only once or very few times within a rather short lifecycle and then leave. Thus, it is an urgent task to analyze the factors of and then further predict the donors behaviors. Especially, we focus on two types of behavioral events, e.g., donation recurrence (whether one donor will make donations at some time slices in the future) and donor retention (whether she will remain on the crowdfunding platform until a future time). However, this problem has not been well explored due to many domain and technical challenges, such as the heterogeneous influence, the relevance of the two types of events, and the censoring phenomenon of retention records. In this paper, we present a focused study on donation recurrence and donor retention with the help of large-scale behavioral data collected from crowdfunding. Specifically, we propose a Joint Deep Survival model, i.e., JDS, which can integrate heterogeneous features, e.g., donor motives, projects recently donated to, social contacts, to jointly model the donation recurrence and donor retention since these two types of behavioral events are highly relevant. In addition, we model the censoring phenomenon and dependence relations of different behaviors from the survival analysis view by designing multiple innovative constraints and incorporating them into the objective functions. Finally, we conduct extensive analysis and validation experiments with large-scale data collected from Kiva.org. The experimental results clearly demonstrate the effectiveness of our proposed models for analyzing and predicting the donation recurrence and donor retention in crowdfunding.","","","10.1109/TKDE.2019.2906199","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8669972","Crowdfunding;Donor Retention;Survival Analysis;Ranking Constraints;Deep Learning","Predictive models;Task analysis;Deep learning;Optimization;Data models;Analytical models;Collaboration","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Modular Lightweight Network for Road Object Detection Using a Feature Fusion Approach","Y. Liu; S. Cao; P. Lasang; S. Shen","School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing 210094, China (e-mail: yazhouliu@njust.edu.cn).; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing 210094, China.; Panasonic R&D Center Singapore, Singapore 469332.; Panasonic R&D Center Singapore, Singapore 469332. She is now with Pensees Pte Ltd., Singapore.","IEEE Transactions on Systems, Man, and Cybernetics: Systems","","2019","PP","99","1","13","This article presents a modular lightweight network model for road objects detection, such as car, pedestrian, and cyclist, especially when they are far away from the camera and their sizes are small. Great advances have been made for the deep networks, but small objects detection is still a challenging task. In order to solve this problem, a majority of existing methods utilize complicated network or bigger image size, which generally leads to higher computation cost. The proposed network model is referred to as modular feature fusion detector (MFFD), using a fast and efficient network architecture for detecting small objects. The contribution lies in the following aspects: 1) two base modules have been designed for efficient computation: a) Front module reduces the information loss from raw input images and b) Tinier module decreases the model size and computation cost, while ensuring the detection accuracy; 2) by stacking the base modules, we design a context features fusion framework for multiscale object detection; and 3) the proposed method is efficient in terms of model size and computation cost, which is applicable for resource-limited devices, such as embedded systems for advanced driver-assistance systems (ADASs). Comparisons with the state-of-the-art on the challenging KITTI dataset reveal the superiority of the proposed method. Especially, 100 ft/s can be achieved on the embedded GPUs such as Jetson TX2.","","","10.1109/TSMC.2019.2945053","National Natural Science Foundation of China; Natural Science Foundation of Jiangsu Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8871351","Advanced driver-assistance systems (ADASs);deep learning;lightweight network;modular network;object detection","Object detection;Feature extraction;Computational modeling;Convolution;Task analysis;Deep learning;Roads","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Automation of the Timed-Up-and-Go Test Using a Conventional Video Camera","P. Savoie; J. Cameron; M. Kaye; E. Scheme","Electrical and Computer Engineering, University of New Brunswick, 3427 Fredericton, New Brunswick Canada (e-mail: p.savoie@unb.ca); Electrical and Computer Engineering, University of New Brunswick, 3427 Fredericton, New Brunswick Canada E3B5A3 (e-mail: james.cameron111@unb.ca); Electrical and Computer Engineering, University of New Brunswick, 3427 Fredericton, New Brunswick Canada (e-mail: kaye@unb.ca); Institute of Biomedical Engineering, University of New Brunswick, Fredericton, New Brunswick Canada E3B5A3 (e-mail: escheme@unb.ca)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","The Timed-Up-and-Go (TUG) test is a simple clinical tool commonly used to quickly assess the mobility of patients. Researchers have endeavored to automate the test using sensors or motion tracking systems to improve its accuracy and to extract more resolved information about its sub-phases. While some approaches have shown promise, they often require the donning of sensors or the use of specialized hardware, such as the now discontinued Microsoft Kinect, which combines video information with depth sensors (RGBD). In this work, we leverage recent advances in computer vision to automate the TUG test using a regular RGB video camera without the need for custom hardware or additional depth sensors. Thirty healthy participants were recorded using a Kinect V2 and a standard video feed while performing multiple trials of 3 and 1.5 meter versions of the TUG test. A Mask Regional Convolutional Neural Net (R-CNN) algorithm and a Deep Multitask Architecture for Human Sensing (DMHS) were then used together to extract global 3D poses of the participants. The timing of transitions between the six key movement phases of the TUG test were then extracted using heuristic features extracted from the time series of these 3D poses. The proposed video-based vTUG system yielded the same or lower error than the standard Kinect-based system for all six key transitions points, and average errors of less than 0.15 seconds from a multi-observer hand labeled ground truth. This work describes a novel method of video-based automation of the TUG test using a single standard camera, removing the need for specialized equipment and facilitating the extraction of additional meaningful information for clinical use.","","","10.1109/JBHI.2019.2934342","New Brunswick Innovation Foundation; Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8793176","Computer vision;automation;deep learning;R-CNN;Timed-up-and-go;gait analysis;neural networks;pose estimation","Cameras;Sensors;Skeleton;Meters;Three-dimensional displays;Data mining;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep-Learning based Lossless Image Coding","I. Schiopu; A. Munteanu","Department of Electronics and Informatics (ETRO), Vrije Universiteit Brussel (VUB), Brussels, Belgium.; Department of Electronics and Informatics (ETRO), Vrije Universiteit Brussel (VUB), Brussels, Belgium.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","The paper proposes a novel approach for lossless image compression. The proposed coding approach employs a deep-learning based method to compute the prediction for each pixel, and a context-tree based bit-plane codec to encode the prediction errors. Firstly, a novel deep learning-based predictor is proposed to estimate the residuals produced by traditional prediction methods. It is shown that the use of a deep-learning paradigm substantially boosts the prediction accuracy compared to traditional prediction methods. Secondly, the prediction error is modeled by a context modeling method and encoded using a novel context-tree based bit-plane codec. Codec profiles performing either one or two coding passes are proposed, trading off complexity for compression performance. The experimental evaluation is carried out on three different types of data: photographic images, lenslet images, and video sequences. Experimental results show that the proposed lossless coding approach systematically and substantially outperforms the state-of-the-art methods for each type of data.","","","10.1109/TCSVT.2019.2909821","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8684320","","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Deep Quadruplet Network for Local Descriptor Learning","X. Wang; X. Zeng; Y. Lyu; K. Chen; Y. Zhang; D. Li","Guangdong University of Technology, China, Guangdong, Guangzhou.; Guangdong University of Technology, China, Guangdong, Guangzhou.; School of Computer, University of Electronic Science and Technology of China, Zhongshan Institute.; Guangzhou University, China, Guangdong, Guangzhou.; Guangdong University of Technology, China, Guangdong, Guangzhou.; Guangdong University of Technology, China, Guangdong, Guangzhou.","IEEE Access","","2019","PP","99","1","1","Generating a distinguishable feature for local patch is a main task in computer vision which aims at matching local patches. Recently, local patch descriptors from deep convolutional neural network (CNN) with a triplet loss have achieved promising performance. In this paper, we design a quadruplet loss, which can achieve a better result than other pairwise loss and triplet loss methods. Our loss is inspired by the thoughts of uniform distribution. It separates non-matching examples by using the hard sampled non-matching pairs in a batch, and simultaneously uses the random sampled non-matching examples to keep non-matching pairs to obey uniform distribution. A compact descriptor named QuadrupletNet is generated by combining the proposed quadruplet loss and L2Net CNN architecture. From our experiment, QuadrupletNet shows better performance on the Brown dataset and Hpatches dataset than Triplet loss methods on the same training set. The pre-trained QuadrupletNet is publicly available.","","","10.1109/ACCESS.2019.2962624","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8944021","Convolutional neural network (CNN);quadruplet network;learned descriptors","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Deep learning for automated feature discovery and classification of sleep stages","M. Sokolovsky; F. Guerrero; S. Paisarnsrisomsuk; C. Ruiz; S. A. Alvarez","Computer Science, Worcester Polytechnic Institute, 8718 Worcester, Massachusetts United States (e-mail: sokoovsky@wpi.edu); Computer Science, Worcester Polytechnic Institute, 8718 Worcester, Massachusetts United States (e-mail: afguerrerohernan@wpi.edu); Computer Science, Worcester Polytechnic Institute, 8718 Worcester, Massachusetts United States (e-mail: spaisarnsrisomsu@wpi.edu); Computer Science, Worcester Polytechnic Institute, 8718 Worcester, Massachusetts United States (e-mail: ruiz@wpi.edu); Computer Science, Boston College, Chestnut Hill, Massachusetts United States 02467 (e-mail: alvarez@bc.edu)","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2019","PP","99","1","1","Convolutional neural networks (CNN) have demonstrated state-of-the-art classification results in image categorization, but have received comparatively little attention for classification of one-dimensional physiological signals. We design a deep CNN architecture for automated sleep stage classification of human sleep EEG and EOG signals. The CNN proposed in this paper amply outperforms recent work that uses a different CNN architecture over a single-EEG-channel version of the same dataset. We show that the performance gains achieved by our network rely mainly on network depth, and not on the use of several signal channels. Performance of our approach is on par with human expert inter-scorer agreement. By examining the internal activation levels of our CNN, we find that it spontaneously discovers signal features such as sleep spindles and slow waves that figure prominently in sleep stage categorization as performed by human experts.","","","10.1109/TCBB.2019.2912955","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8695777","Clinical neuroscience;sleep apnea;electrophysiology;machine learning;neural networks;feature extraction","Sleep;Electroencephalography;Task analysis;Electrooculography;Computer architecture;Convolutional neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"DeSIRe: Deep Signer-Invariant Representations for Sign Language Recognition","P. M. Ferreira; D. Pernes; A. Rebelo; J. S. Cardoso","Centre for Telecommunications and Multimedia, INESC TEC, 4200-465 Porto, Portugal, also with the Faculdade de Engenharia, Universidade do Porto, 4200-465 Porto, Portugal, also with the Faculdade de Ciências, Universidade do Porto, 4169-007 Porto, Portugal, and also with Ciência e Tecnologia, Universidade Portucalense, 4200-072 Porto, Portugal (e-mail: pmmf@inesctec.pt).; Centre for Telecommunications and Multimedia, INESC TEC, 4200-465 Porto, Portugal, also with the Faculdade de Engenharia, Universidade do Porto, 4200-465 Porto, Portugal, also with the Faculdade de Ciências, Universidade do Porto, 4169-007 Porto, Portugal, and also with Ciência e Tecnologia, Universidade Portucalense, 4200-072 Porto, Portugal.; Centre for Telecommunications and Multimedia, INESC TEC, 4200-465 Porto, Portugal, also with the Faculdade de Engenharia, Universidade do Porto, 4200-465 Porto, Portugal, also with the Faculdade de Ciências, Universidade do Porto, 4169-007 Porto, Portugal, and also with Ciência e Tecnologia, Universidade Portucalense, 4200-072 Porto, Portugal.; Centre for Telecommunications and Multimedia, INESC TEC, 4200-465 Porto, Portugal, also with the Faculdade de Engenharia, Universidade do Porto, 4200-465 Porto, Portugal, also with the Faculdade de Ciências, Universidade do Porto, 4169-007 Porto, Portugal, and also with Ciência e Tecnologia, Universidade Portucalense, 4200-072 Porto, Portugal.","IEEE Transactions on Systems, Man, and Cybernetics: Systems","","2019","PP","99","1","16","As a key technology to help bridging the gap between deaf and hearing people, sign language recognition (SLR) has become one of the most active research topics in the human-computer interaction field. Although several SLR methodologies have been proposed, the development of a real-world SLR system is still a very challenging task. One of the main challenges is related to the large intersigner variability that exists in the manual signing process of sign languages. To address this problem, we propose a novel end-to-end deep neural network that explicitly models highly discriminative signer-independent latent representations from the input data. The key idea of our model is to learn a distribution over latent representations, conditionally independent of signer identity. Accordingly, the learned latent representations will preserve as much information as possible about the signs, and discard signer-specific traits that are irrelevant for recognition. By imposing such regularization in the representation space, the result is a truly signer-independent model which is robust to different and new test signers. The experimental results demonstrate the effectiveness of the proposed model in several SLR databases.","","","10.1109/TSMC.2019.2957347","European Regional Development Fund through the Operational Programme for Competitiveness and Internationalisation--COMPETE 2020 Programme; National Funds through the Portuguese Funding Agency Fundação para a Ciência e a Tecnologia; Ph.D.; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8937777","Deep neural networks;generative models;representation learning;signer-independent sign language recognition;variational autoencoders (VAEs)","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Recurrent model for wireless indoor tracking and positioning recovering using generative networks","A. Belmonte-Hernández; G. Hernández-Peñaloza; D. M. Gutiérrez; F. Álvarez","NA; NA; NA; NA","IEEE Sensors Journal","","2019","PP","99","1","1","Indoor person tracking attracts a considerable effort from the research community as it allows to perform Human Behaviour Analysis tasks, where wireless technologies play a key role. However, complex signal propagation effects in indoor environments are the main issue to face when performing accurate indoor positioning and tracking. The advances in machine and deep learning models, applied to improve the estimation of the position captured by wireless sensors, can provide a more precise tracking and positioning, an open field for research which has been used to improve the prior art. In this paper, a novel framework for Adaptive Indoor Tracking using Recurrent models, in combination with Generative networks for new data generation (recovery), is presented (RecTrack-GAN). Firstly, a Received Signal Strength Indicator RSSI Fingerprinting database is collected. Secondly, a Recurrent Neural Network (RNN) takes as input the RSSI parameters collected by a Wireless Sensor Network (WSN) and estimates of both orientation and velocity using devices equipped with Inertial Measurement Unit (IMU) sensors, and learns to model the human movement based on these parameters. Thirdly, a Conditional Generative Adversarial Network (CGAN) is used to perform data recovering when no measurements are received and to update the Fingerprinting database taking into account the day time. The experiments performed showed that RecTrack-GAN improves accuracy performance and reduces error deviation for tracking up to 15% compared to the prior art in the literature.","","","10.1109/JSEN.2019.2958201","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8926469","Indoor Tracking;Fingerprinting;Wireless Sensor Network;Received Signal Strength Indicator (RSSI);Inertial Measurement Unit (IMU);Feature Vector;Machine Learning;Deep Learning;Recurrent Networks;Generative Networks","Wireless sensor networks;Sensors;Fingerprint recognition;Machine learning;Databases;Received signal strength indicator;Recurrent neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Hierarchical Deep Click Feature Prediction for Fine-grained Image Recognition","J. Yu; M. Tan; H. Zhang; D. Tao; Y. Rui","Computer Science, Hangzhou Dianzi, Hangzhou, Zhejiang China (e-mail: yujun@hdu.edu.cn); School of Computer Science and Technology, Hangzhou Dianzi University, 12626 Hangzhou, Zhejiang China 310018 (e-mail: tanmin@hdu.edu.cn); Computer Science Department, Hangzhou, Zhejiang Province China (e-mail: zhhy1994226@163.com); Engineering and Information Technologies, University of Sydney, 4334 Sydney, New South Wales Australia (e-mail: dacheng.tao@sydney.edu.au); Lenove, Lenovo Research and Technology, Beijing, Beijing China (e-mail: yongrui@lenovo.com)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","The click feature of an image, defined as the user-click-frequency vector of the image on a pre-defined word vocabulary, is known to effectively reduce the semantic gap for fine-grained image recognition. Unfortunately, user-click-frequency data are usually absent in practice. It remains challenging to predict the click feature from the visual feature, because the user-click-frequency vector of an image is always noisy and sparse. In this paper, we devise a Hierarchical Deep Word Embedding (HDWE) model by integrating sparse constraints and an improved RELU operator to address click feature prediction from visual features. HDWE is a coarse-to-fine click feature predictor that is learned with the help of an auxiliary image dataset containing click information. It can therefore discover the hierarchy of word semantics. We evaluate HDWE on three dog and one bird image datasets, in which Clickture-Dog and Clickture-Bird are respectively utilized as auxiliary datasets to provide click data. Our empirical studies show that HDWE has 1) higher recognition accuracy, 2) a larger compression ratio, and 3) good one-shot learning ability and scalability to unseen categories.","","","10.1109/TPAMI.2019.2932058","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8781933","Click prediction;Hierarchical model;Word embedding;Deep neural network;Transfer learning","Visualization;Feature extraction;Image recognition;Semantics;Predictive models;Vocabulary;Task analysis","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Joint Deep Learning of Facial Expression Synthesis and Recognition","Y. Yan; Y. Huang; S. Chen; C. Shen; H. Wang","School of Informatics, Xiamen University, 12466 Xiamen China (e-mail: yanyan@xmu.edu.cn); School of Informatics, Xiamen University, 12466 Xiamen China (e-mail: ying_hwang@qq.com); Department of Software Engineering, Xiamen University of Technology, 74616 Xiamen China (e-mail: chensi@xmut.edu.cn); School of Computer Science, The University of Adelaide, 1066 Adelaide, South Australia Australia (e-mail: chunhua.shen@adelaide.edu.au); School of Informatics, Xiamen University, 12466 Xiamen, Fujian China (e-mail: Hanzi.Wang@xmu.edu.cn)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","Recently, deep learning based facial expression recognition (FER) methods have attracted considerable attention and they usually require large-scale labelled training data. Nonetheless, the publicly available facial expression databases typically contain a small amount of labelled data. In this paper, to overcome the above issue, we propose a novel joint deep learning of facial expression synthesis and recognition method for effective FER. More specifically, the proposed method involves a two-stage learning procedure. Firstly, a facial expression synthesis generative adversarial network (FESGAN) is pretrained to generate facial images with different facial expressions. To increase the diversity of the training images, FESGAN is elaborately designed to generate images with new identities from a prior distribution. Secondly, an expression recognition network is jointly learned with the pre-trained FESGAN in a unified framework. In particular, the classification loss computed from the recognition network is used to simultaneously optimize the performance of both the recognition network and the generator of FESGAN. Moreover, in order to alleviate the problem of data bias between the real images and the synthetic images, we propose an intra-class loss with a novel real data-guided back-propagation (RDBP) algorithm to reduce the intra-class variations of images from the same class, which can significantly improve the final performance. Extensive experimental results on public facial expression databases demonstrate the superiority of the proposed method compared with several state-of-the-art FER methods.","","","10.1109/TMM.2019.2962317","Natural Science Foundation of Fujian Province of China; National Natural Science Foundation of China; National Key R and D Program of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8943107","Facial expression recognition;facial expression synthesis;convolutional neural networks (CNNs);generative adversarial net (GAN)","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Sequential Saliency Guided Deep Neural Network for Joint Mitosis Identification and Localization in Time-Lapse Phase Contrast Microscopy Images","Y. Lu; A. Liu; M. Chen; W. Nie; Y. Su","Tianjin University, Tianjin China (e-mail: hiluyao@gmail.com); Electronics Information Engineering, Tianjin University, Tianjin China 300072 (e-mail: anan0422@gmail.com); Microsoft Corp, 6834 Redmond, Washington United States (e-mail: may4mc@gmail.com); Tianjin University, 12605 Tianjin, Tianjin China (e-mail: weizhinie@tju.edu.cn); Tianjin University, Tianjin China (e-mail: ytsu@tju.edu.cn)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","The analysis of cell mitotic behavior plays important role in many biomedical research and medical diagnostic applications. To improve the accuracy of mitosis detection in automated analysis systems, this paper proposes the sequential saliency guided deep neural network (SSG-DNN) to jointly identify and localize mitotic events in time-lapse phase contrast microscopy images. It consists of three key modules. First, the module of visual context learning extracts static visual feature and dynamic visual transition within individual volumetric cell regions. Secondly, with these information, the module of sequential saliency modeling aims to discover the saliency distribution over all successive frames in each volumetric region. Finally, the module of sequence structure modeling can leverage both visual context and saliency distribution for mitosis identification and localization. SSG-DNN can jointly realize visual feature learning and sequential structure modeling in the end-to-end framework. Moreover, the proposed method is independent of complicated preconditioning methods for mitotic candidate extraction and can be applied for mitosis detection in one-shot manner. To our knowledge, it is the first weakly supervised work to realize joint mitosis identification and localization only with sequence-wise labels. In our experiments, we evaluate its performances of both tasks on the popular C3H10 dataset and a novel and large-scale dataset, C2C12-16, which contains much more mitotic events and is more challenging owing to diverse cell culture conditions. Experimental results can demonstrate the superiority of the proposed method.","","","10.1109/JBHI.2019.2943228","2018 Tianjin New Generation Artificial Intelligence Major Program; the Open Project Program of the State Key Lab of CAD and CG Zhejiang University; National Natural Science Foundation of China; Elite Scholar Program of Tianjin University; 2019 Tianjin New Generation Artificial Intelligence Major Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8846748","Microscopy Image;Mitosis Detection;Computer Vision;Deep Learning","Visualization;Feature extraction;Microscopy;Task analysis;Computer architecture;Image sequences;Informatics","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Confidence Estimation for ToF and Stereo Sensors and its Application to Depth Data Fusion","M. Poggi; G. Agresti; F. Tosi; P. Zanuttigh; S. Mattoccia","University of Bologna.; University of Padova.; University of Bologna.; University of Padova.; University of Bologna.","IEEE Sensors Journal","","2019","PP","99","1","1","Time-of-Flight (ToF) sensors and stereo vision systems are two widely used technologies for depth estimation. Due to their rather complementary strengths and limitations, the two sensors are often combined to infer more accurate depth maps. A key research issue in this field is how to estimate the reliability of the sensed depth data. While this problem has been widely studied for stereo systems, it has been seldom considered for ToF sensors. Therefore, starting from the work done for stereo data, in this paper, we firstly introduce novel confidence estimation techniques for ToF data. Moreover, we also show how by using learning-based confidence metrics jointly trained on the two sensors yields better performance. Finally, deploying different fusion frameworks, we show how confidence estimation can be exploited in order to guide the fusion of depth data from the two sensors. Experimental results show how accurate confidence cues allow outperforming state-of-the-art data fusion schemes even with the simplest fusion strategies known in the literature.","","","10.1109/JSEN.2019.2946591","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8865643","Time-of-Flight;Stereo Vision;Confidence Information;Data Fusion;Deep Learning","Estimation;Sensors;Feature extraction;Stereo vision;Reliability;Deep learning;Task analysis","","","","","","","","","","IEEE","IEEE Early Access Articles"
"CoRRN: Cooperative Reflection Removal Network","R. Wan; B. Shi; H. Li; L. Duan; A. Tan; A. Kot Chichung","School of Electrical and Electronic Engineering, Nanyang Technological University, 54761 Singapore, Singapore Singapore (e-mail: wanpeoplejie@gmail.com); School of Electronics Engineering and Computer Science, Peking University, Beijing, Beijing China 100871 (e-mail: boxin.shi@gmail.com); School of Electrical and Electronic Engineering, Nanyang Technological University, 54761 Singapore, Singapore Singapore (e-mail: hli016@e.ntu.edu.sg); Schoold of EECS, Peking University, Beijing, Beijing China (e-mail: lingyu@pku.edu.cn); School of Computer Engineering, Nanyang Technological University, Singapore, Sngapore Singapore 639798 (e-mail: asahtan@ntu.edu.sg); School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore, Singapore Singapore (e-mail: eackot@ntu.edu.sg)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Removing the undesired reflections from images taken through the glass is of broad application to various computer vision tasks. Non-learning based methods utilize different handcrafted priors such as the separable sparse gradients caused by different levels of blurs, which often fail due to their limited description capability to the properties of real-world reflections. In this paper, we propose a network with the feature-sharing strategy to tackle this problem in a cooperative and unified framework, by integrating image context information and the multi-scale gradient information. To remove the strong reflections existed in some local regions, we propose a statistic loss by considering the gradient level statistics between the background and reflections. Our network is trained on a new dataset with 3250 reflection images taken under diverse real-world scenes. Experiments on a public benchmark dataset show that the proposed method performs favorably against state-of-the-art methods.","","","10.1109/TPAMI.2019.2921574","National Research Foundation Singapore; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8733000","Reflection removal;deep learning;statistic loss;cooperative framework","Deep learning;Glass;Computer vision;Task analysis;Feature extraction;Pattern analysis","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Beyond the Patchwise Classification: Spectral-Spatial Fully Convolutional Networks for Hyperpsectral Image Classificaiton","Y. Xu; B. Du; L. Zhang","LIESMARS, Wuhan University, Wuhan, Hubei China (e-mail: yonghaoxu@qq.com); School of Computer, Wuhan University, 12390 Wuhan, Hubei China (e-mail: remoteking@whu.edu.cn); LIESMARS, Wuhan University, Wuhan, Hubei China (e-mail: zlp62@whu.edu.cn)","IEEE Transactions on Big Data","","2019","PP","99","1","1","In recent years, patchwise classification methods are commonly adopted when dealing with the hyperspectral image (HSI) classification. Despite of their promising results from the perspective of accuracy, the efficiency of these methods can hardly be ensured since there are redundant computations between adjacent patches. In this paper, we propose a spectral-spatial fully convolutional network for HSI classification with an end-to-end, pixel-to-pixel architecture. Compared with patchwise methods, the proposed framework can avoid the patch extraction and is more efficient. Since the training samples in HSIs are highly sparse, the training strategy in original fully convolutional networks is no longer feasible for HSIs. To solve this problem, we propose a novel mask matrix to assist the back-propagation in the training stage. Considering the importances of spectral and spatial features may vary for different objects and scenes, we combine both features with two weighting factors which can be adaptively learned during the network training. Besides, the dense conditional random field (CRF) is introduced into the framework to further balance the local and global information. Experiments on three benchmark HSI data sets demonstrate that the proposed method can yield competitive results with less time costs compared with patchwise methods.","","","10.1109/TBDATA.2019.2923243","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8737729","Conditional Random Field;Deep Learning;Fully Convolutional Network;Hyperspectral Image Classification","Feature extraction;Big Data;Training;Deep learning;Hyperspectral imaging;Support vector machines;Task analysis","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Computer-Aided Diagnosis in Histopathological Images of the Endometrium Using a Convolutional Neural Network and Attention Mechanisms","H. Sun; X. Zeng; T. Xu; G. Peng; Y. Ma","School of Computer Science, Wuhan University, 12390 Wuhan, Hubei China (e-mail: sunhow@whu.edu.cn); Department of Pathology, Zhengzhou University Third Hospital and Henan Province Women and Children's Hospital, 117977 Zhengzhou, Henan China (e-mail: xianxu77@163.com); Zhengzhou Ultralucia Medical Technology Company Limited, Zhengzhou, Henan China (e-mail: taoxu@ultralucia.com); Cancer center, Wuhan Union Hospital, 36630 Wuhan, Hubei China (e-mail: penggang1977@aliyun.com); School of Computer Science, Wuhan University, 12390 Wuhan, Hubei China (e-mail: ytma@whu.edu.cn)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","Uterine cancer (also known as endometrial cancer) can seriously affect the female reproductive system, and histopathological image analysis is the gold standard for diagnosing endometrial cancer. Due to the limited ability to model the complicated relationships between histopathological images and their interpretations, existing computer-aided diagnosis (CADx) approaches using traditional machine learning algorithms often failed to achieve satisfying results. In this study, we develop a CADx approach based on a convolutional neural network (CNN) and attention mechanisms, called HIENet. In the ten-fold cross-validation on ~3,300 hematoxylin and eosin (H&E) image patches from ~500 endometrial specimens, HIENet achieved a 76.91 ± 1.17% (mean ± s. d.) accuracy for four classes of endometrial tissue, i.e., normal endometrium, endometrial polyp, endometrial hyperplasia, and endometrial adenocarcinoma. Also, HIENet obtained an area-under-the-curve (AUC) of 0.9579 ± 0.0103 with an 81.04 ± 3.87% sensitivity and 94.78 ± 0.87% specificity in a binary classification task that detected endometrioid adenocarcinoma. Besides, in the external validation on 200 H&E image patches from 50 randomly-selected female patients, HIENet achieved an 84.50% accuracy in the four-class classification task, as well as an AUC of 0.9829 with a 77.97% (95% confidence interval, CI, 65.27%~87.71%) sensitivity and 100% (95% CI, 97.42%~100.00%) specificity. The proposed CADx method outperformed three human experts and five CNN-based classifiers regarding overall classification performance. It was also able to provide pathologists better interpretability of diagnoses by highlighting the histopathological correlations of local pixel-level image features to morphological characteristics of endometrial tissue.","","","10.1109/JBHI.2019.2944977","Ministry of Science and Technology of the Peoples Republic of China; Science and Technology Department of Henan Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8854180","Endometrial cancer;Hematoxylin and eosin (H and E) image;Deep learning;Class activation map (CAM);Human-machine collaboration","Cancer;Pathology;Deep learning;Lung;Support vector machines;Medical diagnostic imaging","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Evolving Deep Convolutional Neural Networks for Image Classification","Y. Sun; B. Xue; M. Zhang; G. G. Yen","College of Computer Science, Sichuan University, Chengdu 610065 CHINA and with the School of Engineering and Computer Science, Victoria University of Wellington, Wellington 6140 NEW ZEALAND.; School of Engineering and Computer Science, Victoria University of Wellington, PO Box 600, Wellington 6140, New Zealand.; School of Engineering and Computer Science, Victoria University of Wellington, PO Box 600, Wellington 6140, New Zealand.; School of Electrical and Computer Engineering, Oklahoma State University, Stillwater, OK 74078 USA.","IEEE Transactions on Evolutionary Computation","","2019","PP","99","1","1","Evolutionary paradigms have been successfully applied to neural network designs for two decades. Unfortunately, these methods cannot scale well to the modern deep neural networks due to the complicated architectures and large quantities of connection weights. In this paper, we propose a new method using genetic algorithms for evolving the architectures and connection weight initialization values of a deep convolutional neural network to address image classification problems. In the proposed algorithm, an efficient variable-length gene encoding strategy is designed to represent the different building blocks and the potentially optimal depth in convolutional neural networks. In addition, a new representation scheme is developed for effectively initializing connection weights of deep convolutional neural networks, which is expected to avoid networks getting stuck into local minimum that is typically a major issue in the backward gradient-based optimization. Furthermore, a novel fitness evaluation method is proposed to speed up the heuristic search with substantially less computational resource. The proposed algorithm is examined and compared with 22 existing algorithms on nine widely used image classification tasks, including the state-of-the-art methods. The experimental results demonstrate the remarkable superiority of the proposed algorithm over the state-of-the-art designs in terms of classification error rate and the number of parameters (weights).","","","10.1109/TEVC.2019.2916183","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8712430","Genetic algorithms;convolutional neural network;image classification;deep learning.","Computer architecture;Architecture;Optimization;Genetic algorithms;Encoding;Task analysis;Convolutional neural networks","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"A Deep Convolutional Neural Network Approach to Classify Normal and Abnormal Gastric Slow Wave Initiation from the High Resolution Electrogastrogram","A. S. Agrusa; A. A. Gharibans; A. Allegra; D. C. Kunkel; T. Coleman","Bioengineering, University of California San Diego Jacobs School of Engineering, 140242 La Jolla, California United States 92093 (e-mail: aagrusa@eng.ucsd.edu); Bioengineering, University of California, San Diego, La Jolla, California United States 92093 (e-mail: armen.gharibans@gmail.com); Electrical Engineering, University of California San Diego Jacobs School of Engineering, 140242 La Jolla, California United States (e-mail: aallegra@eng.ucsd.edu); GI Motility & Physiology Program, University of California, San Diego, San Diego, California United States (e-mail: dkunkel@ucsd.edu); Department of Bioengineering, UCSD, La Jolla, California United States 92093 (e-mail: tpcoleman@ucsd.edu)","IEEE Transactions on Biomedical Engineering","","2019","PP","99","1","1","Objective: Gastric slow wave abnormalities have been associated with gastric motility disorders. Invasive studies in humans have described normal and abnormal propagation of the slow wave. This study aims to disambiguate the abnormally functioning wave from one of normalcy using multi-electrode abdominal waveforms of the electrogastrogram (EGG). Methods: Human stomach and abdominal models are extracted from computed tomography scans. Normal and abnormal slow waves are simulated along stomach surfaces. Current dipoles at the stomachs surface are propagated to virtual electrodes on the abdomen, with a forward model. We establish a deep convolutional network (CNN) framework to classify normal and abnormal slow waves from the multi-electrode waveforms. We investigate the effects of non-idealized measurements on performance, including shifted electrode array positioning, smaller array sizes, high body mass index (BMI), and low signal-to-noise ratio (SNR).We compare the performance of our deep CNN to a linear discriminant classifier using wave propagation spatial features. Results: A deep CNN framework demonstrated robust classification, with accuracy above 90% for all SNR above 0dB, horizontal shifts within 3cm, vertical shifts within 6cm, and abdominal tissue depth within 6cm. The linear discriminant classifier was much more vulnerable to SNR, electrode placement, and BMI. Conclusion: This is the first study to attempt, and moreover succeed, in using a deep CNN to disambiguate normal and abnormal gastric slow wave patterns from high-resolution EGG data. Significance: These findings suggest that multi-electrode cutaneous abdominal recordings have potential to serve as widely deployable clinical screening tools for gastrointestinal foregut disorders.","","","10.1109/TBME.2019.2922235","Division of Computing and Communication Foundations; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8735808","Artificial Intelligence;Convolutional Neural Network;Electrogastrogram;Forward Model;Gastroenterology;Gastric Slow Wave;Machine Learning;Neural Network;Video Classification","Stomach;Electrodes;Surface waves;Signal to noise ratio;Machine learning;Tools;Pacemakers","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Reinforcement learning for joint control of traffic signals in a transportation network","J. Lee; J. Chung; K. Sohn","Seoul, Seoul Korea (the Republic of) (e-mail: traffic_control@naver.com); Seoul, Seoul Korea (the Republic of) (e-mail: jiyong369@hanmail.net); Chung-Ang University, 26729 Seoul, Seoul Korea (the Republic of) 06974 (e-mail: kmsohn@cau.ac.kr)","IEEE Transactions on Vehicular Technology","","2019","PP","99","1","1","Reinforcement learning (RL) approaches have recently been spotlighted for use in adaptive traffic-signal control on an area-wide level. Most researchers have employed multi-agent reinforcement learning (MARL) algorithms wherein each agent shares a holistic traffic state and cooperates with other agents to reach a common goal. However, MARL algorithms cannot guarantee a global optimal solution unless the actions of all agents are fully coordinated. The present study employs a RL algorithm that recognizes an entire traffic state and jointly controls all the traffic signals of multiple intersections. With this approach, a deep Q-network (DQN) that depends solely on traffic images is extended to overcome the curse of dimensionality that is associated with a large state and action space. Several front layers in a deep convolutional neural network (CNN) to approximate the true Q-function are shared by each intersection approach. Weight parameters connecting the last hidden layer to the output layer are fixed. The proposed methodology outperforms a fixed-signal operation, a fully actuated signal operation, a multi-agent RL control without coordination, and a multi-agent RL control with partial coordination.","","","10.1109/TVT.2019.2962514","National Research Foundation of Korea; Korea Agency for Infrastructure Technology Advancement; Ministry of Land, Infrastructure and Transport; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8944051","Adaptive traffic signal control;Reinforcement learning;Deep Q-network","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Flexible Deep CNN Framework for Image Restoration","Z. Jin; M. Z. Iqbal; D. Bobkov; W. Zou; X. Li; E. Steinbach","Guangdong Key Laboratory of Intelligent Information Processing, College of Electronics and Information Engineering, Shenzhen University, 47890 Shenzhen China (e-mail: jinzhi_126@163.com); Chair of Media Technology, Technische Universitat Munchen Fakultat fur Informatik, 163258 Munich, Bayern Germany (e-mail: mzafar.iqbal@tum.de); Chair of Media Technology, Technische Universitat Munchen Fakultat fur Informatik, 163258 Munich, Bayern Germany (e-mail: dmytro.bobkov@tum.de); Guangdong Key Laboratory of Intelligent Information Processing, College of Electronics and Information Engineering, Shenzhen University, 47890 Shenzhen China (e-mail: wzouszu@sina.com); the Guangdong Key Laboratory of Intelligent Information Processing, College of Electronics and Information Engineering, Shenzhen University, 47890 Shenzhen, Guangdong China (e-mail: xia.li@szu.edu.cn); Dept. of Electrical Engineering and Information Technology, Institute for Media Technology, Munich Germany 80299 (e-mail: eckehard.steinbach@tum.de)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","Image restoration is a long-standing problem in image processing and low-level computer vision. Recently, discriminative convolutional neural network (CNN)-based approaches have attracted considerable attention due to their superior performance. However, most of these frameworks are designed for one specific image restoration task; hence, they seldom show high performance on other image restoration tasks. To address this issue, we propose a flexible deep CNN framework that exploits the frequency characteristics of different types of artifacts. Hence, the same approach can be employed for a variety of image restoration tasks by adjusting the architecture. For reducing the artifacts with similar frequency characteristics, a quality enhancement network that adopts residual and recursive learning is proposed. Residual learning is utilized to speed up the training process and boost the performance; recursive learning is adopted to significantly reduce the number of training parameters as well as boost the performance. Moreover, lateral connections transmit the extracted features between different frequency streams via multiple paths. One aggregation network combines the outputs of these streams to further enhance the restored images. We demonstrate the capabilities of the proposed framework with three representative applications: image compression artifacts reduction (CAR), image denoising, and single image super-resolution (SISR). Extensive experiments confirm that the proposed framework outperforms the state-of-the-art approaches on benchmark datasets for these applications.","","","10.1109/TMM.2019.2938340","China Postdoctoral Science Foundation Grants; Guangdong Key Research Platform of Universities; National Natural Science Foundation of China; Science and Technology Program of Shenzhen; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8820082","Image restoration;Flexible CNN framework;Image decomposition;Recursive learning;Residual learning","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Semi-supervised Learning for Semantic Segmentation of Emphysema with Partial Annotations","L. Peng; L. Lin; H. Hu; Y. Zhang; H. Li; Y. Iwamoto; X. Han; Y. W. Chen","Hangzhou China 310000 (e-mail: 394964966@qq.com); Hangzhou China (e-mail: llf@zju.edu.cn); The department of radiology, Sir Run Run Shaw Hospital, Hangzhou, Zhejiang, Hangzhou China (e-mail: huhongjie@zju.edu.cn); Hangzhou, Zhejiang China (e-mail: yuezhang95@zju.edu.cn); The department of radiology, Sir Run Run Shaw Hospital, Hangzhou China (e-mail: hualili@zju.edu.cn); Minami Kusatsu Japan (e-mail: yiwamoto@fc.ritsumei.ac.jp); the College of Information Science and Engineering, Ritsumeikan University, Kusatsu Japan (e-mail: hanxhua@yamaguchi-u.ac.jp); Zhejiang University, Hangzhou China (e-mail: chen@is.ritsumei.ac.jp)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","Segmentation and quantification of each subtype of emphysema is helpful to monitor chronic obstructive pulmonary disease. Due to the nature of emphysema (diffuse pulmonary disease), it is very difficult for experts to allocate semantic labels to every pixel in the CT images. In practice, partially annotating is a better choice for the radiologists to reduce their workloads. In this paper, we propose a new end-to-end trainable semi- supervised framework for semantic segmentation of emphysema with partial annotations, in which a segmentation network is trained from both annotated and unannotated areas. In addition, we present a new loss function, referred to as Fisher loss, to enhance the discriminative power of the model and successfully integrate it into our proposed framework. Our experimental results show that the proposed methods have superior performance over the baseline supervised approach (trained with only annotated areas) and outperform the state-of-the-art methods for emphysema segmentation.","","","10.1109/JBHI.2019.2963195","Key Science and Technology Innovation Support Program of Hangzhou; Grant-in Aid for Scientific Research from the Japanese Ministry for Education Science Culture and Sports; Major Scientific Research Project of Zhejiang Lab; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8946590","emphysema semantic segmentation;semisupervised learning;partial annotations;deep learning","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Curriculum Domain Adaptation Approach to the Semantic Segmentation of Urban Scenes","Y. Zhang; P. David; H. Foroosh; B. Gong","Department of Computer Science, University of Central Florida, Orlando, Florida United States (e-mail: yangzhang@knights.ucf.edu); Computational and Information Sciences Directorate, US Army Research Laboratory, 1024 Adelphi, Maryland United States (e-mail: philip.j.david4.civ@mail.mil); Department of Computer Science, University of Central Florida, Orlando, Florida United States (e-mail: foroosh@cs.ucf.edu); A.I. Lab, Tencent, 508929 Bellevue, Washington United States (e-mail: boqinggo@outlook.com)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","During the last half decade, convolutional neural networks (CNNs) have triumphed over semantic segmentation, which is one of the core tasks in many applications such as autonomous driving. However, to train CNNs requires a considerable amount of data, which is difficult to collect and laborious to annotate. Recent advances in computer graphics make it possible to train CNNs on photo-realistic synthetic imagery with computer-generated annotations. Despite this, the domain mismatch between the real images and the synthetic data cripples the models' performance. Hence, we propose a curriculum-style learning approach to minimize the domain gap in urban scenery semantic segmentation. The curriculum domain adaptation solves easy tasks first to infer necessary properties about the target domain; in particular, the first task is to learn global label distributions over images and local distributions over landmark superpixels. These are easy to estimate because images of urban scenes have strong idiosyncrasies (e.g., the size and spatial relations of buildings, streets, cars, etc.). We then train a segmentation network while regularizing its predictions in the target domain to follow those inferred properties. In experiments, our method outperforms the baselines on two datasets and two backbone networks. We also report extensive ablation studies about our approach.","","","10.1109/TPAMI.2019.2903401","Division of Information and Intelligent Systems; National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8661514","Domain Adaptation;Semantic Segmentation;Curriculum Learning;Curriculum Domain Adaptation;Deep Learning;Self-Driving","Semantics;Image segmentation;Task analysis;Adaptation models;Neural networks;Training;Buildings","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Adaptive Deep Modeling of Users and Items Using Side Information for Recommendation","J. Han; L. Zheng; Y. Xu; B. Zhang; F. Zhuang; P. S. Yu; W. Zuo","Department of Computer Science and Technology, Jilin University, Changchun 130012, China, and also with the Key Laboratory of Symbolic Computation and Knowledge Engineering for the Ministry of Education, Jilin University, Changchun 130012, China.; Department of Computer Science, University of Illinois at Chicago, Chicago, IL 60661 USA.; Department of Computer Science and Technology, Jilin University, Changchun 130012, China, and also with the Key Laboratory of Symbolic Computation and Knowledge Engineering for the Ministry of Education, Jilin University, Changchun 130012, China.; School of Information Science and Technology, Northeast Normal University, Changchun 130117, China.; Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences (CAS), Beijing 100190, China, and also with the University of Chinese Academy of Sciences, Beijing 100049, China.; Department of Computer Science, University of Illinois at Chicago, Chicago, IL 60661 USA.; Department of Computer Science and Technology, Jilin University, Changchun 130012, China, and also with the Key Laboratory of Symbolic Computation and Knowledge Engineering for the Ministry of Education, Jilin University, Changchun 130012, China (e-mail: wanli@jlu.edu.cn).","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","12","In the existing recommender systems, matrix factorization (MF) is widely applied to model user preferences and item features by mapping the user-item ratings into a low-dimension latent vector space. However, MF has ignored the individual diversity where the user's preference for different unrated items is usually different. A fixed representation of user preference factor extracted by MF cannot model the individual diversity well, which leads to a repeated and inaccurate recommendation. To this end, we propose a novel latent factor model called adaptive deep latent factor model (ADLFM), which learns the preference factor of users adaptively in accordance with the specific items under consideration. We propose a novel user representation method that is derived from their rated item descriptions instead of original user-item ratings. Based on this, we further propose a deep neural networks framework with an attention factor to learn the adaptive representations of users. Extensive experiments on Amazon data sets demonstrate that ADLFM outperforms the state-of-the-art baselines greatly. Also, further experiments show that the attention factor indeed makes a great contribution to our method.","","","10.1109/TNNLS.2019.2909432","Scientific and Technological Development Program of Jilin Province; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8736041","Adaptive user preference model;attention factor;convolutional neural network (CNN);recommendation system.","Adaptation models;Recommender systems;Feature extraction;Computational modeling;Predictive models;Task analysis;Adaptive systems","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Scene Categorization by Deeply Learning Gaze Behavior in a Semisupervised Context","L. Zhang; R. Liang; J. Yin; D. Zhang; L. Shao","College of Computer Sciences, Zhejiang University, Hangzhou 310027, China.; College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou 310023, China (e-mail: rhliang@zjut.edu.cn).; College of Computer Sciences, Zhejiang University, Hangzhou 310027, China.; College of Computer Sciences, Zhejiang University, Hangzhou 310027, China.; Inception Institute of Artificial Intelligence, Abu Dhabi, UAE.","IEEE Transactions on Cybernetics","","2019","PP","99","1","12","Accurately recognizing different categories of sceneries with sophisticated spatial configurations is a useful technique in computer vision and intelligent systems, e.g., scene understanding and autonomous driving. Competitive accuracies have been observed by the deep recognition models recently. Nevertheless, these deep architectures cannot explicitly characterize human visual perception, that is, the sequence of gaze allocation and the subsequent cognitive processes when viewing each scenery. In this paper, a novel spatially aware aggregation network is proposed for scene categorization, where the human gaze behavior is discovered in a semisupervised setting. In particular, as semantically labeling a large quantity of scene images is labor-intensive, a semisupervised and structure-preserved non-negative matrix factorization (NMF) is proposed to detect a set of visually/semantically salient regions from each scenery. Afterward, the gaze shifting path (GSP) is engineered to characterize the process of humans perceiving each scene picture. To deeply describe each GSP, a novel spatially aware CNN termed SA-Net is developed. It accepts input regions with various shapes and statistically aggregates all the salient regions along each GSP. Finally, the learned deep GSP features from the entire scene images are fused into an image kernel, which is subsequently integrated into a kernel SVM to categorize different sceneries. Comparative experiments on six scene image sets have shown the advantage of our method.","","","10.1109/TCYB.2019.2913016","National Natural Science Foundation of China; National Basic Research Program of China (973 Program); National Science and Technology Major Project of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8721241","Deep model;machine learning;non-negative matrix factorization (NMF);scene categorization;semisupervised","Semantics;Feature extraction;Sparse matrices;Visualization;Training;Kernel;Image recognition","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Survey on Data Collection for Machine Learning: A Big Data - AI Integration Perspective","Y. Roh; G. Heo; S. E. Whang","Electrical Engineering, Korea Advanced Institute of Science and Technology, 34968 Daejeon, Daejeon Korea (the Republic of) 34141 (e-mail: rohyj113@gmail.com); Electrical Engineering, Korea Advanced Institute of Science and Technology, 34968 Daejeon, Daejeon Korea (the Republic of) (e-mail: heogoen2475@kaist.ac.kr); Electrical Engineering, Korea Advanced Institute of Science and Technology, 34968 Daejeon, Daejeon Korea (the Republic of) (e-mail: euijong@gmail.com)","IEEE Transactions on Knowledge and Data Engineering","","2019","PP","99","1","1","Data collection is a major bottleneck in machine learning and an active research topic in multiple communities. There are largely two reasons data collection has recently become a critical issue. First, as machine learning is becoming more widely-used, we are seeing new applications that do not necessarily have enough labeled data. Second, unlike traditional machine learning, deep learning techniques automatically generate features, which saves feature engineering costs, but in return may require larger amounts of labeled data. Interestingly, recent research in data collection comes not only from the machine learning, natural language, and computer vision communities, but also from the data management community due to the importance of handling large amounts of data. In this survey, we perform a comprehensive study of data collection from a data management point of view. Data collection largely consists of data acquisition, data labeling, and improvement of existing data or models. We provide a research landscape of these operations, provide guidelines on which technique to use when, and identify interesting research challenges. The integration of machine learning and data management for data collection is part of a larger trend of Big data and Artificial Intelligence (AI) integration and opens many opportunities for new research.","","","10.1109/TKDE.2019.2946162","Google AI Focused Research Award; National Research Foundation of Korea; SK Telecom; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8862913","data collection;data acquisition;data labeling;machine learning","Machine learning;Data collection;Labeling;Data models;Data acquisition;Training data;Smart manufacturing","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Multiview High Dynamic Range Image Synthesis Using Fuzzy Broad Learning System","H. Guo; B. Sheng; P. Li; C. L. P. Chen","Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai 200240, China.; Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai 200240, China (e-mail: shengbin@sjtu.edu.cn).; Department of Computing, Hong Kong Polytechnic University, Hong Kong.; School of Computer Science and Engineering, South China University of Technology, Guangzhou 510006, China, also with the Navigation College, Dalian Maritime University, Dalian 116026, China, and also with the Faculty of Science and Technology, University of Macau, Macau 999078, China.","IEEE Transactions on Cybernetics","","2019","PP","99","1","13","Compared with the normal low dynamic range (LDR) images, the high dynamic range (HDR) images provide more dynamic range and image details. Although the existing techniques for generating the HDR images have a good effect for static scenes, they usually produce artifacts on the HDR images for dynamic scenes. In recent years, some learning-based approaches are used to synthesize the HDR images and obtain good results. However, there are also many problems, including the deficiency of explaining and the time-consuming training process. In this article, we propose a novel approach to synthesize multiview HDR images through fuzzy broad learning system (FBLS). We use a set of multiview LDR images with different exposure as input and transfer corresponding Takagi-Sugeno (TS) fuzzy subsystems; then, the structure is expanded in a wide sense in the ``enhancement groups'' which transfer from the TS fuzzy rules with nonlinear transformation. After integrating fuzzy subsystems and enhancement groups with the trained-well weight, the HDR image is generated. In FBLS, applying the incremental learning algorithm and the pseudoinverse method to compute the weights can greatly reduce the training time. In addition, the fuzzy system has better interpretability. In the learning process, IF-THEN fuzzy rules can effectively help the model to detect the artifacts and reject them in the final HDR result. These advantages solve the problem of existing deep-learning methods. Furthermore, we set up a new dataset of multiview LDR images with corresponding HDR ground truth to train our system. Our experimental results show that our system can synthesize high-quality multiview HDR images, which has a higher training speed than other learning methods.","","","10.1109/TCYB.2019.2934823","National Natural Science Foundation of China; Macau Science and Technology Development Fund; National Key Research and Development Program of China; Science and Technology Commission of Shanghai Municipality; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8820128","Fuzzy broad learning system (FBLS);high dynamic range (HDR) image;multiview synthesis","Dynamic range;Learning systems;Optical imaging;Optical sensors;Image color analysis;Cameras;Image synthesis","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Knowledge-Powered Deep Breast Tumor Classification with Multiple Medical Reports","D. Chen; M. Huang; W. Li","Donghua University, 12475 Shanghai, Shanghai China (e-mail: chendehua@dhu.edu.cn); Shanghai, Shanghai China (e-mail: woshihmhj@163.com); Shanghai University, Shanghai, Shanghai China (e-mail: 108wml@gmail.com)","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2019","PP","99","1","1","Breast tumor classification with multiple medical reports such as B-ultrasound, Mammography (X-ray) and Nuclear Magnetic Resonance Imaging (MRI) is crucial to the intelligent cancer diagnosis system. Unlike the other domain texts, the medical reports have latent hierarchical syntactic structures and have hidden rich semantic information about the entities and relationships, which poses a great challenge of breast cancer classification. In this paper, we proposed a Knowledge-powered Deep Breast Tumor Classification model (KDBTC), which takes the semantic information as a kind of prior knowledge and incorporated it into deep neural networks. Specially, our proposed model first uses Hierarchical Attention Bidirectional Recurrent Neural Networks (HA-BiRNNs) to encode the syntax-aware representation of medical reports in a hierarchical way. In the HA-BiRNN, a hierarchical neural network structure, consisting in two encoder layers of BiRNN (Bidirectional Recurrent Neural Networks), mirrors the hierarchical structure of medical reports, and a hierarchical attention mechanism, consisting of two levels attentions, attends to important elements within clinical report with wordlevel attention and sentence-level attention. Secondly, our model obtains the semantic information relevant to the medical reports from the clinical domain semantic tree, and encodes the semantic representation of medical reports by using Tree Structured Recurrent Neural Network with gated recursive units (Tree-GRUs). Finally, we classify breast tumors by combining both the syntax and semantic representations of medical reports. We evaluate our method on the real-world breast cancer medical reports, and results show that our method achieves higher performance on breast cancer classification.","","","10.1109/TCBB.2019.2955484","The National Key RD Program of China; The Science and Technology Development Foundation of Shanghai; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8911259","breast tumor;deep learning;bidirectional recurrent neural networks;prior knowledge","Semantics;Breast tumors;Medical diagnostic imaging;Magnetic resonance imaging;Cancer","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Multi-Task Deep Model with Margin Ranking Loss for Lung Nodule Analysis","L. Liu; Q. Dou; H. Chen; J. Qin; P. Heng","Department of Computer Science and Engineering, and Chinese University of Hong Kong, Hong Kong.; Department of Computing, Imperial College London, UK.; Department of Computer Science and Engineering, and Chinese University of Hong Kong, Hong Kong.; Centre for Smart Health, School of Nursing and Hong Kong Polytechnic University, Hong Kong.; Department of Computer Science and Engineering, and Chinese University of Hong Kong, Hong Kong.","IEEE Transactions on Medical Imaging","","2019","PP","99","1","1","Lung cancer is the leading cause of cancer deaths worldwide and early diagnosis of lung nodule is of great importance for therapeutic treatment and saving lives. Automated lung nodule analysis requires both accurate lung nodule benignmalignant classification and attribute score regression. However, this is quite challenging due to the considerable difficulty of lung nodule heterogeneity modeling and the limited discrimination capability on ambiguous cases. To solve these challenges, we propose a Multi-Task deep model with Margin Ranking loss (referred as MTMR-Net) for automated lung nodule analysis. Compared to existing methods which consider these two tasks separately, the relatedness between lung nodule classification and attribute score regression is explicitly explored in a causeand-effect manner within our multi-task deep model, which can contribute to the performance gains of both tasks. The results of different tasks can be yielded simultaneously for assisting the radiologists in diagnosis interpretation. Furthermore, a Siamese network with a margin ranking loss is elaborately designed to enhance the discrimination capability on ambiguous nodule cases. To further explore the internal relationship between two tasks and validate the effectiveness of the proposed model, we use the recursive feature elimination method to iteratively rank the most malignancy-related features. We validate the efficacy of our method MTMR-Net on the public benchmark LIDCIDRI dataset. Extensive experiments show that the diagnosis results with internal relationship explicitly explored in our model has met some similar patterns in clinical usage and also demonstrate that our approach can achieve competitive classification performance and more accurate scoring on attributes over the state-of-the-arts. Codes are publicly available at: https://github.com/CaptainWilliam/MTMR-NET.","","","10.1109/TMI.2019.2934577","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8794587","Lung Nodule;Benign-Malignant Diagnosis;Attribute Score Regression;Deep Learning;Multi-Task","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Modeling Brain Diverse and Complex Hemodynamic Response Patterns via Deep Recurrent Autoencoder","Y. Cui; S. Zhao; Y. Chen; J. Han; L. Guo; L. Xie; T. Liu","College of Biomedical Engineering & Instrument Science, Zhejiang University, Hangzhou, 310027, China.; School of Automation, Northwestern Polytechnical University, Xi’an, 710072, China.; College of Biomedical Engineering & Instrument Science, Zhejiang University, Hangzhou, 310027, China.; School of Automation, Northwestern Polytechnical University, Xi’an, 710072, China.; School of Automation, Northwestern Polytechnical University, Xi’an, 710072, China.; College of Biomedical Engineering & Instrument Science, Zhejiang University, Hangzhou, 310027, China.; Cortical Architecture Imaging and Discovery Lab, Department of Computer Science and Bioimaging Research Center, The University of Georgia, Athens, GA, 30602, USA.","IEEE Transactions on Cognitive and Developmental Systems","","2019","PP","99","1","1","For decades, a variety of task-based functional MRI (tfMRI) data analysis approaches have been developed, including the general linear model (GLM), sparse representations, and independent component analysis (ICA). However, these methods are mainly shallow models and are limited in faithfully modeling the complex, diverse, and concurrent spatial-temporal functional brain activities. Recently, recurrent neural networks (RNNs) demonstrate great superiority in modeling temporal dependency of signals, while autoencoder models have been proven to be effective in automatically estimating the optimal representations of the original data. These characteristics of RNNs and autoencoders naturally meet the requirement of modeling hemodynamic response patterns in tfMRI data. Thus, we proposed a novel unsupervised framework of deep recurrent autoencoder (DRAE) for modeling hemodynamic response patterns in this paper. The basic idea of the DRAE model is to combine the deep recurrent neural network and autoencoder to automatically characterize the meaningful functional brain networks and corresponding diverse and complex hemodynamic response patterns simultaneously. Experimental results demonstrated the superiority of the proposed DRAE model in automatically estimating the diverse and complex hemodynamic response patterns.","","","10.1109/TCDS.2019.2949195","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8883244","Task fMRI;Brain network;Hemodynamic Response Pattern;RNN;Autoencoder;Deep learning.","Brain modeling;Hemodynamics;Data models;Task analysis;Recurrent neural networks;Feature extraction","","","","","","","","","","IEEE","IEEE Early Access Articles"
"WeGAN: Deep Image Hashing with Weighted Generative Adversarial Networks","Y. Wang; L. Zhang; F. Nie; X. Li; Z. Chen; F. Wang","China University of Geosciences, School of Land Science and Technology, Beijing China 100083 (e-mail: xxgcdxwyb@163.com); the State Key Laboratory of Remote Sensing Science, Beijing Normal University, 47836 Beijing, Beijing China 100875 (e-mail: zhanglq@bnu.edu.cn); Department of Automation, Tsinghua University, Beijing China 710072 (e-mail: feipingnie@gmail.com); Faculty of Geographical Science, Beijing Normal University, 47836 Beijing, Beijing China (e-mail: lixg95@126.com); School of Mathematical Sciences, Beijing Normal University, 47836 Beijing, Beijing China (e-mail: zhijun.chen@mail.bnu.edu.cn); School of Mathematical Sciences, Beijing Normal University, 47836 Beijing, Beijing China (e-mail: fqwang@mail.bnu.edu.cn)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","Image hashing has been widely used in image retrieval tasks. Many existing methods generate hashing codes based on image feature representations. They rarely consider the rich information such as image clustering information contained in the image set as well as uncertain relationships between images and tags simultaneously. In this paper, we develop a Weighted Generative Adversarial Networks (WeGAN) to transfer the clustering information of images to construct the hashing code. WeGAN consists three modules: 1) a hashing learning process for transferring knowledge of the image set to hashing codes of single images; 2) by means of hashing codes, a module to generate image content, tag representation, and their joint information which reflects the correlation between the image and the corresponding tags; 3) a discriminator to distinguish the generated data from the original source, and then formulating three loss functions. Different weights are assigned to these loss functions in order to deal with the uncertainties between images and tags. Through introducing the image set to process the image hashing with different tags, WeGAN can naturally provide the information of clustering results, which is useful for self-supervision of image hashing with multi-tags. The generated hashing code has the ability to dynamically process the uncertain relationships between images and tags. Experiments on three challenging datasets show that WeGAN outperforms the state-of-the-art methods.","","","10.1109/TMM.2019.2947197","National Key Research and Development Program of China; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8867954","Image Hashing;Generative Adversarial Networks;Image Set;Uncertainties between Images and Tags","Gallium nitride;Generative adversarial networks;Deep learning;Uncertainty;Semantics;Task analysis;Linear programming","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Learning Complexity-Aware Cascades for Pedestrian Detection","Z. Cai; M. J. Saberian; N. Vasconcelos","ECE, University of California San Diego, San Diego, California United States (e-mail: zwcai@eng.ucsd.edu); ECE, UC San Diego, San Diego, California United States (e-mail: mj.saberian@gmail.com); ECE, UC San Diego, La Jolla, California United States 92093 (e-mail: nvasconcelos@ucsd.edu)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","The problem of pedestrian detection is considered. The design of complexity-aware cascaded pedestrian detectors, combining features of very different complexities, is investigated. A new cascade design procedure is introduced, by formulating cascade learning as the Lagrangian optimization of a risk that accounts for both accuracy and complexity. A boosting algorithm, denoted as complexity aware cascade training (CompACT), is then derived to solve this optimization. CompACT cascades are shown to seek an optimal trade-off between accuracy and complexity by pushing features of higher complexity to the later cascade stages, where only a few difficult candidate patches remain to be classified. This enables the use of features of vastly different complexities in a single detector. In result, the feature pool can be expanded to features previously impractical for cascade design, such as the responses of a deep convolutional neural network (CNN). This is demonstrated through the design of pedestrian detectors with a pool of features whose complexities span orders of magnitude. The resulting cascade generalizes the combination of a CNN with an object proposal mechanism: rather than a pre-processing stage, CompACT cascades seamlessly integrate CNNs in their stages. This enables accurate detection on the Caltech and KITTI datasets, at fairly fast speeds.","","","10.1109/TPAMI.2019.2910514","National Science Foundation; Office of Naval Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8686227","Real-time pedestrian detection;detector cascades;boosting;complexity constrained learning","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Learning Part-based Convolutional Features for Person Re-identification","Y. Sun; L. Zheng; Y. Li; Y. Yang; Q. Tian; S. Wang","electronic engineering, Tsinghua University, 12442 Beijing, Beijing China 100084 (e-mail: sunyf15@mails.tsinghua.edu.cn); QCIS, University of Technology Sydney, Sydney, New South Wales Australia 2007 (e-mail: liangzheng06@gmail.com); Electronic Engineering, Tsinghua University, 12442 Beijing, Beijing China 100084 (e-mail: liyali13@tsinghua.edu.cn); FEIT, University of Technology Sydney, Sydney, NSW China (e-mail: yee.i.yang@gmail.com); Computer Science Department, University of Texas at San Antonio, San Antonio, Texas United States (e-mail: Qi.Tian@utsa.edu); EE, Tsinghua University, Beijing, Beijing China (e-mail: wgsgj@tsinghua.edu.cn)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Part-level features offers fine granularity for pedestrian image description. In this article, we generally aim to learn discriminative part-informed features for person re-identification. Our contribution is two-fold. First, we introduce a general part-level feature learning method, named Part-based Convolutional Baseline (PCB). Given an image, it outputs a convolutional descriptor consisting of several part-level features. PCB is general in that it is able to accommodate several part partitioning strategies. In experiment, we show that the learned descriptor maintains a significantly higher discriminative ability than the global descriptor. Second, Based on PCB, we propose refined part pooling (RPP) to improve the original partition. Our idea is that pixels within a well-located part should be similar to each other while being dissimilar with pixels from other parts. We call it within-part consistency. When a pixel-wise feature vector in a part is more similar to some other part, it is then an outlier, indicating inappropriate partitioning. RPP re-assigns these outliers to the parts they are closest to, resulting in refined parts with enhanced within-part consistency. Experiment confirms that RPP gains another round of performance boost over PCB. For instance, on the Market-1501 dataset, we achieve (77.4+4.2)% mAP and (92.3+1.5)% rank-1 accuracy, a competitive performance with the state of the art.","","","10.1109/TPAMI.2019.2938523","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8826008","Person Re-identification;Part-based Convolutional Baseline;Part Refinement","Pose estimation;Training;Feature extraction;Deep learning;Semantics;Sun;Labeling","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Spectral Adversarial Feature Learning for Anomaly Detection in Hyperspectral Imagery","W. Xie; B. Liu; Y. Li; J. Lei; C. Chang; G. He","State Key Laboratory of Integrated Service Networks, Xidian University, Xi'an 710071, China.; State Key Laboratory of Integrated Service Networks, Xidian University, Xi'an 710071, China.; State Key Laboratory of Integrated Service Networks, Xidian University, Xi'an 710071, China (e-mail: ysli@mail.xidian.edu.cn).; State Key Laboratory of Integrated Service Networks, Xidian University, Xi'an 710071, China.; Center of Hyperspectral Imaging in Remote Sensing, Information and Technology College, Dalian Maritime University, Dalian 116026, China, with the Department of Computer Science and Information Engineering, National Yunlin University of Science and Technology, Douliu 64002, Taiwan, with the Remote Sensing Signal and Image Processing Laboratory, Department of Computer Science and Electrical Engineering, University of Maryland, Baltimore, MD 21250 USA, and also with the Department of Computer Science and Information Management, Providence University, Taichung 02912, Taiwan.; State Key Laboratory of Integrated Service Networks, Xidian University, Xi'an 710071, China (e-mail: ghe@xidian.edu.cn).","IEEE Transactions on Geoscience and Remote Sensing","","2019","PP","99","1","14","Theoretically, hyperspectral images (HSIs) are capable of providing subtle spectral differences between different materials, but in fact, it is difficult to distinguish between background and anomalies because the samples of anomalous pixels in HSIs are limited and susceptible to background and noise. To explore the discriminant features, a spectral adversarial feature learning (SAFL) architecture is specially designed for hyperspectral anomaly detection in this article. In addition to reconstruction loss, SAFL also introduces spectral constraint loss and adversarial loss in the network with batch normalization to extract the intrinsic spectral features in deep latent space. To further reduce the false alarm rate, we present an iterative optimization approach by a weighted suppression function that depends on the contribution rate of each feature to the detection. In particular, the structure tensor matrix is adopted to adaptively calculate the contribution rate of each feature. Benefiting from these improvements, the proposed method is superior to the typical and state-of-the-art methods either in detection probability or false alarm rate.","","","10.1109/TGRS.2019.2948177","National Natural Science Foundation of China; Young Talent Fund of University Association for Science and Technology in Shaanxi of China; Special Financial Grant from the China Postdoctoral Science Foundation; 111 Project; Fundamental Research Funds for the Central Universities; Natural Science Basic Research Plan in Shaanxi Province of China; General Financial Grant from the China Postdoctoral Science Foundation; Yangtse Rive Scholar Bonus Schemes; Ten Thousand Talent Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8892616","Adversarial learning;anomaly detection;feature extraction;hyperspectral image (HSI);iterative optimization.","Feature extraction;Anomaly detection;Hyperspectral imaging;Decoding;Image reconstruction;Training","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Ensemble Convolutional Neural Networks for Mode Inference in Smartphone Travel Survey","A. Yazdizadeh; Z. Patterson; B. Farooq","Department of Geography, Planning and Environment, Concordia University, Montreal, QC H3G 1M8, Canada (e-mail: ali.yazdizadeh.pres@gmail.com).; Department of Geography, Planning and Environment, Concordia University, Montreal, QC H3G 1M8, Canada.; Department of Civil Engineering, Ryerson University, Toronto, ON M5B 2K3, Canada.","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","8","We develop ensemble convolutional neural networks (CNNs) to classify the transportation mode of trip data collected as part of a large-scale smartphone travel survey in Montreal, Canada. Our proposed ensemble library is composed of a series of CNN models with different hyper-parameter values and CNN architectures. In our final model, we combine the output of CNN models using ``average voting,'' ``majority voting,'' and ``optimal weights'' methods. Furthermore, we exploit the ensemble library by deploying a random forest model as a meta-learner. The ensemble method with random forest as meta-learner shows an accuracy of 91.8% which surpasses the other three ensemble combination methods, and other comparable models reported in the literature. The ``majority voting'' and ``optimal weights'' combination methods result in prediction accuracy rates around 89%, while ``average voting'' is able to achieve an accuracy of only 85%.","","","10.1109/TITS.2019.2918923","Social Sciences and Humanities Research Council of Canada; Canada Research Chairs; MTL Trajet research contract with the Ville de Montreal; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8733201","Deep learning;convolutional neural networks;meta learning;smartphone travel surveys;GPS trajectories;mode inference;machine learning.","Global Positioning System;Trajectory;Transportation;Predictive models;Feature extraction;Convolutional neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Feature Re-Learning with Data Augmentation for Video Relevance Prediction","J. Dong; X. Wang; L. Zhang; C. Xu; G. Yang; X. Li","College of Computer and Information Engineering, Zhejiang Gongshang University, 12625 Hangzhou, Zhejiang China (e-mail: dongjf24@gmail.com); College of Computer and Information Engineering, Zhejiang Gongshang University, 12625 Hangzhou, Zhejiang China (e-mail: wx@mail.zjgsu.edu.cn); College of Computer and Information Engineering, Zhejiang Gongshang University, 12625 Hangzhou, Zhejiang China (e-mail: zlm390178067@163.com); School of Information, Renmin University of China, 12471 Beijing, Beijing China (e-mail: xcx@ruc.edu.cn); School of Information, Renmin University of China, 12471 Beijing, Beijing China (e-mail: yanggang@ruc.edu.cn); Key Lab of Data Engineering and Knowledge Engineering, Renmin University of China, 12471 Beijing, Beijing China (e-mail: xirong@ruc.edu.cn)","IEEE Transactions on Knowledge and Data Engineering","","2019","PP","99","1","1","Predicting the relevance between two given videos with respect to their visual content is a key component for content-based video recommendation and retrieval. Thanks to the increasing availability of pre-trained image and video Convolutional Neural Network (CNN) models, deep visual features are widely used for video content representation. However, as how two videos are relevant is task-dependent, such off-the-shelf features are not always optimal for all tasks. Moreover, due to varied concerns including copyright, privacy and security, one might have access to only pre-computed video features rather than original videos. We propose in this paper feature re-learning for video relevance prediction. A given feature is projected into a new space by an affine transformation. Different from previous works that use a standard triplet ranking loss, we optimize the projection process by a novel negative-enhanced triplet ranking loss. In order to generate more training data, we propose a new data augmentation strategy which works directly on video features. Extensive experiments in the context of the Hulu Content-based Video Relevance Prediction Challenge 2018 justifies the effectiveness of the proposed method and its state-of-the-art performance for content-based video relevance prediction.","","","10.1109/TKDE.2019.2947442","National Natural Science Foundation of China; Natural Science Foundation of Zhejiang Province; Fundamental Research Funds for the Central Universities and the Research Funds of Renmin University of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8869872","Feature Re-learning;Ranking Loss;Data Augmentation;Content-based Video Recommendation","Visualization;Task analysis;Feature extraction;Training;Image color analysis;Standards;Metadata","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Heterogeneous Domain Adaptation via Nonlinear Matrix Factorization","H. Li; S. J. Pan; S. Wang; A. C. Kot","School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore 639798 (e-mail: hli016@e.ntu.edu.sg).; School of Computer Science and Engineering, Nanyang Technological University, Singapore 639798.; Department of Computer Science, College of Science and Engineering, Hong Kong.; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore 639798.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","13","Heterogeneous domain adaptation (HDA) aims to solve the learning problems where the source- and the target-domain data are represented by heterogeneous types of features. The existing HDA approaches based on matrix completion or matrix factorization have proven to be effective to capture shareable information between heterogeneous domains. However, there are two limitations in the existing methods. First, a large number of corresponding data instances between the source domain and the target domain are required to bridge the gap between different domains for performing matrix completion. These corresponding data instances may be difficult to collect in real-world applications due to the limited size of data in the target domain. Second, most existing methods can only capture linear correlations between features and data instances while performing matrix completion for HDA. In this paper, we address these two issues by proposing a new matrix-factorization-based HDA method in a semisupervised manner, where only a few labeled data are required in the target domain without requiring any corresponding data instances between domains. Such labeled data are more practical to obtain compared with cross-domain corresponding data instances. Our proposed algorithm is based on matrix factorization in an approximated reproducing kernel Hilbert space (RKHS), where nonlinear correlations between features and data instances can be exploited to learn heterogeneous features for both the source and the target domains. Extensive experiments are conducted on cross-domain text classification and object recognition, and experimental results demonstrate the superiority of our proposed method compared with the state-of-the-art HDA approaches.","","","10.1109/TNNLS.2019.2913723","National Research Foundation NRF NSFC Prime Ministers Office Singapore; NTU Singapore Nanyang Assistant Professorship NAP; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8725935","Heterogeneous domain adaptation (HDA);matrix factorization;reproducing kernel Hilbert space (RKHS).","Kernel;Task analysis;Training;Object recognition;Correlation;Hilbert space;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Inception-Residual Laplacian Pyramid Networks for Accurate Single-Image Super-Resolution","Y. Tang; W. Gong; X. Chen; W. Li","AInnovation Co., Ltd., Beijing 100089, China.; Key Laboratory of Optoelectronic Technology and System of Education Ministry, Chongqing University, Chongqing 400044, China (e-mail: wggong@cqu.edu.cn).; Key Laboratory of Optoelectronic Technology and System of Education Ministry, Chongqing University, Chongqing 400044, China.; Key Laboratory of Optoelectronic Technology and System of Education Ministry, Chongqing University, Chongqing 400044, China.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","15","With exploiting contextual information over large image regions in an efficient way, the deep convolutional neural network has shown an impressive performance for single-image super-resolution (SR). In this paper, we propose a new deep convolutional network by cascading multiple well-designed inception-residual blocks within the deep Laplacian pyramid framework to progressively restore the missing high-frequency details in the low-resolution images. By optimizing our network structure, the trainable depth of our proposed network gains a significant improvement, which in turn improves super-resolving accuracy. However, the saturation and degradation of training accuracy remains a critical problem. With regard to this, we propose an effective two-stage training strategy, in which we first use the images downsampled from the ground-truth high-resolution (HR) images to pretrain the inception-residual blocks on each pyramid level with an extremely high learning rate enabled by gradient clipping, and then the original ground-truth HR images are used to fine-tune all the pretrained inception-residual blocks for obtaining our final SR models. Furthermore, we present a new loss function operating in both image space and local rank space to optimize our network for exploiting the contextual information among different output components. Extensive experiments on benchmark data sets validate that the proposed method outperforms the existing state-of-the-art SR methods in terms of the objective evaluation as well as the visual quality.","","","10.1109/TNNLS.2019.2920852","Key Projects of Science and Technology Agency of Guangxi Province China; National Natural Science Foundation of China; Municipal Science and Technology Project of CQMMC China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8750865","Convolutional neural networks (CNNs);Laplacian pyramid framework;local rank space;single-image super-resolution (SR).","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"An Unsupervised Embedding Learning Feature Representation Scheme for Network Big Data Analysis","W. Guo; Y. Shi; S. Wang; N. Xiong","Mathematics and Computer Science, Fuzhou University, Fuzhou, Fuzhou China 350108 (e-mail: guowenzhong@fzu.edu.cn); College of Mathematics and Computer Science, Fuzhou University, Fuzhou, Fujian China (e-mail: 417shelly@gmail.com); Fuzhou University, 12423 Fuzhou, Fujian China 350002 (e-mail: shipingwangphd@163.com); Dept of CS, Colorado Technical University, colorado Springs, Colorado United States (e-mail: xiongnaixue@gmail.com)","IEEE Transactions on Network Science and Engineering","","2019","PP","99","1","1","With the arrival of the big data era, data come frequently with increasing volume and high dimensionality, which imposes a considerable challenge on data compression in network representation and analysis.How to learn an effective low-dimensional representation has a dramatic influence on learning performance. In this paper, we propose an unsupervised embedding learning feature representation scheme by deep Siamese neural networks. Unsupervised embedding learning is one tough but interesting task since its searching strategy is performed without the guidance of class label information. Siamese network is a neural network that can learn an efficient feature subspace in a supervised mode. It trains two networks with shared weights simultaneously, and feeds them with random sampling from the same dataset. As a result, the feature space is projected onto a low-dimensional subspace such that the similar samples are with small values close to zero, whereas the dissimilar ones come with big values greater than a predefined margin. The proposed method can be used to address semi-supervised feature representation problems. Finally, the learned unsupervised embedding is validated on eight publicly available databases including images, voices and text documents. Extensive experiments demonstrate the superiority of the proposed method against the existing state-of-the-art embedding approaches","","","10.1109/TNSE.2019.2903913","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8663452","Artificial intelligence;big data;network analysis;machine learning;Siamese network;embedding learning","Neural networks;Measurement;Manifolds;Training;Optimization;Big Data;Kernel","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Self-Paced Collaborative and Adversarial Network for Unsupervised Domain Adaptation","W. Zhang; D. Xu; W. Ouyang; W. Li","EIE, Sydney, New South Wales Australia (e-mail: zhangweichen2006@gmail.com); School of Electrical and Information Engineering, The University of Sydney, Sydney, New South Wales Australia 2006 (e-mail: dong.xu@sydney.edu.au); School of Electrical and Information Engineering, University of Sydney, Sydney, New South Wales Australia (e-mail: wanli.ouyang@sydney.edu.au); Computer Vision Laboratory, Eidgenossische Technische Hochschule Zurich, 27219 Zurich, Zurich Switzerland 8092 (e-mail: liwen@vision.ee.ethz.ch)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","This paper proposes a new unsupervised domain adaptation approach called Collaborative and Adversarial Network (CAN), which uses the domain-collaborative and domain-adversarial learning for training the neural network. We show that these two learning strategies can be uniformly formulated as a domain classifier learning with positive or negative weights on the losses. Moreover, to further enhance the descriminability in the target domain, we propose Self-Paced CAN (SPCAN), which progressively selects pseudo-labeled target samples for re-training the classifiers. Additionally, we extend our domain adaptation approach for more difficult video action recognition task, which is based on the popular two stream approach but additionally considering the cooperation between the RGB stream and the optical flow stream. We propose the Cooperative SPCAN (CoSPCAN) method to select and reweigh the pseudo labeled target samples of one stream (RGB/Flow) based on the information from another stream (Flow/RGB) in a cooperative way. As a result, our CoSPCAN model is able to exchange the information between the two streams. Comprehensive experiments on different benchmark datasets for the object recognition task and the video action recognition task, show our newly proposed approach achieves state-of-the-art performance, which clearly demonstrate the effectiveness of our proposed approaches for unsupervised domain adaptation.","","","10.1109/TPAMI.2019.2962476","Australian Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8943120","domain adaptation;transfer learning;deep learning;adversarial learning;self-paced learning","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Cyber Vulnerability Intelligence for IoT Binary","S. Liu; M. Dibaei; Y. Tai; C. Chen; J. Zhang; Y. Xiang","School of Software and Electrical Engineering, Swinburne University of Technology, 3783 Melbourne, Victoria Australia 3122 (e-mail: liushigang103@163.com); Department of Computing, Macquarie University, 7788 Sydney, New South Wales Australia 2109 (e-mail: dibayimahdi@yahoo.com); Yunnan Normal University, 66343 Kunming, Yunnan China 650101 (e-mail: taiyonghang@ynnu.edu.cn); School of Software and Electrical Engineering, Swinburne University of Technology, 3783 Hawthorn, Victoria Australia 3122 (e-mail: chaochen@swin.edu.au); School of Software and Electrical Engineering, Swinburne University of Technology, 3783 Hawthorn, Victoria Australia 3122 (e-mail: junzhang@swin.edu.au); School of Software and Electrical Engineering, Swinburne University of Technology - Hawthorn Campus, 3783 Hawthorn, Victoria Australia 3122 (e-mail: yxiang@swin.edu.au)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","Internet of Things (IoT) integrates a variety of software (e.g., autonomous vehicles and military systems) in order to enable the advanced and intelligent services. These software increase the potential of cyber-attacks because an adversary can launch an attack using system vulnerabilities. Existing software vulnerability analysis methods used to be relying on human experts crafted features, which usually miss many vulnerabilities. It is important to develop an automatic vulnerability analysis system to improve the countermeasures. However, source code is not always available (e.g., most IoT related industry software are closed source). Therefore, vulnerability detection on binary code is a demanding task. This paper addresses the automatic binary-level software vulnerability detection problem by proposing a deep learning-based approach. The proposed approach consists of two phases: binary function extraction, and model building. First, we extract binary functions from the cleaned binary instructions obtained by using \text{IDA Pro}. Then, we employ the attention mechanism on top of a bidirectional LSTM for building the predictive model. To show the effectiveness of the proposed approach, we collected data sets from several different sources. We compared our proposed approach with a series of baselines including source code-based techniques and binary code-based techniques. We also applied the proposed approach to real-world IoT related software such as VLC media player and LibTIFF project that used on Autonomous Vehicles. Experimental results show that our proposed approach betters the baselines and is able to detect more vulnerabilities.","","","10.1109/TII.2019.2942800","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8892533","Software vulnerability;binary code;deep learning;machine learning","Software;Binary codes;Predictive models;Machine learning;Buildings;Feature extraction;Autonomous vehicles","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Reference Generation with Multi-Domain Hierarchical Constraints for Inter Prediction","J. Liu; S. Xia; W. Yang","Institute of Computer Science and Technology, Peking University, 12465 Beijing China 100871 (e-mail: liujiaying@pku.edu.cn); Institute of Computer Science and Technology, Peking University, 12465 Beijing China (e-mail: sfxia18@163.com); Institute of Computer Science & Techology, Peking University, 12465 Beijing, Beijing China 100871 (e-mail: yangwenhan@pku.edu.cn)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","Inter prediction is an important module in video coding for temporal redundancy removal, where similar reference blocks are searched from previously coded frames and employed to predict the block to be coded. Although existing video codecs can estimate and compensate for block-level motions, their inter prediction performance is still heavily affected by the remaining inconsistent pixel-wise displacement caused by irregular rotation and deformation. In this paper, we address the problem by proposing a deep frame interpolation network to generate additional reference frames in coding scenarios. First, we summarize the previous adaptive convolutions used for frame interpolation and propose a factorized kernel convolutional network to improve the modeling capacity and simultaneously keep its compact form. Second, to better train this network, multi-domain hierarchical constraints are introduced to regularize the training of our factorized kernel convolutional network. For spatial domain, we use a gradually down-sampled and up-sampled auto-encoder to generate the factorized kernels for frame interpolation at different scales. For quality domain, considering the inconsistent quality of the input frames, the factorized kernel convolution is modulated with quality-related features to learn to exploit more information from high quality frames. For frequency domain, a sum of absolute transformed difference loss that performs frequency transformation is utilized to facilitate network optimization from the view of coding performance. With the well-designed frame interpolation network regularized by multidomain hierarchical constraints, our method surpasses HEVC on average 3.8% BD-rate saving for the luma component under the random access configuration and also obtains on average 0.83% BD-rate saving over the upcoming VVC.","","","10.1109/TMM.2019.2961504","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8938722","High Efficient Video Coding (HEVC);inter prediction;frame interpolation;deep learning;multi-domain hierarchical constraints;factorized kernel convolution","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Reinforcement Learning for 5G Networks: Joint Beamforming, Power Control, and Interference Coordination","F. B. Mismar; B. L. Evans; A. Alkhateeb","Wireless Networking and Communications Group, Dept. of Electrical and Comp. Eng and University of Texas at Austin, Austin, TX, 78712, USA.; Wireless Networking and Communications Group, Dept. of Electrical and Comp. Eng and University of Texas at Austin, Austin, TX, 78712, USA.; School of Electrical, Computer and Energy Engineering at Arizona State University, Tempe, AZ 85287, USA.","IEEE Transactions on Communications","","2019","PP","99","1","1","The fifth generation of wireless communications (5G) promises massive increases in traffic volume and data rates, as well as improved reliability in voice calls. Jointly optimizing beamforming, power control, and interference coordination in a 5G wireless network to enhance the communication performance to end users poses a significant challenge. In this paper, we formulate the joint design of beamforming, power control, and interference coordination as a non-convex optimization problem to maximize the signal to interference plus noise ratio (SINR) and solve this problem using deep reinforcement learning. By using the greedy nature of deep Q-learning to estimate future rewards of actions and using the reported coordinates of the users served by the network, we propose an algorithm for voice bearers and data bearers in sub-6 GHz and millimeter wave (mmWave) frequency bands, respectively. The algorithm improves the performance measured by SINR and sum-rate capacity. In realistic cellular environments, the simulation results show that our algorithm outperforms the link adaptation industry standards for sub-6 GHz voice bearers. For data bearers in the mmWave frequency band, our algorithm approaches the maximum sum rate capacity, but with less than 4% of the required run time.","","","10.1109/TCOMM.2019.2961332","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8938771","","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Learning-Based Energy-Efficient Resource Management by Heterogeneous RF/VLC for Ultra-Reliable Low-Latency Industrial IoT Networks","H. Yang; A. Alphones; W. Zhong; C. Chen; X. Xie","School of Electrical and Electronic Engineering, Nanyang Technological University, 54761 Singapore Singapore 639798 (e-mail: HYANG013@e.ntu.edu.sg); Nanyang Technological University, 54761 Singapore, Singapore Singapore 639798 (e-mail: ealphones@ntu.edu.sg); School of Electrical and Electronic Engineering, Nanyang Technological University, 54761 Singapore, Singapore Singapore 639798 (e-mail: ewdzhong@ntu.edu.sg); school of microelectronics and communication engineering, Chongqing University, 47913 Chongqing, Sichuan China 400044 (e-mail: c.chen@cqu.edu.cn); Chongqing Key Lab of Computer Network and Communication Technology, Chongqing University of Posts and Telecommunications, 12419 Chongqing, Chongqing China 400065 (e-mail: xiexzh@cqupt.edu.cn)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","Smart factory under Industry 4.0 and industrial Internet of Thighs (IoT) has attracted much attention from both academia and industry. In wireless industrial networks, massive Machine Type Communication (mMTC) can effectively support a variety of IoT applications, where industrial IoT (IIoT) and IoT devices have different quality-of-service (QoS) requirements, ranging from high reliability and low-latency to high transmission data rates. These industrial networks will be highly complex and heterogeneous, as well as the spectrum and energy resources are severely limited. Hence, this paper presents a heterogeneous radio frequency (RF)/visible light communication (VLC) industrial network architecture to guarantee the different QoS requirements, where RF is capable of offering wide-area coverage and VLC has the ability to provide high transmission data rate. A joint uplink and downlink energy-efficient resource management decision-making problem (network selection, subchannel assignment and power management) is formulated as a Markov decision process. In addition, a new deep post-decision state (PDS) based experience replay and transfer (PDS-ERT) reinforcement learning algorithm is proposed to learn the optimal policy. Simulation results corroborate the superiority in performance of the presented heterogeneous network, and verify that the proposed PDS-ERT learning algorithm outperforms other existing algorithms in terms of meeting the energy efficiency and the QoS requirements.","","","10.1109/TII.2019.2933867","Key Science and Technology Research Program of Chongqing Municipal Education Commission; Delta-NTU Corporate Lab for Cyber-Physical Systems with funding support from Delta Electronics Inc.; National Nature Science Foundation of China; National Research Foundation Singapore under the Corp Lab University Scheme; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8792078","Industrial Internet of Things;heterogeneous RF/VLC industrial networks;URLLC;energy efficiency;resource management;deep reinforcement learning","Reliability;Radio frequency;Quality of service;Resource management;Uplink;Computer network reliability;Informatics","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Fuzzy Neural Networks for Biomarker Selection for Accurate Cancer Detection","T. K. Bamunu Mudiyanselage; X. Xiao; Y. Zhang; Y. Pan","Computer Science, Georgia State University, 1373 Atlanta, Georgia United States 30302-5060 (e-mail: tbamunumudiyanselag1@student.gsu.edu); Computer Science, Georgia State University, 1373 Atlanta, Georgia United States (e-mail: xxiao2@student.gsu.edu); Computer Science, Georgia State University, 1373 Atlanta, Georgia United States (e-mail: yzhang@gsu.edu); Computer Science, Georgia State University, 1373 Atlanta, Georgia United States (e-mail: yipan@gsu.edu)","IEEE Transactions on Fuzzy Systems","","2019","PP","99","1","1","Different biomedical computing methods for cancer specific gene recognition have been developed in recent years. Currently, how to build an open-box machine learning system to discover explainable knowledge from gene expression data is a difficult research problem due to a large number of genes, a small number of samples and noise. Fuzzy systems can be used to deal with data ambiguity and noise issues and extract meaningful knowledge from gene data. In this research, we create a new deep fuzzy neural network to handle uncertainty in gene data to generate useful knowledge for specific disease diagnosis. A new hybrid algorithm is designed to preprocess data and select informative genes for accurate cancer detection. Various experiments using six different cancer data sets indicate that the new method has better and more reliable performance than other conventional classification methods with different gene selection methods.","","","10.1109/TFUZZ.2019.2958295","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8928970","deep fuzzy neural networks;feature selection;explainable machine learning systems;cancer detection;biomarker selection;gene expression data","Cancer;Feature extraction;Fuzzy neural networks;Support vector machines;Gene expression;Cancer detection","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Switchable Deep Learning Approach for In-loop Filtering in Video Coding","D. Ding; L. Kong; G. Chen; Z. Liu; Y. Fang","School of Information Science and Engineering, Hangzhou Normal University, Hangzhou, Zhejiang 311121, China.; School of Information Science and Engineering, Hangzhou Normal University, Hangzhou, Zhejiang 311121, China.; School of Information Science and Engineering, Hangzhou Normal University, Hangzhou, Zhejiang 311121, China.; Visionular Inc., Mountain View, CA 94040.; School of Information Engineering, Chang’an University, Xi’an, Shannxi 710064, China.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Deep learning provides a great potential for in-loop filtering to improve both coding efficiency and subjective quality in video coding. State-of-the-art work focuses on network structure design and employs a single powerful network to solve all problems. In contrast, this paper proposes a deep learning based systematic approach that includes an effective Convolutional Neural Network (CNN) structure, a hierarchical training strategy, and a video codec oriented switchable mechanism. First, we propose a novel CNN structure, i.e., Squeeze-and-Excitation Filtering CNN (SEFCNN), as an optional in-loop filter. To capture the non-linear interaction between channels, the SEFCNN is comprised of two subnets, i.e., Feature EXtracting (FEX) subnet and Feature ENhancing (FEN) subnet. Then, we develop a hierarchical model training strategy to adapt the two subnets to different coding scenarios. For high-rate videos with small artifacts, we train a single global model using the FEX for all types of frames, whereas for low-rate videos with large artifacts, different models are trained using both FEX and FEN for different types of frames. Finally, we propose an adaptive enhancing mechanism which is switchable between the CNN-based and the conventional methods. We selectively apply the CNN model to some frames or some regions in a frame. Experimental results show that the proposed scheme outperforms state-of-the-art work in coding efficiency, while the computational complexity is acceptable after GPU acceleration.","","","10.1109/TCSVT.2019.2935508","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8801877","CNN;in-loop filter;video coding;enhancement","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Adversarial Training for Multi-Organ Nuclei Segmentation in Histopathology Images","F. Mahmood; D. Borders; R. Chen; G. N. McKay; K. J. Salimian; A. Baras; N. J. Durr","Department of Biomedical Engineering, Johns Hopkins University (JHU), Baltimore, MD 21218, they and Department of Pathology at the Brigham and Womens Hospital and Departments of Pathology and Biomedical Informatics at Harvard Medical School.; Department of Biomedical Engineering, Johns Hopkins University.; Department of Biomedical Engineering, Johns Hopkins University.; Department of Biomedical Engineering, Johns Hopkins University.; Department of Pathology, Johns Hopkins School of Medicine.; Department of Pathology, Johns Hopkins School of Medicine.; Department of Biomedical Engineering, Johns Hopkins University.","IEEE Transactions on Medical Imaging","","2019","PP","99","1","1","Nuclei segmentation is a fundamental task for various computational pathology applications, including nuclei morphology analysis, cell type classification, and cancer grading. Deep learning has emerged as a powerful approach to segmenting nuclei, but the accuracy of convolutional neural networks (CNNs) depends on the volume and quality of labeled histopathology data for training. In particular, conventional CNN-based approaches lack structured prediction capabilities, which are required to distinguish overlapping and clumped nuclei. Here, we present an approach to nuclei segmentation that overcomes these challenges by utilizing a conditional generative adversarial network (cGAN) trained with synthetic and real data. We generate a large dataset of H&E training images with perfect nuclei segmentation labels using an unpaired GAN framework. This synthetic data along with real histopathology data from six different organs are used to train a conditional GAN with spectral normalization and gradient penalty for nuclei segmentation. This adversarial regression framework enforces higher-order spacial-consistency when compared to conventional CNN models. We demonstrate that this nuclei segmentation approach generalizes across different organs, sites, patients and disease states, and outperforms conventional approaches, especially in isolating individual and overlapping nuclei.","","","10.1109/TMI.2019.2927182","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8756037","Nuclei segmentation;Histopathology segmentation;Computational pathology;Deep Learning;Adversarial Training;Synthetic Data;Synthetic Pathology Data","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Memory Mechanisms for Discriminative Visual Tracking Algorithms with Deep Neural Networks","L. Wang; L. Zhang; J. Wang; Z. Yi","Machine Intelligence Laboratory, College of Computer Science, Sichuan University, Chengdu 610065, China.; Machine Intelligence Laboratory, College of Computer Science, Sichuan University, Chengdu 610065, China.; Machine Intelligence Laboratory, College of Computer Science, Sichuan University, Chengdu 610065, China.; Machine Intelligence Laboratory, College of Computer Science, Sichuan University, Chengdu 610065, China.","IEEE Transactions on Cognitive and Developmental Systems","","2019","PP","99","1","1","Deep neural networks based online visual tracking methods have achieved state-of-the-art results. One of the core components of these methods is the memory pool, in which a number of samples consisting of image patches and the corresponding labels are stored to update the online tracking network. Hence, the mechanism of updating the stored samples determines the performance of the tracking method. In this paper, a novel memory mechanism is proposed to control the writing and reading accesses of the memory pool using credit assignment network H, which learns features of the target object. This memory mechanism comprises the writing and reading mechanisms. In the writing mechanism, network H produces credits for the current tracked object and the samples in the memory pool. This ensures that the reliable samples are written into the memory pool and the unreliable samples are replaced if the memory pool is full. In the reading mechanism, network H assigns an importance score to each sample selected to update the online tracking network. The state-of-the-art tracking methods with and without the proposed memory mechanism are evaluated on the CVPR2013 and OTB100 benchmarks. Experimental results demonstrated that the proposed memory mechanism improves tracking performance significantly.","","","10.1109/TCDS.2019.2900506","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8648225","memory mechanisms;deep neural networks;online learning;visual tracking.","Target tracking;Visualization;Feature extraction;Writing;Neural networks;Reliability","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Video Anomaly Detection and Localization Based on an Adaptive Intra-frame Classification Network","K. Xu; T. Sun; X. Jiang","School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, 12474 Shanghai China 200240 (e-mail: xuke900708@163.com); School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, 12474 Shanghai China (e-mail: tfsun@sjtu.edu.cn); School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, 12474 Shanghai China 200240 (e-mail: xhjiang@sjtu.edu.cn)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","Anomaly detection and localization in videos is still a challenging task in computer vision field. Previous methods took this task as a one-class deviation problem, which computed the deviation between test samples and normal patterns. In this paper, an Adaptive Intra-frame Classification Network (AICN) is proposed to transform this task to a multi-class classification problem. The contributions of our method are: 1) AICN is a more effective anomaly evaluation network. It evaluates abnormality based on intra-frame classification results, which reserves more connection information of sub-regions and makes the model outperform previous one-class classifiers. 2) AICN reduces the computational cost. Motion Convolutional Layers (MCLs) and Shape Convolutional Layers (SCLs) are proposed to extract feature maps, which utilize the simplicity of convolution to reduce computational cost. Adaptive Region Pooling Layer (ARPL) is also proposed to reduce the calculation cost of overlapped sub-regions. 3) AICN enhances the adaptiveness of model. Only one multi-class classifier is used rather than multiple one-class classifiers. It makes the network easier to be applied on other scenes and makes the model adaptive to samples with different resolutions. The proposed method is examined on four public datasets with different background complexities and resolutions: UCSD Ped1 dataset, UCSD Ped2 dataset, Avenue dataset and Subway dataset. The results are further compared with previous approaches to confirm the effectiveness and the advantage of our method.","","","10.1109/TMM.2019.2929931","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8767943","anomaly detection;AICN;deep learning;motion convolutional layers;adaptive region pooling","Anomaly detection;Feature extraction;Deep learning;Task analysis;Adaptive systems;Adaptation models;Training","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Hierarchical Long Short-Term Concurrent Memory for Human Interaction Recognition","X. Shu; J. Tang; G. Qi; W. Liu; J. Yang","School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, Jiangsu China (e-mail: shuxb@njust.edu.cn); School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, Jiangsu China 210094 (e-mail: tangjh1981@acm.org); Computer Science, University of Central Florida, Orlando, Florida United States (e-mail: guojun.qi@ucf.edu); Computer Vision Group, Tencent AI Lab, Shenzhen, Guangdong China (e-mail: wliu@ee.columbia.edu); School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, Jiangsu China (e-mail: csjyang@njust.edu.cn)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","In this work, we aim to address the problem of human interaction recognition in videos by exploring the long-term inter-related dynamics among multiple persons. Recently, Long Short-Term Memory (LSTM) has become a popular choice to model individual dynamic for single-person action recognition due to its ability to capture the temporal motion information in a range. However, most existing LSTM-based methods focus only on capturing the dynamics of human interaction by simply combining all dynamics of individuals or modeling them as a whole. Such methods neglect the inter-related dynamics of how human interactions change over time. To this end, we propose a novel Hierarchical Long Short-Term Concurrent Memory (H-LSTCM) to model the long-term inter-related dynamics among a group of persons for recognizing human interactions. Specifically, we first feed each person's static features into a Single-Person LSTM to model the single-person dynamic. Subsequently, at one time step, the outputs of all Single-Person LSTM units are fed into a novel Concurrent LSTM (Co-LSTM) unit, which mainly consists of multiple sub-memory units, a new cell gate, and a new co-memory cell. In the Co-LSTM unit, each sub-memory unit stores individual motion information, while this Co-LSTM unit selectively integrates and stores inter-related motion information between multiple interacting persons from multiple sub-memory units via the cell gate and co-memory cell, respectively. Extensive experiments on several public datasets validate the effectiveness of the proposed H-LSTCM by comparing against baseline and state-of-the-art methods.","","","10.1109/TPAMI.2019.2942030","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8840975","Human interaction recognition;long short-term memory;activity recognition;deep learning","Dynamics;Videos;Logic gates;Deep learning;Task analysis;Pattern recognition;Feeds","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Improving attention model based on cognition grounded data for sentiment analysis","Y. Long; R. Xiang; Q. Lu; C. Huang; M. Li","Horizon digital economy research institute, University of Nottingham, 6123 Nottingham, Nottinghamshire United Kingdom of Great Britain and Northern Ireland (e-mail: Yunfei.Long@nottingham.ac.uk); Department of Computing, Hong Kong Polytechnic University, 26680 Kowloon, Hong Kong Hong Kong (e-mail: csrxiang@comp.polyu.edu.hk); Department of Computing, Hong Kong Polytechnic University, 26680 Kowloon, Hong Kong Hong Kong (e-mail: csluqin@comp.polyu.edu.hk); Department of Chinese and Bilingual Studies, Hong Kong Polytechnic University, 26680 Kowloon, Hong Kong Hong Kong (e-mail: churen.huang@polyu.edu.hk); Department of Computing, Hong Kong Polytechnic University, 26680 Kowloon, Hong Kong Hong Kong (e-mail: minglei.li@connect.polyu.hk)","IEEE Transactions on Affective Computing","","2019","PP","99","1","1","Attention models are proposed in sentiment analysis and other classification tasks because some words are more important than others to train the attention models. However, most existing methods either use local context based information, affective lexicons, or user preference information. In this work, we propose a novel attention model trained by cognition grounded eye-tracking data. First,a reading prediction model is built using eye-tracking data as dependent data and other features in the context as independent data. The predicted reading time is then used to build a cognition grounded attention layer for neural sentiment analysis. Our model can capture attentions in context both in terms of words at sentence level as well as sentences at document level. Other attention mechanisms can also be incorporated together to capture other aspects of attentions, such as local attention, and affective lexicons. Results of our work include two parts. The first part compares our proposed cognition ground attention model with other state-of-the-art sentiment analysis models. The second part compares our model with an attention model based on other lexicon based sentiment resources. Evaluations show that sentiment analysis using cognition grounded attention model outperforms the state-of-the-art sentiment analysis methods significantly. Comparisons to affective lexicons also indicate that using cognition grounded eye-tracking data has advantages over other sentiment resources by considering both word information and context information. This work brings insight to how cognition grounded data can be integrated into natural language processing (NLP) tasks.","","","10.1109/TAFFC.2019.2903056","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8658126","Affective lexicons;Sentiment analysis;Cognition grounded data;Deep learning;Attention model","Sentiment analysis;Analytical models;Cognition;Data models;Task analysis;Context modeling;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Brain Deformable Registration Using Global and Local Label-Driven Deep Regression Learning in the First Year of Life","S. Hu; L. Zhang; G. Li; M. Liu; D. Fu; W. Zhang","School of Information Science and Engineering, Linyi University, Linyi Shandong, 27600, China and Linda Institute, Shandong Provincial Key Laboratory of Network Based Intelligent Compu-ting, Linyi University, Linyi Shandong, 276000, China.; School of Information Science and Engineering, Linyi University, Linyi Shandong, 27600, China and Linda Institute, Shandong Provincial Key Laboratory of Network Based Intelligent Compu-ting, Linyi University, Linyi Shandong, 276000, China.; School of Information Science and Engineering, Linyi University, Linyi Shandong, 27600, China and Linda Institute, Shandong Provincial Key Laboratory of Network Based Intelligent Compu-ting, Linyi University, Linyi Shandong, 276000, China.; School of Information Science and Engineering, Linyi University, Linyi Shandong, 27600, China and Linda Institute, Shandong Provincial Key Laboratory of Network Based Intelligent Compu-ting, Linyi University, Linyi Shandong, 276000, China.; School of Information Science and Engineering, Linyi University, Linyi Shandong, 27600, China and Linda Institute, Shandong Provincial Key Laboratory of Network Based Intelligent Compu-ting, Linyi University, Linyi Shandong, 276000, China.; School of Information Science and Engineering, Linyi University, Linyi Shandong, 27600, China and Linda Institute, Shandong Provincial Key Laboratory of Network Based Intelligent Compu-ting, Linyi University, Linyi Shandong, 276000, China.","IEEE Access","","2019","PP","99","1","1","Accurate medical image registration is highly important for the quantitative analysis of infant brain dynamic development in the first year of life. However, the deformable registration of infant brain magnetic resonance (MR) images is highly challenging for the following two reasons: First, there are very large anatomical and appearance variations in these longitudinal images; Second, there is a one-to-many correspondence in appearance between global anatomical tissues and the small local tissues therein. In this paper, we use a CNN (convolution neural network)-based global-and-local-label-driven deformable registration scheme. Two to-be-registered image patches are input into the UNet-style regression network. Then, a dense displacement field (DDF) between them is obtained by optimizing the total loss function between two corresponding label patches. Global and local label patches are used only during training. During inference, two new MR images are divided into many patch pairs and fed into the trained network. By averaging the deformation of the patches at the same location, the final 3D DDF between the two whole images is obtained. The highlight is that the global (white matter (WM), gray matter (GM), and cerebrospinal fluid (CSF)) and local tissues can be registered simultaneously without any prior ground-truth deformation. Especially for the local hippocampal tissues, the Dice ratios are substantially improved after registration via our method. Experimental results are presented on the intrasubject and intersubject registration of infant brain MR images between different time points, and the intersubject registration of brain T1-weighted MR images on the OASIS-1 dataset, according to which the proposed method realizes higher accuracy on both global and local tissues compared with state-of-the-art registration methods.","","","10.1109/ACCESS.2019.2957233","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8920023","Infant brain MR images;deformable registration;label-driven learning","Strain;Image registration;Three-dimensional displays;Training;Hippocampus;Image segmentation;Task analysis","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Convolutional Recurrent Neural Networks for Glucose Prediction","K. Li; J. Daniels; C. Liu; P. Herrero-Vinas; P. Georgiou","Electrical and Electronic Engineering, Imperial College London, London United Kingdom of Great Britain and Northern Ireland (e-mail: kezhi.li@imperial.ac.uk); Electrical and Electronic Engineering, Imperial College London, London United Kingdom of Great Britain and Northern Ireland (e-mail: john.daniels11@imperial.ac.uk); Electrical and Electronic Engineering, Imperial College London, London United Kingdom of Great Britain and Northern Ireland SW7 2AZ (e-mail: chengyuan.liu12@imperial.ac.uk); Imperial College London, London United Kingdom of Great Britain and Northern Ireland SW7 2AZ (e-mail: p.herrero-vinias@imperial.ac.uk); Electrical and Electronic Engineering, Imperial College London, London, London United Kingdom of Great Britain and Northern Ireland SW7 2BT (e-mail: pantelis@imperial.ac.uk)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","Control of blood glucose is essential for diabetes management. Current digital therapeutic approaches for subjects with Type 1 diabetes mellitus (T1DM) such as the artificial pancreas and insulin bolus calculators leverage machine learning techniques for predicting subcutaneous glucose for improved control. Deep learning has recently been applied in healthcare and medical research to achieve state-of-the-art results in a range of tasks including disease diagnosis, and patient state prediction among others. In this work, we present a deep learning model that is capable of forecasting glucose levels with leading accuracy for simulated patient cases (RMSE = 9.38±0.71 [mg/dL] over a 30-minute horizon, RMSE = 18.87±2.25 [mg/dL] over a 60-minute horizon) and real patient cases (RMSE = 21.07±2.35 [mg/dL] for 30-minute, RMSE = 33.27±4.79\% for 60-minute). In addition, the model provides competitive performance in providing effective prediction horizon ($PH_{eff}$) with minimal time lag both in a simulated patient dataset ($PH_{eff}$ = 29.0±0.7 for 30-min and $PH_{eff}$ = 49.8±2.9 for 60-min) and in a real patient dataset ($PH_{eff}$ = 19.3±3.1 for 30-min and $PH_{eff}$ = 29.3±9.4 for 60-min). This approach is evaluated on a dataset of 10 simulated cases generated from the UVa/Padova simulator and a clinical dataset of 10 real cases each containing glucose readings, insulin bolus, and meal (carbohydrate) data. Performance of the recurrent convolutional neural network is benchmarked against four algorithms. The proposed algorithm is implemented on an Android mobile phone, with an execution time of 6ms on a phone compared to an execution time of 780ms on a laptop.","","","10.1109/JBHI.2019.2908488","Engineering and Physical Sciences Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8678399","Type 1 diabetes;continuous glucose monitor (CGM);glucose prediction;deep learning;long short term memory (LSTM)","Sugar;Insulin;Time series analysis;Convolution;Diabetes;Recurrent neural networks;Data models","","","","2","","","","","","IEEE","IEEE Early Access Articles"
"An Active Learning Paradigm for Online Audio-Visual Emotion Recognition","I. Kansizoglou; L. Bampis; A. Gasteratos","Production and Management Engineering, Democritus University of Thrace School of Engineering, 112221 Xanthi, Thrace Greece (e-mail: ikansizo@pme.duth.gr); Production and Management Engineering, Democritus University of Thrace School of Engineering, 112221 Xanthi, Thrace Greece (e-mail: lbampis@pme.duth.gr); Production and Management Engineering, Democritus University of Thrace School of Engineering, 112221 Xanthi, Thrace Greece (e-mail: agaster@pme.duth.gr)","IEEE Transactions on Affective Computing","","2019","PP","99","1","1","The advancement of Human-Robot Interaction (HRI) drives research into the development of advanced emotion identification architectures that fathom audio-visual (A-V) modalities of human emotion. State-of-the-art methods in multi-modal emotion recognition mainly focus on the classification of complete video sequences, leading to systems with no online potentialities. Such techniques are capable of predicting emotions only when the videos are concluded, thus restricting their applicability in practical scenarios. The paper at hand provides a novel paradigm for online emotion classification, which exploits both audio and visual modalities and produces a responsive prediction when the system is confident enough. We propose two deep Convolutional Neural Network (CNN) models for extracting emotion features, one for each modality, and a Deep Neural Network (DNN) for their fusion. In order to conceive the temporal quality of human emotion in interactive scenarios, we train in cascade a Long Short-Term Memory (LSTM) layer and a Reinforcement Learning (RL) agent -which monitors the speaker- thus stopping feature extraction and making the final prediction. The comparison of our results on two publicly available A-V emotional datasets viz., RML and BAUM-1s, against other state-of-the-art models, demonstrates the beneficial capabilities of our work.","","","10.1109/TAFFC.2019.2961089","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8937495","Multi-modal emotion recognition;Sensor fusion;Deep reinforcement learning;Emotion in human-computer interaction","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Acoustic Deep-Sea Seafloor Characterization Accounting for Heterogeneity Effect","K. Zhang; Q. Li; H. Zhu; F. Yang; Z. Wu","Key Laboratory of Submarine Geosciences, Second Institute of Oceanography, Ministry of Natural Resources, Hangzhou 310012, China, and also with the College of Geomatics, Shandong University of Science and Technology, Qingdao 266590, China.; College of Geomatics, Shandong University of Science and Technology, Qingdao 266590, China.; College of Geomatics, Shandong University of Science and Technology, Qingdao 266590, China.; College of Geomatics, Shandong University of Science and Technology, Qingdao 266590, China, and also with the Key Laboratory of Surveying and Mapping Technology on Island and Reef, Ministry of Natural Resources, Qingdao 266590, China (e-mail: flyang@126.com).; Key Laboratory of Submarine Geosciences, Second Institute of Oceanography, Ministry of Natural Resources, Hangzhou 310012, China (e-mail: zywu@vip.163.com).","IEEE Transactions on Geoscience and Remote Sensing","","2019","PP","99","1","9","An algorithm is described and tested to provide accurate and robust deep-sea seafloor classification based on the backscatter data derived from a multibeam bathymetry system. This article focuses on significant heterogeneity in the deep-sea backscatter strength (BS) data. The angular response curve information is decomposed into different units, and BS data are grouped on the basis of the incidence angle to address the heterogeneity in the across-ship direction. Subsequently, a sliding window is applied on BS data in each group, and a robust estimation method is used to address the potential heterogeneity in the window during feature extraction. Thereafter, the extracted features are learned by fuzzy c-means (FCM) to obtain a clustering solution. In the learning process, the features of each group are learned by an independent FCM. The modified FCM algorithm is used to cluster each group of data to handle unbalanced backscatter data sets. With this procedure, heterogeneity in BS data can be accounted for, which is universal in deep-sea survey application. Finally, the results of the different groups are merged to obtain a global label set for the survey region. The method was tested on the multibeam data collected from an offshore region around the Kyushu-Palau Ridge. Monte Carlo simulation was performed to evaluate the performance of the robust method. Computational results demonstrate that the improved algorithm can address the heterogeneity in BS data efficiently and provide an accurate classification solution in the deep-sea survey environment.","","","10.1109/TGRS.2019.2946986","National Natural Science Foundation of China; National Key R and D Program of China; Scientific Research Fund of the Second Institute of Oceanography Ministry of Natural Resources MNR; China Postdoctoral Science Foundation funded project; Shandong Provincial Key R and D Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8887535","Acoustic backscatter strength (BS);deep sea;heterogeneity;multibeam;seafloor;underwater acoustic measurement.","Feature extraction;Backscatter;Acoustics;Sea measurements;Sediments;Substrates;Acoustic measurements","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep clustering: On the link between discriminative models and K-means","M. Jabi; M. Pedersoli; A. Mitiche; I. Ben Ayed","System Engineering, ETS Montreal, Montreal, Quebec Canada (e-mail: jabi.mohamed@gmail.com); System Engineering, ETS Montreal, Montreal, Quebec Canada (e-mail: Marco.Pedersoli@etsmtl.ca); EMT, Institut National de la Recherche Scientifique, Montreal, Quebec Canada H5A 1K6 (e-mail: mitiche@emt.inrs.ca); System Engineering, EST Montreal, Montreal, Quebec Canada (e-mail: ismail.benayed@gmail.com)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","In the context of recent deep clustering studies, discriminative models dominate the literature and report the most competitive performances. These models learn a deep discriminative neural network classifier in which the labels are latent. Typically, they use multinomial logistic regression posteriors and parameter regularization, as is very common in supervised learning. It is generally acknowledged that discriminative objective functions (e.g., those based on the mutual information or the KL divergence) are more flexible than generative approaches (e.g., K-means) in the sense that they make fewer assumptions about the data distributions and, typically, yield much better unsupervised deep learning results. On the surface, several recent discriminative models may seem unrelated to K-means. This study shows that these models are, in fact, equivalent to K-means under mild conditions and common posterior models and parameter regularization. We prove that, for the commonly used logistic regression posteriors, maximizing the L2-regularized mutual information via an approximate alternating direction method (ADM) is equivalent to a soft and regularized K-means loss. Our theoretical analysis not only connects directly several recent state-of-the-art discriminative models to K-means, but also leads to a new soft and regularized deep K-means algorithm, which yields competitive performance on several image clustering benchmarks.","","","10.1109/TPAMI.2019.2962683","Natural Sciences and Engineering Research Council of Canada; Fonds de Recherche du Quebec - Nature et Technologies; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8944041","Deep Clustering;Convolutional Neural Networks;Alternating Direction Methods;K-means;Mutual Information;Kullback-Leibler (KL) divergence;Regularization;Multilogit Regression","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Leveraging the Deep Learning Paradigm for Continuous Affect Estimation from Facial Expressions","M. C. Oveneke; Y. Zhao; E. Pei; A. D. Berenguer; D. Jiang; H. Sahli","ETRO-AVSP, Vrije Universiteit Brussel, Brussels, Brussels Belgium 1050 (e-mail: mcovenek@etrovub.be); Department of Computer Information and Engineering, Northwestern Polytechnical University, 26487 Xi'an, Shaanxi China (e-mail: yzhao@etrovub.be); Electronics and Informatics, Vrije Universiteit Brussel, 70493 Brussel, Brussel Belgium (e-mail: epei@etrovub.be); Electronics and Informatics, Vrije Universiteit Brussel, 70493 Brussel, Brussel Belgium (e-mail: aberengu@etrovub.be); VUB-NPU joint AVSP Research Lab, Northwestern Polytechnical University, 26487 Xi'an, Shaanxi China (e-mail: jiangdm@nwpu.edu.cn); Electronics \& Informatics (ETRO), Vrije Universiteit Brussel (VUB), Brussels, Brussels Belgium (e-mail: hsahli@etrovub.be)","IEEE Transactions on Affective Computing","","2019","PP","99","1","1","Continuous affect estimation from facial expressions has attracted increased attention in the affective computing research community. This paper presents a principled framework for estimating continuous affect from video sequences. Based on recent developments, we address the problem of continuous affect estimation by leveraging the Bayesian filtering paradigm, i.e. considering affect as a latent dynamical system corresponding to a general feeling of pleasure with a degree of arousal, and recursively estimating its state using a sequence of visual observations. To this end, we advance the state-of-the-art as follows: (i) Canonical face representation (CFR): a novel algorithm for two-dimensional face frontalization, (ii) Convex unsupervised representation learning (CURL): a novel frequency-domain convex optimization algorithm for unsupervised training of deep convolutional neural networks (CNN)s, and (iii) Deep extended Kalman filtering (DEKF): an extended Kalman filtering-based algorithm for affect estimation from a sequence of deep CNN observations. The performance of the resulting CFR-CURL-DEKF algorithmic framework is empirically evaluated on publicly available benchmark datasets for facial expression recognition (CK+) and continuous affect estimation (AVEC 2012 and 2014).","","","10.1109/TAFFC.2019.2944603","Agentschap voor Innovatie door Wetenschap en Technologie; China Scholarship Council; National Natural Science Foundation of China; Vrije Universiteit Brussel; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8852690","Affect Estimation;Facial Expressions;Face Frontalization;Partial Least-Squares Regression;Convolutional Auto-Encoders;Neural Networks;Extended Kalman Filtering","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Objects Discovery Based on Co-Occurrence Word Model with Anchor-Box Polishing","Z. Zhang; T. Jing; C. Tian; P. Cui; X. Li; M. Gao","School of Electronics and Information Engineering, Beijing Jiaotong University, Beijing, China.; School of Electronics and Information Engineering, Beijing Jiaotong University, Beijing, China.; K2data Ltd. Research Department of artificial intelligence, Beijing, China.; K2data Ltd. Research Department of artificial intelligence, Beijing, China.; School of Electronics and Information Engineering, Beijing Jiaotong University, Beijing, China.; School of Electronics and Information Engineering, Beijing Jiaotong University, Beijing, China.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","State-of-art objects discovery approaches can be categorized into two categories: The deep learning methods based on convolutional neural network with region proposals, and the conventional machine learning methods based on topic models, low-rank matrix factorization, or image processing. Deep learning methods for objects discovery are based on sacrificing computational complexity to achieve precision, and the training time can be long without GPU platforms, whereas the conventional methods are usually lack of detection accuracy. To effectively address the problems of the training complexity and the detection speed, we present a new objects discovery approach by proposing a two-stage (training and verification) method. In the training stage, a topic model with words co-occurrence prior is proposed on the basis of Latent Dirichlet Allocation (LDA) model, in which the co-occurrence information among the features is sufficiently ultilized. In the verification stage, we propose an Anchor-box polishing algorithm that fine-tunes the detection results corresponding to the pre-trained topic model from some conventional algorithms with fast detection time. Experiments on various datasets demonstrate that the proposed approach can improve the detection performance in terms of efficiency and computing costs. It is also robust to objects different in colors, lightings, scales, etc. Interestingly, the proposed method can be combined with many fast but inaccurate detection algorithms, in which it enhances the model’s flexibility.","","","10.1109/TCSVT.2019.2894363","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8624610","LDA;word co-occurrence prior;object discovery;machine learning;pattern recognition;region of interest","Training;Visualization;Deep learning;Computational modeling;Feature extraction;Principal component analysis","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Learning from Large-scale Noisy Web Data with Ubiquitous Reweighting for Image Classification","J. Li; Y. Song; J. Zhu; L. Cheng; Y. Su; L. Ye; P. Yuan; S. Han","School of Computer Science and Engineering, Beihang University, Beijing, Beijing China 100191 (e-mail: jiali@buaa.edu.cn); National Engineering Laboratory for Video Technology, School of Electronics Engineering and Computer Science, Peking University, Beijing, Beijing China (e-mail: songyf@pku.edu.cn); Computer Vision Technology Department, Baidu Inc, 438127 Beijing, Beijing China (e-mail: zhujianfeng03@baidu.com); Computer Vision Technology Department, Baidu Inc, 438127 Beijing, Beijing China (e-mail: chenglele@baidu.com); Computer Vision Technology Department, Baidu Inc, 438127 Beijing, Beijing China (e-mail: suying02@baidu.com); Computer Vision Technology Department, Baidu Inc, 438127 Beijing, Beijing China (e-mail: yelin02@baidu.com); School of Computer Science and Engineering, Beihang University, Beijing, Beijing China (e-mail: yuanpengcheng@buaa.edu.cn); Computer Vision Technology Department, Baidu Inc, 438127 Beijing, Beijing China (e-mail: hanshumin@baidu.com)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Many important advances of deep learning techniques have originated from the efforts of addressing the image classification task on large-scale datasets. However, the construction of clean datasets is costly and time-consuming since the Internet is overwhelmed by noisy images with inadequate and inaccurate tags. In this paper, we propose a Ubiquitous Reweighting Network (URNet) that can learn an image classification model from noisy web data. By observing the web data, we find that there are five key challenges, i.e., imbalanced class sizes, high intra-classes diversity and inter-class similarity, imprecise instances, insufficient representative instances, and ambiguous class labels. With these challenges in mind, we assume every training instance has the potential to contribute positively by alleviating the data bias and noise via reweighting the influence of each instance according to different class sizes, large instance clusters, its confidence, small instance bags, and the labels. In this manner, the influence of bias and noise in the data can be gradually alleviated, leading to the steadily improving performance of URNet. Experimental results in the WebVision 2018 challenge with 16 million noisy training images from 5000 classes show that our approach outperforms state-of-the-art models and ranks first place in the image classification task.","","","10.1109/TPAMI.2019.2961910","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8941250","Image classification;noisy web data;CNNs;ubiquitous reweighting;deep learning","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Gradient-Guided Residual Learning for Inverse Halftoning and Image Expanding","J. Yuan; C. Pan; Y. Zheng; X. Zhu; Z. Qin; Y. Xiao","College of Computer Science and Electronic Engineering, Hunan University, Changsha, PRC.; College of Computer Science and Electronic Engineering, Hunan University, Changsha, PRC.; College of Electrical and Information Engineering, Hunan University, Changsha, PRC.; College of Computer Science and Electronic Engineering, Hunan University, Changsha, PRC.; College of Computer Science and Electronic Engineering, Hunan University, Changsha, PRC.; School of Design, Hunan University, Changsha, PRC.","IEEE Access","","2019","PP","99","1","1","Inverse halftoning and image expanding refer to problems to restore the pixel values of images from compressed images of smaller bit depth. Since these two problems are ill-posed, there are few perfect solutions. Recently, deep convolutional neural networks (DCNN) have shown their powerful ability in inverse halftoning and image expanding. However, the restored images still suffer from visual artifacts or fine details loss due to the improper design of network structure. To this end, this paper proposes a residual learning model for inverse halftoning and image expanding. The whole model consists of two progressive stages. The first stage is a gradient-guided DCNN, which coarsely recovers the main content of the image with the guidance of the predicted gradients. The second stage is a residual network, which learns the residual maps to fine-tune the coarse images, leading better local detail representation. Extensive experiments, including visual quality and numerical evaluation, are performed on the COCO data set. Results show that our method achieves the best performance when compared to the state-of-art methods.","","","10.1109/ACCESS.2019.2955025","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8908755","Deep convolutional neural network;inverse halftoning;image expanding;residual learning","Image restoration;Image coding;Convolution;Table lookup;Convolutional neural nets;Visualization","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Face Hallucination from New Perspective of Non-linear Learning Compressed Sensing","S. Yang; X. Hao; Z. Liu; C. Yang; M. Wang","School of Artificial Intelligence, Xidian University, China.; School of Artificial Intelligence, Xidian University, China.; School of Artificial Intelligence, Xidian University, China.; School of Artificial Intelligence, Xidian University, China.; Key Laboratory of Radar Signal Processing, Xidian University, China.","IEEE Access","","2019","PP","99","1","1","The past decade has witnessed a prosperity of sparsity-inspired face hallucination methods that use sparse prior and instances to generate High-Resolution (HR) faces. However, they need numerous Low-Resolution (LR) and HR instance pairs and adopt approximate sparse coding, which will bring bias to the recovery and suffer from high computational burden. In this paper we advance a Single Face Image Hallucination (SFIH) method from a new perspective of Non-linear Learning Compressive Sensing (NLCS), which can recover HR faces from a surprisingly small number of HR faces. The nonlinear sparse coding of facial images is explored, and a Deep AutoEncoder (DAE) network is constructed for learning a kernel function from a single HR instance set. SFIH is then reduced to an analytic compressive recovery problem by reformulating linear sparse coding as a nonlinear DAE model. By exploring the nonlinear sparsity in the feature space, NLCS can accurately and rapidly recover HR facial images with large magnification factor and exhibit robustness to LR-HR instance pairs mapping. Some experiments are taken on realizing 3X, 6X, 9X amplification of face images, and the results prove its efficiency and superiority to its counterparts.","","","10.1109/ACCESS.2019.2963360","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8946533","Face hallucination;nonlinear sparse coding;non-linear learning compressed sensing;deep autoencoder","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Spatio-Temporal Convolutional LSTMs for Tumor Growth Prediction by Learning 4D Longitudinal Patient Data","L. Zhang; L. Lu; X. Wang; R. M. Zhu; M. Bagheri; R. M. Summers; J. Yao","PAII Inc., Bethesda, MD 20817, USA.; PAII Inc., Bethesda, MD 20817, and Johns Hopkins University, Baltimore, MD 21218, USA.; Nvidia Corporation, Bethesda, MD 20814, USA.; Imaging Biomarkers and Computer-Aided Diagnosis Laboratory and Clinical Image Processing Service, Radiology and Imaging Sciences Department, National Institutes of Health Clinical Center, Bethesda, MD 20892, USA.; Imaging Biomarkers and Computer-Aided Diagnosis Laboratory and Clinical Image Processing Service, Radiology and Imaging Sciences Department, National Institutes of Health Clinical Center, Bethesda, MD 20892, USA.; Imaging Biomarkers and Computer-Aided Diagnosis Laboratory and Clinical Image Processing Service, Radiology and Imaging Sciences Department, National Institutes of Health Clinical Center, Bethesda, MD 20892, USA.; Tencent Holdings Limited, Shenzhen 518057, China.","IEEE Transactions on Medical Imaging","","2019","PP","99","1","1","Prognostic tumor growth modeling via volumetric medical imaging observations can potentially lead to better outcomes of tumor treatment management and surgical planning. Recent advances of convolutional networks (ConvNets) have demonstrated higher accuracy than traditional mathematical models can be achieved in predicting future tumor volumes. This indicates that deep learning based data-driven techniques may have great potentials on addressing such problem. However, current 2D image patch based modeling approaches can not make full use of the spatio-temporal imaging context of the tumor’s longitudinal 4D (3D + time) patient data. Moreover, they are incapable to predict clinically-relevant tumor properties, other than the tumor volumes. In this paper, we exploit to formulate the tumor growth process through convolutional Long Short-Term Memory (ConvLSTM) that extract tumor’s static imaging appearances and simultaneously capture its temporal dynamic changes within a single network. We extend ConvLSTM into the spatio-temporal domain (ST-ConvLSTM) by jointly learning the inter-slice 3D contexts and the longitudinal or temporal dynamics from multiple patient studies. Our approach can incorporate other nonimaging patient information in an end-to-end trainable manner. Experiments are conducted on the largest 4D longitudinal tumor dataset of 33 patients to date. Results validate that the proposed ST-ConvLSTM model produces a Dice score of 83.2%±5.1% and a RVD of 11.2%±10.8%, both statistically significantly outperforming (p <0.05) other compared methods of traditional linear model, ConvLSTM, and generative adversarial network (GAN) under the metric of predicting future tumor volumes. Additionally, our new method enables the prediction of both cell density and CT intensity numbers. Last, we demonstrate the generalizability of ST-ConvLSTM by employing it in 4D medical image segmentation task, which achieves an averaged Dice score of 86.3%±1.2% for left-ventricle segmentation in 4D ultrasound with 3 seconds per patient case.","","","10.1109/TMI.2019.2943841","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8848835","Tumor growth prediction;Deep learning;Convolutional LSTM;Spatio-temporal Longitudinal Study;4D Medical Imaging","Tumors;Three-dimensional displays;Image segmentation;Predictive models;Mathematical model;Computed tomography","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Inferring Latent Domains for Unsupervised Deep Domain Adaptation","M. Mancini; L. Porzi; S. R. Bulo; B. Caputo; E. Ricci","Technologies of Vision Lab, Fondazione Bruno Kessler, 18466 Trento, Trentino-Alto Adige Italy (e-mail: mancini@diag.uniroma1.it); Mapillary Research, Mapillary Research, Graz, Graz Austria (e-mail: lorenzo@mapillary.com); Mapillary Research, Mapillary Research, Graz, Graz Austria (e-mail: samuel@mapillary.com); Visual and Multimodal Applied Learning, Istituto Italiano di Tecnologia, 121451 Milano, Lombardia Italy (e-mail: barbara.caputo@iit.it); Technologies of Vision, Fondazione Bruno Kessler, 18466 Trento, Trentino-Alto Adige Italy (e-mail: eliricci@fbk.eu)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Unsupervised Domain Adaptation (UDA) refers to the problem of learning a model in a target domain where labeled data are not available by leveraging information from annotated data in a source domain. Most deep UDA approaches operate in a single-source, single-target scenario, i.e. they assume that the source and the target samples arise from a single distribution. However, in practice most datasets can be regarded as mixtures of multiple domains. In these cases, exploiting traditional single-source, single-target methods for learning classification models may lead to poor results. Furthermore, it is often difficult to provide the domain labels for all data points, i.e. latent domains should be automatically discovered. This paper introduces a novel deep architecture which addresses the problem of UDA by automatically discovering latent domains in visual datasets and exploiting this information to learn robust target classifiers. Specifically, our architecture is based on two main components, i.e. a side branch that automatically computes the assignment of each sample to its latent domain and novel layers that exploit domain membership information to appropriately align the distribution of the CNN internal feature representations to a reference distribution. We evaluate our approach on publicly available benchmarks, showing that it outperforms state-of-the-art domain adaptation methods.","","","10.1109/TPAMI.2019.2933829","osterreichische Forschungsforderungsgesellschaft; H2020 European Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8792192","Unsupervised Domain Adaptation;Batch Normalization;Domain Discovery;Object Recognition","Adaptation models;Data models;Computer architecture;Neural networks;Training;Visualization;Training data","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Exploiting Embedding Manifold of Autoencoders for Hyperspectral Anomaly Detection","X. Lu; W. Zhang; J. Huang","Key Laboratory of Spectral Imaging Technology CAS, Xi'an Institute of Optics and Precision Mechanics, Chinese Academy of Sciences, Xi'an 710119, China (e-mail: luxq666666@gmail.com).; Key Laboratory of Spectral Imaging Technology CAS, Xi'an Institute of Optics and Precision Mechanics, Chinese Academy of Sciences, Xi'an 710119, China, and also with the Xi'an Institute of Optics and Precision Mechanics, University of Chinese Academy of Sciences, Beijing 100049, China.; Key Laboratory of Spectral Imaging Technology CAS, Xi'an Institute of Optics and Precision Mechanics, Chinese Academy of Sciences, Xi'an 710119, China, and also with the Xi'an Institute of Optics and Precision Mechanics, University of Chinese Academy of Sciences, Beijing 100049, China.","IEEE Transactions on Geoscience and Remote Sensing","","2019","PP","99","1","11","Hyperspectral anomaly detection is an important task in the remote sensing domain. Recently, researchers have shown great interest in deep learning-based methods because they can learn hierarchical, abstract, and high-level representations. However, the latent features learned from the autoencoder (AE) are not always able to reflect the intrinsic structure of hyperspectral data because the locality property is not considered during the learning process. In order to address this problem, a novel manifold constrained AE network (MC-AEN)-based hyperspectral anomaly detection method is proposed in this article. First, the manifold learning method is employed to learn the embedding manifold. Then, the latent representations are learned by an AE network with the learned embedding manifold constraints to preserve the intrinsic structure of hyperspectral data. Finally, the reconstruction errors are calculated to detect anomalies. The global reconstruction error from MC-AEN and the local reconstruction error from the learned latent representations are combined to fully utilize the learned knowledge for better detection performance. We test our proposed algorithm on three different real data sets. Experimental results on these three data sets show the superiority of our proposed method.","","","10.1109/TGRS.2019.2944419","National Natural Science Foundation of China; Young Top Notch Talent Program of Chinese Academy of Sciences; National Key R and D Program of China; CAS Light of West China Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8889706","Autoencoder (AE);global reconstruction;hyperspectral imagery (HSI);hyperspetral anomaly detection;local reconstruction;manifold learning.","Hyperspectral imaging;Anomaly detection;Manifolds;Learning systems;Image reconstruction;Task analysis","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Deep Latent Factor Model for High-Dimensional and Sparse Matrices in Recommender Systems","D. Wu; X. Luo; M. Shang; Y. He; G. Wang; M. Zhou","Chongqing Engineering Research Center of Big Data Application for Smart Cities, Chongqing Institute of Green and Intelligent Technology, Chinese Academy of Sciences, Chongqing 400714, China, also with the Chongqing Key Laboratory of Big Data and Intelligent Computing, Chongqing Institute of Green and Intelligent Technology, Chinese Academy of Sciences, Chongqing 400714, China, and also with the School of Computer Science and Technology, University of Chinese Academy of Sciences, Beijing 100049, China.; Chongqing Engineering Research Center of Big Data Application for Smart Cities, Chongqing Institute of Green and Intelligent Technology, Chinese Academy of Sciences, Chongqing 400714, China, also with the Chongqing Key Laboratory of Big Data and Intelligent Computing, Chongqing Institute of Green and Intelligent Technology, Chinese Academy of Sciences, Chongqing 400714, China, and also with the Department of Computing, Hong Kong Polytechnic University, Hong Kong 999077 (e-mail: luoxin21@cigit.ac.cn).; Chongqing Engineering Research Center of Big Data Application for Smart Cities, Chongqing Institute of Green and Intelligent Technology, Chinese Academy of Sciences, Chongqing 400714, China, and also with the Chongqing Key Laboratory of Big Data and Intelligent Computing, Chongqing Institute of Green and Intelligent Technology, Chinese Academy of Sciences, Chongqing 400714, China.; School of Computing and Informatics, University of Louisiana at Lafayette, Lafayette, LA 70503 USA.; Chongqing Engineering Research Center of Big Data Application for Smart Cities, Chongqing Institute of Green and Intelligent Technology, Chinese Academy of Sciences, Chongqing 400714, China, and also with the Chongqing Key Laboratory of Big Data and Intelligent Computing, Chongqing Institute of Green and Intelligent Technology, Chinese Academy of Sciences, Chongqing 400714, China.; Department of Electrical and Computer Engineering, New Jersey Institute of Technology, Newark, NJ 07102 USA, and also with the Center of Research Excellence in Renewable Energy and Power Systems, King Abdulaziz University, Jeddah 21589, Saudi Arabia.","IEEE Transactions on Systems, Man, and Cybernetics: Systems","","2019","PP","99","1","12","Recommender systems (RSs) commonly adopt a user-item rating matrix to describe users' preferences on items. With users and items exploding, such a matrix is usually high-dimensional and sparse (HiDS). Recently, the idea of deep learning has been applied to RSs. However, current deep-structured RSs suffer from high computational complexity. Enlightened by the idea of deep forest, this paper proposes a deep latent factor model (DLFM) for building a deep-structured RS on an HiDS matrix efficiently. Its main idea is to construct a deep-structured model by sequentially connecting multiple latent factor (LF) models instead of multilayered neural networks through a nonlinear activation function. Thus, the computational complexity grows linearly with its layer count, which is easy to resolve in practice. The experimental results on four HiDS matrices from industrial RSs demonstrate that when compared with state-of-the-art LF models and deep-structured RSs, DLFM can well balance the prediction accuracy and computational efficiency, which well fits the desire of industrial RSs for fast and right recommendations.","","","10.1109/TSMC.2019.2931393","National Basic Research Program of China (973 Program); National Natural Science Foundation of China; Chongqing Basic Research and Frontier Exploration; Chongqing Overseas Scholars Innovation Program; Chongqing Research Program of Key Standard Technologies Innovation of Key Industries; Chongqing Research Program of Technology Innovation and Application; Pioneer Hundred Talents Program of Chinese Academy of Sciences; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8802269","Big data;deep model;high-dimensional and sparse (HiDS) matrix;latent factor (LF) analysis;recommender system (RS)","Sparse matrices;Computational modeling;Forestry;Green products;Big Data;Stochastic processes;Recommender systems","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Convolutional Neural Network-based Driving Cycle Prediction Method for Plug-in Hybrid Electric Vehicles with Bus Route","Z. Chen; C. Yang; S. Fang","School of Sciences, Ningbo University of Technology, Ningbo, 315211 China.; School of Mechanical Engineering, Beijing Institute of Technology, Beijing, 100081 China.; State Key Laboratory of Automotive Safety and Energy, Tsinghua University, Beijing, 100084 China.","IEEE Access","","2019","PP","99","1","1","Driving cycle prediction plays a key role in energy management strategy (EMS) for hybrid electric vehicles (HEVs). This paper studies a driving cycle prediction method based on convolutional neural network (CNN). Firstly, the k-shape clustering method is used to group the driving cycle data into six different types. Moreover, this method is compared with the k-means algorithm which is often used for clustering driving cycles. Secondly, CNN is adopted to predict the different types of the driving cycles based on the results of k-Shape clustering. Some basic features are selected to construct the input of the networks with no assistance of human experience. In the process of training neural networks, some high-level features which can describe the information of a driving cycle more accurately are extracted, and the deep neural networks are built, which are different from traditional experience-based driving cycle prediction methods. And then, the better performance of the proposed method is illustrated by making a comparison with the traditional machine learning method. Finally, an adaptive energy management strategy for plug-in hybrid electric buses (PHEB) based on deep learning is given, and simulation results prove the effectiveness of the proposed method.","","","10.1109/ACCESS.2019.2960771","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8936885","Plug-in hybrid electric bus;driving cycle prediction;energy management strategy;deep learning","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"ParaML: A Polyvalent Multi-core Accelerator for Machine Learning","S. Zhou; Q. Guo; Z. Du; D. Liu; T. Chen; L. Li; S. Liu; J. Zhou; O. Teman; X. Feng; X. Zhou; Y. Chen","Intelligent Processor Research Center, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China and also with University of Chinese Academy of Sciences, Beijing, China.; Intelligent Processor Research Center, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China and also with Cambricon Technologies Corporation Limited.; Intelligent Processor Research Center, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China and also with Cambricon Technologies Corporation Limited.; Intelligent Processor Research Center, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China and also with Cambricon Technologies Corporation Limited.; Intelligent Processor Research Center, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China, with Cambricon Technologies Corporation Limited and also with CAS Center for Excellence in Brain Science and Intelligence Technology.; Institute of Software, Chinese Academy of Sciences, Beijing, China.; Intelligent Processor Research Center, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China and also with Cambricon Technologies Corporation Limited.; Intelligent Processor Research Center, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China and also with Cambricon Technologies Corporation Limited.; Google (Paris and Mountain View offices).; State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China.; University of Science and Technology of China, Anhui Province, China.; Intelligent Processor Research Center, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China, with University of Chinese Academy of Sciences and also with CAS Center for Excellence in Brain Science and Intelligence Technology. Y. Chen is the corresponding author.","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","","2019","PP","99","1","1","In recent years, Machine Learning (ML) techniques are proven to be powerful tools in various emerging applications. Traditionally, ML techniques are processed on general-purpose CPUs and GPUs, but their energy-efficiencies are limited due to their excessive support for flexibility. As an efficient alternative to CPUs/GPUs, hardware accelerators are still limited as they often accommodate only a single ML technique (family). However, different problems may require different ML techniques, which implies that such accelerators may achieve poor learning accuracy or even be ineffective. In this study, we present a polyvalent accelerator architecture integrated with multiple processing cores, called ParaML, which accommodates ten representative ML techniques, including k-means, k-nearest neighbors (k-NN), naive bayes (NB), support vector machine (SVM), linear regression (LR), classification tree (CT), deep neural network (DNN), learning vector quantization (LVQ), parzen window (PW) and principal component analysis (PCA). Benefited from our thorough analysis on computational primitives and locality properties of different ML techniques, the single-core ParaML can perform up to 1056 GOP/s (e.g., additions and multiplications) in an area of 3.51 mm and consumes 596 mW only, estimated by ICC and PrimeTime PX with post-synthesis netlist respectively. Compared with the NVIDIA K20M GPU (28 nm process), the single-core ParaML (65 nm process) is 1.21× faster, and can reduce the energy by 137.93×. We also compare the single-core ParaML with other accelerators. Compared with PRINS, single-core ParaML achieves 72.09× and 2.57× energy benefit for k-NN and k-means respectively, and speeds up each query in k-NN by 44.76×. Compared with EIE, the single-core ParaML achieves 5.02× speedup and 4.97× energy benefit with 11.62× less area when evaluating with dense DNN. Compared with TPU, the single-core ParaML achieves 2.45× better power efficiency (5647 Gop/W vs. 2300 Gop/W) with 321.36× less area. Compared to the single-core version, the 8-core ParaML will further improve the speedup up to 3.98× with an area of 13.44 mm and a power of 2036 mW.","","","10.1109/TCAD.2019.2927523","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8758353","Machine Learning techniques;Accelerator;Multi-core accelerator.","Neural networks;Machine learning;Testing;Support vector machines;Linear regression;Computers;Computer architecture","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Face Hallucination by Attentive Sequence Optimization with Reinforcement Learning","Y. Shi; G. LI; Q. Cao; K. Wang; L. Lin","School of Data and Computer Science, Sun Yat-sen University, Guangzhou, Guangdong China (e-mail: shiyk3@mail2.sysu.edu.cn); School of Data and Computer Science, Sun Yat-Sen University, 26469 Guangzhou, Guangdong China (e-mail: liguanbin@mail.sysu.edu.cn); School of Data and Computer Science, Sun Yat-sen University, Guangzhou, Guangdong China (e-mail: caoqx@mail2.sysu.edu.cn); School of Data and Computer Science, Sun Yat-Sen University, 26469 Guangzhou, Guangdong China (e-mail: kezewang@gmail.com); School of Information Science and Technology, Sun Yat-sen University, Guangzhou, Guangdong China (e-mail: linliang@ieee.org)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Face hallucination is a domain-specific super-resolution problem that aims to generate a high-resolution (HR) face image from a low-resolution (LR) input. In contrast to the existing patch-wise super-resolution models that divide a face image into regular patches and independently apply LR to HR mapping to each patch, we implement deep reinforcement learning and develop a novel attention-aware face hallucination (Attention-FH) framework, which recurrently learns to attend a sequence of patches and performs facial part enhancement by fully exploiting the global interdependency of the image. Specifically, our proposed framework incorporates two components: a recurrent policy network for dynamically specifying a new attended region at each time step based on the status of the super-resolved image and the past attended region sequence, and a local enhancement network for selected patch hallucination and global state updating. The Attention-FH model jointly learns the recurrent policy network and local enhancement network through maximizing a long-term reward that reflects the hallucination result with respect to the whole HR image. Extensive experiments demonstrate that our Attention-FH significantly outperforms the state-of-the-art methods on in-the-wild face images with large pose and illumination variations.","","","10.1109/TPAMI.2019.2915301","National Basic Research Program of China (973 Program); Fundamental Research Funds for the Central Universities; National Natural Science Foundation of China; NSFC-Shenzhen Robotics Projects; National High Level Talents Special Support Plan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8708944","Face Hallucination;Reinforcement Learning;Recurrent Neural Network","Face;Image resolution;Image reconstruction;Optimization;Reinforcement learning;Visualization;Image restoration","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Operating Electric Vehicle Fleet for Ride-Hailing Services With Reinforcement Learning","J. Shi; Y. Gao; W. Wang; N. Yu; P. A. Ioannou","Department of Electrical and Computer Engineering, University of California at Riverside, Riverside, CA 92501 USA (e-mail: jshi005@ucr.edu).; Department of Electrical and Computer Engineering, University of California at Riverside, Riverside, CA 92501 USA.; Department of Electrical and Computer Engineering, University of California at Riverside, Riverside, CA 92501 USA.; Department of Electrical and Computer Engineering, University of California at Riverside, Riverside, CA 92501 USA.; Department of Electrical Engineering, University of Southern California, Los Angeles, CA 90007 USA.","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","13","Providing ride-hailing services with electric vehicles can help reduce greenhouse gas emissions and solve the last mile problem. This paper develops a reinforcement learning based algorithm to operate a community owned electric vehicle fleet, which provides ride-hailing services to local residents. The goals of operating the electric vehicle fleet are to minimize customer waiting time, electricity cost, and operational costs of the vehicles. A novel framework characterized by decentralized learning and centralized decision making is proposed to solve the electric vehicle fleet dispatch problem. The decentralized learning process allows the individual vehicles to share their operating experiences and deep neural network model for state-value function estimation, which mitigates the curse of dimensionality of state and action domains. The centralized decision making framework converts the vehicle fleet coordination problem into a linear assignment problem, which has polynomial time complexity. Numerical study results show that the proposed approach outperforms the benchmark algorithms in terms of societal cost reduction.","","","10.1109/TITS.2019.2947408","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8878000","Assignment problem;electric vehicle;reinforcement learning;ride-hailing services.","Reinforcement learning;Routing;Electric vehicles;Vehicle dynamics;Decision making;Charging stations;Batteries","","","","","","","","","","IEEE","IEEE Early Access Articles"
"TGNet: Geometric Graph CNN on 3-D Point Cloud Segmentation","Y. Li; L. Ma; Z. Zhong; D. Cao; J. Li","Department of Geography and Environmental Management, University of Waterloo, Waterloo, ON N2L 3G1, Canada.; Department of Geography and Environmental Management, University of Waterloo, Waterloo, ON N2L 3G1, Canada.; School of Data and Computer Science, Sun Yat-sen University, Guangzhou 1010, China.; Waterloo Cognitive Autonomous Driving Lab, University of Waterloo, Waterloo, ON N2L 3G1, Canada.; Department of Geography and Environmental Management, University of Waterloo, Waterloo, ON N2L 3G1, Canada, and also with the Department of System Design Engineering, University of Waterloo, Waterloo, ON N2L 3G1, Canada (e-mail: junli@uwaterloo.ca).","IEEE Transactions on Geoscience and Remote Sensing","","2019","PP","99","1","13","Recent geometric deep learning works define convolution operations in local regions and have enjoyed remarkable success on non-Euclidean data, including graph and point clouds. However, the high-level geometric correlations between the input and its neighboring coordinates or features are not fully exploited, resulting in suboptimal segmentation performance. In this article, we propose a novel graph convolution architecture, which we term as Taylor Gaussian mixture model (GMM) network (TGNet), to efficiently learn expressive and compositional local geometric features from point clouds. The TGNet is composed of basic geometric units, TGConv, that conduct local convolution on irregular point sets and are parametrized by a family of filters. Specifically, these filters are defined as the products of the local point features and the neighboring geometric features extracted from local coordinates. These geometric features are expressed by Gaussian weighted Taylor kernels. Then, a parametric pooling layer aggregates TGConv features to generate new feature vectors for each point. TGNet employs TGConv on multiscale neighborhoods to extract coarse-to-fine semantic deep features while improving its scale invariance. Additionally, a conditional random field (CRF) is adopted within the output layer to further improve the segmentation results. Using three point cloud data sets, qualitative and quantitative experimental results demonstrate that the proposed method achieves 62.2% average accuracy on ScanNet, 57.8% and 68.17% mean intersection over union (mIoU) on Stanford Large-Scale 3D Indoor Spaces (S3DIS) and Paris-Lille-3D data sets, respectively.","","","10.1109/TGRS.2019.2958517","Natural Sciences and Engineering Research Council of Canada; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8941003","Deep learning;LiDAR point clouds;semantic segmentation.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Semi-supervised learning based on Hybrid Neural Network for the Signal Integrity Analysis","S. Chen; J. Chen; T. Zhang; S. Wei","National Key Laboratory of Science and Technology on Communications, University of Electronic Science and Technology of China, Chengdu, Sichuan, 611731, China.; National Key Laboratory of Science and Technology on Communications, University of Electronic Science and Technology of China, Chengdu, Sichuan, 611731, China.; National Key Laboratory of Science and Technology on Communications, University of Electronic Science and Technology of China, Chengdu, Sichuan, 611731, China.; National Key Laboratory of Science and Technology on Communications, University of Electronic Science and Technology of China, Chengdu, Sichuan, 611731, China.","IEEE Transactions on Circuits and Systems II: Express Briefs","","2019","PP","99","1","1","The signal integrity analysis of high-speed circuit channels becomes a challenging task, with the development of integrated circuit technology. To solve this problem, we proposed a fast-training semi-supervised learning method based on hybrid neural network (HNN) to predict the eye-diagram metrics. Compared with the existing methods, the proposed method only requires a small amount of training data with labels, the proposed method can automatically generate the labels for the unlabeled data with a small amount of labeled data with HNN based semi-supervised learning. To this end, the proposed method can save a great amount of time, which will be a more realistic solution for the practical application. Compared with existing machine learning-based methods, the proposed method requires 50% less labeled data for training with 32.29% and 20.73% accuracy improving on deep neural network (DNN) and co-training-style semi-supervised regression (COREG) methods, receptively.","","","10.1109/TCSII.2019.2948527","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8877863","eye-diagram predict;semi-supervised learning;signal integrity analysis;hybrid neural network (HNN).","Signal integrity;Neural networks;Training;Semisupervised learning;Euclidean distance;Training data","","","","","","","","","","IEEE","IEEE Early Access Articles"
"IN-YOLO: Real-time Detection of Outdoor High Voltage Insulators using UAV Imaging","D. Sadykova; D. Pernebayeva; M. Bagheri; A. James","Electrical and Computer Engineering, Nazarbayev University, 214082 Astana Kazakhstan (e-mail: Diana.Sadykova@nu.edu.kz); Electrical and Computer Engineering, Nazarbayev University, 214082 Astana Kazakhstan (e-mail: damira.pernebayeva@nu.edu.kz); Electrical and Computer Engineering, Astana, Astana Kazakhstan 010000 (e-mail: mehdi.bagheri@nu.edu.kz); Electrical and Computer Engineering, Nazarbayev University, 214082 Astana Kazakhstan 010000 (e-mail: apj@ieee.org)","IEEE Transactions on Power Delivery","","2019","PP","99","1","1","The high voltage insulator requires continuous monitoring and inspection to prevent failures and emergencies. Manual inspections are costly as it requires covering a large geographical area where insulators are often subjected to harsh weather conditions. Automatic detection of insulators from aerial images is the first step towards performing real-time classification of insulator conditions using Unmanned Aerial Vehicle (UAV). In this paper, we provide a cost-effective solution for detecting insulators under the conditions of an uncluttered background, varied object resolution and illumination conditions using You Only Look Once (YOLO) deep learning neural network model from aerial images. We apply data augmentation to avoid overfitting with a training set size of 56000 image samples. It is demonstrated experimentally that this method can accurately locate insulator on UAV based real-time image data. The detected insulator images are then successfully subjected to insulator surface condition assessment for the presence of ice, snow and water using different classifiers.","","","10.1109/TPWRD.2019.2944741","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8853298","YOLOv2;data augmentation;detection;insulators;UAV","Insulators;Real-time systems;Training;Neural networks;Unmanned aerial vehicles;Deep learning;Computer architecture","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Toward Driver Face Recognition in the Intelligent Traffic Monitoring Systems","C. Hu; Y. Zhang; F. Wu; X. Lu; P. Liu; X. Jing","College of Automation and College of Artificial Intelligence, Nanjing University of Posts and Telecommunications, Nanjing 210023, China, and also with the School of Automation, Southeast University, Nanjing 210096, China (e-mail: hchnjupt@126.com).; School of Automation, Southeast University, Nanjing 210096, China.; College of Automation and College of Artificial Intelligence, Nanjing University of Posts and Telecommunications, Nanjing 210023, China.; School of Automation, Southeast University, Nanjing 210096, China.; School of Transportation, Southeast University, Nanjing 210096, China.; College of Automation and College of Artificial Intelligence, Nanjing University of Posts and Telecommunications, Nanjing 210023, China.","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","14","This paper models the driver face recognition problem under the intelligent traffic monitoring systems as severe illumination variation face recognition with single sample problem. Firstly, in the point of view of numerical value sign, the current illumination invariant unit is derived from the subtraction of two pixels in the face local region, which may be positive or negative, we propose a generalized illumination robust (GIR) model based on positive and negative illumination invariant units to tackle severe illumination variations. Then, the GIR model can be used to generate several GIR images based on the local edge-region or the local block-region, which results in the edge-region based GIR (EGIR) image or the block-region based GIR (BGIR) image. For single GIR image based classification, the GIR image utilizes the saturation function and the nearest neighbor classifier, which can develop EGIR-face and BGIR-face. For multi GIR images based classification, the GIR images employ the extended sparse representation classification (ESRC) as the classifier that can form the EGIR image based classification (GIRC) and the BGIR image based classification (BGIRC). Further, the GIR model is integrated with the pre-trained deep learning (PDL) model to construct the GIR-PDL model. Finally, the performances of the proposed methods are verified on the Extended Yale B, CMU PIE, AR, self-built Driver and VGGFace2 face databases. The experimental results indicate that the proposed methods are efficient to tackle severe illumination variations.","","","10.1109/TITS.2019.2945923","National Natural Science Foundation of China; Natural Science Foundation of Jiangsu Province; China Postdoctoral Science Foundation; Postdoctoral Research Funding Program of Jiangsu Province; National Postdoctoral Program for Innovative Talents; Nanjing University of Posts and Telecommunications Science Foundation NUPTSF; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8868118","Traffic driver face recognition;severe illumination variations;generalized illumination robust model;single sample problem.","Lighting;Face;Face recognition;Vehicles;Deep learning;Monitoring;Facial features","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Enhanced Object Detection With Deep Convolutional Neural Networks for Advanced Driving Assistance","J. Wei; J. He; Y. Zhou; K. Chen; Z. Tang; Z. Xiong","Onlyou Artificial Intelligence Institute, Shanghai 200240, China.; School of Engineering and Applied Science, Aston University, Birmingham B4 7ET, U.K. (e-mail: j.he7@aston.ac.uk).; Institute of Image Communication and Network Engineering, Shanghai Jiaotong University, Shanghai 200240, China.; Institute of Image Communication and Network Engineering, Shanghai Jiaotong University, Shanghai 200240, China.; School of Engineering and Applied Science, Aston University, Birmingham B4 7ET, U.K..; Forward Innovation Ltd., Shenzhen 518055, China.","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","12","Object detection is a critical problem for advanced driving assistance systems (ADAS). Recently, convolutional neural networks (CNN) achieved large successes on object detection, with performance improvement over traditional approaches, which use hand-engineered features. However, due to the challenging driving environment (e.g., large object scale variation, object occlusion, and bad light conditions), popular CNN detectors do not achieve very good object detection accuracy over the KITTI autonomous driving benchmark dataset. In this paper, we propose three enhancements for CNN-based visual object detection for ADAS. To address the large object scale variation challenge, deconvolution and fusion of CNN feature maps are proposed to add context and deeper features for better object detection at low feature map scales. In addition, soft non-maximal suppression (NMS) is applied across object proposals at different feature scales to address the object occlusion challenge. As the cars and pedestrians have distinct aspect ratio features, we measure their aspect ratio statistics and exploit them to set anchor boxes properly for better object matching and localization. The proposed CNN enhancements are evaluated with various image input sizes by experiments over KITTI dataset. The experimental results demonstrate the effectiveness of the proposed enhancements with good detection performance over KITTI test set.","","","10.1109/TITS.2019.2910643","European Unions Horizon 2020 Research and Innovation Programme; FP7 grant DETERMINE; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8694965","Machine learning;object recognition;autonomous vehicles;intelligent vehicles.","Object detection;Proposals;Feature extraction;Detectors;Visualization;Computational modeling;Benchmark testing","","","","4","","","","","","IEEE","IEEE Early Access Articles"
"Single-image fence removal using deep convolutional neural network","T. Matsui; M. Ikehara.","Department of Electronics and Electrical Engineering, Keio University, Yokohama-shi, 223-8522, Japan.; Department of Electronics and Electrical Engineering, Keio University, Yokohama-shi, 223-8522, Japan.","IEEE Access","","2019","PP","99","1","1","In public spaces such as zoos and sports facilities, the presence of fences often annoys tourists and professional photographers. There is a demand for a post-processing tool to produce a non-occluded view from an image or video. This “de-fencing” task is divided into two stages: one to detect fence regions and the other to fill the missing part. For over a decade, various methods have been proposed for video-based de-fencing. However, only a few single-image-based methods are proposed. In this paper, we focus on single-image fence removal. Conventional approaches suffer from inaccurate and non-robust fence detection and inpainting due to less content information. To solve these problems, we combine novel methods based on a deep convolutional neural network (CNN) and classical domain knowledge in image processing. In the training process, we are required to obtain both fence images and corresponding non-fence ground truth images. Therefore, we synthesize natural fence images from real images. Moreover, spacial filtering processing (e.g. a Laplacian filter and a Gaussian filter) improves the performance of the CNN for detection and inpainting. Our proposed method can automatically detect a fence and generate a clean image without any user input. Experimental results demonstrate that our method is effective for a broad range of fence images.","","","10.1109/ACCESS.2019.2960087","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933392","De-fencing;Deep learning;Image restoration;Object removal;Convolutional neural network","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Small-Scale Pedestrian Detection Based on Deep Neural Network","B. Han; Y. Wang; Z. Yang; X. Gao","School of Electronic Engineering, Xidian University, Xi'an 710071, China (e-mail: bhan@xidian.edu.cn).; School of Electronic Engineering, Xidian University, Xi'an 710071, China.; School of Electronic Engineering, Xidian University, Xi'an 710071, China.; School of Electronic Engineering, Xidian University, Xi'an 710071, China.","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","10","Pedestrian detection is a crucial component for intelligent transport system and advanced driver assistance system. In recent years, pedestrian detection methods have achieved higher accuracy. However, the existing algorithms are insufficient for small-scale pedestrian detection that is relatively far from cameras in practical applications. In this paper, we propose a novel deep small-scale sense network (termed SSN) for small-scale pedestrian detection. The proposed architecture could generate some proposal regions which are more effective to detect small-scale pedestrians. Furthermore, we design a novel loss function based on cross entropy loss to increase the loss contribution from hard-to-detect small-scale pedestrians. In addition, a novel evaluation metric is introduced, which can measure the location precision of the pedestrian detection methods. In addition an Asian pedestrian detection dataset named VIP pedestrian dataset is constructed from various road condition data. Our method achieves good detection performance on Caltech pedestrian dataset and our VIP pedestrian dataset.","","","10.1109/TITS.2019.2923752","National Natural Science Foundation of China; National Basic Research Program of China (973 Program); Chinas Postdoctoral Fund First Class Funding; Shanxi Province Postdoctoral Science Fund Key Research and Development Program of Shaanxi Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8751139","Pedestrian detection;deep learning;small-scale;VIP pedestrian dataset.","Proposals;Feature extraction;Detectors;Vehicles;Convolution;Entropy;Histograms","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Fast Training Algorithms for Deep Convolutional Fuzzy Systems with Application to Stock Index Prediction","L. Wang","Environment and resources, University of the Chinese Academy of Sciences, 74519 Beijing China 100049 (e-mail: lxwang@ucas.edu.cn)","IEEE Transactions on Fuzzy Systems","","2019","PP","99","1","1","A deep convolutional fuzzy system (DCFS) on a high-dimensional input space is a multi-layer connection of many low-dimensional fuzzy systems, where the input variables to the low-dimensional fuzzy systems are selected through a moving window across the input spaces of the layers. To design the DCFS based on input-output data pairs, we propose a bottom-up layer-by-layer scheme. Specifically, by viewing each of the first-layer fuzzy systems as a weak estimator of the output based only on a very small portion of the input variables, we design these fuzzy systems using the WM Method. After the first-layer fuzzy systems are designed, we pass the data through the first layer to form a new data set and design the second-layer fuzzy systems based on this new data set in the same way as designing the first-layer fuzzy systems. Repeating this process layer-by-layer we design the whole DCFS. We also propose a DCFS with parameter sharing to save memory and computation. We apply the DCFS models to predict a synthetic chaotic plus random time-series and the real Hang Seng Index of the Hong Kong stock market.","","","10.1109/TFUZZ.2019.2930488","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8788632","Hierarchical fuzzy systems;deep learning;the WM Method;stock index prediction","Fuzzy systems;Training;Input variables;Windows;Prediction algorithms;Computational modeling;Fuzzy sets","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Edge AI: On-Demand Accelerating Deep Neural Network Inference via Edge Computing","E. Li; L. Zeng; Z. Zhou; X. Chen","School of Data and Computer Science, Sun Yat-sen University, Guangzhou 510006, China.; School of Data and Computer Science, Sun Yat-sen University, Guangzhou 510006, China.; School of Data and Computer Science, Sun Yat-sen University, Guangzhou 510006, China.; School of Data and Computer Science, Sun Yat-sen University, Guangzhou 510006, China.","IEEE Transactions on Wireless Communications","","2019","PP","99","1","1","As a key technology of enabling Artificial Intelligence (AI) applications in 5G era, Deep Neural Networks (DNNs) have quickly attracted widespread attention. However, it is challenging to run computation-intensive DNN-based tasks on mobile devices due to the limited computation resources. What’s worse, traditional cloud-assisted DNN inference is heavily hindered by the significant wide-area network latency, leading to poor real-time performance as well as low quality of user experience. To address these challenges, in this paper, we propose Edgent, a framework that leverages edge computing for DNN collaborative inference through device-edge synergy. Edgent exploits two design knobs: (1) DNN partitioning that adaptively partitions computation between device and edge for purpose of coordinating the powerful cloud resource and the proximal edge resource for real-time DNN inference; (2) DNN right-sizing that further reduces computing latency via early exiting inference at an appropriate intermediate DNN layer. In addition, considering the potential network fluctuation in real-world deployment, Edgent is properly design to specialize for both static and dynamic network environment. Specifically, in a static environment where the bandwidth changes slowly, Edgent derives the best configurations with the assist of regression-based prediction models, while in a dynamic environment where the bandwidth varies dramatically, Edgent generates the best execution plan through the online change point detection algorithm that maps the current bandwidth state to the optimal configuration. We implement Edgent prototype based on the Raspberry Pi and the desktop PC and the extensive experimental evaluations demonstrate Edgent’s effectiveness in enabling on-demand low-latency edge intelligence.","","","10.1109/TWC.2019.2946140","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8876870","Edge intelligence;edge computing;deep learning;computation offloading","Computational modeling;Mobile handsets;Bandwidth;Image edge detection;Performance evaluation;Edge computing;Wireless communication","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Strong Baseline and Batch Normalization Neck for Deep Person Re-identification","H. Luo; W. Jiang; Y. Gu; F. Liu; X. Liao; S. Lai; J. Gu","Zhejiang University Department of Control Science and Engineering, Zhejiang University Institute of Cyber-Systems and Control, 229035 Hangzhou, Zhejiang China (e-mail: haoluocsc@zju.edu.cn); Zhejiang University Department of Control Science and Engineering, Zhejiang University Institute of Cyber-Systems and Control, 229035 Hangzhou, Zhejiang China 310027 (e-mail: jiangwei_zju@zju.edu.cn); Zhejiang University Department of Control Science and Engineering, Zhejiang University Institute of Cyber-Systems and Control, 229035 Hangzhou, Zhejiang China (e-mail: gu_youzhi@zju.edu.cn); Ping An Technology, Ping An Technology, Shen Zhen China (e-mail: LIUFUXU641@pingan.com.cn); Institution of Automation, Chinese Academy of Sciences, 12381 Beijing, Beijing China (e-mail: randall@mail.ustc.edu.cn); Xi'an Jiantong University, Xi'an Jiaotong University, 12480 Xi'an, Shaanxi China (e-mail: laishenqi@stu.xjtu.edu.cn); Department of Control Science and Engineering, Zhejiang University Institute of Cyber-Systems and Control, 229035 Hang Zhou, Zhejiang China (e-mail: 3150102234@zju.edu.cn)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","This study explores a simple but strong baseline for person re-identification (ReID). Person ReID with deep neural networks has progressed and achieved high performance in recent years. However, many state-of-the-art methods design complex network structures and concatenate multi-branch features. In the literature, some effective training tricks briefly appear in several papers or source codes. The present study collects and evaluates these effective training tricks in person ReID. By combining these tricks, the model achieves 94.5% rank-1 and 85.9% mean average precision on Market1501 with only using the global features of ResNet50. The performance surpasses all existing global- and part-based baselines in person ReID. We propose a novel neck structure named as batch normalization neck (BNNeck). BNNeck adds a batch normalization layer after global pooling layer to separate metric and classification losses into two different feature spaces because we observe they are inconsistent in one embedding space. Extended experiments show that BNNeck can boost the baseline, and our baseline can improve the performance of existing state-of-the-art methods. Our codes and models are available at: https://github.com/michuanhaohao/reid-strong-baseline.","","","10.1109/TMM.2019.2958756","Science Foundation of Chinese Aerospace Industry; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8930088","Person ReID;Baseline;Tricks;BNNeck;Deep learning","Training;Feature extraction;Computational modeling;Neck;Measurement;Task analysis;Gallium nitride","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Real-time Radiofrequency Ablation Lesion Depth Estimation Using Multi-frequency Impedance with a Deep Neural Network and Tree-based Ensembles","E. Besler; Y. C. Wang; A. V. Sahakian","Electrical and Computer Engineering, Northwestern University, 3270 Evanston, Illinois United States 60208 (e-mail: emrebesler2020@u.northwestern.edu); Electrical and Computer Engineering, Northwestern University, Evanston, Illinois United States (e-mail: ycwang@u.northwestern.edu); Biomedical Engineering, Northwestern University, 3270 Evanston, Illinois United States (e-mail: sahakian@eecs.northwestern.edu)","IEEE Transactions on Biomedical Engineering","","2019","PP","99","1","1","Objective: Design and optimization of statistical models for use in methods for estimating radiofrequency ablation (RFA) lesion depths in soft real-time performance. Methods: Using tissue complex electrical impedance data collected from a low-cost embedded system, a deep neural network (NN) and tree-based ensembles (TEs) were trained for estimating the RFA lesion depth via regression. Results: Addition of frequency sweep data, previous depth data, and previous RF power state data boosted accuracy of the statistical models. The root mean square errors were 2 mm for NN and 0.5 mm for TEs for previous statistical models and the root mean square errors were 0.4 mm for NN and 0.04 mm for TEs for the statistical models presented in this paper. Simulation ablation performance showed a mean difference against physical measurements of $0.5 \pm 0.2\;\mathrm{mm}$ for the NN-based depth estimation method and $0.7 \pm 0.4\;\mathrm{mm}$ for the TE-based depth estimation method. Conclusion: The results show that multi-frequency data significantly improves the depth estimation performance of the statistical models. Significance: The RFA lesion depth estimation methods presented in this work achieve millimeter-resolution accuracy with soft real-time performance on an ARMv7-based embedded system for potential translation to clinical RFA technologies.","","","10.1109/TBME.2019.2950342","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8886409","Radiofrequency ablation;tumor;cancer;control;monitoring;machine learning;ensemble;lesion;depth;deep network;random forest;adaptive boosting","Lesions;Real-time systems;Estimation;Impedance;Ultrasonic imaging;Tomography","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Deep CNN-Based Ground Vibration Monitoring Scheme for MEMS Sensed Data","J. Kang; I. Kim; S. Lee; D. Ryu; J. Kwon","School of Intelligent Mechatronics Engineering, Sejong University, Seoul 05006, South Korea.; Department of Electrical and Computer Engineering, Queen's University, Kingston, ON K7L 3N6, Canada (e-mail: ilmin.kim@queensu.ca).; Geoscience Platform Division, Korea Institute of Geoscience and Mineral Resources, Daejeon 34132, South Korea.; Geoscience Platform Division, Korea Institute of Geoscience and Mineral Resources, Daejeon 34132, South Korea.; Geoscience Platform Division, Korea Institute of Geoscience and Mineral Resources, Daejeon 34132, South Korea.","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","Ground vibration monitoring with microelectromechanical systems (MEMS) sensors is very effective and promising for alerting geological disasters. In this letter, explicitly considering and effectively addressing several specific issues related to practical MEMS sensors, we develop a novel ground vibration monitoring scheme for MEMS sensed data based on a deep convolutional neural network (CNN). Experiments are then conducted on the synthetic and real data sets. Experimental results on both data sets demonstrate that the proposed scheme significantly outperforms the other comparable schemes. For the synthetic data set, the proposed scheme achieves a very high overall accuracy of 98.82%. Also, for the real data set, the proposed scheme achieves a high overall accuracy of 81.64%, which is about 7% higher than that reported in the literature.","","","10.1109/LGRS.2019.2918641","Korea Institute of Geoscience and Mineral Resources KIGAM funded by the Ministry of Science and ICT of Korea through the Basic Research Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8736006","Convolutional neural network (CNN);deep learning;ground vibration;microelectromechanical systems (MEMS);sensed data.","Micromechanical devices;Vibrations;Monitoring;Convolution;Feature extraction;Sensor phenomena and characterization","","","","","","","","","","IEEE","IEEE Early Access Articles"
"4D Modeling of fMRI Data via Spatio-Temporal Convolutional Neural Networks (ST-CNN)","Y. Zhao; X. Li; H. Huang; W. Zhang; S. Zhao; M. Makkie; M. Zhang; Q. Li; T. Liu","Cortical Architecture Imaging and Discovery (CAID) Lab, Department of Computer Science and Bioimaging Research Center, The University of Georgia, Athens, GA, USA.; Massachusetts General Hospital and Harvard Medical School, Boston MA 02115, USA.; School of Automation, Northwestern Polytechnical University, Xi’an, Sha’anxi 710072, China.; Cortical Architecture Imaging and Discovery (CAID) Lab, Department of Computer Science and Bioimaging Research Center, The University of Georgia, Athens, GA, USA.; School of Automation, Northwestern Polytechnical University, Xi’an, Sha’anxi 710072, China.; Cortical Architecture Imaging and Discovery (CAID) Lab, Department of Computer Science and Bioimaging Research Center, The University of Georgia, Athens, GA, USA.; Center for Data Science, Peking University, Beijing 100080, China.; Massachusetts General Hospital and Harvard Medical School, Boston MA 02115, USA, and also with Peking University, Laboratory for Biomedical Image Analysis, Beijing Institute of Big Data Research, Beijing 100871, China.; Cortical Architecture Imaging and Discovery Lab, Department of Computer Science and Bioimaging Research Center, The University of Georgia, Athens, GA, USA.","IEEE Transactions on Cognitive and Developmental Systems","","2019","PP","99","1","1","Since the human brain functional mechanism has been enabled for investigation by the functional Magnetic Resonance Imaging (fMRI) technology, simultaneous modeling of both the spatial and temporal patterns of brain functional networks from 4D fMRI data has been a fundamental but still challenging research topic for neuroimaging and medical image analysis fields. Currently, general linear model (GLM), independent component analysis (ICA), sparse dictionary learning, and recently deep learning models, are major methods for fMRI data analysis in either spatial or temporal domains, but there are few joint spatial-temporal methods proposed, as far as we know. As a result, the 4D nature of fMRI data has not been effectively investigated due to this methodological gap. The recent success of deep learning applications for functional brain decoding and encoding greatly inspired us in this work to propose a novel framework called spatio-temporal convolutional neural network (ST-CNN) to extract both spatial and temporal characteristics from targeted networks jointly and automatically identify of functional networks. The identification of Default Mode Network (DMN) from fMRI data was used for evaluation of the proposed framework. Results show that only training the framework on one fMRI dataset is sufficiently generalizable to identify the DMN from different datasets of different cognitive tasks and resting state. Further investigation of the results shows that the joint-learning scheme can capture the intrinsic relationship between the spatial and temporal characteristics of DMN and thus it ensures the accurate identification of DMN from independent datasets. The ST-CNN model brings new tools and insights for fMRI analysis in cognitive and clinical neuroscience studies.","","","10.1109/TCDS.2019.2916916","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8713897","fMRI;functional brain networks;deep learning.","Functional magnetic resonance imaging;Brain modeling;Dictionaries;Data models;Task analysis;Machine learning;Sparse matrices","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Convolutional Graph Autoencoder: A Generative Deep Neural Network for Probabilistic Spatio-temporal Solar Irradiance Forecasting","M. Khodayar; S. Mohammadi; M. E. Khodayar; J. Wang; G. Liu","Electrical Engineering, Southern Methodist University Bobby B Lyle School of Engineering, 184721 Dallas, Texas United States 75205 (e-mail: mahdik@smu.edu); Electrical Engineering, Southenr Methodist University, Dallas, Texas United States 75205 (e-mail: smohammadi@smu.edu); Electrical Engineering, Southern Methodist University, Dallas, Texas United States 75205 (e-mail: mkhodayar@smu.edu); Department of Electrical Engineering, Southern Methodist University Bobby B Lyle School of Engineering, 184721 Dallas, Texas United States 75275-0221 (e-mail: jianhui@smu.edu); GEIRI North America, Santa Clara United States (e-mail: guangyi.liu@geirina.net)","IEEE Transactions on Sustainable Energy","","2019","PP","99","1","1","Machine Learning on graph-structured data is an important and omnipresent task for a vast variety of applications including anomaly detection and dynamic network analysis. In this paper, a deep generative model is introduced to capture continuous probability densities corresponding to the nodes of an arbitrary graph. In contrast to all learning formulations in the area of discriminative pattern recognition, we propose a scalable generative optimization/algorithm theoretically proved to capture distributions at the nodes of a graph. Our model is able to generate samples from the probability densities learned at each node. This probabilistic data generation model, i.e. convolutional graph auto-encoder (CGAE), is devised based on the localized first-order approximation of spectral graph convolutions, deep learning, and the variational Bayesian inference. We apply our CGAE to a new problem, the spatio-temporal probabilistic solar irradiance prediction. Multiple solar radiation measurement sites in a wide area in northern states of the US are modeled as an undirected graph. Using our proposed model, the distribution of future irradiance given historical radiation observations is estimated for every site/node. Numerical results on the National Solar Radiation Database show state-of-the-art performance for probabilistic radiation prediction on geographically distributed irradiance data in terms of reliability, sharpness, and continuous ranked probability score.","","","10.1109/TSTE.2019.2897688","Division of Electrical, Communications and Cyber Systems; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8663347","Deep Neural Network;Spatio-temporal Forecasting;Probabilistic Forecasting;Spectral Graph Convolutions;Variational Bayesian Inference","Predictive models;Probabilistic logic;Forecasting;Data models;Mathematical model;Solar radiation;Computational modeling","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Densely Connected Neural Network With Unbalanced Discriminant and Category Sensitive Constraints for Polyp Recognition","Y. Yuan; W. Qin; B. Ibragimov; G. Zhang; B. Han; M. Q. -. Meng; L. Xing","Department of Electrical Engineering, City University of Hong Kong, Hong Kong. (e-mail: yxyuan.ee@cityu.edu.hk).; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Beijing 518055, China.; Department of Machine Learning and Medical Imaging, University of Copenhagen, 2100 Copenhagen, Denmark, and also with the Department of Computer Science, University of Copenhagen, 2100 Copenhagen, Denmark.; Beijing Advanced Innovation Center for Biomedical Engineering, School of Biological Science and Medical Engineering, Beihang University, Beijing 100191, China.; Department of Radiation Oncology, Stanford University, Stanford, CA 94305 USA.; Department of Electronic Engineering, The Chinese University of Hong Kong, Hong Kong.; Department of Radiation Oncology, Stanford University, Stanford, CA 94305 USA.","IEEE Transactions on Automation Science and Engineering","","2019","PP","99","1","10","Automatic polyp recognition in endoscopic images is challenging because of the low contrast between polyps and the surrounding area, the fuzzy and irregular polyp borders, and varying imaging light conditions. In this article, we propose a novel densely connected convolutional network with ``unbalanced discriminant (UD)'' loss and ``category sensitive (CS)'' loss (DenseNet-UDCS) for the task. We first utilize densely connected convolutional network (DenseNet) as the basic framework to conduct end-to-end polyp recognition task. Then, the proposed dual constraints, UD loss and CS loss, are simultaneously incorporated into the DenseNet model to calculate discriminative and suitable image features. The UD loss in our network effectively captures classification errors from both majority and minority categories to deal with the strong data imbalance of polyp images and normal ones. The CS loss imposes the ratio of intraclass and interclass variations in the deep feature learning process to enable features with large interclass variation and small intraclass compactness. With the joint supervision of UD loss and CS loss, a robust DenseNet-UDCS model is trained to recognize polyps from endoscopic images. The experimental results achieved polyp recognition accuracy of 93.19%, showing that the proposed DenseNet-UDCS can accurately characterize the endoscopic images and recognize polyps from the images. In addition, our DenseNet-UDCS model is superior in detection accuracy in comparison with state-of-the-art polyp recognition methods.","","","10.1109/TASE.2019.2936645","Sichuan Provincial Science and Technology Department Applied Basic Research Project; CityU Start Up Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8842597","Category sensitive (CS) loss;densely connected convolutional network (DenseNet);polyp image classification;unbalanced discriminant (UD) loss.","Deep learning;Image recognition;Task analysis;Data models;Biomedical imaging;Shape;Feature extraction","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Using Latent Knowledge to Improve Real-Time Activity Recognition for Smart IoT","S. Yan; K. Lin; X. Zheng; W. Zhang","Information, Zhejiang University of Finance and Economics, 12623 Hangzhou, ZHEJIANG China 310018 (e-mail: surong.y@gmail.com); Electrical Engineering and Computer Science, University of California, Irvine, Irvine, California United States (e-mail: klinuci@gmail.com); College of Computer Science, Zhejiang University, Hangzhou, Zhejiang China 310027 (e-mail: xlzheng@zju.edu.cn); information, Zhejiang University of Finance and Economics, 12623 Hangzhou, Zhejiang China (e-mail: WYZHANG@e.ntu.edu.sg)","IEEE Transactions on Knowledge and Data Engineering","","2019","PP","99","1","1","Real-time/online activity recognition (AR) is an important technology in smart Internet of Things (IoT) systems where users are assisted by smart devices in their daily activities. How to generate appropriate feature representation from sensor event streaming is a challenging issue for accurate and efficient real-time AR. Previous AR models that rely on explicit domain knowledge are not appropriate for online recognition of complex human activities. We propose to use unsupervised learning to learn the latent knowledge and embed the activity probability distribution prediction as high-level features to boost real-time AR performance. The proposed approach first learns the latent knowledge from explicit-activity window sequences using unsupervised learning, and derives the probability distribution prediction of activity classes for a given sliding window. Our approach then feeds the prediction with other basic features of the sliding window into a classifier to produce the final class result on each event-count sliding window. Experiments on five smart home datasets show that the proposed method achieves a higher accuracy by at least 20% improvement on F1_score than previous traditional algorithms, while maintaining a lower time cost than deep learning based methods. An analysis on the feature importance shows that the addition of probability distribution prediction about activity classes leads to a promising direction for real-time AR.","","","10.1109/TKDE.2019.2891659","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8606138","Activity recognition;streaming data;latent knowledge;activity prediction;unsupervised learning","Hidden Markov models;Probability distribution;Real-time systems;Windows;Deep learning;Microsoft Windows","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Detecting Parkinsonian Tremor from IMU Data Collected In-The-Wild using Deep Multiple-Instance Learning","A. Papadopoulos; K. Kyritsis; L. Klingelhoefer; S. Bostanjopoulou; K. R. Chaudhuri; A. Delopoulos","Department of Electrical and Computer Engineering, Aristotle University of Thessaloniki, 37782 Thessaloniki Greece (e-mail: alpapado@mug.ee.auth.gr); Department of Electrical and Computer Engineering, Aristotle University of Thessaloniki, 37782 Thessaloniki Greece (e-mail: kokirits@mug.ee.auth.gr); Department of Neurology, Dresden University of Technology, 9169 Dresden, Sachsen Germany (e-mail: lisa.klingelhoefer@uniklinikum-dresden.de); Third Neurological Clinic, George Papanikolaou General Hospital of Thessaloniki, 37798 Thessaloniki, Makedonia Thraki Greece (e-mail: bostkamb@otenet.gr); International Parkinson Excellence Research Centre, King's College London, 4616 London, London United Kingdom of Great Britain and Northern Ireland (e-mail: ray.chaudhuri@nhs.net); Department of Electrical and Computer Engineering, University Campus, Faculty of Enginnering, Building D, 5th floor, GR 54124, Aristotle University of Thessaloniki, 37782 Thessaloniki Greece (e-mail: adelo@eng.auth.gr)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","Parkinson's Disease (PD) is a slowly evolving neuro-logical disease that affects about 1% of the population above 60 years old, causing symptoms that are subtle at first, but whose intensity increases as the disease progresses. Automated detection of these symptoms could offer clues as to the early onset of the disease, thus improving the expected clinical outcomes of the patients via appropriately targeted interventions. This potential has led many researchers to develop methods that use widely available sensors to measure and quantify the presence of PD symptoms such as tremor, rigidity and braykinesia. However, most of these approaches operate under controlled settings, such as in lab or at home, thus limiting their applicability under free-living conditions. In this work, we present a method for automatically identifying tremorous episodes related to PD, based on IMU signals captured via a smartphone device. We propose a Multiple-Instance Learning approach, wherein a subject is represented as an unordered bag of accelerometer signal segments and a single, expert-provided, tremor annotation. Our method combines deep feature learning with a learnable pooling stage that is able to identify key instances within the subject bag, while still being trainable end-to-end. We validate our algo- rithm on a newly introduced dataset of 45 subjects, containing accelerometer signals collected entirely in-the-wild. The good classification performance obtained in the conducted experiments suggests that the proposed method can efficiently navigate the noisy environment of in-the-wild recordings.","","","10.1109/JBHI.2019.2961748","European Commission; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8941232","","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Learning to Recommend with Multiple Cascading Behaviors","C. Gao; X. He; D. Gan; X. Chen; F. Feng; Y. Li; T. Chua; L. Yao; Y. Song; D. Jin","Department of Electronic Engineering, Tsinghua University, Beijing, Beijing China (e-mail: gc16@mails.tsinghua.edu.cn); School of Computing, National University of Singapore, Singapore, Singapore Singapore 117417 (e-mail: xiangnanhe@gmail.com); Computer Science, Carnegie Mellon University, Beijing, Connecticut United States (e-mail: dgan@andrew.cmu.edu); Department of Electronic Engineering, Tsinghua University, Beijing, Beijing China (e-mail: cxn15@mails.tsinghua.edu.cn); School of Computing, National University of Singapore, 37580 Singapore, Singapore Singapore (e-mail: fulifeng93@gmail.com); Department of Electronic Engineering, Tsinghua University, Beijing, Beijing China (e-mail: liyong07@tsinghua.edu.cn); School of Computing, National University of Singapore, 37580 Singapore, Singapore Singapore (e-mail: dcscts@nus.edu.sg); Computer Science and Engineering, University of New South Wales, 7800 Sydney, New South Wales Australia 2052 (e-mail: lina.yao@unsw.edu.au); Computer Science and Engineering, University of New South Wales, 7800 Beijing, New South Wales Australia (e-mail: yang.song1@unsw.edu.au); Electronic Engineering, Tsinghua University, Beijing, Beijing China (e-mail: jindp@tsinghua.edu.cn)","IEEE Transactions on Knowledge and Data Engineering","","2019","PP","99","1","1","Most existing recommender systems leverage user behavior data of one type only, such as the purchase behavior in E-commerce that is directly related to the business KPI (Key Performance Indicator) of conversion rate. Besides the key behavioral data, we argue that other forms of user behaviors also provide valuable signal, such as views, clicks, adding a product to shopping carts and so on. They should be taken into account properly to provide quality recommendation for users. In this work, we contribute a new solution named NMTR (short for Neural Multi-Task Recommendation) for learning recommender systems from user multi-behavior data. We develop a neural network model to capture the complicated and multi-type interactions between users and items. In particular, our model accounts for the cascading relationship among different types of behaviors (e.g., a user must click on a product before purchasing it). To fully exploit the signal in the data of multiple types of behaviors, we perform a joint optimization based on the multi-task learning framework, where the optimization on a behavior is treated as a task. Extensive experiments on two real-world datasets demonstrate that NMTR significantly outperforms state-of-the-art recommender systems that are designed to learn from both single-behavior data and multi-behavior data. Further analysis shows that modeling multiple behaviors is particularly useful for providing recommendation for sparse users that have very few interactions.","","","10.1109/TKDE.2019.2958808","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8930270","Multi-behavior Recommendation;Collaborative Filtering;Deep Learning","Collaboration;Neural networks;Semantics;Recommender systems;Predictive models;Data models;Gallium nitride","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Hybrid Deep Neural Networks for Friend Recommendations in Edge Computing Environment","J. Gong; Y. Zhao; S. Chen; H. Wang; L. Du; S. Wang; J. Li; M. Z. A. Bhuiyan; M. Liu; H. Peng; B. Du","School of Information Science and Engineering, Yanshan University, Qinhuangdao 066004, China and Key Lab for Computer Virtual Technology and System Integration, Yanshan University, Qinhuangdao 066004, China and State Key Lab of Mathematical Engineering and Advanced Computing, Wuxi 214000, China and Key Laboratory for Software Engineering of Hebei Province, Yanshan University, Qinhuangdao 066004,China.; School of Information Science and Engineering, Yanshan University, Qinhuangdao 066004, China and Key Lab for Computer Virtual Technology and System Integration, Yanshan University, Qinhuangdao 066004, China.; School of Information Science and Engineering, Yanshan University, Qinhuangdao 066004, China and State Key Lab of Mathematical Engineering and Advanced Computing, Wuxi 214000, China.; School of Computer Science and Technology, Beihang University, Beijing 100083, China.; School of Computer Science and Technology, Beihang University, Beijing 100083, China.; Department of Applied Mathematics, Yanshan University, Qinhuangdao 066044, China.; School of Information Science and Technology, Shijiazhuang TIEDAO University, Shijiazhuang 050043, China.; Department of Computer and Information Sciences, Fordham University, NY 10458, USA.; School of Electrical Engineering, Hebei University of Technology, Tianjin 300132, China.; School of Cyber Science and Technology, Beihang University, Beijing 100083, China.; School of Computer Science and Technology, Beihang University, Beijing 100083, China.","IEEE Access","","2019","PP","99","1","1","With the rising popularity of social networks and service recommendations, research on new methods of friend recommendation have become a key topic, especially when based on quality-driven resource processing in an edge computing environment. Traditional methods seldom systematically combine static attributes (e.g., interests, geographical locations, and common friends), dynamic behaviors (e.g., liking, making comments, forwarding and @), and network structures (e.g., social ties) to recommend a new friend to a target user. Meanwhile, with the advent of deep learning, it has become more challenging to integrate these features into a deep neural network framework for friend recommendation. For example, how do we optimally make use of these features to form a united framework and what type of deep neural network architecture should be introduced into a novel recommendation method in an edge computing environment? In this paper, we propose DFRec++, a hybrid deep neural network framework combining attribute attention and network embeddings to make social friend recommendations with the help of both interactive semantics and contextual enhancement. More specifically, we first utilize the latent dirichlet allocation (LDA) topic model to generate common interest topics between users and compute the similarity of the explicit static attribute vector representation of topics, locations, and common friends. Then we feed dynamic behavior attributes into a convolutional neural network (CNN) to obtain the implicit vector representation of the interactions and context between two users. Subsequently, a multi-attention mechanism is designed to further improve the deep vector representation of the attribute information. Next, the LINE-based network embeddings algorithm is applied to embed the network structure into a low-dimensional vector. Finally, the attribute attention vector and the network embeddings are concatenated to form a deep feature representation, which is subsequently fed to a fully connected neural network (FCNN) to capture the probability of friendship between two users. The output of FCNN indicates the probability of two users becoming friends. We conducted experiments on a real-world Weibo dataset and the results show that DFRec++ outperforms several existing methods.","","","10.1109/ACCESS.2019.2958599","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8930557","Friend Recommendation;Deep Neural Network;Attribute-specific Multi-attention Mechanism;Network Embedding;Convolutional Neural Network","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Fault Location in Power Distribution Systems via Deep Graph Convolutional Networks","K. Chen; J. Hu; Y. Zhang; Z. Yu; J. He","State Key Lab of Power Systems, Dept. of Electrical Engineering, Tsinghua University, Beijing 100084, P. R. of China.; State Key Lab of Power Systems, Dept. of Electrical Engineering, Tsinghua University, Beijing 100084, P. R. of China.; Dept. of Electrical and Computer Engineering, University of California, Santa Cruz, CA 95064, USA.; State Key Lab of Power Systems, Dept. of Electrical Engineering, Tsinghua University, Beijing 100084, P. R. of China.; State Key Lab of Power Systems, Dept. of Electrical Engineering, Tsinghua University, Beijing 100084, P. R. of China.","IEEE Journal on Selected Areas in Communications","","2019","PP","99","1","1","This paper develops a novel graph convolutional network (GCN) framework for fault location in power distribution networks. The proposed approach integrates multiple measurements at different buses while taking system topology into account. The effectiveness of the GCN model is corroborated by the IEEE 123 bus benchmark system. Simulation results show that the GCN model significantly outperforms other widely-used machine learning schemes with very high fault location accuracy. In addition, the proposed approach is robust to measurement noise and data loss errors. Data visualization results of two competing neural networks are presented to explore the mechanism of GCNs superior performance. A data augmentation procedure is proposed to increase the robustness of the model under various levels of noise and data loss errors. Further experiments show that the model can adapt to topology changes of distribution networks and perform well with a limited number of measured buses.","","","10.1109/JSAC.2019.2951964","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8892483","Fault location;distribution systems;deep learning;graph convolutional networks","Fault location;Circuit faults;Voltage measurement;Feature extraction;Convolution;Current measurement;Task analysis","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Semi-Supervised Image Dehazing","L. Li; Y. Dong; W. Ren; J. Pan; C. Gao; N. Sang; M. Yang","National Key Laboratory of Science and Technology on Multi-spectral Information Processing, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, 430074, China.; National Key Laboratory of Science and Technology on Multi-spectral Information Processing, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, 430074, China.; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, 100049, China.; Intelligent Media Analysis Group, School of Computer Science, Nanjing University of Science and Technology, Nanjing, 210094, China.; National Key Laboratory of Science and Technology on Multi-spectral Information Processing, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, 430074, China.; National Key Laboratory of Science and Technology on Multi-spectral Information Processing, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, 430074, China.; School of Engineering, University of California at Merced, Merced, CA, 95534, USA.","IEEE Transactions on Image Processing","","2019","PP","99","1","1","We present an effective semi-supervised learning algorithm for single image dehazing. The proposed algorithm applies a deep Convolutional Neural Network (CNN) containing a supervised learning branch and an unsupervised learning branch. In the supervised branch, the deep neural network is constrained by the supervised loss functions, which are mean squared, perceptual, and adversarial losses. In the unsupervised branch, we exploit the properties of clean images via sparsity of dark channel and gradient priors to constrain the network. We train the proposed network on both the synthetic data and real-world images in an end-to-end manner. Our analysis shows that the proposed semi-supervised learning algorithm is not limited to synthetic training datasets and can be generalized well to real-world images. Extensive experimental results demonstrate that the proposed algorithm performs favorably against the state-of-the-art single image dehazing algorithms on both benchmark datasets and real-world images.","","","10.1109/TIP.2019.2952690","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8902220","Image dehazing;Deep learning;Semi-supervised learning","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Learning Image Profile Enhancement and Denoising Statistics Priors for Single-Image Super-Resolution","C. Ren; X. He; Y. Pu; T. Q. Nguyen","College of Electronics and Information Engineering, Sichuan University, Chengdu 610065, China (e-mail: chaoren@scu.edu.cn).; College of Electronics and Information Engineering, Sichuan University, Chengdu 610065, China.; College of Computer Science, Sichuan University, Chengdu 610065, China.; Department of Electrical and Computer Engineering, University of California at San Diego, La Jolla, CA 92093 USA.","IEEE Transactions on Cybernetics","","2019","PP","99","1","14","Single-image super-resolution (SR) has been widely used in computer vision applications. The reconstruction-based SR methods are mainly based on certain prior terms to regularize the SR problem. However, it is very challenging to further improve the SR performance by the conventional design of explicit prior terms. Because of the powerful learning ability, deep convolutional neural networks (CNNs) have been widely used in single-image SR task. However, it is difficult to achieve further improvement by only designing the network architecture. In addition, most existing deep CNN-based SR methods learn a nonlinear mapping function to directly map low-resolution (LR) images to desirable high-resolution (HR) images, ignoring the observation models of input images. Inspired by the split Bregman iteration (SBI) algorithm, which is a powerful technique for solving the constrained optimization problems, the original SR problem is divided into two subproblems: 1) inversion subproblem and 2) denoising subproblem. Since the inversion subproblem can be regarded as an inversion step to reconstruct an intermediate HR image with sharper edges and finer structures, we propose to use deep CNN to capture low-level explicit image profile enhancement prior (PEP). Since the denoising subproblem aims to remove the noise in the intermediate image, we adopt a simple and effective denoising network to learn implicit image denoising statistics prior (DSP). Furthermore, the penalty parameter in SBI is adaptively tuned during the iterations for better performance. Finally, we also prove the convergence of our method. Thus, the deep CNNs are exploited to capture both implicit and explicit image statistics priors. Due to SBI, the SR observation model is also leveraged. Consequently, it bridges between two popular SR approaches: 1) learning-based method and 2) reconstruction-based method. Experimental results show that the proposed method achieves the state-of-the-art SR results.","","","10.1109/TCYB.2019.2933257","National Natural Science Foundation of China; National Post Doctoral Program for Innovative Talents of China; Post Doctoral Research and Development Foundation of Sichuan University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8809912","Deep convolutional neural networks (CNNs);denoising statistics prior (DSP);profile enhancement prior (PEP);split Bregman iteration (SBI);super-resolution (SR)","Image reconstruction;Noise reduction;Optimization;Image edge detection;Image resolution;Degradation;Image restoration","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Differentiable Random Forests for Age Estimation","W. Shen; Y. Guo; Y. Wang; K. Zhao; B. Wang; A. L. Yuille","Department of Computer Science, Johns Hopkins University, 1466 Baltimore, Maryland United States (e-mail: shenwei1231@gmail.com); School of Communications and Information Engineering, Shanghai University, 34747 Shanghai, Shanghai China (e-mail: gyl.luan0@gmail.com); Department of Computer Science, Johns Hopkins University, 1466 Baltimore, Maryland United States (e-mail: wyanny.9@gmail.com); College of Computer and Control Engineering, Nankai University, 12538 Tianjin, Tianjin China (e-mail: zhaok1206@gmail.com); Department of Medical Biophysics, University of Toronto, 7938 Toronto, Ontario Canada (e-mail: bowang87@stanford.edu); Department of Computer Science, Johns Hopkins University, 1466 Baltimore, Maryland United States (e-mail: alan.l.yuille@gmail.com)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Age estimation from facial images is typically cast as a label distribution learning or regression problem, since aging is a gradual progress. Its main challenge is the facial feature space w.r.t. ages is inhomogeneous, due to the large variation in facial appearance across different persons of the same age and the non-stationary property of aging. In this paper, we propose two Deep Differentiable Random Forests methods, Deep Label Distribution Learning Forest (DLDLF) and Deep Regression Forest (DRF), for age estimation. Both of them connect split nodes to the top layer of convolutional neural networks (CNNs) and deal with inhomogeneous data by jointly learning input-dependent data partitions at the split nodes and age distributions at the leaf nodes. This joint learning follows an alternating strategy: (1) Fixing the leaf nodes and optimizing the split nodes and the CNN parameters by Back-propagation; (2) Fixing the split nodes and optimizing the leaf nodes by Variational Bounding. Two Deterministic Annealing processes are introduced into the learning of the split and leaf nodes, respectively, to avoid poor local optima and obtain better estimates of tree parameters free of initial values. Experimental results show that DLDLF and DRF achieve state-of-the-art results on three age estimation datasets.","","","10.1109/TPAMI.2019.2937294","ONR; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812930","Age estimation;random forest;regression;label distribution learning;deterministic annealing","Vegetation;Estimation;Forestry;Nonhomogeneous media;Aging;Facial features","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Direct Cup-to-Disc Ratio Estimation for Glaucoma Screening via Semi-supervised Learning","R. Zhao; X. Chen; L. Xiyao; C. Zailiang; F. Guo; S. Li","School of Computer Science and Engineering, Central South University, 12570 Changsha, Hunan China (e-mail: byrons.zhao@gmail.com); School of Computer Science and Engineering, Central South University, 12570 Changsha, Hunan China (e-mail: 1710353485@qq.com); School of Computer Science and Engineering, Central South University, 12570 Changsha, Hunan China (e-mail: lxyzoewx@csu.edu.cn); School of Computer Science and Engineering, Central South University, 12570 Changsha, Hunan China (e-mail: czlchen@qq.com); Central South University, 12570 Changsha, Hunan China (e-mail: fanguo@csu.edu.cn); Medical Imaging, Western University, London, Ontario Canada (e-mail: slishuo@gmail.com)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","Glaucoma is chronic eye disease that leads to irreversible vision loss. The Cup-to-Disc Ratio (CDR) serves as the most important indicator for glaucoma screening and plays an significant role in clinical screening and early diagnosis of glaucoma. In general, obtaining CDR is subjected to measuring on manually or automatically segmented optic disc and cup. Despite great efforts have been devoted, obtaining CDR values automatically with high accuracy and robustness is still a great challenge due to the heavy overlap between optic cup and neuroretinal rim regions. In this paper, a direct CDR estimation method is proposed based on the well-designed semi-supervised learning scheme, in which CDR estimation is formulated as a general regression problem while optic disc/cup segmentation is cancelled. The method directly regresses CDR value based on the feature representation of optic nerve head via deep learning technique while bypassing intermediate segmentation. The scheme is a two-stage cascaded approach comprised of two phases: unsupervised feature representation of fundus image witha convolutional neural networks (MFPPNet) and CDR value regression by random forest regressor. The proposed scheme is validated on the challenging glaucoma dataset Direct-CSU and public ORIGA, and the experimental results demonstrate that our method can achieve a lower average CDR error of 0.0563 and a higher correlation of around 0.726 with measurement before manual segmentation of optic disc/cup by human experts. Our estimated CDR values are also tested for glaucoma screening, which achieves the areas under curve of 0.905 on dataset of 421 fundus images. The experiments show that the proposed method is capable of state-of-the-art CDR estimation and satisfactory glaucoma screening with calculated CDR value.","","","10.1109/JBHI.2019.2934477","China Scholarship Council; Primary Research and Developement Plan of Hunan Province; National Natural Science Foundation of China; National Key R and D Program of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8794624","Cup-to-disc ratio (CDR);representation learning;direct estimation;glaucoma screening;semi-supervised learning","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"HAR-Net: Joint Learning of Hybrid Attention for Single-stage Object Detection","Y. Li; S. Wang","Department of Electrical Engineering, Tsinghua University, Beijing, 100084 PRC.; Department of Electrical Engineering, Tsinghua University, Beijing, 100084 PRC.","IEEE Transactions on Image Processing","","2019","PP","99","1","1","Object detection has been a challenging task in computer vision. Although significant progress has been made in object detection with deep neural networks, the attention mechanism has yet to be fully developed. In this paper, we propose a hybrid attention mechanism for single-stage object detection. First, we present the modules of spatial attention, channel attention and aligned attention for single-stage object detection. In particular, dilated convolution layers with symmetrically fixed rates are stacked to learn spatial attention. A channel attention mechanism with the cross-level group normalization and squeeze-and-excitation operation is proposed. Aligned attention is constructed with organized deformable filters. Second, the three types of attention are unified to construct the hybrid attention mechanism. We then plug the hybrid attention into Retina-Net and propose the efficient single-stage HAR-Net for object detection. The attention modules and the proposed HAR-Net are evaluated on the COCO detection dataset. The experiments demonstrate that hybrid attention can significantly improve the detection accuracy and that the HAR-Net can achieve a state-of-the-art 45.8% mAP, thus outperforming existing single-stage object detectors.","","","10.1109/TIP.2019.2957850","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8931260","Object detection;deep neural networks;hybrid attention mechanism;single-stage detection;joint learning.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Adversarial Feature Sampling Learning for Efficient Visual Tracking","Y. Yin; D. Xu; X. Wang; L. Zhang","Research Center of Precision Sensing and Control, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China, also with the Department of Computing, The Hong Kong Polytechnic University, Hong Kong, and also with the School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing 100049, China.; Research Center of Precision Sensing and Control, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China, and also with the School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing 100049, China (e-mail: de.xu@ia.ac.cn).; Research Center of Precision Sensing and Control, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China, and also with the School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing 100049, China.; Department of Computing, The Hong Kong Polytechnic University, Hong Kong.","IEEE Transactions on Automation Science and Engineering","","2019","PP","99","1","11","The tracking-by-detection tracking framework usually consists of two stages: drawing samples around the target object and classifying each sample as either the target object or background. Current popular trackers under this framework typically draw many samples from the raw image and feed them into the deep neural networks, resulting in high computational burden and low tracking speed. In this article, we propose an adversarial feature sampling learning (AFSL) method to address this problem. A convolutional neural network is designed, which takes only one cropped image around the target object as input, and samples are collected from the feature maps with spatial bilinear resampling. To enrich the appearance variations of positive samples in the feature space, which has limited spatial resolution, we fuse the high-level features and low-level features to better describe the target by using a generative adversarial network. Extensive experiments on benchmark data sets demonstrate that the proposed ASFL achieves leading tracking accuracy while significantly accelerating the speed of tracking-by-detection trackers.","","","10.1109/TASE.2019.2948402","National Basic Research Program of China (973 Program); National Natural Science Foundation of China; Hong Kong Scholars Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8895806","Adversarial learning;deep convolution neural network;feature sampling;visual tracking.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"BMAN: Bidirectional Multi-scale Aggregation Networks for Abnormal Event Detection","S. Lee; H. G. Kim; Y. M. Ro","Image and Video Systems Lab., School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), 291 Daehak-ro, Yuseong-gu, Daejeon, 34141, Republic of Korea.; Image and Video Systems Lab., School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), 291 Daehak-ro, Yuseong-gu, Daejeon, 34141, Republic of Korea.; Image and Video Systems Lab., School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), 291 Daehak-ro, Yuseong-gu, Daejeon, 34141, Republic of Korea.","IEEE Transactions on Image Processing","","2019","PP","99","1","1","Abnormal event detection is an important task in video surveillance systems. In this paper, we propose a novel bidirectional multi-scale aggregation networks (BMAN) for abnormal event detection. The proposed BMAN learns spatiotemporal patterns of normal events to detect deviations from the learned normal patterns as abnormalities. The BMAN consists of two main parts: an inter-frame predictor and an appearancemotion joint detector. The inter-frame predictor is devised to encode normal patterns, which generates an inter-frame using bidirectional multi-scale aggregation based on attention. With the feature aggregation, robustness for object scale variations and complex motions is achieved in normal pattern encoding. Based on the encoded normal patterns, abnormal events are detected by the appearance-motion joint detector in which both appearance and motion characteristics of scenes are considered. Comprehensive experiments are performed, and the results show that the proposed method outperforms the existing state-of-the-art methods. The resulting abnormal event detection is interpretable on the visual basis of where the detected events occur. Further, we validate the effectiveness of the proposed network designs by conducting ablation study and feature visualization.","","","10.1109/TIP.2019.2948286","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8882515","Video analysis;abnormal event detection;normal pattern encoding;multi-scale","Event detection;Feature extraction;Encoding;Detectors;Task analysis;Heuristic algorithms;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Unsupervised Segmentation of Hyperspectral Images Using 3-D Convolutional Autoencoders","J. Nalepa; M. Myller; Y. Imai; K. Honda; T. Takeda; M. Antoniak","Silesian University of Technology, Gliwice, Poland, and also with KP Labs, Gliwice, Poland (e-mail: jnalepa@ieee.org).; Silesian University of Technology, Gliwice, Poland, and also with KP Labs, Gliwice, Poland.; Kokusai Kogyo, Company, Ltd., Tokyo 102-0085, Japan.; Kokusai Kogyo, Company, Ltd., Tokyo 102-0085, Japan.; Japan Space Systems, Tokyo 105-0011, Japan.; KP Labs, Gliwice, Poland.","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","Hyperspectral image analysis has become an important topic widely researched by the remote sensing community. Classification and segmentation of such imagery help understand the underlying materials within a scanned scene since hyperspectral images convey detailed information captured in a number of spectral bands. Although deep learning has established the state-of-the-art in the field, it still remains challenging to train well-generalizing models due to the lack of ground-truth data. In this letter, we tackle this problem and propose an end-to-end approach to segment hyperspectral images in a fully unsupervised way. We introduce a new deep architecture which couples 3-D convolutional autoencoders with clustering. Our multifaceted experimental study--performed over the benchmark and real-life data--revealed that our approach delivers high-quality segmentation without any prior class labels.","","","10.1109/LGRS.2019.2960945","European Space Agency HYPERNET; Polish National Centre for Research and Development; Silesian University of Technology Funds under The Rectors Habilitation; Hyperspectral Imager SUIte Public Research promoted by the Ministry of Economy Trade and Industry Japan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8948005","Autoencoder;clustering;deep learning;hyperspectral imaging (HSI);unsupervised segmentation.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Snapshot High Dynamic Range Imaging via Sparse Representations and Feature Learning","K. Fotiadou; G. Tsagkatakis; P. Tsakalides","Institute of Computer Science, Foundation for Research and Technology - Hellas (FORTH), Heraklion Greece GR-700 13 (e-mail: kfot@ics.forth.gr); Institute of Computer Science, Contact Info Foundation for Research and Technology - Hellas (FORTH), Heraklion, Greece Greece (e-mail: greg@ics.forth.gr); Institute of Computer Science, Foundation for Research and Technology - Hellas (FORTH), Heraklion Greece (e-mail: tsakalid@ics.forth.gr)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","Bracketed High Dynamic Range (HDR) imaging architectures acquire a sequence of Low Dynamic Range (LDR) images in order to either produce a HDR image or an “optimally” exposed LDR image, achieving impressive results under static camera and scene conditions. However, in real world conditions, ghost-like artifacts and noise effects limit the quality of HDR reconstruction. We address these limitations by introducing a post-acquisition snapshot HDR enhancement scheme that generates a bracketed sequence from a small set of LDR images, and in the extreme case, directly from a single exposure. We achieve this goal via a sparse-based approach where transformations between differently exposed images are encoded through a dictionary learning process, while we learn appropriate features by employing a stacked sparse autoencoder (SSAE) based framework. Via experiments with real images, we demonstrate the improved performance of our method over the state-of-the-art, while our single-shot based HDR formulation provides a novel paradigm for the enhancement of LDR imaging and video sequences.","","","10.1109/TMM.2019.2933333","DEDALE; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8788627","High Dynamic Range Imaging;Deep Learning;Sparse Stacked Autoencoders;Sparse Representations","Imaging;Dynamic range;Image reconstruction;Computer science;Streaming media;Lighting;Optimization","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Induced-Current Learning Method for Nonlinear Reconstructions in Electrical Impedance Tomography","Z. Wei; X. Chen","Department of Electrical and Computer Engineering, National University of Singapore, Singapore 117583.; Department of Electrical and Computer Engineering, National University of Singapore, Singapore 117583.","IEEE Transactions on Medical Imaging","","2019","PP","99","1","1","Electrical impedance tomography (EIT) is an attractive technique that aims to reconstruct the unknown electrical property in a domain from the surface electrical measurements. In this work, the induced-current learning method (ICLM) is proposed to solve nonlinear electrical impedance tomography (EIT) problems. Specifically, the cascaded end-to-end convolutional neural network (CEE-CNN) architecture is designed to implement the ICLM. The CEE-CNN greatly decreases the nonlinearities in EIT problems by designing a combined objective function and introducing multiple labels. A noticeable characteristic of the proposed CNN scheme is that the input parameters are chosen as both induced contrast current (ICC) and the updated electrical field from a spectral analysis and the output is chosen as ICC, which is fundamentally different from prevailing CNN schemes. Further, several skip connections are introduced to focus on learning only the unknown part of ICC. ICLM is verified with both numerical and experimental tests on typical EIT problems, and it is found that ICLM is able to solve typical EIT problems in less than 1 second with high image qualities. More importantly, it is also highly robust to measurement noises and modeling errors, such as inaccurate boundary data.","","","10.1109/TMI.2019.2948909","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8879500","Electrical impedance tomography;deep learning;convolutional neural network","Tomography;Conductivity;Mathematical model;Image reconstruction;Inverse problems;Pollution measurement;Electrodes","","","","","","","","","","IEEE","IEEE Early Access Articles"
"CHIP: Channel-Wise Disentangled Interpretation of Deep Convolutional Neural Networks","X. Cui; D. Wang; Z. J. Wang","Department of Electrical and Computer Engineering, The University of British Columbia, Vancouver, BC V6T 1Z4, Canada.; Department of Electrical and Computer Engineering, The University of British Columbia, Vancouver, BC V6T 1Z4, Canada (e-mail: danw@ece.ubc.ca).; Department of Electrical and Computer Engineering, The University of British Columbia, Vancouver, BC V6T 1Z4, Canada.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","14","With the increasing popularity of deep convolutional neural networks (DCNNs), in addition to achieving high accuracy, it becomes increasingly important to explain how DCNNs make their decisions. In this article, we propose a CHannel-wise disentangled InterPretation (CHIP) model for visual interpretations of DCNN predictions. The proposed model distills the class-discriminative importance of channels in DCNN by utilizing sparse regularization. We first introduce network perturbation to learn the CHIP model. The proposed model is capable to not only distill the global perspective knowledge from networks but also present class-discriminative visual interpretations for the predictions of networks. It is noteworthy that the CHIP model is able to interpret different layers of networks without retraining. By combining the distilled interpretation knowledge at different layers, we further propose the Refined CHIP visual interpretation that is both high-resolution and class-discriminative. Based on qualitative and quantitative experiments on different data sets and networks, the proposed model provides promising visual interpretations for network predictions in an image classification task compared with the existing visual interpretation methods. The proposed model also outperforms the related approaches in the ILSVRC 2015 weakly supervised localization task.","","","10.1109/TNNLS.2019.2952322","Natural Sciences and Engineering Research Council of Canada; Four Year Doctoral Fellowship; International Doctoral Fellowship at The University of British Columbia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8924894","Channel-wise disentanglement;model interpretability;network perturbation;visual interpretation.","Visualization;Logic gates;Predictive models;Data models;Knowledge engineering;Task analysis;Perturbation methods","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Unsupervised Deep Visual-Inertial Odometry with Online Error Correction for RGB-D Imagery","E. J. Shamwell; K. Lindgren; S. Leung; W. D. Nothwang","SEDD, US Army Research Laboratory, 1024 Adelphi, Maryland United States 20783-1197 (e-mail: jared.shamwell@gmail.com); Electrical and Computer Engineering, University of Washington, 7284 Seattle, Washington United States (e-mail: kyle509@uw.edu); SEDD, US Army Research Laboratory, 1024 Adelphi, Maryland United States (e-mail: sarah.c.leung@gmail.com); Human Research and Engineering Directorate, United States Army Research Laboratory, Aberdeen Proving Ground, Maryland United States (e-mail: william.d.nothwang.civ@mail.mil)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","While numerous deep approaches to the problem of vision-aided localization have been recently proposed, systems operating in the real world will undoubtedly experience novel sensory states previously unseen even under the most prodigious training regimens. We address the localization problem with online error correction (OEC) modules that are trained to correct a vision-aided localization network's mistakes. We demonstrate the generalizability of the OEC modules and describe our unsupervised deep neural network approach to the fusion of RGB-D imagery with inertial measurements for absolute trajectory estimation. Our network, dubbed the Visual-Inertial-Odometry Learner (VIOLearner), learns to perform visual-inertial odometry (VIO) without inertial measurement unit (IMU) intrinsic parameters or the extrinsic calibration between an IMU and camera. The network learns to integrate IMU measurements and generate hypothesis trajectories which are then corrected online according to the Jacobians of scaled image projection errors with respect to spatial grids of pixel coordinates. We evaluate our network against state-of-the-art (SoA) VIO, VO, and visual simultaneous localization and mapping (VSLAM) approaches on the KITTI Odometry dataset as well as a MAV dataset that we collected in the AirSim simulation environment. We demonstrate better than SoA translational localization performance against comparable SoA approaches on our evaluation sequences.","","","10.1109/TPAMI.2019.2909895","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8691513","","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Recomputation of dense layers for the performance improvement of DCNN","Y. Yang; J. Q. M. Wu; X. Feng; A. Thangarajah","Computer Science Department, Lakehead University, 7890 Thunder Bay, Ontario Canada (e-mail: yyang48@lakeheadu.ca); Electrical and Computer Engineering, University of Windsor, Windsor, Ontario Canada n9b 3p4 (e-mail: jwu@uwindsor.ca); ECE, Windsor, Ontario Canada (e-mail: xiexing.feng@uwindsor.ca); ECE, Windsor, Ontario Canada (e-mail: thangara@uwindsor.ca)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","radient descent optimization of learning has become a paradigm for training deep convolutional neural networks (DCNN). However, utilizing other learning strategies in the training process of the DCNN has rarely been explored by the deep learning (DL) community. This serves as the motivation to introduce a non-iterative learning strategy to retrain neurons at the top dense or fully connected (FC) layers of DCNN, resulting in, higher performance.radient descent optimization of learning has become a paradigm for training deep convolutional neural networks (DCNN). However, utilizing other learning strategies in the training process of the DCNN has rarely been explored by the deep learning (DL) community. This serves as the motivation to introduce a non-iterative learning strategy to retrain neurons at the top dense or fully connected (FC) layers of DCNN, resulting in, higher performance.G The proposed method exploits the Moore-Penrose Inverse to pull back the current residual error to each FC layer, generating well-generalized features. Further, the weights of each FC layers are recomputed according to the Moore-Penrose Inverse. We evaluate the proposed approach on six most widely accepted object recognition benchmark datasets: Scene- 15, CIFAR-10, CIFAR-100, SUN-397, Places365, and ImageNet. The experimental results show that the proposed method obtains improvements over 30 state-of-the-art methods. Interestingly, it also indicates that any DCNN with the proposed method can provide better performance than the same network with its original Backpropagation (BP)- based training.","","","10.1109/TPAMI.2019.2917685","Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8718406","","Training;Mathematical model;Optimization;Neurons;Convolutional neural networks;Deep learning","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"FFDNet-Based Channel Estimation for Massive MIMO Visible Light Communication Systems","Z. Gao; Y. Wang; X. Liu; F. Zhou; K. Wong","Nanchang University, China.; Nanchang University, China.; Wuhan University, China.; College of Electronic and Information Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing, 210000, P. R. China.; University College London, UK.","IEEE Wireless Communications Letters","","2019","PP","99","1","1","Channel estimation is of crucial importance in massive multiple-input multiple-output (m-MIMO) visible light communication (VLC) systems. In order to tackle this problem, a fast and flexible denoising convolutional neural network (FFDNet)-based channel estimation scheme for m-MIMO VLC systems was proposed. The channel matrix of the m-MIMO VLC channel is identified as a two-dimensional natural image since the channel has the characteristic of sparsity. A deep learning-enabled image denoising network FFDNet is exploited to learn from a large number of training data and to estimate the m-MIMO VLC channel. Simulation results demonstrate that our proposed channel estimation based on the FFDNet significantly outperforms the benchmark scheme based on minimum mean square error.","","","10.1109/LWC.2019.2954511","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8907449","Channel estimation;m-MIMO;visible light communication;FFDNet;deep learning.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Image Retargetability","F. Tang; W. Dong; Y. Meng; C. Ma; F. Wu; X. Li; T. Lee","National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Science, Beijing China (e-mail: tangfan2013@ia.ac.cn); National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Science, Beijing China (e-mail: weiming.dong@ia.ac.cn); Didi Research, Didi Chuxing, Beijing China (e-mail: mengyipingkitty@didichuxing.com); YLab, Kuaishou Technology, San Francisco United States (e-mail: chongyangm@gmail.com); Collaborative Innovation Center, Institute of Software, Chinese Academy of Sciences, Beijing China (e-mail: fuzhang@iscas.ac.cn); Department of Mathematics and Physics, North China Electric Power University, Beijing China (e-mail: szyclxr@163.com); Dept of Computer Science and Information Engineering, National Cheng-Kung University, Tainan Taiwan 701 (e-mail: tonylee@mail.ncku.edu.tw)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","Real-world applications could benefit from the ability to automatically retarget an image to different aspect ratios and resolutions while preserving its visually and semantically important content. However, not all images can be equally processed. This study introduces the notion of image retargetability to describe how well a particular image can be handled by content-aware image retargeting. We propose to learn a deep convolutional neural network to rank photo retargetability, in which the relative ranking of photo retargetability is directly modeled in the loss function. Our model incorporates the joint learning of meaningful photographic attributes and image content information, which can facilitate the regularization of the complicated retargetability rating problem. To train and analyze this model, we collect a database that contains retargetability scores and meaningful image attributes assigned by six expert raters. The experiments demonstrate that our unified model can generate retargetability rankings that are highly consistent with human labels. To further validate our model, we show the applications of image retargetability in retargeting method selection, retargeting method assessment, and generating a photo collage.","","","10.1109/TMM.2019.2932620","National Key R and D Program of China; Ministry of Science and Technology; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8784158","image retargetability;visual attributes;multitask learning;deep convolutional neural network","Visualization;Task analysis;Distortion;Measurement;Image resolution;Convolutional neural networks;Semantics","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Context-Interactive CNN for Person Re-Identification","W. Song; S. Li; T. Chang; A. Hao; Q. Zhao; H. Qin","State Key Laboratory of Virtual Reality Technology and Systems, Beihang University.; State Key Laboratory of Virtual Reality Technology and Systems, Beihang University and Peng Cheng Laboratory, Shenzhen, China.; State Key Laboratory of Virtual Reality Technology and Systems, Beihang University.; State Key Laboratory of Virtual Reality Technology and Systems, Beihang University.; State Key Laboratory of Virtual Reality Technology and Systems, Beihang University.; Stony Brook University.","IEEE Transactions on Image Processing","","2019","PP","99","1","1","Despite growing progresses in recent years, cross-scenario person re-identification remains challenging, mainly due to the pedestrians commonly surrounded by highly-complex environment contexts. In reality, the human perception mechanism could adaptively find proper contextualized spatial-temporal clues towards pedestrian recognition. However, conventional methods fall short in adaptively leveraging the long-term spatial-temporal information due to ever-increasing computational cost. Moreover, CNN-based deep learning methods are hard to conduct optimization due to the non-differentiable property of the built-in context search operation. To ameliorate, this paper proposes a novel Context-Interactive CNN (CI-CNN) to dynamically find both spatial and temporal contexts by embedding multi-task Reinforcement Learning (MTRL). The CI-CNN streamlines the multi-task reinforcement learning by using an actor-critic agent to capture the temporal-spatial context simultaneously, which comprises a context-policy network and a context-critic network. The former network learns policies to determine the optimal spatial context region and temporal sequence range. Based on the inferred temporal-spatial cues, the latter one focuses on the identification task and provides feedback for the policy network. Thus, CI-CNN can simultaneously zoom in/out the perception field in spatial and temporal domain for the context interaction with the environment. By fostering the collaborative interaction between the person and context, our method could achieve outstanding performance on various public benchmarks, which confirms the rationality of our hypothesis, and verifies the effectiveness of our CI-CNN framework.","","","10.1109/TIP.2019.2953587","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8907836","Person re-identification;Multi-task reinforcement learning;Context interaction;Actor-critic agent;Context-critic network","Task analysis;Reinforcement learning;Feature extraction;Videos;Cameras;Context modeling;Clutter","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep and Structure-Preserving Autoencoders for Clustering Data With Missing Information","S. J. Choudhury; N. R. Pal","Electronics and Communication Sciences Unit, Indian Statistical Institute, Kolkata 700108, India (e-mail: cshuvrajyoti@gmail.com).; Electronics and Communication Sciences Unit, Indian Statistical Institute, Kolkata 700108, India (e-mail: nikhil@isical.ac.in).","IEEE Transactions on Emerging Topics in Computational Intelligence","","2019","PP","99","1","12","Most real-life data suffer from missing values. Here we deal with the problem of exploratory analysis, via clustering, of data with missing values. For this we need an effective mechanism to deal with missing features so that all available information can be used for clustering. We propose two autoencoder-based methods for handling of missing data for clustering. The autoencoder is trained in a two-phase scheme using only part of the given data set which does not have any incomplete instances in such a manner that the autoencoder is better equipped to deal with incomplete data. To cluster the entire data set which has instances with missing values, we generate the latent space representation of the all instances, with or without, missing information. Before the incomplete instances are submitted to the autoencoder, the missing inputs are filled in by a $k-$nearest neighbor-based rule. The clustering is then done in the latent space using the fuzzy-c-means (FCM) algorithm. In the second method, to preserve the “structure” of the input data in the latent space we extend our method by adding Sammon’s stress as a regularizer to the objective function of the autoencoder. We test the effectiveness of the proposed algorithms on several data sets and compare the results with five state-of-the-art techniques. For comparison, we use two performance indicators: Normalized Mutual Information (NMI) and Adjusted Rand index (ARI).","","","10.1109/TETCI.2019.2949264","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8910612","Clustering;fuzzy-c-means;latent space representation;missing data;neural networks;deep network;Sammon’s stress","Clustering algorithms;Linear programming;Training;Machine learning;Stress;Neural networks;Feature extraction","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Multi-task Transfer Network for Cross Domain Person Re-identification","H. Wang; J. Hu","School of Computer Science and Technology, Baoji University of Arts and Sciences, Baoji 721016, China.; School of Electronic and Electrical Engineering, Baoji University of Arts and Sciences, Baoji 721016, China.","IEEE Access","","2019","PP","99","1","1","As a prominent application of surveillance video analysis, person re-identification attracts much more research attention recently. Existing person re-identification models often focus on supervision by the pedestrian identity annotation, while it has limited scalability in realistic. Though several unsupervised person re-identification researches pay attention to solve this problem, they are either clustering based or cross domain based approaches, where a conventional assumption of them is the identity number of the target dataset is acknowledged. To relax this hypothesis, we propose a Deep Multi-task Transfer Network (DMTNet) for cross domain person re-identification, which conduct classification, attribute attention and identification task between source and target domains. There are three main novelties in DMTNet, including clustering number estimating algorithm to learn prior knowledge from source data to estimate the identity number, attribute attention importance learning rather than directly utilizing attribute information, and a multi-task transfer learning mechanism to transfer specific tasks cross domains. To prove the superiority of our DMTNet, we implement several compared experiments on DukeMTMC-reID and Market-1501 datasets, which results show the advancement of our network. Moreover, the discussions for different modules also point out the significance of the specific tasks.","","","10.1109/ACCESS.2019.2962581","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8943405","Cross Domain Person re-identification;Multi-task Transfer;Attribute Attention;Identity Number Estimating","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Multilabel Deep Visual-Semantic Embedding","M. Yeh; Y. Li","Computer Science and Information Engineering, National Taiwan Normal University, Taipei, N/A Taiwan (e-mail: myeh@csie.ntnu.edu.tw); Computer Science and Information Engineering, National Taiwan Normal University, Taipei, N/A Taiwan (e-mail: eric11519@gmail.com)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Inspired by the great success from deep convolutional neural networks (CNNs) for single-label visual-semantic embedding, we exploit extending these models for multilabel images. We propose a new learning paradigm for multilabel image classification, in which labels are ranked according to its relevance to the input image. In contrast to conventional CNN models that learn a latent vector representation (i.e. the image embedding vector), the developed visual model learns a mapping (i.e. a transformation matrix) from an image in an attempt to differentiate between its relevant and irrelevant labels. Despite the conceptual simplicity of our approach, the proposed model achieves state-of-the-art results on three public benchmark datasets.","","","10.1109/TPAMI.2019.2911065","Ministry of Science and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8691414","Multilabel classification;visual semantic embedding;convolutional neural networks","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Improved Deep Hashing with Soft Pairwise Similarity for Multi-label Image Retrieval","Z. Zhang; Q. Zou; Y. Lin; L. Chen; S. Wang","Computer Science, Wuhan University, Wuhan, Hubei China (e-mail: zhengzhang@whu.edu.cn); Computer Science, Wuhan University, 12390 Wuhan China 430072 (e-mail: qzou@whu.edu.cn); Computational Science Initiative, Brookhaven National Laboratory, 8099 Upton, New York United States (e-mail: ywlin.cq@gmail.com); Data and Computer Science, Sun Yat-sen University, GuangZhou China (e-mail: chenl46@mail.sysu.edu.cn); Computer Science and Engineering, University of South Carolina, 2629 Columbia, South Carolina United States (e-mail: songwang@cec.sc.edu)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","Hash coding has been widely used in the approximate nearest neighbor search for large-scale image retrieval. Recently, many deep hashing methods have been proposed and shown largely improved performance over traditional feature-learning methods. Most of these methods examine the pairwise similarity on the semantic-level labels, where the pairwise similarity is generally defined in a hard-assignment way. That is, the pairwise similarity is ‘1’ if they share no less than one class label and ‘0’ if they do not share any. However, such similarity definition cannot reflect the similarity ranking for pairwise images that hold multiple labels. In this paper, an improved deep hashing method is proposed to enhance the ability of multi-label image retrieval. We introduce a pairwise quantified similarity calculated on the normalized semantic labels. Based on this, we divide the pairwise similarity into two situations -- ‘hard similarity’ and ‘soft similarity’, where cross-entropy loss and mean square error loss are adapted respectively for more robust feature learning and hash coding. Experiments on three popular datasets demonstrate that, the proposed method outperforms the competing methods and achieves the state-of-the-art performance in multi-label image retrieval.","","","10.1109/TMM.2019.2929957","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8782545","image retrieval;convolutional neural network;semantic label;pairwise similarity;deep hashing","Image retrieval;Semantics;Hash functions;Binary codes;Computer science;Neural networks;Kernel","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"A Deep Non-negative Matrix Factorization Approach via Autoencoder for Nonlinear Fault Detection","Z. Ren; W. Zhang; Z. Zhang","Institute of Automation Chinese Academy of Sciences, 74522 Beijing, Beijing China 100190 (e-mail: rzl8816@126.com); Institute of Automation Chinese Academy of Sciences, 74522 Beijing, Beijing China 100190 (e-mail: zhangwenshengia@hotmail.com); Institute of Automation Chinese Academy of Sciences, 74522 Beijing, Beijing China 100190 (e-mail: zhangzhizhong2014@ia.ac.cn)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","In the era of big data, data-driven fault detection is vital for modern industrial systems. This paper considers the potential complexity of fault detection and proposes a novel nonlinear method based on non-negative matrix factorization (NMF). Motived by autoencoder, we first utilize the input data to learn an appropriate nonlinear mapping function, which transforms the original space into a high-dimension feature space. Then according to the decomposition rule of NMF, we divide the learned feature space into two subspaces, and two statistics in these subspaces are designed appropriately for nonlinear fault detection. The established method, deep non-negative matrix factorization (DNMF) is implemented by three parts: an encoder module, an NMF module and a decoder module. Unlike conventional NMF-based nonlinear methods using implicit and predetermined kernels, DNMF provides a new nonlinear scheme applied to NMF via deep autoencoder framework and realizes nonlinear mapping for input data automatically. Our proposed nonlinear framework can be further generalized to other linear methods. Besides, DNMF greatly expands the NMF application scope by breaking through the limitation of non-negative input. The Tennessee Eastman (TE) process as an industrial benchmark is employed to verify the effectiveness of the proposed method.","","","10.1109/TII.2019.2951011","Natural Science Foundation of Beijing Municipality; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8889711","Data-driven fault detection;deep autoencoder;24 nonlinear industrial process;non-negative matrix factorization 25 (NMF)","Kernel;Fault detection;Feature extraction;Matrix decomposition;Neural networks;Informatics","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Prediction of Cloud Resources Demand Based on Hierarchical Pythagorean Fuzzy Deep Neural Network","D. Chen; X. Zhang; L. L. Wang; Z. Han","Department of Electrical and Computer Engineering, University of Houston, Houston, Texas United States (e-mail: dchen22@uh.edu); Tianjin University of Commerce, 12607 Tianjin, Tianjin China (e-mail: zhangxiaoqin@tjcu.edu.cn); School of Electronic Engineering, Beijing University of Posts and Telecommunications, Beijing, Beijing China 100088 (e-mail: liwang@bupt.edu.cn); ECE, University of Houston, Houston, Texas United States (e-mail: zhan2@uh.edu)","IEEE Transactions on Services Computing","","2019","PP","99","1","1","Having stepped into the era of information explosion, storing, processing and analyzing the vast data sometimes are quite intractable problems. However, it is impossible for personal computer or devices to tackle with such heavy workloads. Then, companies that provides cloud computational services come into business. Aiming at minimizing the expenditures, the most important part is how many cloud services the customers should reserve in advance because different amounts they consume will yield different expense. The emerging machine learning method provides a powerful tool to address such a prediction problem. In this paper, we propose a hierarchical Pythagorean fuzzy deep neural network to forecast the quantity of requisite cloud services. Besides the employment of fuzzy logic, the neural representation is also utilized as a complementary method. The knowledge acquired from fuzzy and neural perspectives are coalesced as the final transformed data to be put into the learning systems. Based on the anticipation of the deep neural network, the consumers are able to decide the amount of cloud services to purchase. Numerical results based on the real data set from Carnegie Mellon University demonstrate that the proposed model yields the economical predictions and outperforms the prediction by the traditional neural network.","","","10.1109/TSC.2019.2906901","Beijing Science and Technology Nova Program; Fundamental Research Funds for the Central Universities; US MURI; NSF; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8673603","Cloud services;fog computing;hierarchical deep neural network;Pythagorean fuzzy number;neural representation","Cloud computing;Companies;Edge computing;Pricing;Neural networks;Computational modeling;Data models","","","","","","","","","","IEEE","IEEE Early Access Articles"
"DCNN-based Multi-signal Induction Motor Fault Diagnosis","S. Shao; R. Yan; Y. Lu; P. Wang; R. Gao","School of Instrument Science and Engineering, Southeast University, Nanjing, 210096, China.; School of Instrument Science and Engineering, Southeast University, Nanjing, 210096, China and School of Mechanical Engineering, Xi’an Jiaotong University, Xi’an, Shaanxi 710049, China.; Department of Statistics, University of California, Irvine, CA, 92697-3435, USA.; Department of Mechanical and Aerospace Engineering, Case Western Reserve University, Cleveland, OH 44106 USA.; Department of Mechanical and Aerospace Engineering, Case Western Reserve University, Cleveland, OH 44106 USA.","IEEE Transactions on Instrumentation and Measurement","","2019","PP","99","1","1","Deep learning architecture, which exploits multiple hidden layers to learn hierarchical representations automatically from massive input data, presents a promising tool for characterizing fault conditions. This paper proposes a deep learning-based multi-signal fault diagnosis method that leverages the powerful feature learning ability of convolutional neural network (CNN) in images. The proposed deep model is able to learn from multiple types of sensor signals simultaneously so that it can achieve robust performance and finally realize accurate induction motor fault recognition. Firstly, the acquired sensor signals are converted to time-frequency distribution (TFD) by wavelet transform. Then a deep convolutional neural network is applied to learning discriminative representations from the TFD images. After that, a fully connected layer in deep architecture gives prediction of induction motor condition based on learned features. In order to verify the effectiveness of the designed deep model, experiments are carried out on a machine fault simulator where both vibration and current signals are analyzed. Experiment results indicate that the proposed method outperforms traditional fault diagnosis methods, hence demonstrating effectiveness in induction motor application. Compared with conventional methods that rely on delicate features extracted by experienced experts, the proposed deep model is able to automatically learn and select suitable features that contribute to accurate fault diagnosis. Compared with single-signal input, the multi-signal model has more accurate and stable performance and overcomes the overfitting problem to some degree.","","","10.1109/TIM.2019.2925247","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8751989","fault diagnosis;deep learning;convolutional neural network;multi-signal model;induction motor","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"PixelRL: Fully Convolutional Network With Reinforcement Learning for Image Processing","R. Furuta; N. Inoue; T. Yamasaki","Department of Information and Computer Technology, Tokyo University of Science, 26413 Katsushika-ku, Tokyo Japan (e-mail: rfuruta@rs.tus.ac.jp); Department of Information and Communication Engineering, The University of Tokyo, 13143 Bunkyo-ku, Tokyo Japan (e-mail: inoue@hal.t.u-tokyo.ac.jp); Department of Information and Communication Engineering, The University of Tokyo, 13143 Bunkyo-ku, Tokyo Japan (e-mail: yamasaki@hal.t.u-tokyo.ac.jp)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","This paper tackles a new problem setting: reinforcement learning with pixel-wise rewards (pixelRL) for image processing. After the introduction of the deep Q-network, deep RL has been achieving great success. However, the applications of deep RL for image processing are still limited. Therefore, we extend deep RL to pixelRL for various image processing applications. In pixelRL, each pixel has an agent, and the agent changes the pixel value by taking an action. We also propose an effective learning method for pixelRL that significantly improves the performance by considering not only the future states of the own pixel but also those of the neighbor pixels. The proposed method can be applied to some image processing tasks that require pixel-wise manipulations, where deep RL has never been applied. Besides, it is possible to visualize what kind of operation is employed for each pixel at each iteration, which would help us understand why and how such an operation is chosen. We also believe that our technology can enhance the explainability and interpretability of the deep neural networks. In addition, because the operations executed at each pixels are visualized, we can change or modify the operations if necessary. We apply the proposed method to a variety of image processing tasks: image denoising, image restoration, local color enhancement, and saliency-driven image editing. Our experimental results demonstrate that the proposed method achieves comparable or better performance, compared with the state-of-the- art methods based on supervised learning. The source code is available on https://github.com/rfuruta/pixelRL.","","","10.1109/TMM.2019.2960636","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8936404","Reinforcement learning;image processing;denoising;restoration;local color enhancement;saliency-driven image editing","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Neural Network-based Impacts Analysis of Multimodal Factors on Heat Demand Prediction","Z. Ma; J. Xie; H. Li; Q. Sun; F. Wallin; Z. Si; J. Guo","Pattern Recognition and Intelligent Systems Lab., Beijing University of Posts and Telecommunications, Beijing, Beijing China (e-mail: mazhanyu@bupt.edu.cn); Pattern Recognition and Intelligent Systems Lab., Beijing University of Posts and Telecommunications, 12472 Beijing, Beijing China (e-mail: xiejiyang2013@bupt.edu.cn); Malardalen University, Vasteras, Vasteras Sweden (e-mail: hailong.li@mdh.se); Shandong University, 12589 Jinan, Shandong China (e-mail: qie@sdu.edu.cn); Malardalen University, Vasteras, Vasteras Sweden (e-mail: fredrik.wallin@mdh.se); Beijing University of Posts and Telecommunications, 12472 Beijing, Beijing China (e-mail: sizhongwei@bupt.edu.cn); Beijing University of Posts and Telecommunications, 12472 Beijing, Beijing China (e-mail: guoju@butp.edu.cn)","IEEE Transactions on Big Data","","2019","PP","99","1","1","Prediction of heat demand using artificial neural networks has attracted enormous research attention. Weather conditions, such as direct solar irradiance and wind speed, have been identified as key parameters affecting heat demand. This paper employs an Elman neural network to investigate the impacts of direct solar irradiance and wind speed on the heat demand from the perspective of the entire district heating network. Results of the overall mean absolute percentage error (MAPE) show that direct solar irradiance and wind speed have quite similar impacts. However, the involvement of direct solar irradiance can clearly reduce the maximum absolute deviation when only involving direct solar irradiance and wind speed, respectively. In addition, the simultaneous involvement of both wind speed and direct solar irradiance does not show an obvious improvement of MAPE. Moreover, the prediction accuracy can also be affected by other factors like data discontinuity and outliers.","","","10.1109/TBDATA.2019.2907127","Natural Science Foundation of Shandong Province; National Natural Science Foundation of China; Energimyndigheten and Energiforsk AB; BUPT Excellent Ph.D. Students Foundation; Beijing Nova Program Interdisciplinary Cooperation Project; Beijing Nova Program; Fundamental Research Funds of Shandong University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8675486","District heating;deep learning;Elman neural network;heat demand;direct solar irradiance;wind speed","Wind speed;Solar heating;Neural networks;Predictive models;Bibliometrics;Big Data","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Memristive Quantized Neural Networks: A Novel Approach to Accelerate Deep Learning On-Chip","Y. Zhang; M. Cui; L. Shen; Z. Zeng","Computer Vision Institute, School of Computer Science and Software Engineering, National Engineering Laboratory for Big Data System Computing Technology, Guangdong Key Laboratory of Intelligent Information Processing, Shenzhen University, Shenzhen 518060, China, and also with the Department of Electrical and Computer Engineering, University of Massachusetts, Amherst, MA 01003 USA.; School of Computer Science, University of Nottingham, Ningbo 315100, China.; Computer Vision Institute, School of Computer Science and Software Engineering, National Engineering Laboratory for Big Data System Computing Technology, Shenzhen University, Shenzhen 518060, China, and also with the Guangdong Key Laboratory of Intelligent Information Processing, Shenzhen University, Shenzhen 518060, China (e-mail: llshen@szu.edu.cn).; School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan 430074, China, and also with the Key Laboratory of Image Processing and Intelligent Control of Education Ministry of China, Huazhong University of Science and Technology, Wuhan 430074, China.","IEEE Transactions on Cybernetics","","2019","PP","99","1","13","Existing deep neural networks (DNNs) are computationally expensive and memory intensive, which hinder their further deployment in novel nanoscale devices and applications with lower memory resources or strict latency requirements. In this paper, a novel approach to accelerate on-chip learning systems using memristive quantized neural networks (M-QNNs) is presented. A real problem of multilevel memristive synaptic weights due to device-to-device (D2D) and cycle-to-cycle (C2C) variations is considered. Different levels of Gaussian noise are added to the memristive model during each adjustment. Another method of using memristors with binary states to build M-QNNs is presented, which suffers from fewer D2D and C2C variations compared with using multilevel memristors. Furthermore, methods of solving the sneak path issues in the memristive crossbar arrays are proposed. The M-QNN approach is evaluated on two image classification datasets, that is, ten-digit number and handwritten images of mixed National Institute of Standards and Technology (MNIST). In addition, input images with different levels of zero-mean Gaussian noise are tested to verify the robustness of the proposed method. Another highlight of the proposed method is that it can significantly reduce computational time and memory during the process of image recognition.","","","10.1109/TCYB.2019.2912205","National Natural Science Foundation of China; Science and Technology Project of Guangdong Province; National Key Research and Development Program of China; Foundation for Innovative Research Groups of Hubei Province of China; China Post Doctoral Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8705375","Acceleration;crossbar array;image processing;image recognition;memristor;quantized convolutional neural networks (CNNs)","Memristors;Neural networks;Acceleration;System-on-chip;Training;Memory management;Device-to-device communication","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Impact of Memory Voltage Scaling on Accuracy and Resilience of Deep Learning Based Edge Devices","B. W. Denkinger; F. Ponzina; S. S. Basu; A. Bonetti; S. Balási; M. Ruggiero; M. Peón-Quirós; D. Rossi; A. Burg; D. Atienza","Embedded Systems Lab (ESL), EPFL, Lausanne, Switzerland.; Embedded Systems Lab (ESL), EPFL, Lausanne, Switzerland.; Embedded Systems Lab (ESL), EPFL, Lausanne, Switzerland.; Telecommunications Circuits Laboratory (TCL), EPFL, Lausanne, Switzerland.; Nespresso, Romont, Switzerland.; Nespresso, Romont, Switzerland.; Embedded Systems Lab (ESL), EPFL, Lausanne, Switzerland.; Integrated Systems Laboratory, ETH Zürich, Switzerland, and also with the Department of Electrical, Electronic, and Information Engineering, University of Bologna, Italy.; Telecommunications Circuits Laboratory (TCL), EPFL, Lausanne, Switzerland.; Embedded Systems Lab (ESL), EPFL, Lausanne, Switzerland.","IEEE Design & Test","","2019","PP","99","1","1","Energy consumption is a significant obstacle to integrate deep learning into edge devices. Two common techniques to curve it are quantization, which reduces the size of the memories (static energy) and the number of accesses (dynamic energy), and voltage scaling. However, static random access memories (SRAMs) are prone to failures when operating at sub-nominal voltages, hence potentially introducing errors in computations. In this paper we first analyze the resilience of artificial intelligence (AI) based methods for edge devices—in particular convolutional neural networks (CNNs)—to SRAM errors when operating at reduced voltages. Then, we compare the relative energy savings introduced by quantization and voltage scaling, both separately and together. Our experiments with an industrial use case confirm that CNNs are quite resilient to bit errors in the model, particularly for fixed-point implementations (5:7 accuracy loss with an error rate of 0:0065 errors per bit). Quantization alone can lead to savings of up to 61:3% in the dynamic energy consumption of the memory subsystem, with an additional reduction of up to 11:0% introduced by voltage scaling; all at the price of a 13:6% loss in accuracy.","","","10.1109/MDAT.2019.2947282","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8868100","Fault-tolerance;neural nets;energy-aware;yield analysis","Random access memory;Resilience;Quantization (signal);Memory management;Sociology;Statistics;Energy consumption","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Towards Energy-Quality Scaling in Deep Neural Networks","J. Anderson; Y. Alkabani; T. El-Ghazawi","George Washington University Washington, D.C.; George Washington University Washington, D.C.; George Washington University Washington, D.C.","IEEE Design & Test","","2019","PP","99","1","1","We survey the latest advances in neural network architectures by applying them to the task of energy-quality scaling. Results show that, while coarse scaling is possible with existing neural network architectures, fine-grain scaling is needed for fog computing efforts and further work should focus on hybrid NN architecture development. Advances in this area requires the development of novel architectures designed for energy-quality scaling and novel modeling and training methods.","","","10.1109/MDAT.2019.2952328","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8894043","deep learning;energy-quality scaling;neural networks","Artificial neural networks;Computer architecture;Hardware;Training;Dynamic range;Biological neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep UL2DL: Data-Driven Channel Knowledge Transfer from Uplink to Downlink","M. S. Safari; V. Pourahmadi; S. Sodagari","Electrical Engineering Department, Amirkabir University of Technology, Tehran, Iran, (email: msadeghsafari, v.pourahmadi@aut.ac.ir); Electrical Engineering Department, Amirkabir University of Technology, Tehran, Iran, (email: msadeghsafari, v.pourahmadi@aut.ac.ir); Electrical Engineering Department, Amirkabir University of Technology, Tehran, Iran, (email: msadeghsafari, v.pourahmadi@aut.ac.ir)","IEEE Open Journal of Vehicular Technology","","2019","PP","99","1","1","To remove the need for signaling overhead of feedback channels for transmitter channel state information (CSI) in Frequency Division Duplexing (FDD), we propose using convolutional neural networks and generative adversarial networks (GANs) to infer the downlink (DL) CSI by observing the uplink (UL) CSI. Our data-driven scheme exploits the fact that both DL and UL channels share the same propagation environment. As such, we extracted the environment information from UL channel response to a latent domain and then transferred the derived environment information from the latent domain to predict the DL channel. To prevent incorrect latent domain and the problem of oversimplistic assumptions, we did not use any specific parametric model and, instead, used data-driven approaches to discover the underlying structure of data without any prior model assumptions. To overcome the challenge of capturing the UL-DL joint distribution, we used a mean square error-based variant of the GAN structure with improved convergence properties called boundary equilibrium GAN. For training and testing we used simulated data of Extended Vehicular-A (EVA) and Extended Typical Urban (ETU) models. Simulation results verified that our methods can accurately infer and predict the downlink CSI from the uplink CSI for different multipath environments","","","10.1109/OJVT.2019.2962631","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8944056","Channel Prediction;Convolutional Neural Networks;Deep Learning;Downlink;FDD Systems;Generative Adversarial Networks;Uplink","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Power Allocation in Cache-Aided NOMA Systems: Optimization and Deep Reinforcement Learning Approaches","K. N. Doan; M. Vaezi; W. Shin; H. V. Poor; H. Shin; T. Q. S. Quek","Singapore University of Technology and Design, Singapore.; Department of Electrical and Computer Engineering, Villanova University, Villanova, PA, USA.; Department of Electronics Engineering, Pusan National University, Busan, South Korea and also with Department of Electrical Engineering, Princeton University, Princeton, NJ, USA.; Department of Electrical Engineering, Princeton University, Princeton, NJ, USA.; Department of Electronics and Radio Engineering, Kyung Hee University, Yongin-si, Gyeonggi-do, Korea.; Singapore University of Technology and Design, Singapore 487372, and also with the Department of Electronic Engineering, Kyung Hee University, Yongin 17104, South Korea.","IEEE Transactions on Communications","","2019","PP","99","1","1","This work exploits the advantages of two prominent techniques in future communication networks, namely caching and non-orthogonal multiple access (NOMA). Particularly, a system with Rayleigh fading channels and cache-enabled users is analyzed. It is shown that the caching-NOMA combination provides a new opportunity of cache hit which enhances the cache utility as well as the effectiveness of NOMA. Importantly, this comes without requiring users’ collaboration, and thus, avoids many complicated issues such as users’ privacy and security, selfishness, etc. In order to optimize users’ quality of service and, concurrently, ensure the fairness among users, the probability that all users can decode the desired signals is maximized. In NOMA, a combination of multiple messages are sent to users, and the defined objective is approached by finding an appropriate power allocation for message signals. To address the power allocation problem, two novel methods are proposed. The first one is a divide-and-conquer-based method for which closed-form expressions for the optimal resource allocation policy are derived making this method simple and flexible to the system context. The second one is based on deep reinforcement learning method that allows all users to share the full bandwidth. Finally, simulation results are provided to demonstrate the effectiveness of the proposed methods and to compare their performance.","","","10.1109/TCOMM.2019.2947418","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8869815","","Resource management;NOMA;Interference;Bandwidth;Signal to noise ratio;Silicon carbide;Quality of service","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A dual-modal attention-enhanced deep learning network for quantification of Parkinson’s disease characteristics","Y. Xia; Z. Yao; Q. Ye; N. Cheng","Key Laboratory of Intelligent Computing and Signal Processing of Ministry of Education, School of Electrical Engineering and Automation, Anhui University, Hefei 230601, China.; Institute of Intelligent Machines, Chinese Academy of Sciences, Hefei 230031, China.; Department of sport and health science, Nanjing Sport Institute, Nanjing 210014, China.; Hospital Affiliated to Anhui Chinese Medical University, Hefei 230061, China.","IEEE Transactions on Neural Systems and Rehabilitation Engineering","","2019","PP","99","1","1","It is well known that most patients with Parkinson’s disease (PD) have different degree of movement disorders, such as shuffling, festination and akinetic episodes, which could degenerate the life quality of PD patients. Therefore, it is very useful to develop a computerized tool to provide an objective evaluation of PD patients’ gait. In this study, we implemented a novel gait evaluating approach to provide not only a binary classification of PD gaits and normal walking, but also a quantification of the PD gaits to relate them to the PD severity level. The proposed system is a dual-modal deep-learning-based model, where left and right gait is modeled separately by a convolutional neural network (CNN) followed by an attention-enhanced long short-term memory (LSTM) network. The left and right samples for model training and testing were segmented sequentially from multiple 1D vertical ground reaction force (VGRF) signals according to the detected gait cycle. Experimental results indicate that our model can provide state-of-the-art performance in terms of classification accuracy. It is expected that the proposed model can be a useful gait assistance to provide a quantitative evaluation of PD gaits with high confidence and accuracy if trained suitably.","","","10.1109/TNSRE.2019.2946194","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8862940","Parkinson’s disease (PD);Attention mechanism;Classification;Long Short-Term Memory (LSTM);Vertical Ground Reaction Force (VGRF)","Diseases;Foot;Force;Legged locomotion;Sensors;Feature extraction;Neurons","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Electric Load Forecasting Model using a Multi-Column Deep Neural Networks","A. O. Hoori; A. Al Kazzaz; R. Khimani; Y. Motai; A. J. Aved","School of Engineering, Virginia Commonwealth University, Richmond, Virginia United States (e-mail: hooriao@vcu.edu); School of Engineering, Virginia Commonwealth University, Richmond, Virginia United States (e-mail: alkazzazaz@vcu.edu); School of Engineering, Virginia Commonwealth University, Richmond, Virginia United States (e-mail: khimanir@vcu.edu); School of Engineering, Virginia Commonwealth University, Richmond, Virginia United States 23284-3068 (e-mail: ymotai@vcu.edu); REID, Air Force Research Laboratory, Rome, New York United States (e-mail: Alexander.Aved@us.af.mil)","IEEE Transactions on Industrial Electronics","","2019","PP","99","1","1","In this paper, a new approach to short term load forecasting (STLF) is proposed using a Multi-Column Radial Basis Function Neural Network (MCRN). The advantage of this new approach over similar models in speed and accuracy is also discussed, especially in regards to renewable generation forecasting. Because weather and seasonal effects have a direct impact not only on load demand but also on renewable energy production, it follows, that as the penetration rate of renewable DG increases, the grid will become even more sensitive to weather impacts in the long term. In our approach, we use a k-d tree algorithm to split our feature rich data set, into dense, specialized subsets. These subsets are then trained in parallel as multiple Artificial Neural Network (ANN) using a modified error correction (ErrCor) algorithm to form the MCRN. This approach reduces the number of hidden neurons, increases the speed of convergence, and improves generalization over similar, alternative forecasting methods.","","","10.1109/TIE.2019.2939988","Higher Committee of Education Development of Iraq; Air Force Research Laboratory; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8835054","Electric Forecasting;Deep Learning;Neural Network;Renewable Energy;Industrial Power System Planning","Load forecasting;Forecasting;Training;Load modeling;Predictive models;Meteorology;Biological neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Video Face Clustering with Self-Supervised Representation Learning","V. Sharma; M. Tapaswi; M. S. Sarfraz; R. Stiefelhagen","Department of Informatics-Institute for Anthropomatics and Robotics (IAR), Computer Vision for Human-Computer Interaction Lab (CV:HCI), Karlsruhe Institute of Technology, Karlsruhe, Germany, and also with the Massachusetts Institute of Technology, Cambridge, USA.; Inria, Paris, France. A. majority of this work was done when Makarand was with University of Toronto, and the Vector Institute, Toronto, Canada.; Department of Informatics-Institute for Anthropomatics and Robotics (IAR), Computer Vision for Human-Computer Interaction Lab (CV:HCI), Karlsruhe Institute of Technology, Karlsruhe, Germany.; Department of Informatics-Institute for Anthropomatics and Robotics (IAR), Computer Vision for Human-Computer Interaction Lab (CV:HCI), Karlsruhe Institute of Technology, Karlsruhe, Germany.","IEEE Transactions on Biometrics, Behavior, and Identity Science","","2019","PP","99","1","1","Characters are a key component of understanding the story conveyed in TV series and movies. With the rise of advanced deep face models, identifying face images may seem like a solved problem. However, as face detectors get better, clustering and identification need to be revisited to address increasing diversity in facial appearance. In this paper, we propose unsupervised methods for feature refinement with application to video face clustering. Our emphasis is on distilling the essential information, identity, from the representations obtained using deep pre-trained face networks. We propose a self-supervised Siamese network that can be trained without the need for video/track based supervision, that can also be applied to image collections. We evaluate our methods on three video face clustering datasets. Thorough experiments including generalization studies show that our methods outperform current state-of-the-art methods on all datasets. The datasets and code are available at https://github.com/vivoutlaw/SSIAM.","","","10.1109/TBIOM.2019.2947264","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8873682","Video Understanding;Video Face Clustering;Self-Supervised Learning;Representation Learning;Siamese Networks;Variational Autoencoders.","Face;Training data;Hidden Markov models;TV;Motion pictures;Training;Analytical models","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Regularized Deep Transfer Learning: When CNN Meets kNN","S. Wang; L. Zhang","School of Microelectronics and Communication Engineering, Chongqing University, Chongqing 400044, China.; School of Microelectronics and Communication Engineering, Chongqing University, Chongqing 400044, China.","IEEE Transactions on Circuits and Systems II: Express Briefs","","2019","PP","99","1","1","In this paper, we propose a regularized deep transfer learning architecture composed of a softmax classifier and a k-nearest neighbor (kNN) classifier. We aim to generalize the softmax classifier possibly well under the regularization effect of the kNN classifier. That is, given a training sample, the kNN classifier assigns a soft label vector according to its distance to the center of each class. The working mechanism of the kNN classifier is attributed to both the source and target domains. On the one hand, it gradually becomes stronger by backpropagating the cross-entropy classification loss on the source images. On the other hand, for target data, we enforce to minimize the discrepancy between the label vectors produced by the kNN classifier and the softmax classifier. Using the kNN classifier, we are able to reduce the intra-class variations on the source domain and meanwhile pull close the source and target feature distributions, which can better bound the expected error of target domain. In experiment, we demonstrate that our method compares favorably with the state-of-the-arts on benchmarks.","","","10.1109/TCSII.2019.2954709","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8907357","kNN;CNN;classification;domain adaptation.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Simultaneous Segmentation and Classification of Mass Region from Mammograms Using a Mixed-Supervision Guided Deep Model","T. Shen; C. Gou; J. Wang; F. Wang","Institute of Automation Chinese Academy of Sciences, 74522 Beijing, Beijing China (e-mail: shentianyu2016@ia.ac.cn); Institute of Automation Chinese Academy of Sciences, 74522 Beijing, Beijing China (e-mail: gouchao.cas@gmail.com); Institute of Automation Chinese Academy of Sciences, 74522 Beijing, Beijing China (e-mail: wangjiangong2018@ia.ac.cn); Institute of Automation Chinese Academy of Sciences, 74522 Beijing, Beijing China (e-mail: feiyue.wang@ia.ac.cn)","IEEE Signal Processing Letters","","2019","PP","99","1","1","Automatic diagnosis based on medical imaging necessitates both lesion segmentation and disease classification. Lesion segmentation requires pixel-level annotations while disease classification only requires image-level annotations. The two tasks are usually studied separately despite the latter problem relies on the former. Motivated by the close correlation between them, we propose a mixed-supervision guided method and a residual-aided classification U-Net model (ResCU-Net) for joint segmentation and benign-malignant classification. By coupling the strong supervision in the form of segmentation mask and weak supervision in the form of benign-malignant label through a simple annotation procedure, our method efficiently segments tumor regions while simultaneously predicting a discriminative map for identifying the benign-malignant types of tumors. Our network, ResCU-Net, extends U-Net by incorporating the residual module and the SegNet architecture to exploit multilevel information for achieving improved tissue identification. With experiments on a public mammogram database of INbreast, we validate the effectiveness of our method and achieve consistent improvements over state-of-the-art models.","","","10.1109/LSP.2019.2963151","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8946755","Mixed-supervision;deep learning;segmentation and classification;mammogram","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Binary Particle Swarm Optimizer With Priority Planning and Hierarchical Learning for Networked Epidemic Control","T. Zhao; W. Chen; A. W. Liew; T. Gu; X. Wu; J. Zhang","School of Computer Science and Engineering, South China University of Technology, Guangzhou 510006, China, and also with the State Key Laboratory of Subtropical Building Science, South China University of Technology, Guangzhou 510006, China.; School of Computer Science and Engineering, South China University of Technology, Guangzhou 510006, China, and also with the State Key Laboratory of Subtropical Building Science, South China University of Technology, Guangzhou 510006, China (e-mail: cwnraul634@aliyun.com).; School of Information and Communication Technology, Griffith University, Nathan, QLD 4222, Australia.; School of Computer Science and Engineering, Guilin University of Electronic Technology, Guilin 541004, China.; School of Journalism and Communication, South China University of Technology, Guangzhou 510006, China.; School of Division Electrical Engineering, Hanyang University, Seoul 04763, South Korea.","IEEE Transactions on Systems, Man, and Cybernetics: Systems","","2019","PP","99","1","15","The control of epidemics taking place in complex networks has been an increasingly active topic in public health management. In this article, we propose an efficient networked epidemic control system, where a modified susceptible-exposed-infected-vigilant (SEIV) model is first built to simulate epidemic spreading. Then, different from existing continuous resource models which abstractly map resources to parameters of epidemic models, a concrete resource description model is built to simulate real-world goods/services and their allocation. Based on the two models, a cost-constraint subset selection problem in epidemic control is identified. To solve the problem, a swarm-based stochastic optimization policy is proposed, where each particle in the swarm can determine its own solutions according to the guidance of its superior peers and historical searching experience of the whole swarm, without extra problem-relative information. Theoretical proof about system equilibrium is provided, which is consistent with experimental observations. The competitive performance of the proposed optimizer is validated by theoretical analysis and comparison experiments. Finally, an application case is provided to illustrate the practicability.","","","10.1109/TSMC.2019.2945055","Key Project of Science and Technology Innovation 2030 through Ministry of Science and Technology of China; National Natural Science Foundation of China; Guangdong Hong Kong Joint Innovation Platform of Big Data and Computational Intelligence; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8887458","Complex network;epidemic control;particle swarm optimization;resource allocation;spreading model","Resource management;Computational modeling;Optimization;Mathematical model;Network topology;Planning;Deep learning","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Cyber physical security analytics for transactive energy systems","Y. Zhang; V. V. G. Krishnan; J. Pi; K. Kaur; A. Srivastava; A. Hahn; S. Suresh","school of Electrical Engineering and Computer Science, Washington State University, Pullman, WA-99163.; WSU. He is now working with Indian Institute of Technology, Tirupati 517506, India.; Siemens Corporation, Princeton, NJ.; school of Electrical Engineering and Computer Science, Washington State University, Pullman, WA-99163.; school of Electrical Engineering and Computer Science, Washington State University, Pullman, WA-99163.; school of Electrical Engineering and Computer Science, Washington State University, Pullman, WA-99163.; Siemens Corporation, Princeton, NJ.","IEEE Transactions on Smart Grid","","2019","PP","99","1","1","With the significant increase in integration of renewable energy generation into the electric grid, market-based transactive exchanges between energy producers and prosumers will become more common. Transactive energy systems (TES) employ economic and control mechanisms to dynamically balance the demand and supply across the electrical grid. Emerging transactive control mechanism depends on a large number of distributed edge-computing and Internet of Things (IoT) devices making autonomous/semi-autonomous decisions on energy production, and demand response. However, the electric grid cyber assets and the IoT devices are increasingly vulnerable to attack. TES will likely have similar vulnerabilities and cyber attacks especially with financial interest motives of stakeholders, which could affect the operation of the power grid. Therefore, new analytical methods are needed to continuously monitor these systems operations and detect malicious activity. In this research work, various components of transactive energy systems are modeled and simulated in detail. Various cyber attack models are developed based on threats identified in TES. A deep learning approach called deep stacked autoencoder (SAE) is utilized to detect possible anomalies in the market and physical system measurements. The proposed unsupervised technique is validated for satisfactory performance to detect anomalies and trigger a further investigation for root cause analysis using end-to-end TES testbed and use case.","","","10.1109/TSG.2019.2928168","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8759931","Cyber Attacks;Cyber-Physical Security;Deep Learning;Deep Stacked Autoencoder;Data Analytics;Transactive Energy Systems.","Transactive energy;Load management;Cyberattack;Internet of Things;Power systems;Anomaly detection","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Fuzzy Least Squares Support Vector Machine with Adaptive Membership for Object Tracking","S. Zhang; L. Zhang; A. Hauptmann","School of Software Engineering, Beijing Jiaotong University, 47829 Beijing China 100044 (e-mail: zslsdu@163.com); Electornic Engineering, Tsinghua University, Beijing China 100084 (e-mail: chinazhangli@mail.tsinghua.edu.cn); Computer Science, Carnegie Mellon University, Pittsburgh, Pennsylvania United States 15213-3891 (e-mail: alex@cs.cmu.edu)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","Fuzzy learning has been introduced into tracking and achieved great success. However, the membership in the existing fuzzy learning based tracking algorithm is fixed, which lacks the adaptivity to measure the importance of the samples. To improve the tracking adaptivity and flexibility, in this paper, we propose a novel tracking method based on fuzzy least squares support vector machine with adaptive membership (FLS-SVM-AM). First, we formulate tracking as an adaptive membership based fuzzy learning problem, which addresses the issue of fixed membership in existing methods and can better measure the importance of the training samples. Second, we present the FLS-SVM-AM method to build the appearance model, and develop an iterative optimization process to solve the FLS-SVM-AM problem. Third, we define a new membership based on the PASCAL VOC overlap rate and exponential function, which is used to measure the importance of different samples more accurately. Experimental results in the benchmark datasets demonstrate that the proposed method can not only outperform the existing fuzzy learning based tracking method, but also possess comparable performance to many state-of-the-art methods.","","","10.1109/TMM.2019.2952252","Natural Science Foundation of Beijing Municipality; Fundamental Research Funds for the Central Universities; Intelligence Advanced Research Projects Activity; National Natural Science Foundation of China; financial assistance award; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8894508","Object tracking;fuzzy learning;adaptive membership;fuzzy least squares support vector machine","Target tracking;Adaptation models;Correlation;Support vector machines;Deep learning;Feature extraction","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Regression Guided by Relative Ranking Using Convolutional Neural Network (R3CNN) for Facial Beauty Prediction","L. Lin; L. Liang; L. Jin","School of Electronic and Information Engineering, South China University of Technology, 26467 Guangzhou, Guangdong China (e-mail: linluojun2009@126.com); School of Electronic and Information Engineering, South China University of Technology, 26467 Guangzhou, Guangdong China (e-mail: lianglysky@gmail.com); School of Electronics and Information Engineering, South China University of Technology, 26467 Guangzhou, Guangdong China (e-mail: lianwen.jin@gmail.com)","IEEE Transactions on Affective Computing","","2019","PP","99","1","1","Facial beauty prediction (FBP) aims to assess facial attractiveness with judgements based on human perception. Most of previous methods formulate FBP as a classification, regression or ranking problem of machine learning. However, humans not only represent facial attractiveness as a score, but also perceive the relative aesthetics of faces. Inspired by this observation, we formulate FBP as a specific regression problem guided by ranking information. Specifically, we propose a general CNN architecture, called R$^3$CNN, to integrate the relative ranking of faces in terms of aesthetics to improve performance of facial beauty prediction. As R$^3$CNN consists of both regression and ranking components, it is challenging to train and fine-tune it by existing techniques. To tackle this problem, we propose the following learning schemes for R$^3$CNN: 1) hard pair sampling that generates challenging-to-predicted image pairs and pseudo ranking labels from true rating scores; 2) an assemble loss function that combines regression loss and pairwise ranking loss (PR-Loss); 3) a cascaded fine-tuning method that further improves prediction. Moreover, we build a benchmark dataset, called SCUT-FBP5500, containing 5,500 images of faces with diverse properties and labels. Experiments were performed on both the SCUT-FBP and the SCUT-FBP5500 benchmark datasets, where our method achieved state-of-the-art performance.","","","10.1109/TAFFC.2019.2933523","National Natural Science Foundation of China; National Basic Research Program of China (973 Program); Natural Science Foundation of Guangdong Province; Guangzhou Science Technology and Innovation Commission; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8789541","Facial Beauty Prediction;Face Attractiveness Assessment;Deep Residual Network;Siamese Network","Benchmark testing;Databases;Training;Computer architecture;Fasteners;Deep learning;Task analysis","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Very High Resolution Remote Sensing Imagery Classification Using a Fusion of Random Forest and Deep Learning Technique—Subtropical Area for Example","L. Dong; H. Du; F. Mao; N. Han; X. Li; G. Zhou; D. Zhu; J. Zheng; M. Zhang; L. Xing; T. Liu","State Key Laboratory of Subtropical Silviculture, Lin'an 311300, China with the Key Laboratory of Carbon Cycling in Forest Ecosystems and Carbon Sequestration of Zhejiang Province, Lin'an 311300, China, and also with the School of Environmental and Resources Science, Zhejiang A&F University, Lin'an 311300, China (e-mail: dongluofan@gmail.com).; State Key Laboratory of Subtropical Silviculture, Lin'an 311300, China with the Key Laboratory of Carbon Cycling in Forest Ecosystems and Carbon Sequestration of Zhejiang Province, Lin'an 311300, China, and also with the School of Environmental and Resources Science, Zhejiang A&F University, Lin'an 311300, China (e-mail: dhqrs@126.com).; State Key Laboratory of Subtropical Silviculture, Lin'an 311300, China with the Key Laboratory of Carbon Cycling in Forest Ecosystems and Carbon Sequestration of Zhejiang Province, Lin'an 311300, China, and also with the School of Environmental and Resources Science, Zhejiang A&F University, Lin'an 311300, China (e-mail: mfangjie@gmail.com).; State Key Laboratory of Subtropical Silviculture, Lin'an 311300, China with the Key Laboratory of Carbon Cycling in Forest Ecosystems and Carbon Sequestration of Zhejiang Province, Lin'an 311300, China, and also with the School of Environmental and Resources Science, Zhejiang A&F University, Lin'an 311300, China (e-mail: hangis2002@163.com).; State Key Laboratory of Subtropical Silviculture, Lin'an 311300, China with the Key Laboratory of Carbon Cycling in Forest Ecosystems and Carbon Sequestration of Zhejiang Province, Lin'an 311300, China, and also with the School of Environmental and Resources Science, Zhejiang A&F University, Lin'an 311300, China (e-mail: xuejianli201609@163.com).; State Key Laboratory of Subtropical Silviculture, Lin'an 311300, China with the Key Laboratory of Carbon Cycling in Forest Ecosystems and Carbon Sequestration of Zhejiang Province, Lin'an 311300, China, and also with the School of Environmental and Resources Science, Zhejiang A&F University, Lin'an 311300, China (e-mail: zhougm@zafu.edu.cn).; State Key Laboratory of Subtropical Silviculture, Lin'an 311300, China with the Key Laboratory of Carbon Cycling in Forest Ecosystems and Carbon Sequestration of Zhejiang Province, Lin'an 311300, China, and also with the School of Environmental and Resources Science, Zhejiang A&F University, Lin'an 311300, China (e-mail: 1096178563@qq.com).; State Key Laboratory of Subtropical Silviculture, Lin'an 311300, China with the Key Laboratory of Carbon Cycling in Forest Ecosystems and Carbon Sequestration of Zhejiang Province, Lin'an 311300, China, and also with the School of Environmental and Resources Science, Zhejiang A&F University, Lin'an 311300, China (e-mail: 1459165815@qq.com).; State Key Laboratory of Subtropical Silviculture, Lin'an 311300, China with the Key Laboratory of Carbon Cycling in Forest Ecosystems and Carbon Sequestration of Zhejiang Province, Lin'an 311300, China, and also with the School of Environmental and Resources Science, Zhejiang A&F University, Lin'an 311300, China (e-mail: 781792079@126.com).; State Key Laboratory of Subtropical Silviculture, Lin'an 311300, China with the Key Laboratory of Carbon Cycling in Forest Ecosystems and Carbon Sequestration of Zhejiang Province, Lin'an 311300, China, and also with the School of Environmental and Resources Science, Zhejiang A&F University, Lin'an 311300, China (e-mail: x522874591@163.com).; State Key Laboratory of Subtropical Silviculture, Lin'an 311300, China with the Key Laboratory of Carbon Cycling in Forest Ecosystems and Carbon Sequestration of Zhejiang Province, Lin'an 311300, China, and also with the School of Environmental and Resources Science, Zhejiang A&F University, Lin'an 311300, China (e-mail: lty706695603@163.com).","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2019","PP","99","1","16","Recently, convolutional neural networks (CNNs) showed excellent performance in many tasks, such as computer vision and remote sensing semantic segmentation. Especially, the ability to learn high-representation features of CNN draws much attention. And random forest (RF) algorithm, on the other hand, is widely applied for variables selection, classification, and regression. Based on the previous fusion models that fused CNN with the other models, such as conditional random fields (CRFs), support vector machine (SVM), and RF, this article tested a method based on the fusion of an RF classifier and the CNN for a very high resolution remote sensing (VHRRS) based forests mapping. The study area is located in the south of China and the main purpose was to precisely distinguish Lei bamboo forests from the other subtropical forests. The main novelties of this article are as follows. First, a test was conducted to confirm if a fusion of CNN and RF make an improvement in the VHRRS information extraction. Second, based on RF, variables with high importance were selected. Then, a test was again conducted to confirm if the learning from the selected variables will further give better results.","","","10.1109/JSTARS.2019.2953234","National Natural Science Foundation of China; State Key Laboratory of Subtropical Silviculture Foundation; Joint Research Fund of Department of Forestry of Zhejiang Province and Chinese Academy of Forestry; Zhejiang Provincial Collaborative Innovation Center for Bamboo Resources and High-efficiency Utilization; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8935521","Classification;convolutional neural networks (CNNs);random forest (RF);subtropical forest;very high resolution remote sensing (VHRRS)","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Virtual Network Function placement optimization with Deep Reinforcement Learning","R. Solozabal; J. Ceberio; A. Sanchoyerto; L. Zabala; B. Blanco; F. Liberal","Networking Quality and Security Department.; Department of Computer Science and Artificial Intelligence University of the Basque Country (UPV/EHU).; Networking Quality and Security Department.; Networking Quality and Security Department.; Networking Quality and Security Department.; Networking Quality and Security Department.","IEEE Journal on Selected Areas in Communications","","2019","PP","99","1","1","Network Function Virtualization (NFV) introduces a new network architecture framework that evolves network functions, traditionally deployed over dedicated equipment, to software implementations that run on general-purpose hardware. One of the main challenges for deploying NFV is the optimal resource placement of demanded network services in the NFV infrastructure. The virtual network function placement and network embedding can be formulated as a mathematical optimization problem concerned with a set of feasibility constraints that express the restrictions of the network infrastructure and the services contracted. This problem has been reported to be NP-hard, as a result most of the optimization work carried out in the area has focused on designing heuristic and metaheuristic algorithms. Nevertheless, in highly constrained problems, as in this case, inferring a competitive heuristic can be a daunting task that requires expertise. Consequently, an interesting solution is the use of Reinforcement Learning to model an optimization policy. The work presented here extends the Neural Combinatorial Optimization theory by considering constraints in the definition of the problem. The resulting agent is able to learn placement decisions by exploring the NFV infrastructure with the aim of minimizing the overall power consumption. The experiments conducted demonstrate that when the proposed strategy is also combined with heuristics, highly competitive results are achieved using relatively simple algorithms.","","","10.1109/JSAC.2019.2959183","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8945291","Constrained Combinatorial Optimization;Reinforcement Leaning;5G;NFV","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Chaotic Type-2 Transient-Fuzzy Deep Neuro-Oscillatory Network (CT2TFDNN) for Worldwide Financial Prediction","R. S. T. Lee","Computer Science & Technology Division, Beijing-Normal University-Hong Kong Baptist University United International College (UIC), 2000 Jintong Road, Tangjiawan, Zhuhai, Guangdong, China. (e-mail: raymondshtlee@uic.edu.hk)","IEEE Transactions on Fuzzy Systems","","2019","PP","99","1","1","Over the years, financial engineering ranging from the study of financial signals to the modelling of financial prediction is one of the most exciting topics for both academia and financial community. With the flourishing of AI technology in the past 20 years, various hybrid intelligent financial prediction systems with the integration of neural networks, chaos theory, fuzzy logic and genetic algorithms have been proposed. Interval Type-2 Fuzzy Logic System (IT2FLS) with its remarkable capability for the modelling of highly uncertain events and attributes, provides a perfect tool to interpret various financial phenomena and patterns. In this paper, the author proposes a Chaotic Type-2 Transient-Fuzzy Deep Neuro-oscillatory Network with Retrograde Signaling (aka CT2TFDNN) for worldwide financial prediction. With the extension of author's original work on Lee-oscillator – a chaotic discrete-time neural oscillator with profound transient-chaotic property, CT2TFDNN provides: 1) effective modelling of Interval Type-2 Fuzzy Logic with Chaotic Transient-Fuzzy Membership Function (CT2TFMF); 2) effective time-series network training and prediction using Chaotic Deep Neuro-oscillatory Network with Retrograde Signaling (CDNONRS). CT2TFDNN not only provides a fast chaotic fuzzy-neuro deep learning and forecast solution, more prominently it successfully resolves the massive data over-training and deadlock problems which are usually imposed by traditional recurrent neural networks using classical sigmoid-based activation functions. From the implementation perspective, CT2TFDNN is integrated with 2048-trading day time-series financial data and Top-10 major financial signals as Fuzzy Financial Signals (FFS) for the real-time prediction of 129 worldwide financial products which consists of: 9 major cryptocurrencies, 84 worldwide forex, 19 major commodities and 17 worldwide financial indices.","","","10.1109/TFUZZ.2019.2914642","Beijing Normal University-Hong Kong Baptist University United International College UIC; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8704876","financial prediction;chaotic type-2 transient-fuzzy logic;chaotic deep neuro-oscillatory network;Lee-oscillator;chaotic bifurcation transfer function","Fuzzy logic;Predictive models;Oscillators;Indexes;Linguistics;Cryptography;Uncertainty","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Training- and Test-Time Data Augmentation for Hyperspectral Image Segmentation","J. Nalepa; M. Myller; M. Kawulok","Institute of Informatics, Silesian University of Technology, 44-100 Gliwice, Poland, and also with KP Labs, 44-100 Gliwice, Poland (e-mail: jnalepa@ieee.org).; Institute of Informatics, Silesian University of Technology, 44-100 Gliwice, Poland, and also with KP Labs, 44-100 Gliwice, Poland.; Institute of Informatics, Silesian University of Technology, 44-100 Gliwice, Poland, and also with KP Labs, 44-100 Gliwice, Poland.","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","Data augmentation helps improve generalization capabilities of deep neural networks when only limited ground-truth training data are available. In this letter, we propose test-time augmentation of hyperspectral data, which is executed during the inference rather than before the training of deep networks. We introduce two augmentation techniques, which can be applied at both training time and test time. The experiments revealed that our augmentations boost generalization of deep models and work in real time, and the test-time approach can be combined with training-time techniques to enhance the classification accuracy.","","","10.1109/LGRS.2019.2921011","European Space Agency through HYPERNET Project; Silesian University of Technology; Silesian University of Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8746168","Classification;data augmentation;deep learning;hyperspectral imaging;principal component analysis (PCA);segmentation.","Training;Principal component analysis;Hyperspectral imaging;Image segmentation;Gallium nitride;Neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Dynamic Prediction in Clinical Survival Analysis using Temporal Convolutional Networks","D. Jarrett; J. Yoon; M. van der Schaar","Engineering Science, University of Oxford, 6396 Oxford United Kingdom of Great Britain and Northern Ireland OX1 3PJ (e-mail: daniel.jarrett@eng.ox.ac.uk); Electrical Engineering, University of California, Los Angeles, Los Angeles, California United States 90025 (e-mail: jsyoon0823@gmail.com); Electrical Engineering, University of California Los Angeles, Los Angeles, California United States (e-mail: mihaela@ee.ucla.edu)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","Accurate prediction of disease trajectories is critical for early identification and timely treatment of patients at risk. Conventional methods in survival analysis are often constrained by strong parametric assumptions and limited in their ability to learn from high-dimensional data. This paper develops a novel convolutional approach that addresses the drawbacks of both traditional statistical approaches as well as recent neural network models for survival. We present MATCH-Net: a Missingness-Aware Temporal Convolutional Hitting-time Network, designed to capture temporal dependencies and heterogeneous interactions in covariate trajectories and patterns of missingness. To the best of our knowledge, this is the first investigation of temporal convolutions in the context of dynamic prediction for personalized risk prognosis. Using real-world data from the Alzheimer's Disease Neuroimaging Initiative (ADNI), we demonstrate state-of-the-art performance without making any assumptions regarding underlying longitudinal or time-to-event processes-attesting to the model's potential utility in clinical decision support.","","","10.1109/JBHI.2019.2929264","ONR and NSF; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8765241","Alzheimer's Disease Neuroimaging Initiative;dynamic prediction;survival analysis;temporal convolutions","Alzheimer's disease;Data models;Hazards;Predictive models;Deep learning;Informatics","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Federated Echo State Learning for Minimizing Breaks in Presence in Wireless Virtual Reality Networks","M. Chen; O. Semiari; W. Saad; X. Liu; C. Yin","Beijing Key Laboratory of Network System Architecture and Convergence, Beijing University of Posts and Telecommunications, Beijing, 100876, China and Department of Electrical Engineering, Princeton University, Princeton, NJ, 08544, USA and with the Chinese University of Hong Kong, Shenzhen, 518172, China.; Department of Electrical and Computer Engineering, University of Colorado Colorado Springs, Colorado Springs, CO, 80918, USA.; Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, 24060, USA.; Beijing Key Laboratory of Network System Architecture and Convergence, Beijing University of Posts and Telecommunications, Beijing, 100876, China.; Beijing Key Laboratory of Network System Architecture and Convergence, Beijing University of Posts and Telecommunications, Beijing, 100876, China.","IEEE Transactions on Wireless Communications","","2019","PP","99","1","1","In this paper, the problem of enhancing the virtual reality (VR) experience for wireless users is investigated by minimizing the occurrence of breaks in presence (BIP) that can detach the users from their virtual world. To measure the BIP for wireless VR users, a novel model that jointly considers the VR application type, transmission delay, VR video quality, and users’ awareness of the virtual environment is proposed. In the developed model, the base stations (BSs) transmit VR videos to the wireless VR users using directional transmission links so as to provide high data rates for the VR users, thus, reducing the number of BIP for each user. Since the body movements of a VR user may result in a blockage of its wireless link, the location and orientation of VR users must also be considered when minimizing BIP. The BIP minimization problem is formulated as an optimization problem which jointly considers the predictions of users’ locations, orientations, and their BS association. To predict the orientation and locations of VR users, a distributed learning algorithm based on the machine learning framework of deep (ESNs) is proposed. The proposed algorithm uses concept from federated learning to enable multiple BSs to locally train their deep ESNs using their collected data and cooperatively build a learning model to predict the entire users’ locations and orientations. Using these predictions, the user association policy that minimizes BIP is derived. Simulation results demonstrate that the developed algorithm reduces the users’ BIP by up to 16% and 26%, respectively, compared to centralized ESN and deep learning algorithms.","","","10.1109/TWC.2019.2942929","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8851408","","Prediction algorithms;Delays;Uplink;Downlink;Machine learning algorithms;Wireless networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Recipe1M+: A Dataset for Learning Cross-Modal Embeddings for Cooking Recipes and Food Images","J. Marin; A. Biswas; F. Ofli; N. Hynes; A. Salvador; Y. Aytar; I. Weber; A. Torralba","Electrical Engineering and Computer Science, Massachusetts Institute of Technology, 2167 Cambridge, Massachusetts United States 02139-4307 (e-mail: jmarin@csail.mit.edu); EECS, MIT, Cambridge, Massachusetts United States (e-mail: abiswas@mit.edu); Social Media, Qatar Computing Research Institute, Doha, Doha Qatar (e-mail: fofli@hbku.edu.qa); EECS, MIT, Cambridge, Massachusetts United States (e-mail: nhynes@mit.edu); Signal Theory and Communications Department, Universitat Politecnica de Catalunya, Barcelona, Catalonia Spain (e-mail: amaia.salvador@upc.edu); EECS, MIT, Cambridge, Massachusetts United States (e-mail: yusuf@csail.mit.edu); Social Media, Qatar Computing Research Institute, Doha, Doha Qatar (e-mail: iweber@hbku.edu.qa); EECS, MIT, Cambridge, Massachusetts United States (e-mail: torralba@mit.edu)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","In this paper, we introduce Recipe1M+, a new large-scale, structured corpus of over one million cooking recipes and 13 million food images. As the largest publicly available collection of recipe data, Recipe1M+ affords the ability to train high-capacity models on aligned, multi-modal data. Using these data, we train a neural network to learn a joint embedding of recipes and images that yields impressive results on an image-recipe retrieval task. Moreover, we demonstrate that regularization via the addition of a high-level classification objective both improves retrieval performance to rival that of humans and enables semantic vector arithmetic. We postulate that these embeddings will provide a basis for further exploration of the Recipe1M+ dataset and food and cooking in general. Code, data and models are publicly available.","","","10.1109/TPAMI.2019.2927476","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8758197","Cross-modal;deep learning;cooking recipes;food images","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Frank-Wolfe Network: An Interpretable Deep Structure for Non-Sparse Coding","D. Liu; K. Sun; Z. Wang; R. Liu; Z. Zha","CAS Key Laboratory of Technology in Geo-Spatial Information Processing and Application System, University of Science and Technology of China, Hefei, China.; CAS Key Laboratory of Technology in Geo-Spatial Information Processing and Application System, University of Science and Technology of China, Hefei, China.; Department of Computer Science and Engineering, Texas A&M University, College Station, TX, USA.; University of Science and Technology of China, Hefei, China.; CAS Key Laboratory of Technology in Geo-Spatial Information Processing and Application System, University of Science and Technology of China, Hefei, China.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","The problem of Lp-norm constrained coding is to convert signal into code that lies inside an Lp-ball and most faithfully reconstructs the signal. Previous works under the name of sparse coding considered the cases of L0 and L1 norms. The cases with p > 1 values, i.e. non-sparse coding studied in this paper, remain a difficulty. We propose an interpretable deep structure namely Frank-Wolfe Network (F-W Net), whose architecture is inspired by unrolling and truncating the Frank-Wolfe algorithm for solving an Lp-norm constrained problem with p ≥ 1. We show that the Frank-Wolfe solver for the Lp-norm constraint leads to a novel closed-form nonlinear unit, which is parameterized by p and termed poolp. The poolp unit links the conventional pooling, activation, and normalization operations, making F-W Net distinct from existing deep networks either heuristically designed or converted from projected gradient descent algorithms. We further show that the hyper-parameter p can be made learnable instead of pre-chosen in F-W Net, which gracefully solves the non-sparse coding problem even with unknown p. We evaluate the performance of F-W Net on an extensive range of simulations as well as the task of handwritten digit recognition, where F-W Net exhibits strong learning capability. We then propose a convolutional version of FWNet, and apply the convolutional F-W Net into image denoising and super-resolution tasks, where F-W Net all demonstrates impressive effectiveness, flexibility, and robustness.","","","10.1109/TCSVT.2019.2936135","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8805092","Convolutional network;Frank-Wolfe algorithm;Frank-Wolfe network;non-sparse coding","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Multi-modal Deep Analysis for Multimedia","W. Zhu; X. Wang; H. Li","Department of Computer Science and Technology, Tsinghua University, Beijing, China.; Department of Computer Science and Technology, Tsinghua University, Beijing, China.; Microsoft Research, Redmond, USA.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","With the rapid development of Internet and multimedia services in the past decade, a huge amount of user-generated and service provider-generated multimedia data become available. These data are heterogeneous and multi-modal in nature, imposing great challenges for processing and analyzing them. Multi-modal data consist of a mixture of various types of data from different modalities such as texts, images, videos, audios etc. In this article, we present a deep and comprehensive overview for multi-modal analysis in multimedia. We introduce two scientific research problems, data-driven correlational representation and knowledge-guided fusion for multimedia analysis. To address the two scientific problems, we investigate them from the following aspects: 1) multi-modal correlational representation: multi-modal fusion of data across different modalities, and 2) multi-modal data and knowledge fusion: multi-modal fusion of data with domain knowledge. More specifically, on data-driven correlational representation, we highlight three important categories of methods, such as multi-modal deep representation, multi-modal transfer learning, and multi-modal hashing. On knowledge-guided fusion, we discuss the approaches for fusing knowledge with data and four exemplar applications that require various kinds of domain knowledge, including multi-modal visual question answering, multi-modal video summarization, multi-modal visual pattern mining and multi-modal recommendation. Finally, we bring forward our insights and future research directions.","","","10.1109/TCSVT.2019.2940647","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8832161","Multi-modal analysis;Data-driven correlational representation;Knowledge-guided data fusion","Task analysis;Streaming media;Semantics;Videos;Visualization;Data integration;Cognition","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Identification of VoIP Speech with Multiple Domain Deep Features","Y. Huang; B. Li; M. Barni; J. Huang","Guangdong Key Laboratory of Intelligent Information Processing, Shenzhen Key Laboratory of Media Security, Guangdong Laboratory of Artificial Intelligence and Digital Economy(SZ), Shenzhen University, Shenzhen 518060, China and Shenzhen Institute of Artificial Intelligence and Robotics for Society, Shenzhen, China.; Guangdong Key Laboratory of Intelligent Information Processing, Shenzhen Key Laboratory of Media Security, Guangdong Laboratory of Artificial Intelligence and Digital Economy(SZ), Shenzhen University, Shenzhen 518060, China and Shenzhen Institute of Artificial Intelligence and Robotics for Society, Shenzhen, China.; Department of Information Engineering and Mathematics, University of Siena, Siena 53100, Italy.; Guangdong Key Laboratory of Intelligent Information Processing, Shenzhen Key Laboratory of Media Security, Guangdong Laboratory of Artificial Intelligence and Digital Economy(SZ), Shenzhen University, Shenzhen 518060, China and Shenzhen Institute of Artificial Intelligence and Robotics for Society, Shenzhen, China.","IEEE Transactions on Information Forensics and Security","","2019","PP","99","1","1","Identifying whether a phone call comes from VoIP (Voice over Internet Protocol) is a challenging but less-investigated audio forensic issue. As shown in a previous study, existing feature based methods do not work well. In this paper, we propose a robust data-driven approach, called CNN-MLS (convolutional neural network based multi-domain learning scheme), to distinguish VoIP calls from mobile phone calls. To better explore the differences between VoIP and mobile phone calls, we first process data with high-pass filtering, and then extract deep features from both temporal domain and spectral domain. Two CNN architectures are designed for accepting data from respective domains, and some tricks such as auxiliary classifiers and individual subnet training are used for accelerating network convergence. The deep features are finally fused in a classification module for identifying the phone call type. The proposed method is evaluated on VPCID (VoIP Phone Call Identification Database) dataset, under various testing conditions. We pay particular attention to tests on data belonging to a source mismatched with the training sources. Experimental results show that, compared with existing methods, our method can achieve satisfactory and better accuracy on two-second-long inputs, implying that an alert may be activated shortly after a VoIP call is made.","","","10.1109/TIFS.2019.2960635","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8936059","Audio forensics;convolutional neural network;voice over Internet protocol","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Roller Bearing Degradation Assessment Based on a Deep MLP Convolution Neural Network Considering Outlier Regions","D. Zhang; E. Stewart; J. Ye; M. Entezami; C. Roberts","Department of Electronic, Electrical and Systems Engineering, University of Birmingham, Birmingham B15 2TT, UK.; Department of Electronic, Electrical and Systems Engineering, University of Birmingham, Birmingham B15 2TT, UK.; Department of Electronic, Electrical and Systems Engineering, University of Birmingham, Birmingham B15 2TT, UK.; Department of Electronic, Electrical and Systems Engineering, University of Birmingham, Birmingham B15 2TT, UK.; Department of Electronic, Electrical and Systems Engineering, University of Birmingham, Birmingham B15 2TT, UK.","IEEE Transactions on Instrumentation and Measurement","","2019","PP","99","1","1","Roller bearings are one of the most safety-critical components in many machines. Predicting the vibration-based remaining useful life (RUL) of roller bearings allows operators to make informed maintenance decisions and to guarantee reliability and safety. The health indices (HIs) for degradation assessment are constructed by extracting feature information from the collected data, which significantly influences the prognosis result. Conventional HI construction methods rely heavily on expert knowledge and also have limited capacity for learning health information from the raw data from roller bearings. Furthermore, outlier regions often occur in HIs developed by those methods, and these can easily result in false alarms. To address these problems, a novel HI construction method based on a deep multilayer perceptron (MLP) convolution neural network (DMLPCNN) model, which also considers outlier regions, is proposed in this paper. In the proposed model, a 1-D MLP convolution (Mlpconv) block, consisting of a convolution layer and a micro network, is applied to learn features directly from vibrational data. The learned features are then mapped into an HI using a global average pooling layer and a logistic regression layer. Finally, an outlier region correction method, based on sliding thresholds, is proposed to detect and remove outliers in the HI. The outlier region correction method is able to enhance the interpretability of the constructed HI. The effectiveness of the proposed method is verified using whole-life datasets of 17 bearings. The experimental results demonstrate that the proposed method outperforms conventional methods.","","","10.1109/TIM.2019.2929669","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8765772","Roller bearings;RUL prediction;degradation assessment;deep MLP convolution neural network;outlier region correction method","Convolution;Rolling bearings;Degradation;Neural networks;Logistics;Feature extraction;Vibrations","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Aspect-based Sentiment Analysis with New Target Representation and Dependency Attention","T. Yang; Q. Yin; L. Yang; O. Wu","Center for Applied Mathematics, Tianjin University, 12605 Tianjin, Tianjin China (e-mail: yangtao087@gmail.com); Center for Applied Mathematics, Tianjin University, 12605 Tianjin, Tianjin China (e-mail: qingyin@tju.edu.cn); Center for Applied Mathematics, Tianjin University, 12605 Tianjin, Tianjin China (e-mail: yl7268@tju.edu.cn); Center for Applied Mathematics, Tianjin University, Tianjin, Tianjin China (e-mail: wuou@tju.edu.cn)","IEEE Transactions on Affective Computing","","2019","PP","99","1","1","Aspect-based sentiment analysis (ABSA) is crucial for exploring user feedbacks and preferences on produces or services. Although numerous classical deep learning-based methods have been proposed in previous literature, several useful cues (e.g., contextual, lexical, and syntactic) are still not fully considered and utilized. In this study, a new approach for ABSA is proposed through the guidance of contextual, lexical, and syntactic cues. First, a novel sub-network is introduced to represent a target in a sentence in ABSA by considering the whole context. Second, lexicon embedding is applied to incorporate additional lexical cues. Third, a new attention module, namely, dependency attention, is proposed to elaborate syntactic dependency cues between words in attention inference. Experimental results on four benchmark data sets demonstrate the effectiveness of our proposed approach to aspect-based sentiment analysis.","","","10.1109/TAFFC.2019.2945028","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8854152","ABSA;target representation;GRU;lexicon embedding;CRF;dependency attention","Sentiment analysis;Syntactics;Encoding;Deep learning;Grammar;Recurrent neural networks;Learning systems","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Inverse Synthetic Aperture Radar Imaging Using a Fully Convolutional Neural Network","C. Hu; L. Wang; Z. Li; D. Zhu","Key Laboratory of Radar Imaging and Microwave Photonics, Ministry of Education, Nanjing University of Aeronautics and Astronautics, Nanjing 210016, China; Key Laboratory of Radar Imaging and Microwave Photonics, Ministry of Education, Nanjing University of Aeronautics and Astronautics, Nanjing 210016, China (e-mail: tulip_wling@nuaa.edu.cn).; Key Laboratory of Radar Imaging and Microwave Photonics, Ministry of Education, Nanjing University of Aeronautics and Astronautics, Nanjing 210016, China; Key Laboratory of Radar Imaging and Microwave Photonics, Ministry of Education, Nanjing University of Aeronautics and Astronautics, Nanjing 210016, China","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","The traditional inverse synthetic aperture radar (ISAR) imaging uses the range-Doppler (RD) type of methods. The compressive sensing (CS)-based ISAR imaging is capable of obtaining good target images of high contrast and less sidelobe with much less downsampling data. However, the real application of CS ISAR imaging is limited by the time-consuming iteration-based image reconstruction. The image quality is also limited by the performance of sparse representation of the target scene. In recent years, deep learning methods, more specifically the convolutional neural network (CNN), has shown its capability in signal recovery with downsampling or noncomplete data. The well-trained CNN can extract high-level abstract feature representation from the input data autonomously and exploit it in the signal recovery. We are interested in exploiting the CNN to enhance the CS ISAR imaging capability. The successful training of CNN always requires many thousand annotated training samples. This limits the application of CNN to the radar imaging field where large amount of training data cannot be obtained as easy as in other fields, e.g., computer vision. We propose a fully CNN (FCNN) for ISAR imaging. The constructed FCNN has a multistage decomposition and multichannel filtering architecture and has no fully connected layers. It can work with very few training samples as compared to existing CNN-based imaging networks. The imaging results of real ISAR data show that the proposed FCNN-based ISAR imaging method outperforms the state-of-the-art CS ISAR imaging methods in both image quality and computational efficiency.","","","10.1109/LGRS.2019.2943069","National Basic Research Program of China (973 Program); National Natural Science Foundation of China; Postgraduate Research and Practice Innovation Program of Jiangsu Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8863507","Deep learning (DL);fully convolutional neural network (FCNN);imaging;inverse synthetic aperture radar (ISAR);radar.","Imaging;Radar imaging;Training;Image reconstruction;Training data;Feature extraction;Convolution","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Towards Big data processing in IoT: Path Planning and Resource Management of UAV Base Stations in Mobile-Edge Computing System","S. Wan; J. Lu; P. Fan; K. B. Letaief","Beijing National Research Center for Information Science and Technology(BNRist), and also with the Department of Electronic Engineering, Tsinghua University, Beijing, P.R. China.; Beijing National Research Center for Information Science and Technology(BNRist), and also with the Department of Electronic Engineering, Tsinghua University, Beijing, P.R. China.; Beijing National Research Center for Information Science and Technology(BNRist), and also with the Department of Electronic Engineering, Tsinghua University, Beijing, P.R. China.; Department of Electronic Engineering, Hong Kong University of Science and Technology, Hong Kong.","IEEE Internet of Things Journal","","2019","PP","99","1","1","Heavy data load and wide cover range have always been crucial problems for big data processing in internet of things (IoT). Recently, mobile-edge computing (MEC) and unmanned aerial vehicle base stations (UAV-BSs) have emerged as promising techniques in IoT. In this paper, we propose a three-layer online data processing network based on MEC technique. On the bottom layer, raw data are generated by distributed sensors with local information. Upon them, UAV-BSs are deployed as moving MEC servers, which collect data and conduct initial steps of data processing. On top of them, a center cloud receives processed results and conducts further evaluation. For online processing requirements, the edge nodes should stabilize delay to ensure data freshness. Furthermore, limited onboard energy poses constraints to edge processing capability. In this paper, we propose an online edge processing scheduling algorithm based on Lyapunov Optimization. In cases of low data rate, it tends to reduce edge processor frequency for saving energy. In the presence of high data rate, it will smartly allocate bandwidth for edge data offloading. Meanwhile, hovering UAV-BSs bring a large and flexible service coverage, which results in path planning issue. In this paper, we also consider this problem and apply deep reinforcement learning to develop an online path planning algorithm. Taking observations of around environment as input, a CNN network is trained to predict action rewards. By simulations, we validate its effectiveness in enhancing service coverage. The result will contribute to big data processing in future IoT.","","","10.1109/JIOT.2019.2954825","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8908690","Big data;Internet of Things;Deep reinforcement learning;Edge computing;Online data processing.","Cloud computing;Internet of Things;Base stations;Distributed databases;Sensors;Big Data","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Convolutional Autoencoder based Feature Extraction and Clustering for Customer Load Analysis","S. Ryu; H. Choi; H. Lee; H. Kim","Electronic Engineering, Sogang University, Seoul Korea (the Republic of) 04107 (e-mail: shryu@sogang.ac.kr); Electronic Engineering, Sogang University, Seoul Korea (the Republic of) (e-mail: hyungeun@sogang.ac.kr); Encored Technologies, Seoul Korea (the Republic of) (e-mail: hslee@encoredtech.com); Electronic Engineering, Sogang University, 35014 Mapo-gu, Seoul Korea (the Republic of) (e-mail: hongseok@sogang.ac.kr)","IEEE Transactions on Power Systems","","2019","PP","99","1","1","As the number of smart meters increases, compression of metering data becomes essential for data transmission, storing and processing perspectives. Specifically, feature extraction can be used for the compression of metering data and further be utilized for smart grid applications such as customer clustering. So far, there are many studies for compression and clustering based on daily load profiles. However, in order to account for long-term characteristics of electricity consumption, utilizing yearly load profiles (YLPs) is vital for customer load clustering and analysis. In this paper, we propose a deep learning based YLP compression that jointly captures daily and seasonal variations. By leveraging convolutional autoencoder (CAE), YLPs in 8,640-dimensional space are compressed to 100-dimensional vectors. We apply the proposed CAE framework to YLPs of 1,405 residential customers and verify that the proposed CAE outperforms other dimensionality reduction methods in terms of reconstruction errors, e.g., by 19-40%, or the compression ratio is increased by 130% or higher than other methods for the same reconstruction error. In addition, clustering analysis is performed on the encoded YLPs. Our results confirm that year-round characteristics are well captured during the clustering process and also clearly visualized with load images.","","","10.1109/TPWRS.2019.2936293","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8807267","convolutional autoencoder;convolutional neural network;clustering;deep learning;load profile;smart grid","Feature extraction;Smart meters;Smart grids;Image reconstruction;Data compression;Dimensionality reduction;Encoding","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Clustering With Sample-Assignment Invariance Prior","X. Peng; H. Zhu; J. Feng; C. Shen; H. Zhang; J. T. Zhou","College of Computer Science, Sichuan University, Chengdu 610065, China.; Institute for Infocomm Research, ASTAR, Singapore 138632.; Department of Electrical and Computer Engineering, National University of Singapore, Singapore 119077.; School of Computer Science, The University of Adelaide, Adelaide, SA 5005, Australia.; College of Computer Science, Sichuan University, Chengdu 610065, China.; Institute of High Performance Computing, ASTAR, Singapore 138632 (e-mail: joey.tianyi.zhou@gmail.com).","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","12","Most popular clustering methods map raw image data into a projection space in which the clustering assignment is obtained with the vanilla k-means approach. In this article, we discovered a novel prior, namely, there exists a common invariance when assigning an image sample to clusters using different metrics. In short, different distance metrics will lead to similar soft clustering assignments on the manifold. Based on such a novel prior, we propose a novel clustering method by minimizing the discrepancy between pairwise sample assignments for each data point. To the best of our knowledge, this could be the first work to reveal the sample-assignment invariance prior based on the idea of treating labels as ideal representations. Furthermore, the proposed method is one of the first end-to-end clustering approaches, which jointly learns clustering assignment and representation. Extensive experimental results show that the proposed method is remarkably superior to 16 state-of-the-art clustering methods on five image data sets in terms of four evaluation metrics.","","","10.1109/TNNLS.2019.2958324","Fundamental Research Funds for the Central Universities; NFSC; Singapore Governments Research Innovation and Enterprise 2020 Plan Advanced Manufacturing and Engineering Domain; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8946880","Label as representation;least square regression;low-rank representation;subspace clustering.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Context-Aware Sliding Window for Sentiment Classification","M. A. Masood; R. A. Abbasi; N. W. Keong","Department of Computer Science, Quaid-i-Azam University, Islamabad, Pakistan.; Department of Computer Science, Quaid-i-Azam University, Islamabad, Pakistan.; School of Computer Science and Engineering, Nanyang Technological University, Singapore.","IEEE Access","","2019","PP","99","1","1","Sentiment classification is an active area of research with applications in many domains. Many researchers in the past have proposed techniques to identify sentiments with reasonable accuracy. However, the focus is more on the syntactic and semantic features of the documents. These features are effective but they ignore the user’s past sentiments. In this research, we hypothesize that the past sentiments help the classifier to effectively link the user’s history along with the contents of the current tweet. Thus, allowing learning algorithms to correlate past activities in determining the current sentiments. For this sake, we propose three sliding window features to accumulate past sentiments from the time series data. In this paper, we propose seven variations of Context-aware Sliding Window (CSW) features on different machine learning and deep learning algorithms. Furthermore, we propose a temporal dataset of user tweets, which is manually labeled by nine human annotators. The proposed dataset consists of 36 users having 4,557 tweets. Results indicate significant improvements over six state-of-the-art baseline methods.","","","10.1109/ACCESS.2019.2963586","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8948044","Sentiment classification;user history;temporal sliding window;deep learning;machine-learning;temporal dataset","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Image-based Service Recommendation System: A JPEG-Coefficient RFs Approach","F. Ullah; B. Zhang; R. U. Khan","School of Computer Engineering and Science, Shanghai University, 200444.; School of Computer Engineering and Science, Shanghai University, 200444.; IT Department, College of Computer, Qassim University, KSA and Intelligent Analytics Group (IAG), College of Computer, Qassim University, KSA.","IEEE Access","","2019","PP","99","1","1","Online shopping platforms are growing at an unprecedented rate all over the world. These platforms mostly rely on search engines, which are still primarily based on the knowledge-base and use keywords matching for finding similar products. However, customers want an interactive setup that is convenient and reliable for querying related products. In this paper, we propose a novel idea of searching for products in an online shopping system using an image-based approach. A user can provide, select, or click an image, and similar image-based products will be presented to the user. The proposed recommendation system is based on content-based image retrieval and is composed of two major phases; Phase 1 and Phase 2. In Phase 1, the proposed approach learns the class/type of the product. In Phase 2, the proposed recommendation system retrieves closely matched similar products. For Phase 1, the proposed approach creates a model of products using Machine Learning (ML). The model is then used to find the category of the test products. From the ML perspectives, we employ the Random Forests (RF) classifier, and for feature extraction, we use the JPEG coefficients. The dataset used for proof of concepts includes 20 categories of products. For image-based recommendation, the proposed RF model is evaluated for Phase 1 and Phase 2. In Phase 1, the evaluation of the proposed model generates a 75% accurate model. For performance enhancements, the RF model has been integrated into the Deep Learning (DL) setup achieving 84% accurate predictions. Based on the custom evaluation approach for Phase 2, the proposed recommendation approach achieves 98% correct recommendations, thus demonstrating its efficacy for the product recommendation in practical applications.","","","10.1109/ACCESS.2019.2962315","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8943224","Recommendation system;services;Machine learning;Random Forests;Deep Learning;SVM","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"An Effective MR-Guided CT Network Training for Segmenting Prostate in CT Images","W. Yang; Y. Shi; S. H. Park; M. Yang; Y. Gao; D. Shen","Nanjing Normal University, Nanjing China 210046 (e-mail: nju.yangwanqi@gmail.com); Computer Science, Nanjing University, Nanjing China 210046 (e-mail: syh@nju.edu.cn); Robotics Engineering, Daegu Gyeongbuk Institute of Science and Technology, Daegu Korea (the Republic of) 711-873 (e-mail: shpark13135@dgist.ac.kr); Computer Science, Nanjing Normal University - Xianlin Campus, 124193 Nanjing, Jiangsu China (e-mail: myang@njnu.edu.cn); The Department of Computer Science, Nanjing University, Nanjing China 210046 (e-mail: gaoy@nju.edu.cn); Department of Radiology and BRIC, University of North Carolina at Chapel Hill, Chapel Hill, North Carolina United States 27599 (e-mail: dgshen@med.unc.edu)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","Segmentation of prostate in medical imaging data (e.g., CT, MRI, TRUS) is often considered as a critical yet challenging task for radiotherapy treatment. It is relatively easier to segment prostate from MR images than from CT images, due to better soft tissue contrast of the MR images. For segmenting prostate from CT images, most previous methods mainly used CT alone, and thus their performances are often limited by low tissue contrast in the CT images. In this paper, we explore the possibility of using indirect guidance from MR images for improving prostate segmentation in the CT images. In particular, we propose a novel deep transfer learning approach, i.e., MR-guided CT network training (namely MICS-NET), which can employ MR images to help better learning of features in CT images for prostate segmentation. In MICS-NET, the guidance from MRI consists of two steps: (1) learning informative and transferable features from MRI and then transferring them to CT images in a cascade manner, and (2) adaptively transferring the prostate likelihood of MRI model (i.e., well-trained convnet by purely using MR images) with a view consistency constraint. To illustrate the effectiveness of our approach, we evaluate MICS-NET on a real CT prostate image set, with the manual delineations available as the ground truth for evaluation. Our methods generate promising segmentation results which achieve (1) six percentages higher Dice Ratio than the CT model purely using CT images and (2) comparable performance with the MRI model purely using MR images.","","","10.1109/JBHI.2019.2960153","National Natural Science Foundation of China; Natural Science Foundation of Jiangsu Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933421","Prostate Segmentation;Deep Transfer Learning;Fully Convolutional Network;Cascade Learning;View Consistency Constraint","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Generative Endmember Modeling: An Application to Unsupervised Spectral Unmixing","R. A. Borsoi; T. Imbiriba; J. C. M. Bermudez","Department of Electrical Engineering, Federal University of Santa Catarina (DEE–UFSC), Florianópolis, SC, Brazil, and with the Lagrange Laboratory, Université Cote d'Azur, Nice, France (e-mail: raborsoi@gmail.com); DEE–UFSC, Florianópolis, SC, Brazil, and is with the ECE department of the Northeastern University, Boston, MA, USA (e-mail: talesim@gmail.com); DEE–UFSC, Florianópolis, SC, Brazil, and with the Graduate Program on Electronic Engineering and Computing, Catholic University of Pelotas (UCPel) Pelotas, Brazil (e-mail: bermudez@lpds.ufsc.br)","IEEE Transactions on Computational Imaging","","2019","PP","99","1","1","Endmember (EM) spectral variability can greatly impact the performance of standard hyperspectral image analysis algorithms. Extended parametric models have been successfully applied to account for the EM spectral variability. However, these models still lack the compromise between flexibility and low-dimensional representation that is necessary to properly explore the fact that spectral variability is often confined to a low-dimensional manifold in real scenes. In this paper we propose to learn a spectral variability model directly from the observed data, instead of imposing it a priori. This is achieved through a deep generative EM model, which is estimated using a variational autoencoder (VAE). The encoder and decoder that compose the generative model are trained using pure pixel information extracted directly from the observed image, what allows for an unsupervised formulation. The proposed EM model is applied to the solution of a spectral unmixing problem, which we cast as an alternating nonlinear least-squares problem that is solved iteratively with respect to the abundances and to the low-dimensional representations of the EMs in the latent space of the deep generative model. Simulations using both synthetic and real data indicate that the proposed strategy can outperform the competing state-of-the-art algorithms.","","","10.1109/TCI.2019.2948726","Conselho Nacional de Desenvolvimento Científico e Tecnológico; Brazilian Education Ministry; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8878112","Hyperspectral data;endmember variability;generative models;deep neural networks;variational autoencoders;spectral unmixing","Computational modeling;Parametric statistics;Manifolds;Data models;Neural networks;Training data;Hyperspectral imaging","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Anti-Intelligent UAV Jamming Strategy via Deep Q-Networks","N. Gao; Z. Qin; X. Jing; Q. Ni; S. Jin","National Mobile Communications Research Laboratory, Southeast University, Nanjing 210096, China.; School of Electronic Engineering and Computer Science, Queen Mary University of London, London E1 4NS, U.K.; School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing 100876, China.; School of Computing and Communications, Lancaster University, Lancaster LA1 4WA, U.K.; National Mobile Communications Research Laboratory, Southeast University, Nanjing 210096, China.","IEEE Transactions on Communications","","2019","PP","99","1","1","The downlink communications are vulnerable to intelligent unmanned aerial vehicle (UAV) jamming attack. In this paper, we propose a novel anti-intelligent UAV jamming strategy, in which the ground users can learn the optimal trajectory to elude such jamming. The problem is formulated as a stackelberg dynamic game, where the UAV jammer acts as a leader and the ground users act as followers. First, as the UAV jammer is only aware of the incomplete channel state information (CSI) of the ground users, for the first attempt, we model such leader sub-game as a partially observable Markov decision process (POMDP). Then, we obtain the optimal jamming trajectory via the developed deep recurrent Q-networks (DRQN) in the three-dimension space. Next, for the followers sub-game, we use the Markov decision process (MDP) to model it. Then we obtain the optimal communication trajectory via the developed deep Q-networks (DQN) in the two-dimension space. We prove the existence of the stackelberg equilibrium and derive the closed-form expression for the stackelberg equilibrium in a special case. Moreover, some insightful remarks are obtained and the time complexity of the proposed defense strategy is analyzed. The simulations show that the proposed defense strategy outperforms the benchmark strategies.","","","10.1109/TCOMM.2019.2947918","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8873597","UAV;jamming;Markov decision process;deep Q-networks","Jamming;Base stations;Trajectory;Games;Unmanned aerial vehicles;Space stations;Security","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Improving Massive MIMO Message Passing Detectors with Deep Neural Network","X. Tan; X. Weihong; K. Sun; Y. Xu; Z. Zhang; X. You; C. Zhang","Southeast University, 12579 Nanjing, Jiangsu China (e-mail: tanxiaosi@seu.edu.cn); Southeast University, 12579 Nanjing, Jiangsu China (e-mail: xuweih0712@gmail.com); Southeast University, 12579 Nanjing, Jiangsu China (e-mail: kaisuncn@foxmail.com); Southeast University, 12579 Nanjing, Jiangsu China (e-mail: xuyunhao1996@126.com); School of Information Science and Engineering, Southeast University, Nanjing, Jiangsu China 210096 (e-mail: xhyu@seu.edu.cn); Southeast University, 12579 Nanjing, Jiangsu China 210096 (e-mail: chzhang@seu.edu.cn); Southeast University, 12579 Nanjing, Jiangsu China 210096 (e-mail: chzhang@seu.edu.cn)","IEEE Transactions on Vehicular Technology","","2019","PP","99","1","1","In this paper, deep neural network (DNN) is utilized to improve message passing detectors (MPDs) for massive multiple-input multiple-output (MIMO) systems. A general framework to construct DNN architecture for MIMO detection is first introduced by unfolding iterative MPDs. DNN MIMO detectors are then proposed based on modified MPDs including damped BP, max-sum (MS) BP, and simplified channel hardening-exploiting message passing (CHEMP). The correction factors are optimized via deep learning for better performance. Numerical results demonstrate that, compared with the state-of-the-art (SOA) detectors including MMSE, BP, and CHEMP, the proposed DNN detectors can achieve better bit-error-rate (BER) and improve robustness against various antenna and channel conditions with similar complexity. The DNN is required to be trained only once and can be reused for multiple detections, which assures its high efficiency. The corresponding hardware architecture is also proposed. Implementation results with 65 nm CMOS technology approve the efficiency and flexibility of the proposed DNN framework.","","","10.1109/TVT.2019.2960763","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8936847","Massive MIMO detection;message passing detector (MPD);deep neural network (DNN);low-complexity training;VLSI implementation","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"AbolDeepIO: A Novel Deep Inertial Odometry Network for Autonomous Vehicles","M. A. Esfahani; H. Wang; K. Wu; S. Yuan","School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore 639798.; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore 639798 (e-mail: hw@ntu.edu.sg).; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore 639798.; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore 639798.","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","10","Inertial measurement units (IMUs) suffer from bias and measurement noise, which makes it much more complicated to tackle the problem of inertial odometry (IO). Due to the error propagation over time, while estimating robot position, an inaccurate estimation or a small error will cause the odometry and a localization system unreliable and unusable in a split of seconds. This paper presents a novel triple-channel deep IO network architecture based on the physical and mathematical models of IMUs. The proposed method simulates the noise model in the training phase and becomes robust to noise during testing. Besides, the proposed network architecture also considers the time interval between two consecutive IMU readings (sampling time) so that it is robust to the change of IMU frequency and the missing of IMU information. To the best of our knowledge, this paper is the first work reviewing and analyzing the existing IO methods used by the deep-learning-based visual-IO approaches. The proposed network architecture outperforms all the existing solutions on the IMU readings of the challenging Micro Aerial Vehicle dataset and improves the accuracy by approximately 25%.","","","10.1109/TITS.2019.2909064","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8693766","Inertial odometry;inertial measurement unit (IMU);long short term memories (LSTM);deep neural network;visual-inertial odometry.","","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Modeling Obstructive Sleep Apnea voices using Deep Neural Network Embeddings and Domain-Adversarial Training","J. M. Perero-Codosero; F. Espinoza-Cuadros; J. Anton-Martin; M. A. Barbero-Alvarez; L. A. Hernandez","GAPS Signal Processing Applications Group, Universidad Politecnica de Madrid, 16771 Madrid Spain (e-mail: jmperero@sigma-ai.com); GAPS Signal Processing Applications Group, Universidad Politecnica de Madrid, 16771 Madrid Spain (e-mail: fmespinoza@sigma-ai.com); GAPS Signal Processing Applications Group, Universidad Politecnica de Madrid, 16771 Madrid Spain (e-mail: janton@sigma-ai.com); GAPS Signal Processing Applications Group, Universidad Politecnica de Madrid, 16771 Madrid Spain (e-mail: m.barbero@alumnos.upm.es); GAPS Signal Processing Applications Group, Universidad Politecnica de Madrid, 16771 Madrid Spain (e-mail: luisalfonso.hernandez@upm.es)","IEEE Journal of Selected Topics in Signal Processing","","2019","PP","99","1","1","Obstructive Sleep Apnea (OSA) is a sleep breathing disorder affecting at least 3-7% of male adults and 2-5% of female adults between 30 and 70 years. It causes recurrent partial or total obstruction episodes at the level of the pharynx which causes cessation of breath during sleep. The number of obstruction episodes per sleep hour, known as Apnea-Hypopnea Index (AHI), along with the degree of the daytime sleepiness, determine the severity of OSA. Usually, OSA is diagnosed at a Sleep Unit in a hospital by the time-consuming polysomnography (PSG) test. Based on the expected impact of anatomical and physiological effects of the altered structure of the upper airway in OSA patients’ voices, the assessment of OSA from speech has been proposed as a simple way to help in the diagnostic process. In this paper, we review previous research to assess OSA from speech and underline the difficulty of a weak connection between OSA and speech. We present results to model OSA using, to the best of our knowledge, for the first time Deep Learning on the largest existing database of OSA voice recordings and speakers’ clinical variables. Using state-of-the-art speaker recognition techniques: acoustic subspace modeling (i-vectors), and deep neural network embeddings (x-vectors), we confirm the weak connection between speech and OSA. We hypothesize that this weak effect is mediated by undesired sources of variability as speakers’ age, body mass index (BMI), or height, and we propose Domain-Adversarial Training (DAT) to remove them. Our results show that, taking BMI as adversarial domain, when classifying voices from OSA extreme cases (AHI ≤ 10 vs AHI ≥ 30) accuracy increases from 69.39% to 76.60%. We hope these results can encourage the use of adversarial-domain neural networks to remove the undesired effects of clinical variables or speaker factors when assessing health disorders from speech.","","","10.1109/JSTSP.2019.2957977","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8926341","Obstructive Sleep Apnea;speech;Subspace modeling;Deep Neural Network Embeddings;Domain-Adversarial Training","Sleep;Hidden Markov models;Neural networks;Indexes;Speaker recognition;Training","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Defocus Blur Detection via Multi-Stream Bottom-Top-Bottom Network","W. Zhao; F. Zhao; D. Wang; H. Lu","School of Information and, Dalian University of Technology, 12399 Dalian, Liaoning China (e-mail: zhaowenda@dlut.edu.cn); Dalian Institute of Chemical Physics, Chinese Academy, Dalian, Liaoning China (e-mail: zhaofan@dicp.ac.cn); Dalian University of Technology, Dalian, Liaoning China (e-mail: wdice@dlut.edu.cn); School of Information and Comunicaiton Engineering, Dalian univ. of Tech., dalian, Liaoning China (e-mail: lhchuan@dlut.edu.cn)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Defocus blur detection (DBD) is aimed to estimate the probability of each pixel being in-focus or out-of-focus. This process has been paid considerable attention due to its remarkable potential applications. Accurate differentiation of homogeneous regions and detection of low-contrast focal regions, as well as suppression of background clutter, are challenges associated with DBD. To address these issues, we propose a multi-stream bottom-top-bottom fully convolutional network (BTBNet), which is the first attempt to develop an end-to-end deep network to solve the DBD problems. First, we develop a fully convolutional BTBNet to gradually integrate nearby feature levels of bottom to top and top to bottom. Then, considering that the degree of defocus blur is sensitive to scales, we propose multi-stream BTBNets that handle input images with different scales to improve the performance of DBD. Finally, a cascaded DBD map residual learning architecture is designed to gradually restore finer structures from the small scale to the large scale. To promote further study and evaluation of the DBD models, we construct a new database of 1100 challenging images and their pixel-wise defocus blur annotations. Experimental results demonstrate that the proposed method achieves significantly better performance than other state-of-the-art algorithms.","","","10.1109/TPAMI.2019.2906588","China Postdoctoral Science Foundation; National Natural Science Foundation of China; Fundamental Research Funds for the Central; CCF-Tencent Open Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8673588","Defocus Blur Detection;Multi-Stream Bottom-Top-Bottom Network;Cascaded DBD Map Residual Learning","Feature extraction;Image edge detection;Streaming media;Semantics;Clutter;Image restoration;Deep learning","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Deep Attributed Network Embedding by Preserving Structure and Attribute Information","R. Hong; Y. He; L. Wu; Y. Ge; X. Wu","School of Computer and Information, Hefei University of Technology, Hefei 230009, China.; School of Computer and Information, Hefei University of Technology, Hefei 230009, China.; School of Computer and Information, Hefei University of Technology, Hefei 230009, China (e-mail: lewu.ustc@gmail.com).; Department of Management Information Systems, University of Arizona, Tucson, AZ 85721 USA.; School of Computing and Informatics, University of Louisiana at Lafayette, Lafayette, LA 70504 USA.","IEEE Transactions on Systems, Man, and Cybernetics: Systems","","2019","PP","99","1","12","Network embedding aims to learn distributed vector representations of nodes in a network. The problem of network embedding is fundamentally important. It plays crucial roles in many applications, such as node classification, link prediction, and so on. As the real-world networks are often sparse with few observed links, many recent works have utilized the local and global network structure proximity with shallow models for better network embedding. In reality, each node is usually associated with rich attributes. Some attributed network embedding models leveraged the node attributes in these shallow network embedding models to alleviate the data sparsity issue. Nevertheless, the underlying structure of the network is complex. What is more, the connection between the network structure and node attributes is also hidden. Thus, these previous shallow models fail to capture the nonlinear deep information embedded in the attributed network, resulting in the suboptimal embedding results. In this paper, we propose a deep attributed network embedding framework to capture the complex structure and attribute information. Specifically, we first adopt a personalized random walk-based model to capture the interaction between network structure and node attributes from various degrees of proximity. After that, we construct an enhanced matrix representation of the attributed network by summarizing the various degrees of proximity. Then, we design a deep neural network to exploit the nonlinear complex information in the enhanced matrix for network embedding. Thus, the proposed framework could capture the complex attributed network structure by preserving both the various degrees of network structure and node attributes in a unified framework. Finally, empirical experiments show the effectiveness of our proposed framework on a variety of network embedding-based tasks.","","","10.1109/TSMC.2019.2897152","National Key Research and Development Program of China; National Natural Science Foundation of China; Anhui Provincial Natural Science Foundation; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8654725","Attribute proximity;attributed network embedding;high-order proximity","Neural networks;Data models;Task analysis;Machine learning;Germanium;Social networking (online);Natural languages","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Deep Drone Racing: From Simulation to Reality With Domain Randomization","A. Loquercio; E. Kaufmann; R. Ranftl; A. Dosovitskiy; V. Koltun; D. Scaramuzza","Robotic and Perception Group, Department of Informatics, University of Zürich, 8006, Zürich, Switzerland, and also with the Department of Neuroinformatics, University of Zürich and ETH Zürich, 8057, Zürich, Switzerland (e-mail: loquercio@ifi.uzh.ch).; Robotic and Perception Group, Department of Informatics, University of Zürich, 8006, Zürich, Switzerland, and also with the Department of Neuroinformatics, University of Zürich and ETH Zürich, 8057, Zürich, Switzerland (e-mail: elia.kaufmann92@gmail.com).; Intelligent Systems Lab., Intel (e-mail: rene.ranftl@intel.com).; Intelligent Systems Lab., Intel (e-mail: adosovitskiy@gmail.com).; Intelligent Systems Lab., Intel (e-mail: vkoltun@gmail.com).; Robotic and Perception Group, Department of Informatics, University of Zürich, 8006, Zürich, Switzerland, and also with the Department of Neuroinformatics, University of Zürich and ETH Zürich, 8057, Zürich, Switzerland (e-mail: davide.scaramuzza@ieee.org).","IEEE Transactions on Robotics","","2019","PP","99","1","14","Dynamically changing environments, unreliable state estimation, and operation under severe resource constraints are fundamental challenges that limit the deployment of small autonomous drones. We address these challenges in the context of autonomous, vision-based drone racing in dynamic environments. A racing drone must traverse a track with possibly moving gates at high speed. We enable this functionality by combining the performance of a state-of-the-art planning and control system with the perceptual awareness of a convolutional neural network. The resulting modular system is both platform independent and domain independent: it is trained in simulation and deployed on a physical quadrotor without any fine-tuning. The abundance of simulated data, generated via domain randomization, makes our system robust to changes of illumination and gate appearance. To the best of our knowledge, our approach is the first to demonstrate zero-shot sim-to-real transfer on the task of agile drone flight. We extensively test the precision and robustness of our system, both in simulation and on a physical platform, and show significant improvements over the state of the art.","","","10.1109/TRO.2019.2942989","Intel Network on Intelligent Systems the Swiss National Center of Competence Research Robotics; Schweizerischer Nationalfonds zur Förderung der Wissenschaftlichen Forschung; Swiss National Science Foundation European Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8877728","Drone racing;learning agile flight;learning for control","Drones;Navigation;Trajectory;State estimation;Training;Robot sensing systems","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Structural Analysis of Attributes for Vehicle Re-Identification and Retrieval","Y. Zhao; C. Shen; H. Wang; S. Chen","College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou 310023, China.; School of Computer Science, The University of Adelaide, Adelaide, SA 5005, Australia.; Information Science and Technology College, Dalian Maritime University, Dalian 116026, China.; School of Computer Science and Technology, Zhejiang University of Technology, Hangzhou 310023, China, and also with the School of Computer Science and Engineering, Tianjin University of Technology, Tianjin 300384, China (e-mail: sy@ieee.org).","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","12","Vehicle re-identification plays an important role in video surveillance applications. Despite the efforts made on this problem in the past few years, it remains a challenging task due to various factors such as pose variation, illumination changes, and subtle inter-class difference. We believe that the key information for identification has not been well explored in the literature. In this paper, we first collect a vehicle dataset `VAC21' which contains 7129 images of five types of vehicles. Then, we carefully label the 21 classes of structural attributes hierarchically with bounding boxes. To our knowledge, this is the first dataset with several detailed attributes labeled. Based on this dataset, we use the state-of-the-art one-stage detection method, Single-shot Detection, as a baseline model for detecting attributes. Subsequently, we make a few important modifications tailored for this application to improve accuracy: 1) adding more proposals from low-level layers to improve the accuracy of detecting small objects and 2) employing the focal loss to improve the mean average precision. Furthermore, the results of the attribute detection can be applied to a series of vision tasks that focus on analyzing the images of vehicles. Finally, we propose a novel region of interests (ROIs)-based vehicle re-identification and retrieval method in which the ROIs' deep features are used as discriminative identifiers, encoding the structure information of a vehicle. These deep features are input to a boosting model to improve the accuracy. A set of experiments are conducted on the dataset VehicleID and the experimental results show that our method outperforms the state-of-the-art methods.","","","10.1109/TITS.2019.2896273","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8643580","Vehicle attribute detection;deep learning;vehicle re-identification;vehicle retrieval.","Feature extraction;Automobiles;Task analysis;Licenses;Cameras;Proposals;Surveillance","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Cooperative Computation Offloading and Resource Allocation for Blockchain-Enabled Mobile Edge Computing: A Deep Reinforcement Learning Approach","J. Feng; F. R. Yu; Q. Pei; X. Chu; J. Du; L. Zhu","State Key Laboratory of Integrated Services Networks (Xidian University), School of Telecomm. Engineering, Xidian University, Xi’an, Shaanxi, China.; Dept. of Systems and Computer Eng., Carleton University, Ottawa, ON, Canada.; State Key Laboratory of Integrated Services Networks (Xidian University), School of Telecomm. Engineering, Xidian University, Xi’an, Shaanxi, China.; University of Sheffield, S1 3JD, UK.; Shaanxi Key Laboratory of Information Communications, Xi’an University of Posts and Telecommunications, Xi’an, Shaanxi, China.; Beijing Jiaotong University Beijing, P.R. China.","IEEE Internet of Things Journal","","2019","PP","99","1","1","Mobile edge computing (MEC) is a promising paradigm to improve the quality of computation experience of mobile devices because it allows mobile devices to offload computing tasks to MEC servers, benefiting from the powerful computing resources of MEC servers. However, the existing computation-offloading works have also some open issues: 1) security and privacy issues, 2) cooperative computation offloading, and 3) dynamic optimization. To address the security and privacy issues, we employ blockchain technology that ensures the reliability and irreversibility of data in MEC systems. Meanwhile, we jointly design and optimize the performance of blockchain and MEC. In this paper, we develop a cooperative computation offloading and resource allocation framework for blockchain-enabled MEC systems. In the framework, we design a multi-objective function to maximize the computation rate of MEC systems and the transaction throughput of blockchain systems by jointly optimizing offloading decision, power allocation, block size and block interval. Due to the dynamic characteristics of the wireless fading channel and the processing queues at MEC servers, the joint optimization is formulated as a Markov decision process (MDP). To tackle the dynamics and complexity of the blockchain-enabled MEC system, we develop an A3C-based cooperation computation offloading and resource allocation algorithm to solve the MDP problem. In the algorithm, deep neural networks are optimized by utilizing asynchronous gradient descent and eliminating the correlation of data. Simulation results show that the proposed algorithm converges fast and achieves significant performance improvements over existing schemes in terms of total reward.","","","10.1109/JIOT.2019.2961707","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8941121","Mobile edge computing;blockchain;computation offloading;transaction throughput;A3C.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Computer Modeling of the Eddy Current Losses of Metal Fasteners in Rotor Slots of a Large Nuclear Steam Turbine Generator Based on Finite Element method and Deep Gaussian Process Regression","J. Zhao; H. Guo; L. Wang; M. Han","Faculty of Electronic Information and Electrical Engineering, Dalian University of Technology, China (e-mail: zjy@dlnu.edu.cn); Dalian Nationalities University, 66455 Dalian, Liaoning China (e-mail: guohai@dlnu.edu.cn); College of Electrical and Electronic Engineering, Harbin University of Science and Technology, Harbin, Heilongjiang China 150080 (e-mail: wlkhello@163.com); Dalian University of Technology, 12399 Dalian China 116024 (e-mail: minhan@dlut.edu.cn)","IEEE Transactions on Industrial Electronics","","2019","PP","99","1","1","Eddy current analysis is a key issue for large turbine generators. The finite element method (FEM) is a computational tool for obtaining the electromagnetic characteristics of electrical machines. In this paper, we propose a computer model of the eddy current losses of metal fasteners in the rotor slots of a large turbine generator. The electromagnetic properties of the rotor fasteners and the outer diameter of the rotor are taken as the input, and the eddy current loss of the rotor fasteners is taken as the output. A prediction model is constructed using the FEM and deep learning. The analysis results show that compared with independent finite element analysis, the method reduces the design cycle time and improves the design efficiency for a large-capacity turbine generator. Compared with other machine learning models, the error is smaller and the accuracy is higher. This method provides a new way to accurately predict the eddy current loss of a generator under complex nonlinear conditions.","","","10.1109/TIE.2019.2931487","National Natural Science Foundation of China; China Postdoctoral Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8786928","FEM simulation;nuclear power generator;generator performance prediction;deep Gaussian process regression;eddy current loss","Generators;Eddy currents;Turbines;Rotors;Mathematical model;Finite element analysis;Predictive models","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Using a Multi-task Recurrent Neural Network with Attention Mechanisms to Predict Hospital Mortality of Patients","R. Yu; Y. Zheng; R. Zhang; Y. Jiang; C. C. Y. Poon","Department of Surgery, The Chinese University of Hong Kong, Shatin Hong Kong (e-mail: yuruoxi@surgery.cuhk.edu.hk); Department of Surgery, The Chinese University of Hong Kong, Hong Kong Hong Kong (e-mail: ylzheng@surgery.cuhk.edu.hk); Department of Surgery, The Chinese University of Hong Kong, Shatin Hong Kong (e-mail: rzhang@surgery.cuhk.edu.hk); Department of Surgery, The Chinese University of Hong Kong, Shatin Hong Kong (e-mail: yjiang@surgery.cuhk.edu.hk); Department of Surgery, The Chinese University of Hong Kong, Shatin Hong Kong - (e-mail: cpoon@surgery.cuhk.edu.hk)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","Estimating hospital mortality of patients is important in assisting clinicians to make decisions and hospital providers to allocate resources. This paper proposed a multi-task recurrent neural network with attention mechanisms to predict patients' hospital mortality, using reconstruction of patients' physiological time series as an auxiliary task. Experiments were conducted on a large public electronic health record database, i.e. MIMIC-III. Fifteen physiological measurements during the first 24-hour of critical care were used to predict death before hospital discharge. Compared with the conventional Simplified Acute Physiology Score (SAPS-II), the proposed multi-task learning model achieved better sensitivity (0.503±0.020 versus 0.365±0.021), when predictions were made based on the same 24-hour observation period. The multitask learning model is recommended to be updated daily with at least a 6-hour observation period, in order for it to perform similarly or better than the SAPS-II. In the future, need of intervention can be considered as another task to further optimize the performance of the multi-task learning model.","","","10.1109/JBHI.2019.2916667","Innovation and Technology Commission; Research Grants Council of Hong Kong; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8713596","Deep features;deep learning;missing data;precision medicine;wearable sensing","Hospitals;Task analysis;Time series analysis;Predictive models;Biomedical monitoring;Databases","","","","","","","","","","IEEE","IEEE Early Access Articles"
"High-risk Prediction of Cardiovascular Diseases via Attention-based Deep Neural Networks","Y. An; N. Huang; X. Chen; F. Wu; J. Wang","Institute of Information Security and Big Data, Central South University, 12570 Changsha, Hunan China 410083 (e-mail: anying@csu.edu.cn); Institute of Information Security and Big Data, Central South University, 12570 Changsha, Hunan China (e-mail: 164612233@csu.edu.cn); Institute of Information Security and Big Data, Central South University, 12570 Changsha, Hunan China (e-mail: chenxianlai@csu.edu.cn); Department of Mechanical Engineering, University of Saskatchewan, Saskatoon, Saskatchewan Canada S7N 5A9 (e-mail: faw341@mail.usask.ca); School of Computer Science and Engineering, Central South University, ChangSha, Hunan China (e-mail: jxwang@mail.csu.edu.cn)","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2019","PP","99","1","1","High-risk prediction of cardiovascular disease is of great significance and impendency in medical fields with the increasing phenomenon of sub-health these years. Most existing pathological methods for the prognosis prediction are either costly or prone to misjudgement. Therefore, plenty of automated models based on machine learning have been proposed to predict the onset of cardiovascular disease with the premorbid information of patients extracted from their historical Electronic Health Records (EHRs). However, it is a tough job to select proper features from longitudinal and heterogeneous EHRs, and also a great challenge to obtain accurate and robust representations for patients. In this paper, we propose an entirely end-to-end model called DeepRisk based on attention mechanism and deep neural networks, which can not only learn high-quality features automatically from EHRs, but also efficiently integrate heterogeneous and time-ordered medical data, and finally predict patients' risk of cardiovascular diseases. Experiments are carried out on a real medical dataset and results show that DeepRisk can significantly improve the high-risk prediction accuracy for cardiovascular disease compared with state-of-the-art approaches.","","","10.1109/TCBB.2019.2935059","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798764","High-risk prediction;deep neural network;attention mechanism;cardiovascular diseases","Medical diagnostic imaging;Predictive models;Cardiovascular diseases;Neural networks;Data models;Feature extraction","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Manipulation Skill Acquisition for Robotic Assembly Based on Multi-Modal Information Description","F. Li; Q. Jiang; W. Quan; S. Cai; R. Song; Y. Li","School of Control Science and Engineering, Shandong University, Jinan, 250061, China.; School of Control Science and Engineering, Shandong University, Jinan, 250061, China.; School of Control Science and Engineering, Shandong University, Jinan, 250061, China.; School of Mechanical Engineering, Zhejiang University of Technology, Hangzhou, 310023, China.; School of Control Science and Engineering, Shandong University, Jinan, 250061, China.; School of Control Science and Engineering, Shandong University, Jinan, 250061, China.","IEEE Access","","2019","PP","99","1","1","Automatic assembly of elastic components is difficult because of the potential deformation of parts during the assembly process. Consequently, robots cannot adapt their manipulation to dynamic changes. Designing systems that learn assembly skills can help in alleviating the uncertain factor for industrial-grade assembly robots. This study proposes a skill acquisition method based on multi-modal information description to realize the assembly of systems with elastic components. This multi-modal information includes two-dimensional images, poses, forces/torques, and robot joint parameters. In this method, robots acquire searching, location determination, and pose adjustment skills using these multi-modal information parameters. As a result, robots can reach the assembly target by analyzing two-dimensional images with no position constraint. While acquiring pose adjustment skills, the reward function with depth and assembly steps is used to improve the learning efficiency. The deep deterministic policy gradient (DDPG) algorithm is applied for acquiring skills. Experiments using a KUKA iiwa robot demonstrated the effectiveness and conciseness of our method. Our results indicate that the robot acquired searching, location determination, and pose adjustment skills that allowed it to successfully complete elastic assembly.","","","10.1109/ACCESS.2019.2934174","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8793056","Industrial Robots;Acquisition of Manipulation Skills;Deep Reinforcement Learning;Multi-modal Information Description","Robotic assembly;Service robots;Robot kinematics;Task analysis;Strain;Reinforcement learning","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Deep Learning with Persistent Homology for Orbital Angular Momentum (OAM) Decoding","S. Rostami; W. Saad; C. S. Hong","Huawei Technologies Oy (Finland) Co. Ltd, Helsinki, Finland.; Bradley Department of Electrical and Computer Engineering, Virginia Tech, USA.; Department of Computer Science and Engineering, Kyung Hee University, South Korea.","IEEE Communications Letters","","2019","PP","99","1","1","Orbital angular momentum (OAM)-encoding has recently emerged as an effective approach for increasing the channel capacity of free-space optical communications. In this paper, OAM-based decoding is formulated as a supervised classification problem. To maintain lower error rate in presence of severe atmospheric turbulence, a new approach that combines effective machine learning tools from persistent homology and convolutional neural networks (CNNs) is proposed to decode the OAM modes. A Gaussian kernel with learnable parameters is proposed in order to connect persistent homology to CNN, allowing the system to extract and distinguish robust and unique topological features for the OAM modes. Simulation results show that the proposed approach achieves up to 20% gains in classification accuracy rate over state-of-the-art of method based on only CNNs. These results essentially show that geometric and topological features play a pivotal role in the OAM mode classification problem.","","","10.1109/LCOMM.2019.2954311","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8906044","OAM;convolutional neural networks;persistent homology;free-space optical communication","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Simultaneous Bearing Fault Recognition and Remaining Useful Life Prediction Using Joint Loss Convolutional Neural Network","R. Liu; B. Yang; A. G. Hauptmann","School of Computer Science, Carnegie Mellon University, 6612 Pittsburgh, Pennsylvania United States 15213-3815 (e-mail: liuruonan04@163.com); School of Electrical and Electronic Engineering, The University of Manchester, 5292 Manchester United Kingdom of Great Britain and Northern Ireland M13 9PL (e-mail: yangboyuanxjtu@163.com); Carnegie Mellon University School of Computer Science, 415699 Pittsburgh, Pennsylvania United States 15213-3890 (e-mail: alex@cs.cmu.edu)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","Fault diagnosis and remaining useful life (RUL) prediction are always two major issues in modern industrial systems, which are usually regarded as two separated tasks to make the problem easier but ignore the fact that there are certain information of these two tasks can be shared to improve the performance. Therefore, to capture common features between different relative problems, a joint-loss convolutional neural network (JL-CNN) architecture is proposed in this paper, which can implement bearing fault recognition and RUL prediction in parallel by sharing the parameters and partial networks, meanwhile keeping the output layers of different tasks. The JL-CNN is constructed based on a CNN, which is a widely used deep learning method because of its powerful feature extraction ability. During optimization phase, a joint-loss function is designed to enable the proposed approach to learn the diagnosis-prognosis features and improve generalization while reducing the overfitting risk and computation cost. Moreover, because the information behind the signals of different problems has been shared and exploited deeper, the generalization and the accuracy of results can also be improved. Finally, the effectiveness of the JL-CNN method is validated by run-to-failure dataset. Compared with support vector regression (SVR) and traditional CNN, the MSE of the proposed method decreases 82.7% and 24.9% respectively. Therefore, results and comparisons show that the proposed method can be applied for the inter-crossed applications between fault diagnosis and RUL prediction.","","","10.1109/TII.2019.2915536","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8709822","Joint-loss learning;bearing;fault diagnosis;remaining useful life prediction;deep learning","Task analysis;Fault diagnosis;Convolution;Hidden Markov models;Feature extraction;Neural networks;Mathematical model","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Fault Diagnosis Framework of Rolling Bearing using Adaptive Sparse Contrative Auto-encoder with Optimized Unsupervised Extreme Learning Machine","X. Zhao; M. Jia; Z. Liu; P. Ding; C. Yang; L. Zhu","School of Mechanical Engineering, Southeast University, Nanjing 211189, China and Faculty of Applied Science, School of Engineering, The University of British Columbia, Kelowna, BC V1V 1V7, Canada.; School of Mechanical Engineering, Southeast University, Nanjing 211189, China.; Faculty of Applied Science, School of Engineering, The University of British Columbia, Kelowna, BC V1V 1V7, Canada.; School of Mechanical Engineering, Southeast University, Nanjing 211189, China.; School of Mechanical Engineering, Southeast University, Nanjing 211189, China.; School of Mechanical Engineering, Yangzhou University, Yangzhou 225001, China.","IEEE Access","","2019","PP","99","1","1","Nowadays, the intelligent fault diagnosis based on deep learning have achieved remarkable results in the fields of the industrial equipment health monitoring and management. To implement the adaptive feature extraction and fault isolation for key components of rotating machinery (rolling bearings, etc.), two new algorithms, Adaptive Sparse Contrative Auto-encoder (ASCAE) algorithm and Optimized Unsupervised Extreme Learning Machine (OUSELM) classifier by Cuckoo Search Algorithm (CSA), can be firstly designed in this paper, respectively. Furthermore, a new rolling bearing fault diagnosis framework based on ASCAE combined with OUSELM is first of all proposed in this paper. Accordingly, this designed fault diagnosis framework can be divided into three main steps: i). Firstly, the vibration signals of rolling bearings can be collected and processed on the key components of rotating machinery, and then the collected vibration signals can be accordingly converted into frequency signals; ii). Secondly, the transformed spectral signals can be entered into the constructed ASCAE for feature learning to exploit the multi-layer sensitive features from the hidden raw data; iii). Thirdly, the extracted multi-layer sensitive features can be flowed into the trained OUSELM classifier for unsupervised fault state separation and diagnosis. More specifically, our designed fault diagnosis framework (ASCAE-OUSELM) can employ the homotopy regularization theory, sparse theory, intelligent optimization algorithm and other tools to optimize the parameters and improve the performance of the original Contrative Auto-encoder (CAE) algorithm and Unsupervised Extreme Learning Machine (USLEM) algorithm, respectively. At the same time, the proposed fault diagnosis framework can achieve effective sparse and sensitive feature information extraction in the feature extraction stage (ASCAE) to avoid over-fitting. In fault isolation stage, the issue of the supervised and low training efficiency caused by traditional deep learning model can be perfectly addressed by OUSELM. Eventually, the experimental data of rolling bearings validated the effectiveness of the proposed fault diagnosis framework and two deigned algorithms.","","","10.1109/ACCESS.2019.2963193","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8945331","rolling bearings;fault diagnosis framework;homotopy regularization;Adaptive Sparse Contrative Auto-encoder (ASCAE);Optimized Unsupervised extreme learning machine (OUSELM);Cuckoo Search Algorithm (CSA)","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"ALS Point Cloud Classification With Small Training Data Set Based on Transfer Learning","C. Zhao; H. Guo; J. Lu; D. Yu; D. Li; X. Chen","Information Engineering University, Zhengzhou 450001, China (e-mail:hehe549124@outlook.com).; Information Engineering University, Zhengzhou 450001, China.; Information Engineering University, Zhengzhou 450001, China (e-mail:ljhb45@126.com).; Information Engineering University, Zhengzhou 450001, China.; Information Engineering University, Zhengzhou 450001, China.; Beijing Institute of Tracking and Telecommunications Technology, Beijing 100094, China.","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","Point cloud classification of airborne light detection and ranging (LiDAR) data is essential to extract geoinformation. Although deep learning provides a new approach for classification, the time-consuming training process and data dependence prevent its widespread application to point clouds. To solve these problems and leverage the potential of high-performing neural networks, we propose an airborne LiDAR point cloud classification method based on transfer learning. A strategy to generate feature images considering the point cloud spatial distribution is first introduced for applying traditional convolutional neural networks to point clouds. Then, transfer learning is used to extract multiscale and multiview deep features. A simple neural network classifier is designed to reduce dimensionality, fuse and learn high-level features, and postprocessing considering contextual information further improves the classification accuracy. We verified the performance of the proposed method through experiments on two airborne LiDAR data sets with different characteristics and containing eight classes. The results demonstrate that the proposed method can achieve a satisfactory classification accuracy with relatively short training time and less training samples than if using conventional methods.","","","10.1109/LGRS.2019.2947608","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8887291","Airborne light detection and ranging (LiDAR);classification;feature image;point cloud;small training data set;transfer learning.","Three-dimensional displays;Feature extraction;Training;Laser radar;Training data;Neural networks;Data mining","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Mining Likely Analogical APIs across Third-Party Libraries via Large-Scale Unsupervised API Semantics Embedding","C. Chen; Z. Xing; Y. Liu; K. L. X. Ong","Faculty of Information Technology, Monash University, Melbourne, Victoria Australia (e-mail: chunyang.chen@monash.edu); Research School of Computer Sciecne, Australian National University, Canberra, Australian Capital Territory Australia (e-mail: zhenchang.xing@anu.edu.au); School of Computer Engineering, Nanyang Technological University, Singapore, Singapore Singapore 639798 (e-mail: yangliu@ntu.edu.sg); School of Computer Science and Engineering, Nanayng Technological University, Singapore, Singapore Singapore (e-mail: kent0002@e.ntu.edu.sg)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Establishing API mappings between third-party libraries is a prerequisite step for library migration tasks. Manually establishing API mappings is tedious due to the large number of APIs to be examined. Having an automatic technique to create a database of likely API mappings can significantly ease the task. Unfortunately, existing techniques either adopt supervised learning mechanism that requires already-ported or functionality similar applications across major programming languages or platforms, which are difficult to come by for an arbitrary pair of third-party libraries, or cannot deal with lexical gap in the API descriptions of different libraries. To overcome these limitations, we present an unsupervised deep learning based approach to embed both API usage semantics and API description (name and document) semantics into vector space for inferring likely analogical API mappings between libraries. Based on deep learning models trained using tens of millions of API call sequences, method names and comments of 2.8 millions of methods from 135,127 GitHub projects, our approach significantly outperforms other deep learning or traditional information retrieval (IR) methods for inferring likely analogical APIs. We implement a proof-of-concept website which can recommend analogical APIs for 583,501 APIs of 111 pairs of analogical Java libraries with diverse functionalities. This scale of third-party analogical-API database has never been achieved before.","","","10.1109/TSE.2019.2896123","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8630054","Analogical API;Word embedding;Skip thoughts","Libraries;Semantics;Databases;Task analysis;Recurrent neural networks;Deep learning;Java","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"GANE: A Generative Adversarial Network Embedding","H. Hong; X. Li; M. Wang","School of Computer Science, Beijing Institute of Technology, Beijing 100081, China.; School of Computer Science, Beijing Institute of Technology, Beijing 100081, China (e-mail: xinli@bit.edu.cn).; Business School, University of the Sunshine Coast, Sippy Downs, QLD 4556, Australia.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","11","Network embedding is capable of providing low-dimensional feature representations for various machine learning applications. Current work focuses on: 1) designing the embedding as an unsupervised learning task to explicitly preserve the structural connectivity in the network or 2) generating the embedding as a by-product during the supervised learning of a specific discriminative task in a deep neural network. In this paper, we aim to take advantage of these two lines of research in the view of multi-output learning. That is, we propose a generative adversarial network embedding (GANE) model to adapt the generative adversarial framework to achieve the network embedding learning during the specific machine learning tasks. GANE has a generator to generate link edges, and a discriminator to distinguish the generated link edges from real connections (edges) in the network. Wasserstein-1 distance is adopted to train the generator to gain better stability. GANE is further extended by utilizing the pairwise connectivity of vertices to preserve the structural information in the original network. Experiments with real-world network data sets demonstrate that our models constantly outperform state-of-the-art solutions with significant improvements for the tasks of link prediction, clustering, and network alignment.","","","10.1109/TNNLS.2019.2921841","National Basic Research Program of China (973 Program); National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8758400","Generative adversarial model;link prediction;network alignment;network embedding;Wasserstein distance.","Task analysis;Generators;Generative adversarial networks;Predictive models;Machine learning;Linear programming;Gallium nitride","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Improving Data Analytics with Fast and Adaptive Regularization","Z. Luo; S. Cai; G. Chen; J. Gao; W. Lee; K. Y. Ngiam; M. Zhang","Schoool of Computing, National University of Singapore, Singapore, Singapore Singapore (e-mail: zhaojing@comp.nus.edu.sg); Schoool of Computing, National University of Singapore, Singapore, Singapore Singapore (e-mail: shaofeng@comp.nus.edu.sg); Colleague of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang China 310058 (e-mail: cg@zju.edu.cn); Schoool of Computing, National University of Singapore, Singapore, Singapore Singapore (e-mail: jinyang.gao@comp.nus.edu.sg); Computer Science and Engineering, Penn State University, University Park, Pennsylvania United States 16802 (e-mail: wlee@cse.psu.edu); National University Health System, National University Health System, 150744 Singapore, Singapore Singapore (e-mail: kee_yuan_ngiam@nuhs.edu.sg); School of Computer Science and Technology, Beijing Institute of Technology, Beijing, Beijing China (e-mail: meihui_zhang@bit.edu.cn)","IEEE Transactions on Knowledge and Data Engineering","","2019","PP","99","1","1","Deep Learning and Machine Learning models have recently been shown to be effective in many real world applications. While these models achieve better predictive performance, their structures have become more complex. A common problem for complex models is overfitting. Regularization is widely used to avoid overfitting. However, in most learning frameworks, regularization function is usually set with some hyper-parameters where the best setting is difficult to find. In this paper, we propose an adaptive regularization method, as part of a large end-to-end healthcare data analytics software stack, to address the above difficulty. First, we propose a general adaptive regularization method based on Gaussian Mixture (GM) to learn the best regularization function. Second, we develop an effective update algorithm which integrates Expectation Maximization (EM) with Stochastic Gradient Descent (SGD). Third, we design a lazy update and sparse update algorithm to reduce the computational cost by 4x and 20x respectively. The overall regularization framework is fast and adaptive. We validate the effectiveness of our regularization method through an extensive experimental study over 14 standard benchmark datasets and three kinds of deep learning/machine learning models. The results illustrate that our proposed adaptive regularization method achieves significant improvement over state-of-the-art regularization methods.","","","10.1109/TKDE.2019.2916683","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8713578","Adaptive Regularization;Data Analytics;Complex Analytics;Data Science;Knowledge Discovery and Data Mining","Adaptation models;Training;Tools;Computational modeling;Deep learning;Data analysis;Data models","","","","","","","","","","IEEE","IEEE Early Access Articles"
"LSTM Learning with Bayesian and Gaussian Processing for Anomaly Detection in Industrial IoT","D. Wu; Z. Jiang; X. Xie; X. Wei; W. Yu; R. Li","Hunan University, Changsha China 410082 (e-mail: dwu3@ics.uci.edu); Department of Computer Engineering, Hunan University, Changsha China 410082 (e-mail: peter_bon@hnu.edu.cn); Department of Computer Engineering, Hunan University, Changsha China 410082 (e-mail: xietls@hnu.edu.cn); Department of Computer Science and Engineering, Southern University of Science and Technology, 255310 Shenzhen China 518055 (e-mail: weix2@ucmail.uc.edu); Department of Computer Science, University of Warwick, Coventry United Kingdom of Great Britain and Northern Ireland CV4 7AL (e-mail: w.yu3@aston.ac.uk); College of Computer Science and Electronic Engineering, Hunan University, Changsha, Hunan China 410082 (e-mail: lirenfa@hnu.edu.cn)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","The data generated by millions of sensors in Industrial Internet of Things (IIoT) is extremely dynamic, heterogeneous, and large scale. It poses great challenges on the real-time analysis and decision making for anomaly detection in IIoT. In this paper, we propose a LSTM-Gauss-NBayes method, which is a synergy of the long short-term memory neural network (LSTM-NN) and the Gaussian Bayes model for outlier detection in IIoT. In a nutshell, the LSTM-NN builds model on normal time series. It detects outliers by utilising the predictive error for the Gaussian Naive Bayes model. Our method exploits advantages of both LSTM and Gaussian Naive Bayes models, which not only has strong prediction capability of LSTM for future time point data, but also achieves an excellent classification performance of Gaussian Naive Bayes model through the predictive error. Empirical studies demonstrate our solution outperforms the best-known competitors, which is a preferable choice for detecting anomalies.","","","10.1109/TII.2019.2952917","HuXiang Youth Talent Program; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8896029","Industrial Internet of Things;anomaly detection;deep learning","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Hyperdimensional Computing with Local Binary Patterns: One-shot Learning for Seizure Onset Detection and Identification of Ictogenic Brain Regions from Short-time iEEG Recordings","A. Burrello; K. A. Schindler; L. Benini; A. Rahimi","D-ITET, ETHZ, Zorich Switzerland 8044 (e-mail: alessio.burrello@studenti.polito.it); Sleep-Wake-Epilepsy-Center (SWEZ), Department of Neurology, Inselspital, Bern University Hospital, University Bern, 3010 Bern Switzerland (e-mail: kaspar.schindler@insel.ch); Integrated Systems Laboratory, ETHZ, Zurich Switzerland (e-mail: lbenini@iis.ee.ethz.ch); Eidgenossische Technische Hochschule Zurich Institut fur Integrierte Systeme, 31060 Zurich, ZH Switzerland (e-mail: abbas@ee.ethz.ch)","IEEE Transactions on Biomedical Engineering","","2019","PP","99","1","1","Objective: We develop a fast learning algorithm combining symbolic dynamics and brain-inspired hyperdimensional computing for both seizure onset detection and identification of ictogenic (seizure generating) brain regions from intracranial electroencephalography (iEEG). Methods: Our algorithm first transforms iEEG time series from each electrode into symbolic local binary pattern codes from which a holographic distributed representation of the brain state of interest is constructed across all the electrodes and over time in a hyperdimensional space. The representation is used to quickly learn from few seizures, detect their onset, and identify the spatial brain regions that generated them. Results: We assess our algorithm on our dataset that contains 99 short-time iEEG recordings from 16 drug-resistant epilepsy patients being implanted with 36 to 100 electrodes. For the majority of the patients (10 out of 16), our algorithm quickly learns from one or two seizures and perfectly (100%) generalizes on novel seizures using k-fold cross-validation. For the remaining six patients, the algorithm requires three to six seizures for learning. Our algorithm surpasses the state-of-the-art including deep learning algorithms by achieving higher specificity (94.84% vs. 94.77%) and macroaveraging accuracy (95.42% vs. 94.96%), and 74x lower memory footprint, but slightly higher average latency in detection (15.9 s vs. 14.7 s). Moreover, the algorithm can reliably identify (with a p-value < 0.01) the relevant electrodes covering an ictogenic brain region at two levels of granularity: cerebral hemispheres and lobes. Conclusion and significance: Our algorithm provides: (1) a unified method for both learning and classification tasks with end-to-end binary operations; (2) one-shot learning from seizure examples; (3) linear computational scalability for increasing number of electrodes; (4) generation of transparent codes that enables post-translational supports for clinical decision making.","","","10.1109/TBME.2019.2919137","European Unions Horizon 2020 research and innovation programme under grant agreement; ETHZ Postdoctoral Fellowship Program the Marie Curie Actions for People COFUND Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8723166","iEEG;one-shot learning;local binary patterns;symbolic dynamics;hyperdimensional computing;seizure detection;localization of seizure onset zone","Electrodes;Heuristic algorithms;Epilepsy;Prototypes;Histograms;Surgery;Feature extraction","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Co-saliency Detection via Stacked Autoencoder-enabled Fusion and Self-trained CNNs","C. Tsai; K. Hsu; Y. Lin; X. Qian; Y. Chuang","Electrical and Computer Engineering, Texas A&M University, College Station, Texas United States (e-mail: chungchi@tamu.edu); Research Center for Information Technology Innovation, Academia Sinica, 38017 Taipei Taiwan (e-mail: kuang.jui.hsu@gmail.com); Computer Science, National Chiao Tung University, 34914 Hsinchu Taiwan (e-mail: yylin@citi.sinica.edu.tw); Electrical and Computer Engineering, Texas A&M University, College Station, Texas United States (e-mail: xqian@ece.tamu.edu); Dept. of Computer Science & Information Engineering, National Taiwan Univesity, Taipei Taiwan 10617 (e-mail: cyy@csie.ntu.edu.tw)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","Image co-saliency detection via fusion-based or learning-based methods faces cross-cutting issues. For fusion-based methods, they combine saliency proposals using a majority voting rule. Their performance hence highly depends on the quality and coherence of individual proposals. For learning-based methods, they typically require ground truth annotations for training, which are not available for co-saliency detection. In this work, we present a two-stage approach to address these issues jointly. At the first stage, an unsupervised deep learning model with stacked autoencoder (SAE) is proposed to evaluate the quality of saliency proposals. It employs latent representations for image foregrounds, and auto-encodes foreground consistency and foreground-background distinctiveness in a discriminative way. The resultant model, SAE-enabled fusion (SAEF), can combine multiple saliency proposals to yield a more reliable saliency map. At the second stage, motivated by the fact that fusion often leads to over-smoothed saliency maps, we develop self-trained convolutional neural networks (STCNN) to alleviate this negative effect. STCNN takes the saliency maps produced by SAEF as inputs. It propagates information from regions of high confidence to those of low confidence. During propagation, feature representations are distilled, resulting in sharper and better co-saliency maps. Our approach is comprehensively evaluated on three benchmarks, including MSRC, iCoseg, and Cosal2015, and performs favorably against the state-of-the-arts. In addition, we demonstrate that our method can be applied to object co-segmentation and object co-localization, achieving the state-of-the-art performance in both applications.","","","10.1109/TMM.2019.2936803","MOST Joint Research Center for AI Technology and All Vista Healthcare; National Science Foundation; Ministry of Science and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8809285","Co-saliency detection;stacked autoencoder;reconstruction residual;adaptive fusion;optimization;self-paced learning;CNNs","Proposals;Saliency detection;Image segmentation;Image reconstruction;Reliability;Task analysis;Fuses","","","","","","","","","","IEEE","IEEE Early Access Articles"
"DenseX-Net: An End-to-End Model for Lymphoma Segmentation in Whole-body PET/CT Images","H. Li; H. Jiang; S. Li; M. Wang; Z. Wang; G. Lu; J. Guo; Y. Wang","Software College, Northeastern University, Shenyang, 110819, China.; Software College, Northeastern University, Shenyang, 110819, China and Key Laboratory of Intelligent Computing in Medical Image, Ministry of Education, Northeastern University, Shenyang, 110819, China.; Software College, Northeastern University, Shenyang, 110819, China.; Software College, Northeastern University, Shenyang, 110819, China.; Department of Nuclear Medicine, General Hospital of Northern Military Area, Shenyang, 110016, China.; Department of Nuclear Medicine, General Hospital of Northern Military Area, Shenyang, 110016, China.; Department of Nuclear Medicine, General Hospital of Northern Military Area, Shenyang, 110016, China.; Department of Nuclear Medicine, General Hospital of Northern Military Area, Shenyang, 110016, China.","IEEE Access","","2019","PP","99","1","1","Automatic lymphoma detection and accurate lymphoma boundary delineation from whole body Positron Emission Tomography/Computed Tomography (PET/CT) scans are essential for surgical navigation and radiation therapy. Besides, labeling the data, which means contouring the lymphoma contour in images is time-consuming, operator intensive and subjective. Hence, this paper integrates the supervised learning and unsupervised learning to propose an end-to-end segmentation network, namely DenseX-Net, for both lymphoma detection and segmentation. There are two important flows in the proposed DenseX-Net. One is a reconstruction flow (based on the convolutional encoder-decoder form) that can be used for learning semantic representations of different lymphomas by minimizing the discrepancy between each input and its output in an unsupervised learning form. The other one is a segmentation flow (based on DenseU-Net) that performs the lymphoma segmentation task. Note that, the encoders in both flows are trained jointly with the same weights, which can facilitate DenseX-Net obtaining the accurate segmentation using a little labeled data. We evaluate our proposed DenseX-Net for lymphoma segmentation on 80 real PET/CT cases (from General Hospital of Northern Military Area) with a Dice coefficient of 72.84%. Experimentations and comparisons demonstrate the accuracy and robustness of DenseX-Net as well as its performance advantages as compared with related segmentation networks.","","","10.1109/ACCESS.2019.2963254","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8946601","Lymphoma segmentation;Deep learning;PET/CT;Semi-supervised learning;Computer aided diagnosis","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Robust Malware Defense in Industrial IoT Applications using Machine Learning with Selective Adversarial Samples","M. E. Khoda; T. Imam; J. Kamruzzaman; I. Gondal; A. Rahman","IT, Federation University Australia - Gippsland Campus, 72534 Churchill, Victoria Australia (e-mail: m.khoda@federation.edu.au); CQ University - Melbourne Campus, 527838 Melbourne, Victoria Australia (e-mail: t.imam@cqu.edu.au); Federation University Australia, 1458 Ballarat, Victoria Australia 3353 (e-mail: joarder.kamruzzaman@federation.edu.au); Federation University Australia, 1458 Ballarat, Victoria Australia (e-mail: iqbal.gondal@federation.edu.au); Data61, 170512 Eveleigh, New South Wales Australia (e-mail: ashfaqur.rahman@data61.csiro.au)","IEEE Transactions on Industry Applications","","2019","PP","99","1","1","Industrial Internet of Things (IIoT) deploys edge devices to act as intermediaries between sensors and actuators and application servers or cloud services. Machine learning models have been widely used to thwart malware attacks in such edge devices. However, these models are vulnerable to adversarial attacks where attackers craft adversarial samples by introducing small perturbations to malware samples to fool a classifier to misclassify them as benign applications. Literature on deep learning networks proposes adversarial retraining as a defense mechanism where adversarial samples are combined with legitimate samples to retrain the classifier. However, existing works select such adversarial samples in a random fashion which degrades the classifier's performance. This work proposes two novel approaches for selecting adversarial samples to retrain a classifier. One, based on the distance from malware cluster center, and the other, based on a probability measure derived from a kernel based learning (KBL). Our experiments show that both of our sample selection methods outperform the random selection method and the KBL selection method improves detection accuracy by 6%. Also, while existing works focus on deep neural networks with respect to adversarial retraining, we additionally assess the impact of such adversarial samples on other classifiers and our proposed selective adversarial retraining approaches show similar performance improvement for these classifiers as well. The outcomes from the study can assist in designing robust security systems for IIoT applications.","","","10.1109/TIA.2019.2958530","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8930038","","Malware;Feature extraction;Machine learning;Sensors;Servers;Neural networks;Security","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Convolutional Neural Network With Adaptive Regularization to Classify Driving Styles on Smartphones","M. M. Bejani; M. Ghatee","Department of Computer Science, Amirkabir University of Technology, Tehran 15875-4413, Iran.; Department of Computer Science, Amirkabir University of Technology, Tehran 15875-4413, Iran (e-mail: ghatee@aut.ac.ir).","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","10","Driving style evaluation by smartphones depends on the quality of the features extracted from sensors data. Typically, these features are extracted based on experiments, expertness, or heuristics. In more modern approaches, some automatic methods such as convolutional neural network (CNN) are used to extract features including obvious and hidden ones. We also used the CNN on acceleration data collected by smartphones to extract the knowledge regarding driving style, vehicle, environment, and human characteristics. We found that this novel idea was more successful for evaluating the driving style compared with the previous machine learning algorithms. However, we faced over-fitting in the training process of the CNN and to avoid this, we proposed the state-of-the-art learning method applying two adaptive regularization schemes called adaptive dropout and adaptive weight decay. To evaluate these techniques, first, we checked the results on three popular large-scale datasets. When we proved the efficiency, we utilized them on two transportation data sets. In transportation-modes dataset, the accuracy was at least 95.8%'; and regarding the driving-style dataset, the classification accuracy was 95%. Thus, the adaptive regularized CNN is an amazing option for driving style evaluation on smartphones.","","","10.1109/TITS.2019.2896672","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8643569","Deep learning;driving style evaluation;smartphone sensors;convolutional neural network;adaptive regularization;over-fitting.","Feature extraction;Smart phones;Acceleration;Training;Vehicles;Data mining","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Manifold Sparse Auto-Encoder for Machine Fault Diagnosis","S. Zhang; M. Wang; F. Yang; W. Li","School of Mechanical and Automotive Engineering, South China University of Technology, Guangzhou 510641, China, and College of Mechanical Engineering, Dongguan University of Technology, Dongguan 523808, China.; College of Mechanical Engineering, Dongguan University of Technology, Dongguan 523808, China.; College of Mechanical Engineering, Dongguan University of Technology, Dongguan 523808, China.; School of Mechanical and Automotive Engineering, South China University of Technology, Guangzhou 510641, China.","IEEE Sensors Journal","","2019","PP","99","1","1","Although the use of deep learning algorithms to find effective features for fault diagnosis has somewhat enhanced of fault classification accuracy, the lack of guidelines the parameters such as layers of the deep learning architecture and dimension of each hidden-level has limited further improvement. Based on manifold mapping eigenvalues, an optimized deep learning model, called manifold sparse auto-encoder (MSAE) neural network, is constructed to diagnose the machine faults. Two main contributions of this paper can be summarized as: (1) Every encoding and decoding process is taken as a module to decline the vanishing gradient problem; (2) The dimension of each hidden layer is determined by the manifold mapping eigenvalues of hidden neurones, whereas the layers of the deep learning architecture are determined by the clustering distribution of features. Gearbox datasets demonstrated that the proposed MSAE can extract better discriminative high-level features and has a higher accuracy in machinery fault diagnosis compared with other machine learning methods.","","","10.1109/JSEN.2019.2925845","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8752020","Manifold sparse auto-encoder;Deep learning;Fault classification;Neural network","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Convolutional Neural Network for Convective Storm Nowcasting Using 3-D Doppler Weather Radar Data","L. Han; J. Sun; W. Zhang","College of Information Science and Engineering, Ocean University of China, Qingdao 266100, China.; National Center for Atmospheric Research, Boulder, CO 80301 USA.; College of Information Science and Engineering, Ocean University of China, Qingdao 266100, China (e-mail: weizhang@ouc.edu.cn).","IEEE Transactions on Geoscience and Remote Sensing","","2019","PP","99","1","9","Convective storms are one of the severe weather hazards found during the warm season. Doppler weather radar is the only operational instrument that can frequently sample the detailed structure of convective storm which has a small spatial scale and short lifetime. For the challenging task of short-term convective storm forecasting (i.e., nowcasting), 3-D radar images contain information about the processes in convective storm. However, effectively extracting such information from multisource raw data has been problematic due to a lack of methodology and computation limitations. Recent advancements in deep learning techniques and graphics processing units (GPUs) now make it possible. This article investigates the feasibility and performance of an end-to-end deep learning nowcasting method. The nowcasting problem was transformed into a classification problem first, and then, a deep learning method that uses a convolutional neural network (CNN) was presented to make predictions. On the first layer of CNN, a cross-channel 3-D convolution was proposed to fuse 3-D raw data. The CNN method eliminates the handcrafted feature engineering, i.e., the process of using domain knowledge of the data to manually design features. Operationally produced historical data of the Beijing-Tianjin-Hebei region in China was used to train the nowcasting system and evaluate its performance; 3,737,332 samples were collected in the training data set. The experimental results show that the deep learning method improves nowcasting skills compared with traditional machine learning methods.","","","10.1109/TGRS.2019.2948070","National Key Research and Development Program of China; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8897082","Convective storm forecasting;convolutional neural network (CNN);deep learning;weather radar.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Reinforcement-Learning-Based Relay Mobility and Power Allocation for Underwater Sensor Networks Against Jamming","L. Xiao; D. Jiang; Y. Chen; W. Su; Y. Tang","Department of Communication Engineering, Xiamen University, Xiamen 361005, China, and also with the National Mobile Communications Research Laboratory, Southeast University, Nanjing 210096, China (e-mail: lxiao@xmu.edu.cn).; Department of Communication Engineering, Xiamen University, Xiamen 361005, China (e-mail: winky1508@outlook.com).; Department of Communication Engineering, Xiamen University, Xiamen 361005, China (e-mail: 23320171153108@stu.xmu.edu.cn).; Department of Communication Engineering, Xiamen University, Xiamen 361005, China (e-mail: suweixiamen@xmu.edu.cn).; Department of Communication Engineering, Xiamen University, Xiamen 361005, China (e-mail: tyl@xmu.edu.cn).","IEEE Journal of Oceanic Engineering","","2019","PP","99","1","9","Underwater sensor networks (UWSNs) are vulnerable to jamming attacks due to the narrow frequency bandwidth and the fast fading channels. In this paper, we propose a reinforcement learning (RL)-based antijamming relay scheme for UWSNs that enables an underwater relay to decide whether to leave the heavily jammed location and choose the relay power based on the state that consists of the bit error rate of the previous transmission, the previous relay power, the current transmit power of the sensor, and the jamming power measured by the relay node. We also propose a deep-RL-based relay scheme to further improve the relay performance for the node that supports deep learning computation. We discuss the computational complexity of the deep-RL-based relay scheme and provide the relay performance bound regarding the bit error rate, energy consumption, and utility of the relay node. Experiments taken in a nonanechoic pool with underwater transducers against smart jamming attacks verify the analysis results. According to the experimental results, the proposed relay scheme can improve the relay performance compared with the benchmark underwater relay schemes.","","","10.1109/JOE.2019.2910938","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8718358","Jamming attacks;reinforcement learning (RL);relay;underwater sensor networks (UWSNs)","Relays;Jamming;Sensors;Bit error rate;Energy consumption;Computational modeling;Resource management","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Spatiotemporal Recurrent Convolutional Networks for Recognizing Spontaneous Micro-expressions","Z. Xia; X. Hong; X. Gao; X. Feng; G. Zhao","School of Electronics and Information, Northwestern Polytechnical University, Xian China (e-mail: xiazhaoqiang@gmail.com); Center for Machine Vision and Signal Analysis, University of Oulu, Oulu Finland 90014 (e-mail: xiaopeng.hong@oulu.fi); Institute of Computing Technology, Chinese Academy of Sciences, Beijing, US & Canada only China (e-mail: gxy9910@gmail.com); School of Electronics and Information, Northwestern Polytechnical University, Xian China (e-mail: fengxiao@nwpu.edu.cn); Center for Machine Vision and Signal Analysis, University of Oulu, Oulu Finland (e-mail: guoying.zhao@oulu.fi)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","Recently, the recognition task of spontaneous facial micro-expressions has attracted much attention with its various real-world applications. Plenty of handcrafted or learned features have been employed for a variety of classifiers and achieved promising performances for recognizing micro-expressions. However, the micro-expression recognition is still challenging due to the subtle spatiotemporal changes of micro-expressions. To exploit the merits of deep learning, we propose a novel deep recurrent convolutional networks based micro-expression recognition approach, capturing the spatiotemporal deformations of micro-expression sequence. Specifically, the proposed deep model is constituted of several recurrent convolutional layers for extracting visual features and a classificatory layer for recognition. It is optimized by an end-to-end manner and obviates manual feature design. To handle sequential data, we exploit two ways to extend the connectivity of convolutional networks across temporal domain, in which the spatiotemporal deformations are modeled in views of facial appearance and geometry separately. Besides, to overcome the shortcomings of limited and imbalanced training samples, two temporal data augmentation strategies as well as a balanced loss are jointly used for our deep network. By performing the experiments on three spontaneous micro-expression datasets, we verify the effectiveness of our proposed micro-expression recognition approach compared to the state-of-the-art methods.","","","10.1109/TMM.2019.2931351","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8777194","Micro-Expression Recognition;Spatiotemporal Modeling;Temporal Connectivity;Recurrent Convolutional Networks;Data Augmentation;Balanced Loss","Spatiotemporal phenomena;Feature extraction;Task analysis;Videos;Training;Strain;Deep learning","","","","2","","","","","","IEEE","IEEE Early Access Articles"
"Efficient Multi-View Multi-Target Tracking Using a Distributed Camera Network","L. He; G. Liu; G. Tian; J. Zhang; Z. Ji","School of Control Science and Engineering, Shandong University, Jinan, 250061 China.; School of Control Science and Engineering, Shandong University, Jinan, 250061 China.; School of Control Science and Engineering, Shandong University, Jinan, 250061 China.; School of Mechanical Engineering, Hebei University of Technology, Tianjin, 300131 China.; Robotics and Autonomous Systems Laboratory, School of Engineering, Cardiff University, Cardiff, CF10 3AT UK.","IEEE Sensors Journal","","2019","PP","99","1","1","In this paper, we propose a multi-target tracking method using a distributed camera network, which can effectively handle the occlusion and reidenfication problems by combining advanced deep learning and distributed information fusion. The targets are first detected using a fast object detection method based on deep learning. We then combine the deep visual feature information and spatial trajectory information in the Hungarian algorithm for robust targets association. The deep visual feature information is extracted from a convolutional neural network, which is pre-trained using a large-scale person reidentification dataset. The spatial trajectories of multiple targets in our framework are derived from a multiple view information fusion method, which employs an information weighted consensus filter for fusion and tracking. In addition, we also propose an efficient track processing method for ID assignment using multiple view information. The experiments on public datasets show that the proposed method is robust to solve the occlusion problem and reidentification problem, and can achieve superior performance compared to the state of the art methods.","","","10.1109/JSEN.2019.2949385","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8882315","Multi-target tracking;distributed camera network;information fusion;data association;SORT","Target tracking;Cameras;Visualization;Feature extraction;Object detection;Sensors;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Pulmonary Textures Classification via a Multi-Scale Attention Network","R. Xu; Z. Cong; X. Ye; Y. Hirano; S. Kido; T. Gyobu; Y. Kawata; O. Honda; N. Tomiyama","International School of Information Science and Engineering, Dalian, Liaoning China 116620 (e-mail: xurui@dlut.edu.cn); School of Software, Dalian University of Technology, 12399 Dalian, Liaoning China (e-mail: zhen.cong@qq.com); International School of Information Science and Engineering, Dalian Medical University, 36674 Dalian, Liaoning China (e-mail: yexch@dlut.edu.cn); Graduate School of Sciences and Technology for Innovation, Yamaguchi University, 13150 Ube, Yamaguchi Japan (e-mail: yhirano@yamaguchi-u.ac.jp); Graduate School of Medicine, Department of Diagnostic and Interventional Radiology, Osaka University, 13013 Suita, Osaka Japan (e-mail: kido@radiol.med.osaka-u.ac.jp); Uenokai Clinic, Osaka Japan (e-mail: t-gyobu@radiol.med.osaka-u.ac.jp); Sumitomo Hospital, Osaka Japan (e-mail: y-kawata0912@hotmail.co.jp); Graduate School of Medicine, Department of Diagnostic and Interventional Radiology, Osaka University, 13013 Suita, Osaka Japan (e-mail: ohonda@radiol.med.osaka-u.ac.jp); Graduate School of Medicine, Department of Diagnostic and Interventional Radiology, Osaka University, 13013 Suita, Osaka Japan (e-mail: tomiyama@radiol.med.osaka-u.ac.jp)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","Precise classification of pulmonary textures is crucial to develop a computer aided diagnosis (CAD) system of diffuse lung diseases (DLDs). Although deep learning techniques have been applied to this task, the classification performance is not satisfied for clinical requirements due to that commonly-used deep networks built by stacking convolutional blocks are not able to learn discriminative feature representation to distinguish complex pulmonary textures. For addressing this problem, we design a multi-scale attention network (MSAN) architecture comprised by several stacked residual attention modules followed by a multi-scale fusion module. Our deep network can not only exploit powerful information on different scales but also automatically select optimal features for more discriminative feature representation. Besides, we develop visualization techniques to make the proposed deep model transparent for humans. The proposed method is evaluated by using a large dataset. Experimental results show that our method has achieved the average classification accuracy of 94.78 and the average f-value of 0.9475 in the classification of 7 categories of pulmonary textures. Besides, visualization results intuitively explain the working behavior of the deep network. The proposed method has achieved the state-of-the-art performance to classify pulmonary textures on high resolution CT images.","","","10.1109/JBHI.2019.2950006","National Natural Science Foundation of China; Japanese MEXT Grant-in-Aid for Scientific Research on Innovative Areas; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8890695","","Network architecture;Lung;Deep learning;Visualization;Task analysis;Solid modeling;Computed tomography","","","","","","","","","","IEEE","IEEE Early Access Articles"
"How is Gaze Influenced by Image Transformations? Dataset and Model","Z. Che; A. Borji; G. Zhai; X. Min; G. Guo; P. Le Callet","Institute of Image Communication and Network Engineering, Shanghai Key Laboratory of Digital Media Processing and Transmissions, Shanghai Jiao Tong University, Shanghai 200240, China.; Senior research scientist at Markable AI Inc, Brooklyn, NY 11201, USA.; Institute of Image Communication and Network Engineering, Shanghai Key Laboratory of Digital Media Processing and Transmissions, Shanghai Jiao Tong University, Shanghai 200240, China.; Institute of Image Communication and Network Engineering, Shanghai Key Laboratory of Digital Media Processing and Transmissions, Shanghai Jiao Tong University, Shanghai 200240, China.; Institute of Deep Learning, Baidu Research, Beijing 100193, China, and Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, WV USA.; Équipe Image, Perception et Interaction, Laboratoire des Sciences du Numérique de Nantes, Université de Nantes, France.","IEEE Transactions on Image Processing","","2019","PP","99","1","1","Data size is the bottleneck for developing deep saliency models, because collecting eye-movement data is very time-consuming and expensive. Most of current studies on human attention and saliency modeling have used high-quality stereotype stimuli. In real world, however, captured images undergo various types of transformations. Can we use these transformations to augment existing saliency datasets? Here, we first create a novel saliency dataset including fixations of 10 observers over 1900 images degraded by 19 types of transformations. Second, by analyzing eye movements, we find that observers look at different locations over transformed versus original images. Third, we utilize the new data over transformed images, called data augmentation transformation (DAT), to train deep saliency models. We find that label-preserving DATs with negligible impact on human gaze boost saliency prediction, whereas some other DATs that severely impact human gaze degrade the performance. These label-preserving valid augmentation transformations provide a solution to enlarge existing saliency datasets. Finally, we introduce a novel saliency model based on generative adversarial networks (dubbed GazeGAN). A modified U-Net is utilized as the generator of the GazeGAN, which combines classic “skip connection” with a novel “center-surround connection” (CSC) module. Our proposed CSC module mitigates trivial artifacts while emphasizing semantic salient regions, and increases model nonlinearity, thus demonstrating better robustness against transformations. Extensive experiments and comparisons indicate that GazeGAN achieves state-of-the-art performance over multiple datasets. We also provide a comprehensive comparison of 22 saliency models on various transformed scenes, which contributes a new robustness benchmark to saliency community. Our code and dataset are available at.","","","10.1109/TIP.2019.2945857","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8866748","Human Gaze;Saliency Prediction;Data Augmentation;Generative Adversarial Networks;Model Robustness","Data models;Observers;Image resolution;Visualization;Mathematical model;Semantics;Robustness","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Learning Approach for Suture Thread Detection With Feature Enhancement and Segmentation for 3-D Shape Reconstruction","B. Lu; X. B. Yu; J. W. Lai; K. C. Huang; K. C. C. Chan; H. K. Chu","Department of Mechanical Engineering, The Hong Kong Polytechnic University, Hong Kong. He is now with the T-stone Robotics Institute, The Chinese University of Hong Kong, Hong Kong.; Department of Computing, The Hong Kong Polytechnic University, Hong Kong.; Department of Mechanical Engineering, The Hong Kong Polytechnic University, Hong Kong.; Department of Mechanical Engineering, The Hong Kong Polytechnic University, Hong Kong.; Department of Computing, The Hong Kong Polytechnic University, Hong Kong.; Department of Mechanical Engineering, The Hong Kong Polytechnic University, Hong Kong (e-mail: henry.chu@polyu.edu.hk).","IEEE Transactions on Automation Science and Engineering","","2019","PP","99","1","13","A vision-based system presents one of the most reliable methods for achieving an automated robot-assisted manipulation associated with surgical knot tying. However, some challenges in suture thread detection and automated suture thread grasping significantly hinder the realization of a fully automated surgical knot tying. In this article, we propose a novel algorithm that can be used for computing the 3-D coordinates of a suture thread in knot tying. After proper training with our data set, we built a deep-learning model for accurately locating the suture's tip. By applying a Hessian-based filter with multiscale parameters, the environmental noises can be eliminated while preserving the suture thread information. A multistencils fast marching method was then employed to segment the suture thread, and a precise stereomatching algorithm was implemented to compute the 3-D coordinates of this thread. Experiments associated with the precision of the deep-learning model, the robustness of the 2-D segmentation approach, and the overall accuracy of 3-D coordinate computation of the suture thread were conducted in various scenarios, and the results quantitatively validate the feasibility and reliability of the entire scheme for automated 3-D shape reconstruction.","","","10.1109/TASE.2019.2950005","Research Grant Council of the Hong Kong Special Administrative Region China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8913674","3-D coordinates computation;stereovision;surgical robot;suture thread detection.","Instruction sets;Yarn;Feature extraction;Computational modeling;Image segmentation;Robot kinematics","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Accelerating Minibatch Stochastic Gradient Descent Using Typicality Sampling","X. Peng; L. Li; F. Wang","Department of Automation, Tsinghua University, Beijing 100084, China.; Tsinghua National Laboratory for Information Science and Technology, Department of Automation, Tsinghua University, Beijing 100084, China (e-mail: li-li@tsinghua.edu.cn).; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing 100080, China.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","11","Machine learning, especially deep neural networks, has developed rapidly in fields, including computer vision, speech recognition, and reinforcement learning. Although minibatch stochastic gradient descent (SGD) is one of the most popular stochastic optimization methods for training deep networks, it shows a slow convergence rate due to the large noise in the gradient approximation. In this article, we attempt to remedy this problem by building a more efficient batch selection method based on typicality sampling, which reduces the error of gradient estimation in conventional minibatch SGD. We analyze the convergence rate of the resulting typical batch SGD algorithm and compare the convergence properties between the minibatch SGD and the algorithm. Experimental results demonstrate that our batch selection scheme works well and more complex minibatch SGD variants can benefit from the proposed batch selection strategy.","","","10.1109/TNNLS.2019.2957003","National Key Research and Development Program of China; National Natural Science Foundation of China; Beijing Municipal Science and Technology Commission; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8945166","Batch selection;machine learning;minibatch stochastic gradient descent (SGD);speed of convergence.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Automatic Assessment of Depression from Speech via a Hierarchical Attention Transfer Network and Attention Autoencoders","Z. Zhao; Z. Bao; Z. Zhang; J. Deng; N. Cummins; H. Wang; J. Tao; B. Schuller","College of Computer and Information Engineering, Tianjin Normal University, 12523 Tianjin China (e-mail: ztianjin@126.com); College of Computer and Information Engineering, Tianjin Normal University, 12523 Tianjin China (e-mail: 1942952862@qq.com); Department of Computing, Imperial College London, London United Kingdom of Great Britain and Northern Ireland SW7 2AZ (e-mail: zixing.zhang@tum.de); Agile Robots AG, Gilching, Germany, Gilching, Bayern Germany (e-mail: jun.deng@tum.de); ZD.B Chair of Embedded Intelligence for Health Care and Wellbeing, University of Augsburg, Germany, Augsburg Germany (e-mail: nicholas.cummins@ieee.org); International Research Centre for Affective Intelligence, Tianjin Normal University, 12523 Tianjin China (e-mail: Haishuai_Wang@hms.harvard.edu); Chinese Academy of Sciences, National Laboratory of Pattern Recognition, Chinese Academy of Sciences, Beijing, Beijing China 100190 (e-mail: jhtao@nlpr.ia.ac.cn); International Research Centre for Affective Intelligence, Tianjin Normal University, 12523 Tianjin China (e-mail: schuller@ieee.org)","IEEE Journal of Selected Topics in Signal Processing","","2019","PP","99","1","1","Early interventions in mental health conditions such as Major Depressive Disorder (MDD) are critical to improved health outcomes, as they can help reduce the burden of the disease. As the efficient diagnosis of depression severity is therefore highly desirable, the use of behavioural cues such as speech characteristics in diagnosis is attracting increasing interest in the field of quantitative mental health research. However, despite the widespread use of machine learning methods in the depression analysis community, the lack of adequate labelled data has become a bottleneck preventing the broader application of techniques such as deep learning. Accordingly, we herein describe a deep learning approach that combines unsupervised learning, knowledge transfer and hierarchical attention for the task of speech-based depression severity measurement. Our novel approach, a Hierarchical Attention Transfer Network (HATN), uses hierarchical attention autoencoders to learn attention from a source task, followed by speech recognition, and then transfers this knowledge into a depression analysis system. Experiments based on the depression sub-challenge dataset of the Audio/Visual Emotion Challenge (AVEC) 2017 demonstrate the effectiveness of our proposed model. On the test set, our technique outperformed other speech-based systems presented in the literature, achieving a Root Mean Square Error (RMSE) of 5.51 and a Mean Absolute Error (MAE) of 4.20 on a Patient Health Questionnaire (PHQ)-8 scale [0, 24]. To the best of our knowledge, these scores represent the best-known speech results on the AVEC 2017 depression corpus to date.","","","10.1109/JSTSP.2019.2955012","National Science Fund for Distinguished Young Scholars; Key Program of the National Natural Science Foundation of China; National Natural Science Foundation of China; Open Projects Program of the National Laboratory of Pattern Recognition; Key Program of the Natural Science Foundation of Tianjin; European Unions Horizon 2020 research and innovation programme; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8910358","depression;attention transfer;hierarchical attention;monotonic attention","Task analysis;Deep learning;Speech recognition;Training;Feature extraction","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Convolutional Neural Network Based Bi-prediction Utilizing Spatial and Temporal Information in Video Coding","J. Mao; L. Yu","Institute of Information and Communication Engineering, Zhejiang University, Hangzhou 310027, China.; Institute of Information and Communication Engineering, Zhejiang University, Hangzhou 310027, China.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","With the growing popularity of high-resolution videos, the demand for higher coding efficiency is increasing to cope with multimedia transmission challenges on the communication network. Since conventional linearly weighted bi-prediction does not handle inhomogeneous motion activities inside one block well, in recent works, Convolutional Neural Network (CNN) is explored to tackle inhomogeneous motion by utilizing patch-level information to predict each individual pixel. However, as only two reference blocks are used as input information, those works ignore the variation of pixel values between reference blocks and current block, and ignore the differences between extrapolation and interpolation. This work utilizes both spatial neighboring pixels and temporal display orders as extra inputs for CNN models to further improve the prediction accuracy of a bi-predictor. The extra input information has the following advantages. First, variations among spatial neighboring pixels of both reference blocks and the current block reflect variations between current block and reference blocks. Together with temporal distance, spatial neighboring pixels are able to address extrapolation and interpolation uniformly. Second, spatial neighboring pixels of the current block have a high correlation with current predicted signals, which helps to reduce prediction residuals around the block boundary and alleviate block artifacts. Last, temporal distances help to improve the accuracy of prediction signals based on its ability of reflecting the correlation of video frames. Experimental results show that our proposed network achieves 2.92% and 5.09% bit-rate savings on average compared with HEVC, under Low-Delay B (LDB) and Random-Access (RA) configurations, respectively. As temporal information is used in our network, the LDB and RA configurations share the same networks in this work.","","","10.1109/TCSVT.2019.2954853","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8908826","bi-prediction;temporal distance;spatial information;convolutional neural network;High Efficiency Video Coding","Video coding;Interpolation;Extrapolation;Deep learning;Correlation;Convolutional neural nets;Complexity theory","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Multi-View Saliency Guided Deep Neural Network for 3D Object Retrieval and Classification","H. Zhou; A. Liu; W. Nie; J. Nie","Electrical and Information Engineering, Tianjin University, Tianjin China (e-mail: zhy_std@163.com); Electronic Information Engineering, Tianjin University, 12605 Tianjin China 300072 (e-mail: anan0422@gmail.com); Tianjin University, School of Electronic Information Engineering, Tianjin China 300072 (e-mail: weizhinie@tju.edu.cn); Ocean University of China, Ocean University of China, QIngdao China (e-mail: niejie@ouc.edu.cn)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","In this paper, we propose the multi-view saliency guided deep neural network (MVSG-DNN) for 3D object retrieval and classification. This method mainly consists of three key modules. First, the module of model projection rendering is employed to capture the multiple views of one 3D object. Second, the module of visual context learning applies the basic Convolutional Neural Networks for visual feature extraction of individual views and then employs the saliency LSTM to adaptively select the representative views based on multi-view context. Finally, with these information, the module of multi-view representation learning can generate the compile 3D object descriptors with the designed classification LSTM for 3D object retrieval and classification. The proposed MVSG-DNN has two main contributions: 1) It can jointly realize the selection of representative views and the similarity measure by fully exploiting multi-view context; 2) It can discover the discriminative structure of multi-view sequence without constraints of specific camera settings. Consequently, it can support flexible 3D object retrieval and classification for real applications by avoiding the required camera settings. Extensive comparison experiments on ModelNet10, ModelNet40, and ShapeNetCore55 demonstrate the superiority of MVSG-DNN against the state-of-art methods.","","","10.1109/TMM.2019.2943740","Elite Scholar Program of Tianjin University; Open Project Program of the State Key Lab of CAD and CG Zhejiang University; 2018 Tianjin New Generation Artificial Intelligence Major Program; 2019 Tianjin New Generation Artificial Intelligence Major Program; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8851292","3D Object Retrieval;3D Object Classification;Multi-View Learning;Saliency Analysis","Three-dimensional displays;Solid modeling;Visualization;Cameras;Feature extraction;Computational modeling;Shape","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Light Field Super-Resolution using a Low-Rank Prior and Deep Convolutional Neural Networks","R. Farrugia; C. Guillemot","Communications and Computer Engineering, University of Malta, Msida, NA Malta MSD2080 (e-mail: reuben.farrugia@um.edu.mt); TEMICS, INRIA, Rennes, Brittany France (e-mail: Christine.Guillemot@inria.fr)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Light field imaging has recently known a regain of interest due to the availability of practical light field capturing systems that offer a wide range of applications in the field of computer vision. However, capturing high-resolution light fields remains technologically challenging since the increase in angular resolution is often accompanied by a significant reduction in spatial resolution. This paper describes a learning-based spatial light field super-resolution method that allows the restoration of the entire light field with consistency across all angular views. The algorithm first uses optical flow to align the light field and then reduces its angular dimension using low-rank approximation. We then consider the linearly independent columns of the resulting low-rank model as an embedding, which is restored using a deep convolutional neural network (DCNN). The super-resolved embedding is then used to reconstruct the remaining views. The original disparities are restored using inverse warping where missing pixels are approximated using a novel light field inpainting algorithm. Experimental results show that the proposed method outperforms existing light field super-resolution algorithms,achieving PSNR gains of 0.23 dB over the second best performing method. The performance is shown to be further improved using iterative back-projection as a post-processing step.","","","10.1109/TPAMI.2019.2893666","EU H2020 ERC; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8620368","Deep Convolutional Neural Networks;Light Field;Low-Rank Matrix Approximation;Super-Resolution","Spatial resolution;Cameras;Image restoration;Matrix decomposition;Sparse matrices;Light fields","","","","","","","","","","IEEE","IEEE Early Access Articles"
"On the Robustness of Semantic Segmentation Models to Adversarial Attacks","A. Arnab; O. Miksik; P. H. S. Torr","Information Engineering, University of Oxford, Oxford, Oxfordshire United Kingdom of Great Britain and Northern Ireland (e-mail: aarnab@robots.ox.ac.uk); Information Engineering, University of Oxford, Oxford, Oxfordshire United Kingdom of Great Britain and Northern Ireland (e-mail: omiksik@robots.ox.ac.uk); Information Engineering, University of Oxford, Oxford, Oxfordshire United Kingdom of Great Britain and Northern Ireland (e-mail: philip.torr@eng.ox.ac.uk)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Deep Neural Networks (DNNs) have demonstrated exceptional performance on most recognition tasks such as image classification and segmentation. However, they have also been shown to be vulnerable to adversarial examples. This phenomenon has recently attracted a lot of attention but it has not been extensively studied on multiple, large-scale datasets and structured prediction tasks such as semantic segmentation which often require more specialised networks with additional components such as CRFs, dilated convolutions, skip-connections and multiscale processing. In this paper, we present what to our knowledge is the first rigorous evaluation of adversarial attacks on modern semantic segmentation models, using two large-scale datasets. We analyse the effect of different network architectures, model capacity and multiscale processing, and show that many observations made on the task of classification do not always transfer to this more complex task. Furthermore, we show how mean-field inference in deep structured models, multiscale processing (and more generally, input transformations) naturally implement recently proposed adversarial defenses. Our observations will aid future efforts in understanding and defending against adversarial examples. Moreover, in the shorter term, we show how to effectively benchmark robustness and show which segmentation models should currently be preferred in safety-critical applications due to their inherent robustness.","","","10.1109/TPAMI.2019.2919707","H2020 European Research Council; Engineering and Physical Sciences Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8725541","adversarial attacks;semantic segmentation;deep learning;convolutional neural networks;machine learning security","Robustness;Semantics;Image segmentation;Perturbation methods;Task analysis;Neural networks;Standards","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Attentive Deep Stitching and Quality Assessment for 360° Omnidirectional Images","J. Li; Y. Zhao; W. Ye; K. Yu; S. Ge","School of Computer Science and Engineering, Beihang University, Beijing, Beijing China (e-mail: jiali@buaa.edu.cn); School of Computer Science and Engineering, Beihang University, Beijing, Beijing China (e-mail: zhaoyf@buaa.edu.cn); School of Computer Science and Engineering, Beihang University, Beijing, Beijing China (e-mail: yeweihua@buaa.edu.cn); School of Computer Science and Engineering, Beihang University, Beijing, Beijing China (e-mail: kevinyu@buaa.edu.cn); Institute of Information Engineering, Chinese Academy of Sciences, Beijing, Beijing China 100095 (e-mail: geshiming@iie.ac.cn)","IEEE Journal of Selected Topics in Signal Processing","","2019","PP","99","1","1","360° omnidirectional images are very helpful in creating immersive multimedia contents, which enables a huge demand in their efficient generation and effective assessment. In this paper, we leverage an attentive idea to meet this demand by addressing two concerns: how to generate a good omnidirectional image in a fast and robust way and what is a good omnidirectional image for human. To this end, we propose an attentive deep stitching approach to facilitate the efficient generation of omnidirectional images, which is composed of two modules. The low-resolution deformation module aims to learn the deformation rules from dual-fisheye to omnidirectional images with joint implicit and explicit attention mechanisms, while the high-resolution recurrence module enhances the resolution of stitching results with the high-resolution guidance in a recurrent manner. In this way, the stitching approach can efficiently generate high-resolution omnidirectional images that are highly consistent with human immersive experiences. Beyond the efficient generation, we further present an attention-driven omnidirectional image quality assessment (IQA) method which uses joint evaluation with both global and local metrics. Especially, the local metric mainly focuses on the stitching region and attention region that mostly affect the Mean Opinion Score (MOS), leading to a consistent evaluation of human perception. To verify the effectiveness of our proposed assessment and stitching approaches, we construct a hybrid benchmark evaluation with 7 stitching models and 8 IQA metrics. Qualitative and quantitative experiments show our stitching approach generate preferable results with the state-of-the-art models at a 6x faster speed and the proposed quality assessment approach surpasses other methods by a large margin and is highly consistent with human subjective evaluation","","","10.1109/JSTSP.2019.2953950","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8903278","360 omnidirectional image;image quality assessment;attentive deep stitching","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Big Data Oriented Smart Tool Condition Monitoring System","K. Zhu; G. Li; Y. Zhang","Institute of Advanced Manufaturing Technology, Chinese Academy of Sciences, Changzhou, Jiangsu China 213164 (e-mail: kunpengz@hotmail.com); Institute of Advanced Manufaturing Technology, Chinese Academy of Sciences, Changzhou, Jiangsu China 213164 (e-mail: gcli@iamt.ac.cn); Institute of Advanced Manufaturing Technology, Chinese Academy of Sciences, Changzhou, Jiangsu China 213164 (e-mail: yzhang@iamt.ac.cn)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","The computer numerical control (CNC) machining is the technical foundation of modern high-end manufacturing. To satisfy the productivity and precision requirement, it is required to monitor and adaptively control the machining process in real time under varying working conditions. The current CNC machining system is limited by data acquisition methods and modeling approaches, and it is difficult to make full use of monitoring information to smartly assess and optimize the cutting conditions online. This study proposes a new idea and a novel model to solve the problem, with a big data analytics framework for smart tool condition monitoring (TCM). Driven by the monitored big data, this study systematically investigates the key issues for TCM such as machining dynamics, intelligent tool wear monitoring and compensation algorithms, heterogeneous big data fusion and deep learning methods. Under this scheme, it develops the smart TCM system which could improve the CNC machining precision and productivity significantly.","","","10.1109/TII.2019.2957107","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8918449","Big data;heterogeneous data fusion;tool condition monitoring;deep learning","Tools;Monitoring;Machining;Big Data;Data models;Computer numerical control;Machine learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Personality Traits Classification Using Deep Visual Activity-based Nonverbal Features of Key-Dynamic Images","C. Beyan; A. Zunino; M. Shahid; V. Murino","Pattern Analysis and Computer Vision (PAVIS), Istituto Italiano di Tecnologia, 121451 Genoa, Liguria Italy (e-mail: cigdem.beyan@iit.it); Pattern Analysis and Computer Vision (PAVIS), Istituto Italiano di Tecnologia, 121451 Genoa, Genoa Italy (e-mail: andrea.zunino@iit.it); Pattern Analysis and Computer Vision (PAVIS), Istituto Italiano di Tecnologia, 121451 Genoa, Liguria Italy (e-mail: Shahid.Muhammad@iit.it); Pattern Analysis and Computer Vision, Italian Institute of Technology, Genova, Genova Italy 16163 (e-mail: vittorio.murino@iit.it)","IEEE Transactions on Affective Computing","","2019","PP","99","1","1","This paper addresses nonverbal behavior analysis for the classification of perceived personality traits using novel deep visual activity (VA)-based features extracted only from key-dynamic images. Dynamic images represent short-term VA. Key-dynamic images carry more discriminative information i.e., nonverbal features (NFs) extracted from them contribute to the classification more than NFs extracted from other dynamic images. Dynamic image construction, learning long-term VA with CNN+LSTM, and detecting spatio-temporal saliency are applied to determine key-dynamic images. Once VA-based NFs are extracted, they are encoded using covariance, and resulting representation is used for classification. This method was evaluated on two datasets: small group meetings and vlogs. For the first dataset, proposed method outperforms not only the state-of-the-art VA-based methods but also multi-modal approaches for all personality traits. For extraversion classification, it performs better than i) the most popular key-frames selection algorithm, ii) random and uniform dynamic image selection, and iii) NFs extracted from all dynamic images. Furthermore, the ablation study proves the superiority of proposed method. For the further dataset, it performs as well as the state-of-the-art visual-NFs on average, while showing improved performance for agreeableness classification. Proposed method can be adapted to any application based on nonverbal behavior analysis, thanks to being data-driven.","","","10.1109/TAFFC.2019.2944614","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8852681","nonverbal behavior;visual activity;dynamic image;deep neural networks;long short term memory;spatio-temporal saliency;key-frame;personality traits classification","Feature extraction;Dynamics;Heuristic algorithms;Visualization;Data mining;Image recognition;Optical imaging","","","","","","","","","","IEEE","IEEE Early Access Articles"
"MR-Forest: A Deep Decision Framework for False Positive Reduction in Pulmonary Nodule Detection","H. Zhu; H. Zhao; C. Song; Z. Bian; Y. Bi; T. Liu; X. He; D. Yang; W. Cai","School of Computer Science and Engineering, Northeastern University, Shenyang, Liaoning China (e-mail: zhuhongbo@neuera.com); School of Computer Science and Engineering, Northeastern University, Shenyang, Liaoning China (e-mail: zhaohai@neuera.com); Shenyang Institute of Automation, Chinese Academy of Sciences, Shenyang, Liaoning China (e-mail: songchunhe@sia.cn); Philips China Investment Co., Ltd., Imaging Clinical Applications & Platform, Shanghai China (e-mail: zijian.bian@philips.com); School of Computer Science and Engineering, Northeastern University, Shenyang, Liaoning China (e-mail: yuanguobi@neuera.com); School of Computer Science and Engineering, Northeastern University, Shenyang, Liaoning China (e-mail: liutong@neuera.com); Sino-Dutch Biomedical and Information Engineering School, Northeastern University, Shenyang, Liaoning China (e-mail: hexuan@bmie.neu.edu.cn); Affiliated Hospital, Liaoning University of Traditional Chinese Medicine, 66473 Shenyang, Liaoning China (e-mail: yangdongxiang@neuera.com); Neusoft Institute of Intelligent Healthcare Technology, Co. Ltd., Shenyang, Liaoning China (e-mail: cai.wei@neusoft.com)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","With the development of deep learning methods such as convolutional neural network (CNN), the accuracy of automated pulmonary nodule detection has been greatly improved. However, the high computational and storage costs of the large-scale network have been a potential concern for the future widespread clinical application. In this paper, an alternative Multi-ringed (MR)-Forest framework, against the resource-consuming neural networks (NN)-based architectures, has been proposed for false positive reduction in pulmonary nodule detection, which consists of three steps. First, a novel multi-ringed scanning method is used to extract the order ring facets (ORFs) from the surface voxels of the volumetric nodule models; Second, Mesh-LBP and mapping deformation are employed to estimate the texture and shape features. By sliding and resampling the multi-ringed ORFs, feature volumes with different lengths are generated. Finally, the outputs of multilevel are cascaded to predict the candidate class. On 1034 scans merging the dataset from the Affiliated Hospital of Liaoning University of Traditional Chinese Medicine (AH-LUTCM) and the LUNA16 Challenge dataset, our framework performs enough competitiveness than state-of-the-art in false positive reduction task (CPM score of 0.865). Experimental results demonstrate that MR-Forest is a successful substitution to satisfied both resource-consuming and effectiveness for automated pulmonary nodule detection systems. The proposed MR-forest is a general architecture for 3D target detection, it can be easily extended in many other medical imaging analysis tasks, where the growth trend of the targeting object is approximated as a spheroidal expansion.","","","10.1109/JBHI.2019.2947506","Open Program of Neusoft Research of Intelligent Healthcare Technology Co. Ltd.; National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; National Key Research and Development Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8869886","False positive reduction;Spherical surface feature;Deep decision;ORFs;Computer tomography","Feature extraction;Forestry;Three-dimensional displays;Harmonic analysis;Artificial neural networks;Task analysis;Computed tomography","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Domain Adaption for Fine-Grained Urban Village Extraction From Satellite Images","Q. Shi; M. Liu; X. Liu; P. Liu; P. Zhang; J. Yang; X. Li","Guangdong Key Laboratory for Urbanization and Geo-simulation, School of Geography and Planning, Sun Yat-sen University, Guangzhou 510275, China; Guangdong Key Laboratory for Urbanization and Geo-simulation, School of Geography and Planning, Sun Yat-sen University, Guangzhou 510275, China; Guangdong Key Laboratory for Urbanization and Geo-simulation, School of Geography and Planning, Sun Yat-sen University, Guangzhou 510275, China; Guangdong Key Laboratory for Urbanization and Geo-simulation, School of Geography and Planning, Sun Yat-sen University, Guangzhou 510275, China (e-mail: liuph3@mail2.sysu.edu.cn).; Guangdong Key Laboratory for Urbanization and Geo-simulation, School of Geography and Planning, Sun Yat-sen University, Guangzhou 510275, China; School of Geographical Sciences, Guangzhou University, Guangzhou 510006, China.; School of Geographic Sciences, East China Normal University, Shanghai 200241, China, and also with the Key Laboratory of Geographic Information Science, Ministry of Education, East China Normal University, Shanghai 200241, China","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","Urban villages (UVs) are distinctive products formed in the process of rapid urbanization. The fine-grained mapping of UVs from satellite images has always been a considerable challenge because of the complex urban structures and the insufficiency of labeled samples. In this letter, we propose using the domain adaptation strategy to tackle the domain shift problem by employing adversarial learning to tune the semantic segmentation network so as to adaptively obtain similar outputs for input images from different domains. The proposed method was coupled with several segmentation networks, including U-Net, RefineNet, and DeepLab v3+, and the results show that domain adaptation can significantly improve the pixel-level mapping of UVs.","","","10.1109/LGRS.2019.2947473","National Basic Research Program of China (973 Program); National Natural Science Foundation of China; National Natural Science Foundation of China; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8886520","Adversarial learning;domain adaptation;satellite images;semantic segmentation;urban village (UV).","Image segmentation;Semantics;Training;Feature extraction;Adaptation models;Deep learning;Satellites","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Deep Learning-based Semantic Filter for RANSAC-based Fundamental Matrix Calculation and the ORB-SLAM System","C. Shao; C. Zhang; Z. Fang; G. Yang","Zhejing Key Laboratory of Robotics and Intelligent Manufacturing Equipment Technology and Engineering, Ningbo Institute of Materials Technology and Engineering, CAS, Ningbo 315201, China and Transportation Research Institute of Tongji University, Tongji University, Shanghai 201804, China.; Zhejing Key Laboratory of Robotics and Intelligent Manufacturing Equipment Technology and Engineering, Ningbo Institute of Materials Technology and Engineering, CAS, Ningbo 315201, China.; Zhejing Key Laboratory of Robotics and Intelligent Manufacturing Equipment Technology and Engineering, Ningbo Institute of Materials Technology and Engineering, CAS, Ningbo 315201, China.; Zhejing Key Laboratory of Robotics and Intelligent Manufacturing Equipment Technology and Engineering, Ningbo Institute of Materials Technology and Engineering, CAS, Ningbo 315201, China.","IEEE Access","","2019","PP","99","1","1","The estimation of a fundamental matrix (F-matrix) from two-view images is a crucial problem in epipolar geometry, and a key point in visual simultaneous localization and mapping (VSLAM). Conventional robust methods proposed by the data calculation space, such as Random Sample Consensus (RANSAC), encounter computational inefficiency and low accuracy when the outliers exceed 50%. In this paper, a semantic filter-based on faster region-based convolutional neural network (faster R-CNN) is proposed to solve the outlier problem in RANSAC based F-matrix calculations. The semantic filter is trained using semantic patches tailored by inliers, providing different semantic labels in various image regions. First, the patches classified into the top three bad labels are filtered out during the pre-processing phase. Second, precise and robust correspondences are determined by the remaining high-level semantic contexts. Finally, the inliers are assessed using RANSAC to produce an accurate F-matrix. The proposed algorithm can improve the accuracy of F-matrix calculations, as low-quality feature correspondences are effectively decreased. Experiments on KITTI and ETH sequences illustrate that the 3D position error can be reduced by applying the semantic filter to the ORB-SLAM system. Further, indoor and real environment experiments demonstrate that an effective lower trajectory error is yielded with the proposed approach.","","","10.1109/ACCESS.2019.2962268","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8943202","fundamental matrix;RANSAC;faster R-CNN;semantic filter;semantic patches;ORB-SLAM","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Adversarial WiFi Sensing for Privacy Preservation of Human Behaviors","S. Zhou; W. Zhang; D. Peng; Y. Liu; X. Liao; H. Jiang","College of Computer Science and Electrical Engineering, Hunan University, Changsha 410082 China.; College of Computer Science and Electrical Engineering, Hunan University, Changsha 410082 China.; College of Computer Science and Electrical Engineering, Hunan University, Changsha 410082 China.; Department of Computer Science and Engineering, the University of Texas at Arlington, TX 76019, USA.; College of Computer Science and Electrical Engineering, Hunan University, Changsha 410082 China.; College of Computer Science and Electrical Engineering, Hunan University, Changsha 410082 China.","IEEE Communications Letters","","2019","PP","99","1","1","Recent research on WiFi sensing focuses on the identification of a wide range of human behaviors with high recognition accuracy. However, these well-studied recognition techniques can cause privacy concerns due to the ubiquity of WiFi signal and comprehensive behavior information embedded therein. In this paper, we take the first attempt to develop an adversarial deep network architecture for human behavior preservation. Our goal is to make desirable private behaviors of a human being not recognizable by general classifiers, while the recognition of other ones remaining unaffected. To achieve this, we propose a novel loss function, using which our network is capable of intentionally modifying CSI data extracted from received WiFi signal, constraining the new classification results to match the adversarial requirements. Experimental results demonstrate that, with the proposed adversarial scheme, the recognition rate of the human behaviors needed to be protected can be significantly decreased, while still maintaining the accuracy of other ones desired to be identified. Our source codes are available at https://github.com/siwangzhou/WiFi-ADG.","","","10.1109/LCOMM.2019.2952844","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8897594","Adversarial learning;deep network;privacy preservation;WiFi sensing","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"An Adaptive Scale Sea Surface Temperature Predicting Method Based on Deep Learning With Attention Mechanism","J. Xie; J. Zhang; J. Yu; L. Xu","School of Computer Engineering and Science, Shanghai University, Shanghai 200444, China (e-mail: jiangx@shu.edu.cn).; School of Computer Engineering and Science, Shanghai University, Shanghai 200444, China.; School of Computer Engineering and Science, Shanghai University, Shanghai 200444, China.; School of Computer Engineering and Science, Shanghai University, Shanghai 200444, China (e-mail: xly@shu.edu.cn).","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","Sea surface temperature (SST) prediction plays an important role in ocean-related fields. It is challenging due to the nonlinear temporal dynamics with changing complex factors and the inherent difficulties in long-scale predictions. Conventional models often lack efficient information extraction and cannot meet the requirements of long-scale predictions. Therefore, the gate recurrent unit (GRU) encoder-decoder with SST codes and dynamic influence link (DIL), GRU encoder-decoder (GED), which considered both the static and dynamic influence, is proposed in this letter. Each SST code, capturing the static information more effectively, was computed by all hidden states of the encoder and was individually associated with each predicted SST. The DIL, capturing the dynamic influence, connected the SST code with the early predicted future SST for solving the long-scale dependence problem. GED was tested on the Bohai Sea SST data sets and South China Sea SST data sets and compared with full-connected long-short term memory (FC-LSTM) and support vector regression. The results demonstrated that GED outperformed others on different prediction scales and different prediction terms (daily, weekly, and monthly), especially in terms of long-scale and long-term predictions. In addition, attention relationships between historical and future SSTs were further explored, and there was a meaningful finding that each future daily mean SST of Bohai Sea most strongly correlated with the past 27th to 29th historical values.","","","10.1109/LGRS.2019.2931728","National Basic Research Program of China (973 Program); National Natural Science Foundation of China; Natural Science Foundation of Shanghai; High Performance Computing Center of Shanghai University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8804357","Dynamic influence link (DIL);encoder-decoder;gate recurrent unit (GRU);sea surface temperature (SST);SST codes.","Ocean temperature;Electronics packaging;Decoding;Predictive models;Sea surface;Biological system modeling;Logic gates","","","","","","","","","","IEEE","IEEE Early Access Articles"
"DeepSUM: Deep Neural Network for Super-Resolution of Unregistered Multitemporal Images","A. B. Molini; D. Valsesia; G. Fracastoro; E. Magli","Department of Electronics and Telecommunications, Politecnico di Torino, 10129 Turin, Italy.; Department of Electronics and Telecommunications, Politecnico di Torino, 10129 Turin, Italy. (e-mail: diego.valsesia@polito.it).; Department of Electronics and Telecommunications, Politecnico di Torino, 10129 Turin, Italy.; Department of Electronics and Telecommunications, Politecnico di Torino, 10129 Turin, Italy.","IEEE Transactions on Geoscience and Remote Sensing","","2019","PP","99","1","13","Recently, convolutional neural networks (CNNs) have been successfully applied to many remote sensing problems. However, deep learning techniques for multi-image super-resolution (SR) from multitemporal unregistered imagery have received little attention so far. This article proposes a novel CNN-based technique that exploits both spatial and temporal correlations to combine multiple images. This novel framework integrates the spatial registration task directly inside the CNN, and allows one to exploit the representation learning capabilities of the network to enhance registration accuracy. The entire SR process relies on a single CNN with three main stages: shared 2-D convolutions to extract high-dimensional features from the input images; a subnetwork proposing registration filters derived from the high-dimensional feature representations; 3-D convolutions for slow fusion of the features from multiple images. The whole network can be trained end-to-end to recover a single high-resolution image from multiple unregistered low-resolution images. The method presented in this article is the winner of the PROBA-V SR challenge issued by the European Space Agency (ESA).","","","10.1109/TGRS.2019.2959248","Smart-Data at PoliTO Center for Big Data and Machine Learning Technologies; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8946717","Convolutional neural networks (CNNs);dynamic filter networks;multi-image super resolution (MISR);multitemporal images.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"RADAR: Robust Algorithm for Depth Image Super Resolution Based on FRI Theory and Multimodal Dictionary Learning","X. Deng; P. Song; M. R. D. Rodrigues; P. L. Dragotti","Department of Electrical and Electronic Engineering, Imperial College London, SW7 2AZ, London, the United Kingdom.; department of Electronic and Electrical Engineering, University College London, WC1E 6BT, London, the United Kingdom.; department of Electronic and Electrical Engineering, University College London, WC1E 6BT, London, the United Kingdom.; Department of Electrical and Electronic Engineering, Imperial College London, SW7 2AZ, London, the United Kingdom.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Depth image super-resolution is a challenging problem, since normally high upscaling factors are required (e.g., 16×), and depth images are often noisy. In order to achieve large upscaling factors and resilience to noise, we propose a Robust Algorithm for Depth imAge super Resolution (RADAR) that combines the power of finite rate of innovation (FRI) theory with multimodal dictionary learning. Given a low-resolution (LR) depth image, we first model its rows and columns as piece-wise polynomials and propose a FRI-based depth upscaling (FDU) algorithm to super-resolve the image. Then, the upscaled moderate quality (MQ) depth image is further enhanced with the guidance of a registered high-resolution (HR) intensity image. This is achieved by learning multimodal mappings from the joint MQ depth and HR intensity pairs to the HR depth, through a recently proposed triple dictionary learning (TDL) algorithm. Moreover, to speed up the super-resolution process, we introduce a new projection-based rapid upscaling (PRU) technique that pre-calculates the projections from the joint MQ depth and HR intensity pairs to the HR depth. Compared with state-of-the-art deep learning based methods, our approach has two distinct advantages: we need a fraction of training data but can achieve the best performance, and we are resilient to mismatches between training and testing datasets. Extensive numerical results show that the proposed method outperforms other state-of-the-art methods on either noise-free or noisy datasets with large upscaling factors up to 16× and can handle unknown blurring kernels well.","","","10.1109/TCSVT.2019.2923901","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8741062","Depth image super-resolution;finite rate of innovation;multimodal image processing","Image resolution;Training;Machine learning;Color;Image reconstruction;Noise measurement;Image edge detection","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Multi-scale Kernel based Residual Convolutional Neural Network for Motor Fault Diagnosis Under Non-stationary Conditions","R. Liu; F. Wang; B. Yang; S. J. Qin","School of Computer Science, Carnegie Mellon University, 6612 Pittsburgh, Pennsylvania United States 15213-3815 (e-mail: liuruonan04@163.com); Institute of Cyberspace Research, Zhejiang University, 12377 Hangzhou, Zhejiang China 310058 (e-mail: feiw2.ri@gmail.com); School of Electrical and Electronic Engineering, The University of Manchester, 5292 Manchester United Kingdom of Great Britain and Northern Ireland M13 9PL (e-mail: yangboyuanxjtu@163.com); Chemical and Electrical Engineerings, Univ of Southern California, Arcadia United States 91006-1912 (e-mail: sqin@usc.edu)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","Motor fault diagnosis is imperative to enhance the reliability and security of industrial systems. However, since motors are often operated under non-stationary conditions, the high complexity of vibration signals raises notable difficulties for fault diagnosis. Therefore, considering the special physical characteristics of motor signals under non-stationary conditions, a multi-scale kernel based residual network (MK-ResCNN) is proposed in this paper for motor fault diagnosis. Our contributions mainly fall into two aspects. First, we notice that each motor fault category has various patterns in vibration signals due to the changing operational conditions of the motor. To capture these patterns, a multi-scale kernel algorithm are applied in the CNN architecture. Second, since the motor vibration signals are made up of many different components from different transfer paths, they are very complex and variable. To enable the architecture to extract fault features from deep and hierarchical representation spaces, sufficient depth of the network is needed, which will lead to the degradation problem. In the proposed method, residual learning is embedded into the multi-scale kernel CNN to avoid performance degradation and build a deeper network. To validate the effectiveness of the proposed networks, a normal motor and five motors with different failures are tested. The results and comparisons with state-of-the-art methods highlight the superiority of the proposed method.","","","10.1109/TII.2019.2941868","National Science and Technology Major Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8842598","Motor fault diagnosis;multi-scale kernel convolutional neural network;residual learning;deep learning","Feature extraction;Fault diagnosis;Kernel;Convolution;Degradation;Vibrations;Convolutional neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Decoding Brain States from fMRI Signals by using Unsupervised Domain Adaptation","Y. Gao; Y. Zhang; Z. Cao; X. Guo; J. Zhang","Beijing China 100875 (e-mail: yfgao@mail.bnu.edu.cn); College of Life Sciences, Beijing Normal University, 47836 Beijing, Beijing China (e-mail: ymzhang@mail.bnu.educn); Beijing China 100875 (e-mail: caozhiyuan@mail.bnu.edu.cn); College of Information Science and Technology, Beijing Normal University, Beijing, Beijing China 100875 (e-mail: gxj@bnu.edu.cn); College of Information Science and Technology, Beijing Normal University, Beijing, Haidian China 100875 (e-mail: jiacai.zhang@bnu.edu.cn)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","With the development of deep learning in medical image analysis, decoding brain states from functional magnetic resonance imaging (fMRI) signals has made significant progress. Previous studies often utilized deep neural networks to automatically classify brain activity patterns related to diverse cognitive states. However, due to the individual differences between subjects and the variation in acquisition parameters across devices, the inconsistency in data distributions degrades the performance of cross-subject decoding. Besides, most current networks were trained in a supervised way, which is not suitable for the actual scenarios in which massive amounts of data are unlabeled. To address these problems, we proposed the deep crosssubject adaptation decoding (DCAD) framework to decipher the brain states. The proposed volume-based 3D feature extraction architecture can automatically learn the common spatiotemporal features of labeled source data to generate a distinct descriptor. Then, the distance between the source and target distributions is minimized via an unsupervised domain adaptation (UDA) method, which can help to accurately decode the cognitive states across subjects. The performance of the DCAD was evaluated on task-fMRI (tfMRI) dataset from the Human Connectome Project (HCP). Experimental results showed that the proposed method achieved the state-of-the-art decoding performance with mean 81.9% and 84.9% accuracies under two conditions (4 brain states and 9 brain states respectively) of working memory task. Our findings also demonstrated that UDA can mitigate the impact of the data distribution shift, thereby providing a superior choice for increasing the performance of cross-subject decoding without depending on annotations.","","","10.1109/JBHI.2019.2940695","National Key Technologies R and D Program; Beijing Advanced Education Center for Future Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8832215","neural decoding;cross-subject;unsupervised domain adaptation;tfMRI","Decoding;Three-dimensional displays;Task analysis;Functional magnetic resonance imaging;Feature extraction;Kernel;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Construction of Robust Representations for Small Data Sets Using Broad Learning System","H. Tang; P. Dong; Y. Shi","School of Management and Economics, Beijing Institute of Technology, Beijing 100081, China, and also with the College of Information Science and Technology, University of Nebraska at Omaha, Omaha, NE 68182 USA.; School of Management and Economics, Beijing Institute of Technology, Beijing 100081, China.; Research Center on Fictitious Economy and Data Science, Chinese Academy of Sciences, Beijing 100190, China, also with the Key Laboratory of Big Data Mining and Knowledge Management, Chinese Academy of Sciences, Beijing 100190, China, also with the College of Information Science and Technology, University of Nebraska at Omaha, NE 68182 USA, and also with the College of Electrical and Information Engineering, Southwest Minzu University, Chengdu 610041, China (e-mail: yshi@unomaha.edu).","IEEE Transactions on Systems, Man, and Cybernetics: Systems","","2019","PP","99","1","11","Feature processing is an important step for modeling and can improve the accuracy of machine learning models. Feature extraction methods can effectively extract features from high-dimensional data sets and enhance the accuracy of tasks. However, the performance of feature extraction methods is not stable in low-dimensional data sets. This article extends the broad learning system (BLS) to a framework for constructing robust representations in low-dimensional and small data sets. First, the BLS changed from a supervised prediction method to an ensemble feature extraction method. Second, feature extraction methods instead of random mapping are used to generate mapped features. Third, deep representations, called enhancement features, are learned from the ensemble mapped features. Fourth, data for generating mapped features and enhancement features can be randomly selected. The ensemble of mapped features and enhancement features can provide robust representations to enhance the performance of downstream tasks. A label-based autoencoder (LA) is embedded in the BLS framework as an example to show the effectiveness of the framework. A random LA (RLA) is presented to generate more different features. The experimental results show that the BLS framework can construct robust representations and significantly promote the performance of machine learning models.","","","10.1109/TSMC.2019.2957818","National Natural Science Foundation of China; International Graduate Exchange Program of Beijing Institute of Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8941069","Broad learning system (BLS);feature extraction;label-based autoencoder (LA);random LA (RLA);robust representation","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Vision-to-Language Tasks Based on Attributes and Attention Mechanism","X. Li; A. Yuan; X. Lu","School of Computer Science and Center for Optical Imagery Analysis and Learning, Northwestern Polytechnical University, Xi'an 710072, China.; Key Laboratory of Spectral Imaging Technology CAS, Xi'an Institute of Optics and Precision Mechanics, Chinese Academy of Sciences, Xi'an 710119, China, and also with the University of Chinese Academy of Sciences, Beijing 100049, China.; Key Laboratory of Spectral Imaging Technology CAS, Xi'an Institute of Optics and Precision Mechanics, Chinese Academy of Sciences, Xi'an 710119, China (e-mail: luxq666666@gmail.com).","IEEE Transactions on Cybernetics","","2019","PP","99","1","14","Vision-to-language tasks aim to integrate computer vision and natural language processing together, which has attracted the attention of many researchers. For typical approaches, they encode image into feature representations and decode it into natural language sentences. While they neglect high-level semantic concepts and subtle relationships between image regions and natural language elements. To make full use of these information, this paper attempt to exploit the text-guided attention and semantic-guided attention (SA) to find the more correlated spatial information and reduce the semantic gap between vision and language. Our method includes two-level attention networks. One is the text-guided attention network which is used to select the text-related regions. The other is SA network which is used to highlight the concept-related regions and the region-related concepts. At last, all these information are incorporated to generate captions or answers. Practically, image captioning and visual question answering experiments have been carried out, and the experimental results have shown the excellent performance of the proposed approach.","","","10.1109/TCYB.2019.2914351","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8718014","Deep learning;image captioning;multimodal;visual question answering (VQA)","Semantics;Task analysis;Visualization;Cats;Natural languages;Knowledge discovery;Feature extraction","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Volcano-Seismic Transfer Learning and Uncertainty Quantification With Bayesian Neural Networks","A. Bueno; C. Benítez; S. De Angelis; A. Díaz Moreno; J. M. Ibáñez","Department of Signal Theory, Telematics and Communications, University of Granada, 18071 Granada, Spain (e-mail: angelbueno@ugr.es).; Department of Signal Theory, Telematics and Communications, University of Granada, 18071 Granada, Spain.; Department of Earth, Ocean and Ecological Sciences, University of Liverpool, Liverpool L69 3GP, U.K.; Department of Earth, Ocean and Ecological Sciences, University of Liverpool, Liverpool L69 3GP, U.K.; Instituto Andaluz de Geofísica, University of Granada, 18071 Granada, Spain.","IEEE Transactions on Geoscience and Remote Sensing","","2019","PP","99","1","11","Over the past few years, deep learning (DL) has emerged as an important tool in the fields of volcano and earthquake seismology. However, these methods have been applied without performing thorough analyses of the associated uncertainties. Here, we propose a solution to enhance volcano-seismic monitoring systems, through probabilistic Bayesian DL; we implement and demonstrate a workflow for waveform classification, rapid quantification of the associated uncertainty, and link these uncertainties to changes in volcanic unrest. Specifically, we introduce Bayesian neural networks (BNNs) to perform event identification, classification, and their estimated uncertainty on data gathered at two active volcanoes, Mount St. Helens, Washington, USA, and Bezymianny, Kamchatka, Russia. We demonstrate how BNNs achieve excellent performance (92.08%) in discriminating both the type of event and its origin when the two data sets are merged together, and no additional training information is provided. Finally, we demonstrate that the data representations learned by the BNNs are transferable across different eruptive periods. We also find that the estimated uncertainty is related to changes in the state of unrest at the volcanoes and propose that it could be used to gauge whether the learned models may be exported to other eruptive scenarios.","","","10.1109/TGRS.2019.2941494","Spanish Government MINECO FEDER through the KNOWAVES Project; Natural Environment Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8861294","Geophysics computing;neural networks;seismology;uncertainty;volcanoes.","Uncertainty;Volcanoes;Bayes methods;Earthquakes;Neural networks;Seismology;Probabilistic logic","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Residual-Dyad Encoder Discriminator Network for Remote Sensing Image Matching","N. Khurshid; M. Tharani; M. Taj; F. Z. Qureshi","Department of Computer Science, Syed Babar Ali School of Science and Engineering, Lahore University of Management Sciences, Lahore 54792, Pakistan (e-mail: 15060051@lums.edu.pk).; Department of Computer Science, Syed Babar Ali School of Science and Engineering, Lahore University of Management Sciences, Lahore 54792, Pakistan.; Department of Computer Science, Syed Babar Ali School of Science and Engineering, Lahore University of Management Sciences, Lahore 54792, Pakistan.; Faculty of Science, Ontario Tech University, Oshawa, ON L1G 0C5, Canada.","IEEE Transactions on Geoscience and Remote Sensing","","2019","PP","99","1","14","łooseness1We propose a new method for remote sensing image matching. The proposed method uses an encoder subnetwork of an autoencoder pretrained on the GTCrossView data to construct image features. A discriminator network trained on the University of California Merced land-use/land-cover data set (LandUse) and the high-resolution satellite scene data set (SatScene) computes a match score between a pair of computed image features. We also propose a new network unit, called residual-dyad, and empirically demonstrate that networks that use residual-dyad units outperform those that do not. We compare our approach with both traditional and more recent learning-based schemes on the LandUse and SatScene data sets, and the proposed method achieves the state-of-the-art result in terms of mean average precision and average normalized modified retrieval rank (ANMRR) metrics. Specifically, our method achieves an overall improvement in performance of 11.26% and 22.41%, respectively, for LandUse and SatScene benchmark data sets.","","","10.1109/TGRS.2019.2951820","National Science and Engineering Council NSERC of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8917718","Content-based remote sensing image retrieval (CBRSIR);convolutional neural network (CNN);deep learning;residual encoder-decoder;RS image search.","Feature extraction;Image matching;Measurement;Image retrieval;Training;Task analysis;Computer architecture","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Backpropagation With N-D Vector-Valued Neurons Using Arbitrary Bilinear Products","Z. Fan; T. T. Chan; Y. Yang; J. R. Jang","Department of Computer Science and Information Engineering, National Taiwan University, Taipei 10617, Taiwan (e-mail: zcfan.tw@gmail.com).; Research Center for Information Technology Innovation, Academia Sinica, Taipei 11529, Taiwan.; Research Center for Information Technology Innovation, Academia Sinica, Taipei 11529, Taiwan.; Department of Computer Science and Information Engineering, National Taiwan University, Taipei 10617, Taiwan.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","15","Vector-valued neural learning has emerged as a promising direction in deep learning recently. Traditionally, training data for neural networks (NNs) are formulated as a vector of scalars; however, its performance may not be optimal since associations among adjacent scalars are not modeled. In this article, we propose a new vector neural architecture called the Arbitrary BIlinear Product NN (ABIPNN), which processes information as vectors in each neuron, and the feedforward projections are defined using arbitrary bilinear products. Such bilinear products can include circular convolution, 7-D vector product, skew circular convolution, reversed-time circular convolution, or other new products that are not seen in the previous work. As a proof-of-concept, we apply our proposed network to multispectral image denoising and singing voice separation. Experimental results show that ABIPNN obtains substantial improvements when compared to conventional NNs, suggesting that associations are learned during training.","","","10.1109/TNNLS.2019.2933882","Research Center for Information Technology Innovation Academia Sinica Taiwan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8826334","Backpropagation;bilinear products;vector neural learning;vector neural network (NN);vector products.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Multispectral Information Fusion with Reinforcement Learning for Object Tracking in IoT Edge Devices","P. Saha; S. Mukhopadhyay","School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA 30332 USA.; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA 30332 USA.","IEEE Sensors Journal","","2019","PP","99","1","1","With recent advances in sensor technology, multispectral systems are becoming increasingly attractive for intelligence, surveillance, and reconnaissance applications. Fusing information from multiple imaging modalities is a major task for such systems. Combining feature maps obtained from multiple deep neural network pipelines demonstrates promising performance for object detection and tracking. However, feature fusion using multiple deep networks is computationally intensive and therefore not suitable for resource-constrained IoT edge devices. In this paper, we propose a novel method to fuse the input space to enable processing of multispectral data via a single deep network. We use task-driven feedback as a reward signal for our reinforcement learning-based multispectral input fusion. Proposed approach not only improves tracking accuracy but also maximizes modality-specific information as intended by the user.","","","10.1109/JSEN.2019.2962834","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8945145","Multispectral fusion;reinforcement learning;edge computing;object tracking","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Integrating Multi-Omic Data with Deep Subspace Fusion Clustering for Cancer Subtype Prediction","B. Yang; Y. Zhang; S. Pang; X. Shang; X. Zhao; M. Han","Xi'an Polytechnic University, 71179 Xi'an, shaanxi China 710048 (e-mail: yangboo@stu.xjtu.edu.cn); , Northwestern Polytechnical University, 26487 Xi'an, Shaanxi China (e-mail: ypzhaang@nwpu.edu.cn); School of Software Engineering, Xi'an Jiaotong University, Xi'an, Shaan Xi China 710049 (e-mail: pangsm@xjtu.edu.cn); Northwestern Polytechnical University, 26487 Xi'an, Shaanxi China (e-mail: shang@nwpu.edu.cn); Xi'an Polytechnic University, 71179 Xi'an, Shaanxi China (e-mail: zhaoxueqing@xpu.edu.cn); School of Software Engineering, Xi'an Jiaotong University, Xi'an, Shaanxi China (e-mail: hanminghui@stu.xjtu.edu.cn)","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2019","PP","99","1","1","One type of cancer usually consists of several subtypes with distinct clinical implications, thus the cancer subtype prediction is an important task in disease diagnosis and therapy. Utilizing one type of data from molecular layers in biological system to predict is difficult to bridge the cancer genome to cancer phenotypes, since the genome is neither simple nor independent but rather complicated and dysregulated from multiple molecular mechanisms. Similarity Network Fusion (SNF) has been recently proposed to integrate diverse omics data for improving the understanding of tumorigenesis. SNF adopts Euclidean distance to measure the similarity between patients, which shows some limitations. In this paper, we introduce a novel prediction technique as an extension of SNF, namely Deep Subspace Fusion Clustering (DSFC). DSFC utilizes auto-encoder and data self-expressiveness approaches to guide a deep subspace model, which can achieve effective expression of discriminative similarity between patients. As a result, the dissimilarity between inter-cluster is delivered and enhanced compactness of intra-cluster is achieved at the same time. The validity of DSFC is examined by extensive simulations over six different cancer through three levels omics data. The survival analysis demonstrates that DSFC delivers comparable or even better results than many state-of-the-art integrative methods.","","","10.1109/TCBB.2019.2951413","China Postdoctoral Science Foundation; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8890799","Subspace learning;cancer subtype;data integration;omics data","Cancer;Genomics;Bioinformatics;Data models;Tumors;Euclidean distance;Gene expression","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Feature Fusion via Two-Stream Convolutional Neural Network for Hyperspectral Image Classification","X. Li; M. Ding; A. Pižurica","School of Instrumentation Science and Engineering, Harbin Institute of Technology, Harbin 150001, China, and also with the Department of Telecommunications and Information Processing, UGent-GAIM, Ghent University, 9000 Ghent, Belgium.; School of Instrumentation Science and Engineering, Harbin Institute of Technology, Harbin 150001, China (e-mail: dingml@hit.edu.cn).; School of Instrumentation Science and Engineering, Harbin Institute of Technology, Harbin 150001, China, and also with the Department of Telecommunications and Information Processing, UGent-GAIM, Ghent University, 9000 Ghent, Belgium.","IEEE Transactions on Geoscience and Remote Sensing","","2019","PP","99","1","15","The representation power of convolutional neural network (CNN) models for hyperspectral image (HSI) analysis is in practice limited by the available amount of the labeled samples, which is often insufficient to sustain deep networks with many parameters. We propose a novel approach to boost the network representation power with a two-stream 2-D CNN architecture. The proposed method extracts simultaneously, the spectral features and local spatial and global spatial features, with two 2-D CNN networks and makes use of channel correlations to identify the most informative features. Moreover, we propose a layer-specific regularization and a smooth normalization fusion scheme to adaptively learn the fusion weights for the spectral-spatial features from the two parallel streams. An important asset of our model is the simultaneous training of the feature extraction, fusion, and classification processes with the same cost function. Experimental results on several hyperspectral data sets demonstrate the efficacy of the proposed method compared with the state-of-the-art methods in the field.","","","10.1109/TGRS.2019.2952758","China Scholarship Council; Research Foundation Flanders FWO; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8920212","Convolutional neural networks (CNNs);feature fusion;hyperspectral image (HSI) classification;squeeze-and-excitation (SE).","Feature extraction;Training;Streaming media;Machine learning;Hyperspectral imaging;Convolutional neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Parallel reinforcement learning-based energy efficiency improvement for a cyber-physical system","T. Liu; B. Tian; Y. Ai; Y. Zou; F. Wang","Department of Automotive Engineering, Chongqing University, Chongqing 400044, China, and also with Vehicle Intelligence Pioneers Inc., Qingdao Shandong 266109, China; Vehicle Intelligence Pioneers Inc., Qingdao Shandong 266109, China, and also with the State Key Lab. of Manage. and Control for Complex Syst., Inst. of Autom., Beijing, China; Vehicle Intelligence Pioneers Inc., Qingdao Shandong 266109, China, and also with the School of Artificial Intelligence University of Chinese Academy of Sciences, Beijing, China; Beijing Collaborative and Innovative Center for Electric Vehicles and School of Mechanical Engineering, Beijing Institute of Technology, Beijing 100081 China; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing 100190 China","IEEE/CAA Journal of Automatica Sinica","","2019","PP","99","1","10","As a complex and critical cyber-physical system ( CPS ), the hybrid electric powertrain is significant to mitigate air pollution and improve fuel economy. Energy management strategy ( EMS ) is playing a key role to improve the energy efficiency of this CPS. This paper presents a novel bidirectional long short-term memory ( LSTM ) network based parallel reinforcement learning ( PRL ) approach to construct EMS for a hybrid tracked vehicle ( HTV ). This method contains two levels. The high-level establishes a parallel system first, which includes a real powertrain system and an artificial system. Then, the synthesized data from this parallel system is trained by a bidirectional LSTM network. The lower-level determines the optimal EMS using the trained action state function in the model-free reinforcement learning ( RL ) framework. PRL is a fully data-driven and learning- enabled approach that does not depend on any prediction and predefined rules. Finally, real vehicle testing is implemented and relevant experiment data is collected and calibrated. Experimental results validate that the proposed EMS can achieve considerable energy efficiency improvement by comparing with the conventional RL approach and deep RL.","","","10.1109/JAS.2019.1911633","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8766202","","Logic gates;Mechanical power transmission;Neurons;Reinforcement learning;Energy efficiency;Biological neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Neural Probabilistic Graphical Model for Face Sketch Synthesis","M. Zhang; N. Wang; Y. Li; X. Gao","State Key Laboratory of Integrated Services Networks, School of Telecommunications Engineering, Xidian University, Xi'an 710071, China, also with the Key Laboratory of Spectral Imaging Technology, Chinese Academy of Sciences, Xi'an 710119, China, and also with the Science and Technology on Reliability Physics and Application Technology of Electronic Component Laboratory, Guangzhou 510610, China.; State Key Laboratory of Integrated Services Networks, School of Telecommunications Engineering, Xidian University, Xi'an 710071, China (e-mail: nnwang@xidian.edu.cn).; State Key Laboratory of Integrated Services Networks, School of Telecommunications Engineering, Xidian University, Xi'an 710071, China.; State Key Laboratory of Integrated Services Networks, School of Electronic Engineering, Xidian University, Xi'an 710071, China.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","15","Neural network learning for face sketch synthesis from photos has attracted substantial attention due to its favorable synthesis performance. However, most existing deep-learning-based face sketch synthesis models stacked only by multiple convolutional layers without structured regression often lose the common facial structures, limiting their flexibility in a wide range of practical applications, including intelligent security and digital entertainment. In this article, we introduce a neural network to a probabilistic graphical model and propose a novel face sketch synthesis framework based on the neural probabilistic graphical model (NPGM) composed of a specific structure and a common structure. In the specific structure, we investigate a neural network for mapping the direct relationship between training photos and sketches, yielding the specific information and characteristic features of a test photo. In the common structure, the fidelity between the sketch pixels generated by the specific structure and their candidates selected from the training data are considered, ensuring the preservation of the common facial structure. Experimental results on the Chinese University of Hong Kong face sketch database demonstrate, both qualitatively and quantitatively, that the proposed NPGM-based face sketch synthesis approach can more effectively capture specific features and recover common structures compared with the state-of-the-art methods. Extensive experiments in practical applications further illustrate that the proposed method achieves superior performance.","","","10.1109/TNNLS.2019.2933590","National Natural Science Foundation of China; National Basic Research Program of China (973 Program); National High-Level Talents Special Support Program of China; Joint Fund of Ministry of Education for Equipment Pre-Research; China Post-Doctoral Science Foundation; Opening Project of Science and Technology on Reliability Physics and Application Technology of Electronic Component Laboratory; Open Research Fund of CAS Key Laboratory of Spectral Imaging Technology; Natural Science Basic Research Plan in Shaanxi Province of China; Young Talent Fund of the University Association for Science and Technology in Shaanxi China; Fundamental Research Funds for the Central Universities; CCF-Tencent Open Fund; 111 Project; Xidian University-Intellifusion Joint Innovation Laboratory of Artificial Intelligence; Light of West China of Chinese Academy of Sciences; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8824214","Common structure;face sketch synthesis;neural probabilistic graphical model (NPGM);specific structure.","Face;Graphical models;Learning systems;Probabilistic logic;Neural networks;Databases;Security","","","","2","","","","","","IEEE","IEEE Early Access Articles"
"Siamese Neural Networks for User Identity Linkage Through Web Browsing","Y. Qiao; Y. Wu; F. Duo; W. Lin; J. Yang","Artificial Intelligence Institute, Beijing University of Posts and Telecommunications (BUPT), Beijing 100876, China (e-mail:yyqiao@bupt.edu.cn).; Artificial Intelligence Institute, Beijing University of Posts and Telecommunications (BUPT), Beijing 100876, China.; Jacobs School of Engineering, University of California San Diego, San Diego, CA 92093 USA.; Technology Research Institute, Aisino Corporation, Beijing 100195, China.; Artificial Intelligence Institute, Beijing University of Posts and Telecommunications (BUPT), Beijing 100876, China (e-mail:janeyang@bupt.edu.cn).","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","11","Linking online identities of users among countless heterogeneous network services on the Internet can provide an explicit digital representation of users, which can benefit both research and industry. In recent years, user identity linkage (UIL) through the Internet has become an emerging task with great potential and many challenges. Existing works mainly focus on online social networks that consider inconsistent profiles, content, and networks as features or use sparse location-based data sets to link the online behaviors of a real person. To extend the UIL problem to a general scenario, we try to link the web-browsing behaviors of users, which can help to distinguish specific users from others, such as children or malicious users. More specifically, we propose a Siamese neural network (NN) architecture-based UIL (SAUIL) model that learns and compares the highest-level feature representation of input web-browsing behaviors with deep NNs. Although the number of matching and nonmatching pairs for the UIL problem is highly imbalanced, previous studies have not considered imbalanced UIL data sets. Therefore, we further address the imbalanced learning issue by proposing cost-sensitive SAUIL (C-SAUIL) model, which assumes higher costs for misclassifying the minority class. In the experiments, the proposed model is robust and exhibits a good performance on very large, real-world data sets collected from different regions with distinct characteristics.","","","10.1109/TNNLS.2019.2929575","National Natural Science Foundation of China; Funds of the Beijing Laboratory of Advanced Information Networks of the Beijing University of Posts and Telecommunications BUPT; Funds of the Beijing Key Laboratory of Network System Architecture and Convergence of BUPT; National Key Research and Development Program of China; Fundamental Research Funds for the Central Universities; 111 Project of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8796417","Cost-sensitive classification;loss function;Siamese neural networks (NNs);user identity linkage (UIL).","Feature extraction;Internet;Artificial neural networks;Data models;Learning systems;Couplings","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Convolutional Auto-Encoder Model for Finger-Vein Verification","B. Hou; R. Yan","School of Instrument Science and Engineering Southeast University Nanjing, China.; School of Instrument Science and Engineering Southeast University Nanjing, China.","IEEE Transactions on Instrumentation and Measurement","","2019","PP","99","1","1","This paper presents a novel deep learning-based method that integrates a Convolutional Auto-Encoder (CAE) with support vector machine (SVM) for finger vein verification. The CAE is used to learn the features from finger vein images and the SVM is used to classify finger vein from these learned feature codes. The CAE consists of a finger vein encoder, which extracts high-level feature representation from raw pixels of the images, and a decoder which outputs reconstruct finger vein images from high-level feature code. As an effective classifier, support vector machine (SVM) is introduced in this paper to classify the feature code which is obtained from CAE. Experiments prove that the proposed deep learning-based approach has superior performance in learning features than traditional method without any prior knowledge, presenting a good potential in the verification of finger vein.","","","10.1109/TIM.2019.2921135","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8731996","Biometrics;finger-vein;deep learning;convolutional auto-encoder;support vector machine","Feature extraction;Veins;Convolutional codes;Fingers;Support vector machines;Image reconstruction;Gabor filters","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Multi-organ Nucleus Segmentation Challenge","N. Kumar; R. Verma; D. Anand; Y. Zhou; O. F. Onder; E. Tsougenis; H. Chen; P. A. Heng; J. Li; Z. Hu; Y. Wang; N. A. Koohbanani; M. Jahanifar; N. Z. Tajeddin; A. Gooya; N. Rajpoot; X. Ren; S. Zhou; Q. Wang; D. Shen; C. K. Yang; C. H. Weng; W. H. Yu; C. Y. Yeh; S. Yang; S. Xu; P. H. Yeung; P. Sun; A. Mahbod; G. Schaefer; I. Ellinger; R. Ecker; O. Smedby; C. Wang; B. Chidester; T. V. Ton; M. Tran; J. Ma; M. N. Do; S. Graham; Q. D. Vu; J. T. Kwak; A. Gunda; R. Chunduri; C. Hu; X. Zhou; D. Lotfi; R. Safdari; A. Kascenas; A. O’Neil; D. Eschweiler; J. Stegmaier; Y. Cui; B. Yin; K. Chen; X. Tian; P. Gruening; E. Barth; E. Arbel; I. Remer; A. Ben-Dor; E. Sirazitdinova; M. Kohl; S. Braunewell; Y. Li; X. Xie; L. Shen; J. Ma; K. D. Baksi; M. A. Khan; J. Choo; A. n. Colomer; V. Naranjo; L. Pei; K. M. Iftekharuddin; K. Roy; D. Bhattacharjee; A. Pedraza; M. G. Bueno; S. Devanathan; S. Radhakrishnan; P. Koduganty; Z. Wu; G. Cai; X. Liu; Y. Wang; A. Sethi","Department of Pathology, University of Illinois at Chicago.; Department of Biomedical Engineering, Case Western Reserve University.; Department of Electrical Engineering, Indian Institute of Technology Bombay.; Department of Computer Science and Engineering, Chinese University of Hong Kong.; Imsight Medical Technology Inc., Hong Kong.; Imsight Medical Technology Inc., Hong Kong.; Imsight Medical Technology Inc., Hong Kong.; Department of Computer Science and Engineering, Chinese University of Hong Kong.; School of Computer Science, Beijing University of Post and Telecommunications, Beijing, China.; School of Electronics Engineering and Computer Science, Peking University, China.; Department of Electrical and Computer Engineering, University of Oklahoma, Oklahoma, USA.; Department of Computer Science, University of Warwick, Warwick, United Kingdom.; Department of Computer Science, University of Warwick, Warwick, United Kingdom.; Department of Computer Science, University of Warwick, Warwick, United Kingdom.; Department of Computer Science, University of Warwick, Warwick, United Kingdom.; Department of Computer Science, University of Warwick, Warwick, United Kingdom.; School of Biomedical Engineering, Shanghai Jiao Tong University, Shangai, China.; Department of Radiology and BRIC, University of North Carolina at Chapel Hill, Chapel Hill, North Carolina, USA.; School of Biomedical Engineering, Shanghai Jiao Tong University, Shangai, China.; Department of Radiology and BRIC, University of North Carolina at Chapel Hill, Chapel Hill, North Carolina, USA.; aetherAI, Taipei City, Taiwan.; aetherAI, Taipei City, Taiwan.; aetherAI, Taipei City, Taiwan.; aetherAI, Taipei City, Taiwan.; Zhejiang University, Hangzhou, Zhejiang, China.; Sun Yat-Sen University Cancer Center, Guangzhou, China and with Bio-totem Pte. Ltd, Shenzhen, China.; University of Hong Kong, Hong Kong and Bio-totem Pvt. Ltd, Shenzhen, China.; Sun Yat-Sen University Cancer Center, Guangzhou, China.; Institute for Pathophysiology and Allergy Research, Medical University of Viena, Viena, Austria.; Department of Computer Science, Loughborough University, Loughborough, United Kingdom.; Institute for Pathophysiology and Allergy Research, Medical University of Viena, Viena, Austria.; TissueGnostics GmbH, Vienna, Austria.; Department of Biomedical Engineering and Health Systems, KTH Royal Institute of Technology, Stockholm, Sweden.; Department of Biomedical Engineering and Health Systems, KTH Royal Institute of Technology, Stockholm, Sweden.; School of Computer Science, Carnegie Mellon University, Pennsylvania, USA.; Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Illinois, USA.; University of Science, Vietnam National University, Vietnam.; School of Computer Science, Carnegie Mellon University, Pennsylvania, USA.; Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Illinois, USA.; Department of Computer Science, University of Warwick, Warwick, United Kingdom.; College of Software Convergence, Sejong University, Seoul, South Korea.; College of Software Convergence, Sejong University, Seoul, South Korea.; Department of Mechanical Engineering, Indian Intitute of Technology Madras, Chennai, India.; Department of Pathology, University of Illinois at Chicago.; Department of Aerospace Engineering, Indian Institute of Technology Bombay, Mumbai, India.; Department of Aerospace Engineering, Indian Institute of Technology Bombay, Mumbai, India.; Department of Computer Science, University of California Berkeley, California, USA.; Department of Computer Science, University of California Berkeley, California, USA.; Hong Kong University of Science and Technology, Hong Kong.; Hong Kong University of Science and Technology, Hong Kong.; Tehran Science and Research and Qazvin Branches of the Islamic Azad University, Iran.; Tehran Science and Research and Qazvin Branches of the Islamic Azad University, Iran.; Canon Medical Research Europe, Edinburgh, United Kingdom.; Institute of Imaging and Computer Vision, RWTH Aachen University, Aachen, Germany.; Institute of Imaging and Computer Vision, RWTH Aachen University, Aachen, Germany.; Canon Medical Research Europe, Edinburgh, United Kingdom.; University of Science and Technology of China, Anhui, China.; University of Science and Technology of China, Anhui, China.; iFlytek AI Research, Guangzhou, China.; iFlytek AI Research, Guangzhou, China.; iFlytek AI Research, Guangzhou, China.; Department of Computer Science, Institute for Neuro- and Bioinformatics, University of Lübeck, Lübeck, Germany.; Department of Computer Science, Institute for Neuro- and Bioinformatics, University of Lübeck, Lübeck, Germany.; Department of Computer Science, Institute for Neuro- and Bioinformatics, University of Lübeck, Lübeck, Germany.; Agilent Labs, Agilent Technologies Ltd., Tel-Aviv, Israel.; Agilent Labs, Agilent Technologies Ltd., Tel-Aviv, Israel.; Agilent Labs, Agilent Technologies Ltd., Tel-Aviv, Israel.; Konica Minolta Laboratory Europe, Munich, Germany.; Computer Vision Institute, Shenzhen University, Shenzhen, China.; Department of Mathematics, Nanjing University of Science and Technology, Nanjing, China.; Department of Mathematics, Nanjing University of Science and Technology, Nanjing, China.; Biosciences R&D, TCS Research, TATA Consultancy Services Ltd., Pune, India.; Biosciences R&D, TCS Research, TATA Consultancy Services Ltd., Pune, India.; Department of Computer Science and Engineering, Korea University, Seoul, South Korea.; Department of Computer Science and Engineering, Korea University, Seoul, South Korea.; Instituto de Investigación e Innovación en Bioingeníera, Universitat Politècnica de València, València, Spain.; Instituto de Investigación e Innovación en Bioingeníera, Universitat Politècnica de València, València, Spain.; Department of Electrical & Computer Engineering, Old Dominion University, Norfolk, Virginia.; Department of Electrical & Computer Engineering, Old Dominion University, Norfolk, Virginia.; Department of Computer Science and Engineering, Jadavpur University, Kolkata, India.; Visilab Research Group, University of Castilla - La Mancha, Ciudad Real, Spain.; Cognizant Technology Solutions India Private Ltd, India.; Xiamen University, Xiamen, China.; Department of Computer Science, Tongji University, Shanghai, China.; Department of Computer Science, Tongji University, Shanghai, China.; Department of Computer Science, Tongji University, Shanghai, China.; Department of Electrical Engineering, Indian Institute of Technology Bombay, Mumbai, India.","IEEE Transactions on Medical Imaging","","2019","PP","99","1","1","Generalized nucleus segmentation techniques can contribute greatly to reducing the time to develop and validate visual biomarkers for new digital pathology datasets. We summarize the results of MoNuSeg 2018 Challenge whose objective was to develop generalizable nuclei segmentation techniques in digital pathology. The challenge was an official satellite event of the MICCAI 2018 conference in which 32 teams with more than 80 participants from geographically diverse institutes participated. Contestants were given a training set with 30 images from seven organs with annotations of 21,623 individual nuclei. A test dataset with 14 images taken from seven organs, including two organs that did not appear in the training set was released without annotations. Entries were evaluated based on average aggregated Jaccard index (AJI) on the test set to prioritize accurate instance segmentation as opposed to mere semantic segmentation. More than half the teams that completed the challenge outperformed a previous baseline 1. Among the trends observed that contributed to increased accuracy were the use of color normalization as well as heavy data augmentation. Additionally, fully convolutional networks inspired by variants of U-Net 2, FCN 3, and Mask-RCNN 4 were popularly used, typically based on ResNet 5 or VGG 6 base architectures. Watershed segmentation on predicted semantic segmentation maps was a popular post-processing strategy. Several of the top techniques compared favorably to an individual human annotator and can be used with confidence for nuclear morphometrics.","","","10.1109/TMI.2019.2947628","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8880654","Multi-organ;nucleus segmentation;digital pathology;instance segmentation;aggregated Jaccard index","Image segmentation;Pathology;Image color analysis;Semantics;Machine learning algorithms;Task analysis;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Incorporating Human Domain Knowledge in 3D LiDAR-based Semantic Segmentation","J. Mei; H. Zhao","School of Electronics Engineering and Computer Science, Peking University, 12465 Beijing, Beijing China (e-mail: mjlsuccess@pku.edu.cn); School of Electronics Engineering and Computer Science, Peking University, Beijing, Beijing China 100871 (e-mail: zhaohj@cis.pku.edu.cn)","IEEE Transactions on Intelligent Vehicles","","2019","PP","99","1","1","This work studies semantic segmentation using 3D LiDAR data. Popular deep learning methods applied for this task require a large number of manual annotations to train the parameters. We propose a new method that makes full use of the advantages of traditional methods and deep learning methods via incorporating human domain knowledge into the neural network model to reduce the demand for large numbers of manual annotations and improve the training efficiency. We first pretrain a model with autogenerated samples from a rule-based classifier so that human knowledge can be propagated into the network. Based on the pretrained model, only a small set of annotations is required for further fine-tuning. Quantitative experiments show that the pretrained model achieves better performance than random initialization in almost all cases; furthermore, our method can achieve similar performance with fewer manual annotations.","","","10.1109/TIV.2019.2955851","National Natural Science Foundation of China; National Basic Research Program of China (973 Program); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8911436","3D LiDAR data;semantic segmentation;human domain knowledge","Three-dimensional displays;Semantics;Laser radar;Image segmentation;Manuals;Deep learning;Neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Constrained Magnetic Resonance Spectroscopic Imaging by Learning Nonlinear Low-Dimensional Models","F. Lam; Y. Li; X. Peng","Department of Bioengineering and the Beckman Institute for Advanced Science and Technology, University of Illinois at Urbana-Champaign, Urbana, IL, 61801 USA.; Department and Bioengineering, University of Illinois at Urbana-Champaign.; University of Illinois at Urbana-Champaign.","IEEE Transactions on Medical Imaging","","2019","PP","99","1","1","Magnetic resonance spectroscopic imaging (MRSI) is a powerful molecular imaging modality but has very limited speed, resolution and SNR tradeoffs. Construction of a lowdimensional model to effectively reduce the dimensionality of the imaging problem has recently shown great promise in improving these tradeoffs. This work presents a new approach to model and reconstruct spectroscopic signals, by learning a nonlinear lowdimensional representation of general MR spectra. Specifically, we trained a deep neural network to capture the low-dimensional manifold where the high-dimensional spectroscopic signals reside. A regularization formulation is proposed to effectively integrate the learned model and physics-based data acquisition model for MRSI reconstruction, with the capability to incorporate additional spatiospectral constraints. An efficient numerical algorithm was developed to solve the associated optimization problem involving back-propagating the trained network. Simulation and experimental results were obtained to demonstrate the representation power of the learned model and the ability of the proposed formulation in producing SNR-enhancing reconstruction from practical MRSI data.","","","10.1109/TMI.2019.2930586","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8770102","MR spectroscopic imaging;spectroscopy;lowdimensional models;neural network;manifold learning;spatiospectral reconstruction","Data models;Feature extraction;Image reconstruction;Imaging;Neural networks;Manifolds;Signal to noise ratio","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Every Pixel Counts ++: Joint Learning of Geometry and Motion with 3D Holistic Understanding","C. Luo; Z. Yang; P. Wang; Y. Wang; W. Xu; R. Nevatia; A. Yuille","Computer Science, Johns Hopkins University, 1466 Baltimore, Maryland United States (e-mail: chenxuluo@jhu.edu); Computer Science, University of Southern California Viterbi School of Engineering, 115098 Los Angeles, California United States 90089 (e-mail: zhenheny@usc.edu); Baidu Research, Baidu, Sunnyvale, California United States 94089 (e-mail: wangpeng54@baidu.com); Baidu USA Inc., Sunnyvale, California United States (e-mail: wangyangcharles@gmail.com); Horizon Robotics, Sunnyvale, California United States (e-mail: emailweixu@gmail.com); Computer Science, University of Southern California, Los Angeles, California United States (e-mail: nevatia@usc.edu); Computer Science, Johns Hopkins University, 1466 Baltimore, Maryland United States (e-mail: ayuille1@jhu.edu)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Learning to estimate 3D geometry in a single frame and optical flow from consecutive frames by watching unlabeled videos via deep convolutional network has made significant progress recently. Current state-of-the-art (SoTA) methods treat the two tasks independently. One important assumption of the existing depth estimation methods is that the scenes contain no moving object. In this paper, we propose to address the two tasks as a whole, i.e. to jointly understand per-pixel 3D geometry and motion. This eliminates the need of static scene assumption and enforces the inherent geometrical consistency during the learning process, yielding significantly improved results for both tasks. We call our method as ""Every Pixel Counts++"" or ""EPC++"". Various loss terms are formulated to jointly supervise the learning across geometrical cues and effective adaptive training strategy is proposed to achieve better performance. Comprehensive experiments were conducted on datasets with different scenes, including driving scenario (KITTI 2012 and KITTI 2015 datasets), mixed outdoor/indoor scenes (Make3D) and synthetic animation (MPI Sintel dataset). Performance on the five tasks of depth estimation, optical flow estimation, odometry, moving object segmentation and scene flow estimation shows that our approach outperforms other SoTA methods, demonstrating the effectiveness of each module of our proposed method.","","","10.1109/TPAMI.2019.2930258","Office of Naval Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8769907","Depth Estimation;Optical Flow Prediction;Unsupervised Learning","Estimation;Optical imaging;Three-dimensional displays;Cameras;Videos;Geometry;Task analysis","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Adversarial Learning of Structure-Aware Fully Convolutional Networks for Landmark Localization","Y. Chen; C. Shen; H. Chen; X. Wei; L. Liu; J. Yang","School of Computer Science and Engineering, Nanjing University of Science and Technology, 12436 Nanjing, Jiangsu China 210094 (e-mail: chenyu1523@gmail.com); School of Computer Science, The University of Adelaide, Adelaide, South Australia Australia 5005 (e-mail: chhshen@gmail.com); School of Computer Science, The University of Adelaide, Adelaide, South Australia Australia (e-mail: hao.chen01@adelaide.edu.au); Nanjing University, Nanjing, Jiangsu China (e-mail: weixs.gm@gmail.com); School of Computer Science, University of Adelaide, Adelaide, South Australia Australia (e-mail: lingqiao.liu@adelaide.edu.au); Computer Science, Nanjing University of Science and Technology, Nanjing, Jiangsu China (e-mail: csjyang@njust.edu.cn)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Landmark/pose estimation in single monocular images has received much effort in computer vision due to its important applications. It remains a challenging task when input images come with severe occlusions caused by, e.g., adverse camera views. Under such circumstances, biologically implausible pose predictions may be produced. In contrast, human vision is able to predict poses by exploiting geometric constraints of landmark point inter-connectivity. To address the problem, by incorporating priors about the structure of pose components, we propose a novel structure-aware fully convolutional network to implicitly take such priors into account during training of the deep network. Explicit learning of such constraints is typically challenging. Instead, inspired by how human identifies implausible poses, we design discriminators to distinguish the real poses from the fake ones (such as biologically implausible ones). If the pose generator G generates results that the discriminator fails to distinguish from real ones, the network successfully learns the priors. Training of the network follows the strategy of conditional Generative Adversarial Networks (GANs). The effectiveness of the proposed network is evaluated on three pose-related tasks: 2D human pose estimation, 2D facial landmark estimation and 3D human pose estimation. The proposed approach significantly outperforms several state-of-the-art methods and almost always generates plausible pose predictions, demonstrating the usefulness of implicit learning of structures using GANs.","","","10.1109/TPAMI.2019.2901875","National Science Fund of China; Australian Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8653313","Pose Estimation;Landmark Localization;Structure-aware Network;Adversarial Training;Multi-task Learning","Pose estimation;Two dimensional displays;Three-dimensional displays;Heating systems;Task analysis;Training","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Efficient Provision of Service Function Chains in Overlay Networks using Reinforcement Learning","G. Li; H. Zhou; B. Feng; Y. Zhang; S. Yu","School of Electronic and Information Engineering, Beijing Jiaotong University, 47829 Beijing, Beijing China (e-mail: guangleili@bjtu.edu.cn); School of Electronic and Information Engineering, Beijing Jiaotong University, 47829 Beijing, Beijing China (e-mail: hchzhou@bjtu.edu.cn); School of Electronic and Information Engineering, Beijing Jiaotong University, 47829 Beijing, Beijing China 100044 (e-mail: bhfeng@bjtu.edu.cn); School of Electronic and Information Engineering, Beijing Jiaotong University, 47829 Beijing, Beijing China (e-mail: yumingzhang@bjtu.edu.cn); School of Software, University of Technology Sydney Faculty of Engineering and Information Technology, 120558 Ultimo, New South Wales Australia 2007 (e-mail: shui.yu@uts.edu.au)","IEEE Transactions on Cloud Computing","","2019","PP","99","1","1","Software-Defined Networking (SDN) and Network Functions Virtualization (NFV) technologies facilitate deploying Service Function Chains (SFCs) at clouds in efficiency and flexibility. However, it is still challenging to efficiently chain Virtualized Network Functions (VNFs) in overlay networks without knowledge of underlying network configurations. Although there are many deterministic approaches for VNF placement and chaining, they have high complexity and depend on state information of substrate networks. Fortunately, Reinforcement Learning (RL) brings opportunities to alleviate this challenge as it can learn to make suitable decisions without prior knowledge. Therefore, in this paper, we propose an RL approach for efficient SFC provision in overlay networks, where the same VNFs provided by multiple vendors are with different performance. Specifically, we first formulate the problem into an Integer Linear Programming (ILP) model for benchmarking. Then, we present the online SFC path selection into a Markov Decision Process (MDP) and propose a corresponding policy-gradient-based solution. Finally, we evaluate our proposed approach with extensive simulations with randomly generated SFC requests and a real-world video streaming dataset, and implement an emulation system for feasibility verification. Related results demonstrate that performance of our approach is close to the ILP-based method and better than deep Q-learning, random, and load-least-greedy methods.","","","10.1109/TCC.2019.2961093","National Key R and D Program of China; National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8939325","Service Function Chains;Overlay Networks;Policy Gradient;Reinforcement Learning","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Biologically Plausible Fuzzy-Knowledge-Out and Its Induced Wide Learning of Interpretable TSK Fuzzy Classifiers","B. Qin; F. Chung; S. Wang","School of Digital Media, Jiangnan University, 66374 Wuxi, Jiangsu China 214122 (e-mail: qinbin_sd@126.com); Computing, Hong Kong Polytechnic University, Hong Kong Hong Kong N.A. (e-mail: cskchung@comp.polyu.edu.hk); School of Information, Southern Yangtse University, WuXi, Jiangsu China 214122 (e-mail: wxwangst@aliyun.com)","IEEE Transactions on Fuzzy Systems","","2019","PP","99","1","1","As an alternative to existing construction methods of Takagi-Sugeno-Kang (TSK) fuzzy classifiers, this work presents a novel design methodology formulated by a new concept called fuzzy-knowledge-out and its induced wide learning way. Analogous to the “dropout” concept in deep learning, the concept of fuzzy-knowledge-out in TSK fuzzy classifiers is motivated by the firing pattern of knowledge in biological neural networks. Our theoretical analysis reveals that a fuzzy classifier built after fuzzy-knowledge-out from a complete set of highly interpretable fuzzy rules is distinctive in generalization and co-adaption avoidance. As such, an ensemble, called WL-TSK, of highly interpretable zero-order TSK fuzzy sub-classifiers constructed quickly by means of fuzzy-knowledge-out operations in a wide learning manner is proposed to achieve enhanced classification performance and high interpretability. With the use of the proposed halving or averaging operations, WL-TSK essentially behaves like only one zero-order TSK fuzzy classifier. Thus, the proposed method can be considered as a new design methodology of TSK fuzzy classifiers. Our experimental results on fifteen datasets indicate the effectiveness of WL-TSK in terms of both enhanced classification performance and high interpretability.","","","10.1109/TFUZZ.2019.2907497","Natural Science Foundation of Jiangsu Province; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8673902","Takagi-Sugeno-Kang (TSK) fuzzy classifier;Wide learning;Fuzzy-knowledge-out;Overfitting;Co-adaption","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"On the Convergence of Learning-based Iterative Methods for Nonconvex Inverse Problems","R. Liu; S. Cheng; Y. He; X. Fan; Z. Lin; Z. Luo","School of Software Technology, Dalian University of Technology, Dalian, Liaoning China (e-mail: rsliu@dlut.edu.cn); School of Mathematical Sciences, Dalian University of Technology, 12399 Dalian, Liaoning China (e-mail: shichao.cheng@outlook.com); School of Software Technology, Dalian University of Technology, 12399 Dalian, Liaoning China (e-mail: heyiking@outlook.com); DUT-RU Intenational School of Information Science and Technology, Dalian University of Technology, Dalian, Liaoning China (e-mail: xin.fan@dlut.edu.cn); Key Lab. of Machine Perception (MOE), Peking University, Beijing, Beijing China 100080 (e-mail: zlin@pku.edu.cn); School of Mathematical Sciences, Dalian University of Technology, Dalian, Liaoning China (e-mail: zxluo@dlut.edu.cn)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Numerous tasks at the core of statistics, learning and vision areas are specific cases of ill-posed inverse problems. Recently, learning-based (e.g., deep) iterative methods have been empirically shown to be useful for these problems. Nevertheless, integrating learnable structures into iterations is still a laborious process, which can only be guided by intuitions or empirical insights. Moreover, there is a lack of rigorous analysis about the convergence behaviors of these reimplemented iterations, and thus the significance of such methods is a little bit vague. This paper moves beyond these limits and proposes Flexible Iterative Modularization Algorithm (FIMA), a generic and provable paradigm for nonconvex inverse problems. Our theoretical analysis reveals that FIMA allows us to generate globally convergent trajectories for learning-based iterative methods. Meanwhile, the devised scheduling policies on flexible modules should also be beneficial for classical numerical methods in the nonconvex scenario. Extensive experiments on real applications verify the superiority of FIMA.","","","10.1109/TPAMI.2019.2920591","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8727950","Nonconvex optimization;Learning-based iteration;Global convergence;Computer vision","Inverse problems;Convergence;Task analysis;Trajectory;Acceleration;Iterative algorithms","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Self-Enhanced Convolutional Network for Facial Video Hallucination","C. Fang; G. Li; X. Han; Y. Yu","PhD candidate at the Department of Computer Science, The University of Hong Kong, Hong Kong.; School of Data and Computer Science, Sun Yat-sen University, Guangzhou 510006, China.; Shenzhen Research Institute of Big Data, The Chinese University of Hong Kong (Shenzhen), Shenzhen 518172, China.; Department of Computer Science, The University of Hong Kong, Hong Kong.","IEEE Transactions on Image Processing","","2019","PP","99","1","1","As a domain-specific super-resolution problem, facial image hallucination has enjoyed a series of breakthroughs thanks to the advances of deep convolutional neural networks. However, the direct migration of existing methods to video is still difficult to achieve good performance due to its lack of alignment and consistency modelling in temporal domain. Taking advantage of high inter-frame dependency in videos, we propose a selfenhanced convolutional network for facial video hallucination. It is implemented by making full usage of preceding super-resolved frames and a temporal window of adjacent low-resolution frames. Specifically, the algorithm first obtains the initial high-resolution inference of each frame by taking into consideration a sequence of consecutive low-resolution inputs through temporal consistency modelling. It further recurrently exploits the reconstructed results and intermediate features of a sequence of preceding frames to improve the initial super-resolution of the current frame by modelling the coherence of structural facial features across frames. Quantitative and qualitative evaluations demonstrate the superiority of the proposed algorithm against state-of-theart methods. Moreover, our algorithm also achieves excellent performance in the task of general video super-resolution in a single-shot setting.","","","10.1109/TIP.2019.2955640","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8920227","facial video hallucination;recurrent frame fusion;sequential feature encoding;deep learning.","Spatial resolution;Face;Image reconstruction;Machine learning;Image restoration;Computer science","","","","","","","","","","IEEE","IEEE Early Access Articles"
"The Gap of Semantic Parsing: A Survey on Automatic Math Word Problem Solvers","D. Zhang; L. Wang; L. Zhang; B. T. Dai; H. T. Shen","Computer Science, University of Electronic Science and Technology of China, 12599 Chengdu, Sichuan China (e-mail: zhangdongxiang37@gmail.com); Computer Science, University of Electronic Science and Technology of China, 12599 Chengdu, Sichuan China (e-mail: demolei@outlook.com); College of Computer Science, Zhejiang University, 12377 Hangzhou, Zhejiang China (e-mail: zglumg@gmail.com); Information System, Singapore Management University, 54756 Singapore, Singapore Singapore (e-mail: btdai@smu.edu.sg); School of Computer Science and Engineering, University of Electronic Science and Technology of China, 12599 Chengdu, Sichuhan China 610054 (e-mail: shenhengtao@hotmail.com)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Solving mathematical word problems (MWPs) automatically is challenging, primarily due to the semantic gap between human-readable words and machine-understandable logics. Despite the long history dated back to the $1960$s, MWPs have regained intensive attention in the past few years with the advancement of Artificial Intelligence (AI). Solving MWPs successfully is considered as a milestone towards general AI. Many systems have claimed promising results in self-crafted and small-scale datasets. However, when applied on large and diverse datasets, none of the proposed methods in the literature achieves high precision, revealing that current MWP solvers still have much room for improvement. This motivated us to present a comprehensive survey to deliver a clear and complete picture of automatic math problem solvers. In this survey, we emphasize on algebraic word problems, summarize their extracted features and proposed techniques to bridge the semantic gap, and compare their performance in the publicly accessible datasets. We also cover automatic solvers for other types of math problems such as geometric problems that require the understanding of diagrams. Finally, we identify several emerging research directions for the readers with interests in MWPs.","","","10.1109/TPAMI.2019.2914054","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8703135","math word problem;semantic parser;reasoning;survey;natural language processing;machine learning","Semantics;Feature extraction;Mathematical model;Cognition;Natural languages;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Distortion Rectification from Static to Dynamic: A Distortion Sequence Construction Perspective","K. Liao; C. Lin; Y. Zhao; M. Gabboujd","Institute of Information Science, Beijing Jiaotong University, Beijing 100044, China and Beijing Key Laboratory of Advanced Information Science and Network Technology, Beijing 100044, China.; Institute of Information Science, Beijing Jiaotong University, Beijing 100044, China and Beijing Key Laboratory of Advanced Information Science and Network Technology, Beijing 100044, China.; Institute of Information Science, Beijing Jiaotong University, Beijing 100044, China and Beijing Key Laboratory of Advanced Information Science and Network Technology, Beijing 100044, China.; Department of Signal Processing, Tampere University of Technology, Tampere 33720, Finland.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Distortion rectification is a fundamental task in the field of computer vision and image processing. Nevertheless, previous methods have regarded distortion rectification as a static problem that learns a mapping function and corrects the distorted image to a unique state. However, this state is generally not the optimal solution, as it would result in an under-rectified or over-rectified structure. In this study, we revisit the classical distortion rectification task with a new perspective and redesign the algorithm, inspired by video processing techniques. Specifically, we regard distortion rectification as a dynamic problem that can be extended to a sequence of different distortion states: the input distorted image (t), under-rectified image (t+1), ideal-rectified image (t+2), and over-rectified image (t+3). We first estimate the residual distortion map (RDM) between the input distorted image and the coarse-rectified (t+1 or t+3) image. Here, RDM indicates the motion difference between two distorted images. Subsequently, the RDM is used to guide the refinement rectification process, aiming to convert the coarse-rectified state into the ideal-rectified state. In addition, the flexible implementation of the proposed refinement process with RDM to improve the rectification results of any method is appealing. The experimental results demonstrate that our method outperforms the state-of-the-art schemes by a significant margin, revealing approximately 40% improvement through quantitative evaluation.","","","10.1109/TCSVT.2019.2958199","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8926530","Distortion Rectification;Deep Learning;Video Processing;Dynamic Construction","Cameras;Nonlinear distortion;Optical distortion;Task analysis;Feature extraction;Learning systems","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Ensemble of Deep Convolutional Neural Networks with Gabor Face Representations for Face Recognition","J. Y. Choi; B. S. Lee","Pattern Recognition and Machine Intelligence (PMI) Lab., Division of Computer & Electronic Systems Engineering, Hankuk University of Foreign Studies, 81, Oedae-ro, Mohyeon-myeon, Cheoin-gu, Yongin-si, Gyeonggi-do, 17305, Republic of Korea.; Multimedia Information Processing Lab., Department of Information and Communications Engineering, Chosun University, Pilmundaero 309, Gwangju, Republic of Korea.","IEEE Transactions on Image Processing","","2019","PP","99","1","1","Most DCNN-based FR approaches typically employ grayscale or RGB color images as input representations of DCNN architectures. However, other effective face representation methods have been developed and incorporated into current practical FR systems. In light of this fact, the focus of our study is to employ Gabor face representations in the design of DCNN-based FR frameworks to improve FR performance. To this end, we develop a novel “Gabor DCNN (GDCNN)” ensemble method that effectively applies different and multiple Gabor face representations as inputs during the training and testing phases of a DCNN for FR applications. The proposed GDCNN ensemble method primarily consists of two parts: 1) GDCNN ensemble construction and 2) GDCNN ensemble combination. The goal of the former part is to build an ensemble of GDCNN members (i.e., base models), each learned with a particular type of Gabor face representation. The objective of the latter part is to adaptively combine multiple FR outputs of individual GDCNN members. We perform extensive experiments to evaluate our proposed method on four public face databases (DBs) using the associated standard evaluation protocols. Experimental results demonstrate that our approach exhibits significantly better FR performance than typical DCNN-based approaches that rely only on grayscale or color face images as input representations. In addition, the feasibility of our proposed GDCNN ensemble has been successfully demonstrated by making comparisons with other state-of-the-art DCNN-based FR methods.","","","10.1109/TIP.2019.2958404","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8936536","Deep Convolutional Neural Network (DCNN);Gabor Face Representations;Gabor DCNN (GDCNN) Ensemble;Face Recognition (FR);Confidence based Majority Voting","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Transient Thermography for Flaw Detection in Friction Stir Welding: A machine learning approach","M. Atwya; G. Panoutsos","Department of Automatic Control and Systems Engineering, University of Sheffield, 7315 Sheffield United Kingdom of Great Britain and Northern Ireland S1 3JD (e-mail: Matwya1@Sheffield.ac.uk); Department of Automatic Control and Systems Engineering, University of Sheffield, 7315 Sheffield United Kingdom of Great Britain and Northern Ireland S1 3JD (e-mail: g.panoutsos@sheffield.ac.uk)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","A systematic computational method to simulate and detect sub-surface flaws, through non-destructive transient thermography, in aluminium sheets and friction stir welded sheets is proposed. The proposed method relies on feature extraction methods and a data driven machine learning modelling structure. In this work, we propose the use of a multi-layer perceptron feed-forward neural-network with feature extraction methods to improve the flaw-probing depth of transient thermography inspection. Furthermore, for the first time, we propose Thermographic Signal Linear Modelling (TSLM), a hyper-parameterfree feature extraction technique for transient thermography. The new feature extraction and modelling framework was tested with out-of-sample experimental transient thermography data and results show effectiveness in sub-surface flaw detection of up to 2.3 mm deep in aluminium sheets (99.8 % true positive rate, 92.1 % true negative rate) and up to 2.2 mm deep in friction stir welds (97.2 % true positive rate, 87.8 % true negative rate).","","","10.1109/TII.2019.2948023","University of Sheffield; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8873595","Friction-stir welding;Non-destructive testing;Infrared thermal imaging;Image processing;Transient thermography;Artificial neural-network;Machine learning","Welding;Feature extraction;Transient analysis;Thermal conductivity;Heating systems;Testing;Signal to noise ratio","","","","","","","","","","IEEE","IEEE Early Access Articles"
"One shot segmentation: unifying rigid detection and non-rigid segmentation using elastic regularization","J. C. Nascimento; G. Carneiro","Electrical and Computer Engineering, IST/ISR, Lisbon, Portugal Portugal 1049-001 (e-mail: jan@isr.ist.utl.pt); School of Computer Science, University of Adelaide Faculty of the Professions, 95343 Adelaide, South Australia Australia (e-mail: gustavo.carneiro@adelaide.edu.au)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","This paper proposes a novel approach for the non-rigid segmentation of deformable objects in image sequences, which is based on one-shot segmentation that unifies rigid detection and non-rigid segmentation using elastic regularization. The domain of application is the segmentation of a visual object that temporally undergoes a rigid transformation (e.g., affine transformation) and a non-rigid transformation (i.e., contour deformation). The majority of segmentation approaches to solve this problem are generally based on two steps that run in sequence: a rigid detection, followed by a non-rigid segmentation. In this paper, we propose a new approach, where both the rigid and non-rigid segmentation are performed in a single shot using a sparse low-dimensional manifold that represents the visual object deformations. Given the multi-modality of these deformations, the manifold partitions the training data into several patches, where each patch provides a segmentation proposal during the inference process. These multiple segmentation proposals are merged using the classification results produced by deep belief networks (DBN) that compute the confidence on each segmentation proposal. Thus, an ensemble of DBN classifiers is used for estimating the final segmentation. Compared to current methods proposed in the field, our proposed approach is advantageous in four aspects: (i) it is a unified framework to produce rigid and non-rigid segmentations; (ii) it uses an ensemble classification process, which can help the segmentation robustness; (iii) it provides a significant reduction in terms of the number of dimensions of the rigid and non-rigid segmentations search spaces, compared to current approaches that divide these two problems; and (iv) this lower dimensionality of the search space can also reduce the need for large annotated training sets to be used for estimating the DBN models. Experiments on the problem of left ventricle endocardial segmentation from ultrasound images, and lip segmentation from frontal facial images using the extended Cohn-Kanade (CK+) database, demonstrate the potential of the methodology through qualitative and quantitative evaluations, and the ability to reduce the search and training complexities without a significant impact on the segmentation accuracy.","","","10.1109/TPAMI.2019.2922959","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8736792","Deep Learning;Data augmentation;Manifold learning;Object Segmentation","Image segmentation;Training;Complexity theory;Visualization;Shape;Object segmentation;Strain","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Architecting Effectual Computation for Machine Learning Accelerators","H. Lu; M. Zhang; Y. Han; H. Li; X. Li","Institute of Computing Technology, Chinese Academy of Sciences, Kexueyuan South No. 6, Zhongguancun, Beijing 100190, China.; Institute of Computing Technology, Chinese Academy of Sciences, Kexueyuan South No. 6, Zhongguancun, Beijing 100190, China.; Institute of Computing Technology, Chinese Academy of Sciences, Kexueyuan South No. 6, Zhongguancun, Beijing 100190, China.; Institute of Computing Technology, Chinese Academy of Sciences, Kexueyuan South No. 6, Zhongguancun, Beijing 100190, China.; Institute of Computing Technology, Chinese Academy of Sciences, Kexueyuan South No. 6, Zhongguancun, Beijing 100190, China.","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","","2019","PP","99","1","1","Inference efficiency is the predominant design consideration for modern machine learning accelerators. The ability of executing multiply-and-accumulate (MAC) significantly impacts the throughput and energy consumption during inference. However, MAC operation suffers from significant ineffectual computations that severely undermines the inference efficiency and must be appropriately handled by the accelerator. The ineffectual computations are manifested in two ways: firstly, zero values as the input operands of the multiplier, waste time and energy but contribute nothing to the model inference; secondly, zero bits in non-zero values occupy a large portion of multiplication time but are useless to the final result. In this article, we propose an ineffectual-free yet cost-effective computing architecture, called Split-and-ACcumulate (SAC) with two essential bit detection mechanisms to address these intractable problems in tandem. It replaces the conventional MAC operation in the accelerator by only manipulating the essential bits in the parameters (weights) to accomplish the partial sum computation. Besides, it also eliminates multiplications without any accuracy loss, and supports a wide range of precision configurations. Based on SAC, we propose an accelerator family called Tetris and demonstrate its application in accelerating state-of-the-art deep learning models. Tetris includes two implementations designed for either high performance (i.e. cloud applications) or low power consumption (i.e. edge devices) respectively, contingent to its built-in essential bit detection mechanism. We evaluate our design with Vivado HLS platform and achieve up to 6.96x performance enhancement, and up to 55.1x energy efficiency improvement over conventional accelerator designs.","","","10.1109/TCAD.2019.2946810","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8865615",".","Computational modeling;Throughput;Adders;Machine learning;Acceleration;Kernel;Computational efficiency","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Survey of Computational Intelligence Techniques for Wind Power Uncertainty Quantification in Smart Grids","H. Quan; A. Khosravi; D. Yang; D. Srinivasan","Department of Electrical Engineering, School of Automation, Nanjing University of Science and Technology, Nanjing 210094, China (e-mail: quanhao@njust.edu.cn).; Institute for Intelligent Systems Research and Innovation, Deakin University, Geelong, VIC 3220, Australia.; Singapore Institute of Manufacturing Technology, Agency for Science, Technology and Research, Singapore 138634.; Department of Electrical and Computer Engineering, National University of Singapore, Singapore 117576.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","18","The high penetration level of renewable energy is thought to be one of the basic characteristics of future smart grids. Wind power, as one of the most increasing renewable energy, has brought a large number of uncertainties into the power systems. These uncertainties would require system operators to change their traditional ways of decision-making. This article provides a comprehensive survey of computational intelligence techniques for wind power uncertainty quantification in smart grids. First, prediction intervals (PIs) are introduced as a means to quantify the uncertainties in wind power forecasts. Various PI evaluation indices, including the latest trends in comprehensive evaluation techniques, are compared. Furthermore, computational intelligence-based PI construction methods are summarized and classified into traditional methods (parametric) and direct PI construction methods (nonparametric). In the second part of this article, methods of incorporating wind power forecast uncertainties into power system decision-making processes are investigated. Three techniques, namely, stochastic models, fuzzy logic models, and robust optimization, and different power system applications using these techniques are reviewed. Finally, future research directions, such as spatiotemporal and hierarchical forecasting, deep learning-based methods, and integration of predictive uncertainty estimates into the decision-making process, are discussed. This survey can benefit the readers by providing a complete technical summary of wind power uncertainty quantification and decision-making in smart grids.","","","10.1109/TNNLS.2019.2956195","National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8937810","Computational intelligence;decision-making;neural network (NN);prediction interval (PI);uncertainty quantification;wind power.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Greedy Projected Gradient-Newton Method for Sparse Logistic Regression","R. Wang; N. Xiu; C. Zhang","Department of Applied Mathematics, Beijing Jiaotong University, Beijing 100044, China (e-mail: wangruibjtu@bjtu.edu.cn).; Department of Applied Mathematics, Beijing Jiaotong University, Beijing 100044, China.; Department of Applied Mathematics, Beijing Jiaotong University, Beijing 100044, China.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","12","Sparse logistic regression (SLR), which is widely used for classification and feature selection in many fields, such as neural networks, deep learning, and bioinformatics, is the classical logistic regression model with sparsity constraints. In this paper, we perform theoretical analysis on the existence and uniqueness of the solution to the SLR, and we propose a greedy projected gradient-Newton (GPGN) method for solving the SLR. The GPGN method is a combination of the projected gradient method and the Newton method. The following characteristics show that the GPGN method achieves not only elegant theoretical results but also a remarkable numerical performance in solving the SLR: 1) the full iterative sequence generated by the GPGN method converges to a global/local minimizer of the SLR under weaker conditions; 2) the GPGN method has the properties of afinite identification for an optimal support set and local quadratic convergence; and 3) the GPGN method achieves higher accuracy and higher speed compared with a number of state-of-the-art solvers according to numerical experiments.","","","10.1109/TNNLS.2019.2905261","Fundamental Research Funds for the Central Universities; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8688642","Convergence analysis;greedy projected gradient-Newton (GPGN) algorithm;model analysis;numerical experiment;sparse logistic regression (SLR).","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Depth Map Enhancement by Revisiting Multi-scale Intensity Guidance within Coarse-to-fine Stages","Y. Zuo; Y. Fang; Y. Yang; X. Shang; Q. Wu","School of Information Management, Jiangxi University of Finance and Economics, Nanchang, Jiangxi, China.; School of Information Management, Jiangxi University of Finance and Economics, Nanchang, Jiangxi, China.; School of Information Management, Jiangxi University of Finance and Economics, Nanchang, Jiangxi, China.; School of Electronic and Electrical Engineering, Shanghai University of Engineering Science, Shanghai, China.; Faculty of Engineering and Information Technology, University of Technology Sydney, NSW, Australia.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Being different from the most methods of guided depth map enhancement based on deep convolutional neural network which focus on increasing the depth of networks, this paper is to improve the effectiveness of intensity guidance when the network goes deep. Overall, the proposed network upsamples the low-resolution depth maps from coarse to fine. Within each refinement stage of certain-scale depth features, the current-scale and all coarse-scales of the guidance features are revisited by dense connection. Therefore, the multi-scale guidance is efficiently maintained as the propagation of features. Furthermore, the proposed network maintains the intensity features in the high-resolution domain from which the multi-scale guidance is directly extracted. This design further improves the quality of intensity guidance. In addition, the shallow depth features upsampled via transposed convolution layer are directly transferred to the final depth features for reconstruction, which is called global residual learning in feature domain. Similarly, the global residual learning in pixel domain learns the difference between the depth ground truth and the coarsely upsampled depth map. Also, the local residual learning is to maintain the low frequency within each refinement stage and progressively recover the high frequency. The proposed method is tested for noise-free and noisy cases which compares against 16 state-of-the-art methods. Our experimental results show the improved performances based on the qualitative and quantitative evaluations.","","","10.1109/TCSVT.2019.2962867","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8945171","Depth Map Enhancement;Deep Convolutional Neual Network (DCNN);Depth Map Denoising;Residual Learning;Dense Connection","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Diagnosis of benign and malignant thyroid nodules using combined conventional ultrasound and ultrasound elasticity imaging","P. Qin; K. Wu; Y. Hu; J. Zeng; X. Chai","data science and technology, Taiyuan China 030051 (e-mail: qpl@nuc.edu.cn); taiyuan, shanxi China 030051 (e-mail: wukuan1995@gmail.com); School of Big Data, North University of China, 66291 Taiyuan, Shanxi China (e-mail: 996716708@qq.com); data science and technology north university of china Taiyuan, CN 030051, taiyuan China (e-mail: zjc@nuc.edu.cn); Department of Radiation Oncology, Stanford University School of Medicine, Palo Alto, California United States (e-mail: chaixiangfei@hotmail.com)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","Ultrasonography is one of the main imaging methods for diagnosing thyroid nodules. Automatic differentiation between benign and malignant nodules in ultrasound images can great assist inexperienced clinicians in their diagnosis. The core of problem is the effective utilization of the features of ultrasound images. In this study, we propose a method that is based on the combination of conventional ultrasound and ultrasound elasticity images based on a convolutional neural network and introduces richer feature information for the classification of benign and malignant thyroid nodules. First, the conventional network model performs pretraining on ImageNet and transfers the feature parameters to the ultrasound image domain by transfer learning so that depth features may be extracted and small samples may be processed. Then, we combine the depth features of conventional ultrasound and ultrasound elasticity images to form a hybrid feature space. Finally, the classification is completed on the hybrid feature space, and an end-to-end CNN model is implemented. The experimental results demonstrate that the accuracy of the proposed method is 0.9470, which is better than that of other single data-source methods under the same conditions.","","","10.1109/JBHI.2019.2950994","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8890856","Image classification;Transfer learning;Deep learning;Ultrasound image;Elastic ultrasound","Ultrasonic imaging;Feature extraction;Elasticity;Biomedical imaging;Cancer;Training","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Heterogeneous Transfer Learning for Hyperspectral Image Classification Based on Convolutional Neural Network","X. He; Y. Chen; P. Ghamisi","School of Electronics and Information Engineering, Harbin Institute of Technology, Harbin 150001, China.; School of Electronics and Information Engineering, Harbin Institute of Technology, Harbin 150001, China (e-mail: chenyushi@hit.edu.cn).; Helmholtz-Zentrum Dresden-Rossendorf, Helmholtz Institute Freiberg for Resource Technology, 09599 Freiberg, Germany.","IEEE Transactions on Geoscience and Remote Sensing","","2019","PP","99","1","18","Deep convolutional neural networks (CNNs) have shown their outstanding performance in the hyperspectral image (HSI) classification. The success of CNN-based HSI classification relies on the availability sufficient training samples. However, the collection of training samples is expensive and time consuming. Besides, there are many pretrained models on large-scale data sets, which extract the general and discriminative features. The proper reusage of low-level and midlevel representations will significantly improve the HSI classification accuracy. The large-scale ImageNet data set has three channels, but HSI contains hundreds of channels. Therefore, there are several difficulties to simply adapt the pretrained models for the classification of HSIs. In this article, heterogeneous transfer learning for HSI classification is proposed. First, a mapping layer is used to handle the issue of having different numbers of channels. Then, the model architectures and weights of the CNN trained on the ImageNet data sets are used to initialize the model and weights of the HSI classification network. Finally, a well-designed neural network is used to perform the HSI classification task. Furthermore, attention mechanism is used to adjust the feature maps due to the difference between the heterogeneous data sets. Moreover, controlled random sampling is used as another training sample selection method to test the effectiveness of the proposed methods. Experimental results on four popular hyperspectral data sets with two training sample selection strategies show that the transferred CNN obtains better classification accuracy than that of state-of-the-art methods. In addition, the idea of heterogeneous transfer learning may open a new window for further research.","","","10.1109/TGRS.2019.2951445","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8913592","Classification;convolutional neural network (CNN);hyperspectral image (HSI);transfer learning.","Feature extraction;Training;Hyperspectral imaging;Convolutional neural nets;Data models;Kernel","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Pay attention to the activations: a modular attention mechanism for fine-grained image recognition","P. Rodriguez Lopez; D. Velazquez Dorta; G. Cucurull Preixens; J. M. Gonfaus Sitjes; F. X. Roca Marva; J. Gonzalez","ISE, Computer Vision Center, 518689 Barcelona Spain (e-mail: pau.rodriguez@cvc.uab.cat); Computer Science, Computer Vision Center, Universitat Autonoma de Barcelona, Cerdanyola del Vallas, Barcelona Spain (e-mail: diegovd0296@gmail.com); Computer Science, Computer Vision Center, Universitat Autonoma de Barcelona, Cerdanyola del Vallas, Barcelona Spain (e-mail: gcucurull@cvc.uab.es); Computer Vision, Visual Tagging Services SL, Bellaterra Spain (e-mail: pep.gonfaus@visual-tagging.com); Computer Science, Computer Vision Center, Universitat Autonoma de Barcelona, Cerdanyola del Vallas, Barcelona Spain (e-mail: xavir@cvc.uab.es); Computer Science, Universidad Autonoma Barcelona, Barcelona, Barcelona Spain (e-mail: jordi.gonzalez@cvc.uab.cat)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","Fine-grained image recognition is central to many multimedia tasks such as search, retrieval and captioning. Unfortunately, these tasks are still challenging since the appearance of samples of the same class can be more different than those from different classes. This issue is mainly due to changes in deformation, pose, and the presence of clutter. In the literature, attention has been one of the most successful strategies to handle the aforementioned problems. Attention has been typically implemented in neural networks by selecting the most informative regions of the image that improve classification. In contrast, in this paper, attention is not applied at the image level but to the convolutional feature activations. In essence, with our approach, the neural model learns to attend to lower-level feature activations without requiring part annotations and uses those activations to update and rectify the output likelihood distribution. The proposed mechanism is modular, architecture-independent and efficient in terms of both parameters and computation required. Experiments demonstrate that well-known networks such as Wide Residual Networks and ResNeXt, when augmented with our approach, systematically improve their classification accuracy and become more robust to changes in deformation and pose and to the presence of clutter. As a result, our proposal reaches state-of-the-art classification accuracies in CIFAR-10, the Adience gender recognition task, Stanford Dogs, and UEC-Food100 while obtaining competitive performance in ImageNet, CIFAR-100, CUB200 Birds, and Stanford Cars. In addition, we analyze the different components of our model, showing that the proposed attention modules succeed in finding the most discriminative regions of the image. Finally, as a proof of concept, we demonstrate that with only local predictions, an augmented neural network can successfully classify an image before reaching any fully connected layer, thus reducing the computational amount up to 10%.","","","10.1109/TMM.2019.2928494","Departament dUniversitats Recerca i Societat de la Informaci; Secretara de Estado de Investigacin Desarrollo e Innovacin; European Cooperation in Science and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8762109","Image Retrieval Deep Learning Convolutional Neural Networks Attention-based Learning","Computer architecture;Computational modeling;Image recognition;Task analysis;Proposals;Logic gates;Clutter","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Super-Resolution Convolutional-Neural-Network-Based Approach for Subpixel Mapping of Hyperspectral Images","X. Ma; Y. Hong; Y. Song; Y. Chen","School of Land Science and Technology, China University of Geosciences, Beijing 100083, China (e-mail: maxf0203@163.com).; School of Land Science and Technology, China University of Geosciences, Beijing 100083, China (e-mail: hongyoutang@163.com).; Australasian Joint Research Centre for Building Information Modeling, School of Design and the Built Environment, Curtin University, Perth, WA 6845, Australia (e-mail: yongze.song@postgrad.curtin.edu.au).; School of Land Science and Technology, China University of Geosciences, Beijing 100083, China (e-mail: lovecugb@126.com).","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2019","PP","99","1","10","A new subpixel mapping (SPM) method based on a super-resolution convolutional neural network (SRCNN) is proposed to generate subpixel land cover maps for hyperspectral images. The SRCNN is used to restore the image spatial resolution from a coarse input image, which is equivalent to interpolation. First, an efficient subpixel convolutional neural network, which is a state-of-the-art SRCNN, is utilized to calculate the subpixel soft class value via a transfer learning strategy. Then, a classifier is used to transform the subpixel soft class values to hard-classified land cover maps with the constraint of fraction images. Experiments on three different hyperspectral images demonstrate that the SPM accuracy of the proposed SRCNN-based method is significantly better than those of three traditional SPM methods. In addition, the SRCNN-based SPM method has a simplified calculation process, does not require training data, and is less time consuming. This article provides a new solution for SPM of hyperspectral images.","","","10.1109/JSTARS.2019.2941089","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8847414","Deep learning;hyperspectral remote sensing image;subpixel mapping (SPM);super-resolution convolutional neural network (SRCNN);transfer learning (TL)","Hyperspectral imaging;Spatial resolution;Training;Convolution","","","","","","","","","","IEEE","IEEE Early Access Articles"
"3D APA-Net: 3D Adversarial Pyramid Anisotropic Convolutional Network for Prostate Segmentation in MR Images","H. Jia; Y. Xia; Y. Song; D. Zhang; H. Huang; Y. Zhang; W. Cai","National Engineering Laboratory for Integrated Aero-Space-Ground-Ocean Big Data Application Technology, School of Computer Science and Engineering, Northwestern Polytechnical University, Xian 710072, China.; National Engineering Laboratory for Integrated Aero-Space-Ground-Ocean Big Data Application Technology, School of Computer Science and Engineering, Northwestern Polytechnical University, Xian 710072, China.; School of Computer Science and Engineering, University of New South Wales, Sydney, NSW 2052, Australia.; School of Computer Science, The University of Sydney, Sydney, NSW 2006, Australia.; Department of Electrical and Computer Engineering, University of Pittsburgh, Pittsburgh, PA 15261 USA.; National Engineering Laboratory for Integrated Aero-Space-Ground-Ocean Big Data Application Technology, School of Computer Science and Engineering, Northwestern Polytechnical University, Xian 710072, China.; School of Computer Science, The University of Sydney, Sydney, NSW 2006, Australia.","IEEE Transactions on Medical Imaging","","2019","PP","99","1","1","Accurate and reliable segmentation of the prostate gland using magnetic resonance (MR) imaging has critical importance for the diagnosis and treatment of prostate diseases, especially prostate cancer. Although many automated segmentation approaches including those based on deep learning have been proposed, the segmentation performance still has room for improvement due to the large variability in image appearance, imaging interference, and anisotropic spatial resolution. In this paper, we propose the 3D adversarial pyramid anisotropic convolutional deep neural network (3D APA-Net) for prostate segmentation in MR images. This model is composed of a generator (i.e. 3D PA-Net) that performs image segmentation and a discriminator (i.e. a six-layer convolutional neural network) that differentiates between a segmentation result and its corresponding ground truth. The 3D PA-Net has an encoderdecoder architecture, which consists of a 3D ResNet encoder, an anisotropic convolutional decoder, and multi-level pyramid convolutional skip connections. The anisotropic convolutional blocks can exploit the 3D context information of the MR images with anisotropic resolution, the pyramid convolutional blocks address both voxel classification and gland localization issues, and the adversarial training regularizes 3D PA-Net and thus enables it to generate spatially consistent and continuous segmentation results. We evaluated the proposed 3D APA-Net against several state-of-the-art deep learning-based segmentation approaches on two public databases and the hybrid of the two. Our results suggest that the proposed model outperforms the compared approaches on three databases and could be used in a routine clinical workflow.","","","10.1109/TMI.2019.2928056","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8759928","Prostate segmentation;deep learning;adversarial training;magnetic resonacne imaging","Image segmentation;Three-dimensional displays;Spatial resolution;Decoding;Convolution;Glands;Biomedical imaging","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Contextual Bandit Learning for Machine Type Communications in the Null Space of Multi-Antenna Systems","S. Ali; H. Asgharimoghaddam; N. Rajatheva; W. Saad; J. Haapola","Centre for Wireless Communications (CWC), University of Oulu, Finland.; Centre for Wireless Communications (CWC), University of Oulu, Finland.; Centre for Wireless Communications (CWC), University of Oulu, Finland.; Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA.; Centre for Wireless Communications (CWC), University of Oulu, Finland.","IEEE Transactions on Communications","","2019","PP","99","1","1","Ensuring an effective coexistence of conventional broadband cellular users with machine type communications (MTCs) is challenging due to the interference from MTCs to cellular users. This interference challenge stems from the fact that the acquisition of channel state information (CSI) from machine type devices (MTD) to cellular base stations (BS) is infeasible due to the small packet nature of MTC traffic. In this paper, a novel approach based on the concept of opportunistic spatial orthogonalization (OSO) is proposed for interference management between MTC and conventional cellular communications. In particular, a cellular system is considered with a multi-antenna BS in which a receive beamformer is designed to maximize the rate of a cellular user, and, a machine type aggregator (MTA) that receives data from a large set of MTDs. The BS and MTA share the same uplink resources, and, therefore, MTD transmissions create interference on the BS. However, if there is a large number of MTDs to chose from for transmission at each given time for each beamformer, one MTD can be selected such that it causes almost no interference on the BS. A comprehensive analytical study of the characteristics of such an interference from several MTDs on the same beamformer is carried out. It is proven that, for each beamformer, an MTD exists such that the interference on the BS is negligible. To further investigate such interference, the distribution of the signal-to-interference-plus-noise ratio (SINR) of the cellular user is derived, and, subsequently, the distribution of the outage probability is presented. However, the optimal implementation of OSO requires the CSI of all the links in the BS, which is not practical for MTC. To solve this problem, an online learning method based on the concept of contextual multi-armed bandits (MAB) learning is proposed. The receive beamformer is used as the context of the contextual MAB setting and Thompson sampling: a well-known method of solving contextual MAB problems is proposed. Since the number of contexts in this setting can be unlimited, approximating the posterior distributions of Thompson sampling is required. Two function approximation methods, a) linear full posterior sampling, and, b) neural networks are proposed for optimal selection of MTD for transmission for the given beamformer. Simulation results show that is possible to implement OSO with no CSI from MTDs to the BS. Linear full posterior sampling achieves almost 90% of the optimal allocation when the CSI from all the MTDs to the BS is known.","","","10.1109/TCOMM.2019.2955454","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8911355","Machine type communications;scheduling;fast uplink grant;multi-armed bandits;internet of things;multi-antenna communications;deep contextual bandits;Thompson sampling","Interference;Uplink;MIMO communication;Wireless communication;Internet of Things;Antennas;Cellular networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Spontaneous Speech Emotion Recognition Using Multiscale Deep Convolutional LSTM","S. Zhang; X. Zhao; Q. Tian","Institute of Intelligent Information Processing, Taizhou University, 12629 Taizhou, Zhejiang China (e-mail: tzczsq@163.com); Institute of Intelligent Information Processing, Taizhou University, 12629 Taizhou, Zhejiang China (e-mail: tzxyzxm@163.com); Huawei Noah's Ark Lab, Huawei, Shenzhen, Guangdong China (e-mail: tian.qi1@huawei.com)","IEEE Transactions on Affective Computing","","2019","PP","99","1","1","Recently, emotion recognition in real sceneries such as in the wild has attracted extensive attention in affective computing, because existing spontaneous emotions in real sceneries are more challenging and difficult to identify than other emotions. Motivated by the diverse effects of different lengths of audio spectrograms on emotion identification, this paper proposes a multiscale deep convolutional long short-term memory (LSTM) framework for spontaneous speech emotion recognition. Initially, a deep convolutional neural network (CNN) model is used to learn deep segment-level features on the basis of the created image-like three channels of spectrograms. Then, a deep LSTM model is adopted on the basis of the learned segment-level CNN features to capture the temporal dependency among all divided segments in an utterance for utterance-level emotion recognition. Finally, different emotion recognition results, obtained by combining CNN with LSTM at multiple lengths of segment-level spectrograms, are integrated by using a score-level fusion strategy. Experimental results on two challenging spontaneous emotional datasets, i.e., the AFEW5.0 and BAUM-1s databases, demonstrate the promising performance of the proposed method, outperforming state-of-the-art methods.","","","10.1109/TAFFC.2019.2947464","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8873581","Speech emotion recognition;Convolutional neural networks;LSTM;Multiscale","Image segmentation;Spectrogram;Feature extraction;Emotion recognition;Speech recognition;Neural networks;Acoustics","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Structured Bayesian Compression for Deep Models in Mobile-Enabled Devices for Connected Healthcare","S. Chen; B. Song; X. Du; N. Guizani","NA; NA; NA; NA","IEEE Network","","2019","PP","99","1","8","Deep models, typically deep neural networks, have millions of parameters, analyze medical data accurately, yet in a time-consuming method. However, energy cost effectiveness and computational efficiency are important for prerequisites developing and deploying mobile-enabled devices, the mainstream trend in connected healthcare. Therefore, deep models' compression has become a problem of great significance for real-time health services. In this article, we first emphasize the use of Bayesian learning for model sparsity, effectively reducing the number of parameters while maintaining model performance. Specifically, with sparsity inducing priors, large parts of the network can be pruned with a simple retraining of arbitrary datasets. Then, we propose a novel structured Bayesian compression architecture by adaptively learning both group sparse and block sparse while also designing sparse-oriented mixture priors to improve the expandability of the compression model. Experimental results from both simulated datasets (MNIST) as well as practical medical datasets (Histopathologic Cancer) demonstrate the effectiveness and good performance of our framework on deep model compression.","","","10.1109/MNET.001.1900204","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8823872","","Bayes methods;Computational modeling;Medical services;Adaptation models;Computer architecture;Mixture models;Task analysis","","","","","","","","","","IEEE","IEEE Early Access Articles"
"HybridSN: Exploring 3-D-2-D CNN Feature Hierarchy for Hyperspectral Image Classification","S. K. Roy; G. Krishna; S. R. Dubey; B. B. Chaudhuri","Computer Science and Engineering Department, Jalpaiguri Government Engineering College, Jalpaiguri 735102, India.; Computer Science and Engineering Department, Jalpaiguri Government Engineering College, Jalpaiguri 735102, India.; Computer Vision Group, Indian Institute of Information Technology, Sri City 517646, India (e-mail: srdubey@iiits.in).; Computer Vision and Pattern Recognition Unit, Indian Statistical Institute, Kolkata 700108, India.","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","Hyperspectral image (HSI) classification is widely used for the analysis of remotely sensed images. Hyperspectral imagery includes varying bands of images. Convolutional neural network (CNN) is one of the most frequently used deep learning-based methods for visual data processing. The use of CNN for HSI classification is also visible in recent works. These approaches are mostly based on 2-D CNN. On the other hand, the HSI classification performance is highly dependent on both spatial and spectral information. Very few methods have used the 3-D-CNN because of increased computational complexity. This letter proposes a hybrid spectral CNN (HybridSN) for HSI classification. In general, the HybridSN is a spectral-spatial 3-D-CNN followed by spatial 2-D-CNN. The 3-D-CNN facilitates the joint spatial-spectral feature representation from a stack of spectral bands. The 2-D-CNN on top of the 3-D-CNN further learns more abstract-level spatial representation. Moreover, the use of hybrid CNNs reduces the complexity of the model compared to the use of 3-D-CNN alone. To test the performance of this hybrid approach, very rigorous HSI classification experiments are performed over Indian Pines, University of Pavia, and Salinas Scene remote sensing data sets. The results are compared with the state-of-the-art hand-crafted as well as end-to-end deep learning-based methods. A very satisfactory performance is obtained using the proposed HybridSN for HSI classification. The source code can be found at https://github.com/gokriznastic/HybridSN.","","","10.1109/LGRS.2019.2918719","IIIT SRi City India; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8736016","2-D-convolutional neural network (CNN);3-D-CNN;deep learning;CNNs;hybrid spectral CNN (HybridSN);hyperspectral image (HSI) classification;remote sensing;spectral-spatial.","Kernel;Feature extraction;Hyperspectral imaging;Principal component analysis;Computational modeling;IP networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Unsupervised Single Image Dehazing Using Dark Channel Prior Loss","A. Golts; D. Freedman; M. Elad","Department of Computer Science, Technion Institute of Technology, Technion City, Haifa 32000, Israel, corresponding e-mails.; Google Research, Haifa, Israel, (ISF) grant no. 335/18.; Department of Computer Science, Technion Institute of Technology, Technion City, Haifa 32000, Israel, corresponding e-mails.","IEEE Transactions on Image Processing","","2019","PP","99","1","1","Single image dehazing is a critical stage in many modern-day autonomous vision applications. Early prior-based methods often involved a time-consuming minimization of a hand-crafted energy function. Recent learning-based approaches utilize the representational power of deep neural networks (DNNs) to learn the underlying transformation between hazy and clear images. Due to inherent limitations in collecting matching clear and hazy images, these methods resort to training on synthetic data, constructed from indoor images and corresponding depth information. This may result in a possible domain shift when treating outdoor scenes. We propose a completely unsupervised method of training via minimization of the well-known, Dark Channel Prior (DCP) energy function. Instead of feeding the network with synthetic data, we solely use real-world outdoor images and tune the network’s parameters by directly minimizing the DCP. Although our “Deep DCP” technique can be regarded as a fast approximator of DCP, it actually improves its results significantly. This suggests an additional regularization obtained via the network and learning process. Experiments show that our method performs on par with large-scale supervised methods.","","","10.1109/TIP.2019.2952032","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8897130","Energy functions;deep neural networks;unsupervised learning;single image dehazing;dark channel prior","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Quadratic Autoencoder (Q-AE) for Low-dose CT Denoising","F. Fan; H. Shan; M. K. Kalra; R. Singh; G. Qian; M. Getzin; Y. Teng; J. Hahn; G. Wang","Department of Biomedical Engineering, Rensselaer Polytechnic Institute, Troy, NY, USA.; Department of Biomedical Engineering, Rensselaer Polytechnic Institute, Troy, NY, USA.; Department of Radiology, Massachusetts General Hospital, Boston, MA 02114, USA.; Department of Radiology, Massachusetts General Hospital, Boston, MA 02114, USA.; Department of Biomedical Engineering, Rensselaer Polytechnic Institute, Troy, NY, USA.; Department of Biomedical Engineering, Rensselaer Polytechnic Institute, Troy, NY, USA.; Sino-Dutch Biomedical and Information Engineering School, Northeastern University, Shenyang, China, 110169.; Department of Biomedical Engineering, Rensselaer Polytechnic Institute, Troy, NY, USA.; Department of Biomedical Engineering, Rensselaer Polytechnic Institute, Troy, NY, USA.","IEEE Transactions on Medical Imaging","","2019","PP","99","1","1","Inspired by complexity and diversity of biological neurons, our group proposed quadratic neurons by replacing the inner product in current artificial neurons with a quadratic operation on input data, thereby enhancing the capability of an individual neuron. Along this direction, we are motivated to evaluate the power of quadratic neurons in popular network architectures, simulating human-like learning in the form of “quadratic-neuron-based deep learning”. Our prior theoretical studies have shown important merits of quadratic neurons and networks in representation, efficiency, and interpretability. In this paper, we use quadratic neurons to construct an encoder-decoder structure, referred as the quadratic autoencoder, and apply it to low-dose CT denoising. The experimental results on the Mayo low-dose CT dataset demonstrate the utility and robustness of quadratic autoencoder in terms of image denoising and model efficiency. To our best knowledge, this is the first time that the deep learning approach is implemented with a new type of neurons and demonstrates a significant potential in the medical imaging field.","","","10.1109/TMI.2019.2963248","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8946589","Deep learning;quadratic neurons;autoencoder;low-dose CT","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Multimodal Wearable System for Continuous and Real-time Breathing Pattern Monitoring During Daily Activity","W. Qi; A. Aliverti","deib, Politecnico di Milano Dipartimento di Elettronica Informazione e Bioingegneria, 124243 Milano Italy 20133 (e-mail: phyllis.wenqi@gmail.com); Politecnico di Milano Dipartimento di Elettronica Informazione e Bioingegneria, 124243 Milano Italy (e-mail: andrea.aliverti@polimi.it)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","Objective: This study aims to understand breathing patterns during daily activities by developing a wearable respiratory and activity monitoring (WRAM) system. Methods: A novel multimodal fusion architecture is proposed to calculate the respiratory and exercise parameters and simultaneously identify human actions. A hybrid hierarchical classification (HHC) algorithm combining deep learning and threshold-based methods is presented to distinguish 15 complex activities for accuracy enhancement and fast computation. A series of signal processing algorithms are utilized and integrated to calculate breathing and motion indices. The designed wireless communication structure achieves the interactions among chest bands, mobile devices, and the data processing center. Results: The advantage of the proposed HHC method is evaluated by comparing the average accuracy (97.22\%) and predictive time (0.0094s) with machine learning and deep learning approaches. The nine breathing patterns during 15 activities were analyzed by investigating the data from 12 subjects. With 12 hours of naturalistic data collected from one participant, the WRAM system reports the breathing and exercise performance within the identified motions. The demonstration shows the ability of the WRAM system to monitor multiple users’ breathing and exercise status in real-time. Conclusion: The present system demonstrates the usefulness of the framework of breathing pattern monitoring during daily activities, which may be potentially used in healthcare. Significance: The proposed multimodal based WRAM system offers new insights into the breathing function of exercise in action and presents a novel approach for precision medicine and health state monitoring.","","","10.1109/JBHI.2019.2963048","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8946736","Multimodal data fusion;deep learning;wearable devices;human activity recognition;signal processing","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Automatic Traffic Sign Detection and Recognition Using SegU-Net and a Modified Tversky Loss Function With L1-Constraint","U. Kamal; T. I. Tonmoy; S. Das; M. K. Hasan","Department of Electrical and Electronic Engineering, Bangladesh University of Engineering and Technology, Dhaka 1205, Bangladesh.; Department of Electrical and Electronic Engineering, Bangladesh University of Engineering and Technology, Dhaka 1205, Bangladesh.; Department of Electrical and Electronic Engineering, Bangladesh University of Engineering and Technology, Dhaka 1205, Bangladesh.; Department of Electrical and Electronic Engineering, Bangladesh University of Engineering and Technology, Dhaka 1205, Bangladesh (e-mail: khasan@eee.buet.ac.bd).","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","13","Traffic sign detection is a central part of autonomous vehicle technology. Recent advances in deep learning algorithms have motivated researchers to use neural networks to perform this task. In this paper, we look at traffic sign detection as an image segmentation problem and propose a deep convolutional neural network-based approach to solve it. To this end, we propose a new network, the SegU-Net, which we form by merging the state-of-the-art segmentation architectures-SegNet and U-Net to detect traffic signs from video sequences. For training the network, we use the Tversky loss function constrained by an L1 term instead of the intersection over union loss traditionally used to train segmentation networks. We use a separate network, inspired by the VGG-16 architecture, to classify the detected signs. The networks are trained on the challenge free sequences of the CURE-TSD dataset. Our proposed network outperforms the state-of-the-art object detection networks, such as the Faster R-CNN inception Resnet V2 and R-FCN Resnet 101, by a large margin and obtains a precision and recall of 94.60% and 80.21%, respectively, which is the current state of the art on this part of the dataset. In addition, the network is tested on the German Traffic Sign Detection Benchmark (GTSDB) dataset, where it achieves a precision and recall of 95.29% and 89.01%, respectively. This is on a par with the performance of the aforementioned object detection networks. These results prove the generalizability of the proposed architecture and its suitability for robust traffic sign detection in autonomous vehicles.","","","10.1109/TITS.2019.2911727","Higher Education Quality Enhancement Program HEQEP of University Grants Commission UGC Bangladesh; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8700606","Traffic sign detection;traffic sign recognition;convolutional neural network;Tversky index;L1 constraint.","Image segmentation;Image color analysis;Task analysis;Training;Benchmark testing;Shape;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Regional Multi-scale Approach for Visually Pleasing Explanations of Deep Neural Networks (December 2019)","D. Seo; K. Oh; I. Oh","National Institute of Agricultural Sciences, Jeonju, 54875, Republic of Korea.; Division of Computer Science and Engineering, Jeonbuk National University, Jeonju, 54896, Republic of Korea.; Division of Computer Science and Engineering, Jeonbuk National University, Jeonju, 54896, Republic of Korea and Research Center for Artificial Intelligence Technology.","IEEE Access","","2019","PP","99","1","1","Recently, many methods to interpret and visualize deep neural network predictions have been proposed, and significant progress has been made. However, a more class-discriminative and visually pleasing explanation is required. Thus, this paper proposes a region-based approach that estimates feature importance in terms of appropriately segmented regions. By fusing the saliency maps generated from multi-scale segmentations, a more class-discriminative and visually pleasing map is obtained. This paper incorporates this regional multi-scale concept into a prediction difference method that is model-agnostic. An input image is segmented in several scales using the superpixel method, and exclusion of a region is simulated by sampling a normal distribution constructed via the boundary prior. The experimental results demonstrate that the regional multi-scale method produces much more class-discriminative and visually pleasing saliency maps.","","","10.1109/ACCESS.2019.2963055","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8945372","Computer vision;neural networks;explainable artificial intelligence;machine learning","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"In-Hardware Training Chip Based on CMOS Invertible Logic for Machine Learning","N. Onizawa; S. C. Smithson; B. H. Meyer; W. J. Gross; T. Hanyu","Research Institute of Electrical Communication, Tohoku University, Sendai 980-8577, Japan (e-mail: naoya.onizawa.a7@tohoku.ac.jp).; Department of Electrical and Computer Engineering, McGill University, Montreal, QC H3A 0E9, Canada.; Department of Electrical and Computer Engineering, McGill University, Montreal, QC H3A 0E9, Canada.; Department of Electrical and Computer Engineering, McGill University, Montreal, QC H3A 0E9, Canada.; Research Institute of Electrical Communication, Tohoku University, Sendai 980-8577, Japan.","IEEE Transactions on Circuits and Systems I: Regular Papers","","2019","PP","99","1","10","Deep Neural Networks (DNNs) have recently shown state-of-the-art results on various applications, such as computer vision and recognition tasks. DNN inference engines can be implemented in hardware with high energy efficiency as the computation can be realized using a low-precision fixed point or even binary precision with sufficient cognition accuracies. On the other hand, training DNNs using the well-known back-propagation algorithm requires high-precision floating-point computations on a CPU and/or GPU causing significant power dissipation (more than hundreds of kW) and long training time (several days or more). In this paper, we demonstrate a training chip fabricated using a commercial 65-nm CMOS technology for machine learning. The chip performs training without back propagation by using invertible logic with stochastic computing that can directly obtain weight values using input/output training data with low precision suitable for inference. When training neurons that compute the weighted sum of all inputs and then apply a non-linear activation function, our chip demonstrates a reduction of power dissipation and latency by 99.98% and 99.95%, respectively, in comparison with a state-of-the-art software implementation.","","","10.1109/TCSI.2019.2960383","MEXT Brainware LSI Project and JST PRESTO; VDEC; University of Tokyo in collaboration with Cadence Inc and Synopsys Inc; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8946714","Stochastic computing;neural networks;digital circuits.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Traffic Flow Imputation Using Parallel Data and Generative Adversarial Networks","Y. Chen; Y. Lv; F. Wang","State Key Laboratory for Management and Control of Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China, and also with the University of Chinese Academy of Sciences, Beijing 100190, China.; State Key Laboratory for Management and Control of Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China, and also with the Qingdao Academy of Intelligent Industries, Shandong 266109, China (e-mail: yisheng.lv@ia.ac.cn).; State Key Laboratory for Management and Control of Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China, and also with the Qingdao Academy of Intelligent Industries, Shandong 266109, China.","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","7","Traffic data imputation is critical for both research and applications of intelligent transportation systems. To develop traffic data imputation models with high accuracy, traffic data must be large and diverse, which is costly. An alternative is to use synthetic traffic data, which is cheap and easy-access. In this paper, we propose a novel approach using parallel data and generative adversarial networks (GANs) to enhance traffic data imputation. Parallel data is a recently proposed method of using synthetic and real data for data mining and data-driven process, in which we apply GANs to generate synthetic traffic data. As it is difficult for the standard GAN algorithm to generate time-dependent traffic flow data, we made twofold modifications: 1) using the real data or the corrupted ones instead of random vectors as latent codes to generator within GANs and 2) introducing a representation loss to measure discrepancy between the synthetic data and the real data. The experimental results on a real traffic dataset demonstrate that our method can significantly improve the performance of traffic data imputation.","","","10.1109/TITS.2019.2910295","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699108","Parallel data;generative adversarial networks;traffic flow imputation;data augmentation;deep learning.","Generators;Data models;Gallium nitride;Generative adversarial networks;Training;Loss measurement;Biological system modeling","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Res2Net: A New Multi-scale Backbone Architecture","S. Gao; M. Cheng; K. Zhao; X. Zhang; M. Yang; P. H. S. Torr","Computer Science, Nankai University, 12538 Tianjin, Tianjin China (e-mail: shgao@mail.nankai.edu.cn); Computer Science, Nankai University, Tianjin, Tianjin China (e-mail: cmm@nankai.edu.cn); Computer Science, Nankai University, 12538 Tianjin, Tianjin China (e-mail: kaiz.xyz@gmail.com); Computer Science, Nankai University, Tianjin, Tianjin China (e-mail: xinyuzhang@mail.nankai.edu.cn); EECS, University of California at Merced, Merced, California United States 95344 (e-mail: mhyang@ucmerced.edu); Engineering, University of Oxford, 6396 Oxford, Oxfordshire United Kingdom of Great Britain and Northern Ireland (e-mail: philip.torr@eng.ox.ac.uk)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Representing features at multiple scales is of great importance for numerous vision tasks. Recent advances in backbone convolutional neural networks (CNNs) continually demonstrate stronger multi-scale representation ability, leading to consistent performance gains on a wide range of applications. However, most existing methods represent the multi-scale features in a layer-wise manner. In this paper, we propose a novel building block for CNNs, namely Res2Net, by constructing hierarchical residual-like connections within one single residual block. The Res2Net represents multi-scale features at a granular level and increases the range of receptive fields for each network layer. The proposed Res2Net block can be plugged into the state-of-the-art backbone CNN models, e.g., ResNet, ResNeXt, and DLA. We evaluate the Res2Net block on all these models and demonstrate consistent performance gains over baseline models on widely-used datasets, e.g., CIFAR-100 and ImageNet. Further ablation studies and experimental results on representative computer vision tasks, i.e., object detection, class activation mapping, and salient object detection, further verify the superiority of the Res2Net over the state-of-the-art baseline methods. The source code and trained models are available on https://mmcheng.net/res2net/.","","","10.1109/TPAMI.2019.2938758","National Natural Science Foundation of China; national youth talent support program; Natural Science Foundation of Tianjin City; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8821313","Multi-scale;deep learning","Feature extraction;Task analysis;Object detection;Semantics;Computer architecture;Kernel;Convolution","","","","3","","","","","","IEEE","IEEE Early Access Articles"
"Object Detection in High Resolution Remote Sensing Imagery Based on Convolutional Neural Networks With Suitable Object Scale Features","Z. Dong; M. Wang; Y. Wang; Y. Zhu; Z. Zhang","State Key Laboratory of Information Engineering in Surveying, Mapping, and Remote Sensing, Wuhan University, Wuhan 430079, China.; State Key Laboratory of Information Engineering in Surveying, Mapping, and Remote Sensing, Wuhan University, Wuhan 430079, China. (e-mail: wangmi@whu.edu.cn).; State Key Laboratory of Information Engineering in Surveying, Mapping, and Remote Sensing, Wuhan University, Wuhan 430079, China.; State Key Laboratory of Information Engineering in Surveying, Mapping, and Remote Sensing, Wuhan University, Wuhan 430079, China.; State Key Laboratory of Information Engineering in Surveying, Mapping, and Remote Sensing, Wuhan University, Wuhan 430079, China.","IEEE Transactions on Geoscience and Remote Sensing","","2019","PP","99","1","11","Object detection in high spatial resolution remote sensing images (HSRIs) is an important part of image information automatic extraction, analysis, and understanding. The region of interest (ROI) scale of object detection and the object feature representation are two vital factors in HSRI object detection. With respect to these two issues, this article presents a novel HSRI object detection method based on convolutional neural networks (CNNs) with suitable object scale features. First, the suitable ROI scale of object detection is obtained by compiling statistics for the scale range of objects in HSRIs. Then, a CNN framework for object detection in HSRIs is designed using a suitable ROI scale of object detection. The object features obtained using a CNN have good universality and robustness. Finally, a CNN framework with a suitable ROI scale of object detection is trained and tested. Using the WHU-RSONE data set, the proposed method is compared with the faster region-based CNN (Faster-RCNN) framework. The experimental results show that the proposed method outperforms the Faster-RCNN framework and provides good object detection results in HSRIs.","","","10.1109/TGRS.2019.2953119","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8931244","Convolutional neural network (CNN);deep learning;high-resolution remote sensing image;object detection;object scare.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Complex-Valued 3-D Convolutional Neural Network for PolSAR Image Classification","X. Tan; M. Li; P. Zhang; Y. Wu; W. Song","National Laboratory of Radar Signal Processing, Xidian University, Xi'an 710071, China.; National Laboratory of Radar Signal Processing, Collaborative Innovation Center of Information Sensing and Understanding, Xidian University, Xi'an 710071, China (e-mail: liming@xidian.edu.cn).; National Laboratory of Radar Signal Processing, Collaborative Innovation Center of Information Sensing and Understanding, Xidian University, Xi'an 710071, China.; Remote Sensing Image Processing and Fusion Group, School of Electronics Engineering, Xidian University, Xi'an 710071, China.; National Laboratory of Radar Signal Processing, Xidian University, Xi'an 710071, China.","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","Recently, convolutional neural network (CNN) has been successfully utilized in the terrain classification of polarimetric synthetic aperture radar (PolSAR) images. However, most CNN-based models are currently limited to handle 2-D real-valued inputs, and therefore, the physical scattering mechanism contained in the complex-valued (CV) covariance/coherency matrix cannot be extracted effectively. For this reason, CV 3-D CNN (CV-3D-CNN) is proposed for PolSAR image classification. Compared with CNN, CV-3D-CNN simultaneously extracts hierarchical features in both the spatial and the scattering dimensions by performing 3-D CV convolutions, thereby capturing the physical property from polarimetric adjacent resolution cells. Experiments on real PolSAR images classification demonstrate the effectiveness and the superiorities of CV-3D-CNN and illustrate that CV-3D-CNN can deal with scattering characteristic in a more complete manner and achieve better performance in PolSAR image classification.","","","10.1109/LGRS.2019.2940387","National Natural Science Foundation of China; Natural Science Basic Research Plan in Shaanxi Province of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8864110","Convolutional neural network (CNN);deep learning;image classification;polarimetric synthetic aperture radar (PolSAR).","Feature extraction;Convolution;Scattering;Kernel;Covariance matrices;Synthetic aperture radar;Radar imaging","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Enhancing Driver Distraction Recognition Using Generative Adversarial Networks","C. Ou; F. Karray","ECE, University of Waterloo Faculty of Engineering, 120492 Waterloo, Ontario Canada N2L 3G1 (e-mail: c9ou@uwaterloo.ca); Electrical and Computer Engineering, University of Waterloo, Waterloo, Ontario Canada (e-mail: karray@uwaterloo.ca)","IEEE Transactions on Intelligent Vehicles","","2019","PP","99","1","1","Distracted driving is among the primary causes for serious car accidents. The leading cause of death among teenagers today is traffic accidents and major part of them are related to driving while being distracted. We propose an end-to-end Convolutional Neural Network-based driver distraction recognition (DDR) system that can generalize to diverse driving conditions. The proposed method consists of two steps: developing generative models to produce images of different driving scenarios and developing a discriminative model for image classification. Unlike traditional methods based on image datasets collected by simulation experiments, we collect a diverse dataset of drivers in different driving conditions and activity patterns from the Internet and train generative models for multiple driving scenarios. By sampling from these generative models, we augment the collected dataset with new training samples and train a Convolutional Neural Network for distraction recognition. We demonstrate that the generative models are able to generate images of drivers in different driving scenarios. With augmentative images, the DDR system achieves an improvement of 11.45% on image classification performance in a driving simulation environment. Moreover, we demonstrate how the trained DDR systems can be integrated within a driver monitoring system.","","","10.1109/TIV.2019.2960930","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8936914","Driver;distraction;generative model;deep learning","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Real-Time Semantic Segmentation-Based Stereo Reconstruction","V. Miclea; S. Nedevschi","Department of Computer Science, Technical University of Cluj-Napoca, 400027 Cluj-Napoca, Romania (e-mail: vlad.miclea@cs.utcluj.ro).; Department of Computer Science, Technical University of Cluj-Napoca, 400027 Cluj-Napoca, Romania.","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","11","In this paper, we propose a novel semantic segmentation-based stereo reconstruction method that can keep up with the accuracy of the state-of-the art approaches while running in real time. The solution follows the classic stereo pipeline, each step in the stereo workflow being enhanced by additional information from semantic segmentation. Therefore, we introduce several improvements to computation, aggregation, and optimization by adapting existing techniques to integrate additional surface information given by each semantic class. For the cost computation and optimization steps, we propose new genetic algorithms that can incrementally adjust the parameters for better solutions. Furthermore, we propose a new post-processing edge-aware filtering technique relying on an improved convolutional neural network (CNN) architecture for disparity refinement. We obtain the competitive results at 30 frames/s, including segmentation.","","","10.1109/TITS.2019.2913883","UP Drive Project Automated Urban Parking and Driving of the Horizon 2020 EU; Romanian National Authority for Scientific Research UEFISCDI a Romanian National Research Agency through the national research projects PN III PCCF SEPCA Semantic Visual Perception and Integrated Control for Autonomous Systems; Multispectral Environment Perception by Fusion of 2D and 3D Sensorial Data from the Visible and Infrared Spectrum MULTISPECT; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8751135","Stereo reconstruction;semantic segmentation;deep learning;genetic algorithm;census;SGM;refinement.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"SD-GAN: Saliency-Discriminated GAN for Remote Sensing Image Superresolution","J. Ma; L. Zhang; J. Zhang","School of Artificial Intelligence, Beijing Normal University, Beijing 100875, China.; School of Artificial Intelligence, Beijing Normal University, Beijing 100875, China (e-mail: libaozhang@bnu.edu.cn).; School of Artificial Intelligence, Beijing Normal University, Beijing 100875, China.","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","Recently, convolutional neural networks have shown superior performance in single-image superresolution. Although existing mean-square-error-based methods achieve high peak signal-to-noise ratio (PSNR), they tend to generate oversmooth results. Generative adversarial network (GAN)-based methods can provide high-resolution (HR) images with higher perceptual quality, but produce pseudotextures in images, which generally leads to lower PSNR. Besides, different regions in remote sensing images (RSIs) reflect discrepant surface topography and visual characteristics. This means a uniform reconstruction strategy may not be suitable for all targets in RSIs. To solve these problems, we propose a novel saliency-discriminated GAN for RSI superresolution. First, hierarchical weakly supervised saliency analysis is introduced to compute a saliency map, which is subsequently employed to distinguish the diverse demands of regions in the following generator and discriminator part. Different from previous GANs, the proposed residual dense saliency generator takes saliency maps as a supplementary condition in the generator. Simultaneously, combining the characteristic of RSIs, we design a new paired discriminator to enhance the perceptual quality, which measures the distance between generated images and HR images in salient areas and nonsalient areas, respectively. Comprehensive evaluations validate the superiority of the proposed model.","","","10.1109/LGRS.2019.2956969","Beijing Natural Science Foundation; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933080","Deep learning;generative adversarial network (GAN);remote sensing;saliency analysis;superresolution.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Self-Attentive Generative Adversarial Network for Cloud Detection in High Resolution Remote Sensing Images","Z. Wu; J. Li; Y. Wang; Z. Hu; M. Molinier","School of Remote Sensing and Information Engineering, Wuhan University, Wuhan 430079, China.; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan 430079, China (e-mail: jun__li@whu.edu.cn).; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan 430079, China.; College of Life Sciences and Oceanography, Shenzhen University, Shenzhen 518061, China.; VTT Technical Research Centre of Finland, Ltd., 02044 Espoo, Finland.","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","Cloud detection is an important step in the processing of remote sensing images. Most methods based on convolutional neural networks (CNNs) for cloud detection require pixel-level labels, which are time-consuming and expensive to annotate. To overcome this challenge, this letter proposes a novel semisupervised algorithm for cloud detection by training a self-attentive generative adversarial network (SAGAN) to extract the feature difference between cloud images and cloud-free images. Our main idea is to introduce visual attention into the process of generating ``real'' cloud-free images. The training of SAGAN is based on three guiding principles: expansion of attention maps of cloud regions which will be replaced with translated cloud-free images, reduction of attention maps to coincide with cloud boundaries, and optimization of a self-attentive network to handle the extreme cases. The inputs for SAGAN training are the images and image-level labels, which are easier, cheaper, and more time-saving than the existing methods based on CNN. To test the performance of SAGAN, experiments are conducted on the Sentinel-2A Level 1C image data. The results show that the proposed method achieves very promising results with only the image-level labels of training samples.","","","10.1109/LGRS.2019.2955071","National Key Research Development Program of China; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8924781","Cloud detection;deep learning (DL);generative adversarial network (GAN);remote sensing;self-attention.","Image restoration;Remote sensing;Gallium nitride;Generative adversarial networks;Clouds;Training;Optimization","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Facial Action Unit Recognition and Intensity Estimation from Partially Labelled Data","S. Wang; B. Pan; S. Wu; Q. Ji","Computer Science and Technology, University of Science and Technology of China, Hefei, Anhui China 230027 (e-mail: sfwang@ustc.edu.cn); Computer Science and Technology, University of Science and Technology of China, 12652 Hefei, Anhui China 230026 (e-mail: bowenpan@mail.ustc.edu.cn); computer science and technology, university of science and technology of china, hefei, anhui China (e-mail: sa14ws@mail.ustc.edu.cn); Department of Electrical, Computer andSystem Engineering, Rensselaer Polytechnic Institute, Troy, New York United States 12180 (e-mail: qji@ecse.rpi.edu)","IEEE Transactions on Affective Computing","","2019","PP","99","1","1","Research on facial action unit (AU) analysis typically require facial images that are labelled with those action units. While unlabelled facial images abound, labelling those images with action units or intensity is costly and time-consuming. Our approach makes it possible to analyze facial AUs when only some of the images have been labelled. We use many facial images to learn a deep framework that is able to take advantage of the facial representations. A restricted Boltzmann machine uses the available AU annotations to learn the AU label or intensity distribution. We train a support vector machine for AU recognition and a support vector regression for AU intensity estimation by maximizing the log likelihood of the AU mapping functions, taking into account the learned multiple AU distribution for all training data, while simultaneously diminishing errors between the predicted action units and ground-truth action unit occurrence or intensities for all labelled data. We perform experiments on two databases. The results demonstrate the superiority of a deep neural network for learning facial features, as well as the benefit of action unit label or intensity constraints for action unit occurrence recognition or intensity estimation in fully or semi-supervised scenarios.","","","10.1109/TAFFC.2019.2914654","Anhui Science and Technology Agency; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8705351","AU recognition;intensity estimation;partially labelled data","Gold;Estimation;Face recognition;Image recognition;Support vector machines;Training data;Databases","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Unsupervised Domain Adaptation With Adversarial Residual Transform Networks","G. Cai; Y. Wang; L. He; M. Zhou","Department of Computer Science and Technology, Tongji University, Shanghai 201804, China.; Department of Computer Science and Technology, Tongji University, Shanghai 201804, China.; Department of Computer Science and Technology, Tongji University, Shanghai 201804, China (e-mail: helianghua@tongji.edu.cn).; Department of Electrical and Computer Engineering, New Jersey Institute of Technology, Newark, NJ 07102 USA (e-mail: zhou@njit.edu).","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","14","Domain adaptation (DA) is widely used in learning problems lacking labels. Recent studies show that deep adversarial DA models can make markable improvements in performance, which include symmetric and asymmetric architectures. However, the former has poor generalization ability, whereas the latter is very hard to train. In this article, we propose a novel adversarial DA method named adversarial residual transform networks (ARTNs) to improve the generalization ability, which directly transforms the source features into the space of target features. In this model, residual connections are used to share features and adversarial loss is reconstructed, thus making the model more generalized and easier to train. Moreover, a special regularization term is added to the loss function to alleviate a vanishing gradient problem, which enables its training process stable. A series of experiments based on Amazon review data set, digits data sets, and Office-31 image data sets are conducted to show that the proposed ARTN can be comparable with the methods of the state of the art.","","","10.1109/TNNLS.2019.2935384","National Natural Science Foundation of China; Joint Funds of the National Science Foundation of China; Shanghai Municipal Science and Technology Committee of Shanghai Outstanding Academic Leaders Plan; Projects of International Cooperation of Shanghai Municipal Science and Technology Committee; Shanghai Science and Technology Committee; National Key Research and Development Program; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8833506","Adversarial neural networks;residual connections;transfer learning;unsupervised domain adaptation (DA).","Feature extraction;Adaptation models;Neural networks;Transforms;Training;Task analysis;Gallium nitride","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Tree Annotations in LiDAR Data Using Point Densities and Convolutional Neural Networks","A. Gupta; J. Byrne; D. Moloney; S. Watson; H. Yin","Department of Electrical and Electronic Engineering, The University of Manchester, Manchester M13 9PL, U.K.. (e-mail:ananya.gupta@manchester.ac.uk).; Intel Corporation, Dublin, W23 CX68 Ireland.; Intel Corporation, Dublin, W23 CX68 Ireland.; Department of Electrical and Electronic Engineering, The University of Manchester, Manchester M13 9PL, U.K..; Department of Electrical and Electronic Engineering, The University of Manchester, Manchester M13 9PL, U.K.. (e-mail:hujun.yin@manchester.ac.uk).","IEEE Transactions on Geoscience and Remote Sensing","","2019","PP","99","1","11","LiDAR provides highly accurate 3-D point clouds. However, data need to be manually labeled in order to provide subsequent useful information. Manual annotation of such data is time-consuming, tedious, and error prone, and hence, in this article, we present three automatic methods for annotating trees in LiDAR data. The first method requires high-density point clouds and uses certain LiDAR data attributes for the purpose of tree identification, achieving almost 90% accuracy. The second method uses a voxel-based 3-D convolutional neural network on low-density LiDAR data sets and is able to identify most large trees accurately but struggles with smaller ones due to the voxelization process. The third method is a scaled version of the PointNet++ method and works directly on outdoor point clouds and achieves an Fscore of 82.1% on the ISPRS benchmark data set, comparable to the state-of-the-art methods but with increased efficiency.","","","10.1109/TGRS.2019.2942201","HiPEAC4 Network of Excellence through the EU H2020 Programme; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8865635","Airborne LiDAR;deep learning;tree segmentation;urban areas;voxelization.","Vegetation;Laser radar;Three-dimensional displays;Urban areas;Forestry;Training;Feature extraction","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Fune: An FPGA Tuning Framework for CNN Acceleration","Q. Xiao; Y. Liang","School of Electronics Engineering and Computer Science, Peking University, Beijing, China, 100871.; School of Electronics Engineering and Computer Science, Peking University, Beijing, China, 100871.","IEEE Design & Test","","2019","PP","99","1","1","CNN models are increasingly deployed on hardware accelerators such as ASICs, GPUs, and FPGAs. Among them, FPGA has emerged as a promising solution as it provides customized hardware performance with general programmability. However, prior works that employ static and uniform FPGA designs forgo the opportunities for flexible dynamic configuration and suffer from poor resource utilization. To address this inefficiency, we propose a framework Fune to enable fine-grained customization for CNNs with dynamic reconfiguration on FPGAs. First, by identifying diversities in CNNs, we demonstrate that idle compute units, unsuitable algorithms, and insufficient parallelisms are the sources of inefficiencies for uniform designs. Then, we propose an algorithm to automatically determine when to reconfigure and what to implement. Experiments using four CNN models demonstrate up to 2.14× performance speedup over static uniform accelerators.","","","10.1109/MDAT.2019.2908549","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8678683","Deep learning;Convolutional Neural Network (CNN);Field Programmable Gate Array (FPGA);reconfiguration","Field programmable gate arrays;Parallel processing;Kernel;Tuning;Heuristic algorithms;Hardware;Feature extraction","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Ultrafast Active Response Strategy against Malfunction Attack on Fault Current Limiter","F. Wei; Z. Wan; H. He; X. Lin","Department of Electrical, Computer and Biomedical Engineering, University of Rhode Island, Kingston, RI 02881 USA.; Department of Electrical, Computer and Biomedical Engineering, University of Rhode Island, Kingston, RI 02881 USA.; Department of Electrical, Computer and Biomedical Engineering, University of Rhode Island, Kingston, RI 02881 USA.; State Key Laboratory of Advanced Electromagnetic Engineering and Technology (Huazhong University of Science and Technology), Wuhan, Hubei 430074 China.","IEEE Transactions on Smart Grid","","2019","PP","99","1","1","Fault current limiter (FCL) is a crucial device to guarantee the corresponding breaker can clear the fault with over-limit short-circuit current (SCC). If a FCL is disabled by malicious cyber-attackers, the breaker will fail to clear the fault. Under this circumstance, the breaker failure protection system will be activated to trip all the connected transmission lines, resulting in a severe N-k contingency. In order to deal with the breaking failure caused by FCL malfunction attack, we propose an ultrafast active response strategy (UFARS) based on deep neural network framework. Firstly, an Long Short-Term Memory (LSTM) network is designed to extract features from the time sequence of SCC. Then, a deep reinforcement learning (RL) based approach is proposed to determine the optimal strategy to clear the fault. More specifically, with the features from the LSTM network, the deep RL will select and trip a combination of transmission lines connected to the faulty line, such that the SCC will become smaller than the breaking capacity. Thus, the fault can be cleared with the corresponding breaker. After the fault is cleared, the tripped connected transmission lines will be reclosed to recover the integrity of power system. An environment is established to simulate the power system dynamics and obtain the essential data to train the proposed deep neural network. Numerical results show that the proposed strategy can clear the fault with the minimum impact on power system stability.","","","10.1109/TSG.2019.2960459","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8939519","Malfunction attack;fault current limiter;deep reinforcement learning;ultrafast active response strategy.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Improving the Accuracy of Binarized Neural Networks and Application on Remote Sensing Data","Q. Wu; C. Chen; C. Wang; Y. Wu; Y. Zhao; X. Wu","School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou 310018, China.; School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou 310018, China.; School of Electronic and Computer Engineering, Shenzhen Graduate School, Peking University, Shenzhen 518055, China.; Intellisense Systems, Inc., Torrance, CA 90501 USA.; School of Electronic and Computer Engineering, Shenzhen Graduate School, Peking University, Shenzhen 518055, China (e-mail: zhaoyong@pkusz.edu.cn).; School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou 310018, China (e-mail: wuxd@hdu.edu.cn).","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","Deep neural networks are well known to achieve outstanding results in many domains. Recently, many researchers have introduced deep neural networks into remote sensing (RS) data processing. However, typical RS data usually possesses enormous scale. Processing RS data with deep neural networks requires a rather demanding computing hardware. Most high-performance deep neural networks are associated with highly complex network structures with many parameters. This restricts their deployment for real-time processing in satellites. Many researchers have attempted overcoming this obstacle by reducing network complexity. One of the promising approaches able to reduce network computational complexity and memory usage dramatically is network binarization. In this letter, through analyzing the learning behavior of binarized neural networks (BNNs), we propose several novel strategies for improving the performance of BNNs. Empirical experiments prove these strategies to be effective in improving BNN performance for image classification tasks on both small- and large-scale data sets. We also test BNN on a remote sense data set with positive results. A detailed discussion and preliminary analysis of the strategies used in the training are provided.","","","10.1109/LGRS.2019.2942348","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8863401","Binarized neural network (BNN);computational infrastructure and geographic information system (GIS);convolutional neural network (CNN);deep learning.","Training;Neural networks;Synapses;Convergence;Remote sensing;Computational modeling;Quantization (signal)","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Exploring Discriminative Representations for Image Emotion Recognition with CNNs","W. Zhang; X. He; W. Lu","School of Control Science and Engineering, Shandong University, Jinan China (e-mail: davidzhangsdu@gmail.com); School of Control Science and Engineering, Shandong University, 12589 Jinan China (e-mail: hexiffer@outlook.com); School of Control Science and Engineering, Shandong University, Jinan China (e-mail: wzlu@sdu.edu.cn)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","Image emotion recognition aims to automatically categorize the emotion conveyed by an image. The potential of deep representation has been demonstrated in recent research on image emotion recognition. To better understand how CNNs work in emotion recognition, we investigate the deep features by visualizing them in this work. The study shows that the deep models mainly rely on the image content but miss the image style information such as color, texture and shapes that are low-level visual features but are vital for evoking emotions. To form a more discriminative representation for emotion recognition, we propose a novel CNN model that learns and integrates the content information from the high layers of the deep network with the style information from the lower layers. The uncertainty of image emotion labels is also investigated in this paper. Rather than using the emotion labels for training directly, as in previous work, a new loss function is designed by including the emotion labeling quality to optimize the proposed inference model. Extensive experiments on benchmark datasets are conducted to demonstrate the superiority of the proposed representation.","","","10.1109/TMM.2019.2928998","Major Research Program of Shandong Province; National Key Research and Development Plan of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8764506","Image emotion classification;Discriminative representation;Emotional inference;Deep learning;Convolutional neural networks","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Ground-Plane-Based Absolute Scale Estimation for Monocular Visual Odometry","D. Zhou; Y. Dai; H. Li","Baidu, Inc., Beijing 100085, China, and also with the National Engineering Laboratory of Deep Learning Technology and Application, Beijing 100085, China.; School of Electronics and Information, Northwestern Polytechnical University, Xi'an 710129, China (e-mail: daiyuchao@gmail.com).; Research School of Electrical, Energy and Materials Engineering, Australian National University, Canberra, ACT 2601, Australia, and also with the Australia Centre for Robotic Vision, Australian National University, Canberra, ACT 2601, Australia.","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","12","Recovering an absolute metric scale from a monocular camera is a challenging but highly desirable problem for monocular camera-based systems. By using different kinds of cues, various approaches have been proposed for scale estimation, such as camera height and object size. In this paper, first, we summarize different kinds of scale estimation approaches. Then, we propose a robust divide-and-conquer absolute scale estimation method based on the ground plane and camera height by analyzing the advantages and disadvantages of different approaches. By using the estimated scale, an effective scale correction strategy has been proposed to reduce the scale drift during the monocular visual odometry estimation process. Finally, the effectiveness and robustness of the proposed method have been verified on both public and self-collected image sequences.","","","10.1109/TITS.2019.2900330","National Natural Science Foundation of China; Australian Research Council ARC Grants; Australia ARC Centre of Excellence Program on Robotic Vision; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8708682","Absolute scale estimation;ground plane;scale correction;monocular VO and SLAM.","Cameras;Estimation;Simultaneous localization and mapping;Three-dimensional displays;Sensor systems;Laser radar","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deterministic Policy Gradient With Integral Compensator for Robust Quadrotor Control","Y. Wang; J. Sun; H. He; C. Sun","School of Automation, Southeast University, Nanjing 210096, China, and also with the Key Laboratory of Measurement and Control of Complex System of Engineering, Ministry of Education, Southeast University, Nanjing 210096, China.; School of Automation and Electrical Engineering, University of Science and Technology Beijing, Beijing 10083, China; Department of Electrical, Computer, and Biomedical Engineering, University of Rhode Island, Kingston, RI 02881 USA (e-mail: he@ele.uri.edu).; School of Automation, Southeast University, Nanjing 210096, China, and also with the Key Laboratory of Measurement and Control of Complex System of Engineering, Ministry of Education, Southeast University, Nanjing 210096, China.","IEEE Transactions on Systems, Man, and Cybernetics: Systems","","2019","PP","99","1","13","In this paper, a deep reinforcement learning-based robust control strategy for quadrotor helicopters is proposed. The quadrotor is controlled by a learned neural network which directly maps the system states to control commands in an end-to-end style. The learning algorithm is developed based on the deterministic policy gradient algorithm. By introducing an integral compensator to the actor-critic structure, the tracking accuracy and robustness have been greatly enhanced. Moreover, a two-phase learning protocol which includes both offline and online learning phase is proposed for practical implementation. An offline policy is first learned based on a simplified quadrotor model. Then, the policy is online optimized in actual flight. The proposed approach is evaluated in the flight simulator. The results demonstrate that the offline learned policy is highly robust to model errors and external disturbances. It also shows that the online learning could significantly improve the control performance.","","","10.1109/TSMC.2018.2884725","National Natural Science Foundation of China; National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8600717","Deterministic policy gradient (DPG);neural network;quadrotor;reinforcement learning","Reinforcement learning;Rotors;Helicopters;Neural networks;Aerodynamics;Heuristic algorithms;Robustness","","","","3","","","","","","IEEE","IEEE Early Access Articles"
"An Interpretable Fuzzy DBN-based Classifier for Indoor User Movement Prediction in Ambient Assisted Living Applications","S. Wang; F. Chung; X. Zhang","School of digital media, WuXi, JiangSu China 214122 (e-mail: wxwangst@aliyun.com); Dept. Computing, HongKong Polytechnic University, HongKong China 999077 (e-mail: korris.chung@polyu.edu.hk); School of Digital Media, JiangNan University, WuXi China 214122 (e-mail: 1047897965@qq.com)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","In this paper, an interpretable fuzzy DBN-based classifier called DBN-TSK-FC is created for indoor user movement prediction in ambient assisted living applications. With its promising classification performance, DBN-TSK-FC features sharing both the powerful neural representation ability of a DBN (deep belief network) and the strong uncertainty-handling capability of an interpretable fuzzy representation. On the one hand, DBN-TSK-FC builds its interpretable fuzzy representation in a hierarchical way by applying the classical fuzzy clustering algorithm FCM to obtain fuzzy partitions on the training dataset. Then, it forms interpretable antecedent parts of fuzzy rules as the corresponding fuzzy representation. On the other hand, DBN-TSK-FC builds its DBN-based neural representation in the other hierarchical way. That is, it applies the existing unsupervised DBN pretraining on the training dataset and then takes the neural representation of all the hidden nodes in the top layer of the corresponding DBN as the set of consequent variables of fuzzy rules. In this approach, both the interpretable fuzzy representation and the DBN-based neural representation are further fused to form the corresponding fuzzy rules quickly by using the least learning machine (LLM) on both the fuzzy rules and the labeling information of the original dataset. Therefore, DBN-TSK-FC is essentially a deep TSK fuzzy classifier from the perspective of fuzzy rules, and it indeed avoids the very slow fine-tuning training required after the unsupervised pretraining of the existing DBN learning. The experimental results on the MovementAAL_RSS dataset indicate the effectiveness of the proposed classifier DBN-TSK-FC.","","","10.1109/TII.2019.2912625","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8695137","Ambient assisted living;TSK fuzzy classifiers;deep belief network;interpretability;fuzzy clustering;least learning machine","Wireless sensor networks;Training;Ambient assisted living;Robot sensing systems;Prediction methods;Informatics;Classification algorithms","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Blind LTE-U/WiFi Coexistence System using Convolutional Neural Network","M. Yang; Y. Song; C. Cai; H. Gu","School of Electronic and Optical Engineering, Nanjing University of Science and Technology, Nanjing 210094, China.; School of Electronic and Optical Engineering, Nanjing University of Science and Technology, Nanjing 210094, China.; National Demonstration Center for Experimental Electrotechnics and Electronics Education, Yangtze University, Jingzhou, 434023, China.; College of Telecommunications and Information Engineering, Nanjing University of Posts and Telecommunications, Nanjing 210003, China.","IEEE Access","","2019","PP","99","1","1","With the rapid development of wireless communications technology, long term evolution (LTE) technology in unlicensed bands (LTE-U) can effectively solve the lack of spectrum resources. However, the competition in LTE-U and wireless fidelity (WiFi) will seriously interfere their communication quality, which making the friendly coexistence of LTE-U and WiFi becomes a hot research area. In this paper, we propose a classification algorithm based on deep learning to realize the identification of LTE-U and WiFi signal. Experiment results use mixed data at different signal to noise ratios (SNRs) and compare the classification results within two data forms. Experimental results show that our proposed deep learning-aided method can effectively distinguish LTE-U and WiFi signals and further achieve their friendly coexistence.","","","10.1109/ACCESS.2019.2962859","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8945240","Automatic LTE-U;WiFi;in-phase and quadrature;deep learning;unlicensed band","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Combining Recurrent Neural Networks and Adversarial Training for Human Motion Synthesis and Control","Z. Wang; J. Chai; S. Xia","Advanced Computing Research Laboratory, Institute of Computing Technology Chinese Academy of Sciences, 53035 Beijing, Beijing China 100190 (e-mail: wangzhiyong@ict.ac.cn); Chinese Academy of Sciences, Institute of Computing Technology, Beijing, Beijing China 100190 (e-mail: xsh@ict.ac.cn); Department of Computer Science and Engineering, Texas A&M University., College Station, Texas United States (e-mail: jxchai@gmail.com)","IEEE Transactions on Visualization and Computer Graphics","","2019","PP","99","1","1","This paper introduces a new generative deep learning network for human motion synthesis and control. Our key idea is to combine recurrent neural networks (RNNs) and adversarial training for human motion modeling. We first describe an efficient method for training an RNN model from prerecorded motion data. We implement RNNs with long short-term memory (LSTM) cells because they are capable of addressing the nonlinear dynamics and long term temporal dependencies present in human motions. Next, we train a refiner network using an adversarial loss, similar to generative adversarial networks (GANs), such that refined motion sequences are indistinguishable from real mocap data using a discriminative network. The resulting model is appealing for motion synthesis and control because it is compact, contact-aware, and can generate an infinite number of naturally looking motions with infinite lengths. Our experiments show that motions generated by our deep learning model are always highly realistic and comparable to high-quality motion capture data. We demonstrate the power and effectiveness of our models by exploring a variety of applications, ranging from random motion synthesis, online/offline motion control, and motion filtering. We show the superiority of our generative model by comparison against baseline models.","","","10.1109/TVCG.2019.2938520","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8826012","Deep learning;Adversarial Training;Human Motion Modeling;Synthesis and Control","Hidden Markov models;Data models;Training;Generators;Mathematical model;Recurrent neural networks;Animation","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Multi-Domain Connectome Convolutional Neural Network for Identifying Schizophrenia from EEG Connectivity Patterns","C. Phang; F. M. Noman; H. Hussain; C. Ting; H. Ombao","School of Biomedical Engineering & Health Sciences, Universiti Teknologi Malaysia, 81310 Skudai, Johor, Malaysia (e-mail: phangcr@gmail.com); School of Biomedical Engineering & Health Sciences, Universiti Teknologi Malaysia, 81310 Skudai, Johor, Malaysia (e-mail: mnfuad3@live.utm.my); School of Biomedical Engineering & Health Sciences, Universiti Teknologi Malaysia, 81310 Skudai, Johor, Malaysia (e-mail: hadrihussain1@gmail.com); Medical Devices & Technology Centre, School of Biomedical Engineering & Health Sciences, Universiti Teknologi Malaysia, 81310 Skudai, Johor, Malaysia, and also the Statistics Program, King Abdullah University of Science and Technology, Thuwal 23955, Saudi Arabia (e-mail: cmting@utm.my); Statistics Program, King Abdullah University of Science and Technology, Thuwal 23955, Saudi Arabia (e-mail: hernando.ombao@kaust.edu.sa)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","Objective: We exploit altered patterns in brain functional connectivity as features for automatic discriminative analysis of neuropsychiatric patients. Deep learning methods have been introduced to functional network classification only very recently for fMRI, and the proposed architectures essentially focused on a single type of connectivity measure. Methods: We propose a deep convolutional neural network (CNN) framework for classification of electroencephalogram (EEG)-derived brain connectome in schizophrenia (SZ). To capture complementary aspects of disrupted connectivity in SZ, we explore combination of various connectivity features consisting of time and frequency-domain metrics of effective connectivity based on vector autoregressive model and partial directed coherence, and complex network measures of network topology. We design a novel multi-domain connectome CNN (MDC-CNN) based on a parallel ensemble of 1D and 2D CNNs to integrate the features from various domains and dimensions using different fusion strategies. We also consider an extension to dynamic brain connectivity using the recurrent neural networks. Results: Hierarchical latent representations learned by the multiple convolutional layers from EEG connectivity reveal apparent group differences between SZ and healthy controls (HC). Results on a large resting-state EEG dataset show that the proposed CNNs significantly outperform traditional support vector machine classifiers. The MDC-CNN with combined connectivity features further improves performance over single-domain CNNs using individual features, achieving remarkable accuracy of 91.69% with a decision-level fusion. Conclusion: The proposed MDC-CNN by integrating information from diverse brain connectivity descriptors is able to accurately discriminate SZ from HC. Significance: The new framework is potentially useful for developing diagnostic tools for SZ and other disorders.","","","10.1109/JBHI.2019.2941222","Ministry of Education Malaysia and Universiti Teknologi Malaysia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8836535","EEG;brain connectivity networks;deep learning;convolution neural networks;ensemble classifiers","Electroencephalography;Reactive power;Time measurement;Frequency-domain analysis;Brain modeling","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Efficient activity recognition in smart homes using delayed fuzzy temporal windows on binary sensors","R. a. Hamad; A. G. Salguero; M. Bouguelia; M. Espinilla; J. M. Quero","Intelligent Systems and Digital Design, Hogskolan i Halmstad, 3694 Halmstad, Halmstad Sweden (e-mail: rebali@hh.se); Computer Science, University of Cadiz, Puerto Real, Cadiz Spain 11519 (e-mail: alberto.salguero@uca.es); Intelligent Systems and Digital Design, Hogskolan i Halmstad, 3694 Halmstad Sweden (e-mail: mohbou@hh.se); Jaen Spain 23071 (e-mail: mestevez@ujaen.es); Computer Science, Universidad de Jaen, 16747 Jaen, Andalucia Spain (e-mail: jmquero@ujaen.es)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","Human activity recognition has become an active research field over the past few years due to its wide application in various fields such as health-care, smart home monitoring, and surveillance. Existing approaches for activity recognition in smart homes have achieved promising results. Most of these approaches evaluate real-time recognition of activities using only sensor activations that precede the evaluation time (where the decision is made). However, in several critical situations, such as diagnosing people with dementia, “preceding sensor activations” are not always sufficient to accurately recognize the inhabitant's daily activities in each evaluated time. To improve performance, we propose a method that delays the recognition process in order to include some sensor activations that occur after the point in time where the decision needs to be made. For this, the proposed method uses multiple incremental fuzzy temporal windows to extract features from both preceding and some oncoming sensor activations. The proposed method is evaluated with two temporal deep learning models (Convolutional Neural Network and Long Short-Term Memory), on a binary sensor dataset of real daily living activities. The experimental evaluation shows that the proposed method achieves significantly better results than the real-time approach, and that the representation with fuzzy temporal windows enhances performance within Deep Learning models.","","","10.1109/JBHI.2019.2918412","REMIND project; Marie Sklodowska-Curie EU Framework; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8719964","Activity Recognition;Fuzzy Temporal Windows;Deep Learning;Temporal Evaluation","Activity recognition;Intelligent sensors;Real-time systems;Smart homes;Hidden Markov models;Feature extraction","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Robust RGB-D Face Recognition Using Attribute-Aware Loss","L. Jiang; J. Zhang; B. Deng","School of Mathematical Sciences, University of Science and Technology of China, Hefei, Anhui China (e-mail: jluo@mail.ustc.edu.cn); Mathematical Sciences, University of Science and Technology of China, Hefei, Anhui China (e-mail: juyong@ustc.edu.cn); School of Computer Science and Informatics, Cardiff University, 2112 Cardiff, South Glamorgan United Kingdom of Great Britain and Northern Ireland (e-mail: bldeng@gmail.com)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Existing convolutional neural network (CNN) based face recognition algorithms typically learn a discriminative feature mapping, using a loss function that enforces separation of features from different classes and/or aggregation of features within the same class. However, they may suffer from bias in the training data such as uneven sampling density, because they optimize the adjacency relationship of the learned features without considering the proximity of the underlying faces. Moreover, since they only use facial images for training, the learned feature mapping may not correctly indicate the relationship of other attributes such as gender and ethnicity, which can be important for some face recognition applications. In this paper, we propose a new CNN-based face recognition approach that incorporates such attributes into the training process. Using an attribute-aware loss function that regularizes the feature mapping using attribute proximity, our approach learns more discriminative features that are correlated with the attributes. We train our face recognition model on a large-scale RGB-D data set with over 100K identities captured under real application conditions. By comparing our approach with other methods on a variety of experiments, we demonstrate that depth channel and attribute-aware loss greatly improve the accuracy and robustness of face recognition.","","","10.1109/TPAMI.2019.2919284","National Natural Science Foundation of China; Youth Innovation Promotion Association of the Chinese Academy of Sciences; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8723091","Face Recognition;RGB-D images;uneven sampling density;attribute-aware loss","Face recognition;Face;Training;Training data;Feature extraction;Task analysis;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Capsule Network based Modeling of Multi-omics Data for Discovery of Breast Cancer-related Genes","C. Peng; Y. Zheng; D. Huang","the Institute of Machine Learning and Systems Biology, Shanghai, Shanghai China (e-mail: pcll@tongji.edu.cn); Shanghai, Shanghai China (e-mail: zy_yang6354@tongji.edu.cn); Computer Science Department, Tongji University, Shanghai, ShangHai China (e-mail: dshuang@tongji.edu.cn)","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2019","PP","99","1","1","Breast cancer is one of the most common cancers all over the world, which bring about more than 450,000 deaths each year. Although this malignancy has been extensively studied by a large number of researchers, its prognosis is still poor. Since therapeutic advance can be obtained based on gene signatures, there is an urgent need to discover genes related to breast cancer that may help uncover the mechanisms in cancer progression. We propose a deep learning method for the discovery of breast cancer-related genes by using Capsule Network based Modeling of Multi-omics Data (CapsNetMMD). In CapsNetMMD, we make use of known breast cancer-related genes to transform the issue of gene identification into the issue of supervised classification. The features of genes are generated through comprehensive in-tegration of multi-omics data, e.g., mRNA expression, z scores for mRNA expression, DNA methylation and two forms of DNA copy-number alterations (CNAs). By modeling features based on cap-sule network, we identify breast cancer-related genes with a significantly better performance than other existing machine learning methods. The predicted genes with prognostic values play potential important roles in breast cancer and may serve as candidates for biologists and medical scientists in the future studies of biomarkers.","","","10.1109/TCBB.2019.2909905","China Postdoctoral Science Foundation; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8684326","Multi-omics data;Capsule network;Prediction of cancer-related genes;Machine learning;Breast cancer","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Prognostic Model Based on DBN and Diffusion Process for Degrading Bearing","C. Hu; H. Pei; X. Si; D. Du; Z. Pang; X. Wang","Automation, Xi'an Institute of High-Tech, Xi'an, Shaanxi China (e-mail: hch6603@263.net); Xi'an High-Tech Institute, China (e-mail: ph2010hph@sina.com); Xi'an Institute of High-Technology, China (e-mail: sixiaosheng@gmail.com); Xi'an Institute of High-Technology, China (e-mail: ddb_effort@126.com); Xi'an Institute of High-Tech., China (e-mail: pznfatfight@163.com); Xi'an Institute of High-Tech., China (e-mail: 492126190@qq.com)","IEEE Transactions on Industrial Electronics","","2019","PP","99","1","1","Remaining useful life (RUL) prediction is extremely significant to ensure the safe and reliable operation for bearing. Current deep learning based RUL prediction methods are difficult to reflect the uncertainty of the RUL prediction results. Toward this end, we propose a RUL prediction model based on deep belief network (DBN) and diffusion process (DP) in this paper. The proposed method consists of two parts: feature extraction combining DBN and locally linear embedding (LLE), DP based RUL prediction. In the first part, DBN is used to extract deep hidden features behind the monitoring signals, and then the features with higher tendency are screened as the input of LLE. The health index that can truly reflect the bearing health condition is further determined through LLE. In the second part, a health index evolving model based on DP is presented and the probability density function (PDF) of the predicted RUL is accordingly derived in the sense of the first hitting time (FHT). As such, the proposed method holds promise to improve the prediction accuracy and facilitate the prognostic uncertainty. Finally, experimental studies on the bearing degradation data and the associated comparative analysis verify the effectiveness and superiority of the proposed method","","","10.1109/TIE.2019.2947839","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8879657","Remaining useful life (RUL);deep belief network (DBN);locally linear embedding (LLE);diffusion process (DP);first hitting time (FHT);bearing degradation","Feature extraction;Indexes;Uncertainty;Degradation;Machine learning;Artificial neural networks;Reliability","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"FCSR-GAN: Joint Face Completion and Super-resolution via Multi-task Learning","J. Cai; H. Han; S. Shan; X. Chen","Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences, Beijing 100190, China, and also with the University of Chinese Academy of Sciences, Beijing 100049, China.; Key Laboratory of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS, Beijing 100190, China, and also with Peng Cheng Laboratory, Shenzhen, China.; Key Laboratory of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS, Beijing 100190, China and University of Chinese Academy of Sciences, Beijing 100049, China, and he is a member of CAS Center for Excellence in Brain Science and Intelligence Technology.; Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences, Beijing 100190, China, and also with the University of Chinese Academy of Sciences, Beijing 100049, China.","IEEE Transactions on Biometrics, Behavior, and Identity Science","","2019","PP","99","1","1","Combined variations containing low-resolution and occlusion often present in face images in the wild, e.g., under the scenario of video surveillance. While most of the existing face image recovery approaches can handle only one type of variation per model, in this work, we propose a deep generative adversarial network (FCSR-GAN) for performing joint face completion and face super-resolution via multi-task learning. The generator of FCSR-GAN aims to recover a high-resolution face image without occlusion given an input low-resolution face image with occlusion. The discriminator of FCSR-GAN uses a set of carefully designed losses (an adversarial loss, a perceptual loss, a pixel loss, a smooth loss, a style loss, and a face prior loss) to assure the high quality of the recovered high-resolution face images without occlusion. The whole network of FCSR-GAN can be trained end-to-end using our two-stage training strategy. Experimental results on the public-domain CelebA and Helen databases show that the proposed approach outperforms the state-of-the-art methods in jointly performing face super-resolution (up to 8 ×) and face completion, and shows good generalization ability in cross-database testing. Our FCSR-GAN is also useful for improving face identification performance when there are low-resolution and occlusion in face images. The code of FCSR-GAN is available at: https://github.com/swordcheng/FCSR-GAN.","","","10.1109/TBIOM.2019.2951063","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8890717","Joint face completion and super-resolution;multi-task learning;generative adversarial network;two-stage training.","Face;Biometrics (access control);Training;Gallium nitride;Generative adversarial networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Mobile Edge Computing based Hierarchical Machine Learning Tasks Distribution for IIoT","B. Yang; X. Cao; X. Li; Q. Zhang; L. Qian","Department of Electrical and Computer Engineering and CREDIT Center, Prairie View A&M University, Texas A&M University System, Prairie View, TX 77446, USA.; Department of Electrical and Computer Engineering, University of Houston, Houston, TX 77004, USA.; Department of Electrical and Computer Engineering and CREDIT Center, Prairie View A&M University, Texas A&M University System, Prairie View, TX 77446, USA.; United Technologies Research Center, East Hartford, CT 06108, USA.; Department of Electrical and Computer Engineering and CREDIT Center, Prairie View A&M University, Texas A&M University System, Prairie View, TX 77446, USA.","IEEE Internet of Things Journal","","2019","PP","99","1","1","In this paper, we propose a novel framework of Mobile Edge Computing (MEC) based hierarchical Machine Learning (ML) tasks distribution for Industrial IoT. It is assumed that a batch of ML tasks such as anomaly detection need to be executed timely in a MEC setting, where the devices have limited computing capability while MEC server has rich computing resources. Thus a small ML model for the device and a deep ML model for the MEC server are pre-trained offline using historical data, and then they are deployed accordingly. However, offloading tasks to the MEC server introduces communications delay. Thus, each device must decide the portion of the tasks to offload to minimize the processing delay. Since the delay and the error of data processing are incurred by communications and ML computing, a joint optimization problem is formulated to minimize the total delay subject to ML model complexity and inference error rate, data quality, computing capability at the device and MEC server, and communications bandwidth. A closed-form solution is derived analytically and an optimal offloading strategy selection algorithm is proposed. Insights are provided to understand the tradeoff between communications and ML computing in offloading decisions, and the effects of key parameters in the proposed algorithm are investigated. Numerical results demonstrate the effectiveness of the proposed algorithm.","","","10.1109/JIOT.2019.2959035","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8931562","Machine learning (ML);mobile edge computing (MEC);industrial internet of things (IIoT).","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Machine Learning-Based Leakage-Event Identification for Smart Water Supply Systems","B. Zhou; V. Lau; X. Wang","Shenzhen Research Institute, Hong Kong University of Science and Technology (HKUST), Shenzhen 518000, China, and he is with the Department of Electronic and Computer Engineering, HKUST, Hong Kong 999077.; Department of Electronic and Computer Engineering, HKUST, Hong Kong 999077.; Department of Civil and Environmental Engineering, HKUST, Hong Kong 999077, China.","IEEE Internet of Things Journal","","2019","PP","99","1","1","In this paper, we are interested in leak identification (LI) for water supply pipelines using transient-wave (pressure) measurement data. This is challenging since water pipeline system conditions are usually uncertain in practice. For instance, the pipeline diameter, the friction factor and the pipeline shape will vary. The conventional signal propagation model-based LI methods rely on a deterministic system model with perfectly-known and fixed-value parameters, which limits their application in general cases. To address this challenge, we design a novel deep neural network (DNN)-based machine learning approach to solve the LI problem. Firstly, we propose a novel fusion-enhanced stochastic optimization algorithm for the DNN training, which can greatly improve the DNN training performance and hence the LI accuracy, without increasing the computational cost. Secondly, we design a novel convolutional-based pooling network to extract the stable texture feature of transient-wave samples, thus achieving a reliable LI solution against the pipeline system dynamics. It is shown in experiments that, thanks to the above system design, the proposed DNN-based LI method can achieve a failure rate lower than 6*10-4 when the signal-to-noise-ratio is 0 dB, which outperforms the conventional LI methods.","","","10.1109/JIOT.2019.2958920","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8930542","Machine learning;water pipeline system;leak identification;neural network;transient-wave model;fusion.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Multimodal Transformer with Multi-View Visual Representation for Image Captioning","J. Yu; J. Li; Z. Yu; Q. Huang","Key Laboratory of Complex Systems Modeling and Simulation, School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, 310018, China.; Key Laboratory of Complex Systems Modeling and Simulation, School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, 310018, China.; Key Laboratory of Complex Systems Modeling and Simulation, School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, 310018, China.; School of Computer and Control Engineering, University of Chinese Academy of Sciences, Beijing 101408, China.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Image captioning aims to automatically generate a natural language description of a given image, and most state-of-the-art models have adopted an encoder-decoder framework. The framework consists of a convolution neural network (CNN)-based image encoder that extracts region-based visual features from the input image, and an recurrent neural network (RNN) based caption decoder that generates the output caption words based on the visual features with the attention mechanism. Despite the success of existing studies, current methods only model the co-attention that characterizes the inter-modal interactions while neglecting the self-attention that characterizes the intra-modal interactions. Inspired by the success of the Transformer model in machine translation, here we extend it to a Multimodal Transformer (MT) model for image captioning. Compared to existing image captioning approaches, the MT model simultaneously captures intra-and inter-modal interactions in a unified attention block. Due to the in-depth modular composition of such attention blocks, the MT model can perform complex multimodal reasoning and output accurate captions. Moreover, to further improve the image captioning performance, multi-view visual features are seamlessly introduced into the MT model. We quantitatively and qualitatively evaluate our approach using the benchmark MSCOCO image captioning dataset and conduct extensive ablation studies to investigate the reasons behind its effectiveness. The experimental results show that our method significantly outperforms the previous state-of-the-art methods. With an ensemble of seven models, our solution ranks the 1st place on the real-time leaderboard of the MSCOCO image captioning challenge at the time of the writing of this paper.","","","10.1109/TCSVT.2019.2947482","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8869845","Image captioning;multi-view learning;deep learning","Visualization;Feature extraction;Hidden Markov models;Adaptation models;Task analysis;Decoding;Computational modeling","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Automated Muscle Segmentation from Clinical CT using Bayesian U-Net for Personalized Musculoskeletal Modeling","Y. Hiasa; Y. Otake; M. Takao; T. Ogawa; N. Sugano; Y. Sato","Division of Information Science, Nara Institute of Science and Technology, Ikoma, Nara, Japan.; Division of Information Science, Nara Institute of Science and Technology, Ikoma, Nara, Japan.; Department of Orthopaedic Surgery, Osaka University Graduate School of Medicine, Suita, Osaka, Japan.; Department of Orthopaedic Surgery, Osaka University Graduate School of Medicine, Suita, Osaka, Japan.; Department of Orthopaedic Medical Engineering, Osaka University Graduate School of Medicine, Suita, Osaka, Japan.; Division of Information Science, Nara Institute of Science and Technology, Ikoma, Nara, Japan.","IEEE Transactions on Medical Imaging","","2019","PP","99","1","1","We propose a method for automatic segmentation of individual muscles from a clinical CT. The method uses Bayesian convolutional neural networks with the U-Net architecture, using Monte Carlo dropout that infers an uncertainty metric in addition to the segmentation label. We evaluated the performance of the proposed method using two data sets: 20 fully annotated CTs of the hip and thigh regions and 18 partially annotated CTs that are publicly available from The Cancer Imaging Archive (TCIA) database. The experiments showed a Dice coefficient (DC) of 0.891±0.016 (mean±std) and an average symmetric surface distance (ASD) of 0.994±0.230 mm over 19 muscles in the set of 20 CTs. These results were statistically significant improvements compared to the state-of-the-art hierarchical multi-atlas method which resulted in 0.845±0.031 DC and 1.556±0.444 mm ASD. We evaluated validity of the uncertainty metric in the multi-class organ segmentation problem and demonstrated a correlation between the pixels with high uncertainty and the segmentation failure. One application of the uncertainty metric in activelearning is demonstrated, and the proposed query pixel selection method considerably reduced the manual annotation cost for expanding the training data set. The proposed method allows an accurate patient-specific analysis of individual muscle shapes in a clinical routine. This would open up various applications including personalization of biomechanical simulation and quantitative evaluation of muscle atrophy.","","","10.1109/TMI.2019.2940555","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8830493","Bayesian Deep Learning;Convolutional Neural Networks;Active Learning;Image Segmentation;Musculoskeletal Model","Muscles;Uncertainty;Image segmentation;Computed tomography;Measurement;Computational modeling;Bayes methods","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Blending Big Data Analytics: Review on Challenges and a Recent Study","F. Amalina; I. A. T. Hashem; Z. H. Azizul; A. T. Fong; A. Firdaus; M. Imran; N. B. Anuar","Faculty of Computer Science and information Technology, University of Malaya, Kuala Lumpur, Malaysia.; School of computing & Information Technology, Taylor’s University, Subang Jaya, Selangor, Malaysia.; Faculty of Computer Science and information Technology, University of Malaya, Kuala Lumpur, Malaysia.; Faculty of Computer Science and information Technology, University of Malaya, Kuala Lumpur, Malaysia.; Faculty of Computer Systems and Software Engineering, University of Malaysia Pahang, Kuantan, Pahang, Malaysia.; College of Computer and Information Sciences, King Saud University, Saudi Arabia.; Faculty of Computer Science and information Technology, University of Malaya, Kuala Lumpur, Malaysia.","IEEE Access","","2019","PP","99","1","1","With the collection of massive amounts of data every day, big data analytics has emerged as an important trend for many organizations. These collected data can contain important information that may be key to solving wide-ranging problems, such as cyber security, marketing, healthcare, and fraud. To analyze their large volumes of data for business analyses and decisions, large companies, such as Facebook and Google, adopt analytics. Such analyses and decisions impact existing and future technology. In this study, we explore how big data analytics is utilized as a technique for solving problems of complex and unstructured data using such technologies as Hadoop, Spark, and MapReduce. We also discuss the data challenges introduced by big data according to the literature, including its six V’s. Moreover, we investigate case studies of big data analytics on various techniques of such analytics, namely, text, voice, video, and network analytics. We conclude that big data analytics can bring positive changes in many fields, such as education, military, healthcare, politics, business, agriculture, banking, and marketing, in the future.","","","10.1109/ACCESS.2019.2923270","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8737669","Big data analytics;data analytics;deep learning;machine learning","Big Data;Data analysis;Tools;Social networking (online);Computer languages;Companies","","","","1","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Epileptic Signal Classification with Deep EEG Features by Stacked CNNs","J. Cao; J. Zhu; W. Hu; A. Kummert","School of Automation, Hangzhou Dianzi University, Zhejiang, 310018, China, and also with the Key Lab for IOT and Information Fusion Technology of Zhejiang, Hangzhou Dianzi University, Zhejiang, 310018, China, also with the Hangzhou Neuro Science and Technology Co. Ltd, Hangzhou, China, and also with the School of Electrical, Information and Media Engineering, University of Wuppertal, 42119 Wuppertal, Germany.; School of Automation, Hangzhou Dianzi University, Zhejiang, 310018, China, and also with the Key Lab for IOT and Information Fusion Technology of Zhejiang, Hangzhou Dianzi University, Zhejiang, 310018, China.; School of Automation, Hangzhou Dianzi University, Zhejiang, 310018, China, and also with the Key Lab for IOT and Information Fusion Technology of Zhejiang, Hangzhou Dianzi University, Zhejiang, 310018, China.; School of Electrical, Information and Media Engineering, University of Wuppertal, 42119 Wuppertal, Germany.","IEEE Transactions on Cognitive and Developmental Systems","","2019","PP","99","1","1","The scalp electroencephalogram (EEG) based epileptic seizure/non-seizure detection has been comprehensively studied and fruitful achievements have been reported in the past. Yet, few investigation has been paid to the preictal stage detection, which is practically more crucial to epileptics in taking precautions before seizure onset. In this paper, a novel epileptic preictal state classification and seizure detection algorithm based on deep features learned by stacked convolutional neural networks (SCNNs) is developed. The mean amplitude of spectrum map (MAS) obtained from the average subband spectra of multichannel EEGs are adopted for representation. The probability feature vectors by stacked CNNs are extracted in the Softmax layer of CNNs, where an adaptive and discriminative feature weighting fusion (AWF) is developed for performance enhancement. Following the deep extraction layer, the effective kernel extreme learning machine (KELM) is adopted for feature learning and epileptic classification. Experiments on the benchmark CHB-MIT database and a real recorded epileptic database are conducted for performance demonstration. Comparisons to many state-of-the-art epileptic classification methods are provided to show the superiority of the proposed SCNN+AWF algorithm.","","","10.1109/TCDS.2019.2936441","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8807291","Electroencephalogram;Epilepsy;Seizure detection;Preictal state classification;Stacked CNNs.","Feature extraction;Electroencephalography;Databases;Brain modeling;Support vector machines;Signal processing algorithms;Kernel","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Tool Wear Prediction Via Multi-Dimensional Stacked Sparse Autoencoders with Feature Fusion","C. Shi; B. Luo; S. He; K. Li; H. Liu; B. Li","Wuhan, Hubei China 430074 (e-mail: 513864035@qq.com); Sheffield United Kingdom of Great Britain and Northern Ireland S1 3JD (e-mail: b.luo@sheffield.ac.uk); Wuhan China 430074 (e-mail: 8562576@qq.com); Wuhan China 430074 (e-mail: 15527965836@163.com); Wuhan China 430074 (e-mail: liuhongqi328@163.com); Wuhan China 430074 (e-mail: li_bin_hust@163.com)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","Tool wear prediction is of critical importance to maintain the desired part quality and improve productivity. Inspired by the successful application of deep learning in many condition monitoring tasks. A novel modeling framework is presented, which includes multiple stacked sparse autoencoders and a nonlinear regression function for tool wear prediction. Multiple stacked sparse autoencoders consists of two main structures: one model is designed with multi-dimensional stacked sparse autoencoders, which can learn more features from different feature-domains in the raw vibration signal; and another single-dimensional stacked sparse autoencoders is used for feature fusion and deeper features learning. And a modified loss function is applied that improves the learning ability. In addition, due to the good properties of tool wear process in nonstationarity and complex nonlinear, a nonlinear regression function is utilized to enhance the progressive tool wear prediction tasks. A dataset from a real manufacturing process is used to evaluate the performance of the proposed modeling framework. Experimental results show that tool wear can be predicted accurately and stably by the proposed tool wear predictive model, which outperforms the already developed methods.","","","10.1109/TII.2019.2949355","Major special projects in Jiangsu Province of China; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8882336","Tool wear prediction;feature extraction;feature fusion;deep learning;stacked sparse autoencoders","Tools;Feature extraction;Predictive models;Informatics;Vibrations;Ground penetrating radar;Force","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Multi-domain and Multi-modal Representation Disentangler for Cross-Domain Image Manipulation and Classification","F. Yang; J. Chang; C. Tsai; Y. F. Wang","Graduate Institute of Communication Engineering, National Taiwan University, Taiwan.; Graduate Institute of Communication Engineering, National Taiwan University, Taiwan.; Qualcomm Technologies, Inc, San Diego, CA, USA.; Graduate Institute of Communication Engineering, National Taiwan University, Department of Electrical Engineering, National Taiwan University, MOST Joint Research Center for AI Technology and All Vista Healthcare, and ASUS Intelligent Cloud Services, Taiwan.","IEEE Transactions on Image Processing","","2019","PP","99","1","1","Learning interpretable data representation has been an active research topic in deep learning and computer vision. While representation disentanglement is an effective technique for addressing this task, existing works cannot easily handle the problems in which manipulating and recognizing data across multiple domains are desirable. In this paper, we present a unified network architecture of Multi-domain and Multi-modal Representation Disentangler (M2RD), with the goal of learning domain-invariant content representation with the associated domain-specific representation observed. By advancing adversarial learning and disentanglement techniques, the proposed model is able to perform continuous image manipulation across data domains with multiple modalities. More importantly, the resulting domain-invariant feature representation can be applied for unsupervised domain adaptation. Finally, our quantitative and qualitative results would confirm the effectiveness and robustness of the proposed model over state-of-the-art methods on the above tasks.","","","10.1109/TIP.2019.2952707","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8902223","Representation disentanglement;image translation;domain adaptation;deep learning","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Holistic Affect Recognition Using PaNDA: Paralinguistic Non-metric Dimensional Analysis","Y. Zhang; F. Weninger; S. Björn; R. Picard","The Media Laboratory, Massachusetts Institute of Technology, 2167 Cambridge, Massachusetts United States (e-mail: yuefw@mit.edu); R&D, Nuance Communications, 17394 Burlington, Massachusetts United States (e-mail: felix@weninger.de); Computing, Imperial College London, 4615 London, London United Kingdom of Great Britain and Northern Ireland (e-mail: schuller@ieee.org); The Media Laboratory, Massachusetts Institute of Technology, 2167 Cambridge, Massachusetts United States (e-mail: picard@media.mit.edu)","IEEE Transactions on Affective Computing","","2019","PP","99","1","1","Humans perceive emotion from each other using a holistic perspective, accounting for diverse personal, non-emotional variables that shape expression. In contrast, today's algorithms are mainly designed to recognize emotion in isolation. In this work, we propose a multi-task learning approach to jointly learn the recognition of affective states from speech along with various speaker attributes. A problem with multi-task learning is that sometimes inductive transfer can negatively impact performance. To mitigate negative transfer, we introduce the Paralinguistic Non-metric Dimensional Analysis (PaNDA) method that systematically measures task relatedness and also enables visualizing the topology of affective phenomena as a whole. In addition, we present a generic framework that conflates the concepts of single-task and multi-task learning. Using this framework, we construct two models that demonstrate holistic affect recognition: one treats all tasks as equally related, whereas the other one incorporates the task correlations between a main task and its supporting tasks obtained from PaNDA. Both models employ a multi-task deep neural network, in which separate output layers are used to predict discrete and continuous attributes, while hidden layers are shared across different tasks. On average across 18 classification and regression tasks, the weighted multi-task learning with PaNDA significantly improves performance compared to single-task and unweighted multi-task learning.","","","10.1109/TAFFC.2019.2961881","EUs Horizon 2020 research and innovation programme under the Marie Sklodowska-Curie grant agreement HOL-DEEP-SENSE; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8941312","Holistic context;speaker attributes;affective space;task relatedness;multi-task learning","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Video Face Recognition Using Siamese Networks with Block-Sparsity Matching","F. Mokhayeri; E. Granger","Laboratoire d’imagerie, de vision et d’intelligence artificielle (LIVIA), Dept. of Systems Engineering, École de technologie supérieure, Université du Québec, Montreal, Canada.; Laboratoire d’imagerie, de vision et d’intelligence artificielle (LIVIA), Dept. of Systems Engineering, École de technologie supérieure, Université du Québec, Montreal, Canada.","IEEE Transactions on Biometrics, Behavior, and Identity Science","","2019","PP","99","1","1","Deep learning models for still-to-video FR typically provide a low level of accuracy because faces captured in unconstrained videos are matched against a reference gallery comprised of a single facial still per individual. For improved robustness to intra-class variations, deep Siamese networks have recently been used for pair-wise face matching. Although these networks can improve state-of-the-art accuracy, the absence of prior knowledge from the target domain means that many images must be collected to account for all possible capture conditions, which is not practical for many real-world surveillance applications. In this paper, we propose the deep SiamSRC network that employs block-sparsity for face matching, while the reference gallery is augmented with a compact set of domain-specific facial images. Prior to deployment, clustering based on row sparsity is performed on unlabelled faces captured in videos from the target domain. Cluster centers discovered in the capture condition space (defined by, e.g., pose, scale and illumination) are used as rendering parameters with an off-the-shelf 3D face model, and a compact set of synthetic faces are thereby generated for each reference still based on representative intra-class information from the target domain. For pair-wise similarity matching with query facial images, the SiamSRC exploits sparse representation-based classification with a block structure. Experimental results obtained with the videos from the Chokepoint and COX-S2V datasets indicate that the proposed SiamSRC network can outperform state-of-the-art methods for still-to-video FR with a single sample per person, with only a moderate increase in computational complexity.","","","10.1109/TBIOM.2019.2949364","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8883245","Video Surveillance;Face Recognition;Deep Learning;Siamese Networks;Single Sample Per Person Problems;3D Face Synthesis;Block Sparsity;Domain Adaptation.","Face;Feature extraction;Three-dimensional displays;Solid modeling;Training;Face recognition","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Edge-Semantic Learning Strategy for Layout Estimation in Indoor Environment","W. Zhang; W. Zhang; J. Gu","School of Control Science and Engineering, Shandong University, Jinan 250061, China.; School of Control Science and Engineering, Shandong University, Jinan 250061, China (e-mail: davidzhangsdu@gmail.com).; School of Control Science and Engineering, Shandong University, Jinan 250061, China.","IEEE Transactions on Cybernetics","","2019","PP","99","1","10","Visual cognition of the indoor environment can benefit from the spatial layout estimation, which is to represent an indoor scene with a 2-D box on a monocular image. In this paper, we propose to fully exploit the edge and semantic information of a room image for layout estimation. More specifically, we present an encoder-decoder network with shared encoder and two separate decoders, which are composed of multiple deconvolution (transposed convolution) layers, to jointly learn the edge maps and semantic labels of a room image. We combine these two network predictions in a scoring function to evaluate the quality of the layouts, which are generated by ray sampling and from a predefined layout pool. Guided by the scoring function, we apply a novel refinement strategy to further optimize the layout hypotheses. Experimental results show that the proposed network can yield accurate estimates of edge maps and semantic labels. By fully utilizing the two different types of labels, the proposed method achieves the state-of-the-art layout estimation performance on the benchmark datasets.","","","10.1109/TCYB.2019.2895837","National Key Research and Development Plan of China; NSFC; Major Research Program of Shandong Province; Fundamental Research Funds of Shandong University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8648227","Deep neural network;indoor environment;layout estimation;scene understanding;visual cognition","Layout;Semantics;Estimation;Image edge detection;Training;Decoding;Deconvolution","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Max-Plus Approach based Intelligent Coordinated Transmission for Robot Swarms","S. Zhong; Z. Zheng","Faculty of Electrical Engineering and Computer Science, Ningbo University, China.; Faculty of Electrical Engineering and Computer Science, Ningbo University, China.","IEEE Access","","2019","PP","99","1","1","Communication is vital to complete tasks coordinately for robot swarms. In this paper, we investigate massive MIMO enabled robot swarms. Specifically, for the robot swarms, the transceiver beamforming not only needs to maximize the rate, but also has to restrict the interference on other receivers. Therefore, the transceiver design of robots is critical to optimize the sum-rate performance under the restriction of the interference on the a specific robot. Currently, only exhaustive search is able to provide the optimal solution for the problem, whereas its complexity is unacceptable. In this paper, to address the intractable issue, based on the max-plus approach, we consider each transmitter or receiver as an independent decision agent, and all robots coordinately choose the optimal joint beam combination by max-plus algorithm. In the multi-agent framework, each agent learns the policy of choosing analog beam by reinforcement learning (RL). Furthermore, to improve the learning efficiency of RL and reduce the transmission latency, we exploit the efficient ELM network to replace the deep network of deep RL, and propose a ELM-based RL method to conduct the transmission between robots in robot swarm. Analysis and simulation results reveal that, the proposed method is able to achieve a near-optimal sum-rate performance, while the complexity is acceptable.","","","10.1109/ACCESS.2019.2963039","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8945321","robot swarms;multi-agent decision;hybrid precoding;reinforcement learning;extreme learning machine","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Projected Neural Network for a Class of Non-Lipschitz Optimization Problems With Linear Constraints","W. Li; W. Bian; X. Xue","School of Mathematics, Harbin Institute of Technology, Harbin 150001, China.; School of Mathematics, Harbin Institute of Technology, Harbin 150001, China, and also with the Institute of Advanced Study in Mathematics, Harbin Institute of Technology, Harbin 150001, China (e-mail: bianweilvse520@163.com).; School of Mathematics, Harbin Institute of Technology, Harbin 150001, China, and also with the Institute of Advanced Study in Mathematics, Harbin Institute of Technology, Harbin 150001, China.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","13","In this article, we consider a class of nonsmooth, nonconvex, and non-Lipschitz optimization problems, which have wide applications in sparse optimization. We generalize the Clarke stationary point and define a kind of generalized stationary point of the problems with a stronger optimal capability. Based on the smoothing method, we propose a projected neural network for solving this kind of optimization problem. Under the condition that the level set of objective function in the feasible region is bounded, we prove that the solution of the proposed neural network is globally existent and bounded. The uniqueness of the solution of the proposed network is also analyzed. When the feasible region is bounded, any accumulation point of the proposed neural network is a generalized stationary point of the optimization model. Based on some suitable conditions, any solution of the proposed neural network is asymptotic convergent to one stationary point. In particular, we give some deep analysis on the proposed network for solving a special class of the non-Lipschitz optimization problem, which indicates a lower bound property and the unify identification for the nonzero elements of all accumulation points. Finally, some numerical results are presented to show the efficiency of the proposed neural network for solving some kinds of sparse optimization models.","","","10.1109/TNNLS.2019.2944388","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8890010","Generalized stationary point;neural network;non-Lipschitz optimization problem;sparse optimization.","Optimization;Neural networks;Smoothing methods;Numerical models;Linear programming;Mathematical model","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Cross-modal Face Naming for People News Retrieval","Y. Tian; L. Zhou; Y. Zhang; T. Zhang; W. Fan","School of Computer Science, Fudan University, 12478 Shanghai, Shanghai China (e-mail: 16210240084@fudan.edu.cn); School of Computer Science, Fudan University, 12478 Shanghai, Shanghai China (e-mail: 16110240019@fudan.edu.cn); Shanghai Key Laboratory of Intelligent Information Processing, Fudan University, 12478 Shanghai, Shanghai China (e-mail: yjzhang@fudan.edu.cn); School of Information Management and Engineering, Shanghai University of Finance and Economics, 12634 Shanghai, Shanghai China (e-mail: taozhang@mail.shufe.edu.cn); Department of Management Sciences, Tippie College of Business, University of Iowa, Iowa City, Iowa United States (e-mail: weiguo-fan@uiowa.edu)","IEEE Transactions on Knowledge and Data Engineering","","2019","PP","99","1","1","How to integrate multimodal information sources for face naming in multimodal news is a hot and yet challenging problem. A novel deep cross-modal face naming scheme is developed in this paper to facilitate more effective people news retrieval for large-scale multimodal news. This scheme integrates deep multimodal analysis, cross-modal correlation learning and multimodal information mining, in which the efficient naming mechanism aims to cluster the deep features of different modalities into a common space to explore their inter-related correlations, and a special Web mining pattern is designed to optimize the name-face matching for rare non-celebrity. Such a cross-modal face naming model can be treated as a problem of bi-media semantic mapping and modeled as an inter-related correlation distribution over deep representations of multimodal news, in which the most important is to create more effective cross-modal name-face correlation and measure to what degree they are correlated. The experiments on a large number of public data from Yahoo! News have obtained very positive results and demonstrated the effectiveness of the proposed model.","","","10.1109/TKDE.2019.2948875","National Natural Science Foundation of China; Shanghai Municipal RD Foundation; Shanghai Natural Science Foundation; The Henry Tippie Endowed Chair Fund from the University of Iowa; Humanities and Social Sciences Planning Fund of Ministry of Education of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8880535","Clustering;Mining methods and algorithms;Modeling structured;textual and multimedia data;Web Search","Face;Correlation;Semantics;Visualization;Feature extraction;Data mining;Videos","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Video Precoding","E. Bourtsoulatze; A. Chadha; I. Fadeev; V. Giotsas; Y. Andreopoulos","iSIZE Ltd., 3 Falconet Court, 123 Wapping High Street, London, E1W. 3NX, United Kingdom.; iSIZE Ltd., 3 Falconet Court, 123 Wapping High Street, London, E1W. 3NX, United Kingdom.; iSIZE Ltd., 3 Falconet Court, 123 Wapping High Street, London, E1W. 3NX, United Kingdom.; iSIZE Ltd., 3 Falconet Court, 123 Wapping High Street, London, E1W. 3NX, United Kingdom.; iSIZE Ltd., 3 Falconet Court, 123 Wapping High Street, London, E1W. 3NX, United Kingdom.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Several groups worldwide are currently investigating how deep learning may advance the state-of-the-art in image and video coding. An open question is how to make deep neural networks work in conjunction with existing (and upcoming) video codecs, such as MPEG H.264/AVC, H.265/HEVC, VVC, Google VP9 and AOMedia AV1, AV2, as well as existing container and transport formats, without imposing any changes at the client side. Such compatibility is a crucial aspect when it comes to practical deployment, especially when considering the fact that the video content industry and hardware manufacturers are expected to remain committed to supporting these standards for the foreseeable future. We propose to use deep neural networks as precoders for current and future video codecs and adaptive video streaming systems. In our current design, the core precoding component comprises a cascaded structure of downscaling neural networks that operates during video encoding, prior to transmission. This is coupled with a precoding mode selection algorithm for each independently-decodable stream segment, which adjusts the downscaling factor according to scene characteristics, the utilized encoder, and the desired bitrate and encoding configuration. Our framework is compatible with all current and future codec and transport standards, as our deep precoding network structure is trained in conjunction with linear upscaling filters (e.g., the bilinear filter), which are supported by all web video players. Extensive evaluation on FHD (1080p) and UHD (2160p) content and with widely-used H.264/AVC, H.265/HEVC and VP9 encoders, as well as a preliminary evaluation with the current test model of VVC (v.6.2rc1), shows that coupling such standards with the proposed deep video precoding allows for 8% to 52% rate reduction under encoding configurations and bitrates suitable for video-on-demand adaptive streaming systems. The use of precoding can also lead to encoding complexity reduction, which is essential for cost-effective cloud deployment of complex encoders like H.265/HEVC, VP9 and VVC, especially when considering the prominence of high-resolution adaptive video streaming.","","","10.1109/TCSVT.2019.2960084","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933383","video coding;neural networks;downscaling;upscaling;adaptive streaming;DASH/HLS","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Automatically Design Convolutional Neural Networks by Optimization With Submodularity and Supermodularity","W. Hu; J. Jin; T. Liu; C. Zhang","Institute for Artificial Intelligence Tsinghua University (THUAI), State Key Lab of Intelligent Technologies and Systems, Beijing National Research Center for Information Science and Technology (BNRist), Department of Automation, Tsinghua University, Beijing 100084, China.; Institute for Artificial Intelligence Tsinghua University (THUAI), State Key Lab of Intelligent Technologies and Systems, Beijing National Research Center for Information Science and Technology (BNRist), Department of Automation, Tsinghua University, Beijing 100084, China.; Microsoft Research Asia, Beijing 100080, China.; Institute for Artificial Intelligence Tsinghua University (THUAI), State Key Lab of Intelligent Technologies and Systems, Beijing National Research Center for Information Science and Technology (BNRist), Department of Automation, Tsinghua University, Beijing 100084, China (e-mail: zcs@mail.tsinghua.edu.cn).","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","15","The architecture of convolutional neural networks (CNNs) is a key factor of influencing their performance. Although deep CNNs perform well in many difficult problems, how to intelligently design the architecture is still a challenging problem. Focusing on two practical architectural design problems: to maximize the accuracy with a given forward running time and to minimize the forward running time with a given accuracy requirement, we innovatively utilize prior knowledge to convert architecture optimization problems into submodular optimization problems. We propose efficient Greedy algorithms to solve them and give theoretical bounds of our algorithms. Specifically, we employ the techniques on some public data sets and compare our algorithms with some other hyperparameter optimization methods. Experiments show our algorithms' efficiency.","","","10.1109/TNNLS.2019.2939157","National Natural Science Foundation of China; Microsoft Research Asia; Beijing Natural Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8855116","Convolutional neural network (CNN);Greedy algorithm;submodular;supermodular","Optimization;Computer architecture;Kernel;Greedy algorithms;Bayes methods;Neural networks;Meters","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Discriminative Multi-View Subspace Feature Learning for Action Recognition","B. Sheng; J. Li; F. Xiaoc; Q. Li; W. Yang; J. Han","College of Computer, Nanjingifd University of Posts and Telecommunications, Nanjingifd, Jiangsujge, China; Also with Jiangsujge High Technology Research Key Laboratory for Wireless Sensor Networks, Nanjingifd, Jiangsujge, China.; School of Computer Science and Technology, Nanjingifd Normal University, Nanjingifd, Jiangsujge, China.; College of Computer, Nanjingifd University of Posts and Telecommunications, Nanjingifd, Jiangsujge, China; Also with Jiangsujge High Technology Research Key Laboratory for Wireless Sensor Networks, Nanjingifd, Jiangsujge, China.; College of Computer, Nanjingifd University of Posts and Telecommunications, Nanjingifd, Jiangsujge, China; Also with Jiangsujge High Technology Research Key Laboratory for Wireless Sensor Networks, Nanjingifd, Jiangsujge, China.; School of Automation, Southeast University, Nanjingifd, Jiangsujge, China.; School of Automation, Northwestern Polytechnical University, Xian, Shaanxi, China.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Although deep features have achieved the state-of-the-art performance in action recognition recently, the hand-crafted shallow features still play a critical role in characterizing human actions for taking advantage of visual contents in an intuitive way such as edge features. Therefore, the shallow features can serve as auxiliary visual cues supplementary to deep representations. In this paper, we propose a discriminative subspace learning model (DSLM) to explore the complementary properties between the hand-crafted shallow feature representations and the deep features. As for RGB action recognition, this is the first work attempting to mine multi-level feature complementaries by the multi-view subspace learning scheme. To sufficiently capture the complementary information among heterogeneous features, we construct DSLM by integrating the multi-view reconstruction error and classification error into an unified objective function. To be specific, we first use Fisher Vector to encode improved dense trajectories (iDT+FV) for shallow representations and two-stream convolutional neural network models (T-CNN) for generating deep features. Then the presented DSLM algorithm projects multi-level features onto a shared discriminative subspace with the complementary information and discriminating capacity simultaneously incorporated. Finally, the action types of test samples are identified by the margins from the learned compact representations to decision boundary. Experimental results on three datasets demonstrate the effectiveness of the proposed method.","","","10.1109/TCSVT.2019.2918591","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8721146","","Feature extraction;Visualization;Testing;Training;Computational modeling;Task analysis;Data mining","","","","","","","","","","IEEE","IEEE Early Access Articles"
"MAVA: Multi-level Adaptive Visual-textual Alignment by Cross-media Bi-attention Mechanism","Y. Peng; J. Qi; Y. Zhuo","Wangxuan Institute of Computer Technology, Peking University, Beijing 100871, China.; Wangxuan Institute of Computer Technology, Peking University, Beijing 100871, China.; Wangxuan Institute of Computer Technology, Peking University, Beijing 100871, China.","IEEE Transactions on Image Processing","","2019","PP","99","1","1","The rapidly developing information technology leads to a fast growth of visual and textual contents, and it comes with huge challenges to make correlation and perform crossmedia retrieval between images and sentences. Existing methods mainly explore cross-media correlation from either global-level instances as the whole images and sentences, or local-level fine-grained patches as the discriminative image regions and key words, which ignore the complementary information from the relation between local-level fine-grained patches. Naturally, relation understanding is highly important for learning crossmedia correlation. People focus on not only the alignment between discriminative image regions and key words, but also their relations lying in the visual and textual context. Therefore, in this paper, we propose Multi-level Adaptive Visual-textual Alignment (MAVA) approach with the following contributions. First, we propose cross-media multi-pathway fine-grained network to extract not only the local fine-grained patches as discriminative image regions and key words, but also visual relations between image regions as well as textual relations from the context of sentences, which contain complementary information to exploit fine-grained characteristics within different media types. Second, we propose visual-textual bi-attention mechanism to distinguish the fine-grained information with different saliency from both local and relation levels, which can provide more discriminative hints for correlation learning. Third, we propose cross-media multi-level adaptive alignment to explore global, local and relation alignments. An adaptive alignment strategy is further proposed to enhance the matched pairs of different media types, and discard those misalignments adaptively to learn more precise cross-media correlation. Extensive experiments are conducted to perform image-sentence matching on 2 widely-used cross-media datasets, namely Flickr-30K and MS-COCO, comparing with 10 state-of-the-art methods, which can fully verify the effectiveness of our proposed MAVA approach.","","","10.1109/TIP.2019.2952085","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8910611","Cross-media multi-pathway fine-grained network;visual-textual bi-attention mechanism;cross-media multilevel adaptive alignment","Correlation;Visualization;Media;Semantics;Deep learning;Adaptation models;Games","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Pixel-Level Remote Sensing Image Recognition Based on Bidirectional Word Vectors","H. You; S. Tian; L. Yu; Y. Lv","School of Information Science and Engineering, Xinjiang University, Urumqi 830000, China.; Software College, Xinjiang University, Urumqi 830000, China (e-mail: tianshengwei@163.com).; Network Center, Xinjiang University, Urumqi 830000, China.; School of Information Science and Engineering, Xinjiang University, Urumqi 830000, China.","IEEE Transactions on Geoscience and Remote Sensing","","2019","PP","99","1","13","In the traditional remote sensing image recognition, the traditional features (e.g., color features and texture features) cannot fully describe complex images, and the relationships between image pixels cannot be captured well. Using a single model or a traditional sequential joint model, it is easy to lose deep features during feature mining. This article proposes a new feature extraction method that uses the word embedding method from natural language processing to generate bidirectional real dense vectors to reflect the contextual relationships between the pixels. A bidirectional independent recurrent neural network (BiIndRNN) is combined with a convolutional neural network (CNN) to improve the sliced recurrent neural network (SRNN) algorithm model, which is then constructed in parallel with graph convolutional networks (GCNs) under an attention mechanism to fully exploit the deep features of images and to capture the semantic information of the context. This model is collectively named an improved SRNN and attention-treated GCN-based parallel (SAGP) model. Experiments conducted on Populus euphratica forests demonstrate that the proposed method outperforms traditional methods in terms of recognition accuracy. The validation done on public data set also proved it.","","","10.1109/TGRS.2019.2945591","Xinjiang Uygur Autonomous Region Natural Science Fund Project; Xinjiang Autonomous Region Science and Technology Talents Training Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8879704","Attention mechanism;bidirectional independent recurrent neural network (BiIndRNN);bidirectional word vector;graph convolutional networks (GCNs);parallel joint algorithm;sliced recurrent neural network (SRNN).","Feature extraction;Remote sensing;Recurrent neural networks;Image recognition;Semantics;Deep learning;Image color analysis","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Human Detection Aided by Deeply Learned Semantic Masks","X. Wang; C. Shen; H. Li; S. Xu","School of Computer Science, The University of Adelaide, SA 5005, Australia.; School of Computer Science, The University of Adelaide, SA 5005, Australia.; School of Computer and Information Engineering, Jiangxi Normal University, Nanchang 330022, China.; School of Information and Communication Engineering, Shanghai University, Shanghai, 200444, China.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Abstract—Human detection is one of the long-standing computer vision tasks, and it has been a cornerstone for many real-world applications such as photo album organization, video surveillance, and autonomous driving. Benefiting from deep learning technologies such as convolutional neural networks, modern object detectors have been achieving much improved accuracy in generic object detection tasks. In this paper, we aim to improve deep learning based human detection. Our main idea is to exploit semantic context information for human detection by using deep-learnt semantic features provided by semantic segmentation masks. Segmentation masks play as an attention mechanism and enforce the detectors to focus on the image regions where potential object candidates are likely to appear. Meanwhile, the extra segmentation mask channel can also guide the convolutional kernels to automatically learn more discriminative features which make it easier to distinguish the background and foreground. We implement our methods with two popular detection frameworks, i.e., Faster R-CNN and SSD, and experimentally analyze the effectiveness of the proposed methods. Evaluation results on the widely used MS-COCO dataset and the very recent CrowdHuman dataset are provided. Our proposed methods outperform the baseline detectors and achieve better performance on highly occluded human detection.","","","10.1109/TCSVT.2019.2924912","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8746171","Human Detection;Object Detection;Convolutional Neural Network;Fully Convolution Network;Semantic Segmentation;Instance Segmentation","Feature extraction;Image segmentation;Semantics;Detectors;Task analysis;Object detection;Neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A General Decoupled Learning Framework for Parameterized Image Operators","Q. Fan; D. Chen; L. Yuan; G. Hua; N. Yu; B. Chen","Computer Science, Stanford University, 6429 Stanford, California United States (e-mail: fqnchina@gmail.com); Electronic Engineering and Information Science, University of Science and Technology of China, Hefei, Anhui China (e-mail: cd722522@mail.ustc.edu.cn); Microsoft Research Redmond, Microsoft, Redmond, Washington United States (e-mail: luyuan@microsoft.com); Microsoft Research Redmond, Microsoft, Redmond, Washington United States (e-mail: ganghua@microsoft.com); Elec. Engi. & Infor. Sci., Univ. of Sci. & Tech. of China, Information Processing Center, Hefei, Anhui China (e-mail: ynh@ustc.edu.cn); the Center on Frontiers of Computing Studies, School of Electronics Engineering and Computer Science, Peking University, Beijing, Beijing China (e-mail: baoquan.chen@gmail.com)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Many different deep networks have been used to approximate, accelerate or improve traditional image operators. Among these traditional operators, many contain parameters which need to be tweaked to obtain the satisfactory results, which we refer to as ""parameterized image operators"". However, most existing deep networks trained for these operators are only designed for one specific parameter configuration, which does not meet the needs of real scenarios that usually require flexible parameters settings. To overcome this limitation, we propose a new decoupled learning algorithm to learn from the operator parameters to dynamically adjust the weights of a deep network for image operators, denoted as the base network. The learned algorithm is formed as another network, namely the weight learning network, which can be end-to-end jointly trained with the base network. Experiments demonstrate that the proposed framework can be successfully applied to many traditional parameterized image operators. To accelerate the parameter tuning for practical scenarios, the proposed framework can be further extended to dynamically change the weights of only one single layer of the base network while sharing most computation cost. We demonstrate that this cheap parameter-tuning extension of the proposed decoupled learning framework even outperforms the state-of-the-art alternative approaches.","","","10.1109/TPAMI.2019.2925793","National Basic Research Program of China (973 Program); National Natural Science Foundation of China; NSFC-ISF; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8750830","Image Processing and Computer Vision;Filtering;Restoration;Smoothing","Convolution;Task analysis;Image resolution;Acceleration;Image edge detection;Runtime;Fans","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Generative Adversarial Gated Recurrent Unit Model for Precipitation Nowcasting","L. Tian; X. Li; Y. Ye; P. Xie; Y. Li","Department of Computer Science, Harbin Institute of Technology, Shenzhen 518055, China.; Department of Computer Science, Harbin Institute of Technology, Shenzhen 518055, China.; Department of Computer Science, Harbin Institute of Technology, Shenzhen 518055, China (e-mail: yeyunming@hit.edu.cn).; Department of Computer Science, Harbin Institute of Technology, Shenzhen 518055, China.; Department of Computer Science, Shenzhen PolyTechnic, Shenzhen 518055, China.","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","Precipitation nowcasting is an important task in operational weather forecasts. The key challenge of the task is the radar echo map extrapolation. The problem is mainly solved by an optical-flow method in existing systems. However, the method cannot model rapid and nonlinear movements. Recently, a convolutional gated recurrent unit (ConvGRU) method is developed, which aims to model such movements based on deep learning techniques. Despite the promising performance, ConvGRU tends to yield blurring extrapolation images and fails to multi-modal and skewed intensity distribution. To overcome the limitations, we propose in this letter a generative adversarial ConvGRU (GA-ConvGRU) model. The model is composed of two adversarial learning systems, which are a ConvGRU-based generator and a convolution neural network-based discriminator. The two systems are trained by playing a minimax game. With the adversarial learning scheme, GA-ConvGRU can yield more realistic and more accurate extrapolation. Experiments on real data sets have been conducted and the results demonstrate that the proposed GA-ConvGRU significantly outperforms state-of-the-art extrapolation methods ConvGRU and optical flow.","","","10.1109/LGRS.2019.2926776","National Basic Research Program of China (973 Program); Shenzhen Science and Technology Program; NSFC; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8777193","Deep learning;image sequence prediction;nowcasting;radar echo extrapolation.","Generators;Extrapolation;Radar imaging;Image sequences;Optical imaging;Optical network units","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Stacked Bidirectional Convolutional LSTMs for Deriving 3D Non-contrast CT from Spatiotemporal 4D CT","S. C. van de Leemput; M. Prokop; B. van Ginneken; R. Manniesing","Department of Radiology and Nuclear Medicine, Radboud University Medical Center, 6525 GA Nijmegen, The Netherlands.; Department of Radiology and Nuclear Medicine, Radboud University Medical Center, 6525 GA Nijmegen, The Netherlands.; Department of Radiology and Nuclear Medicine, Radboud University Medical Center, 6525 GA Nijmegen, The Netherlands.; Department of Radiology and Nuclear Medicine, Radboud University Medical Center, 6525 GA Nijmegen, The Netherlands.","IEEE Transactions on Medical Imaging","","2019","PP","99","1","1","The imaging workup in acute stroke can be simplified by deriving non-contrast CT (NCCT) from CT perfusion (CTP) images. This results in reduced workup time and radiation dose. To achieve this, we present a stacked bidirectional convolutional LSTM (C-LSTM) network to predict 3D volumes from 4D spatiotemporal data. Several parameterizations of the C-LSTM network were trained on a set of 17 CTP-NCCT pairs to learn to derive a NCCT from CTP and were subsequently quantitatively evaluated on a separate cohort of 16 cases. The results show that the C-LSTM network clearly outperforms the baseline and competitive convolutional neural network methods. We show good scalability and performance of the method by continued training and testing on an independent dataset which includes pathology of 80 and 83 CTP-NCCT pairs, respectively. C-LSTM is, therefore, a promising general deep learning approach to learn from high-dimensional spatiotemporal medical images.","","","10.1109/TMI.2019.2939044","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8822732","Deep Learning;Neural Networks;Long Short-Term Memory;LSTM;Convolutional Neural Network;CNN;Convolutional LSTM;C-LSTM","Three-dimensional displays;Spatiotemporal phenomena;Computed tomography;Convolution;Biomedical imaging;Stroke (medical condition)","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Adversarial Margin Maximization Networks","Z. Yan; Y. Guo; C. Zhang","Automation, Tsinghua University, 12442 Beijing, Beijing China (e-mail: yza18@mails.tsinghua.edu.cn); Bytedance, Bytedance AI Lab, Beijign, Beijing China (e-mail: guoyiwen89@gmail.com); Automation, Tsinghua University, 12442 Beijing, Beijing China (e-mail: zcs@mail.tsinghua.edu.cn)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","The tremendous recent success of deep neural networks (DNNs) has sparked a surge of interest in understanding their predictive ability. Unlike the human visual system which is able to generalize robustly and learn with little supervision, DNNs normally require a massive amount of data to learn new concepts. In addition, research works also show that DNNs are vulnerable to adversarial examples---maliciously generated images which seem perceptually similar to the natural ones but are actually formed to fool learning models, which means the models have problem generalizing to unseen data with certain type of distortions. In this paper, we analyze the generalization ability of DNNs comprehensively and attempt to improve it from a geometric point of view. We propose adversarial margin maximization (AMM), a learning-based regularization which exploits an adversarial perturbation as a proxy. It encourages a large margin in the input space, just like the support vector machines. With a differentiable formulation of the perturbation, we train the regularized DNNs simply through back-propagation in an end-to-end manner. Experimental results on various datasets (including MNIST, CIFAR-10/100, SVHN and ImageNet) and different DNN architectures demonstrate the superiority of our method over previous state-of-the-arts. Code and models for reproducing our results will be made publicly available.","","","10.1109/TPAMI.2019.2948348","Beijing Academy of Artificial Intelligence; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8877866","Large margin classifier;adversarial perturbation;generalization ability;deep neural networks","Perturbation methods;Training;Support vector machines;Distortion;Radio frequency;Robustness;Neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"RNA-Protein Binding Sites Prediction via Multi Scale Convolutional Gated Recurrent Unit Networks","Z. Shen; S. Deng; D. Huang","SEIE, Tongji University, 12476 Shanghai, Shanghai China 200092 (e-mail: zzuliszhen@163.com); Tongji University, Shanghai, Shanghai China (e-mail: dsptk2003@126.com); Computer Science Department, Tongji University, Shanghai, ShangHai China (e-mail: dshuang@tongji.edu.cn)","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2019","PP","99","1","1","RNA-Protein binding plays important roles in the field of gene expression. With the development of high throughput sequencing, several conventional methods and deep learning-based methods have been proposed to predict the binding preference of RNA-protein binding. These methods can hardly meet the need of consideration of the dependencies between subsequence and the various motif lengths of different translation factors (TFs). To overcome such limitations, we propose a predictive model that utilizes a combination of multi-scale convolutional layers and bidirectional gated recurrent unit (GRU) layer. Multi-scale convolution layer has the ability to capture the motif features of different lengths, and bidirectional GRU layer is able to capture the dependencies among subsequence. Experimental results show that the proposed method performs better than four art-of-the-state methods in this field. In addition, we investigate the effect of model structure on model performance by performing our proposed method with different convolution layer and different number of kernel size. We also demonstrate the effectiveness of bidirectional GRU in improving model performance through comparative experiments.","","","10.1109/TCBB.2019.2910513","China Postdoctoral Science Foundation; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8686117","Character Embedding;Multi-scale convolutional layer;Bidirectional GRU;Translation Factor;RNA-Protein binding site","Convolution;RNA;Logic gates;Kernel;Deep learning;Predictive models;Computational modeling","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Effects of Image Degradation and Degradation Removal to CNN-based Image Classification","Y. Pei; Y. Huang; Q. Zou; X. Zhang; S. Wang","School of Computer and Information Technology and Beijing Key Laboratory of Traffic Data Analysis and Mining, Beijing Jiaotong University, 47829 Beijing, Beijing China (e-mail: yantingpei@bjtu.edu.cn); School of Computer and Information Technology and Beijing Key Laboratory of Traffic Data Analysis and Mining, Beijing Jiaotong University, 47829 Beijing, Beijing China (e-mail: yphuang@bjtu.edu.cn); School of Computer and Information Technology and Beijing Key Laboratory of Traffic Data Analysis and Mining, Beijing Jiaotong University, 47829 Beijing, Beijing China (e-mail: qzou@bjtu.edu.cn); School of Computer and Information Technology and Beijing Key Laboratory of Traffic Data Analysis and Mining, Beijing Jiaotong University, 47829 Beijing, Beijing China (e-mail: 15112071@bjtu.edu.cn); College of Intelligence and Computing, Tianjin University, 12605 Tianjin, Tianjin China (e-mail: songwang@cec.sc.edu)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Just like many other topics in computer vision, image classification has achieved significant progress recently by using deep learning neural networks, especially the Convolutional Neural Networks (CNNs). Most of the existing works focused on classifying very clear natural images, evidenced by the widely used image databases such as Caltech-256, PASCAL VOCs and ImageNet. However, in many real applications, the acquired images may contain certain degradations that lead to various kinds of blurring, noise, and distortions. One important and interesting problem is the effect of such degradations to the performance of CNN-based image classification and whether degradation removal helps CNN-based image classification. More specifically, we wonder whether image classification performance drops with each kind of degradation, whether this drop can be avoided by including degraded images into training, and whether existing computer vision algorithms that attempt to remove such degradations can help improve the image classification performance. In this paper, we empirically study those problems for nine kinds of degraded images - hazy images, motion-blurred images, fish-eye images, underwater images, low resolution images, salt-and-peppered images, images with white Gaussian noise, Gaussian-blurred images and out-of-focus images. We expect this work can draw more interests from the community to study the classification of degraded images.","","","10.1109/TPAMI.2019.2950923","Fundamental Research Funds for the Central Universities; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8889765","Image classification;image degradation;degradation removal;CNN","Degradation;Cameras;Image resolution;Image recognition;Training;Computer vision;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"APDC-Net: Attention Pooling-Based Convolutional Network for Aerial Scene Classification","Q. Bi; K. Qin; H. Zhang; J. Xie; Z. Li; K. Xu","School of Remote Sensing and Information Engineering, Wuhan University, Wuhan 430079, China.; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan 430079, China (e-mail: qink@whu.edu.cn).; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan 430079, China.; School of Geography and Information Engineering, China University of Geosciences, Wuhan 430074, China.; School of Geography and Information Engineering, China University of Geosciences, Wuhan 430074, China.; School of Geography and Information Engineering, China University of Geosciences, Wuhan 430074, China.","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","Deep learning methods have boosted the performance of a series of visual tasks. However, the aerial image scene classification remains challenging. The object distribution and spatial arrangement in aerial scenes are often more complicated than in natural image scenes. Possible solutions include highlighting local semantics relevant to the scene label and preserving more discriminative features. To tackle this challenge, in this letter, we propose an attention pooling-based dense connected convolutional network (APDC-Net) for aerial scene classification. First, it uses a simplified dense connection structure as the backbone to preserve features from different levels. Then, we propose a trainable pooling to down-sample the feature maps and to enhance the local semantic representation capability. Finally, we introduce a multi-level supervision strategy, so that features from different levels are all allowed to supervise the training process directly. Exhaustive experiments on three aerial scene classification benchmarks demonstrate that our proposed APDC-Net outperforms other state-of-the-art methods with much fewer parameters and validate the effectiveness of our attention-based pooling and multi-level supervision strategy.","","","10.1109/LGRS.2019.2949930","National Basic Research Program of China (973 Program); National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8892506","Aerial image;attention-based pooling;convolutional neural network;dense connection;multi-level supervision;scene classification.","Training;Semantics;Feature extraction;Deep learning;Task analysis;Benchmark testing;Probability distribution","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Nei-TTE: Intelligent Traffic Time Estimation Based on Fine-grained Time Derivation of Road Segments for Smart City","J. Qiu; L. Du; D. Zhang; S. Su; Z. Tian","Cyberspace Institute of Advanced Technology, Guangzhou China 510006 (e-mail: qiujing.ch@gmail.com); Hebei University of Science and Technology, 83524 Shijiazhuang, Hebei China 050018 (e-mail: leidu_close@163.com); Hebei University of Science and Technology, 83524 Shijiazhuang, Hebei China 050018 (e-mail: zdwwtx@hebust.edu.cn); Guangzhou China 510006 (e-mail: johnsuhit@gmail.com); Guangzhou China 510006 (e-mail: tianzhihong@gzhu.edu.cn)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","With the development of the Internet of Things (IoT) and big data technology, the intelligent transportation system is becoming the main development direction of future transportation systems. The time required for a given path in a transportation system can be accurately estimated using the trajectory data of the taxis in a city. This is a very challenging task. Although historical data has been used in existing research, excessive use of trace information in historical data or inaccurate neighbor trajectory information does not allow for better prediction accuracy of the query path. We propose a deep learning method based on neighbors for travel time estimation (TTE), called the Nei-TTE method. We divide the entire path into multiple disjoint segments and use the historical trajectory data approximated at the time level. Our model captures the characteristics of each segment and utilizes the trajectory characteristics of adjacent segments as the road network topology and speed interact. We use velocity features to effectively represent adjacent segment structures. The experiments on the Porto dataset show that the experimental results of our model are significantly better than those of the existing models.","","","10.1109/TII.2019.2943906","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8850027","Intelligent transportation systems;travel time estimation;trajectories;GRU;time series","Trajectory;Roads;Network topology;Topology;Public transportation;Smart cities;Deep learning","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"DNNVM: End-to-End Compiler Leveraging Heterogeneous Optimizations on FPGA-based CNN Accelerators","Y. Xing; S. Liang; L. Sui; X. Jia; J. Qiu; X. Liu; Y. Wang; Y. Shan; Y. Wang","Xilinx, Beijing 100083, China, also with the Department of Electronic Engineering, Tsinghua National Laboratory for Information Science and Technology, Tsinghua University, Beijing 100084, China, and also with Beijing National Research Center for Information Science and Technology (BNRist).; Department of Electronic Engineering, Tsinghua National Laboratory for Information Science and Technology, Tsinghua University, Beijing 100084, China, and also with the Beijing National Research Center for Information Science and Technology (BNRist).; Xilinx, Beijing 100083, China.; Xilinx, Beijing 100083, China.; Department of Electronic Engineering, Tsinghua National Laboratory for Information Science and Technology, Tsinghua University, Beijing 100084, China, and also with the Beijing National Research Center for Information Science and Technology (BNRist).; Xilinx, Beijing 100083, China.; Xilinx, Beijing 100083, China.; Xilinx, Beijing 100083, China.; Department of Electronic Engineering, Tsinghua National Laboratory for Information Science and Technology, Tsinghua University, Beijing 100084, China, and also with the Beijing National Research Center for Information Science and Technology (BNRist).","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","","2019","PP","99","1","1","The convolutional neural network (CNN) has become a state-of-the-art method for several artificial intelligence domains in recent years. The increasingly complex CNN models are both computation-bound and I/O-bound. FPGA-based accelerators driven by custom instruction set architecture (ISA) achieve a balance between generality and efficiency, but there is much on them left to be optimized. We propose the full-stack compiler DNNVM, which is an integration of optimizers for graphs, loops and data layouts, and an assembler, a runtime supporter and a validation environment. The DNNVM works in the context of deep learning frameworks and transforms CNN models into the directed acyclic graph: XGraph. Based on XGraph, we transform the optimization challenges for both the data layout and pipeline into graph-level problems. DNNVM enumerates all potentially profitable fusion opportunities by a heuristic subgraph isomorphism algorithm to leverage pipeline and data layout optimizations, and searches for the best choice of execution strategies of the whole computing graph. On the Xilinx ZU2 @330 MHz and ZU9 @330 MHz, we achieve equivalently state-of-the-art performance on our benchmarks by naïve implementations without optimizations, and the throughput is further improved up to 1.26x by leveraging heterogeneous optimizations in DNNVM. Finally, with ZU9 @330 MHz, we achieve state-of-the-art performance for VGG and ResNet50. We achieve a throughput of 2.82 TOPs/s and an energy efficiency of 123.7 GOPs/s/W for VGG. Additionally, we achieve 1.38 TOPs/s for ResNet50 and 1.41 TOPs/s for GoogleNet.","","","10.1109/TCAD.2019.2930577","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8770305","FPGA;convolutional neural network;compiler;fusion;optimizations.","Hardware;Optimization;Layout;Field programmable gate arrays;Throughput;Computer architecture;Deep learning","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Palmprint Recognition in Uncontrolled and Uncooperative Environment","W. M. Matkowski; T. Chai; A. W. K. Kong","School of Computer Science and Engineering, Nanyang Technological University, Singapore, 639798.; Institute of Information Science, Beijing Jiaotong University, Beijing, 100044, P.R. China.; School of Computer Science and Engineering, Nanyang Technological University, Singapore, 639798.","IEEE Transactions on Information Forensics and Security","","2019","PP","99","1","1","Online palmprint recognition and latent palmprint identification are two branches of palmprint studies. The former uses middle-resolution images collected by a digital camera in a well-controlled or contact-based environment with user cooperation for commercial applications and the latter uses high-resolution latent palmprints collected in crime scenes for forensic investigation. However, these two branches do not cover some palmprint images which have the potential for forensic investigation. Due to the prevalence of smartphone and consumer camera, more evidence is in the form of digital images taken in uncontrolled and uncooperative environment, e.g., child pornographic images and terrorist images, where the criminals commonly hide or cover their face. However, their palms can be observable. To study palmprint identification on images collected in uncontrolled and uncooperative environment, a new palmprint database is established and an end-to-end deep learning algorithm is proposed. The new database named NTU Palmprints from the Internet (NTU-PI-v1) contains 7881 images from 2035 palms collected from the Internet. The proposed algorithm consists of an alignment network and a feature extraction network and is end-to-end trainable. The proposed algorithm is compared with the state-of-the-art online palmprint recognition methods and evaluated on three public contactless palmprint databases, IITD, CASIA, and PolyU and two new databases, NTU-PI-v1 and NTU contactless palmprint database. The experimental results showed that the proposed algorithm outperforms the existing palmprint recognition methods.","","","10.1109/TIFS.2019.2945183","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8854829","Biometrics;criminal and victim identification;forensics;palmprint recognition","Palmprint recognition;Databases;Feature extraction;Deep learning;Forensics;Face","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Neural Diffusion Model for Microscopic Cascade Study","C. Yang; M. Sun; H. Liu; S. Han; Z. Liu; H. Luan","School of Computer Science, Beijing University of Posts and Telecommunications, 12472 Beijing, Beijing China (e-mail: albertyang33@gmail.com); Department of Computer Science and Technology, Tsinghua University, Beijing, Beijing China (e-mail: sms@mail.tsinghua.edu.cn); Electric Engineering, Tsinghua University, 12442 Beijing, Beijing China (e-mail: liu-hr15@mails.tsinghua.edu.cn); Computer Science, Brown University, Providence, Rhode Island United States (e-mail: hanshiyi123@gmail.com); Computer Science and Technology, Tsinghua University, Beijing, Beijing China 100084 (e-mail: liuzy@tsinghua.edu.cn); Department of Computer Science and Technology, Tsinghua University, Beijing, Beijing China (e-mail: luanhuanbo@gmail.com)","IEEE Transactions on Knowledge and Data Engineering","","2019","PP","99","1","1","The study of information diffusion or cascade has attracted much attention over the last decade. Most related works target on studying cascade-level macroscopic properties such as the final size of a cascade. Existing microscopic cascade models which focus on user-level modeling either make strong assumptions on how a user gets infected by a cascade or limit themselves to a specific scenario where ""who infected whom"" information is explicitly labeled. The strong assumptions oversimplify the complex diffusion mechanism and prevent these models from better fitting real-world cascade data. Also, the methods which focus on specific scenarios cannot be generalized to a general setting where the diffusion graph is unobserved. To overcome the drawbacks of previous works, we propose a Neural Diffusion Model for general microscopic cascade study. NDM makes relaxed assumptions and employs deep learning techniques including attention mechanism and convolutional network for modeling. Both advantages enable our model to go beyond the limitations of previous methods, better fit the diffusion data and generalize to unseen cascades. Experimental results on diffusion identification task over four realistic cascade datasets show that our model can achieve a relative improvement up to 26% against the best performing baseline in terms of F1 score.","","","10.1109/TKDE.2019.2939796","National Basic Research Program of China (973 Program); National Natural Science Foundation of China; Major Project of the National Social Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8826231","Information Diffusion;Neural Network","Microscopy;Integrated circuit modeling;Task analysis;Data models;Deep learning;Twitter","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Multi-Task Convolutional Neural Network with Information Fusion for Bearing Fault Diagnosis and Localization","S. Guo; B. Zhang; T. Yang; D. Lyu; W. Gao","School of Energy and Power Engineering, Huazhong University of Science and Technology, Wuhan, Hubei China 430074 (e-mail: levykwok@hust.edu.cn); Department of Electrical Engineering, The University of South Carolina, Columbia, South Carolina United States 29210 (e-mail: zhangbin@cec.sc.edu); School of Energy and Power Engineering, Huazhong University of Science and Technology, 12443 Wuhan, Hubei China (e-mail: hust_yt@hust.edu.cn); School of Energy and Power Engineering, Huazhong University of Science and Technology, Wuhan, Hubei China (e-mail: lvdongzhen@yeah.net); School of Energy and Power Engineering, Huazhong University of Science and Technology, Wuhan, Hubei China (e-mail: gw@hust.edu.cn)","IEEE Transactions on Industrial Electronics","","2019","PP","99","1","1","Accurate fault information is critical for optimal scheduling of production activities, improving system reliability, and reducing operation and maintenance cost. In recent years, many fault diagnosis methods for rolling element bearings have been developed based on deep learning. Most of them are totally data-driven and do not consider the domain knowledge that has been used in fault diagnosis for years. Meanwhile, operating conditions such as rotating speed and load that have great influence on vibration signals are also ignored. It may cause a decrease in accuracy when bearing type or operating condition changes. To address these problems, this paper proposes a rolling element bearing fault diagnosis and localization approach based on multi-task convolutional neural network (CNN) with information fusion. In the proposed approach, domain knowledge, operating conditions, and vibration signals are fused into a 3-dimensional input that can be processed well by CNN. Then a multi-task CNN with dynamic training rates is constructed to simultaneously accomplish two tasks, fault diagnosis and localization. Experimental results on two rolling element bearing testbeds with different bearing types and operating conditions are presented and compared with existing state-of-the-art approaches to demonstrate the effectiveness and accuracy of the proposed approach.","","","10.1109/TIE.2019.2942548","Chinese National Science and Technology Support Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8848851","fault diagnosis;rolling element bearing;convolutional neural network;information fusion;domain knowledge","Fault diagnosis;Deep learning;Vibrations;Continuous wavelet transforms;Training;Rolling bearings","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Joint Depth Estimation and Color Correction from Monocular Underwater Images based on Unsupervised Adaptation Networks","X. Ye; Z. Li; B. Sun; Z. Wang; R. Xu; H. Li; X. Fan","DUT-RU International School of Information Science & Engineering, Dalian University of Technology, Liaoning and Key Laboratory for Ubiquitous Network and Service Software of Liaoning Province, China.; DUT-RU International School of Information Science & Engineering, Dalian University of Technology, Liaoning and Key Laboratory for Ubiquitous Network and Service Software of Liaoning Province, China.; DUT-RU International School of Information Science & Engineering, Dalian University of Technology, Liaoning and Key Laboratory for Ubiquitous Network and Service Software of Liaoning Province, China.; DUT-RU International School of Information Science & Engineering, Dalian University of Technology, Liaoning and Key Laboratory for Ubiquitous Network and Service Software of Liaoning Province, China.; DUT-RU International School of Information Science & Engineering, Dalian University of Technology, Liaoning and Key Laboratory for Ubiquitous Network and Service Software of Liaoning Province, China.; DUT-RU International School of Information Science & Engineering, Dalian University of Technology, Liaoning and Key Laboratory for Ubiquitous Network and Service Software of Liaoning Province, China.; DUT-RU International School of Information Science & Engineering, Dalian University of Technology, Liaoning and Key Laboratory for Ubiquitous Network and Service Software of Liaoning Province, China.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Degraded visibility and geometrical distortion typically make the underwater vision more intractable than open air vision, which impedes the development of underwater-related machine vision and robotic perception. Therefore, this paper addresses the problem of joint underwater depth estimation and color correction from monocular underwater images, which aims at enjoying the mutual benefits between these two related tasks from a multi-task perspective. Our core ideas lie in our new deep learning architecture. Due to the lack of effective underwater training data, and the weak generalization to the real-world underwater images trained on synthetic data, we consider the problem from a novel perspective of style-level and feature-level adaptation, and propose an unsupervised adaptation network to deal with the joint learning problem. Specifically, a style adaptation network (SAN) is first proposed to learn a style-level transformation to adapt in-air images to the style of underwater domain. Then, we formulate a task network (TN) to jointly estimate the scene depth and correct the color from a single underwater image by learning domain-invariant representations. The whole framework can be trained end-to-end in an adversarial learning manner. Extensive experiments are conducted under air-to-water domain adaptation settings. We show that the proposed method performs favorably against state-of-the-art methods in both depth estimation and color correction tasks.","","","10.1109/TCSVT.2019.2958950","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8932601","Underwater Image;Depth estimation;color correction;unsupervised;domain adapatation","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Multimodal Image Super-resolution via Joint Sparse Representations induced by Coupled Dictionaries","P. Song; X. Deng; J. F. C. Mota; N. Deligiannis; P. Dragotti; M. Rodrigues","Department of Electronic and Electrical Engineering, University College London, London WC1E 6BT United Kingdom of Great Britain and Northern Ireland (e-mail: pingfan.song.14@ucl.ac.uk); Department of Electrical and Electronic Engineering, Imperial College London, 4615 London, London United Kingdom of Great Britain and Northern Ireland SW7 2AZ (e-mail: x.deng16@imperial.ac.uk); Department of School of Engineering \& Physical Sciences, Heriot-Watt University, 3120 Edinburgh EH14 4AS United Kingdom of Great Britain and Northern Ireland (e-mail: j.mota@hw.ac.uk); Electronics and Informatics, Vrije Universiteit Brussel, 70493 Brussel Belgium (e-mail: ndeligia@etrovub.be); Electrical and Electronic Engineering, Imperial College, London, London United Kingdom of Great Britain and Northern Ireland (e-mail: p.dragotti@ieee.org); Department of Electronic and Electrical Engineering, University College London, London United Kingdom of Great Britain and Northern Ireland WC1E 7JE (e-mail: m.rodrigues@ucl.ac.uk)","IEEE Transactions on Computational Imaging","","2019","PP","99","1","1","Real-world data processing problems often involve various image modalities associated with a certain scene, including RGB images, infrared images or multi-spectral images. The fact that different image modalities often share certain attributes, such as edges, textures and other structure primitives, represents an opportunity to enhance various image processing tasks. This paper proposes a new approach to construct a high-resolution (HR) version of a low-resolution (LR) image given another HR image modality as guidance, based on joint sparse representations induced by coupled dictionaries. The proposed approach captures complex dependency correlations, including similarities and disparities, between different image modalities in a learned sparse feature domain in lieu of the original image domain. It consists of two phases: coupled dictionary learning phase and coupled super-resolution phase. The learning phase learns a set of dictionaries from the training dataset to couple different image modalities together in the sparse feature domain. In turn, the super-resolution phase leverages such dictionaries to construct a HR version of the LR target image with another related image modality for guidance. In the advanced version of our approach, multi-stage strategy and neighbourhood regression concept are introduced to further improve the model capacity and performance. Extensive guided image super-resolution experiments on real multimodal images demonstrate that the proposed approach admits distinctive advantages with respect to the state-of-the-art approaches, for example, overcoming the texture copying artifacts commonly resulting from inconsistency between the guidance and target images. Of particular relevance, the proposed model demonstrates much better robustness than competing deep models in a range of noisy scenarios.","","","10.1109/TCI.2019.2916502","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8715417","Multimodal image super-resolution;coupled dictionary learning;joint sparse representation;side information","Image resolution;Dictionaries;Machine learning;Training;Image edge detection;Data models;Signal resolution","","","","2","","","","","","IEEE","IEEE Early Access Articles"
"Proximal Parameter Distribution Optimization","X. Wang; T. Li; Y. Cheng","Xuzhou Key Laboratory of Artificial Intelligence and Big Data, School of Information and Control Engineering, China University of Mining and Technology, Xuzhou 221116, China.; Xuzhou Key Laboratory of Artificial Intelligence and Big Data, School of Information and Control Engineering, China University of Mining and Technology, Xuzhou 221116, China.; Xuzhou Key Laboratory of Artificial Intelligence and Big Data, School of Information and Control Engineering, China University of Mining and Technology, Xuzhou 221116, China (e-mail: chengyuhu@163.com).","IEEE Transactions on Systems, Man, and Cybernetics: Systems","","2019","PP","99","1","10","Encouraging the agent to explore has become a hot topic in the field of reinforcement learning (RL). The popular approaches to engage in exploration are mainly by injecting noise into neural network (NN) parameters or by augmenting additional intrinsic motivation term. However, the randomness of injecting noise and the metric for intrinsic reward must be chosen manually may make RL agents deviate from the optimal policy during the learning process. To enhance the exploration ability of agent and simultaneously ensure the stability of parameter learning, we proposed a novel proximal parameter distribution optimization (PPDO) algorithm. On the one hand, PPDO enhances the exploration ability of RL agent by transforming NN parameter from a certain single value to a function distribution. On the other hand, PPDO accelerates the parameter distribution optimization by setting two groups of parameters. The parameter optimization is guided by evaluating the parameter quality change before and after the parameter distribution update. In addition, PPDO reduces the influence of bias and variance on the value function approximation by limiting the amplitude of the two consecutive parameter updates, which can enhance the stability of the parameter distribution optimization. Experiments on the OpenAI Gym, Atari, and MuJoCo platforms indicate that PPDO can improve the exploration ability and learning efficiency of deep RL algorithms, including DQN and A3C.","","","10.1109/TSMC.2019.2931946","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8820176","Exploration;optimization;parameter distribution;reinforcement learning (RL)","Optimization;Task analysis;Artificial neural networks;Noise measurement;Uncertainty;Reinforcement learning;Acceleration","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Dual Adversarial Autoencoders for Clustering","P. Ge; C. Ren; D. Dai; J. Feng; S. Yan","Intelligent Data Center, School of Mathematics, Sun Yat-sen University, Guangzhou 510275, China.; Intelligent Data Center, School of Mathematics, Sun Yat-sen University, Guangzhou 510275, China (e-mail: rchuanx@mail.sysu.edu.cn).; Intelligent Data Center, School of Mathematics, Sun Yat-sen University, Guangzhou 510275, China.; Department of Electrical and Computer Engineering, National University of Singapore, Singapore.; Department of Electrical and Computer Engineering, National University of Singapore, Singapore.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","8","As a powerful approach for exploratory data analysis, unsupervised clustering is a fundamental task in computer vision and pattern recognition. Many clustering algorithms have been developed, but most of them perform unsatisfactorily on the data with complex structures. Recently, adversarial autoencoder (AE) (AAE) shows effectiveness on tackling such data by combining AE and adversarial training, but it cannot effectively extract classification information from the unlabeled data. In this brief, we propose dual AAE (Dual-AAE) which simultaneously maximizes the likelihood function and mutual information between observed examples and a subset of latent variables. By performing variational inference on the objective function of Dual-AAE, we derive a new reconstruction loss which can be optimized by training a pair of AEs. Moreover, to avoid mode collapse, we introduce the clustering regularization term for the category variable. Experiments on four benchmarks show that Dual-AAE achieves superior performance over state-of-the-art clustering methods. In addition, by adding a reject option, the clustering accuracy of Dual-AAE can reach that of supervised CNN algorithms. Dual-AAE can also be used for disentangling style and content of images without using supervised information.","","","10.1109/TNNLS.2019.2919948","National Natural Science Foundation of China; Science and Technology Program of Guangzhou; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8742794","AAE;clustering;deep generative models;latent variable;mutual information regularization.","Mutual information;Training;Clustering methods;Clustering algorithms;Gallium nitride;Generative adversarial networks;Task analysis","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Probabilistic Neural Network With Complex Exponential Activation Functions in Image Recognition","A. V. Savchenko","National Research University Higher School of Economics, Laboratory of Algorithms and Technologies for Network Analysis, Nizhny Novgorod 603155, Russia (e-mail: avsavchenko@hse.ru).","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","10","If the training data set in image recognition task is not very large, the feature extraction with a convolutional neural network is usually applied. Here, we focus on the nonparametric classification of extracted feature vectors using the probabilistic neural network (PNN). The latter is characterized by the high runtime and memory space complexity. We propose to overcome these drawbacks by replacing the exponential activation function in the Gaussian kernel to the complex exponential functions. Such complex nonlinearities make it possible to accurately approximate the unknown density function using the network with the number of neurons proportional to only cubic root of the database size. As a result, the proposed approach decreases the runtime and memory complexities of the PNN without losing its main advantages, namely, fast training and convergence to the Bayesian decision. In the experimental study, we describe a protocol for comparing recognition methods using the well-known visual object category data sets in the context of the small sample size problem. It has been experimentally shown that our approach rapidly obtains accurate decisions when compared to the known classifiers including the baseline PNN.","","","10.1109/TNNLS.2019.2908973","National Research University Higher School of Economics HSE within the framework of Basic Research Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8700611","Complex exponential activation functions;deep neural networks;image recognition;orthogonal series kernel;probabilistic neural network (PNN).","Training;Kernel;Image recognition;Task analysis;Feature extraction;Complexity theory;Biological neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Trusted Cloud-Edge Network Resource Management: DRL-driven Service Function Chain Orchestration for IoT","S. Guo; Y. Dai; S. Xu; X. Qiu; F. Qi","State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing 100876, China.; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing 100876, China.; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing 100876, China.; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing 100876, China.; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing 100876, China, and also with the Cyberspace Security Research Center, Peng Cheng Laboratory, Shenzhen, China.","IEEE Internet of Things Journal","","2019","PP","99","1","1","Private and public networks sharing resources for IoT network through Network Function Virtualization (NFV) and Software-Defined-Networking (SDN) forms a heterogeneous cloud-edge environment. However, the heterogeneous cloud-edge network faces trust and adaptation issues in resource allocation. To address these two problems, we introduce consortium blockchain and Deep Reinforcement Learning (DRL) to construct the trusted and auto-adjust Service Function Chain (SFC) orchestration architecture. In the architecture, this paper integrates consortium blockchain into the distributed SFC orchestration model to realize trusted resource sharing. In addition, for realizing auto-adjusted service provision, the paper designs a Dynamic Hierarchical SFC Orchestration Algorithm (DHSOA) based on DRL to minimize orchestration cost and improve the QoS. Moreover, considering dynamics of network entities, the paper proposes a time-slotted model to support dynamic service migration which adapts to high-mobility IoT network. Simulation results show that DHSOA has better performance than link-state routing algorithm and deep Q-network placement algorithm not only in cost saving of 15.8% and 10.1% but also in time saving of 22.0% and 10.0%.","","","10.1109/JIOT.2019.2951593","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8891803","IoT;trusted cloud-edge network;SFC orchestration;blockchain;deep reinforcement learning.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Multi-Sensor Time-Series Classification for Activity Tracking Under Variable Length","S. Norgaard; R. Saeedi; A. H. Gebremedhin","School of Electrical Engineering and Computer Science, Washington State University, Pullman, WA, 99164 USA.; School of Electrical Engineering and Computer Science, Washington State University, Pullman, WA, 99164 USA.; School of Electrical Engineering and Computer Science, Washington State University, Pullman, WA, 99164 USA.","IEEE Sensors Journal","","2019","PP","99","1","1","Recent advances in mobile devices, wearable sensors and data analytics are enabling greater adoption of remote health monitoring systems, where human activity recognition (HAR) plays a key role. Most HAR systems assume that consecutive data segments are independent and aim at accurately classifying each individual data segment. However, because training and operating contexts are often different, and collecting labels can be time-consuming and expensive, the recognition accuracy is typically considerably lower in the new (operating) context. In this paper, we propose a framework for HAR that has several unique capabilities: 1) Turns predictions into useful information (e.g. daily distribution of activities for a user) that could be assessed by a clinician or health professional. Our goal is to mitigate the effects of variation between a training and an operating context. 2) Leverages the dependence between consecutive data samples to perform robust activity recognition. And 3) Performs activity classification for variable length set of activities. The framework we present encompasses two main modules. The first is a Recurrent Long Short-Term Memory deep neural network, the core component which gives us the capability to capture the dependence between consecutive sensor data samples and generate labels for every micro segment. The second is a post-processing step performed for uncertainty filtering and label smoothing of decisions. The filtering method enables the system to recognize activities in the presence of difference in the training and testing data distributions, and the smoothing method makes the system properly capture the distribution of activities. We demonstrate that our deep learning architecture can achieve 90% accuracy in standard training scenarios. Furthermore, we show that, in the case of inter-subject variation, the two methods allow us to still accurately capture the distribution of activities.","","","10.1109/JSEN.2019.2953938","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8903306","Sensors;Mobile Health Monitoring;Wearables;Deep Learning;LSTMs;Time Series;Human Activity Recognition;Accelerometer","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Image and Video Compression with Neural Networks: A Review","S. Ma; X. Zhang; C. Jia; Z. Zhao; S. Wang; S. Wanga","Institute of Digital Media, School of Electronic Engineering and Computer Science, Peking University, Beijing 100871, China and Peng Cheng Lab, Shenzhen, China. (e-mail: swma@pku.edu.cn); Department of Computer Science, University of Chinese Academy of Sciences, Beijing 100049, China.; Institute of Digital Media, School of Electronic Engineering and Computer Science, Peking University, Beijing 100871, China and Peng Cheng Lab, Shenzhen, China.; Institute of Digital Media, School of Electronic Engineering and Computer Science, Peking University, Beijing 100871, China and Peng Cheng Lab, Shenzhen, China.; Department of Computer Science, City University of Hong Kong, Kowloon, Hong Kong.; Institute of Digital Media, School of Electronic Engineering and Computer Science, Peking University, Beijing 100871, China and Peng Cheng Lab, Shenzhen, China.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","In recent years, the image and video coding technologies have advanced by leaps and bounds. However, due to the popularization of image and video acquisition devices, the growth rate of image and video data is far beyond the improvement of the compression ratio. In particular, it has been widely recognized that there are increasing challenges of pursuing further coding performance improvement within the traditional hybrid coding framework. Deep convolution neural network (CNN) which makes the neural network resurge in recent years and has achieved great success in both artificial intelligent and signal processing fields, also provides a novel and promising solution for image and video compression. In this paper, we provide a systematic, comprehensive and up-to-date review of neural network based image and video compression techniques. The evolution and development of neural network based compression methodologies are introduced for images and video respectively. More specifically, the cutting-edge video coding techniques by leveraging deep learning and HEVC framework are presented and discussed, which promote the state-of-the-art video coding performance substantially. Moreover, the end-to-end image and video coding frameworks based on neural networks are also reviewed, revealing interesting explorations on next generation image and video coding frameworks/standards. The most significant research works on the image and video coding related topics using neural networks are highlighted, and future trends are also envisioned. In particular, the joint compression on semantic and visual information is tentatively explored to formulate high efficiency signal representation structure for both human vision and machine vision, which are the two dominant signal receptor in the age of artificial intelligence.","","","10.1109/TCSVT.2019.2910119","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8693636","Neural network;deep learning;CNN;image compression;video coding","","","","","2","","","","","","IEEE","IEEE Early Access Articles"
"Pixel Transposed Convolutional Networks","H. Gao; H. Yuan; Z. Wang; S. Ji","School of Electrical Engineering & Computer Science, Washington State University, Pullman, Washington United States (e-mail: hongyang.gao@tamu.edu); School of Electrical Engineering & Computer Science, Washington State University, Pullman, Washington United States (e-mail: hao.yuan@wsu.edu); School of Electrical Engineering & Computer Science, Washington State University, Pullman, Washington United States (e-mail: zhengyang.wang@tamu.edu); School of Electrical Engineering & Computer Science, Washington State University, Pullman, Washington United States 99164 (e-mail: shuiwang.ji@gmail.com)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Transposed convolutional layers have been widely used in a variety of deep models for up-sampling, including encoder-decoder networks for semantic segmentation and deep generative models for unsupervised learning. One of the key limitations of transposed convolutional operations is that they result in the so-called checkerboard problem. This is caused by the fact that no direct relationship exists among adjacent pixels on the output feature map. To address this problem, we propose the pixel transposed convolutional layer (PixelTCL) to establish direct relationships among adjacent pixels on the up-sampled feature map. Our method is based on a fresh interpretation of the regular transposed convolutional operation. The resulting PixelTCL can be used to replace any transposed convolutional layer in a plug-and-play manner without compromising the fully trainable capabilities of original models. The proposed PixelTCL may result in slight decrease in efficiency, but this can be overcome by an implementation trick. Experimental results on semantic segmentation demonstrate that PixelTCL can consider spatial features such as edges and shapes and yields more accurate segmentation outputs than transposed convolutional layers. When used in image generation tasks, our PixelTCL can largely overcome the checkerboard problem suffered by regular transposed convolutional operations.","","","10.1109/TPAMI.2019.2893965","Defense Advanced Research Projects Agency; Division of Information and Intelligent Systems; Division of Biological Infrastructure; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8618415","Deep learning;pixel-wise prediction;up-sampling;transposed convolution;pixel transposed convolution","Convolution;Semantics;Image segmentation;Kernel;Task analysis;Image generation;Analytical models","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Tanji: a General-purpose Neural Network Accelerator with Unified Crossbar Architecture","H. Zhu; Y. Wang; C. -. R. Shi","State Key Laboratory of ASIC and Systems, Fudan University, Shanghai, China.; State Key Laboratory of ASIC and Systems, Fudan University, Shanghai, China.; State Key Laboratory of ASIC and Systems, Fudan University, Shanghai, China and Department of Electrical Engineering, University of Washington.","IEEE Design & Test","","2019","PP","99","1","1","In advanced deep neural networks, computation intensive layers such as convolution neural networks and data communication intensive layers such as fully-connected or recurrent neural networks are both widely used. To achieve energy and area efficiency in processing, a deep learning accelerator (DLA), Tanji, with unified crossbar architecture for the both types of the neural networks is proposed in this paper. When processing convolution layers, the crossbar architecture deployed by Tanji achieves massive data reuse and efficient on-chip data movement; whereas when processing fully-connected or recurrent layers, the same architecture leverages high-speed off-chip data access, sparsity exploiting and fast processing. An accelerator prototype is implemented on the Xilinx Kintex XC7K325t platform, consuming 440mW at a clock rate of 165MHz. A real-time demonstration based on the Tanji DLA is also presented achieving 20.12fps on a YOLOv2-352 network for object detection applications.","","","10.1109/MDAT.2019.2952329","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8894091","Neural network accelerator;multi-type neural network;deep learning;crossbar architecture","Computer architecture;Neural networks;Convolution;Kernel;System-on-chip;Bandwidth;Unicast","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Attentive Stacked Denoising Autoencoder with Bi-LSTM for Personalized Context-aware Citation Recommendation","T. Dai; L. Zhu; Y. Wang; K. M. Carley","School of Software Engineering, Xi'an Jiaotong University, 12480 Xi'an, Shaanxi China (e-mail: zzj.ddt@stu.xjtu.edu.cn); School of Software Engineering, Xi'an Jiaotong University, 12480 Xi'an, Shaanxi China 710049 (e-mail: zhuli@xjtu.edu.cn); School of Software Engineering, Xi'an Jiaotong University, 12480 Xi'an, Shaanxi China (e-mail: wangyx15@stu.xjtu.edu.cn); Institute for Software Research, Carnegie Mellon University, 6612 Pittsburgh, Pennsylvania United States (e-mail: kathleen.carley@cs.cmu.edu)","IEEE/ACM Transactions on Audio, Speech, and Language Processing","","2019","PP","99","1","1","The rapid growth of scientific publications brings the problem of finding appropriate citations for authors. Context-aware citation recommendation is an essential technology to overcome this obstacle when given a fragment of manuscript. In this paper, we propose a novel neural network model for context-aware citation recommendation by combining stacked denoising autoencoders (SDAE) and Bi-LSTM. To obtain effective embedding for cited paper, we extend SDAE into attentive SDAE (ASDAE) by utilizing the attentive information from citation context, which essentially enhance the learning ability of original SDAE. For citation context, we devise an attentive Bi-LSTM to obtain effective embedding. Specifically, the attentive Bi-LSTM is able to simultaneously extract suitable citation context and recommend citations when given a long text, which is a issue that few papers addressed before. We also integrate personalized author information to improve the performance of recommendation. Our model is essentially a seemly integration of different types of neural network with latent variables. We derive the generative process of our model, and develop a learning algorithm based on maximum a posteriori (MAP) estimation. Experimental results on the RefSeer, ANN and DBLP datasets show that our model outperforms baseline methods.","","","10.1109/TASLP.2019.2949925","China Scholarship Council; National Natural Science Foundation of China; Natural Science Basic Research Plan in Shaanxi Province of China; New Generation Artificial Intelligence Major Project in the Ministry of Science and Technology of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8884121","Stacked denoising autoencoders;Bi-LSTM;attention mechanism;citation recommendation;citation context extraction","Context modeling;Speech processing;Task analysis;Noise reduction;Deep learning;Recurrent neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Representation Calibrated Bayesian Neural Network for Semantically Explainable Face Inpainting and Editing","H. Xiong; C. Wang; X. Wang; D. Tao","Australian Institute of Health Innovation, Macquarie University, North Ryde, NSW 2113, Australia.; UBTECH Sydney Artificial Intelligence Centre, School of Computer Science, Faculty of Engineering and Information Technologies, University of Sydney, Darlington, NSW 2008, Australia.; Department of Computer Science, Stevens Institute of Technology, Hoboken, New Jersey 07030, USA.; UBTECH Sydney Artificial Intelligence Centre, School of Computer Science, Faculty of Engineering and Information Technologies, University of Sydney, Darlington, NSW 2008, Australia.","IEEE Access","","2019","PP","99","1","1","Image inpainting seeks to fill in corrupted areas with pixels that have a similar texture and content with its surroundings. For high-structured data, e.g., human face, some recent works can achieve quite realistic results. However, almost all existing methods learned a determined mapping from a corrupted input to the final result, yet ignored the potential multiple plausible solutions of the same input. Furthermore, they have not explored the underlying connections between those plausible solutions and semantic conditions. In this work, we propose a novel deep representation calibrated Bayesian neural network (DRCBNN) for semantically explainable face inpainting and editing. By leveraging the advantages that Bayesian decision theory deals with uncertainty, the proposed framework exploits deep representation into Bayesian decision theory and derive a deep representation calibrated evidence lower bound (ELBO). In comparison with traditional ELBO in BNN, the newly calibrated ELBO is a more task-specific loss function. After optimizing the newly calibrated ELBO, it allows to inference desired inpainting outputs in accordance with specific semantics. Finally, experiments demonstrated that our method can produce multiple semantics-aware inpainting outputs and outperforms the state-of-the-arts.","","","10.1109/ACCESS.2019.2963675","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8947931","Bayesian Neural Network;Latent Variable;Face Inpainting and Editing;Variational Inference","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Further Exploring Convolutional Neural Networks' Potential for Land-Use Scene Classification","B. Li; W. Su; H. Wu; R. Li; W. Zhang; W. Qin; S. Zhang; J. Wei","National Innovation Institute of Defense Technology, Academy of Military Sciences, Beijing 100071, China, and also with the Tianjin Artificial Intelligence Innovation Center (TAIIC), Tianjin, China.; National Innovation Institute of Defense Technology, Academy of Military Sciences, Beijing 100071, China, and also with the Tianjin Artificial Intelligence Innovation Center (TAIIC), Tianjin, China (e-mail: directorsu@126.com).; Institute of Medical Support Technology, Academy of Military Science, Tianjin 300161, China.; National Innovation Institute of Defense Technology, Academy of Military Sciences, Beijing 100071, China, and also with the Tianjin Artificial Intelligence Innovation Center (TAIIC), Tianjin, China.; Institute of Medical Support Technology, Academy of Military Science, Tianjin 300161, China.; National Innovation Institute of Defense Technology, Academy of Military Sciences, Beijing 100071, China, and also with the Tianjin Artificial Intelligence Innovation Center (TAIIC), Tianjin, China.; National Innovation Institute of Defense Technology, Academy of Military Sciences, Beijing 100071, China, and also with the Tianjin Artificial Intelligence Innovation Center (TAIIC), Tianjin, China.; Swanson School of Engineering, University of Pittsburgh, Pittsburgh, PA 15261 USA.","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","Recently, with the success of deep convolutional neural networks (CNNs), many end-to-end learning algorithms have yielded excellent results. However, in the field of land use and land cover (LULC), very deep CNNs cannot be driven with even tens of thousands of images. In contrast to transferring methods that only employ a model pretrained with an irrelevant data set (e.g., ImageNet) and directly inherit parameters without refining, we explore an approach for effectively driving a deep CNN with a small data capacity. We propose a novel concept called the best activation model (BAM) in the end-to-end process for LULC image classification. BAM theoretically represents the best activation status for end-to-end networks with a small data set, taking both the data-capacity limitation and target-scene specificity into full consideration. The proposed method overcomes the problem of under-fitting and has optimal scene specificity for LULC scenes. Our approach greatly improves the time efficiency and yields excellent performance compared with state-of-the-art methods, obtaining averages of 99.0%, 98.8%, and 96.1% on the UC Merced Land-Use, WHU-RS19 data sets, and the Google data set of SIRI_WHU, respectively.","","","10.1109/LGRS.2019.2952660","National Natural Science Foundation of China; Tianjin Natural Science Foundation of China; Tianjin Science and Technology Support Project Key R and D Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8910362","Best activation model (BAM);convolutional neural network (CNN);end-to-end learning method;land-use and land-cover (LULC) scene classification.","Feature extraction;Visualization;Data models;Training;Google;Convolutional neural nets;Learning systems","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A 3D CNN-LSTM-Based Image-to-Image Foreground Segmentation","T. Akilan; Q. J. Wu; A. Safaei; J. Huo; Y. Yang","Department of Electrical and Computer Engineering, University of Windsor, Windsor, ON N9B 3P4, Canada.; Department of Electrical and Computer Engineering, University of Windsor, Windsor, ON N9B 3P4, Canada (e-mail: jwu@uwindsor.ca).; Toronto Micro Electronics Inc., Mississauga, ON L5T 2H7, Canada.; Department of Electrical and Computer Engineering, University of Windsor, Windsor, ON N9B 3P4, Canada.; Computer Science Department, Lakehead University, Thunder Bay, ON P7B 5E1, Canada.","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","13","The video-based separation of foreground (FG) and background (BG) has been widely studied due to its vital role in many applications, including intelligent transportation and video surveillance. Most of the existing algorithms are based on traditional computer vision techniques that perform pixel-level processing assuming that FG and BG possess distinct visual characteristics. Recently, state-of-the-art solutions exploit deep learning models targeted originally for image classification. Major drawbacks of such a strategy are the lacking delineation of FG regions due to missing temporal information as they segment the FG based on a single frame object detection strategy. To grapple with this issue, we excogitate a 3D convolutional neural network (3D CNN) with long short-term memory (LSTM) pipelines that harness seminal ideas, viz., fully convolutional networking, 3D transpose convolution, and residual feature flows. Thence, an FG-BG segmenter is implemented in an encoder-decoder fashion and trained on representative FG-BG segments. The model devises a strategy called double encoding and slow decoding, which fuses the learned spatio-temporal cues with appropriate feature maps both in the down-sampling and up-sampling paths for achieving well generalized FG object representation. Finally, from the Sigmoid confidence map generated by the 3D CNN-LSTM model, the FG is identified automatically by using Nobuyuki Otsu's method and an empirical global threshold. The analysis of experimental results via standard quantitative metrics on 16 benchmark datasets including both indoor and outdoor scenes validates that the proposed 3D CNN-LSTM achieves competitive performance in terms of figure of merit evaluated against prior and state-of-the-art methods. Besides, a failure analysis is conducted on 20 video sequences from the DAVIS 2016 dataset.","","","10.1109/TITS.2019.2900426","Canada Research Chair Program; NSERC Discovery Grant; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8671459","Deep learning;foreground-background segmentation;intelligent systems;LSTM;spatiotemporal cues.","Three-dimensional displays;Solid modeling;Image segmentation;Visualization;Decoding;Encoding;Computational modeling","","","","2","","","","","","IEEE","IEEE Early Access Articles"
"Optical Flow Estimation Using Dual Self-Attention Pyramid Networks","M. Zhai; X. Xiang; R. Zhang; N. Lv; A. El Saddik","School of Information and Communication Engineering, Harbin Engineering University, Harbin 150001, China.; School of Information and Communication Engineering, Harbin Engineering University, Harbin 150001, China.; School of Information and Communication Engineering, Harbin Engineering University, Harbin 150001, China.; School of Information and Communication Engineering, Harbin Engineering University, Harbin 150001, China.; school of Electrical Engineering and Computer Science, University of Ottawa, Ottawa ON K1N 6N5, Canada.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Recently, optical flow estimation benefits greatly from deep learning based techniques. Most approaches use encoder-decoder architecture (U-Net) or spatial pyramid network (SPN) to learn optical flow. Both U-Net and SPN can extract multi-scale features and can predict optical flow directly. However, existing networks ignore to exploit the global information among channel features and inter-spatial relationship of features. In this paper, we propose a dual self-attention pyramid network, which adaptively integrates local features with their global dependencies and focuses on important features and suppresses unimportant features. Specifically, we introduce two types of attention modules into SPN, which emphasizes meaningful features along channel and spatial axes. The channel attention can adaptively re-weight channel-wise features by considering interdependencies among channels. Moreover, the spatial attention can utilize global contextual information to emphasize or suppress features in different spatial locations. In addition, two attention modules are embedded into each pyramidal level, which can refine features at different scale. We evaluate our method on MPI-Sintel and KITTI. The experimental results show that using the dual self-attention module can improve the representation power of network and further increase the accuracy of optical flow estimation.","","","10.1109/TCSVT.2019.2943140","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8846749","Deep learning;convolutional neural networks (CNNs);optical flow estimation;dual self-attention;pyramid network","Optical imaging;Estimation;Task analysis;Optical fiber networks;Adaptive optics;Computational modeling;Adaptation models","","","","","","","","","","IEEE","IEEE Early Access Articles"
"K_net: Lysine Malonylation Sites Identification with Neural Networ","J. Sun; Y. Cao; D. Wang; W. Bao; Y. Chen","School of Information, University of Jinan, Jinan 250024, China.; School of Information, University of Jinan, Jinan 250024, China.; School of Information, University of Jinan, Jinan 250024, China.; School of Information and Electrical Engineering, Xuzhou University of Technology, Xuzhou 221018, China.; School of Information, University of Jinan, Jinan 250024, China.","IEEE Access","","2019","PP","99","1","1","Lysine Malonylation (Kmal) is a newly discovered protein post-translational modifications (PTMs) type, which plays an important role in many biological processes. Therefore, identifying and understanding Kmal sites is very critical in the studies of biology and diseases. The typical methods are time-wasting and expensive. Nowadays, many researchers have proposed machine learning (ML) methods to deal with PTMs’s identification issue. Especially, some deep learning (DL) methods are also utilized in this field. In this work, we proposed K_net, which employed Convolutional Neural Network to identify the potential sites. Meanwhile, we proposed a new verification method Split to Equal Validation (SEV), which can well solve the impact of sample imbalance on prediction results. More Specifically, Acc, Sn, Sp, MCC and AUC values were adopted to evaluate the prediction performance of predictors. In total, CNNKmal achieved the better performance than other methods.","","","10.1109/ACCESS.2019.2961941","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8941011","Lysine Malonylation;Deep learning;Convolutional Neural Network;Split to Equal Validation","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Sensor-Augmented Neural Adaptive Bitrate Video Streaming on UAVs","X. Xiao; W. Wang; T. Chen; Y. Cao; T. Jiang; Q. Zhang","School of electronic information and communications, Huazhong University of Science and Technology, 12443 Wuhan, Hubei China 430074 (e-mail: xuedouxiao@hust.edu.cn); School of Electronic Information and Communications, Huazhong University of Science and Technology, 12443 Wuhan China 430074 (e-mail: gswwang@connect.ust.hk); School of Electronic Information and Communications, Huazhong University of Science and Technology, 12443 Wuhan, Hubei China 430074 (e-mail: chentaobin@hust.edu.cn); School of Electronic Information and Communications, Huazhong University of Science and Technology, 12443 Wuhan China 430074 (e-mail: ycao@hust.edu.cn); Electronics and Information Engineering, Huazhong University of Science and Technology, Wuhan, HuBei China 430074 (e-mail: Tao.Jiang@ieee.org); HKUST, Hong Kong University of Science and Technology, Clear Water Bay Hong Kong nil (e-mail: qianzh@cse.ust.hk)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","Recent advances in unmanned aerial vehicle (UAV) technology have revolutionized a broad class of civil and military applications. But the design of wireless technologies that enable real-time streaming of high-definition video between UAVs and ground devices presents a conundrum. Most existing adaptive bitrate (ABR) algorithms are not optimized for the UAV links, which usually fluctuate dramatically due to the dynamic flight states of the UAV. In this paper, we present SA-ABR, a new sensor-augmented system that generates ABR video streaming algorithms with the assistance of various kinds of inherent sensor data that are used to pilot UAVs. By incorporating the inherent sensor data with network observations, SA-ABR trains a deep reinforcement learning (DRL) model to extract salient features from the flight state information and automatically learn ABR algorithm to adapt to the varying UAV channel capacity through the training process. SA-ABR does not rely on any assumptions or models about UAV's flight states or the environment, but instead, it makes decisions by exploiting temporal properties of past throughput patterns through the long short-term memory (LSTM) to adapt itself to a wide range of highly dynamic environments. We have implemented SA-ABR in a commercial UAV and evaluated it in the wild. We compare SA-ABR with a variety of existing state-of-the-art ABR algorithms, and the results show that our system outperforms the best known existing ABR algorithm by 21.4% in terms of the average quality of experience (QoE) reward.","","","10.1109/TMM.2019.2945167","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8855031","Unmanned aerial vehicle;adaptive bitrate algorithm;video streaming;sensor-augmented system;deep reinforcement learning","Throughput;Streaming media;Acceleration;Heuristic algorithms;Bit rate;Unmanned aerial vehicles;Adaptation models","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Fingerprint Identification With Shallow Multifeature View Classifier","M. Ghafoor; S. A. Tariq; T. Zia; I. A. Taj; A. Abbas; A. Hassan; A. Y. Zomaya","Department of Computer Science, COMSATS University, Islamabad 46000, Pakistan.; Department of Computer Science, COMSATS University, Islamabad 46000, Pakistan (e-mail: s.alitariq1@gmail.com).; Department of Computer Science, COMSATS University, Islamabad 46000, Pakistan.; Department of Electrical Engineering, Capital University of Science and Technology, Islamabad 46000, Pakistan.; Department of Computer Science, COMSATS University, Islamabad 46000, Pakistan.; Department of Computer Science, COMSATS University, Islamabad 46000, Pakistan.; School of Information Technologies, University of Sydney, Sydney, NSW 2006, Australia.","IEEE Transactions on Cybernetics","","2019","PP","99","1","13","This article presents an efficient fingerprint identification system that implements an initial classification for search-space reduction followed by minutiae neighbor-based feature encoding and matching. The current state-of-the-art fingerprint classification methods use a deep convolutional neural network (DCNN) to assign confidence for the classification prediction, and based on this prediction, the input fingerprint is matched with only the subset of the database that belongs to the predicted class. It can be observed for the DCNNs that as the architectures deepen, the farthest layers of the network learn more abstract information from the input images that result in higher prediction accuracies. However, the downside is that the DCNNs are data hungry and require lots of annotated (labeled) data to learn generalized network parameters for deeper layers. In this article, a shallow multifeature view CNN (SMV-CNN) fingerprint classifier is proposed that extracts: 1) fine-grained features from the input image and 2) abstract features from explicitly derived representations obtained from the input image. The multifeature views are fed to a fully connected neural network (NN) to compute a global classification prediction. The classification results show that the SMV-CNN demonstrated an improvement of 2.8% when compared to baseline CNN consisting of a single grayscale view on an open-source database. Moreover, in comparison with the state-of-the-art residual network (ResNet-50) image classification model, the proposed method performs comparably while being less complex and more efficient during training. The result of classification-based fingerprint identification has shown that the search space is reduced by over 50% without degradation of identification accuracies.","","","10.1109/TCYB.2019.2957188","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8941056","CNN;deep learning (DL);fingerprint identification;image classification","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"H2O-Cloud: A Resource and Quality of Service-Aware Task Scheduling Framework for Warehouse-Scale Data Centers","M. Cheng; J. Li; P. Bogdan; S. Nazarian","Department of Electrical and Computer Engineering, University of Southern California, Los Angeles, CA, 90089, USA.; Department of Electrical and Computer Engineering, University of Southern California, Los Angeles, CA, 90089, USA.; Department of Electrical and Computer Engineering, University of Southern California, Los Angeles, CA, 90089, USA.; Department of Electrical and Computer Engineering, University of Southern California, Los Angeles, CA, 90089, USA.","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","","2019","PP","99","1","1","Cloud computing has attracted both end-users and Cloud Service Providers (CSPs) in recent years. Improving resource utilization rate (RUtR), such as CPU and memory usages on servers, while maintaining Quality-of-Service (QoS) is one key challenge faced by CSPs with warehouse-scale datacenters. Prior works proposed various algorithms to reduce energy cost or to improve RUtR, which either lack the fine-grained tasks scheduling capabilities, or fail to take a comprehensive system model into consideration. This paper presents H2O-Cloud, a hierarchical hybrid online task scheduling framework for warehouse-scale CSPs, to improve resource usage effectiveness while maintaining QoS. H2O-Cloud is highly scalable and considers comprehensive information such as various workload scenarios, cloud platform configurations, user request information and dynamic pricing model. The hierarchy and hybridity of the framework, combined with its deep reinforcement learning (DRL) engines, enables H2O-Cloud to efficiently start on-the-go scheduling and learning in an unpredictable environment without pre-training. Our experiments confirm the high efficiency of the proposed H2O-Cloud when compared to baseline approaches, in terms of energy and cost while maintaining QoS. Compared with one of the state-of-the-art DRL-based algorithm, H2O-Cloud achieves up to 201.17% energy cost efficiency improvement, 47.88% energy efficiency improvement and 551.76% reward rate improvement.","","","10.1109/TCAD.2019.2930575","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8770260","Cloud resource management;deep reinforcement learning (DRL);hierarchical and hybrid framework;task scheduling;quality of service-aware.","Task analysis;Servers;Cloud computing;Resource management;Quality of service;Integrated circuit modeling;Scheduling","","","","1","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Robust identification of thermal models for in-production High-Performance-Computing clusters with machine learning-based data selection","F. Pittino; R. Diversi; L. Benini; A. Bartolini","Department of Electrical, Electronic and Information Engineering (DEI), University of Bologna, Italy.; Department of Electrical, Electronic and Information Engineering (DEI), University of Bologna, Italy.; Department of Electrical, Electronic and Information Engineering (DEI), University of Bologna, Italy, and also with the Integrated Systems Laboratory, ETH Zurich, Switzerland.; Department of Electrical, Electronic and Information Engineering (DEI), University of Bologna, Italy.","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems","","2019","PP","99","1","1","Power and thermal management are critical components of High-Performance-Computing (HPC) systems, due to their high power density and large total power consumption. The assessment of thermal dissipation by means of compact models directly from the thermal response of the final device enables more robust and precise thermal control strategies as well as automated diagnosis. However, when dealing with large scale systems “in production"", the accuracy of learned thermal models depends on the dynamics of the power excitation, which depends also on the executed workload, and measurement nonidealities, such as quantization. In this paper we show that, using an advanced system identification algorithm, we are able to generate very accurate thermal models (average error lower than our sensors quantization step of 1∘C) for a large scale HPC system on real workloads for very long time periods. However, we also show that: 1) not all real workloads allow for the identification of a good model; 2) starting from the theory of system identification it is very difficult to evaluate if a trace of data leads to a good estimated model. We then propose and validate a set of techniques based on machine learning and deep learning algorithms for the choice of data traces to be used for model identification. We also show that deep learning techniques are absolutely necessary to correctly choose such traces up to 96% of the times.","","","10.1109/TCAD.2019.2950378","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8887210",".","Computational modeling;Thermal sensors;Power demand;Integrated circuit modeling;Data models;Predictive models;Noise measurement","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Predicting Asthma Attacks: Effects of Indoor PM Concentrations on Peak Expiratory Flow Rates of Asthmatic Children","D. Kim; S. Cho; L. Tamil; D. J. Song; S. Seo","School of Economic, Political and Policy Sciences, University of Texas at Dallas, Richardson, TX 75080, USA.; School of Economic, Political and Policy Sciences, University of Texas at Dallas, Richardson, TX 75080, USA.; Quality of Life Technology Laboratory, Department of Electrical & Computer Engineering, University of Texas at Dallas, Richardson, TX 75080, USA.; Department of Pediatrics, Korea University Guro Hospital, Seoul, 08308, South Korea.; Department of Environmental Health and Safety, College of Health Industry, Eulji University, Seongnam, 13135, South Korea.","IEEE Access","","2019","PP","99","1","1","Despite ample research on the association between indoor air pollution and allergic disease prevalence, public health and environmental policies still lack predictive evidence for developing a preventive guideline for patients or vulnerable populations mostly due to limitation of real-time big data and model predictability. Recent popularity of IoT and machine learning techniques could provide enabling technologies for collecting real-time big data and analyzing them for more accurate prediction of allergic disease risks for evidence-based intervention, but the effort is still in its infancy. This pilot study explored and evaluated the feasibility of a deep learning algorithm for predicting asthma risk. It is based on peak expiratory flow rates (PEFR) of 14 pediatric asthma patients visiting the Korea University Medical Center and indoor particulate matter PM10 and PM2.5 concentration data collected at their residence every 10 minutes using a PM monitoring device with a low-cost sensor between September 1, 2017 and August 31, 2018. We interpolated the PEFR results collected twice a day for each patient throughout the day so that it can be matched to the PM and other weather data. The PEFR results were classified into three categories such as ‘Green’ (normal), ‘Yellow’ (mild to moderate exacerbation) and ‘Red’ (severe exacerbation) with reference to their best peak flow value. Long Short-Term Memory (LSTM) model was trained using the first 10 months of the linked data and predicted asthma risk categories for the next 2 months during the study period. LSTM model is found to predict the asthma risk categories better than multinomial logistic (MNL) regression as it incorporates the cumulative effects of PM concentrations over time. Upon successful modifications of the algorithm based on a larger sample, this approach could potentially play a groundbreaking role for the scientific data-driven medical decision making.","","","10.1109/ACCESS.2019.2960551","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8936445","asthma;indoor particulate matter;deep learning;peak expiratory flow rates;real-time monitoring","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Short-Term Prediction of Residential Power Energy Consumption via CNN and Multilayer Bi-directional LSTM Networks","F. U. M. Ullah; A. Ullah; I. U. Haq; S. Rho; S. W. Baik","Intelligent Media Laboratory, Digital Contents Research Institute, Sejong University, Seoul 143-747, South Korea.; Intelligent Media Laboratory, Digital Contents Research Institute, Sejong University, Seoul 143-747, South Korea.; Intelligent Media Laboratory, Digital Contents Research Institute, Sejong University, Seoul 143-747, South Korea.; Intelligent Media Laboratory, Digital Contents Research Institute, Sejong University, Seoul 143-747, South Korea.; Intelligent Media Laboratory, Digital Contents Research Institute, Sejong University, Seoul 143-747, South Korea.","IEEE Access","","2019","PP","99","1","1","Excessive power consumption (PC) and demand for power is increasing on a daily basis, due to advancements in technology, the rise in electricity-dependent machinery, and the growth of the human population. It has become necessary to predict PC in order to improve power management and co-operation between the energy used in a building and the power grid. State-of-the-art energy consumption prediction (ECP) methods are limited in terms of predicting the energy effectively, due to various challenges such as weather conditions and the dynamic behaviour of occupants. Thus, to overcome the drawbacks of these methods, we present an intelligent hybrid technique that combines a convolutional neural network (CNN) with a multi-layer bi-directional long-short term memory (M-BLSTM) method using three steps. When applied to short-term power ECP, this approach helps to provide efficient power management i.e. it can assist the supplier to produce the optimum amount of power. The first step in our proposed method integrates the pre-processing and data organisation mechanisms to refine the data and remove abnormalities. The second step employs a deep learning network, where the sequence of refined data is fed into the CNN via the M-BLSTM network to learn the sequence pattern effectively. The third step generates the ECP/PC by comparing actual and predicted data series and evaluates the prediction using error metrics. The proposed method achieves better prediction results than existing techniques, thus demonstrating its effectiveness. Furthermore, it achieved the smallest value of the Mean Square Error (MSE) and Root Mean Square Error (RMSE) for individual household dataset using 10-fold cross validation (CV) and a hold-out (CV) method.","","","10.1109/ACCESS.2019.2963045","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8945363","Artificial intelligence;deep learning;power consumption;CNN;bi-directional LSTM;and short-term energy consumption","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Solder joint recognition using Mask R-CNN method","H. Wu; W. Gao; X. Xu","Anhui Province Key Laboratory of Special Heavy Load Robot, the Anhui University of Technology, China, 243032.; Anhui University of Technology, China, 243032.; Anhui University of Technology, China, 243032.","IEEE Transactions on Components, Packaging and Manufacturing Technology","","2019","PP","99","1","1","This paper proposes a novel solder joint recognition method based on the state-of-the-art Mask R-CNN deep learning method. Traditional classification methods, such as neural networks and statistical methods, can only classify defect type, and the template matching method can only match the position of the object. Based on Mask R-CNN, our proposed approach can classify, position and segment of the solder joint defect at the same time. To train our Mask R-CNN-based detection method, the transfer learning method uses the ResNet-101, which is initialized and trained on the Microsoft COCO dataset. Through experimentation, our proposed method obtained better results than the traditional classification method in solder joint recognition, and it can achieve very high classification accuracy with an over 95% mean of average precision (mAP) for segmentation. The proposed method can classify and identify the position and segment of the solder joint defect simultaneously with very high recognition accuracy.","","","10.1109/TCPMT.2019.2952393","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8894555","Convolutional neural network;Deep learning;Defect detection;Solder joint inspection","Soldering;Inspection;Feature extraction;Image segmentation;Training;Proposals;Neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Salient Object Detection by Spatiotemporal and Semantic Features in Real-Time Video Processing Systems","Y. Fang; G. Ding; W. Wen; F. Yuan; Y. Yang; Z. Fang; W. Lin","Jiangxi University of Finance and Economics, 12460 Nanchang China 330013 (e-mail: fa0001ng@e.ntu.edu.sg); Jiangxi University of Finance and Economics, 12460 Nanchang China (e-mail: 834480686@qq.com); Jiangxi University of Finance and Economics, 12460 Nanchang China (e-mail: wenyingwen@sina.cn); Jiangxi University of Finance and Economics, 12460 Nanchang China (e-mail: yfn@ustc.edu.cn); Jiangxi University of Finance and Economics, 12460 Nanchang China (e-mail: greatyangy@126.com); Shanghai University of Engineering Science, 66323 Shanghai China (e-mail: zjfang@sues.edu.cn); Nanyang Technological University, Singapore (e-mail: wslin@ntu.edu.sg)","IEEE Transactions on Industrial Electronics","","2019","PP","99","1","1","Object detection is significant for event analysis in various intelligent multimedia processing systems. Although there have been many studies conducting research in this area, effective and efficient object detection methods for video sequences are still much desired. In this study, we investigate salient object detection in real-time multimedia processing systems. Considering the intrinsic relationship between top-down and bottom-up saliency features, we present a new effective method for video salient object detection based on deep semantic and spatiotemporal cues. After extracting top-down semantic features for object perception by a 2D convolutional networks (Conv2DNet), we concatenate them with bottom-up spatiotemporal cues for motion perception extracted by a 3D convolutional network (Conv3DNet). In order to combine these features effectively, we feed them into a 3D deconvolutional network (Deconv3DNet) for feature-sharing learning between semantic features and spatiotemporal cues for the final saliency prediction. Additionally, we propose a novel Gaussian-like based loss function with L2-norm regularization term for parameter learning. Experimental results show that the proposed salient object detection approach performs better in both effectiveness and efficiency for video sequences compared with the state-of-the-art models.","","","10.1109/TIE.2019.2956418","National Natural Science Foundation of China; Henry Fok Education Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8924951","object detection;saliency detection;3D convolutional networks;deep learning;real-time object detection","Feature extraction;Spatiotemporal phenomena;Three-dimensional displays;Semantics;Object detection;Two dimensional displays;Video sequences","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Intelligent Hazard-Risk Prediction Model for Train Control Systems","J. Liu; Y. Zhang; J. Han; J. He; J. Sun; T. Zhou","Shanghai Key Laboratory of Trustworthy Computing, East China Normal University, Shanghai 200062, China.; China Unionpay, Shanghai 200136, China.; Department of Computer Engineering, New York University, New York, NY 10003 USA.; Shanghai Key Laboratory of Trustworthy Computing, East China Normal University, Shanghai 200062, China (e-mail: jifeng@sei.ecnu.edu.cn).; CASCO Signal Ltd., Shanghai 200071, China.; CASCO Signal Ltd., Shanghai 200071, China.","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","12","Although there has been substantial research in system analytics for risk assessment in traditional methods, little work has been done for safety risk prediction in communication-based train control (CBTC) system, especially intelligently predicting risk caused by the uncertainty in the system operation. Risk prediction and assessment of hazards in train control systems are vital for the safety and efficiency of urban rail transit. In this paper, we propose an intelligent hazard-risk prediction model based on a deep recurrent neural network for a new communication-mode CBTC system. First, a train-to-train communication-based train control (T2T-CBTC) system is proposed to improve the drawback of CBTC in information-exchanging mode. Then we design a risk prediction feature selection and generation method and estimate a critical function feature in the T2T-CBTC system by statistical model checking. Finally, we construct our intelligent hazard-risk prediction model based on a deep recurrent neural network using a long-short-term memory (LSTM) network. The model had excellent risk prediction classification results and performance in our experiment, even for unbalanced data set. This model consistently outperforms the deep belief network trained in Accuracy, Precision, Recall and F1-score for the hazard-risk prediction problem. Specifically, the mean accuracy is 97.2% and mean F1-score is 93.9% in overall performance of model. The improvements of our model against DBN model are 8.2% for Precision, 7% for Recall and 8% for F1-score.","","","10.1109/TITS.2019.2945333","National Key Research and Development Project; NSFC; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8865446","Risk prediction;deep learning;long-short-term memory (LSTM);communication-based train control system;statistical model checking.","Predictive models;Hazards;Control systems;Rails;Neural networks;Systems architecture","","","","","","","","","","IEEE","IEEE Early Access Articles"
"3D-GLCM CNN: A 3-dimensional gray-level co-occurrence matrix based CNN model for polyp classification via CT colonography","J. Tan; Y. Gao; Z. Liang; W. Cao; M. J. Pomeroy; Y. Huo; L. Li; M. A. Barish; A. F. Abbasi; P. J. Pickhardt","Department of Radiology, Stony Brook University, Stony Brook, NY 11794, USA and Department of Computer Science, City University of New York at CSI, NY, 10314, USA.; Department of Radiology, Stony Brook University, Stony Brook, NY 11794, USA.; Departments of Radiology and Biomedical Engineering, Stony Brook University, Stony Brook, NY 11794, USA.; Department of Radiology, Stony Brook University, Stony Brook, NY 11794, USA.; Departments of Radiology and Biomedical Engineering, Stony Brook University, Stony Brook, NY 11794, USA.; Department of Computer Science, City University of New York at CSI, NY, 10314, USA.; Department of Computer Science, City University of New York at CSI, NY, 10314, USA.; Department of Radiology, Stony Brook University, Stony Brook, NY 11794, USA.; Department of Radiology, Stony Brook University, Stony Brook, NY 11794, USA and Department of Computer Science, City University of New York at CSI, NY, 10314, USA.; Department of Radiology, School of Medicine, University of Wisconsin, Madison, WI 53792, USA.","IEEE Transactions on Medical Imaging","","2019","PP","99","1","1","Accurately classifying colorectal polyps, or differentiating malignant from benign ones, has a significant clinical impact on early detection and identifying optimal treatment of colorectal cancer. Convolution neural network (CNN) has shown great potential in recognizing different objects (e.g. human faces) from multiple slice (or color) images, a task similar to the polyp differentiation, given a large learning database. This study explores the potential of CNN learning from multiple slice (or feature) images to differentiate malignant from benign polyps from a relatively small database with pathological ground truth, including 32 malignant and 31 benign polyps represented by volumetric computed tomographic (CT) images. The feature image in this investigation is the gray-level co-occurrence matrix (GLCM). For each volumetric polyp, there are 13 GLCMs, computed from each of the 13 directions through the polyp volume. For comparison purpose, the CNN learning is also applied to the multi-slice CT images of the volumetric polyps. The comparison study is further extended to include Random Forest (RF) classification of the Haralick texture features (derived from the GLCMs). From the relatively small database, this study achieved scores of 0.91/0.93 (two-fold/leave-one-out evaluations) AUC (area under curve of the receiver operating characteristics) by using the CNN on the GLCMs, while the RF reached 0.84/0.86 AUC on the Haralick features and the CNN rendered 0.79/0.80 AUC on the multiple-slice CT images. The presented CNN learning from the GLCMs can relieve the challenge associated with relatively small database, improve the classification performance over the CNN on the raw CT images and the RF on the Haralick features, and have the potential to perform the clinical task of differentiating malignant from benign polyps with pathological ground truth.","","","10.1109/TMI.2019.2963177","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8945384","Polyp differentiation;image features;deep learning;GLCM;CT colonoscopy","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Active Shape Model for Robust Object Fitting","D. O. Medley; C. Santiago; J. C. Nascimento","Institute for Systems and Robotics, Instituto Superior Técnico, Lisbon 1049-001, Portugal.; Institute for Systems and Robotics, Instituto Superior Técnico, Lisbon 1049-001, Portugal.; Institute for Systems and Robotics, Instituto Superior Técnico, Lisbon 1049-001, Portugal.","IEEE Transactions on Image Processing","","2019","PP","99","1","1","Object recognition and localization is still a very challenging problem, despite recent advances in deep learning (DL) approaches, especially for objects with varying shapes and appearances. Statistical models, such as an Active Shape Model (ASM), rely on a parametric model of the object, allowing an easy incorporation of prior knowledge about shape and appearance in a principled way. To take advantage of these benefits, this paper proposes a new ASM framework that addresses two tasks: (i) comparing the performance of several image features used to extract observations from an input image; and (ii) improving the performance of the model fitting by relying on a probabilistic framework that allows the use of multiple observations and is robust to the presence of outliers. The goal in (i) is to maximize the quality of the observations by exploring a wide set of handcrafted features (HOG, SIFT, and texture templates) and more recent DL-based features. Regarding (ii), we use the Generalized Expectation-Maximization algorithm to deal with outliers and to extend the fitting process to multiple observations. The proposed framework is evaluated in the context of facial landmark fitting and the segmentation of the endocardium of the left ventricle in cardiac magnetic resonance volumes. We experimentally observe that the proposed approach is robust not only to outliers, but also to adverse initialization conditions and to large search regions (from where the observations are extracted from the image). Furthermore, the results of the proposed combination of the ASM with DL-based features are competitive with more recent DL approaches (e.g. FCN [1], U-Net [2] and CNN Cascade [3]), showing that it is possible to combine the benefits of statistical models and DL into a new deep ASM probabilistic framework.","","","10.1109/TIP.2019.2948728","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8884671","Image Segmentation;Convolutional Neural Networks;Generalized Expectation-Maximization;HOG;SIFT;Active Shape Model","Feature extraction;Shape;Probabilistic logic;Active appearance model;Image segmentation;Image edge detection;Active shape model","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Sensor Fusion between 2D Laser Scanner and IMU for Mobile Robot Localization","C. Li; S. Wang; Y. Zhuang; F. Yan","School of Control Science and Engineering, Dalian Univ. of Technology, Dalian 116024, China.; Edinburgh Centre for Robotics at Heriot-Watt University,UK.; School of Control Science and Engineering, Dalian Univ. of Technology, Dalian 116024, China.; School of Control Science and Engineering, Dalian Univ. of Technology, Dalian 116024, China.","IEEE Sensors Journal","","2019","PP","99","1","1","Multi-sensor fusion plays a key role in 2D laser based robot location and navigation. Although it has achieved great success, there are still some challenges, e.g., being fragile when having large angular rotation. In this paper, we present a deep learning based approach to localizing a mobile robot using a 2D laser and an Inertial Measurement Unit. A novel Recurrent Convolutional Neural Network (RCNN) based architecture is developed to fuse laser and inertial data for scan-to-scan pose estimation. A scan-to-submap optimization is also introduced to optimize the poses estimated by the RCNN for enhanced robustness and accuracy. Extensive experiments have been conducted in both simulation and practice with a real mobile robot, verifying the effectiveness of the proposed deep sensor fusion system.","","","10.1109/JSEN.2019.2910826","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8689068","Data fusion;Pose estimation;2D laser scanning;Inertial measurement unit (IMU)","","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Deep Collaborative Filtering with Multi-Aspect Information in Heterogeneous Networks","C. Shi; X. Han; S. Li; X. Wang; S. Wang; J. Du; P. Yu","School of Computer, Beijing University of Posts and Telecommunications, Beijing, Beijing China (e-mail: shichuan@bupt.edu.cn); School of Computer Science, Beijing University of Posts and Telecommunications, BEIJING, BEIJING China (e-mail: hanxiaotian.h@gmail.com); School of Computer Science, Beijing University of Posts and Telecommunications, Beijing, Beijing China (e-mail: song200626@gmail.com); School of Computer, Beijing University of Posts and Telecommunications, 12472 Beijing, Beijing China (e-mail: xiaowang@bupt.edu.cn); College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, Jiangsu China (e-mail: szwang@nuaa.edu.cn); School of Computer, BUPT, Beijing, Beijing China (e-mail: junpingdu@126.com); Computer Science, UIC, Chicago, Illinois United States 60607 (e-mail: psyu@cs.uic.edu)","IEEE Transactions on Knowledge and Data Engineering","","2019","PP","99","1","1","Recently, recommender systems play a pivotal role in alleviating the problem of information overload. Latent factor models have been widely used for recommendation. The unified latent factor only represents the characteristics of users and the properties of items from the aspect of purchase history. Moreover, the latent factor models usually use the shallow projection, which cannot capture the characteristics of users and items well. Deep neural network has shown tremendous potential to model the non-linearity relationship between users and items. In this paper, we propose a Neural network based Aspect-level Collaborative Filtering model (NeuACF) to exploit different aspect latent factors. Through modelling the recommender system as a heterogeneous information network, NeuACF first extracts different aspect-level similarity matrices of users and items respectively through different meta-paths, and then feeds an elaborately designed deep neural network with these matrices to learn aspect-level latent factors. Finally, the aspect-level latent factors are fused for the top-N recommendation. Moreover, to fuse information from different aspects more effectively, we further propose NeuACF++ to fuse aspect-level latent factors with self-attention mechanism. Extensive experiments on three real world datasets show that NeuACF and NeuACF++ significantly outperform both existing latent factor models and recent neural network models.","","","10.1109/TKDE.2019.2941938","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8840873","Recommender Systems;Heterogeneous Information Network;Aspect-level Latent Factor","Neural networks;Feature extraction;Fuses;Recommender systems;Collaboration;Data mining","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Lightweight On-Device Detection Method for Android Malware","W. Yuan; Y. Jiang; H. Li; M. Cai","School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan 430074, China (e-mail:yuanwei@mail.hust.edu.cn).; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan 430074, China. He is now with Tencent, Shenzhen, China.; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan 430074, China (e-mail:liheng@hust.edu.cn).; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan 430074, China.","IEEE Transactions on Systems, Man, and Cybernetics: Systems","","2019","PP","99","1","12","Android malware poses severe threats to users, hence raising an urgent demand for malware detection. In-cloud Android malware detection often suffers privacy leakage and communication overheads. Therefore, this article focuses on on-device Android malware detection. At present, on-device malware detectors are usually trained on servers and then transplanted to mobile devices (e.g., smartphones). In practice, on-device training is particularly important due to the demand for offline updates. Because mobile devices are limited in resource, however, on-device training is hard to implement, especially for those high-complexity malware detectors. To overcome this challenge, we design a lightweight on-device Android malware detector, based on the recently proposed broad learning method. Our detector mainly uses one-shot computation for model training. Hence it can be fully or incrementally trained directly on mobile devices. As far as detection accuracy is concerned, our detector outperforms the shallow learning-based models, including support vector machine (SVM) and AdaBoost, and approaches the deep learning-based models multilayer perceptron (MLP) and convolutional neural network (CNN). Moreover, our detector is more robust to adversarial examples than the existing detectors, and its robustness can be further improved through on-device model retraining. Finally, its advantages are confirmed by extensive experiments, and its practicality is demonstrated through runtime evaluation on smartphones.","","","10.1109/TSMC.2019.2958382","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8944288","Android malware detection;broad learning;information security;machine learning","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Near-Field wireless power transfer to deep-tissue implants for biomedical applications","K. Zhang; C. Liu; Z. H. Jiang; Y. Zhang; X. Liu; H. Guo; X. Yang","School of Electronic and Information Engineering, Soochow University, Jiangsu, 215006.; School of Electronic and Information Engineering, Soochow University, Jiangsu, 215006.; School of Information Science and Engineering, Southeast University, Jiangsu, 211100, and State Key Laboratory of Millimeter Waves, Nanjing 211100, China.; School of Electronic and Information Engineering, Soochow University, Jiangsu, 215006.; School of Electronic and Information Engineering, Soochow University, Jiangsu, 215006.; School of Electronic and Information Engineering, Soochow University, Jiangsu, 215006.; School of Electronic and Information Engineering, Soochow University, Jiangsu, 215006.","IEEE Transactions on Antennas and Propagation","","2019","PP","99","1","1","Wireless power transfer (WPT) plays critical roles in powering deep-tissue implants, which also contributes to several emerging advances for biomedical engineering. To enable a high-power density region in implants, this paper presents a method, termed the self-phasing technology, to focus electromagnetic fields from various paths at a deep-tissue spot. By performing the phase-conjugated operation on the incident signal and then retransfer back to the source, coherent RF power can be achieved without learning the precise or even dynamic locations of sources and concerning inhomogeneous medium perturbations. An external slot antenna array placed above skin surface 4mm is considered as a transmitter and an implanted rectenna consisting of a magnetic resonant coil and a RF-to-DC rectifier circuit is treated as a receiver. The conversion efficiency of the rectifier circuit is optimized within the received power range and the measured efficiency of 50% can be achieved at 0dBm. To visualize the transceiver effects of the integrated system under safety thresholds, a light-emitting diode is soldered at the terminal of the rectenna and measurements show that smooth drive can be achieved. Certain brightness of LED can demonstrate that the self-phasing technology can support wireless power transfer for biomedical applications.","","","10.1109/TAP.2019.2943424","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8852813","Wireless power transfer;implantable antenna;near-field powering;rectenna;focused antenna","Slot antennas;Implants;Antenna arrays;Rectennas;Transmitters;Antenna measurements","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Real-world Image Denoising with Deep Boosting","C. Chen; Z. Xiong; X. Tian; Z. Zha; F. Wu","EEIS, University of Science and Technology of China, 12652 Hefei, Anhui China (e-mail: changc@mail.ustc.edu.cn); EEIS, University of Science and Technology of China, 12652 Hefei, Anhui China (e-mail: zwxiong@ustc.edu.cn); EEIS, University of Science and Technology of China, 12652 Hefei, Anhui China (e-mail: xinmei@ustc.edu.cn); EEIS, University of Science and Technology of China, 12652 Hefei, Anhui China (e-mail: zhazj@ustc.edu.cn); EEIS, University of Science and Technology of China, 12652 Hefei, Anhui China (e-mail: fengwu@ustc.edu.cn)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","We propose a Deep Boosting Framework (DBF) for real-world image denoising by integrating the deep learning technique into the boosting algorithm. The DBF replaces conventional handcrafted boosting units by elaborate convolutional neural networks, which brings notable advantages in terms of both performance and speed. We design a lightweight Dense Dilated Fusion Network (DDFN) as an embodiment of the boosting unit, which addresses the vanishing of gradients during training due to the cascading of networks while promoting the efficiency of limited parameters. The capabilities of the proposed method are first validated on several representative simulation tasks including non-blind and blind Gaussian denoising and JPEG image deblocking. We then focus on a practical scenario to tackle with the complex and challenging real-world noise. To facilitate leaning-based methods including ours, we build a new Real-world Image Denoising (RID) dataset, which contains 200 pairs of high-resolution images with diverse scene content under various shooting conditions. Moreover, we conduct comprehensive analysis on the domain shift issue for real-world denoising and propose an effective one-shot domain transfer scheme to address this issue. Comprehensive experiments on widely used benchmarks demonstrate that the proposed method significantly surpasses existing methods on the task of real-world image denoising.","","","10.1109/TPAMI.2019.2921548","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8733117","Boosting;convolutional neural networks;image denoising;JPEG image deblocking;real-world noise","Boosting;Noise reduction;Image denoising;Task analysis;Image restoration;Transform coding;Computational modeling","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Recurrent Temporal Aggregation Framework for Deep Video Inpainting","D. Kim; S. Woo; J. Lee; I. S. Kweon","The School of Electrical Engineering, Korea Advanced Institute of Science and Technology, 34968 Yu-seong gu, Daejeon Korea (the Republic of) (e-mail: mcahny@kaist.ac.kr); The School of Electrical Engineering, Korea Advanced Institute of Science and Technology, 34968 Yuseong-gu, Daejeon Korea (the Republic of) (e-mail: shwoo93@kaist.ac.kr); Adobe Research, Adobe Systems Inc, 58584 San Jose, California United States (e-mail: jolee@adobe.com); Electrical Engineering, Korea Advanced Institute of Science and Technology, 34968 Yuseong-gu, Daejeon Korea (the Republic of) (e-mail: iskweon77@kaist.ac.kr)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Video inpainting aims to fill in spatio-temporal holes in videos with plausible content. Despite tremendous progress on deep learning-based inpainting of a single image, it is still challenging to extend these methods to video domain due to the additional time dimension. In this paper, we propose a recurrent temporal aggregation framework for fast deep video inpainting. In particular, we construct an encoder-decoder model, where the encoder takes multiple source frames which can provide visible pixels revealed from the scene dynamics. These hints are aggregated and fed into the decoder. We apply a recurrent feedback in an auto-regressive manner to enforce temporal consistency in the video results. We propose two architectural designs based on this framework. Our first model is a blind video decaptioning network (BVDNet) that is designed to automatically remove and inpaint text overlays in videos without any mask information. Our BVDNet wins the first place in the ECCV Chalearn 2018 LAP Inpainting Competition Track 2: Video Decaptioning. Second, we propose a network for more general video inpainting (VINet) to deal with more arbitrary and larger holes. Video results demonstrate the advantage of our framework compared to state-of-the-art methods both qualitatively and quantitatively.","","","10.1109/TPAMI.2019.2958083","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8931251","Video inpainting;Video completion;Video object removal;Video caption removal;Video decaptioning;Video editing","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Encoding Pose Features To Images With Data Augmentation For 3D Action Recognition","T. Huynh-The; H. Hua-Cam; D. Kim","Gumi-si Korea (the Republic of) 39177 (e-mail: thienht@kumoh.ac.kr); Yongin-si Korea (the Republic of) 446-701 (e-mail: hao.hua@oslab.khu.ac.kr); Gumi Korea, Republic of 730-701 (e-mail: dskim@kumoh.ac.kr)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","Recently, numerous methods have been introduced for 3D action recognition using handcrafted feature descriptors coupled traditional classifiers. However, they cannot learn high-level features of a whole skeleton sequence exhaustively. In this paper, a novel encoding technique, namely Pose Feature to Image (PoF2I), is introduced to transform the pose features of joint-joint distance and orientation to color pixels. By concatenating the features of all skeleton frames in a sequence, a color image is generated to depict spatial joint correlations and temporal pose dynamics of an action appearance. The strategy of end-to-end fine-tuning a pre-trained deep convolutional neural network, which completely capture multiple high-level features at multi-scale action representation, is implemented for learning recognition models. We further propose an efficient data augmentation mechanism for informative enrichment and overfitting prevention. The experimental results on six challenging 3D action recognition datasets demonstrate that the proposed method outperforms state-of-the-art approaches.","","","10.1109/TII.2019.2910876","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8691567","Pose feature to image (PoF2I) encoding technique;data augmentation;human action recognition;deep convolutional neural networks (DCNNs)","","","","","2","","","","","","IEEE","IEEE Early Access Articles"
"On the Effect of Observed Subject Biases in Apparent Personality Analysis from Audio-visual Signals","R. D. Pérez Principi; C. Palmero; J. C. Junior; S. Escalera","Department of Mathematics and Informatics, Universitat de Barcelona, 16724 Barcelona, Barcelona Spain (e-mail: principidario@gmail.com); Department of Mathematics and Informatics, Universitat de Barcelona, 16724 Barcelona, Barcelona Spain (e-mail: crpalmec7@alumnes.ub.edu); Computer Science, Multimedia and Telecommunications, Universitat Oberta de Catalunya, 16766 Barcelona, Barcelona Spain (e-mail: jsilveira@uoc.edu); Department of Mathematics and Informatics, Universitat de Barcelona, 16724 Barcelona, Catalunya Spain (e-mail: sergio@maia.ub.es)","IEEE Transactions on Affective Computing","","2019","PP","99","1","1","Personality perception is implicitly biased due to many subjective factors, such as cultural, social, contextual, gender and appearance. Approaches developed for automatic personality perception are not expected to predict the real personality of the target, but the personality external observers attributed to it. Hence, they have to deal with human bias, inherently transferred to the training data. However, bias analysis in personality computing is an almost unexplored area. In this work, we study different possible sources of bias affecting personality perception, including emotions from facial expressions, attractiveness, age, gender, and ethnicity, as well as their influence on prediction ability for apparent personality estimation. To this end, we propose a multi-modal deep neural network that combines raw audio and visual information alongside predictions of attribute-specific models to regress apparent personality. We also analyse spatio-temporal aggregation schemes and the effect of different time intervals on first impressions. We base our study on the ChaLearn First Impressions dataset, consisting of one-person conversational videos. Our model shows state-of-the-art results regressing apparent personality based on the Big-Five model. Furthermore, given the interpretability nature of our network design, we provide an incremental analysis on the impact of each possible source of bias on final network predictions.","","","10.1109/TAFFC.2019.2956030","MINECO FEDER UE; CERCA Programme Generalitat de Catalunya; Ministerio de Ciencia y Tecnologea; ICREA Academia programme; MINECO FEDER UE; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8913501","Automatic personality perception;Personality computing;First impressions;Big-Five;OCEAN;Subjective bias;Multi-modal recognition;Convolutional Neural Networks;Audio-visual Recordings","Videos;Visualization;Feature extraction;Observers;Computational modeling;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Memory Augmented Deep Generative models for Forecasting the Next Shot Location in Tennis","T. Fernando; S. Denman; S. Sridharan; C. Fookes","Electrical Engineering and Computer Science, Queensland University of Technology, 1969 Brisbane, Queensland Australia 4001 (e-mail: t.warnakulasuriya@qut.edu.au); School of Engineering Systems, QUT, Brisbane, Queensland Australia (e-mail: s.denman@qut.edu.au); School of Electrical Engineering and Computer Science, Queensland University of Technology, Brisbane, Queensland Australia (e-mail: s.sridharan@qut.edu.au); School of Electrical Engineering and Computer Science, Queensland University of Technology, 1969 Brisbane, Queensland Australia (e-mail: c.fookes@qut.edu.au)","IEEE Transactions on Knowledge and Data Engineering","","2019","PP","99","1","1","This paper presents a novel framework for predicting shot location and type in tennis. Inspired by recent neuroscience discoveries we incorporate neural memory modules to model the episodic and semantic memory components of a tennis player. We propose a Semi-Supervised Generative Adversarial Network architecture that couples these memory models with the automatic feature learning power of deep neural networks, and demonstrate methodologies for learning player level behavioural patterns with the proposed framework. We evaluate the effectiveness of the proposed model on tennis tracking data from the 2012 Australian Tennis Open and exhibit applications of the proposed method in discovering how players adapt their style depending on the match context.","","","10.1109/TKDE.2019.2911507","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8691787","Neural Memory Networks;Generative Adversarial Networks;Tennis Shot Prediction;Player Behaviour Analysis","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Separation of nonlinearly-mixed Sources using end-to-end Deep Neural Networks","H. Zamani; S. Razavi-Kia; H. Otroshi Shahreza; A. Amini","Electrical Engineering, Sharif University of Technology, 68260 Tehran, Tehran Iran (the Islamic Republic of) (e-mail: zamanihojatollah@gmail.com); Electrical Engineering, Sharif University of Technology, 68260 Tehran, Tehran Iran (the Islamic Republic of) 11365-11155 (e-mail: saeedrazavi1414@gmail.com); Electrical Engineering, Sharif University of Technology, 68260 Tehran, Please select Iran (the Islamic Republic of) 11365-9363 (e-mail: h.otroshi@gmail.com); Electrical Engineering, Sharif University of Technology, 68260 Tehran Iran (the Islamic Republic of) 11365-9363 (e-mail: aamini@sharif.edu)","IEEE Signal Processing Letters","","2019","PP","99","1","1","In this paper, we consider the problem of blind source separation under certain nonlinear mixing conditions using a deep learning approach. Conventionally, the separation of sources within linear mixtures is achieved by applying the independence property of the sources. In the nonlinear regime, however, this property is no longer sufficient. In this paper, we consider nonlinear mixing operators where the non-linearity could be fairly approximated using a Taylor series. Next, for solving the nonlinear BSS problem, we design an end-to-end recurrent neural network (RNN) that learns the inverse of the system, and ultimately separates the sources. For training the RNN, we employ a set of multi-variate polynomial functions to simulate the Taylor expansion of the nonlinear mixture. Nu- merical experiments show that the proposed method successfully separates the sources with a performance superior to the recent approach devised in [1].","","","10.1109/LSP.2019.2957675","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8922787","","Training;Taylor series;Recurrent neural networks;Brain modeling;Blind source separation;Blindness","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Guided Attention Inference Network","K. Li; Z. Wu; K. Peng; J. Ernst; Y. Fu","Electrical and Computer Engineering, Northeastern Unversity, Boston, Massachusetts United States 02115 (e-mail: kunpengli@ece.neu.edu); Corporate Technology, Siemens Corporation, Princeton, New Jersey United States (e-mail: wuzy.buaa@gmail.com); Corporate Technology, Siemens Corporation, Princeton, New Jersey United States (e-mail: kuanchuan.peng@siemens.com); Corporate Technology, Siemens Corporation, Princeton, New Jersey United States (e-mail: jan.ernst@siemens.com); ECE, Northeastern University, Boston, Massachusetts United States (e-mail: yunfu@ece.neu.edu)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","With only coarse labels, weakly supervised learning typically uses top-down attention maps generated by back-propagating gradients as priors for tasks such as object localization and semantic segmentation. While these attention maps are intuitive and informative explanations of deep neural network, there is no effective mechanism to manipulate the network attention during learning process. In this paper, we address three shortcomings of previous approaches in modeling such attention maps in one common framework. First, we make attention maps a natural and explicit component in the training pipeline such that they are end-to-end trainable. Moreover, we provide self-guidance directly on these maps by exploring supervision from the network itself to improve them towards specific target tasks. Lastly, we proposed a design to seamlessly bridge the gap between using weak and extra supervision if available. Despite its simplicity, experiments on the semantic segmentation task demonstrate the effectiveness of our methods. Besides, the proposed framework provides a way not only explaining the focus of the learner but also feeding back with direct guidance towards specific tasks. Under mild assumptions our method can also be understood as a plug-in to existing convolutional neural networks to improve their generalization performance.","","","10.1109/TPAMI.2019.2921543","U.S. Army Research Office Award; NSF IIS Award; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8733010","convolutional neural network;semantic segmentation;network attention;weakly supervised learning;biased data","Task analysis;Semantics;Visualization;Image segmentation;Supervised learning;Training;Convolutional neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Visual Correspondences for Unsupervised Domain Adaptation on Electron Microscopy Images","R. Bermúdez-Chacón; O. Altingövde; C. Becker; M. Salzmann; P. Fua","Computer Vision Laboratory, EPFL, Lausanne, Switzerland.; Computer Vision Laboratory, EPFL, Lausanne, Switzerland.; Computer Vision Laboratory, EPFL, Lausanne, Switzerland.; Computer Vision Laboratory, EPFL, Lausanne, Switzerland.; Computer Vision Laboratory, EPFL, Lausanne, Switzerland.","IEEE Transactions on Medical Imaging","","2019","PP","99","1","1","We present an Unsupervised Domain Adaptation strategy to compensate for domain shifts on Electron Microscopy volumes. Our method aggregates visual correspondences—motifs that are visually similar across different acquisitions—to infer changes on the parameters of pretrained models, and enable them to operate on new data. In particular, we examine the annotations of an existing acquisition to determine pivot locations that characterize the reference segmentation, and use a patch matching algorithm to find their candidate visual correspondences in a new volume. We aggregate all the candidate correspondences by a voting scheme and we use them to construct a consensus heatmap: a map of how frequently locations on the new volume are matched to relevant locations from the original acquisition. This information allows us to perform model adaptations in two different ways: either by a) optimizing model parameters under a Multiple Instance Learning formulation, so that predictions between reference locations and their sets of correspondences agree, or by b) using high-scoring regions of the heatmap as soft labels to be incorporated in other domain adaptation pipelines, including deep learning ones. We show that these unsupervised techniques allow us to obtain high-quality segmentations on unannotated volumes, qualitatively consistent with results obtained under full supervision, for both mitochondria and synapses, with no need for new annotation effort. 1.","","","10.1109/TMI.2019.2946462","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8863400","Electron Microscopy;Transfer Learning;Domain Adaptation","Image segmentation;Adaptation models;Visualization;Training;Electron microscopy;Machine learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Energy-Efficient Pattern Recognition Hardware with Elementary Cellular Automata","A. Morán Costoya; C. F. Frasser; M. Roca; J. L. Rossello","Física, Universitat de les Illes Balears, 16745 Palma de Mallorca, Illes Balears Spain 07122 (e-mail: a.moran@uib.eu); Physics Dept, Universitat de les Illes Balears, 16745 Palma de Mallorca, Balears Spain (e-mail: christian.franco@uib.es); Physics Dept, Universitat de les Illes Balears, 16745 Palma de Mallorca, Balears Spain (e-mail: miquel.roca@uib.es); Physics Dept, Universitat de les Illes Balears, 16745 Palma de Mallorca, Balears Spain 07122 (e-mail: j.rossello@uib.es)","IEEE Transactions on Computers","","2019","PP","99","1","1","The development of power-efficient Machine Learning Hardware is of high importance to provide Artificial Intelligence (AI) characteristics to those devices operating at the Edge. Unfortunately, state-of-the-art data-driven AI techniques such as deep learning are too costly in terms of hardware and energy requirements for Edge Computing (EC) devices. Recently, Cellular Automata (CA) have been proposed as a feasible way to implement Reservoir Computing (RC) systems in which the automaton rule is fixed and the training is performed using a linear regression model. In this work we show that Reservoir Computing based on CA may arise as a promising AI alternative for devices operating at the edge due to its intrinsic simplicity. For this purpose, a new low-power CA-based reservoir hardware is proposed and implemented in a FPGA (known as ReCA circuitry). The use of Elementary Cellular Automata (ECA) are able to further simplify the RC structure to implement a power efficient AI system suitable to be implemented in EC applications. Experiments have been conducted on the well-known MNIST handwritten digits database, obtaining competitive results in terms of processing time, circuit area, power and inference accuracy.","","","10.1109/TC.2019.2949300","Regional European Development Funds; Spanish Ministry of Economy and Competitiveness; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8883070","Reservoir Computing;Machine Learning;Pattern Recognition;Cellular Automata;Hardware Implementation","Reservoirs;Hardware;Training;Automata;Pattern recognition;Machine learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Adaptive Weighting of Handcrafted Feature Losses for Facial Expression Recognition","W. Xie; L. Shen; J. Duan","Computer Vision Institute, School of Computer Science and Software Engineering, Guangdong Key Laboratory of Intelligent Information Processing, Shenzhen University, Shenzhen 518060, China.; Computer Vision Institute, School of Computer Science and Software Engineering, Guangdong Key Laboratory of Intelligent Information Processing, Shenzhen University, Shenzhen 518060, China, and also with the Shenzhen Institute of Artificial Intelligence and Robotics for Society, Shenzhen 518060, China (e-mail: llshen@szu.edu.cn).; School of Computer Science, University of Birmingham, Birmingham B15 2TT, U.K..","IEEE Transactions on Cybernetics","","2019","PP","99","1","14","Due to the importance of facial expressions in human-machine interaction, a number of handcrafted features and deep neural networks have been developed for facial expression recognition. While a few studies have shown the similarity between the handcrafted features and the features learned by deep network, a new feature loss is proposed to use feature bias constraint of handcrafted and deep features to guide the deep feature learning during the early training of network. The feature maps learned with and without the proposed feature loss for a toy network suggest that our approach can fully explore the complementarity between handcrafted features and deep features. Based on the feature loss, a general framework for embedding the traditional feature information into deep network training was developed and tested using the FER2013, CK+, Oulu-CASIA, and MMI datasets. Moreover, adaptive loss weighting strategies are proposed to balance the influence of different losses for different expression databases. The experimental results show that the proposed feature loss with adaptive weighting achieves much better accuracy than the original handcrafted feature and the network trained without using our feature loss. Meanwhile, the feature loss with adaptive weighting can provide complementary information to compensate for the deficiency of a single feature.","","","10.1109/TCYB.2019.2925095","National Natural Science Foundation of China; Science and Technology Project of Guangdong Province; Science and Technology Innovation Commission of Shenzhen; China Post Doctoral Science Foundation; Tencent Rhinoceros Birds Scientific Research Foundation for Young Teachers of Shenzhen University; School Startup Fund of Shenzhen University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8786929","Deep feature loss;expression recognition;handcrafted feature;loss adaptive weighting","Training;Databases;Face;Feature extraction;Loss measurement;Adaptive systems","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Light Field Super-Resolution By Jointly Exploiting Internal And External Similarities","Z. Cheng; Z. Xiong; D. Liu","University of Science and Technology of China, Hefei 230026, China.; University of Science and Technology of China, Hefei 230026, China.; University of Science and Technology of China, Hefei 230026, China.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Light field images taken by plenoptic cameras often have a trade-off between spatial and angular resolutions. In this paper, we propose a novel spatial super-resolution approach for light field images by jointly exploiting internal and external similarities. The internal similarity refers to the correlations across the angular dimensions of the 4D light field itself, while the external similarity refers to the cross-scale correlations learned from an external light field dataset. Specifically, we advance the classic projection-based method that exploits the internal similarity by introducing the intensity consistency checking criterion and a back-projection refinement, while the external correlation is learned by a CNN-based method which aggregates all warped high-resolution sub-aperture images upsampled from the low-resolution input using a single image super-resolution method. By analyzing the error distributions of the above two methods and investigating the upperbound of combining them, we find that the internal and external similarities are complementary to each other. Accordingly, we further propose a pixel-wise adaptive fusion network to take advantage of both their merits by learning a weighting matrix. Experimental results on both synthetic and real-world light field datasets validate the superior performance of the proposed approach over the state-of-the-arts.","","","10.1109/TCSVT.2019.2921660","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8733069","Light field;super-resolution;projection;deep learning","Spatial resolution;Cameras;Correlation;Light fields;Two dimensional displays","","","","","","","","","","IEEE","IEEE Early Access Articles"
"High-dimensional Dense Residual Convolutional Neural Network for Light Field Reconstruction","N. Meng; H. K. So; X. Sun; E. Lam","Electrical and Electronic Engineering, The University of Hong Kong, HONG KONG, China Hong Kong (e-mail: naen.mong@gmail.com); Electrical and Electronic Engineering, University of Hong Kong, Pokfulam, none Hong Kong (e-mail: hso@eee.hku.hk); Tencent, Shanghai, Shanghai China (e-mail: winfred.sun@gmail.com); Electrical and Electronic Engineering, University of Hong Kong, 25809 HONG KONG, Hong Kong China (e-mail: elam@eee.hku.hk)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","We consider the problem of high-dimensional light field reconstruction and develop a learning-based framework for spatial and angular super-resolution. Many current approaches either require disparity clues or restore the spatial and angular details separately. Such methods have difficulties with non-Lambertian surfaces or occlusions. In contrast, we formulate light field super-resolution (LFSR) as tensor restoration and develop a learning framework based on a two-stage restoration with 4-dimensional (4D) convolution. This allows our model to learn the features capturing the geometry information encoded in multiple adjacent views. Such geometric features vary near the occlusion regions and indicate the foreground object border. To train a feasible network, we propose a novel normalization operation based on a group of views in the feature maps, design a stage-wise loss function, and develop the multi-range training strategy to further improve the performance. Evaluations are conducted on a number of light field datasets including real-world scenes, synthetic data, and microscope light fields. The proposed method achieves superior performance and less execution time comparing with other state-of-the-art schemes.","","","10.1109/TPAMI.2019.2945027","Research Grants Council of Hong Kong projects GRF; Research Grants Council University of Hong Kong; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8854138","Light field super-resolution;4-dimensional convolution;Convolutional neural networks;Deep learning","Image reconstruction;Convolution;Estimation;Image restoration;Feature extraction;Correlation","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Convective Clouds Extraction From Himawari-8 Satellite Images Based on Double-Stream Fully Convolutional Networks","X. Zhang; T. Wang; G. Chen; X. Tan; K. Zhu","State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan 430079, China.; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan 430079, China.; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan 430079, China (e-mail: cgz@whu.edu.cn).; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan 430079, China.; State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan University, Wuhan 430079, China.","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","Auto-extraction of convective clouds is of great significance. Convective clouds often bring heavy rain, strong winds, and other disastrous weather. Early warning of convection can effectively reduce loss. Using remote sensing images, we can get large-scale cloud information, which provides many effective methods for convective clouds detection. In this letter, we proposed a novel method to extract convective clouds. We introduce a novel deep network using only 1 x1 convolution (3ONet) to extract the spectral characteristics. We then combine a 3ONet with the symmetrical dense-shortcut deep fully convolutional networks (SDFCNs) with a double-stream fully convolutional network to extract convective clouds. In the experiment, we used 12,000 Himawari-8 satellite image patches to verify the proposed framework. Experimental results with 0.5882 mean intersection over union (mIOU) pointed out the proposed method can extract convective clouds effectively.","","","10.1109/LGRS.2019.2926402","LIESMARS Special Research Funding; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8766846","Convective clouds;deep learning;fully convolutional network (FCN);remote sensing.","Feature extraction;Clouds;Convolution;Remote sensing;Convection;Training;Decoding","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Artificial Intelligence-powered Mobile Edge Computing-based Anomaly Detection in Cellular Networks","B. Hussain; Q. Du; A. Imran; M. A. Imran","School of Information and Communications Engineering, Xian Jiaotong University, China; Shaanxi Smart Networks and Ubiquitous Access Research Center; and the Department of Electronic and Information Engineering, The Hong Kong Polytechnic University, Hong Kong (e-mail: bilalhussain@stu.xjtu.edu.cn); School of Information and Communications Engineering, Xian Jiaotong University, China, and is also with Shaanxi Smart Networks and Ubiquitous Access Research Center (e-mail: duqinghe@mail.xjtu.edu.cn); School of Electrical and Computer Engineering, University of Oklahoma, Tulsa, OK 74135 USA (e-mail: ali.imran@ou.edu).; School of Engineering, University of Glasgow, Glasgow, G12 8QQ, U.K. (e-mail: Muhammad.Imran@glasgow.ac.uk)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","Escalating cell outages and congestion-treated as anomalies-cost a substantial revenue loss to the cellular operators and severely affect subscriber quality of experience. Stateof-the-art literature applies feed-forward deep neural network at core network (CN) for the detection of above problems in a single cell; however, the solution is impractical as it will overload the CN that monitors thousands of cells at a time. Inspired from mobile edge computing and breakthroughs of deep convolutional neural networks (CNNs) in computer vision research, we split the network into several 100-cell regions each monitored by an edge server; and propose a framework that pre-processes raw call detail records having user activities to create an image-like volume, fed to a CNN model. The framework outputs a multilabeled vector identifying anomalous cell(s). Our results suggest that our solution can detect anomalies with up to 96% accuracy, and is scalable and expandable for industrial Internet of things environment.","","","10.1109/TII.2019.2953201","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8896997","Self-Organizing Networks;Self-Healing Networks;Call detail record;Deep learning;Convolutional Neural Networks;Big data analytics","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Social-Enhanced Attentive Group Recommendation","D. Cao; X. He; L. Miao; G. Xiao; H. Chen; J. Xu","College of Computer Science and Electronic Engineering, Hunan University, Changsha, Hunan China (e-mail: caoda0721@gmail.com); School of Information Science and Technology, University of Science and Technology of China, 12652 Hefei, Anhui China (e-mail: xiangnanhe@gmail.com); College of Computer Science and Electronic Engineering, Hunan University, Changsha, Hunan China (e-mail: lianhaimiao@gmail.com); College of Computer Science and Electronic Engineering, Hunan University, Changsha, Hunan China (e-mail: guangyi.xiao@gmail.com); College of Computer Science and Electronic Engineering, Hunan University, Changsha, Hunan China (e-mail: xschenhao@gmail.com); Central Research Institute, CVTE Inc., Guangzhou, Guangdong China (e-mail: xujiao@cvte.com)","IEEE Transactions on Knowledge and Data Engineering","","2019","PP","99","1","1","With the proliferation of social networks, group activities have become an essential ingredient of our daily life. A growing number of users share their group activities online and invite their friends to join in. This imposes the need of an in-depth study on the group recommendation task, i.e., recommending items to a group of users. In this article, we devise neural network-based solutions by utilizing the recent developments of attention network and neural collaborative filtering. First of all, we adopt an attention network to form the representation of a group by aggregating the group members' embeddings, which allows the attention weights of group members to be dynamically learnt from data. Secondly, the social followee information is incorporated via another attention network to enhance the representation of individual user, which is helpful to capture users' personal preferences. Thirdly, considering that many online group systems also have abundant interactions of individual users on items, we further integrate the modeling of user-item interactions into our method. Through this way, the recommendation for groups and users can be mutually reinforced. Extensive experiments on the scope of both macro-level performance comparison and micro-level analyses justify the effectiveness and rationality of our proposed approaches.","","","10.1109/TKDE.2019.2936475","National Basic Research Program of China (973 Program); Natural Science Foundation of Hainan Province; Hunan Key Research and Development Program of China; Fundamental Research Funds for the Central Universities; National Science Foundation of China; National Research Foundation Prime Ministers Office Singapore; National Science Foundation for Young Scientists of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8807225","Group Recommendation;Attention Network;Social Followee Information;Neural Collaborative Filtering","Recommender systems;Neural networks;Aggregates;Collaboration;Deep learning;Social networking (online);Task analysis","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Large scale shadow annotation and detection using lazy annotation and stacked CNNs","L. Hou; T. F. Yago Vicente; M. Hoai; D. Samaras","Computer Science Department, Stony Brook University, 12301 Stony Brook, New York United States (e-mail: le.hou@stonybrook.edu); A9.com, Palo Alto, California United States (e-mail: victomas@a9.com); Computer Science Department, Stony Brook University, 12301 Stony Brook, New York United States (e-mail: minhhoai@cs.stonybrook.edu); Computer Science Department, Stony Brook University, 12301 Stony Brook, New York United States (e-mail: samaras@cs.sunysb.edu)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Recent shadow detection algorithms have shown initial success on small datasets of images from specific domains. However, shadow detection on broader image domains is still challenging due to the lack of representative annotated training data. In this paper we propose ""lazy annotation"", an efficient annotation method where an annotator only needs to mark the important shadow areas and some non-shadow areas. This yields data with noisy labels that are not yet useful for training a shadow detector. We address the problem of label noise by jointly learning a shadow region classifier and recovering the labels in the training set. Experimental results show that a classifier trained with recovered labels achieves comparable performance to a classifier trained on the properly annotated data. These results motivated us to collect a new dataset that is 20 times larger than existing datasets and contains a large variety of scenes and image types. In addition, we propose a stacked Convolutional Neural Network architecture that efficiently trains on patch level shadow examples while incorporating image level semantic information. Our proposed pipeline, trained on recovered labels, performs at state-of-the art level.","","","10.1109/TPAMI.2019.2948011","Stony Brook SensonCAT; FRA; Subsample project from DIGITEO Institute; Partner University Fund; Gift from Adobe; SUNY2020 Infrastructure Transportation Security Center; NSF; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8873648","","Training;Image segmentation;Semantics;Noise measurement;Light sources;Lighting;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Rub-impact Fault Diagnosis of Rotating Machinery Based on 1-D Convolutional Neural Networks","X. Wu; Z. Penga; J. Renc; C. Chenga; W. Zhanga; D. Wang","State Key Laboratory of Mechanical System and Vibration, Shanghai Jiao Tong University, Shanghai, China, 200240 and Shanghai Electric Power Generation Equipment Co., Ltd. Generator Plant, Shanghai, China, 200240.; State Key Laboratory of Mechanical System and Vibration, Shanghai Jiao Tong University, Shanghai, China, 200240.; Beijing Zhongyuan Risen Technology Co.,Ltd., Beijing, China, 100000.; State Key Laboratory of Mechanical System and Vibration, Shanghai Jiao Tong University, Shanghai, China, 200240.; State Key Laboratory of Mechanical System and Vibration, Shanghai Jiao Tong University, Shanghai, China, 200240.; State Key Laboratory of Mechanical System and Vibration, Shanghai Jiao Tong University, Shanghai, China, 200240.","IEEE Sensors Journal","","2019","PP","99","1","1","Rub-impact is a kind of serious malfunction, which often occurs in rotating machinery. The non-stationary rub-impact signals are always submerged in the background and noise signals, which makes it difficult to accurately diagnose the rubbing based on the hand-designed features extracted by the traditional methods. This paper presents a 1-D convolutional neural network (CNN) based approach to automatically learn useful features for rub-impact fault diagnosis from the raw vibration signals of a rotor system. The proposed model is trained on a dataset of vibration signals obtained from an industrial hydro turbine rotor. The results show that timely and accurate rub-impact fault detection can be achieved by a simple 1-D CNN configuration.","","","10.1109/JSEN.2019.2944157","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8851067","1-D convolutional neural network;Rub-impact;Fault diagnosis;Rotating machinery","Feature extraction;Fault diagnosis;Vibrations;Deep learning;Convolution;Rotors;Hydraulic turbines","","","","","","","","","","IEEE","IEEE Early Access Articles"
"An Inception Convolutional Autoencoder Model for Chinese Healthcare Question Clustering","D. Dai; J. Tang; Z. Yu; H. Wong; J. You; W. Cao; Y. Hu; C. L. P. Chen","School of Computer Science and Engineering, South China University of Technology, Guangzhou 510006, China.; department of Neonatology, Guangzhou Women and Children's Medical Centre, Guangzhou 510623, China (e-mail: moyudaoyuan@163.com).; School of Computer Science and Engineering, South China University of Technology, Guangzhou 510006, China (e-mail: zhwyu@scut.edu.cn).; Department of Computer Science, City University of Hong Kong, Hong Kong.; Department of Computing, Hong Kong Polytechnic University, Hong Kong.; Department of Computer Science, City University of Hong Kong, Hong Kong.; School of Computer Science and Engineering, South China University of Technology, Guangzhou 510006, China.; School of Computer Science and Engineering, South China University of Technology, Guangzhou 510006, China.","IEEE Transactions on Cybernetics","","2019","PP","99","1","13","Healthcare question answering (HQA) system plays a vital role in encouraging patients to inquire for professional consultation. However, there are some challenging factors in learning and representing the question corpus of HQA datasets, such as high dimensionality, sparseness, noise, nonprofessional expression, etc. To address these issues, we propose an inception convolutional autoencoder model for Chinese healthcare question clustering (ICAHC). First, we select a set of kernels with different sizes using convolutional autoencoder networks to explore both the diversity and quality in the clustering ensemble. Thus, these kernels encourage to capture diverse representations. Second, we design four ensemble operators to merge representations based on whether they are independent, and input them into the encoder using different skip connections. Third, it maps features from the encoder into a lower-dimensional space, followed by clustering. We conduct comparative experiments against other clustering algorithms on a Chinese healthcare dataset. Experimental results show the effectiveness of ICAHC in discovering better clustering solutions. The results can be used in the prediction of patients' conditions and the development of an automatic HQA system.","","","10.1109/TCYB.2019.2916580","NSFC; National Key Research and Development Program of China; Key Research and Development Program of Guangdong Province; Guangdong Natural Science Funds; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8730479","Autoencoder (AE);convolutional neural networks (CNNs);healthcare questions;inception;skip connections","Kernel;Medical services;Feature extraction;Deep learning;Pediatrics;Knowledge discovery;Indexes","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Novel Sparse Echo Autoencoder Network for Data-Driven Fault Diagnosis of Delta 3-D Printers","J. Long; Z. Sun; C. Li; Y. Hong; Y. Bai; S. Zhang","School of Mechanical Engineering, Dongguan University of Technology, Dongguan 523808, China, and also with the School of Mechanical and Automotive Engineering, South China University of Technology, Guangzhou 510641, China.; School of Mechanical Engineering, Dongguan University of Technology, Dongguan 523808, China.; School of Mechanical Engineering, Dongguan University of Technology, Dongguan 523808, China.; School of Mechanical Engineering, Dongguan University of Technology, Dongguan 523808, China.; School of Mechanical Engineering, Dongguan University of Technology, Dongguan 523808, China.; School of Mechanical Engineering, Dongguan University of Technology, Dongguan 523808, China, and also with the School of Mechanical and Automotive Engineering, South China University of Technology, Guangzhou 510641, China (e-mail: shaohui1985@hotmail.com).","IEEE Transactions on Instrumentation and Measurement","","2019","PP","99","1","10","Fault diagnosis is of importance to guarantee the printing quality and to avoid unexpected downtime for 3-D printers. In this paper, a sparse echo autoencoder network (SEAEN) is proposed for the fault diagnosis of delta 3-D printers using attitude data. Considering the practicality and economy of the fault diagnosis, the attitude data, including three-axial angular velocity signals, three-axial vibratory acceleration ones, and three-axial magnetic field intensity ones, are collected by installing a low-cost attitude sensor on the moving platform of the delta 3-D printer. However, the low-cost sensor will increase the chaos of the attitude data. To make up this deficiency, the SEAEN approach featuring a sparse autoencoder (SAE) combined with an echo state network (ESN) is designed for the fault diagnosis. The SAE is employed to automatically learn features from the high-dimensional attitude data of the delta 3-D printer, while the ESN is used for fault recognition based on the extracted features. The diagnosis performance of the address approach was evaluated in the experiments and its superiority was demonstrated through comparing with other intelligent fault diagnosis techniques.","","","10.1109/TIM.2019.2905752","National Natural Science Foundation of China; Natural Science Foundation of Guangdong Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8699100","Condition monitoring;delta 3-D printer;echo state network (ESN);fault diagnosis;sparse autoencoder (SAE).","Feature extraction;Fault diagnosis;Printers;Deep learning;Printing;Frequency-domain analysis;Solid modeling","","","","","","","","","","IEEE","IEEE Early Access Articles"
"MCSIP Net: Multichannel Satellite Image Prediction via Deep Neural Network","J. Lee; S. S. Lee; H. G. Kim; S. Song; S. Kim; Y. M. Ro","Image and Video Systems Laboratory, School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon 34141, South Korea.; Ybrain, Seongnam-si 13529, South Korea.; Signal Processing Laboratory, Institute of Electrical Engineering, École Polytechnique Fédérale de Lausanne (EPFL), 1015 Lausanne, Switzerland.; Research Data Sharing Center, Korea Institute of Science and Technology (KISTI), Daejeon 34141, South Korea; Research Data Sharing Center, Korea Institute of Science and Technology (KISTI), Daejeon 34141, South Korea; Image and Video Systems Laboratory, School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon 34141, South Korea (e-mail: ymro@ee.kaist.ac.kr).","IEEE Transactions on Geoscience and Remote Sensing","","2019","PP","99","1","13","Satellite image prediction is important in weather nowcasting. In this article, we propose a novel multichannel satellite image prediction network (MCSIP Net) for predicting satellite images. The proposed MCSIP Net consists of three parts such as the satellite image predictor, the spatio-temporal 3-D discriminators, and the domain knowledge critic networks. The satellite image predictor takes a multichannel satellite image as an input and predicts a multichannel satellite image by learning spatio-temporal characteristics of each input channel. The spatio-temporal 3-D discriminators are trained to distinguish whether the input satellite image consists of a real satellite image or predicted image. By learning the spatio-temporal 3-D discriminator to distinguish and the satellite image predictor to deceive, the satellite image predictor can generate satellite image more similar to real satellite image distribution. The domain knowledge critic networks take the satellite image and the corresponding analysis data (which is obtained from a meteorological model) as an input and learn to distinguish whether the input satellite image is real or predicted on the basis of the analysis data. By utilizing the analysis data, the proposed MCSIP Net could take the meteorological knowledge into account efficiently. For the purpose of verification of the proposed method, ablation study and qualitative evaluation were conducted. Experimental results demonstrated that the proposed MCSIP Net could be learned efficiently and predict a multichannel satellite image with remarkable quality.","","","10.1109/TGRS.2019.2955538","Institute for Information and Communications Technology Planning and Evaluation IITP Grant funded by the Korean Government MSIT; Korea Institute of Science and Technology Information KISTI; Brain Korea 21 Plus Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933126","Image prediction;multichannel satellite image prediction;satellite image prediction.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Oil Film Detection Under Solar Irradiation and Image Processing","L. Lu; S. Ichimura; A. Yamagishi; T. Rokunohe","R&D Group, Hitachi, Ltd., Omika-cho 7-1-1, Hitachi, Ibaraki, 316-0001 Japan.; R&D Group, Hitachi, Ltd., Omika-cho 7-1-1, Hitachi, Ibaraki, 316-0001 Japan.; Hitachi, Ltd., Kokubu-cho 1-1-1, Hitachi, Ibaraki, 316-0001 Japan.; R&D Group, Hitachi, Ltd., Omika-cho 7-1-1, Hitachi, Ibaraki, 316-0001 Japan.","IEEE Sensors Journal","","2019","PP","99","1","1","To detect oil leakage from a power transformer at its initial stage to prevent environmental pollution, we aimed to detect and localize leaked oil film that had adhered to the surface of a power transformer. Since the inspection for oil leakage is generally carried out in the daytime, in this research, a method to localize the oil film under solar irradiation was developed to support the inspection. To detect oil leakages, observation of the emitted fluorescence when the oil is irradiated with ultraviolet (UV) light has been commonly adopted. However, the fluorescence of an oil film adhered to a surface is too weak to recognize under solar irradiation. Therefore, the detection of strong specular reflection light of the oil film when it was irradiated with a light containing a visible component was used to additionally detect leaked oil film. Moreover, image processing using deep learning was applied on the obtained images to automatically recognize the oil film. By using the proposed oil-localization method, the oil-adhered area on the surface was recognized with a high accuracy of 99.2%. The proposed method is expected to be used to detect oil leakages for various types of oil filled equipment.","","","10.1109/JSEN.2019.2955088","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8910619","Oil leakage;Reflection light;Fluorescence;Image processing;Deep learning","Oils;Reflection;Fluorescence;Band-pass filters;Radiation effects;Surface treatment;Power transformers","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Joint Design of Access Point Selection and Path Planning for UAV-Assisted Cellular Networks","S. Zhu; L. Gui; N. Cheng; F. Sun; Q. Zhang","Department of Electronic Engineering, Shanghai Jiao Tong University, Shanghai 200240, China.; Department of Electronic Engineering, Shanghai Jiao Tong University, Shanghai 200240, China.; School of Telecommunication, Xidian University, Xi’an 710071, China.; Department of Electronic Engineering, Shanghai Jiao Tong University, Shanghai 200240, China.; Department of Electronic Engineering, Shanghai Jiao Tong University, Shanghai 200240, China.","IEEE Internet of Things Journal","","2019","PP","99","1","1","Unmanned aerial vehicle (UAV)-assisted communication is envisioned as a potential solution to the data traffic explosion in the massive machine type communications (mMTC) scenario. In this paper, we investigate the UAV-assisted cellular networks, where a UAV acts as a flying relay to offload part of the data traffic from the overloaded cell to another. We utilize the practical spatial distribution of data traffic and a convincing air-to-ground channel model. The quality of service (QoS) is defined as a UAV utility function which is designed based on a packet loss ratio (PLR)-related users cost function to represent the performance improvements brought by the UAV. We formulate a joint optimization problem to maximize the UAV utility function and then decompose it into the sub-problems about the access point selection and the UAV path planning, which influence the PLR by influencing the packet collision rate and channel state. Since the access point selection sub-problem is NP-hard, a game theory-based distributed algorithm is proposed, instructing the users to select the base station (BS) or the UAV as the access point autonomously. To achieve the most superior channel state, we solve the UAV path planning sub-problem by a deep reinforcement learning (DRL)-based approach, instructing the UAV to take the optimal action in each position. Simulation results show that the proposed access point selection scheme can significantly reduce the average cost of users and the proposed UAV path planning method can achieve a path with smaller average channel pathloss compared with other approaches.","","","10.1109/JIOT.2019.2947718","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8871183","Unmanned aerial vehicle (UAV);quality of service (QoS);access point selection;path planning;game theory;deep reinforcement learning (DRL).","Cellular networks;Quality of service;Resource management;Trajectory;Internet of Things;Unmanned aerial vehicles","","","","","","","","","","IEEE","IEEE Early Access Articles"
"FRF-Net: Land Cover Classification From Large-Scale VHR Optical Remote Sensing Images","Q. Sang; Y. Zhuang; S. Dong; G. Wang; H. Chen","Beijing Key Laboratory of Embedded Real-Time Information Processing Technology, Beijing 100081, China.; School of Electronic Engineering and Computer Science, Peking University, Beijing 100871, China (e-mail: zhuangyin640829@163.com).; Engineering Center of Digital Audio and Video, Communication University of China, Beijing 100024, China.; Beijing Key Laboratory of Embedded Real-Time Information Processing Technology, Beijing 100081, China.; Beijing Key Laboratory of Embedded Real-Time Information Processing Technology, Beijing 100081, China.","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","Deep learning (DL) technique is widely applied in remote sensing (RS) applications because of its outstanding nonlinear feature extraction ability. However, with regard to the issues of large-scale and very high-resolution (VHR) land cover classification, multi-object distributions and clear appearance with large intraclass difference become challenges for refined pixelwise land cover mapping. Focusing on these problems, the letter proposed a novel encoding-to-decoding method called the full receptive field (RF) network (FRF-Net) based on two types of attention mechanism. In the FRF-Net, ResNet-101 is used as the basic backbone. Then, the ensemble feature is generated by encoding the high-level features based on the self-attention mechanism which could achieve full RF to capture long-range semantic. Next, the encoding result is decoded by the fusion attention mechanism combined with the low-level feature to produce a fusion feature which contains a refined semantic description for accurate land cover mapping. Extensive experiments based on the GID and ISPRS data sets proved that the proposed network outperforms the state-of-the-art methods. The FRF-Net achieved 66.71% and 64.17% of the mean of classwise Intersection over Union (mIOU) with smaller computation cost on ISPRS and GID, respectively.","","","10.1109/LGRS.2019.2938555","Chang Jiang Scholars Program; Hundred Leading Talent Project of Beijing Science and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8848484","Deep learning (DL);land cover classification;remote sensing (RS);semantic segmentation;very high resolution (VHR).","Semantics;Radio frequency;Encoding;Decoding;Feature extraction;Optical imaging;Optical sensors","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Real-Time Fault-Detection for IIoT Facilities using GBRBM-based DNN","H. Huang; S. Ding; L. Zhao; H. Huang; L. Chen; H. Gao; S. H. Ahmed","School of Data and Computer Science, Sun Yat-Sen University, Guangzhou, 510006, China, and the School of Computer Science and Engineering, University of Aizu, Aizu-Wakamatsu, 965-8580, Fukushima, Japan.; School of Artificial Intelligence, Guilin University of Electronic Technology, Guilin-City, Guangxi 541004, and the College of Electronic Information and Optical Engineering, Nankai University, Tianjin 300350, China.; Department of Electronic and Information Engineering, The Hong Kong Polytechnic University, Hong Kong SAR, China.; School of Data and Computer Science, Sun Yat-Sen University, Guangzhou, 510006, China.; School of Data and Computer Science, Sun Yat-Sen University, Guangzhou, 510006, China.; Computing Center, Shanghai University, Shanghai 200444, China.; Department of Computer Science, Georgia Southern University, Statesboro, GA 30460, USA.","IEEE Internet of Things Journal","","2019","PP","99","1","1","Fault-detection is a fundamental requirement for industrial Internet-of-Things (IIoT), such as the process industry sammaknejad2019review. This paper first reviews recent studies focusing on applying fault-detection techniques to IIoT networks. However, we find out that numerous studies focus on resource utilization and workload allocation. The fault-detection towards IIoT facilities is still in its immature stage, because the existing approaches are not accurate enough for the stringent fault-detection in IIoT networks. To this end, we present a novel algorithm, named Gaussian Bernoulli restricted Boltzmann machines (GBRBM) based Deep Neural Network (DNN), to transform the fault-detection into a classification problem. Real trace-driven experiments show that the proposed scheme outperforms other baseline machine learning methods. We anticipate that this article can inspire blooming studies on the related topics of smart IIoT networks.","","","10.1109/JIOT.2019.2948396","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8877731","Fault-Detection;Continuous Intelligence;Self-Driving Networks;Internet of Things;Edge Computing;Deep Learning.","Feature extraction;Neural networks;Real-time systems;Production facilities;Internet of Things;Industries;Support vector machines","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Source camera identification based on coupling coding and adaptive filter","M. Zhao; B. Wang; F. Wei; M. Zhu; X. Sui","School of Information and Communication Engineering, Dalian University of Technology, Dalian, Liaoning, 116024, P.R. China.; School of Information and Communication Engineering, Dalian University of Technology, Dalian, Liaoning, 116024, P.R. China.; Department of Electrical Engineering, The State University of New York at Buffalo, Buffalo, NY 14260-2500 USA.; Beijing Institute of Electronics Technology and Application, Beijing, 100091, P.R. China.; College of Psychology, Liaoning Normal University, Dalian, Liaoning, 116029, P.R. China.","IEEE Access","","2019","PP","99","1","1","Source Camera Identification (SCI) has been playing an important role in the security field for decades.With the development of Deep Learning, the performance of SCI has been noteworthily improved. However, most of the proposed methods are forensic only for a single camera identification category, e.g., the camera model identification. For exploiting the coupling between different camera categories, we present a new coding method. That is, we apply the multi-task training method to regress the categories, namely, to classify brands, models and devices synchronously in a single network. Different from the common multi-task method, we obtain the multi-class classification result by just one single label classification. To be specific, we classify the categories in a progressive way that the parent category classification result will be used in the child category classification (a detailed explanation will be given later in the main context). Also, by appropriately increasing the redundancy of the coding method for classifying new camera categories, the training time can be greatly reduced. To better extract camera attributes, we propose an adaptive filter. Additionally, we propose an auxiliary classifier that only focuses on the camera model re-classification, due to the low performance of the main classifier on certain models. Lastly, the extensive experiments show that our methods have a better performance than other existing methods.","","","10.1109/ACCESS.2019.2959627","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8932363","Source camera identification;deep learning;multi-task training;camera categories coupling coding;adaptive filter;auxiliary classifier","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Cloud Computing Assisted Blockchain-Enabled Internet of Things","C. Qiu; H. Yao; C. Jiang; S. Guo; F. Xu","School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, 12472 Beijing, Beijing China (e-mail: zjkchouchao@bupt.edu.cn); Information and Communication Engineering, Beijing University of Posts and Telecommunications, 12472 Beijing, Beijing China 100088 (e-mail: yaohaipeng@bupt.edu.cn); Space Center, Tsinghua University, 12442 Beijing, Beijing China 100084 (e-mail: jchx@tsinghua.edu.cn); Department of Computing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong China (e-mail: song.guo@polyu.edu.hk); School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, 12472 Beijing, Beijing China (e-mail: xufm@bupt.edu.cn)","IEEE Transactions on Cloud Computing","","2019","PP","99","1","1","Recently, the term ‘Internet of Things’ (IoT) has garnered great attention. As a trusted, dependable, and decentralized approach, blockchain has already been used in IoT. However, the existing blockchain has a number of drawbacks that prevent it from being used as a generic platform for IoT. The nodes in IoT are heavily resource-limited, especially computing and networking resources. Unfortunately, they are necessary for the blockchain to solve complicated puzzles and propagate blocks. In this paper, we propose agent mining and cloud mining approaches to solve the above problem in the blockchain-enabled IoT. To be specific, miners act as mining agents for nodes in IoT, offload mining tasks to cloud computing servers, and use networking resources dynamically. Furthermore, in order to enhance the performance, the access selection of users, computing resources allocation, and networking resources allocation are formulated as a joint optimization problem. We then propose a dueling deep reinforcement learning approach to address this problem. Numerical results justify the effectiveness of our proposed scheme.","","","10.1109/TCC.2019.2930259","National Engineering Laboratory for Public Safety Risk Perception and Control by Big Data; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8769852","Internet of Things (IoT);blockchain;cloud mining;proof of work;dueling deep reinforcement learning","Blockchain;Cloud computing;Protocols;Peer-to-peer computing;Computer architecture;Resource management;Internet of Things","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Rich Features Embedding for Cross-modal Retrieval: A Simple Baseline","X. Fu; Y. Zhao; Y. Wei; Y. Zhao; S. Wei","Institute of Information Science, Beijing Jiaotong University, 47829 Beijing China 100044 (e-mail: xinfu@bjtu.edu.cn); Institute of Information Science, Beijing Jiaotong University, Beijing China 100044 (e-mail: yzhao@bjtu.edu.cn); Institute of Information Science, Beijing Jiaotong University, Beijing China 100044 (e-mail: wychao1987@gmail.com); Institute of Basic Research in Clinical Medicine, China Academy of Chinese Medical Sciences, Beijing China (e-mail: snowmanzhao@163.com); School of Computer and Information Technology, Institute of Information Science, Beijing, Beijing China 100044 (e-mail: shkwei@bjtu.edu.cn)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","During the past few years, significant progress has been made on cross-modal retrieval, benefiting from the development of deep neural networks. Meanwhile, the overall frameworks are becoming more and more complex, making the training as well as the analysis more difficult. In this paper, we provide a Rich Features Embedding (RFE) approach to tackle the cross-modal retrieval tasks in a simple yet effective way. RFE proposes to construct rich representations for both images and texts, which is further leveraged to learn the rich features embedding in the common space according to a simple hard triplet loss. Without any bells and whistles in constructing complex components, the proposed RFE is concise and easy to implement. More importantly, our RFE obtains state-of-the-art results on several popular benchmarks such as MS COCO and Flickr 30K. In particular, the image-to-text and text-to-image retrieval achieve 76.1% and 61.1% (R@1) on MS COCO, which outperform the others more than 3.4% and 2.3% respectively. We hope our RFE will serve as a solid baseline and help ease future research in cross-modal retrieval.","","","10.1109/TMM.2019.2957948","China Scholarship Council; National Basic Research Program of China (973 Program); National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8931635","Rich features embedding;image-text matching;deep representation learning;cross-modal retrieval","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Service-Oriented Permissioned Blockchain for the Internet of Things","C. Qiu; H. Yao; R. Yu; C. Jiang; S. Guo","College of intelligence and computing, school of Computer Science and Technology, Tianjin University, 12605 Tianjin, Tianjin China (e-mail: zjkchouchao@bupt.edu.cn); Information and Communication Engineering, Beijing University of Posts and Telecommunications, 12472 Beijing, Beijing China 100088 (e-mail: yaohaipeng@bupt.edu.cn); Systems and Computer Engineering, Carleton University, Ottawa, Ontario Canada K1S5B6 (e-mail: Richard.Yu@Carleton.ca); Space Center, Tsinghua University, 12442 Beijing, Beijing China 100084 (e-mail: jchx@tsinghua.edu.cn); Department of Computing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong China (e-mail: cssongguo@comp.polyu.edu.hk)","IEEE Transactions on Services Computing","","2019","PP","99","1","1","The emergence of blockchain has stirred great interests in the field of Internet of Things (IoT). However, numerous non-trivial problems in the blockchain prevent it from being used as a generic platform for large-scale services and applications in IoT. One notable drawback is the scalability problem. Lots of researches have been done to solve this problem. Nevertheless, they do not consider different users' conditions, only using a single consensus protocol as the best fit one, as well the IoT system is heavily constrained by computing and networking resources. In this paper, we study a permissioned blockchain-based IoT architecture. To improve the scalability of the blockchain system and meet the needs of different users, we propose a service-oriented permissioned blockchain, where different consensus protocols are launched according to users' quality of service (QoS) requirements. We quantify a few popular consensus protocols. We select block producers, which need a great number of computation resources, as well dynamically allocate network bandwidth to the blockchain system. We formulate consensus protocols selection, block producers selection, and network bandwidth allocation as a joint optimization problem. We use a dueling deep reinforcement learning approach to solve the problem. Simulation results demonstrate the effectiveness of our proposed scheme.","","","10.1109/TSC.2019.2948870","National Engineering Laboratory for Public Safety Risk Perception and Control by Big Data; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8880544","Internet of Things (IoT);permissioned blockchain;service-oriented;Byzantine fault tolerance;deep reinforcement learning","Quality of service;Internet of Things;Computational modeling;Scalability","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Machine Learning Approach to Road Surface Anomaly Assessment using Smartphone Sensors","A. Basavaraju; J. Du; F. Zhou; J. Ji","Department of Electrical Engineering, Texas A&M University, College Station, TX 77840 USA.; Department of Civil and Coastal Engineering, University of Florida, Gainesville, FL 32611 USA.; Texas A&M Transportation Institute, Texas A&M University, College Station, TX 77840 USA.; Department of Electrical Engineering, Texas A&M University, College Station, TX 77840 USA.","IEEE Sensors Journal","","2019","PP","99","1","1","Road surface quality is essential for improving driving experience and reducing traffic accidents. Traditional road condition monitoring systems are limited in their temporal (speed) and spatial (coverage) responses needed for maintaining overall road quality. Several alternative systems have been proposed that utilize sensors mounted on vehicles. In particular, with the ubiquitous use of smartphones for navigation, smartphone-based road condition assessment has emerged as a promising new approach. In this paper, we propose to analyze different multiclass supervised machine learning techniques to effectively classify road surface conditions using accelerometer, gyroscope and GPS data collected from smartphones. Our work focuses on classification of three main class labels-smooth road, potholes, and deep transverse cracks. We hypothesize that using features from all three axes of the sensors provides more accurate results as compared to using features from only one axis. We also investigate the performance of deep neural networks to classify road conditions with and without explicit manual feature extraction. Our results indicate that models trained with features from all axes of the smartphone sensors outperform models that use only one axis. We also observe that the use of neural networks provides a significantly improved data classification. The machine learning approach discussed here can be implemented on a larger scale to monitor roads for defects that present a safety risk to commuters as well as to provide maintenance information to relevant authorities.","","","10.1109/JSEN.2019.2952857","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8896015","Support Vector Machines;Neural Network;Multilayer perceptron;Decision Tree;Road Condition;Pavement Condition;Pothole;Crack;Smartphone Sensor;Accelerometer","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Residual Encoder-Decoder Conditional Generative Adversarial Network for Pansharpening","Z. Shao; Z. Lu; M. Ran; L. Fang; J. Zhou; Y. Zhang","College of Computer Science, Sichuan University, Chengdu 610065, China.; College of Computer Science, Sichuan University, Chengdu 610065, China.; College of Computer Science, Sichuan University, Chengdu 610065, China.; College of Electrical and Information Engineering, Hunan University, Changsha 410082, China (e-mail: yzhang@scu.edu.cn).; College of Computer Science, Sichuan University, Chengdu 610065, China.; College of Computer Science, Sichuan University, Chengdu 610065, China (e-mail: fangleyuan@gmail.com).","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","Due to the limitation of the satellite sensor, it is difficult to acquire a high-resolution (HR) multispectral (HRMS) image directly. The aim of pansharpening (PNN) is to fuse the spatial in panchromatic (PAN) with the spectral information in multispectral (MS). Recently, deep learning has drawn much attention, and in the field of remote sensing, several pioneering attempts have been made related to PNN. However, the big size of remote sensing data will produce more training samples, which require a deeper neural network. Most current networks are relatively shallow and raise the possibility of detail loss. In this letter, we propose a residual encoder-decoder conditional generative adversarial network (RED-cGAN) for PNN to produce more details with sharpened images. The proposed method combines the idea of an autoencoder with generative adversarial network (GAN), which can effectively preserve the spatial and spectral information of the PAN and MS images simultaneously. First, the residual encoder-decoder module is adopted to extract the multiscale features from the last step to yield pansharpened images and relieve the training difficulty caused by deepening the network layers. Second, to further enhance the performance of the generator to preserve more spatial information, a conditional discriminator network with the input of PAN and MS images is proposed to encourage that the estimated MS images share the same distribution as that of the referenced HRMS images. The experiments conducted on the Worldview2 (WV2) and Worldview3 (WV3) images demonstrate that our proposed method provides better results than several state-of-the-art PNN methods.","","","10.1109/LGRS.2019.2949745","National Natural Science Foundation of China; Sichuan Science and Technology Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8894479","Deep learning;generative adversarial network (GAN);multispectral (MS) image;panchromatic (PAN);pansharpening (PNN).","Feature extraction;Generative adversarial networks;Gallium nitride;Training;Generators;Task analysis;Decoding","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Very-Short-Term Probabilistic Forecasting for a Risk-Aware Participation in the Single Price Imbalance Settlement","J. Bottieau; L. Hubert; Z. De Grève; F. Vallée; J. Toubeau","Electrical Power Engineering Unit, Universite de Mons Faculte Polytechnique, 86818 Mons, Hainaut Belgium (e-mail: Jeremie.bottieau@umons.ac.be); Electrical Power Engineering Unit, Universite de Mons Faculte Polytechnique, 86818 Mons, Hainaut Belgium (e-mail: louis.hubert@student.umons.ac.be); Power Electrical Engineering, University of Mons, Mons, Hainaut Belgium B7000 (e-mail: zacharie.DEGREVE@umons.ac.be); Power Electrical Engineering, University of Mons, Mons, Hainaut Belgium B7000 (e-mail: Francois.VALLEE@umons.ac.be); Power Electrical Engineering, Faculty Polytechnique de l'University de Mons, Mons, Hainaut Belgium 7000 (e-mail: Jean-Francois.TOUBEAU@umons.ac.be)","IEEE Transactions on Power Systems","","2019","PP","99","1","1","The single imbalance pricing is an emerging mechanism in European electricity markets where all positive and negative imbalances are settled at a unique price. This real-time scheme thereby stimulates market participants to deviate from their schedule to restore the power system balance. However, exploiting this market opportunity is very risky due to the extreme volatility of the real-time power system conditions. In order to address this issue, we implement a new tailored deep-learning model, named encoder-decoder, to generate improved probabilistic forecasts of the imbalance signal, by efficiently capturing its complex spatio-temporal dynamics. The predicted distributions are then used to quantify and optimize the risk associated with the real-time participation of market players, acting as price-makers, in the imbalance settlement. This leads to an integrated forecast-driven strategy, modeled as a robust bilevel optimization. Results show that our probabilistic forecaster achieves better performance than other state of the art tools, and that the subsequent risk-aware robust dispatch tool allows finding a tradeoff between conservative and risk-seeking policies, leading to improved economic benefits. Moreover, we show that the model is computationally efficient and can thus be incorporated in the very-short-term dispatch of market players with flexible resources.","","","10.1109/TPWRS.2019.2940756","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8832203","Deep learning;electricity markets;encoderdecoder;robust optimization;single imbalance pricing","Probabilistic logic;Real-time systems;Optimization;Tools;Europe;Pricing;Power systems","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Coupled GAN with Relativistic Discriminators for Infrared and Visible Images Fusion","Q. Li; L. Lu; Z. Li; W. Wu; Z. Liu; G. Jeon; X. Yang","College of Electronics and Information Engineering, Sichuan University, Chengdu 610064, China.; College of Electronics and Information Engineering, Sichuan University, Chengdu 610064, China.; College of Electronics and Information Engineering, Sichuan University, Chengdu 610064, China.; College of Electronics and Information Engineering, Sichuan University, Chengdu 610064, China.; University of British Columbia (Okanagan), Kelowna, BC V1V 1V7, Canada.; School of Electronic Engineering, Xidian University, Xi’an 710071, China, and also with the Department of Embedded Systems Engineering, Incheon National University, Incheon 22012, South Korea.; College of Electronics and Information Engineering, Sichuan University, Chengdu 610064, China.","IEEE Sensors Journal","","2019","PP","99","1","1","Infrared and visible images are a pair of multi-source multi-sensors images. However, infrared images lack structural details and visible images are impressionable to the imaging environment. To fully utilize the meaningful information of infrared and visible images, a practical fusion method, termed as RCGAN, is proposed in this paper. In RCGAN, we introduce a pioneering use of the coupled generative adversarial network to the field of image fusion. Moreover, the simple yet efficient relativistic discriminator is applied to our network. By doing so, the network converges faster. More importantly, different from the previous works in which the label for generator is either infrared image or visible image, we innovatively put forward a strategy to use a pre-fused image as the label. This is a technical innovation, which makes the process of generating fused images no longer out of thin air, but from ‘existence’ to ‘excellent’. Extensive experiments demonstrate the proposed RCGAN can produce a faithful fused image, which can efficiently persevere the rich texture from visible images and thermal radiation information from infrared images. Compared with traditional methods, it successfully avoids complex manual designed fusion rules, and also shows clear advantages over other deep learning based fusion methods.","","","10.1109/JSEN.2019.2921803","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8733843","Image Fusion;Infrared image;Visible image;Coupled generative adversarial network;Relativistic discriminator;Deep learning","Generators;Generative adversarial networks;Gallium nitride;Sensors;Image fusion;Transforms;Infrared image sensors","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"MFQE 2.0: A New Approach for Multi-frame Quality Enhancement on Compressed Video","Z. Guan; Q. Xing; M. Xu; R. Yang; T. Liu; Z. Wang","School of Electronic and Information Engineering, Beihang Univ., Beijing 12633 Beijing, China (e-mail: guanzhenyu@buaa.edu.cn); School of Electronic and Information Engineering, Beihang Univ., Beijing 12633 Beijing China (e-mail: xingql@buaa.edu.cn); School of Electronic and Information Engineering, Beihang Univ., Beijing 12633 Beijing China (e-mail: MaiXu@buaa.edu.cn); School of Electronic and Information Engineering, Beihang Univ., Beijing 12633 Beijing China (e-mail: reyang@ee.ethz.ch); School of Electronic and Information Engineering, Beihang Univ., Beijing 12633 Beijing China (e-mail: liutie@buaa.edu.cn); EE, Beihang University, Beijing, Beijing China (e-mail: wzulin@buaa.edu.cn)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","The past few years have witnessed great success in applying deep learning to enhance the quality of compressed image/video. The existing approaches mainly focus on enhancing the quality of a single frame, not considering the similarity between consecutive frames. Since heavy fluctuation exists across compressed video frames as investigated in this paper, frame similarity can be utilized for quality enhancement of low-quality frames given their neighbouring high-quality frames. This task is Multi-Frame Quality Enhancement (MFQE). Accordingly, this paper proposes an MFQE approach for compressed video, as the first attempt in this direction. In our approach, we firstly develop a Bidirectional Long Short-Term Memory (BiLSTM) based detector to locate Peak Quality Frames (PQFs) in compressed video. Then, a novel Multi-Frame Convolutional Neural Network (MF-CNN) is designed to enhance the quality of compressed video, in which the non-PQF and its nearest two PQFs are the input. In MF-CNN, motion between the non-PQF and PQFs is compensated by a motion compensation subnet. Subsequently, a quality enhancement subnet fuses the non-PQF and compensated PQFs, and then reduces the compression artifacts of the non-PQF. Also, PQF quality is enhanced in the same way. Finally, experiments validate the effectiveness and generalization ability of our MFQE approach in advancing the state-of-the-art quality enhancement of compressed video.","","","10.1109/TPAMI.2019.2944806","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8855019","Quality enhancement;compressed video;deep learning","Transform coding;Image coding;Databases;MPEG 1 Standard;Task analysis;Video recording","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Adaptive Resource Allocation in Future Wireless Networks with Blockchain and Mobile Edge Computing","F. Guo; F. R. Yu; H. Zhang; H. Ji; M. Liu; V. C. M. Leung","Key Laboratory of Universal Wireless Communications, Ministry of Education, Beijing University of Posts and Telecommunications, Beijing, 100876, P.R. China.; Department Systems and Computer Engineering, Carleton University, Ottawa, ON K1S 5B6, Canada.; Key Laboratory of Universal Wireless Communications, Ministry of Education, Beijing University of Posts and Telecommunications, Beijing, 100876, P.R. China.; Key Laboratory of Universal Wireless Communications, Ministry of Education, Beijing University of Posts and Telecommunications, Beijing, 100876, P.R. China.; Key Laboratory of Space-ground Interconnection and Convergence, Beijing University of Posts and Telecommunications, Beijing, 100876, P.R. China.; Computer Science and Software Engineering, Shenzhen University, Shenzhen 518060, China, and also with the University of British Columbia, Vancouver, BC V6T 1Z4, Canada.","IEEE Transactions on Wireless Communications","","2019","PP","99","1","1","In this paper, we present a blockchain-based mobile edge computing (B-MEC) framework for adaptive resource allocation and computation offloading in future wireless networks, where the blockchain works as an overlaid system to provide management and control functions. In this framework, how to reach a consensus between the nodes while simultaneously guaranteeing the performance of both MEC and blockchain systems is a major challenge. Meanwhile, resource allocation, block size, and the number of consecutive blocks produced by each producer are critical to the performance of B-MEC. Therefore, an adaptive resource allocation and block generation scheme is proposed. To improve the throughput of the overlaid blockchain system and the quality of services (QoS) of the users in the underlaid MEC system, spectrum allocation, size of the blocks, and number of producing blocks for each producer are formulated as a joint optimization problem, where the time-varying wireless links and computation capacity of the MEC servers are considered. Since this problem is intractable using traditional methods, we resort to the deep reinforcement learning approach. Simulation results show the effectiveness of the proposed approach by comparing with other baseline methods.","","","10.1109/TWC.2019.2956519","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8928522","Mobile edge computing;Computation offloading;Blockchain;Deep reinforcement learning","Wireless networks;Resource management;Computational modeling;Task analysis;Adaptive systems","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Mobility Predictions for IoT Devices Using Gated Recurrent Unit Network","A. B. Adege; H. Lin; L. Wang","department of Electrical and Computer Engineering, National Taipei University of Technology, Taipei, Taiwan.; department of Electronic Engineering, National Taipei University of Technology, Taipei, Taiwan.; department of Electrical and Computer Engineering, National Chiao Tung University, Hsinchu 300-10, Taiwan.","IEEE Internet of Things Journal","","2019","PP","99","1","1","Wireless and mobile technologies, as well as their users, are growing rapidly as the Internet of things (IoT) products, such as sensor-network technologies, mobile devices, and supporting applications become widely dispersed. Owing to the dynamic changes in wireless networks and the exponential growth of IoT products, which make it difficult to locate large quantities of users and devices, providing accurate tracking and trajectory predictions in open and highly condensed wireless networks is extremely difficult. An adaptive and scalable system is required to offer accurate location-based services (LBS) for the success of IoT. To enhance the attainment of IoT, we propose a hybrid of a principal component analysis (PCA) and gated recurrent unit (GRU) algorithms for mobility predictions in a wireless urban area. During the system development processes, we first collect an LTE signal from three unmanned aerial vehicle base stations (UAV-BSs), the Wi-Fi signal strength from each reachable Wi-Fi access points (AP), and channel information from the Wi-Fi signal media. We then apply a PCA to reduce the number of Wi-Fi features and to decrease signal noise. Next, we train the GRU algorithm to develop models that can predict the mobility of IoT device users. Finally, we evaluate the tracking and trajectory models. To evaluate the proposed techniques, we compare the common parameters of the GRU with those of other deep learning types. The proposed technique provides plausible and state-of-the-art results for mobility predictions of IoT devices in a wireless environment.","","","10.1109/JIOT.2019.2948075","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8873637","Deep learning;mobility predictions;gated recurrent units;principal component analysis.","Internet of Things;Wireless fidelity;Wireless sensor networks;Wireless networks;Trajectory;Principal component analysis","","","","","","","","","","IEEE","IEEE Early Access Articles"
"ApGAN: Approximate GAN for Robust Low Energy Learning from Imprecise Components","A. Roohi; S. Sheikhfaal; S. Angizi; D. Fan; R. F. DeMara","Department of Electrical Engineering and Computer Science, University of Central Florida, Orlando, FL 32816-2362 USA, Orlando, Florida United States (e-mail: aroohi@utexas.edu); Electrical and Computer Engineering, University of Central Florida, Orlando, Florida United States 32816 (e-mail: shadi@knights.ucf.edu); Department of Electrical Engineering and Computer Science, University of Central Florida, Orlando, FL 32816-2362 USA, Orlando, Florida United States (e-mail: angizi@Knights.ucf.edu); Electrical and Computer Engineering, University of Central Florida, 6243 Orlando, Florida United States 32816 (e-mail: dfan@asu.edu); Electrical Engineering and Computer Science, University of Central Florida, Orlando, Florida United States 32816-2362 (e-mail: ronald.demara@ucf.edu)","IEEE Transactions on Computers","","2019","PP","99","1","1","A Generative Adversarial Network (GAN) is an adversarial learning approach that empowers conventional deep learning methods by alleviating the demands of massive labeled datasets. However, GAN training can be computationally-intensive limiting its feasibility in resource-limited edge devices. In this paper, we propose an approximate GAN (ApGAN) for accelerating GANs from both algorithm and hardware implementation perspectives. First, inspired by the binary pattern feature extraction method along with binarized representation entropy, the existing Deep Convolutional GAN (DCGAN) algorithm is modified by binarizing the weights for a specific portion of layers within both the generator and discriminator models. Further reduction in storage and computation resources is achieved by leveraging a novel hardware-configurable in-memory addition scheme, which can operate in the accurate and approximate modes. Finally, a memristor-based processing-in-memory accelerator for ApGAN is developed. The performance of the ApGAN accelerator on different data-sets such as Fashion-MNIST, CIFAR-10, STL-10, and celeb-A is evaluated and compared with recent GAN accelerator designs. With almost the same Inception Score (IS) to the baseline GAN, the ApGAN accelerator can increase the energy-efficiency by ~28.6X achieving 35-fold speedup compared with a baseline GPU platform. Additionally, it shows 2.5X and 5.8X higher energy-efficiency and speedup over CMOS-ASIC accelerator subject to an 11% reduction in IS.","","","10.1109/TC.2019.2949042","Semiconductor Research Corporation; Division of Computing and Communication Foundations; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8880521","Generative adversarial network;in-memory processing platform;neural network acceleration;hardware mapping","Gallium nitride;Training;Generative adversarial networks;Random access memory;Hardware;Generators;Computational modeling","","","","","","","","","","IEEE","IEEE Early Access Articles"
"REVAMP2T: Real-time Edge Video Analytics for Multi-camera Privacy-aware Pedestrian Tracking","C. Neff; M. Mendieta; S. Mohan; M. Baharani; S. Rogers; H. Tabkhi","Electrical and Computer Engineering Department, The University of North Carolina at Charlotte, Charlotte, NC, 28223 USA.; Electrical and Computer Engineering Department, The University of North Carolina at Charlotte, Charlotte, NC, 28223 USA.; Electrical and Computer Engineering Department, The University of North Carolina at Charlotte, Charlotte, NC, 28223 USA.; Electrical and Computer Engineering Department, The University of North Carolina at Charlotte, Charlotte, NC, 28223 USA.; Electrical and Computer Engineering Department, The University of North Carolina at Charlotte, Charlotte, NC, 28223 USA.; Electrical and Computer Engineering Department, The University of North Carolina at Charlotte, Charlotte, NC, 28223 USA.","IEEE Internet of Things Journal","","2019","PP","99","1","1","This article presents REVAMP2T, Real-time Edge Video Analytics for Multi-camera Privacy-aware Pedestrian Tracking, as an integrated end-to-end IoT system for privacy-built-in decentralized situational awareness. REVAMP2T presents novel algorithmic and system constructs to push deep learning and video analytics next to IoT devices (i.e. video cameras). On the algorithm side, REVAMP2T proposes a unified integrated computer vision pipeline for detection, re-identification, and tracking across multiple cameras without the need for storing the streaming data. At the same time, it avoids facial recognition, and tracks and re-identifies pedestrians based on their key features at runtime. On the IoT system side, REVAMP2T provides infrastructure to maximize hardware utilization on the edge, orchestrates global communications, and provides system-wide re-identification, without the use of personally identifiable information, for a distributed IoT network. For the results and evaluation, this article also proposes a new metric, Accuracy∙Efficiency (AE), for holistic evaluation of IoT systems for real-time video analytics based on accuracy, performance, and power efficiency. REVAMP2T outperforms current state-of-the-art by as much as thirteen-fold improvement.","","","10.1109/JIOT.2019.2954804","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8907426","Edge Computing;Video Analytics;Deep Learning;Re-identification;Pedestrian Tracking;Privacy.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Temporal-Spatial Mapping for Action Recognition","X. Song; C. Lan; W. Zeng; J. Xing; X. Sun; J. Yang","School of Electrical and Information Engineering, Tianjin University, Tianjin 300072, China.; Microsoft Research Asia, Beijing 100080, China.; Microsoft Research Asia, Beijing 100080, China.; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China.; Microsoft Research Asia, Beijing 100080, China.; School of Electrical and Information Engineering, Tianjin University, Tianjin 300072, China.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Deep learning models have enjoyed great success for image related computer vision tasks like image classification and object detection. For video related tasks like human action recognition, however, the advancements are not as significant yet. The main challenge is the lack of effective and efficient models in modeling the rich temporal spatial information in a video. We introduce a simple yet effective operation, termed Temporal-Spatial Mapping (TSM), for capturing the temporal evolution of the frames by jointly analyzing all the frames of a video. We propose a video level 2D feature representation by transforming the convolutional features of all frames to a 2D feature map, referred to as VideoMap. With each row being the vectorized feature representation of a frame, the temporalspatial features are compactly represented, while the temporal dynamic evolution is also well embedded. Based on the VideoMap representation, we further propose a temporal attention model within a shallow convolutional neural network to efficiently exploit the temporal-spatial dynamics. The experiment results show that the proposed scheme achieves the state-of-the-art performance, with 4.2% accuracy gain over Temporal Segment Network (TSN), a competing baseline method, on the challenging human action benchmark dataset HMDB51.","","","10.1109/TCSVT.2019.2896029","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8630593","Temporal-Spatial Mapping (TSM);action recognition;deep learning","Two dimensional displays;Three-dimensional displays;Feature extraction;Optical imaging;Computational modeling;Streaming media;Kernel","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A novel multi-agent DDQN-AD method-based distributed strategy for automatic generation control of integrated energy systems","L. Xi; L. Yu; Y. Xu; S. Wang; X. Chen","Yichang China 443000 (e-mail: xilei2014@163.com); Yichang, hubei China (e-mail: yushuizhilu@163.com); College of Electrical Engineering and New Energy, University of China Three Gorges, Yichang, Hubei Province China (e-mail: xyc7309@163.com); School of Electrical Engineering and Information Engineering, Tianjin University, Tianjin City China 300072 (e-mail: sxwang@tju.edu.cn); Guangzhou China 510641 (e-mail: xichen_1021@hotmail.com)","IEEE Transactions on Sustainable Energy","","2019","PP","99","1","1","The widely adoption of distributed renewable energy sources (DREs) effectively reduces carbon emission and beat atmospheric haze in developing countries. However, random disturbance issues emerge in power grids with DREs when applying traditional centralized automatic generation control (AGC) strategies. Therefore, a multi-agent distributed control strategy is proposed for AGC in this work, which is mainly based on the concept of deep reinforcement learning, and developed by the strategy of action discovery. Moreover, area control error and the amount of carbon emission are employed in reward functions to obtain optimal solutions in the implementing process of the proposed strategy. Simulations are provided in the work to show the effectiveness of the strategy, while comparisons are also offered, where the simulating results obtained by two other intelligent AGC algorithms are used as references, according to which, the superiority of the proposed strategy is confirmed.","","","10.1109/TSTE.2019.2958361","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8928960","Deep reinforcement learning;Automatic generation control;Action discovery strategy;Multi-agent DDQN-AD method","Automatic generation control;Power grids;Heuristic algorithms;Real-time systems;Power system dynamics;Frequency control;Neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Multistage GAN for Fabric Defect Detection","J. Liu; C. Wang; H. Su; B. Du; D. Tao","School of Printing and Packaging, Artificial Intelligence Institute, Wuhan University, Wuhan, China, with the UBTECH Sydney Artificial Intelligence Centre, School of Computer Science, Faculty of Engineering and Information Technologies, The University of Sydney, Darlington, NSW, Australia, and also with the Suzhou Institute, Wuhan University, Suzhou, China.; UBTECH Sydney Artificial Intelligence Centre, School of Computer Science, Faculty of Engineering and Information Technologies, The University of Sydney, Darlington, NSW, Australia.; School of Software, South China Normal University, Guangzhou, China.; National Engineering Research Center for Multimedia Software, Institute of Artificial Intelligence and School of Computer Science, Wuhan University, Wuhan, China.; UBTECH Sydney Artificial Intelligence Centre, School of Computer Science, Faculty of Engineering and Information Technologies, The University of Sydney, Darlington, NSW, Australia.","IEEE Transactions on Image Processing","","2019","PP","99","1","1","Fabric defect detection is an intriguing but challenging topic. Many methods have been proposed for fabric defect detection, but these methods are still suboptimal due to the complex diversity of both fabric textures and defects. In this paper, we propose a generative adversarial network (GAN)-based framework for fabric defect detection. Considering existing challenges in real-world applications, the proposed fabric defect detection system is capable of learning existing fabric defect samples and automatically adapting to different fabric textures during different application periods. Specifically, we customize a deep semantic segmentation network for fabric defect detection that can detect different defect types. Furthermore, we attempted to train a multistage GAN to synthesize reasonable defects in new defect-free samples. First, a texture-conditioned GAN is trained to explore the conditional distribution of defects given different texture backgrounds. Given a novel fabric, we aim to generate reasonable defective patches. Then, a GAN-based fusion network fuses the generated defects to specific locations. Finally, the well-trained multistage GAN continuously updates the existing fabric defect datasets and contributes to the fine-tuning of the semantic segmentation network to better detect defects under different conditions. Comprehensive experiments on various representative fabric samples are conducted to verify the detection performance of our proposed method.","","","10.1109/TIP.2019.2959741","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8937049","Fabric defect detection;deep learning;semantic segmentation;generative adversarial network","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"DeepVolume: Brain Structure and Spatial Connection-Aware Network for Brain MRI Super-Resolution","Z. Li; J. Yu; Y. Wang; H. Zhou; H. Yang; Z. Qiao","Department of Electronic Engineering, Fudan University, Shanghai 200433, China.; Department of Electronic Engineering, Fudan University, Shanghai 200433, China, also with the Institute of Functional and Molecular Medical Imaging, Fudan University, Shanghai 200433, China, and also with the Key Laboratory of Medical Imaging Computing and Computer Assisted Intervention, Shanghai 200433, China.; Department of Electronic Engineering, Fudan University, Shanghai 200433, China, also with the Institute of Functional and Molecular Medical Imaging, Fudan University, Shanghai 200433, China, and also with the Key Laboratory of Medical Imaging Computing and Computer Assisted Intervention, Shanghai 200433, China (e-mail: yywang@fudan.edu.cn).; Department of Electronic Engineering, Fudan University, Shanghai 200433, China.; Department of Radiology, Children's Hospital of Fudan University, Shanghai 201102, China.; Department of Radiology, Children's Hospital of Fudan University, Shanghai 201102, China (e-mail: zqiao@fudan.edu.cn).","IEEE Transactions on Cybernetics","","2019","PP","99","1","14","Thin-section magnetic resonance imaging (MRI) can provide higher resolution anatomical structures and more precise clinical information than thick-section images. However, thin-section MRI is not always available due to the imaging cost issue. In multicenter retrospective studies, a large number of data are often in thick-section manner with different section thickness. The lack of thin-section data and the difference in section thickness bring considerable difficulties in the study based on the image big data. In this article, we introduce DeepVolume, a two-step deep learning architecture to address the challenge of accurate thin-section MR image reconstruction. The first stage is the brain structure-aware network, in which the thick-section MR images in axial and sagittal planes are fused by a multitask 3-D U-net with prior knowledge of brain volume segmentation, which encourages the reconstruction result to have correct brain structure. The second stage is the spatial connection-aware network, in which the preliminary reconstruction results are adjusted slice-by-slice by a recurrent convolutional network embedding convolutional long short-term memory (LSTM) block, which enhances the precision of the reconstruction by utilizing the previously unassessed sagittal information. We used 305 paired brain MRI samples with thickness of 1.0 mm and 6.5 mm in this article. Extensive experiments illustrate that DeepVolume can produce the state-of-the-art reconstruction results by embedding more anatomical knowledge. Furthermore, considering DeepVolume as an intermediate step, the practical and clinical value of our method is validated by applying the brain volume estimation and voxel-based morphometry. The results show that DeepVolume can provide much more reliable brain volume estimation in the normalized space based on the thick-section MR images compared with the traditional solutions.","","","10.1109/TCYB.2019.2933633","National Natural Science Foundation of China; National Basic Research Program of China (973 Program); Shanghai Shenkang Hospital Development Center Clinical Auxiliary Capacity Imaging Medicine Construction; Shanghai Science and Technology Committee; Shanghai Municipal Health Commission; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8820143","Brain volume estimation;deep learning;magnetic resonance imaging (MRI) super-resolution;thick-section MRI","Magnetic resonance imaging;Brain;Image reconstruction;Volume measurement;Biomedical imaging","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Color Transferred Convolutional Neural Networks for Image Dehazing","J. Yin; Y. Huang; B. Chen; S. Ye","Department of Computer Science and Engineering, Yuan Ze University, and also with the Innovation Center for Big Data and Digital Convergence, Yuan Ze University, Taoyuan 320, Taiwan.; College of Mathematics and Computer Science, Fuzhou University, Fuzhou, 350116, China, and also with the Department of Computer Science and Engineering, Yuan Ze University, Taoyuan 320, Taiwan.; Department of Computer Science and Engineering, Yuan Ze University, and also with the Innovation Center for Big Data and Digital Convergence, Yuan Ze University, Taoyuan 320, Taiwan.; College of Mathematics and Computer Science, Fuzhou University, Fuzhou, 350116, China.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Image dehazing is a crucial image processing step for outdoor vision systems. However, images recovered through conventional image dehazing methods that use either haze-relevant priors or heuristic cues to estimate transmission maps may not lead to sufficiently accurate haze removal from single images. The most commonly observed effects are darkened and brightened artifacts on some areas of the recovered images, which cause considerable loss of fidelity, brightness, and sharpness. This study develops a variational image dehazing method on the basis of a color-transfer image dehazing model that is superior to conventional image dehazing methods. By creating a color-transfer image dehazing model to remove haze obscuration and acquire information regarding the coefficients of the model by using the devised convolutional neural network based deep framework as a supervised learning strategy, an imageb’s fidelity, brightness, and sharpness can be effectively restored. Experimental results verify through quantitative and qualitative evaluations of either synthesized or real haze images that the proposed method outperforms existing single image dehazing methods.","","","10.1109/TCSVT.2019.2917315","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8716692","Image dehazing;color transfer;deep learning","Atmospheric modeling;Image color analysis;Integrated circuit modeling;Estimation;Standards;Computational modeling","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Load Disaggregation Using One-Directional Convolutional Stacked Long Short-Term Memory Recurrent Neural Network","Y. T. Quek; W. L. Woo; T. Logenthiran","Newcastle University—School of Electrical and Electronic Engineering, SIT Building @ Nanyang Polytechnic, 567739 Singapore (e-mail: q.yang-thee@newcastle.ac.uk).; Newcastle University—School of Electrical and Electronic Engineering, SIT Building @ Nanyang Polytechnic, 567739 Singapore (e-mail: Lok.Woo@newcastle.ac.uk).; Newcastle University—School of Electrical and Electronic Engineering, SIT Building @ Nanyang Polytechnic, 567739 Singapore (e-mail: t.logenthiran@newcastle.ac.uk).","IEEE Systems Journal","","2019","PP","99","1","10","Reliable information about the active loads in the energy system allows for effective and optimized energy management. An important aspect of intelligent energy monitoring system is load disaggregation. The proliferation of direct current (dc) loads has spurred the increasing research interest in extra low voltage (ELV) dc grids. Artificial intelligence, such as deep learning algorithms of stacked recurrent neural network (RNN), improved results on a variety of regression and classification tasks. This paper proposes a 1-D convolutional stacked long short-term memory RNN technique for the bottom-up approach in load disaggregation using single sensor multiple loads ELV dc picogrids. This eliminates the requirement for communication and intelligence on every load in the grid. The proposed technique was applied on two different dc picogrids to test the algorithm's robustness. The proposed technique produced excellent result of over 98% accuracy for smart loads and over 99% accuracy for dumb loads in ELV dc picogrid.","","","10.1109/JSYST.2019.2919668","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8746133","Artificial intelligence;deep learning;direct current (dc) picogrid;energy management;energy monitoring;load disaggregation;long short-term memory (LSTM);neural network application","Home appliances;Monitoring;Feature extraction;Microgrids;Recurrent neural networks;Energy management","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Automatic Diagnosis Based on Spatial Information Fusion Feature for Intracranial Aneurysm","Y. Zeng; X. Liu; N. Xiao; Y. Li; Y. Jiang; J. Feng; S. Guo","School of Life Science, Beijing Institute of Technology, Beijing, China.; Department of Interventional Neuroradiology, Beijing Neurosurgical Institute and Beijing Tiantan Hospital, Capital Medical University, Beijing, China.; School of Life Science, Beijing Institute of Technology, Beijing, China.; Department of Interventional Neuroradiology, Beijing Neurosurgical Institute and Beijing Tiantan Hospital, Capital Medical University, Beijing, China.; Department of Interventional Neuroradiology, Beijing Neurosurgical Institute and Beijing Tiantan Hospital, Capital Medical University, Beijing, China.; Department of Interventional Neuroradiology, Beijing Neurosurgical Institute and Beijing Tiantan Hospital, Capital Medical University, Beijing, China.; School of Life Science, Beijing Institute of Technology, Beijing, China, and Faculty of Engineering, Kagawa University, 2217-20 Hayashi-cho, Takamatsu, Kagawa, Japan.","IEEE Transactions on Medical Imaging","","2019","PP","99","1","1","Timely and accurate auxiliary diagnosis of intracranial aneurysm can help radiologist make treatment plans quickly, saving lives and cutting costs at the same time. At present Digital Subtraction Angiography (DSA) is the gold standard for the diagnosis of intracranial aneurysm, but as radiologists interpret those imaging sequences frame by frame, misdiagnosis might occur. The utilization of computer-assisted diagnosis (CAD) can ease the burdens of radiologists and improve the detection accuracy of aneurysms. In this paper, a deep learning method is applied to detect the intracranial aneurysm in 3D Rotational Angiography (3D-RA) based on a spatial information fusion (SIF) method, and in stead of 3D vascular model, 2D image sequences are used. Given the intracranial aneurysm and vascular overlap having similar feature in the most time, rather than focusing on distinguishing them in one frame, the morphological differences between frames are considered as major feature. In the training data, consecutive frames of every imaging time series are extracted and concatenated in a specific way, so that the spatial contextual information could be embedded into a single twodimensional image. This method enables the time series with obvious correlation between frames be directly trained on 2D convolutional neural network (CNN), instead of 3D-CNN with huge computational cost. Finally, we got an accuracy of 98.89%, with sensitivity and specificity of 99.38% and 98.19% respectively, which proves the feasibility and availability of the SIF feature.","","","10.1109/TMI.2019.2951439","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8890930","Intracranial aneurysm;computer-assisted diagnosis;spatial information fusion;deep learning","Aneurysm;Three-dimensional displays;Angiography;Sensitivity;Two dimensional displays","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Smart and Resilient EV Charging in SDN-Enhanced Vehicular Edge Computing Networks","J. Liu; H. Guo; J. Xiong; N. Kato; J. Zhang; Y. Zhang","School of Cybersecurity, Northwestern Polytechnical University, Xi’an 710072, China.; School of Cybersecurity, Northwestern Polytechnical University, Xi’an 710072, China.; School of Cyber Engineering, Xidian University, Xi’an 710071, China.; Graduate School of Information Sciences, Tohoku University, Sendai 9808579, Japan.; School of Cyber Engineering, Xidian University, Xi’an 710071, China.; School of Cybersecurity, Northwestern Polytechnical University, Xi’an 710072, China.","IEEE Journal on Selected Areas in Communications","","2019","PP","99","1","1","Smart grid delivers power with two-way flows of electricity and information with the support of information and communication technologies. Electric vehicles (EVs) with rechargeable batteries can be powered by external sources of electricity from the grid, and thus charging scheduling that guides low-battery EVs to charging services is significant for service quality improvement of EV drivers. The revolution of communications and data analytics driven by massive data in smart grid brings many challenges as well as chances for EV charging scheduling, and how to schedule EV charging in a smart and resilient way has inevitably become a crucial problem. Toward this end, we in this paper leverage the techniques of software defined networking and vehicular edge computing to investigate a joint problem of fast charging station selection and EV route planning. Our objective is to minimize the total overhead from users’ perspective, including time and charging fares in the whole process, considering charging availability and electricity price fluctuation. A deep reinforcement learning (DRL) based solution is proposed to determine an optimal charging scheduling policy for low-battery EVs. Besides, in response to dynamic EV charging, we further develop a resilient EV charging strategy based on incremental update, with EV drivers’ user experience being well considered. Extensive simulations demonstrate that our proposed DRL-based solution obtains near-optimal EV charging overhead with good adaptivity, and the solution with incremental update achieves much higher computation efficiency than conventional game-theoretical method in dynamic EV charging.","","","10.1109/JSAC.2019.2951966","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8892573","Smart grid;electric vehicle;charging scheduling;vehicular edge computing;deep reinforcement learning","Electric vehicle charging;Processor scheduling;Edge computing;Dynamic scheduling;Batteries;Vehicle dynamics","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Mechanism Design for Wireless Powered Spatial Crowdsourcing Networks","Y. Jiao; P. Wang; D. Niyato; B. Lin; D. I. Kim","School of Computer Science and Engineering, Nanyang Technological University, Singapore, Singapore Singapore (e-mail: YJIAO001@e.ntu.edu.sg); Lassonde School of Engineering, York University, 7991 Toronto, Ontario Canada (e-mail: pingw@yorku.ca); School of Computer Engineering, Nanyang Technological University, Singapore, Singapore Singapore 639798 (e-mail: DNIYATO@ntu.edu.sg); Dalian, Liaoning China 16026 (e-mail: binlin@dlmu.edu.cn); School of Info/Comm Engineering, Sungkyunkwan University (SKKU), Suwon-city, Gyeonggi-do Korea (the Republic of) 440-746 (e-mail: dikim@skku.ac.kr)","IEEE Transactions on Vehicular Technology","","2019","PP","99","1","1","Wireless power transfer (WPT) is a promising technology to prolong the lifetime of the sensors and communication devices, i.e., workers, in completing crowdsourcing tasks by providing continuous and cost-effective energy supplies. In this paper, we propose a wireless powered spatial crowdsourcing framework which consists of two mutually dependent phases: task allocation phase and data crowdsourcing phase. In the task allocation phase, we propose a Stackelberg game based mechanism for the spatial crowdsourcing platform to efficiently allocate spatial tasks and wireless charging power to each worker. In the data crowdsourcing phase, the workers may have an incentive to misreport its real working location to improve its own utility, which causes adverse effects to the spatial crowdsourcing platform. To address this issue, we present three strategyproof deployment mechanisms for the spatial crowdsourcing platform to place a mobile base station, e.g., vehicle or robot, which is responsible for transferring the wireless power and collecting the crowdsourced data. As the benchmark, we first apply the classical median mechanism and evaluate its worst-case performance. Then, we design a conventional strategyproof deployment mechanism to improve the expected utility of the spatial crowdsourcing platform under the condition that the workers' locations follow a known geographical distribution. For a more general case with only the historical location data available, we propose a deep learning based strategyproof deployment mechanism with the aim to maximize the spatial crowdsourcing platform's utility. Extensive experimental results based on synthetic and real-world datasets reveal the effectiveness of the proposed framework in allocating tasks and charging power to workers while avoiding the dishonest worker's manipulation.","","","10.1109/TVT.2019.2952926","National Research Foundation of Korea; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8895988","Spatial crowdsourcing;deep learning;wireless power transfer;facility location;generalized median mechanism;automated mechanism design","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Preterm infants' pose estimation with spatio-temporal features","S. Moccia; L. Migliorelli; V. Carnielli; E. Frontoni","Department of Information Engineering, Universite Politecnica delle Marche, 9294 Ancona, Marche Italy (e-mail: sara.moccia@polimi.it); Department of Information Engineering, Universite Politecnica delle Marche, 9294 Ancona, Marche Italy (e-mail: l.migliorelli@pm.univpm.it); Department of Neonatology, Universite Politecnica delle Marche, 9294 Ancona, Marche Italy (e-mail: virgilio.carnielli@ospedaliriuniti.marche.it); Department of Information Engineering, Universite Politecnica delle Marche, 9294 Ancona, Marche Italy (e-mail: e.frontoni@staff.univpm.it)","IEEE Transactions on Biomedical Engineering","","2019","PP","99","1","1","Objective. Preterm infants' limb monitoring in neonatal intensive care units (NICUs) is of primary importance for assessing infants' health status and motor/cognitive development. Herein, we propose a new approach to preterm-infants' limb pose estimation that features spatio-temporal information to detect and track limb joint position from depth videos with high reliability. Methods. Limb-pose estimation is performed using a deep-learning framework consisting of a detection and a regression convolutional neural network (CNN) for rough and precise joint localization, respectively. The CNNs are implemented to encode connectivity in the temporal direction through 3D convolution. Assessment of the proposed framework is performed through a comprehensive study with sixteen depth videos acquired in the actual clinical practice from sixteen preterm infants. Results. When applied to pose estimation, the median root mean square distance, computed among all limbs, between the estimated and the ground-truth limb pose was 9.30 pixels, overcoming approaches based on spatial features only (11.10 pixels). Conclusion. Results showed that the spatio-temporal features had a significant influence on the pose-estimation performance, especially in challenging cases (e.g., homogeneous image intensity). Significance. This paper significantly enhances the state of art in automatic assessment of preterm-infants' health status by introducing the use of spatio-temporal features for limb-pose detection and tracking, and by being the first study to use depth videos acquired in the actual clinical practice for limb-pose estimation. Our dataset (the babyPose dataset) has been released as the first annotated dataset for infants' pose estimation.","","","10.1109/TBME.2019.2961448","POR MARCHE FESR 2014-2020; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8938758","Preterm infants;spatio-temporal features;deep learning;pose estimation;convolutional neural networks","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Global and Local Enhanced Residual U-Net for Accurate Retinal Vessel Segmentation","S. Lian; L. Li; G. Lian; X. Xiao; Z. Luo; S. Li","Cognitive Science Department, Xiamen University, 12466 Xiamen, Fujian China (e-mail: lancerlian@stu.xmu.edu.cn); Cognitive Science Department, Xiamen University, 12466 xiamen, Fujian China (e-mail: lilei@stu.xmu.edu.cn); College of Mathematics and Informatics, Fujian Normal University, 12425 Fuzhou, Fujian China (e-mail: lz567@fjnu.edu.cn); Cognitive Science Department, Xiamen University, 12466 xiamen, Fujian China (e-mail: 6487888499@qq.com); Postdoc Center of Information and Communication Engineering, Xiamen University, 12466 Xiamen, Fujian China 361005 (e-mail: zhiming.luo@xmu.edu.cn); Cognitive Science Department, Xiamen University, 12466 xiamen, Fujian China (e-mail: szlig@xmu.edu.cn)","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2019","PP","99","1","1","Retinal vessel segmentation is a critical procedure towards the accurate visualization, diagnosis, early treatment and surgery planning of ocular diseases. Recent deep learning-based approaches have achieved impressive performance in retinal vessel segmentation. However, they usually apply global image pre-processing and take the whole retinal images as input during network training, which have two drawbacks for accurate retinal vessel segmentation. First, these methods lack the utilization of the local patch information. Second, they overlook the geometric constraint that retina only occurs in a specific area within the whole image or the extracted patch. As a consequence, these global-based methods suffer in handling details, such as recognizing the small thin vessels, discriminating the optic disk, etc. To address these drawbacks, this study proposes a Global and Local enhanced residual U-nEt (GLUE) for accurate retinal vessel segmentation, which benefits from both the globally and locally enhanced information inside the retinal region. Experimental results on two benchmark datasets demonstrate the effectiveness of the proposed method, which consistently improves the segmentation accuracy over a conventional U-Net and achieves competitive performance compared to the state-of-the-art.","","","10.1109/TCBB.2019.2917188","China Postdoctoral Science Foundation; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8716304","Retinal Vessel Segmentation;Deep Learning;Weighted Res-UNet;Global and Local Enhance","Retinal vessels;Image segmentation;Task analysis;Biomedical imaging;Computational modeling;Diseases","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Real-time Single-Stage Vehicle Detector Optimized by Multi-Stage Image-based Online Hard Example Mining","C. Lin; S. Chen; P. S. Santoso; H. Lin; S. Lai","Computer Science, National Tsing Hua University, 34881 Hsinchu, Taiwan Taiwan (e-mail: alexofntu@gmail.com); Computer Science, National Tsing Hua University, 34881 Hsinchu, Taiwan Taiwan (e-mail: scarletclaw24@gmail.com); Industrial Technology Research Institute, 63129 Hsinchu, Taiwan Taiwan (e-mail: sherrylsantoso@itri.org.tw); Computer Science, National Tsing Hua University, 34881 Hsinchu, Taiwan Taiwan (e-mail: vtsh.jn@gmail.com); National Tsing Hua University, 34881 Hsinchu, Taiwan Taiwan (e-mail: lai@cs.nthu.edu.tw)","IEEE Transactions on Vehicular Technology","","2019","PP","99","1","1","Vehicle detection is a fundamental function required for advanced driver assistance systems. Extensive research has shown that good performance can be obtained on public datasets by various state-of-the-art approaches, especially the deep learning methods. However, those methods are mostly two-stage approaches which inevitably require extensive computing resources and are hard to be deployed on an embedded computing platform with real-time computing performance. We introduce a single-stage vehicle detector which can work in real-time on NVIDIA DrivePX2 platform. The main contributions of this paper are threefold. We propose a detection scheme which includes multi-scale features and multi-anchor boxes to improve the accuracy of a single-stage detector. Secondly, a new data augmentation strategy is proposed to systematically generate a lot of vehicle training images whose appearances are randomly truncated, so our detector is trained to detect partially-seen vehicles better. Thirdly, we present a multi-stage image-based online hard example mining (MSI-OHEM) framework specifically designed for single-stage detectors. MSI-OHEM performs fine-tuning on hard examples and the ones with slightly-insufficient IOU that are considered true positives. Compared to other classical object detectors, the proposed detector achieves very competitive result in terms of average precision (AP) and computational speed. For the newly-defined vehicle class (car+bus) on VOC2007 test, our detector, using MobileNetV2, GoogLeNet, Inception-v2 and ResNet-50 as basenets, achieves 85.35%/85.62%/86.49%/87.81% AP and runs at 64/58/48/28 FPS on NVIDIA DrivePX2, respectively.","","","10.1109/TVT.2019.2961625","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8939461","Deep Learning;vehicle detection;Convolutional Neural Networks (CNN);bootstrapping;hard negative mining","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Detection and Monitoring of Thermal Lesions Induced by Microwave Ablation Using Ultrasound Imaging and Convolutional Neural Networks","S. Zhang; S. Wu; S. Shang; X. Qin; X. Jia; D. Li; Z. Cui; T. Xu; G. Niu; A. Bouakaz; M. Wan","Biomedical engineering, Xi'an Jiaotong University, 12480 Xi'an, Shaanxi China (e-mail: xjtusyzhang@mail.xjtu.edu.cn); Biomedical engineering, Xi'an Jiaotong University, 12480 Xi'an, Shaanxi China (e-mail: wushan212@stu.xjtu.edu.cn); Biomedical engineering, Xi'an Jiaotong University, 12480 Xi'an, Shaanxi China (e-mail: sqshang1993@outlook.com); Biomedical engineering, Xi'an Jiaotong University, 12480 Xi'an, Shaanxi China (e-mail: qinxuewei3104@gmail.com); Biomedical engineering, Xi'an Jiaotong University, 12480 Xi'an, Shaanxi China (e-mail: 1910177619@qq.com); Biomedical engineering, Xi'an Jiaotong University, 12480 Xi'an, Shaanxi China (e-mail: ldpldp@stu.xjtu.edu.cn); Biomedical engineering, Xi'an Jiaotong University, 12480 Xi'an, Shaanxi China (e-mail: cui.zh.w@stu.xjtu.edu.cn); Biomedical engineering, Xian Jiaotong University, 12480 Xi'an, Shaanxi China (e-mail: xutianqi@stu.xjtu.edu.cn); Department of Radiology, First Affiliated Hospital of Xi'an Jiaotong University, Xi'an, Shaanxi China (e-mail: niugang369@mail.xjtu.edu.cn); Universite de Tours, Tours France (e-mail: ayache.bouakaz@univ-tours.fr); Biomedical engineering, Xi'an Jiaotong University, 12480 Xi'an, Shaanxi China (e-mail: mxwan@mail.xjtu.edu.cn)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","Microwave ablation (MWA) for cancer treatment is frequently monitored by ultrasound (US) B-mode imaging in the clinic, which often fails due to the low intrinsic contrast between the thermal lesion and normal tissue. Deep learning, especially convolutional neural network (CNN), has shown significant improvements in medical image analysis. Here, we propose and evaluate an US imaging based on a CNN architecture for the detection and monitoring of thermal lesions induced by MWA in porcine livers. Unlike dealing with images in many visual object recognition tasks, US radiofrequency (RF) data backscattered from the ablated region were utilized to capture features related to the thermal lesion. The dataset comprised of 1640 US RF envelope data matrices and their corresponding gross-pathology images, and were utilized for training and testing. After envelope detection, US B-mode, segmentation results based on CNN ($\text{SI}_{\text{CNN}}$), and modified CNN ($\text{SI}_{\text{m-CNN}}$) for US data were simultaneously reconstructed to reveal the suitability for monitoring of MWA. The $\text{SI}_{\text{CNN}}$ and $\text{SI}_{\text{m-CNN}}$ outperformed B-mode images for the detection and monitoring of MWA-induced thermal lesions. The values of the area under the receiver operating characteristic curve were 0.8728 and 0.8948 for the $\text{SI}_{\text{CNN}}$ and $\text{SI}_{\text{m-CNN}}$, respectively, which were both higher than the value of 0.6904 for B-mode images. Ablated regions that were assessed using $\text{SI}_{\text{m-CNN}}$ showed a good correlation (J 0.8845, $r$ 0.8739, and E 0.410) to gross-pathology images. This study was the first to illustrate that $\text{SI}_{\text{m-CNN}}$ has the potential to detect and monitor thermal lesions, and may be utilized as an alternative modality for image-guided MWA treatments.","","","10.1109/JBHI.2019.2939810","National Major Scientific Instrument and Equipment Development Project; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8826270","Convolutional neural networks;deep learning;microwave ablation;ultrasound imaging;monitoring","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"S3: A Spectral-Spatial Structure Loss for Pan-Sharpening Networks","J. Choi; Y. Kim; M. Kim","School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon 34141, South Korea.; Artificial Intelligence Research Division, Korea Aerospace Research Institute, Daejeon 34133, South Korea.; School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon 34141, South Korea (e-mail: jschoi14@kaist.ac.kr).","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","Recently, many deep-learning-based pan-sharpen-ing methods have been proposed for generating high-quality pan-sharpened (PS) satellite images. These methods focused on various types of convolutional neural network (CNN) structures, which were trained by simply minimizing a spectral loss between network outputs and the corresponding high-resolution (HR) multi-spectral (MS) target images. However, owing to different sensor characteristics and acquisition times, HR panchromatic (PAN) and low-resolution MS image pairs tend to have large pixel misalignments, especially for moving objects in the images. Conventional CNNs trained with only the spectral loss with these satellite image data sets often produce PS images of low visual quality including double-edge artifacts along strong edges and ghosting artifacts on moving objects. In this letter, we propose a novel loss function, called a spectral-spatial structure (S3) loss, based on the correlation maps between MS targets and PAN inputs. Our proposed S3 loss can be very effectively used for pan-sharpening with various types of CNN structures, resulting in significant visual improvements on PS images with suppressed artifacts.","","","10.1109/LGRS.2019.2934493","National Research Foundation of Korea NRF funded by the Ministry of Science ICT and Future Planning through the Basic Science Research Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812763","Convolutional neural network (CNN);deep learning;pan colorization;pan-sharpening;satellite imagery;spectral-spatial structure;super-resolution (SR).","Training;Satellites;Correlation;Spatial resolution;Visualization;Convolutional neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"SDDNet: Real-time Crack Segmentation","W. Choi; Y. Cha","Civil Engineering, University of Manitoba, 8664 Winnipeg, Manitoba Canada (e-mail: choiw@myumanitoba.ca); Civil Engineering, University of Manitoba Faculty of Engineering, 141665 Winnipeg, Manitoba Canada (e-mail: young.cha@umanitoba.ca)","IEEE Transactions on Industrial Electronics","","2019","PP","99","1","1","This paper reports the development of a pure deep learning method for segmenting concrete cracks in images. The objectives are to achieve real-time performance while effectively negating a wide range of various complex backgrounds and crack-like features. To achieve the goals, an original convolutional neural network is proposed. The model consists of standard convolutions, densely connected separable convolution (DenSep) modules, a modified atrous spatial pyramid pooling (ASPP) module, and a decoder module. The SDDNet is trained on a manually created crack dataset, and the trained network records the mean intersection-over-union (mIoU) of 0.846 on the test set. Each test image is analyzed, and the representative segmentation results are presented. The results show that the SDDNet segments cracks effectively unless the features are too faint. The proposed model is also compared with the most recent models, which show that it returns better evaluation metrics even though its number of parameters is 88 times less than in the compared models. In addition, the model processes in real-time (36 FPS) images at 1025×512 pixels, which is 46 times faster than in a recent work.","","","10.1109/TIE.2019.2945265","Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8863123","Crack segmentation;deep learning;separable convolution;structural health monitoring;real time","Image segmentation;Standards;Computer architecture;Computational efficiency;Feature extraction;Real-time systems;Decoding","","","","","","","","","","IEEE","IEEE Early Access Articles"
"An Intelligent Video Tag Recommendation Method for Improving Video Popularity in Mobile Computing Environment","R. Zhou; D. Xia; J. Wan; S. Zhang","School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China and Key Laboratory of Complex Systems Modeling and Simulation of the Ministry of Education, Hangzhou Dianzi University, Hangzhou, China and College of Computer Science and Technology, Zhejiang University, Hangzhou, China.; School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China and Key Laboratory of Complex Systems Modeling and Simulation of the Ministry of Education, Hangzhou Dianzi University, Hangzhou, China.; School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China and Key Laboratory of Complex Systems Modeling and Simulation of the Ministry of Education, Hangzhou Dianzi University, Hangzhou, China and Zhejiang University of Science and Technology, Hangzhou, China.; College of Computer Science and Technology, Zhejiang University, Hangzhou, China.","IEEE Access","","2019","PP","99","1","1","Big data generated from social media and smart mobile devices has been regarded as a key to obtain insights into human behavior and been extensively utilized for launching marketing activities. A successful marketing activity requires attracting high social popularity to their contents, since higher popularity usually indicates stronger influence, more fame and higher revenue. In this paper, we focus on the question of how to improve popularity of videos sharing on websites like YouTube in mobile computing environment. Obviously, composing high quality titles and tags is beneficial for viewers to discover videos of their interests and increase their tendency to watch more videos. However, it is not an easy task for uploaders, which is especially true since the screen is tight for most mobile devices. To this end, this paper proposes a novel hybrid method based on multi-modal content analysis that recommends keywords for video uploaders to compose titles and tags of their videos and then to gain higher popularity. The method generates candidate keywords by integrating techniques of textual semantic analysis of original tags and recognition of video content. On one hand, taking the original keywords of a video as input, the method obtains most relevant words from WordNet and related video titles gathered from the three top video sharing sites (YouTube, Yahoo Video, Bing Video). On the other hand, through recognizing video content with deep learning technology, the method extracts the entity name of video content as candidate keywords. Finally, a TF-SIM algorithm is proposed to rank the candidate keywords and the most relevant keywords are recommended to uploaders for optimizing the titles and tags of their videos. The experimental results show that the proposed method can effectively improve the social popularity of the videos as well as extend the length of video viewing time per playback.","","","10.1109/ACCESS.2019.2961392","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8938802","Mobile Computing;Social Media;Big Data;Video Tagging;Video Popularity;Artificial Intelligence;Deep Learning","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"GazMon: Eye Gazing Enabled Driving Behavior Monitoring and Prediction","X. Fan; F. Wang; D. Song; Y. Lu; J. Liu","the Department of Electrical and Computer Engineering, University of British Columbia, 8166 Vancouver, British Columbia Canada (e-mail: xiaoyif@ece.ubc.ca); Department of Computer and Information Science, The University of Mississippi, University, Mississippi United States 38677 (e-mail: fwang@cs.olemiss.edu); Computing Science, Simon Fraser University, Burnaby, British Columbia Canada (e-mail: arthur_song@sfu.ca); Computing Science, Simon Fraser University, Burnaby, British Columbia Canada (e-mail: yuhel@sfu.ca); Computing science, Simon Fraser University, Vancouver, British Columbia Canada (e-mail: jcliu@cs.sfu.ca)","IEEE Transactions on Mobile Computing","","2019","PP","99","1","1","Automobiles have become one of the necessities of modern life, but also introduced numerous traffic accidents that threaten drivers and other road users. Most state-of-the-art safety systems are passively triggered, reacting to dangerous road conditions or driving maneuvers only after they happen and are observed, which greatly limits the last chances for collision avoidances. Timely tracking and predicting the driving maneuvers calls for a more direct interface beyond the traditional steering wheel/brake/gas pedal. In this paper, we argue that a driver's eyes are the interface, as it is the first and the essential window that gathers external information during driving. Our experiments suggest that a driver's gaze patterns appear prior to and correlate with the driving maneuvers for driving maneuver prediction. We accordingly present GazMon, an active driving maneuver monitoring and prediction framework for driving assistance applications. GazMon extracts the gaze information through a front-camera and analyzes the facial features, including facial landmarks, head pose, and iris centers, through a carefully constructed deep learning architecture. Both our on-road experiments and driving simulator based evaluations demonstrate the superiority of our GazMon on predicting driving maneuvers as well as other distracted behaviors. It is readily deployable using RGB cameras and allows reuse of existing smartphones towards more safely driving.","","","10.1109/TMC.2019.2962764","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8944165","Gaze;Driving Assistant;Mobile Computing;Deep Learning","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Auto-ORVNet: Orientation-boosted Volumetric Neural Architecture Search for 3D Shape Classification","Z. Ma; Z. Zhou; Y. Liu; Y. Lei; H. Yan","College of Electronics and Information Engineering, Sichuan University, Chengdu, China.; College of Electronics and Information Engineering, Sichuan University, Chengdu, China.; College of Electronics and Information Engineering, Sichuan University, Chengdu, China.; College of Electronics and Information Engineering, Sichuan University, Chengdu, China.; College of Electronics and Information Engineering, Sichuan University, Chengdu, China.","IEEE Access","","2019","PP","99","1","1","Recently, more and more 3D shape datasets have become publicly available and significant results have been attained in 3D shape classification with 3D volumetric convolutional neural networks. However, the existing 3D volumetric networks have a problem with balancing model scale and classification accuracy. To address this problem, neural architecture search (NAS) was introduced into 3D shape classification tasks to search for a model satisfying both requirements. Automatically generating neural networks under NAS has attracted increasing research interest in recent years. The models learned by NAS outperform many manually designed networks in several 2D tasks like image classification, detection and semantic segmentation. In this paper, the differentiable formulation of NAS is exploited to search for several repeatable computation cells. The introduction of many light-weight designs for 3D CNNs assists in the construction of deep models with fewer parameters. The loss for the classification task along with the loss for orientation prediction are combined to guide such search. Extensive experiments are designed to evaluate candidate models on three datasets. The results demonstrate that without any pretraining, our discovered model for 3D shape classification outperforms most manually designed networks with small parameter sizes, whilst also showing that our model achieves a balance between model scale and classification accuracy.","","","10.1109/ACCESS.2019.2961715","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8939365","Deep learning;volumetric convolutional neural network;3D shape classification;neural architecture search","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Nonlinear dynamic soft sensor modeling with supervised long short-term memory network","X. Yuan; L. Li; Y. Wang","Central South University, 12570 Changsha, Hunan China 410083 (e-mail: yuanxf@csu.edu.cn); Central South University, 12570 Changsha, Hunan China 410083 (e-mail: 1192732314@qq.com); Changsha China 410083 (e-mail: ylwang@csu.edu.cn)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","Soft sensor has been extensively utilized in industrial processes for prediction of key quality variables. To build an accurate virtual sensor model, it is very significant to model the dynamic and nonlinear behaviors of process sequential data properly. Recently, long short-term memory (LSTM) network has shown great modeling ability on various time series, in which basic LSTM units can handle data nonlinearities and dynamics with a dynamic latent variable structure. However, the hidden variables in the basic LSTM unit mainly focus on describing the dynamics of input variables, which lack representation for the quality data. In this paper, a supervised LSTM (SLSTM) network is proposed to learn quality-relevant hidden dynamics for soft sensor application, which is composed of basic SLSTM unit at each sampling instant. In the basic SLSTM unit, the quality and input variables are simultaneously utilized to learn the dynamic hidden states, which are more relevant and useful for quality prediction. The effectiveness of the proposed SLSTM network is demonstrated on a penicillin fermentation process and an industrial debutanizer column.","","","10.1109/TII.2019.2902129","Innovation-driven plan in Central South University; National Natural Science Foundation of China; Natural Science Foundation of Hunan Province of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8654687","Soft sensor;Quality prediction;Long short-term memory (LSTM);Supervised LSTM;Deep learning","Logic gates;Informatics;Principal component analysis;Process control;Artificial neural networks;Recurrent neural networks;Input variables","","","","2","","","","","","IEEE","IEEE Early Access Articles"
"Deeply Associative Two-stage Representations Learning based on Labels Interval Extension loss and Group loss for Person Re-identification","Y. Huang; Y. Huang; H. Hu; D. Chen; T. Su","School of Electronics and Information Technology, Sun Yat-sen University, 510006.; School of Electronics and Information Technology, Sun Yat-sen University, 510006.; School of Electronics and Information Technology, Sun Yat-sen University, 510006.; School of Electronics and Information Technology, Sun Yat-sen University, 510006.; School of Electronics and Information Technology, Sun Yat-sen University, 510006.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Person Re-identification (ReID) aims to match people across non-overlapping camera views in a public space, which is usually regarded as an image retrieval problem to match query images with pedestrian images in the gallery. It is challenging since many difficulties exist such as pose misalignments, occlusions, similar appearance when detecting people. Existing researches on ReID mainly focus on two major problems: representation learning and metric learning. In this paper, we target at learning discriminative representations and make two contributions in total. (i) We propose a novel architecture named Deeply Associative Two-stage Representations Learning (DATRL). It contains the global re-initialization stage and fully-perceptual classification stage employing two identical CNNs associatively at the same time. On the global stage, we take on the backbone of one deep CNN e.g., dozens of layers in the front of Resnet-50 as a normal re-initialization subnetwork. Meanwhile, we apply our own proposed 3D-transpose technique into the backbone of the other CNN to form the 3D-transpose re-initialization subnetwork. The fully-perceptual stage is actually made up of the leftover layers of the original CNNs. On this stage, we take both the global representations learned at multiple hierarchies and the local representations uniformly-partitioned on the highest conv-layer into consideration, and then optimizing them separately for classification. (ii) We introduce a new joint loss function in which our proposed Labels Interval Extension loss (LIEL) and Group loss (GL) are combined to enhance the performance of gradient decent as well as increasing the distances between image features with different identities. We apply the above DATRL, LIEL and GL to ReID thus obtaining DATRL-ReID. Experimental results on four datasets CUHK03, Market-1501, DukeMTMC-reID and MSMT17-V2 demonstrate that DATRL-ReID shows excellent performance in improving recognition accuracy and is superior to state-of-the-art methods.","","","10.1109/TCSVT.2019.2948267","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8876859","Person Re-identification;Group loss;Labels Interval Extension loss;Feature representation;Video surveillance","Feature extraction;Pose estimation;Training;Semantics;Computer architecture;Task analysis;Cameras","","","","","","","","","","IEEE","IEEE Early Access Articles"
"ERGO: Efficient Recurrent Graph Optimized Emitter Density Estimation in Single Molecule Localization Microscopy","B. Cardoen; H. B. Yedder; A. Sharma; K. C. Chou; I. R. Nabi; G. Hamarneh","Medical Image Analysis Laboratory, School of Computing Science, Simon Fraser University, BC Canada V5A 1S6.; Medical Image Analysis Laboratory, School of Computing Science, Simon Fraser University, BC Canada V5A 1S6.; Medical Image Analysis Laboratory, School of Computing Science, Simon Fraser University, BC Canada V5A 1S6.; Department of Chemistry, University of British Columbia, BC Canada V6T 1Z3.; Life Sciences Institute, University of British Columbia, BC Canada V6T 1Z3.; Medical Image Analysis Laboratory, School of Computing Science, Simon Fraser University, BC Canada V5A 1S6.","IEEE Transactions on Medical Imaging","","2019","PP","99","1","1","Single molecule localization microscopy (SMLM) allows unprecedented insight into the three-dimensional organization of proteins at the nanometer scale. The combination of minimal invasive cell imaging with high resolution positions SMLM at the forefront of scientific discovery in cancer, infectious, and degenerative diseases. By stochastic temporal and spatial separation of light emissions from fluorescent labelled proteins, SMLM is capable of nanometer scale reconstruction of cellular structures. Precise localization of proteins in 3D astigmatic SMLM is dependent on parameter sensitive preprocessing steps to select regions of interest. With SMLM acquisition highly variable over time, it is non-trivial to find an optimal static parameter configuration. The high emitter density required for reconstruction of complex protein structures can compromise accuracy and introduce artifacts. To address these problems, we introduce two modular auto-tuning pre-processing methods: adaptive signal detection and learned recurrent signal density estimation that can leverage the information stored in the sequence of frames that compose the SMLM acquisition process. We show empirically that our contributions improve accuracy, precision and recall with respect to the state of the art. Both modules auto-tune their hyper-parameters to reduce the parameter space for practitioners, improve robustness and reproducibility, and are validated on a reference in silico dataset. Adaptive signal detection and density prediction can offer a practitioner, in addition to informed localization, a tool to tune acquisition parameters ensuring improved reconstruction of the underlying protein complex. We illustrate the challenges faced by practitioners in applying SMLM algorithms on real world data markedly different from the data used in development and show how ERGO can be run on new datasets without retraining while motivating the need for robust transfer learning in SMLM.","","","10.1109/TMI.2019.2962361","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8943153","single molecule localization microscopy;density estimation;signal detection;deep learning;recurrent network;dSTORM;astigmatism","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Integrating Image-based and Knowledge-based Representation Learning","R. Xie; S. Heinrich; Z. Liu; C. Weber; Y. Yao; S. Wermter; M. Sun","Search Product Center, We Chat Search Application Department, Tencent, China.; Knowledge Technology Group, Department of Informatics, Universität Hamburg, Hamburg, Germany.; Department of Computer Science and Technology, the State Key Laboratory of Intelligent Technology and Systems, and Tsinghua National Laboratory for Information Science and Technology, Tsinghua University, Beijing, China.; Knowledge Technology Group, Department of Informatics, Universität Hamburg, Hamburg, Germany.; Department of Computer Science and Technology, the State Key Laboratory of Intelligent Technology and Systems, and Tsinghua National Laboratory for Information Science and Technology, Tsinghua University, Beijing, China.; Knowledge Technology Group, Department of Informatics, Universität Hamburg, Hamburg, Germany.; Department of Computer Science and Technology, the State Key Laboratory of Intelligent Technology and Systems, and Tsinghua National Laboratory for Information Science and Technology, Tsinghua University, Beijing, China.","IEEE Transactions on Cognitive and Developmental Systems","","2019","PP","99","1","1","A variety of brain areas is involved in language understanding and generation, accounting for the scope of language that can refer to many real-world matters. In this work, we investigate how regularities among real-world entities impact on emergent language representations. Specifically, we consider knowledge bases, which represent entities and their relations as structured triples, and image representations, which are obtained via deep convolutional networks. We combine these sources of information to learn representations of an Image-based Knowledge Representation Learning model (IKRL). An attention mechanism lets more informative images contribute more to the image-based representations. Evaluation results show that the model outperforms all baselines on the tasks of knowledge graph completion and triple classification. In analysing the learned models we found that the structure-based and image-based representations integrate different aspects of the entities and the attention mechanism provides robustness during learning.","","","10.1109/TCDS.2019.2906685","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8689107","Generation of representation during development;attention mechanisms and development;embodied cognition.","Visualization;Knowledge representation;Brain modeling;Task analysis;Head;Knowledge based systems;Computational modeling","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Attention-based Video Hashing for Large-Scale Video Retrieval","Y. Wang; X. Nie; Y. Shi; X. Zhou; Y. Yin","School of Computer Science and Technology, Shandong University, Jinan, P. R. China.; School of Computer Science and Technology, Shandong Jianzhu University, Jinan, P. R. China.; School of Software, Shandong University, Jinan, P.R. China.; School of Computer Science and Technology, Shandong University, Jinan, P. R. China.; School of Software, Shandong University, Jinan, P. R. China.","IEEE Transactions on Cognitive and Developmental Systems","","2019","PP","99","1","1","Large-scale video retrieval is a challenging problem because of the exponential growth of video collections on the Internet. To address this challenge, we propose an attention-based video hashing (AVH) method for large-scale video retrieval. Unlike most of existing video hashing methods, which consider different frames within a video separately for hash learning, we use a convolutional neural network and long-short term memory (LSTM) network as the backbone to learn compact and discriminative hash codes by exploiting the structural information among different frames. To better capture informative clues in the video, an attention mechanism is added into the backbone, which can assign different weights to different LSTM time steps. Experiments were conducted to evaluate the proposed AVH method in comparison with existing methods. The experimental results on two widely used datasets show that our method outperforms existing state-of-the-art methods.","","","10.1109/TCDS.2019.2963339","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8946767","hashing;video hashing;video retrieval;deep learning.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Semisupervised Classification of PolSAR Image Incorporating Labels' Semantic Priors","B. Hou; J. Guan; Q. Wu; L. Jiao","Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education of China, Xidian University, Xi'an 710071, China (e-mail: avcodec@hotmail.com).; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education of China, Xidian University, Xi'an 710071, China.; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education of China, Xidian University, Xi'an 710071, China.; Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education of China, Xidian University, Xi'an 710071, China.","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","Deep learning techniques represented by deep convolutional neural networks (CNNs) have been widely used in polarimetric synthetic-aperture radar (PolSAR) image classification in recent years. One challenge is how to get a pleasant classification result with limited human-labeled samples. In this letter, a novel semisupervised classification method incorporating labels' semantic priors is proposed for PolSAR image classification with limited labeled samples. The core idea is that a good classification result map should have consistent regions and aligned boundaries. Thus, a cost function is proposed, which mainly contains three terms including a supervised term, a region consistency term, and a boundary kept term. The supervised term enforces the category label to be the same with the human-labeled labels. The region consistency term encourages the labels in one region to be consistent. The boundary-kept term constrains the region consistency term, preventing the classification map from being too smooth. An alternate iterative optimization method is proposed to solve this equation. First, a CNN is trained using the labeled samples and the classification probability map. Then, the classification probability map is updated by the prediction of the trained CNN and the labeled samples. Repeat these two procedures until the maximum number of iterations is met. Experiments on two real PolSAR images are conducted to validate the effectiveness of the proposed method compared with several state-of-the-art methods.","","","10.1109/LGRS.2019.2953203","National Natural Science Foundation of China; Foundation for Innovative Research Groups of the National Natural Science Foundation of China; Key Research and Development Program in Shaanxi Province of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8915735","Convolutional neural network (CNN);limited labeled samples;polarimetric synthetic aperture radar (PolSAR) image classification;semantic priors.","Semantics;Manganese;Training;Feature extraction;Convolutional neural networks;Cost function;Machine learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Joint Transmission Map Estimation and Dehazing using Deep Networks","H. Zhang; V. Sindagi; V. M. Patel","Department of Electrical and Computer Engineering at Rutgers University, Piscataway, NJ USA.; Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD, USA.; Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD, USA.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Single image haze removal is an extremely challenging problem due to its inherent ill-posed nature. Several prior-based and learning-based methods have been proposed in the literature to solve this problem and they have achieved visually appealing results. However, most of the existing methods assume constant atmospheric light model and tend to follow a two-step procedure involving prior-based methods for estimating transmission map followed by calculation of dehazed image using the closed form solution. In this paper, we relax the constant atmospheric light assumption and propose a novel unified single image dehazing network that jointly estimates the transmission map and performs dehazing. In other words, our new approach provides an end-to-end learning framework, where the inherent transmission map and dehazed result are learned jointly from the loss function. Extensive experiments evaluated on synthetic and real datasets with challenging hazy images demonstrate that the proposed method achieves significant improvements over the state-of-the-art methods.","","","10.1109/TCSVT.2019.2912145","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8695091","","Propagation losses;Atmospheric modeling;Estimation;Feature extraction;Task analysis;Generative adversarial networks;Degradation","","","","","","","","","","IEEE","IEEE Early Access Articles"
"SAR Target Small Sample Recognition Based on CNN Cascaded Features and AdaBoost Rotation Forest","F. Zhang; Y. Wang; J. Ni; Y. Zhou; W. Hu","College of Information Science and Technology, Beijing University of Chemical Technology, Beijing 100029, China.; College of Information Science and Technology, Beijing University of Chemical Technology, Beijing 100029, China.; College of Information Science and Technology, Beijing University of Chemical Technology, Beijing 100029, China.; College of Information Science and Technology, Beijing University of Chemical Technology, Beijing 100029, China (e-mail: zhyosh@mail.buct.edu.cn).; College of Information Science and Technology, Beijing University of Chemical Technology, Beijing 100029, China.","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","Automatic target recognition (ATR) has made great progress with the development of deep learning. However, the target feature in synthetic aperture radar (SAR) image is not consistent with human vision, and the SAR training samples are always limited. These hard issues pose new challenges to the SAR ATR based on convolutional neural network (CNN). In this letter, we propose an improved CNN model to solve the limited sample issue via the feature augmentation and ensemble learning strategies. Normally, the high-level features that are more comprehensive and discriminative than the middle-level and low-level features are always employed for category discrimination. In order to make up the insufficient training features in the limited sample case, the cascaded features from optimally selected convolutional layers are concatenated to provide more comprehensive representation for the recognition. To take full advantage of these cascaded features, the ensemble learning-based classifier, namely, the AdaBoost rotation forest (RoF), is introduced to replace the original softmax layer to realize a more accurate limited sample recognition. Through the AdaBoost RoF method, not only are these features further enhanced by the rotation matrix but also a strong classifier is constructed by several weak classifiers with different adjusted weights. The experimental results on MSTAR data set show that the cascaded features and ensemble weak classifiers can fully exploit effective information in limited samples. Compared with the existing CNN method, the proposed method can improve the recognition accuracy by about 20% under the condition of ten training samples per class.","","","10.1109/LGRS.2019.2939156","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8848596","AdaBoost;convolutional neural network (CNN);ensemble learning;rotation forest (RoF);synthetic aperture radar (SAR);target classification.","Feature extraction;Training;Synthetic aperture radar;Forestry;Target recognition;Radio frequency;Decision trees","","","","","","","","","","IEEE","IEEE Early Access Articles"
"diffGrad: An Optimization Method for Convolutional Neural Networks","S. R. Dubey; S. Chakraborty; S. K. Roy; S. Mukherjee; S. K. Singh; B. B. Chaudhuri","Computer Vision Group, Indian Institute of Information Technology at Sri City, Chittoor 517646, India (e-mail: shivram1987@gmail.com).; Indian Institute of Information Technology at Lucknow, Lucknow 226002, India.; Computer Vision and Pattern Recognition Unit, Indian Statistical Institute, Kolkata 700108, India.; Computer Vision Group, Indian Institute of Information Technology at Sri City, Chittoor 517646, India.; Computer Vision and Biometrics Laboratory, Indian Institute of Information Technology at Allahabad, Allahabad 211015, India.; Computer Vision and Pattern Recognition Unit, Indian Statistical Institute, Kolkata 700108, India, and also with Techno India University, Kolkata 700091, India.","IEEE Transactions on Neural Networks and Learning Systems","","2019","PP","99","1","12","Stochastic gradient descent (SGD) is one of the core techniques behind the success of deep neural networks. The gradient provides information on the direction in which a function has the steepest rate of change. The main problem with basic SGD is to change by equal-sized steps for all parameters, irrespective of the gradient behavior. Hence, an efficient way of deep network optimization is to have adaptive step sizes for each parameter. Recently, several attempts have been made to improve gradient descent methods such as AdaGrad, AdaDelta, RMSProp, and adaptive moment estimation (Adam). These methods rely on the square roots of exponential moving averages of squared past gradients. Thus, these methods do not take advantage of local change in gradients. In this article, a novel optimizer is proposed based on the difference between the present and the immediate past gradient (i.e., diffGrad). In the proposed diffGrad optimization technique, the step size is adjusted for each parameter in such a way that it should have a larger step size for faster gradient changing parameters and a lower step size for lower gradient changing parameters. The convergence analysis is done using the regret bound approach of the online learning framework. In this article, thorough analysis is made over three synthetic complex nonconvex functions. The image categorization experiments are also conducted over the CIFAR10 and CIFAR100 data sets to observe the performance of diffGrad with respect to the state-of-the-art optimizers such as SGDM, AdaGrad, AdaDelta, RMSProp, AMSGrad, and Adam. The residual unit (ResNet)-based convolutional neural network (CNN) architecture is used in the experiments. The experiments show that diffGrad outperforms other optimizers. Also, we show that diffGrad performs uniformly well for training CNN using different activation functions. The source code is made publicly available at https://github.com/shivram1987/diffGrad.","","","10.1109/TNNLS.2019.2955777","IIIT Sri City; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8939562","Adaptive moment estimation (Adam);difference of gradient;gradient descent;image classification;neural networks;optimization;residual network.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"UNet++: Redesigning Skip Connections to Exploit Multiscale Features in Image Segmentation","Z. Zhou; M. M. R. Siddiquee; N. Tajbakhsh; J. Liang","Department of Biomedical Informatics, Arizona State University, Scottsdale, AZ 85259 USA.; School of Computing, Informatics, and Decision Systems Engineering, Arizona State University, Tempe, AZ 85281 USA.; Department of Biomedical Informatics, Arizona State University, Scottsdale, AZ 85259 USA.; Department of Biomedical Informatics, Arizona State University, Scottsdale, AZ 85259 USA.","IEEE Transactions on Medical Imaging","","2019","PP","99","1","1","The state-of-the-art models for medical image segmentation are variants of U-Net and fully convolutional networks (FCN). Despite their success, these models have two limitations: (1) their optimal depth is apriori unknown, requiring extensive architecture search or inefficient ensemble of models of varying depths; and (2) their skip connections impose an unnecessarily restrictive fusion scheme, forcing aggregation only at the same-scale feature maps of the encoder and decoder sub-networks. To overcome these two limitations, we propose UNet++, a new neural architecture for semantic and instance segmentation, by (1) alleviating the unknown network depth with an efficient ensemble of U-Nets of varying depths, which partially share an encoder and co-learn simultaneously using deep supervision; (2) redesigning skip connections to aggregate features of varying semantic scales at the decoder sub-networks, leading to a highly flexible feature fusion scheme; and (3) devising a pruning scheme to accelerate the inference speed of UNet++. We have evaluated UNet++ using six different medical image segmentation datasets, covering multiple imaging modalities such as computed tomography (CT), magnetic resonance imaging (MRI), and electron microscopy (EM), and demonstrating that (1) UNet++ consistently outperforms the baseline models for the task of semantic segmentation across different datasets and backbone architectures; (2) UNet++ enhances segmentation quality of varying-size objects—an improvement over the fixed-depth U-Net; that is bound to segment objects of only certain sizes; (3) Mask RCNN++ (Mask R-CNN with UNet++ design) outperforms the original Mask R-CNN for the task of instance segmentation; and (4) pruned UNet++ models achieve significant speedup while showing only modest performance degradation. Our implementation and pre-trained models are available at https://github.com/MrGiovanni/UNetPlusPlus.","","","10.1109/TMI.2019.2959609","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8932614","Neuronal Structure Segmentation;Liver Segmentation;Cell Segmentation;Nuclei Segmentation;Brain Tumor Segmentation;Lung Nodule Segmentation;Medical Image Segmentation;Semantic Segmentation;Instance Segmentation;Deep Supervision;Model Pruning","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Deep Model for Lung Cancer Type Identification by Densely Connected Convolutional Networks and Adaptive Boosting","S. Pang; Y. Zhang; M. Ding; X. Wang; X. Xie","College of Computer Science and Technology, China University of Petroleum, Qingdao, Shandong, China.; College of Computer Science and Technology, China University of Petroleum, Qingdao, Shandong, China.; Department of Neurology, The Second Hospital of Shandong University, Jinan, Shandong, China.; College of Computer Science and Technology, China University of Petroleum, Qingdao, Shandong, China.; Department of Respiratory Medicine, Shandong Provincial Third Hospital, Jinan, Shandong, China.","IEEE Access","","2019","PP","99","1","1","Timely diagnosis and determination to the type of lung cancer has important clinical significance. Generally, it requires multiple imaging methods to complement each other to obtain a comprehensive diagnosis. In this work, we propose a deep learning model to identify lung cancer type from CT images for patients in Shandong Provincial Hospital. It has a two-fold challenge: artificial intelligent models trained by public datasets cannot meet such practical requires, and the amount of collected patients’ data is quite few. To solve the two-fold problem, we use image rotation, translation and transformation methods to expand and balance our training data, and then densely connected convolutional networks (DenseNet) is used to classify malignant tumor from images collected from, and finally adaptive boosting (adaboost) algorithm is used to aggregate multiple classification results to improve classification performance. Experimental results show that our method can achieve identifying accuracy 89.85%, which performs better than DenseNet without adaboost, ResNet, VGG16 and AlexNet. This provides an efficient, non-invasive detection tool for pathological diagnosis to lung cancer type.","","","10.1109/ACCESS.2019.2962862","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8945194","Adaboost algorithm;Data enhancement;Densely connected convolutional networks;Lung cancer","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Deep Filtering: Signal Extraction and Reconstruction Using Complex Time-Frequency Filters","W. Mack; E. A. P. Habets","International Audio Laboratories Erlangen, Friedrich-Alexander-Universitat Erlangen-Nurnberg, 9171 Erlangen, Bavaria Germany 91054 (e-mail: wolfgang.mack@fau.de); International Audio Laboratories Erlangen, Erlangen, Bavaria Germany (e-mail: emanuel.habets@audiolabs-erlangen.de)","IEEE Signal Processing Letters","","2019","PP","99","1","1","Signal extraction from a single-channel mixture with additional undesired signals is most commonly performed using time-frequency (TF) masks. Typically, the mask is estimated with a deep neural network (DNN), and element-wise applied to the complex mixture short-time Fourier transform (STFT) representation to perform the extraction. Ideal mask magnitudes are zero for solely undesired signals in a TF bin and undefined for total destructive interference. Usually, masks have an upper bound to provide well-defined DNN outputs at the cost of limited extraction capabilities. We propose to estimate with a DNN a complex TF filter for each mixture TF bin which maps an STFT area in the respective mixture to the desired TF bin to address destructive interference in mixture TF bins. The DNN is optimized by minimizing the error between the extracted and the ground-truth desired signal allowing to learn the TF filters without having to specify ground-truth TF filters. We compare our approach with complex and real-valued TF masks by separating speech from a variety of different sound and noise classes from the Google AudioSet corpus. We also process the mixture STFT with notch-filters and zero whole time-frames, to simulate packet-loss during transmission, to demonstrate the reconstruction capabilities of our approach. The proposed method outperformed the baselines, especially when notch-filters and time-frame zeroing were applied.","","","10.1109/LSP.2019.2955818","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8911434","Signal Extraction;Signal Enhancement;Time-Frequency Masking","Time-frequency analysis;Interference;Customer relationship management;Image reconstruction;Estimation;Training;Neural networks","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Bayesian Inferred Self-Attentive Aggregation for Multi-Shot Person Re-Identification","X. Liu; S. Bi; S. Fang; A. Bouridane","Information Science and Technology College, Dalian Maritime University, Dalian, 116026, PR China.; Information Science and Technology College, Dalian Maritime University, Dalian, 116026, PR China.; Information Science and Technology College, Dalian Maritime University, Dalian, 116026, PR China.; Department of Computer and Information Science, Northumbria University at Newcastle, United Kingdom.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Person re-identification is a challenging retrieval task that aims to match pedestrians from multiple non-overlapping cameras. In this paper, we introduce a deep multi-instance learning framework to aggregate instance-level images to boost retrieval performance. Considerable annotation inconsistency inevitably happens in many current person re-identification datasets due to unconcerned of annotations or dramatic varieties in surveillance scenarios, thereby leading to model drifting. To alleviate this issue, we formulate the person re-identification problem in a weakly supervised setting, and propose a self-inspired attention model based on Bayesian inference, to adaptively evaluate regional features with their global dependencies across instances, which we refer to as Bayesian Inferred Self-Attentive Aggregation (BISAA). The evaluation mechanism is parameterized by neural networks to provide an insight into the contribution of each instance and semantic human part to set-level labels. Furthermore, to facilitate aggregation across a set of instances, we propose a new collective aggregation function to make the model more robust to outliers, by adjusting the activation threshold, to allow some non-informative instances to be ignored while paying more attention to the discriminative ones. Extensive experiments with ablation analysis show the effectiveness of our method and the proposed method outperforms many related state-of-the-art techniques on four benchmark datasets: PRID2011, iLIDS-VID, Market-1501 and MSMT17.","","","10.1109/TCSVT.2019.2957539","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8922733","Convolutional Neural Networks;Multi-Instance Learning;Spatial Alignment;Self-Attentive;Collective Aggregation","Neural networks;Semantics;Feature extraction;Bayes methods;Robustness;Cameras;Machine learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Toward Universal Stripe Removal via Wavelet-Based Deep Convolutional Neural Network","Y. Chang; M. Chen; L. Yan; X. Zhao; Y. Li; S. Zhong","National Key Laboratory of Science and Technology on Multispectral Information Processing, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan 430074, China.; National Key Laboratory of Science and Technology on Multispectral Information Processing, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan 430074, China.; National Key Laboratory of Science and Technology on Multispectral Information Processing, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan 430074, China (e-mail: yanluxin@hust.edu.cn).; School of Mathematical Sciences, University of Electronic Science and Technology of China, Chengdu 611731, China.; National Key Laboratory of Science and Technology on Multispectral Information Processing, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan 430074, China.; National Key Laboratory of Science and Technology on Multispectral Information Processing, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan 430074, China.","IEEE Transactions on Geoscience and Remote Sensing","","2019","PP","99","1","18","Stripe noise from different remote sensing imaging systems varies considerably in terms of response, length, angle, and periodicity. Due to the complex distributions of different stripes, the destriping results of previous methods may be oversmoothed or contain residual stripe. To overcome this key problem, we provide a comprehensive analysis of existing destriping methods and propose a deep convolutional neural network (CNN) for handling various kinds of stripes. Moreover, previous methods individually model the stripe or the image priors, which may lose the relationship between them. In this article, a two-stream CNN is designed to simultaneously model the stripe and image, which better facilitates distinguishing them from each other. Moreover, we incorporate the wavelet into our CNN model for better directional feature representation. Therefore, the CNN learns the discriminative representation from the external data set, while the wavelet models the internal directionality of the stripe, in which both the internal and external priors are beneficial to the destriping task. In addition, the wavelet extracts the multiscale information with a larger receptive field for global contextual information modeling; thus, we can better distinguish the stripe from the similar image line pattern structures. The proposed method has been extensively evaluated on a number of data sets and outperforms the state-of-the-art methods by substantially a large margin in terms of quantitative and qualitative assessments, speed, and robustness.","","","10.1109/TGRS.2019.2957153","National Natural Science Foundation of China; Project of the Hubei Provincial Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8936525","Convolutional neural network (CNN);destriping;image decomposition;wavelet.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Asymptotic Soft Filter Pruning for Deep Convolutional Neural Networks","Y. He; X. Dong; G. Kang; Y. Fu; C. Yan; Y. Yang","Center for Artificial Intelligence, University of Technology Sydney, Ultimo, NSW 2007, Australia.; Center for Artificial Intelligence, University of Technology Sydney, Ultimo, NSW 2007, Australia.; Center for Artificial Intelligence, University of Technology Sydney, Ultimo, NSW 2007, Australia.; School of Data Science, Fudan University, Shanghai 200433, China.; Institute of Information and Control, Hangdian University, Hangzhou 310000, China.; Center for Artificial Intelligence, University of Technology Sydney, Ultimo, NSW 2007, Australia (e-mail: yi.yang@uts.edu.au).","IEEE Transactions on Cybernetics","","2019","PP","99","1","11","Deeper and wider convolutional neural networks (CNNs) achieve superior performance but bring expensive computation cost. Accelerating such overparameterized neural network has received increased attention. A typical pruning algorithm is a three-stage pipeline, i.e., training, pruning, and retraining. Prevailing approaches fix the pruned filters to zero during retraining and, thus, significantly reduce the optimization space. Besides, they directly prune a large number of filters at first, which would cause unrecoverable information loss. To solve these problems, we propose an asymptotic soft filter pruning (ASFP) method to accelerate the inference procedure of the deep neural networks. First, we update the pruned filters during the retraining stage. As a result, the optimization space of the pruned model would not be reduced but be the same as that of the original model. In this way, the model has enough capacity to learn from the training data. Second, we prune the network asymptotically. We prune few filters at first and asymptotically prune more filters during the training procedure. With asymptotic pruning, the information of the training set would be gradually concentrated in the remaining filters, so the subsequent training and pruning process would be stable. The experiments show the effectiveness of our ASFP on image classification benchmarks. Notably, on ILSVRC-2012, our ASFP reduces more than 40% FLOPs on ResNet-50 with only 0.14% top-5 accuracy degradation, which is higher than the soft filter pruning by 8%.","","","10.1109/TCYB.2019.2933477","National Key Research Development Program of China; National Nature Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8816678","Filter pruning;image classification;neural networks","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Analytics for Workplace Risk and Disaster Management","S. Dalal; D. Bassu","Applied Analytics, Columbia University, 5798 New York, New York United States 10027-6902 (e-mail: sd2803@columbia.edu); Blackboard Insurance, New York, NY 10271, USA (e-mail: devasis.bassu@blackboardinsurance.com)","IBM Journal of Research and Development","","2019","PP","99","1","1","We discuss dynamic real-time analysis from multi-modal data fusion for contextual risk identification to generate “risk maps” for the workplace, resulting in timely identification of hazards and associated risk mitigation. It includes new machine/deep learning, analytics, methods and its applications that deal with the unconventional data collected from pictures, videos, documents, mobile apps, sensors/Internet of Things [IoT], Occupational Safety and Health Administration [OSHA] rules and Building Information Model [BIM] models, etc. Specifically, we describe a number of advances and challenges in this field with applications of Computer Vision [CV], Natural Language Processing [NLP] and sensor data analysis. Applications include automated cause identification, damage prevention and disaster recovery using current and historical claims data and other public data. The methods developed can be applied to any given situation with different groups of people including first responders. Finally, we discuss some of the important non-technical challenges related to business practicality, privacy, and industry regulations.","","","10.1147/JRD.2019.2945693","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8867981","","","","","","","","","","","","IBM","IBM Early Access Articles"
"Identifying probabilistically shaped modulation formats through 2D Stokes planes with two-stage deep neural networks","W. Zhang; D. Zhu; N. Zhang; H. Xu; X. Zhang; H. Zhang; Y. Li","School of Science, Beijing University of Posts and Telecommunications, China.; School of Science, Beijing University of Posts and Telecommunications, China.; State Key Laboratory of Information Photonics and Optical Communications, Beijing University of Posts and Telecommunications, China.; Physics Science and Information Engineering College, Liaocheng University, China and Shandong Provincial Key Laboratory of Optical Communication Science and Technology, China.; State Key Laboratory of Information Photonics and Optical Communications, Beijing University of Posts and Telecommunications, China.; State Key Laboratory of Information Photonics and Optical Communications, Beijing University of Posts and Telecommunications, China.; School of Electronic Engineering, Beijing Key Laboratory of Work Safety and Intelligent Monitoring, Beijing University of Posts and Telecommunications, China.","IEEE Access","","2019","PP","99","1","1","A lightweight two-stage convolutional (deep) neural network (CNN) based modulation format identification (MFI) scheme is proposed and demonstrated for the polarization domain multiplexing (PDM) fiber communication system with probabilistically shaped (PS) modulation formats. The scheme is tested on a PDM system at a symbol rate of 28 GBaud. Six probabilistically shaped (PS) modulation formats (of 3 bit/symbol PS-16QAM, PS-32QAM, and PS-64QAM, of 4 bit/symbol PS-32QAM and PS-64QAM, and of 5 bit/symbol PS-64QAM) along with six standard modulation formats (BPSK, QPSK, 8PSK and three uniformly shaped (US) QAM: US-16QAM, US-32QAM and US-64QAM) are identified by the trained CNN. By taking advantage of computer vision, the results show that the proposed scheme can provide very high accuracy and significantly improve the identification performance over the existing techniques. The influences of the learning rate of the CNN are also discussed.","","","10.1109/ACCESS.2019.2963504","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8947928","Optical fiber communication;modulation format identification;convolutional neural networks","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Learning to Score Figure Skating Sport Videos","C. Xu; Y. Fu; B. Zhang; Z. Chen; Y. Jiang; X. Xue","School of Data Science, Fudan University,Shanghai, China.; School of Data Science, Fudan University,Shanghai, China.; Electrical and System Engineering Department, Washington University in St. Louis.; School of Computer Science, Shanghai Key Lab of Intelligent Information Processing, Fudan University.; School of Computer Science, Shanghai Key Lab of Intelligent Information Processing, Fudan University.; School of Computer Science, Shanghai Key Lab of Intelligent Information Processing, Fudan University.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","This paper aims at learning to score the figure skating sports videos. To address this task, we propose a deep architecture that includes two complementary components, i.e., Self-Attentive LSTM and Multi-scale Convolutional Skip LSTM. These two components can efficiently learn the local and global sequential information in each video. Furthermore, we present a large-scale figure skating sports video dataset FisV dataset. This dataset includes 500 figure skating videos with the average length of 2 minutes and 50 seconds. Each video is annotated by two scores of nine different referees, i.e., Total Element Score(TES) and Total Program Component Score (PCS). Our proposed model is validated on FisV and MIT-skate datasets. The experimental results show the effectiveness of our models in learning to score the figure skating videos. The codes and datasets would be downloaded from https://github.com/loadder/MS_LSTM.git.","","","10.1109/TCSVT.2019.2927118","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8756030","figure skating sport videos;Self-Attentive LSTM;Multi-scale Convolutional Skip LSTM","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Learning Reliable Visual Saliency for Model Explanations","Y. Wang; H. Su; B. Zhang; X. Hu","Computer Science, Tsinghua University, 12442 Beijing China 100084 (e-mail: wang-yl15@mails.tsinghua.edu.cn); Computer Science and Technology, Tsinghua University, 12442 Beijing, Beijing China (e-mail: suhangss@mail.tsinghua.edu.cn); Computer Science and Technology, Tsinghua University, 12442 Beijing, Beijing China (e-mail: dcszb@tsinghua.edu.cn); Computer Science, Tsinghua University, 12442 Beijing China (e-mail: xlhu@tsinghua.edu.cn)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","By highlighting important features that contribute to model prediction, visual saliency is used as a natural form to interpret the working mechanism of deep neural networks. Numerous methods have been proposed to achieve better saliency results. However, we find that previous visual saliency methods are not reliable enough to provide meaningful interpretation through a simple sanity check: saliency methods are required to explain the output of non-maximum prediction classes, which are usually not ground-truth classes. For example, let the methods interpret an image of ""dog"" given a wrong class label ""fish"" as the query. This procedure can test whether these methods reliably interpret model's predictions based on existing features that appear in the data. Our experiments show that previous methods failed to pass the test by generating similar saliency maps or scattered patterns. This false saliency response can be dangerous in certain scenarios, such as medical diagnosis. We find that these failure cases are mainly due to the attribution vanishing and adversarial noise within these methods. In order to learn reliable visual saliency, we propose a simple method that requires the output of the model to be close to the original output while learning an explanatory saliency mask. To enhance the smoothness of the optimized saliency masks, we then propose a simple Hierarchical Attribution Fusion (HAF) technique. In order to fully evaluate the reliability of visual saliency methods, we propose a new task Disturbed Weakly Supervised Object Localization (D-WSOL) to measure whether these methods can correctly attribute the model's output to existing features. Experiments show that previous methods fail to meet this standard, and our approach helps to improve the reliability by suppressing false saliency responses. After observing a significant layout difference in saliency masks between real and adversarial samples. we propose to train a simple CNN on these learned hierarchical attribution masks to distinguish adversarial samples. Experiments show that our method can improve detection performance over other approaches significantly.","","","10.1109/TMM.2019.2949872","National Key Research and Development Program of China; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8884184","","Visualization;Reliability;Predictive models;Task analysis;Perturbation methods;Backpropagation;Real-time systems","","","","","","","","","","IEEE","IEEE Early Access Articles"
"CDbin: Compact Discriminative Binary Descriptor Learned with Ef?cient Neural Network","J. Ye; S. Zhang; T. Huang; Y. Rui","School of Electronic Engineering and Computer Science, Peking University, Beijing 100871, China.; School of Electronic Engineering and Computer Science, Peking University, Beijing 100871, China.; School of Electronic Engineering and Computer Science, Peking University, Beijing 100871, China.; Lenovo Group, No. 6, Shangdi West Road, Haidian District, Beijing 100871, China.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","As an important computer vision task, image matching requires ef?cient and discriminative local descriptors. Most of existing descriptors like SIFT and ORB are hand-crafted. It is necessary to study more optimized descriptors through endto-end learning. This paper proposes compact binary descriptors learned with a lightweight Convolutional Neural Network (CNN), which is ef?cient for training and testing. Speci?cally, we propose a CNN with no larger than ?ve layers for descriptor learning. The resulting descriptors, i.e., Compact Discriminative binary descriptors (CDbin) are optimized with four complementary loss functions, i.e., 1) triplet loss to ensure the discriminative power, 2) quantization loss to decrease the quantization error, 3) correlation loss to ensure the feature compactness, and 4) even-distribution loss to enrich the embedded information. Extensive experiments on two image patch datasets and three image retrieval datasets show that CDbin exhibits competitive performance compared with existing descriptors. For example, 64-bit CDbin substantially outperforms 256-bit ORB and 1024-bit SIFT on Hpatches dataset. Although generated by a shallow CNN, CDbin also outperforms several recent deep descriptors.","","","10.1109/TCSVT.2019.2896095","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8630864","Image Patch Matching;Binary Descriptor;Convolutional Neural Networks","Feature extraction;Binary codes;Training;Quantization (signal);Neural networks;Task analysis;Correlation","","","","","","","","","","IEEE","IEEE Early Access Articles"
"HPatches: A benchmark and evaluation of handcrafted and learned local descriptors","V. Balntas; K. Lenc; A. Vedaldi; T. Tuytelaars; J. Matas; K. Mikolajczyk","Engineering Science, University Of Oxford, Oxford, Oxfordshire United Kingdom of Great Britain and Northern Ireland (e-mail: balntas@robots.ox.ac.uk); Engineering Science, University of Oxford, Oxford, Oxfordshire United Kingdom of Great Britain and Northern Ireland OX1 3PJ (e-mail: karel@robots.ox.ac.uk); Engineering Science, Oxford University, Oxford, Oxfordshire United Kingdom of Great Britain and Northern Ireland OX13PJ (e-mail: vedaldi@robots.ox.ac.uk); ESAT - PSI, K.U. Leuven, Belgium, Leuven, Belgium Belgium 3001 (e-mail: tinne.tuytelaars@esat.kuleuven.be); Dept. of Cybernetics, Czech Technical University, Prague, - Czech Republic (e-mail: matas@cmp.felk.cvut.cz); Electrical and Electronic Engineering, Imperial College London, 4615 London, London United Kingdom of Great Britain and Northern Ireland (e-mail: k.mikolajczyk@imperial.ac.uk)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","In this paper, a novel benchmark is introduced for evaluating local image descriptors. We demonstrate limitations of the commonly used datasets and evaluation protocols, that lead to ambiguities and contradictory results in the literature. Furthermore, these benchmarks are nearly saturated due to the recent improvements in local descriptors obtained by learning from large annotated datasets. To address these issues, we introduce a new large dataset suitable for training and testing modern descriptors, together with strictly defined evaluation protocols in several tasks such as matching, retrieval and verification. This allows for more realistic, thus more reliable comparisons in different application scenarios. We evaluate the performance of several state-of-the-art descriptors and analyse their properties. We show that a simple normalisation of traditional hand-crafted descriptors is able to boost their performance to the level of deep learning based descriptors once realistic benchmarks are considered. Additionally we specify a protocol for learning and evaluating using cross validation. We show that when training state-of-the-art descriptors on this dataset, the traditional verification task is almost entirely saturated.","","","10.1109/TPAMI.2019.2915233","Engineering and Physical Sciences Research Council; H2020 European Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8712555","local features;feature descriptors;image matching;patch classification","Benchmark testing;Detectors;Protocols;Task analysis;Feature extraction;Training;Image matching","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Familial Clustering For Weakly-labeled Android Malware Using Hybrid Representation Learning","Y. Zhang; Y. Sui; S. Pan; Z. Zheng; B. Ning; I. Tsang; W. Zhou","NA; NA; NA; NA; NA; NA; NA","IEEE Transactions on Information Forensics and Security","","2019","PP","99","1","1","Labeling malware or malware clustering is important for identifying new security threats, triaging and building reference datasets. The state-of-the-art Android malware clustering approaches rely heavily on the raw labels from commercial AntiVirus (AV) vendors, which causes misclustering for a substantial number of weakly-labeled malware due to the inconsistent, incomplete and overly generic labels reported by these closed-source AV engines, whose capabilities vary greatly and whose internal mechanisms are opaque (i.e., intermediate detection results are unavailable for clustering). The raw labels are thus often used as the only important source of information for clustering. To address the limitations of the existing approaches, this paper presents ANDRE, a new ANDroid Hybrid REpresentation Learning approach to clustering weakly-labeled Android malware by preserving heterogeneous information from multiple sources (including the results of static code analysis, the metainformation of an app, and the raw-labels of the AV vendors) to jointly learn a hybrid representation for accurate clustering. The learned representation is then fed into our outlieraware clustering to partition the weakly-labeled malware into known and unknown families. The malware whose malicious behaviours are close to those of the existing families on the network, are further classified using a three-layer Deep Neural Network (DNN). The unknown malware are clustered using a standard density-based clustering algorithm. We have evaluated our approach using 5,416 ground-truth malware from Drebin and 9,000 malware from VIRUSSHARE (uploaded between Mar. 2017 and Feb. 2018), consisting of 3324 weakly-labeled malware. The evaluation shows that ANDRE effectively clusters weaklylabeled malware which cannot be clustered by the state-of-theart approaches, while achieving comparable accuracy with those approaches for clustering ground-truth samples.","","","10.1109/TIFS.2019.2947861","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8871171","","Malware;Labeling;Engines;Neural networks;Standards;Clustering algorithms;Smart phones","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A High-Precision Positioning Approach for Catenary Support Components With Multiscale Difference","Z. Liu; K. Liu; J. Zhong; Z. Han; W. Zhang","School of Electrical Engineering, Southwest Jiaotong University, Chengdu 610031, China (e-mail: liuzg_cd@126.com).; School of Electrical Engineering, Southwest Jiaotong University, Chengdu 610031, China.; School of Electrical Engineering, Southwest Jiaotong University, Chengdu 610031, China.; School of Electrical Engineering, Southwest Jiaotong University, Chengdu 610031, China.; Infrastructure Inspection Research Institute, China Academy of Railway Sciences, Beijing 100081, China.","IEEE Transactions on Instrumentation and Measurement","","2019","PP","99","1","12","The catenary support components (CSCs) are the most important devices in high-speed railways to support contact lines for powering trains. To estimate the states of CSCs, it is very necessary to locate their positions in a monitoring system based on computer vision. Considering the application scenarios and characteristics of CSCs, an automatic and quick positioning system is designed in this paper to simultaneously position the multiscale CSCs with 12 categories. In the system, an effective framework called CSCs network (CSCNET) is presented, which cascades the coarse positioning network and the fine positioning network to reduce multiscale differences between different CSCs. In the coarse positioning network, a new unsupervised clustering algorithm based on the relative positioning information is proposed to classify the catenary images. Then, a convolutional neural network (CNN) classification network is trained to extract the structural features of catenary images and generate the proposal regions with labels. In the fine positioning network, a modified CNN positioning framework is applied to obtain the accurate positions of CSCs based on the coarse positioning results. Due to the special lightweight structure with a classification network, the relative position information is applied and makes the CSCNET sensitive to small-scale components. The experimental results from some high-speed railway lines in China show that the proposed system has obvious advantages in the CSCs positioning. The mean average precision and frames per second of CSCNET reach 0.837 and 2.17, respectively. Compared with some popular convolutional networks [faster region-based CNN (Faster R-CNN), etc.] and a typical positioning method, the proposed system significantly improves the AP without increasing the computational time.","","","10.1109/TIM.2019.2905905","National Natural Science Foundation of China; Sichuan Province Youth Science and Technology Innovation Team; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8824211","Catenary support components (CSCs);convolutional neural network (CNN);electrified railway;multiscale;positioning.","Clustering algorithms;Rail transportation;Proposals;Inspection;Feature extraction;Insulators;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"WiderPerson: A Diverse Dataset for Dense Pedestrian Detection in the Wild","S. Zhang; Y. Xie; J. Wan; H. Xia; S. Z. Li; G. Guo","CBSR & NLPR, Institute of Automation Chinese Academy of Sciences, Beijing China 100080 (e-mail: shifeng.zhang@nlpr.ia.ac.cn); Viterbi School of Engineering, University of South Carolina, 2629 Columbia, South Carolina United States (e-mail: microos316@gmail.com); National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing China 100190 (e-mail: jun.wan@ia.ac.cn); College of Energy and Power Engineering, Nanjing University of Aeronautics and Astronautics, 47854 Nanjing, Jiangsu China (e-mail: hanson_cha@163.com); Center for Biometrics and Security Research, Institute of Automation, Chinese Academy of Sciences, Beijing China (e-mail: szli@nlpr.ia.ac.cn); Computer Science and Electrical Engineering, West Virginia University, Morgantown, West Virginia United States 26506 (e-mail: Guodong.Guo@mail.wvu.edu)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","Pedestrian detection has achieved significant progress with the availability of exiting benchmark datasets. However, there is a gap in the diversity and density between real world requirements and current pedestrian detection benchmarks: 1) most of existing datasets are taken from a vehicle driving through the regular traffic scenario, usually leading to insufficient diversity; 2) crowd scenarios with highly occluded pedestrians are still under represented, resulting in low density. To narrow this gap and facilitate future pedestrian detection research, we introduce a large and diverse dataset named WiderPerson for dense pedestrian detection in the wild. This dataset involves five types of annotations in a wide range of scenarios, no longer limited to the traffic scenario. There are a total of 13,382 images with 399,359 annotations, i.e., 29.84 annotations per image, which means this dataset contains dense pedestrians with various kinds of occlusions. Hence, pedestrians in the proposed dataset are extremely challenging due to large variations in the scenario and occlusion, which is suitable to evaluate pedestrian detectors in the wild. We introduce an improved Faster R-CNN and the vanilla RetinaNet to serve as baselines for the new pedestrian detection benchmark. Several experiments are conducted on previous datasets including Caltech-USA and CityPersons to analyze the generalization capabilities of the proposed dataset and we achieve state-of-the-art performances on these previous datasets without bells and whistles. Finally, we analyze common failure cases and find the classification ability of pedestrian detector needs to be improved to reduce false alarm and miss detection rates.","","","10.1109/TMM.2019.2929005","National Natural Science Foundation of China; Science and Technology Development Fund of Macau; National Key Research and Development Plan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8764496","Pedestrian detection;dataset;rich diversity;high density","Benchmark testing;Detectors;Training;Urban areas;Cameras;Task analysis;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Identification of Encrypted Traffic Through Attention Mechanism Based Long Short Term Memory","H. Yao; C. Liu; P. Zhang; S. Wu; C. Jiang; S. Yu","Information and Communication Engineering, Beijing University of Posts and Telecommunications, 12472 Beijing, Beijing China 100088 (e-mail: yaohaipeng@bupt.edu.cn); University of Science and Technology Beijing School of Computer and Communication Engineering, 506742 Haidian-qu, Beijing China 100083 (e-mail: 254557889@qq.com); College of Computer & Communication Engineering, China University of Petroleum Huadong - Qingdao Campus, 74591 Qingdao, Shandong China (e-mail: 25640521@qq.com); School of Information and Communication Wngineering, Beijing University of Posts and Telecommunications, 12472 Beijing, Beijing China 1000876 (e-mail: peach.shengsheng@gmail.com); Space Center, Tsinghua University, 12442 Beijing, Beijing China 100084 (e-mail: jchx@tsinghua.edu.cn); School of Software, University of Technology Sydney Faculty of Engineering and Information Technology, 120558 Ultimo, New South Wales Australia 2007 (e-mail: shui.yu@uts.edu.au)","IEEE Transactions on Big Data","","2019","PP","99","1","1","Network traffic classification has become an important part of network management, which is beneficial for achieving intelligent network operation and maintenance, enhancing the network quality of service (QoS), and for network security. Given the rapid development of various applications and protocols, more and more encrypted traffic has emerged in networks. Traditional traffic classification methods exhibited the unsatisfied performance since the encrypted traffic is no longer in plain text. In this work, we modeled the time-series network traffic by the recurrent neural network (RNN). Moreover, the attention mechanism was introduced for assisting network traffic classification in the form of the following two models, the attention aided long short term memory (LSTM) as well as the hierarchical attention network (HAN). Finally, relying on the ISCX VPN-NonVPN dataset, extensive experiments were conducted, showing that the proposed methods achieved 91.2% in accuracy while the highest accuracy of other methods was 89.8% relying on the same dataset.","","","10.1109/TBDATA.2019.2940675","Natural Science Foundation of Shandong Province; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8845643","Network traffic classification;encrypted traffic;LSTM;attention mechanism","Feature extraction;Protocols;Big Data;Deep learning;Encryption","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Structured Label Inference for Visual Understanding","N. I. Nauata Junior; H. Hu; G. Zhou; Z. Deng; Z. Liao; G. Mori","Computing Science, Simon Fraser University Faculty of Applied Sciences, 120447 Burnaby, British Columbia Canada (e-mail: nnauata@sfu.ca); Viterbi School of Engineering, University of Southern California, Los Angeles, California United States (e-mail: frank.hexiang@gmail.com); Oracle Labs, Oracle Corp, 50301 Vancouver, British Columbia Canada (e-mail: zhouguangtong@gmail.com); School of Computing Science, Simon Fraser University, Burnaby, British Columbia Canada (e-mail: zhiweid@sfu.ca); Computer Science, Zhejiang University, Hangzhou, Zhejiang China (e-mail: zliao@zju.edu.cn); Computing Science, Simon Fraser University, Burnaby, British Columbia Canada V5A 1S6 (e-mail: mori@cs.sfu.ca)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Visual data such as images and videos contain a rich source of structured semantic labels as well as a wide range of interacting components. Visual content could be assigned with fine-grained labels describing major components, coarse-grained labels depicting high level abstractions, or a set of labels revealing attributes. Such categorization over different, interacting layers of labels evinces the potential for a graph-based encoding of label information. In this paper, we exploit this rich structure for performing graph-based inference in label space for a number of tasks: multi-label image and video classification and action detection in untrimmed videos. We consider the use of the Bidirectional Inference Neural Network (BINN) and Structured Inference Neural Network (SINN) for performing graph-based inference in label space and propose a Long Short-Term Memory (LSTM) based extension for exploiting activity progression on untrimmed videos. The methods were evaluated on (i) the Animal with Attributes (AwA), Scene Understanding (SUN) and NUS-WIDE datasets for multi-label image classification, (ii) the first two releases of the YouTube-8M large scale dataset for multi-label video classification, and (iii) the THUMOS'14 and MultiTHUMOS video datasets for action detection. Our results demonstrate the effectiveness of structured label inference in these challenging tasks, achieving significant improvements against baselines.","","","10.1109/TPAMI.2019.2893215","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8613870","Computer vision;multi-label classification;image classification;video recognition;action detection;structured inference","Videos;Visualization;Task analysis;Hidden Markov models;Deep learning;Feature extraction;Neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Novel Key-frames Selection Framework for Comprehensive Video Summarization","C. Huang; H. Wang","National Key Laboratory of AerospaceFlight Dynamics and School of Astronautics, Northwestern Polytechnical University, Xi’an, Shaanxi,710072, China.; National Key Laboratory of AerospaceFlight Dynamics and School of Astronautics, Northwestern Polytechnical University, Xi’an, Shaanxi,710072, China.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Video summarization has become a popular method in processing massive video data. The key point of video summarization is to select the key-frames to represent the effective contents of a video sequence. Existing methods can only extract static images of video as the content summarization, but they have ignored the representation of motion information. To cope with these issues, a novel framework for an efficient video content summarization as well as video motion summarization is proposed. Initially, Capsules Net is trained as a spatiotemporal information extractor and an inter-frames motion curve is generated based on those spatiotemporal features. Subsequently, a transition effects detection (TED) method is proposed to automatically segment the video streams into shots. Finally, a self-attention model is introduced to select key-frames sequences inside shots, thus key static images are selected as video content summarization and optical flows can be calculated as video motion summarization. The ultimate experimental results demonstrate that our method is competitive on VSUMM, TvSum, SumMe and RAI datasets about shot segmentation and video content summarization, even can also represent a good motion summarization result.","","","10.1109/TCSVT.2019.2890899","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8601376","Key-frames selection;video summarization;Capsules Net;self-attention;transition effects detection","Feature extraction;Motion segmentation;Streaming media;Visualization;Spatiotemporal phenomena;Optical flow;Deep learning","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Interactive Contour Extraction via Sketch-Alike Dense-Validation Optimization","Y. Nie; X. Cao; P. Li; Q. Zhang; Z. Zhang; G. Li; H. Sun","School of Computer Science and Engineering, South China University of Technology, Guangzhou, China, 510006.; School of Computer Science and Engineering, South China University of Technology, Guangzhou, China, 510006.; Faculty of Information Technology, Macau University of Science and Technology, Macau 999078, China.; School of Data and Computer Science, Sun Yat-Sen University, Guangzhou, China.; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Shatin, New Territories, Hong Kong.; School of Computer Science and Engineering, South China University of Technology, Guangzhou, China, 510006.; Department of Computer Science and Engineering, Shanghai Jiao Tong University, China.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","We propose an interactive contour extraction method inspired by a skill often adopted in sketching: an artist usually sketches an object by firstly drawing lots of short, directional, and redundant strokes, then following these small strokes to draw the final outline of the object. Our method simulates this process. To extract a contour, our method relies on user interaction, which provides us with a narrow band containing the target contour. Then we densely sample subbands from the whole band, with each sub-band containing a local segment of the target contour. We design a curve-centered coordinate system in which a dynamic programming algorithm is proposed to extract the local segment in each sub-band. The local segment is guaranteed to be as evident and smooth as possible, to mimic the strokes sketched by the artist. Finally, we integrate all local segments of all sub-bands together to obtain the whole target contour based on weighted Principal Component Analysis (wPCA). Our method can extract high-quality object contours due to the dense validations among local segments. That is, even if one segment deviates from the right location, several other segments in its local neighborhood can correct it in the integration stage. Both quantitative experiments and a user study demonstrate the effectiveness of the proposed method.","","","10.1109/TCSVT.2019.2898691","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8638961","Sketching;image contour extraction;image segmentation;dynamic programming","Image segmentation;Image edge detection;Splines (mathematics);Heuristic algorithms;Dynamic programming;Computer science;Deep learning","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Robot Manipulation in Open Environments: New Perspectives","F. Guerin; P. Ferreira","Department of Computing Science, University of Aberdeen, AB24 3UE Aberdeen, Scotland.; DELL EMC.","IEEE Transactions on Cognitive and Developmental Systems","","2019","PP","99","1","1","The problem of performing everyday manipulation tasks robustly in open environments is currently beyond the capabilities of artificially intelligent robots; humans are required. The difficulty arises from the high variability in open environments; it is not feasible to program for, or train for, every variation. This correspondence paper presents the case for a new approach to the problem, based on three mutually dependent ideas: 1) highly transferable manipulation skills; 2) choice of representation: a scene can be modeled in several different ways; 3) top-down processes by which the robot’s task can influence the bottom-up processes interpreting a scene. The approach we advocate is supported by evidence from what we know about humans, and also the approach is implicitly taken by human designers in designing representations for robots. We present brief results of an implementation of these ideas in robot vision, and give some guidelines for how the key ideas can be implemented more generally in practical robot systems.","","","10.1109/TCDS.2019.2921098","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8731700","Robot Manipulation;Knowledge Representation;Commonsense Reasoning.","Robots;Task analysis;Training;Deep learning;Tools;Cognition","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Large-scale Database and a CNN Model for Attention-based Glaucoma Detection","L. Li; M. Xu; H. Liu; Y. Li; X. Wang; L. Jiang; Z. Wang; X. Fan; N. Wang","School of Electronic and Information Engineering, Beihang University, Beijing 100191 China.; School of Electronic and Information Engineering, Beihang University, Beijing 100191 China.; Beijing Institute of Ophthalmology, Beijing 100730 China.; School of Automation Sciences and Electrical Engineering, Beihang University, Beijing 100191 China.; School of Electronic and Information Engineering, Beihang University, Beijing 100191 China.; School of Electronic and Information Engineering, Beihang University, Beijing 100191 China.; School of Electronic and Information Engineering, Beihang University, Beijing 100191 China.; Department of Ophthalmology, Peking University Third Hospital, Beijing 100191 China. M. Xu is the corresponding author of this paper.; Beijing Institute of Ophthalmology, Beijing 100730 China.","IEEE Transactions on Medical Imaging","","2019","PP","99","1","1","Glaucoma is one of the leading causes of irreversible vision loss. Many approaches have recently been proposed for automatic glaucoma detection based on fundus images. However, none of the existing approaches can efficiently remove high redundancy in fundus images for glaucoma detection, which may reduce the reliability and accuracy of glaucoma detection. To avoid this disadvantage, this paper proposes an attention-based convolutional neural network (CNN) for glaucoma detection, called AG-CNN. Specifically, we first establish a large-scale attention-based glaucoma (LAG) database, which includes 11,760 fundus images labeled as either positive glaucoma (4,878) or negative glaucoma (6,882). Among the 11,760 fundus images, the attention maps of 5,824 images are further obtained from ophthalmologists through a simulated eye-tracking experiment. Then, a new structure of AG-CNN is designed, including an attention prediction subnet, a pathological area localization subnet and a glaucoma classification subnet. The attention maps are predicted in the attention prediction subnet to highlight the salient regions for glaucoma detection, under a weakly supervised training manner. In contrast to other attention-based CNN methods, the features are also visualized as the localized pathological area, which are further added in our AG-CNN structure to enhance the glaucoma detection performance. Finally, the experiment results from testing over our LAG database and another public glaucoma database show that the proposed AG-CNN approach significantly advances the state-of-the-art in glaucoma detection.","","","10.1109/TMI.2019.2927226","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8756196","glaucoma detection;attention mechanism;pathological area detection;weakly supervised","Databases;Feature extraction;Optical imaging;Biomedical optical imaging;Pathology;Deep learning","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"DeepDRBP-2L: a new genome annotation predictor for identifying DNA binding proteins and RNA binding proteins using Convolutional Neural Network and Long Short-Term Memory","J. Zhang; Q. Chen; B. Liu","Computer Science and Technology, Harbin Institute of Technology Shenzhen, 529484 Shenzhen, Guangdong China (e-mail: jzhang@bliulab.net); Computer Science and Technology, Harbin Institute of Technology Shenzhen, 529484 Shenzhen, Guangdong China (e-mail: qingcai.chen@hit.edu.cn); School of Computer Science and Technology, Harbin Institute of Technology Shenzhen, 529484 Shenzhen, Guangdong China (e-mail: bliu@insun.hit.edu.cn)","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2019","PP","99","1","1","DNA-binding proteins (DBPs) and RNA-binding proteins (RBPs) are two kinds of crucial proteins, which are associated with various cellule activities and some important diseases. Accurate identification of DBPs and RBPs facilitate both theoretical research and real world application. Existing sequence-based DBP predictors can accurately identify DBPs but incorrectly predict many RBPs as DBPs, and vice versa, resulting in low prediction precision. Moreover, some proteins (DRBPs) interacting with both DNA and RNA play important roles in gene expression and cannot be identified by existing computational methods. In this study, a two-level predictor named DeepDRBP-2L was proposed by combining Convolutional Neural Network (CNN) and the Long Short-Term Memory (LSTM). It is the first computational method that is able to identify DBPs, RBPs and DRBPs. Rigorous cross-validations and independent tests showed that DeepDRBP-2L is able to overcome the shortcoming of the existing methods and can go one further step to identify DRBPs. Application of DeepDRBP-2L to tomato genome further demonstrated its performance. The webserver of DeepDRBP-2L is freely available at http://bliulab.net/DeepDRBP-2L.","","","10.1109/TCBB.2019.2952338","Scientific Research Foundation in Shenzhen; Fok Ying-Tung Education Foundation for Young Teach-ers in the Higher Education Institutions of China; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8894524","DNA/RNA-binding protein;two-level framework;Convolution Neural Network;Long Short-Term Memory","Proteins;DNA;Benchmark testing;RNA;Deep learning;Databases;Convolutional neural nets","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep convolutional and recurrent neural networks for cell motility discrimination and prediction","J. Kimmel; A. Brack; W. Marshall","Biochemistry and Biophysics, University of California, San Francisco, San Francisco, California United States (e-mail: jacob.kimmel@gmail.com); Orthopedic Surgery, University of California, San Francisco, San Francisco, California United States (e-mail: andrew.brack@ucsf.edu); Biochemistry and Biophysics, University of California, San Francisco, San Francisco, California United States 94158 (e-mail: wallace.ucsf@gmail.com)","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2019","PP","99","1","1","Cells in culture display diverse motility behaviors that may reflect differences in cell state and function, providing motivation to discriminate between different motility behaviors. Current methods to do so rely upon manual feature engineering. However, the types of features necessary to distinguish between motility behaviors can vary greatly depending on the biological context, and it is not always clear which features may be most predictive in each setting for distinguishing particular cell types or disease states. Convolutional neural networks (CNNs) are machine learning models ideally suited to the analysis of spatial data, allowing for relevant spatial features to be learned as parameters of a model. Given that motility data is inherently spatial, we apply CNNs to classify different motility behaviors using two novel approaches. The first approach represents motility explicitly as a 3D space with markers denoting a cell's location at each time point, and the second utilizes recurrent long-term short-term memory (LSTM) units to represent the temporal dimension implicitly. Both 3D CNNs and convolutionalrecurrent neural networks (RNNs) provide accurate classification of simulated motility behaviors, the experimentally measured motility behaviors of multiple cell types, and characteristic motility behaviors of muscle stem cell differentiation states.","","","10.1109/TCBB.2019.2919307","National Science Foundation; National Institutes of Health; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8747369","convolutional neural network;recurrent neural network;cell motility;cell classification;long short-term memory","Computer architecture;Microprocessors;Feature extraction;Time series analysis;Convolutional codes;Recurrent neural networks;Task analysis","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Online Meta Adaptation for Fast Video Object Segmentation","H. Xiao; B. Kang; Y. Liu; M. Zhang; J. Feng","System Engineering, National University of Defense Technology, 58294 Changsha, Huanan China (e-mail: xiaohuaxin@nudt.edu.cn); ECE, National University of Singapore, 37580 Singapore, Singapore Singapore (e-mail: kang@u.nus.edu); System Engineering, National University of Defense Technology, 58294 Changsha, Huanan China (e-mail: jasonyuliu@nudt.edu.cn); System Engineering, National University of Defense Technology, 58294 Changsha, Huanan China (e-mail: mjzhang@nudt.edu.cn); ECE, National University of Singapore, 37580 Singapore, Singapore Singapore (e-mail: elefjia@nus.edu.sg)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Conventional deep neural networks based video object segmentation (VOS) methods are dominated by heavily fine-tuning a segmentation model on the first frame of a given video, which is time-consuming and inefficient. In this paper, we propose a novel method which rapidly adapts a base segmentation model to new video sequences with only a couple of model-update iterations, without sacrificing performance. Such attractive efficiency benefits from the meta-learning paradigm which leads to a meta-segmentation model and a novel continuous learning approach which enables online adaptation of the segmentation model. Concretely, we train a meta-learner on multiple VOS tasks such that the meta model can capture their common knowledge and gains the ability to fast adapt the segmentation model to new video sequences. Furthermore, to deal with unique challenges of VOS tasks from temporal variations in the video, e.g., object motion and appearance changes, we propose a principled online adaptation approach that continuously adapts the segmentation model across video frames by exploiting temporal context effectively, providing robustness to annoying temporal variations. Integrating the meta-learner with the online adaptation approach, the proposed VOS model achieves competitive performance against the state-of-the-arts and moreover provides faster per-frame processing speed.","","","10.1109/TPAMI.2018.2890659","NUS IDS; NUS startup; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8611188","Meta Learning;Video Object Segmentation;Convolutional Neural Networks","Adaptation models;Task analysis;Object segmentation;Optical imaging;Motion segmentation;Image segmentation;Runtime","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Concentrated Local Part Discovery with Fine-Grained Part Representation for Person Re-identification","C. Wan; Y. Wu; X. Tian; J. Huang; X. Hua","Department of Electronic Engineering and Information Science, University of Science and Technology of China, Hefei, Anhui China (e-mail: wancq14@mail.ustc.edu.cn); Damo Academy, Alibaba Group, Hangzhou China (e-mail: matthew.wy@alibaba-inc.com); Department of Electronic Engineering and Information Science, University of Science and Technology of China, Hefei, Anhui China 230027 (e-mail: xinmei@ustc.edu.cn); Damo Academy, Alibaba Group, Hangzhou China (e-mail: jianqiang.hjq@alibaba-inc.com); iDST, Alibaba Group, Hangzhou China (e-mail: xiansheng.hxs@alibaba-inc.com)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","The attention mechanism for person re-identification has been widely studied with deep convolutional neural networks. This mechanism works as a good complement to the global features extracted from an image of the entire human body. However, existing works mainly focus on discovering local parts with simple feature representations, such as global average pooling. Moreover, these works either require extra supervision, such as labeling of body joints, or pay little attention to the guidance of part learning, resulting in scattered activation of learned parts. Furthermore, existing works usually extract local features from different body parts via global average pooling and then concatenate them together as good global features. We find that local features acquired in this way contribute little to the overall performance. In this paper, we argue the significance of local part description and explore the attention mechanism from both local part discovery and local part representation aspects. For local part discovery, we propose a new constrained attention module to make the activated regions concentrated and meaningful without extra supervision. For local part representation, we propose a statistical-positional-relational descriptor to represent local parts from a fine-grained viewpoint. Extensive experiments are conducted to validate the overall performance, the effectiveness of each component, and the generalization ability. We achieve a rank-1 accuracy of 95.1% on Market1501, 64.7% on CUHK03, 87.1% on DukeMTMC-ReID, and 79.9% on MSMT17, outperforming state-of-the-art methods.","","","10.1109/TMM.2019.2946486","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8864036","person re-identification;local part learning;constraint attention mechanism;fine-grained representation","Feature extraction;Visualization;Cameras;Convolutional neural networks;Head;Torso;Legged locomotion","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Convolutional Neural Networks for Spectroscopic Redshift Estimation on Euclid Data","R. Stivaktakis; G. Tsagkatakis; B. Moraes; F. Abdalla; J. Starck; P. Tsakalides","Computer Science Department, University of Crete - Heraklion Campus, 150573 Heraklion, Crete Greece (e-mail: stivakt@ics.forth.gr); Institute of Computer Science, FORTH, Heraklion, Crete Greece 73100 (e-mail: greg@ics.forth.gr); Instituto de Fisica, Universidade Federal do Rio de Janeiro, 28125 Rio de Janeiro, RJ Brazil (e-mail: b.moraes@ucl.ac.uk); Department of Physics and Electronics, Rhodes University, 59100 Grahamstown, South Africa South Africa (e-mail: filipe.abdalla@gmail.com); CEA Saclay, Paris, France France (e-mail: jean-luc.starck@cea.fr); Institute of Computer Science (ICS), FORTH, 54570 Heraklion, Crete Greece (e-mail: tsakalid@ics.forth.gr)","IEEE Transactions on Big Data","","2019","PP","99","1","1","In this paper, we address the problem of spectroscopic redshift estimation in Astronomy. Due to the expansion of the Universe, galaxies recede from each other on average. This movement causes the emitted electromagnetic waves to shift from the blue part of the spectrum to the red part, due to the Doppler effect. Redshift is one of the most important observables in Astronomy, allowing the measurement of galaxy distances. Several sources of noise render the estimation process far from trivial, especially in the low signal-to-noise regime of many astrophysical observations. In recent years, new approaches for a reliable and automated estimation methodology have been sought out, in order to minimize our reliance on currently popular techniques that heavily involve human intervention. The fulfilment of this task has evolved into a grave necessity, in conjunction with the insatiable generation of immense amounts of astronomical data. In our work, we introduce a novel approach based on Deep Convolutional Neural Networks. The proposed methodology is extensively evaluated on a spectroscopic dataset of full spectral energy galaxy distributions, modelled after the upcoming Euclid satellite galaxy survey. Experimental analysis on observations of idealistic and realistic conditions demonstrate the potent capabilities of the proposed scheme.","","","10.1109/TBDATA.2019.2934475","DEDALE Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798648","Astrophysics;Cosmology;Deep Learning;Convolutional Neural Networks;Spectroscopic Redshift Estimation;Euclid","","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"MRFN: Multi-Receptive-Field Network for Fast and Accurate Single Image Super-Resolution","Z. He; Y. Cao; L. Du; B. Xu; J. Yang; Y. Cao; S. Tang; Y. Zhuang","School of Mechanical Engineering, Zhejiang University, Hangzhou China (e-mail: zeweihe@zju.edu.cn); School of Mechanical Engineering, Zhejiang University, Hangzhou China (e-mail: caoyp@zju.edu.cn); Department of Mathematics Teaching and Research, Shaoxing University Yuanpei College, Shaoxing, Zhejiang China (e-mail: dulei@mail.ustc.edu.cn); School of Mechanical Engineering, Zhejiang University, Hangzhou China (e-mail: 21625177@zju.edu.cn); School of Mechanical Engineering, Zhejiang University, Hangzhou China (e-mail: yangjx@zju.edu.cn); School of Mechanical Engineering, Zhejiang University, Hangzhou China (e-mail: sdcaoyl@zju.edu.cn); College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang China 310027 (e-mail: siliang@zju.edu.cn); The Institute of Artificial Intelligence, Zhejiang University, Hangzhou China 310027 (e-mail: yzhuang@cs.zju.edu.cn)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","Recently, convolutional neural network (CNN) based models have shown great potential in the task of single image super-resolution (SISR). However, many state-of-the-art SISR solutions are reproducing some tricks proven effective in other vision tasks, such as pursuing a deeper model. In this paper, we propose a new solution (named as Multi-Receptive-Field Network - MRFN), which outperforms existing SISR solutions in three different aspects. First, from receptive field: a novel multi-receptive-field (MRF) module is proposed to extract and fuse features in different receptive fields from local to global. Integrating these hierarchical features can generate better mappings on recovering high-fidelity details at different scales. Second, from network architectures: both dense skip connections and deep supervision are utilized to combine features from the current MRF module and preceding ones for training more representative features. Moreover, a deconvolution layer is embedded at the end of network to avoid artificial priors induced by numerical data pre-processing (e.g., bicubic stretching), and speedup the restoration process. Finally, from error modeling: different from $L1$ and $L2$ loss functions, we proposed a novel two-parameter training loss called Weighted Huber loss function which can adaptively adjust the value of back-propagated derivative according to the residual value, thus fit the reconstruction error more effectively. Extensive qualitative and quantitative evaluation results on benchmark datasets demonstrate that our proposed MRFN can achieve more accurate recovering results than most state-of-the-art methods with significantly less complexity.","","","10.1109/TMM.2019.2937688","Fundamental Research Funds for the Central Universities; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812972","single image super-resolution;deep learning;multi-receptive-field;loss function","Feature extraction;Training;Image reconstruction;Image resolution;Image restoration;Convolutional neural networks;Computational modeling","","","","","","","","","","IEEE","IEEE Early Access Articles"
"DeepCog: Optimizing Resource Provisioning in Network Slicing with AI-based Capacity Forecasting","D. Bega; M. Gramaglia; M. Fiore; A. Banchs; X. Costa-Perez","IMDEA Networks Institute, 28918 Leganés, Spain and Telematic Engineering Department, University Carlos III of Madrid, 28911 Leganés, Spain.; Telematic Engineering Department, University Carlos III of Madrid, 28911 Leganés, Spain.; CNR, 10129 Torino, Italy.; IMDEA Networks Institute, 28918 Leganés, Spain and Telematic Engineering Department, University Carlos III of Madrid, 28911 Leganés, Spain.; NEC Laboratories Europe, 69115 Heidelberg, Germany.","IEEE Journal on Selected Areas in Communications","","2019","PP","99","1","1","The dynamic management of network resources is both a critical and challenging task in upcoming multi-tenant mobile networks, which requires allocating capacity to individual network slices so as to accommodate future time-varying service demands. Such an anticipatory resource configuration process must be driven by suitable predictors that take into account the monetary cost associated to overprovisioning or underprovisioning of networking capacity, computational power, memory, or storage. Legacy models that aim at forecasting traffic demands fail to capture these key economic aspects of network operation. To close this gap, we present DeepCog, a deep neural network architecture inspired by advances in image processing and trained via a dedicated loss function. Unlike traditional traffic volume predictors, DeepCog returns a cost-aware capacity forecast, which can be directly used by operators to take short- and long-term reallocation decisions that maximize their revenues. Extensive performance evaluations with real-world measurement data collected in a metropolitan-scale operational mobile network demonstrate the effectiveness of our proposed solution, which can reduce resource management costs by over 50% in practical case studies.","","","10.1109/JSAC.2019.2959245","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8932440","Mobile networks;Network Slicing;5G networks;Artificial Intelligence;Deep Learning","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"GradientFlow: Optimizing Network Performance for Large-Scale Distributed DNN Training","P. Sun; Y. Wen; R. Han; W. Feng; S. Yan","SenseTime Research, Hong Kong, Hong Kong Hong Kong (e-mail: sunp0003@e.ntu.edu.sg); Nanyang Technological University, 54761 Singapore, Singapore Singapore (e-mail: ygwen@ntu.edu.sg); SenseTime Research, Hong Kong, Hong Kong Hong Kong (e-mail: hanruobing@sensetime.com); SenseTime Research, Hong Kong, Hong Kong Hong Kong (e-mail: fengwansen@sensetime.com); SenseTime Research, Hong Kong, Hong Kong Hong Kong (e-mail: yanshengen@sensetime.com)","IEEE Transactions on Big Data","","2019","PP","99","1","1","It is important to scale out deep neural network (DNN) training for reducing model training time. The high communication overhead is one of the major performance bottlenecks for distributed DNN training across multiple GPUs. Our investigations have shown that popular open-source DNN systems could only achieve 2.5 speedup ratio on 64 GPUs connected by 56 Gbps network. To address this problem, we propose a communication backend named GradientFlow for distributed DNN training, and employ a set of network optimization techniques. First, we integrate ring-based allreduce, mixed-precision training, and computation/communication overlap into GradientFlow. Second, we propose lazy allreduce to improve network throughput by fusing multiple communication operations into a single one, and design coarse-grained sparse communication to reduce network traffic by only transmitting important gradient chunks. When training AlexNet and ResNet-50 on the ImageNet dataset using 512 GPUs, our approach could achieve 410.2 and 434.1 speedup ratio respectively.","","","10.1109/TBDATA.2019.2957478","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8922719","Distributed Computing;Deep Learning;Computer Network","Training;Graphics processing units;Computational modeling;Servers;Data models;Computer architecture;Bandwidth","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Accelerator-Aware Pruning for Convolutional Neural Networks","H. Kang","School of Computer Science and Engineering, Korea University of Technology and Education, Cheonan, Chungnam, 31253 Republic of Korea.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Convolutional neural networks have shown tremendous performance capabilities in computer vision tasks, but their excessive amounts of weight storage and arithmetic operations prevent them from being adopted in embedded environments. One of the solutions involves pruning, where certain unimportant weights are forced to have a value of zero. Many pruning schemes have been proposed, but these have mainly focused on the number of pruned weights, scarcely considering ASIC or FPGA accelerator architectures. When a pruned network is run on an accelerator, the lack of the architecture consideration causes some inefficiency problems, including internal buffer misalignments and load imbalances. This paper proposes a new pruning scheme that reflects accelerator architectures. In the proposed scheme, pruning is performed so that the same number of weights remain for each weight group corresponding to activations fetched simultaneously. In this way, the pruning scheme resolves the inefficiency problems, doubling the accelerator performance. Even with this constraint, the proposed pruning scheme reached a pruning ratio similar to that of previous unconstrained pruning schemes, not only on AlexNet and VGG16 but also on state-ofthe- art very deep networks such as ResNet. Furthermore, the proposed scheme demonstrated a comparable pruning ratio on compact networks such as MobileNet and on slimmed networks that were already pruned in a channel-wise manner. In addition to improving the efficiency of previous sparse accelerators, it will be also shown that the proposed pruning scheme can be used to reduce the logic complexity of sparse accelerators.","","","10.1109/TCSVT.2019.2911674","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8693518","Deep learning;convolutional neural networks;neural network pruning;neural network accelerator","","","","","2","","","","","","IEEE","IEEE Early Access Articles"
"Intelligent Resource Collaboration in Mobile Target Tracking Oriented Mission-Critical Sensor Networks","L. Zhou; S. Leng; Q. Liu; S. Mao; Y. Liao","University of Electronic Science and Technology of China, Chengdu, 611731, China.; University of Electronic Science and Technology of China, Chengdu, 611731, China.; University of Electronic Science and Technology of China, Chengdu, 611731, China.; University of Electronic Science and Technology of China, Chengdu, 611731, China.; University of Electronic Science and Technology of China, Chengdu, 611731, China.","IEEE Access","","2019","PP","99","1","1","Mobile target tracking-oriented sensor networks are a special kind of Mission-critical Sensor Networks (MCSN), in which the various missions with the diverse priorities exist. However, it is challenging to achieve real time tracking while keeping the MCSN a long life time with limited energy provision in a complicated environment. In this paper, we develop a collaborative perception and intelligent scheduling scheme, which jointly optimizes the system responding latency and tracking accuracy with the constraint of the available energy. A new hierarchical architecture is proposed to realize the coupled function of perception and computation. In particular, the multi-node collaborative perception scheme is applied to obtain the excellent sensing capacity, and the Unmanned Aerial Vehicles (UAVs) play as the edge nodes to provide the computing service for those resource-constrained sensor nodes. To reach the sustained target tracking, we propose an intelligent tracking policy by exploiting the deep deterministic policy gradient (DDPG) method. Simulation results demonstrate that the proposed intelligent collaboration scheme can improve the tracking accuracy by 45.5% compared with the random selection scheme. The system cost is also reduced approximately by 17.3% while guaranteeing the tracking accuracy.","","","10.1109/ACCESS.2019.2962130","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8943188","Multi-target tracking;energy consumption;collaborative perception;deep reinforcement learning","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Photometric Depth Super-Resolution","B. Haefner; S. Peng; A. Verma; Y. Quéau; D. Cremers","Department of Computer Science, TU München, Munich, Bayern Germany (e-mail: bjoern.haefner@in.tum.de); Advanced Digital Sciences Center, University of Illinois at Urbana-Champaign, Singapore, Singapore Singapore (e-mail: songyou.peng@adsc-create.edu.sg); Department of Computer Science, TU München, Munich, Bayern Germany (e-mail: alok.verma@in.tum.de); GREYC UMR CNRS 6072, Universite de Caen Normandie, 27003 Caen, Normandie France (e-mail: yvain.queau@gmail.com); Department of Computer Science, TU München, Munich, Bayern Germany 85748 (e-mail: cremers@tum.de)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","This study explores the use of photometric techniques (shape-from-shading and uncalibrated photometric stereo) for upsampling the low-resolution depth map from an RGB-D sensor to the higher resolution of the companion RGB image. A single-shot variational approach is first put forward, which is effective as long as the target's reflectance is piecewise-constant. It is then shown that this dependency upon a specific reflectance model can be relaxed by focusing on a specific class of objects (e.g., faces), and delegate reflectance estimation to a deep neural network. A multi-shot strategy based on randomly varying lighting conditions is eventually discussed. It requires no training or prior on the reflectance, yet this comes at the price of a dedicated acquisition setup. Both quantitative and qualitative evaluations illustrate the effectiveness of the proposed methods on synthetic and real-world scenarios.","","","10.1109/TPAMI.2019.2923621","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8738841","RGB-D cameras;depth super-resolution;shape-from-shading;photometric stereo;variational methods;deep learning","Image resolution;Lighting;Shape;Training;Cameras;Color;Frequency measurement","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Joint Segmentation and Path Classification of Curvilinear Structures","A. Mosinska; M. Kozinski; P. Fua","Computer Vision Laboratory, École polytechnique fédérale de Lausanne, Lausanne, Vaud Switzerland (e-mail: agata.mosinska@epfl.ch); CVLab, Ecole polytechnique federale de Lausanne Faculte Informatique et Communications, 30685 Lausanne, . Switzerland (e-mail: mateusz.kozinski@gmail.com); IC CVLAB, EPFL, Lausanne, Vaud Switzerland (e-mail: pascal.fua@epfl.ch)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Detection of curvilinear structures in images has long been of interest. One of the most challenging aspects of this problem is inferring the graph representation of the curvilinear network. Most existing delineation approaches first perform binary segmentation of the image and then refine it using either a set of hand-designed heuristics or a separate classifier that assigns likelihood to paths extracted from the pixel-wise prediction. In our work, we bridge the gap between segmentation and path classification by training a deep network that performs those two tasks simultaneously. We show that this approach is beneficial because it enforces consistency across the whole processing pipeline. We apply our approach on roads and neurons datasets.","","","10.1109/TPAMI.2019.2921327","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8732586","Deep Convolutional Neural Networks;Multi-task learning;Segmentation;Delineation;Curvilinear Structures;Road Detection;Neuron Tracing","Image segmentation;Image edge detection;Roads;Task analysis;Decoding;Feature extraction;Computer architecture","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Positional Context Aggregation Network for Remote Sensing Scene Classification","D. Zhang; N. Li; Q. Ye","School of Information Science and Technology, Nanjing Forestry University, Nanjing 210037, China.; College of Biology and the Environment, Nanjing Forestry University, Nanjing 210037, China.; School of Information Science and Technology, Nanjing Forestry University, Nanjing 210037, China (e-mail: yqlcom@njfu.edu.cn).","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","To capture the long-range dependence of an input image for remote sensing scene (RSS) classification, in this letter, we propose a general positional context aggregation (PCA) module in deep convolutional neural networks. The PCA module is with the form of self-attention mechanism, in which two proposed blocks, the spatial context aggregation (SCA) and the relative position encoding (RPE), are used to capture the spatial-dipartite contextual aggregation information and the RPE information. Therefore, compared with the classical self-attention mechanism, global attention maps extracted by PCA not only have the advantage of regional distinction but also satisfy the translation equivariance that is proven to benefit scene classification. To demonstrate the superiority of the PCA module, we implement it on the pretrained ResNet [i.e., the so-called PCA network (PCANet)] and report the results on five popular RSS classification benchmarks. Experimental results show that the PCA module can improve the RSS classification performance significantly, and PCANet50 achieves the state-of-the-art results on these data sets.","","","10.1109/LGRS.2019.2937811","National Natural Science Foundation of China; Natural Science Foundation of Jiangsu Province; Qinglan and Six Talent Peaks Projects of Jiangsu Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8836508","Context aggregation;deep convolutional neural networks (DCNNs);position encoding;remote sensing scene (RSS) classification;supervised representation learning.","Principal component analysis;Convolution;Encoding;Training;Remote sensing;Convolutional neural networks;Benchmark testing","","","","","","","","","","IEEE","IEEE Early Access Articles"
"SmartHandwriting: Handwritten Chinese Character Recognition with Smartwatch","J. Zhang; H. Bi; Y. Chen; M. Wang; L. Han; L. Cai","School of Computer Science, Wuhan University, Wuhan 430072, Hubei, China.; School of Computer Science, Wuhan University, Wuhan 430072, Hubei, China.; School of Computer Science, Wuhan University, Wuhan 430072, Hubei, China.; School of Resource and Environmental Science, Wuhan University, Wuhan 430072, Hubei, China.; School of Computer Science, Wuhan University, Wuhan 430072, Hubei, China.; School of Computer Science, Wuhan University, Wuhan 430072, Hubei, China.","IEEE Internet of Things Journal","","2019","PP","99","1","1","Most existing systems use portable devices or image processing techniques for Handwritten Chinese Character Recognition (HCCR), which are unable to detect character when writing on paper or sensitive to lighting conditions. In this paper, we present the design, implementation and evaluation of a smartwatch-based handwritten Chinese character recognition system, called SmartHandwriting. To segment each Chinese character, we further analyze the hand movement between handwriting gesture and wrist movement gesture and propose a novel algorithm to distinguish the two types of gestures. Due to too many Chinese characters for classification, we utilize the data augmentation method for avoiding over-fitting. Then we build the HCCR model using the deep convolutional neural network (DCNN) method. The recognition accuracy of Chinese characters is 96:0%, and extensive experiments confirm its effectiveness and robustness. Moreover, we also explore adverse factors that affect recognition performance, which can be avoided in the future.","","","10.1109/JIOT.2019.2947448","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8869841","Chinese character recognition;handwriting detection;data augmentation;deep learning.","Sensors;Character recognition;Writing;Wrist;Handwriting recognition;Angular velocity;Gyroscopes","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Novel Electricity Price Forecasting Approach Based on Dimension Reduction Strategy and Rough Artificial Neural Networks","H. Jahangir; H. Tayarani; S. Baghali; A. Ahmadian; A. Elkamel; M. Aliakbar Golkar; M. Castilla","K. N. Toosi University of Technology, Tehran Iran (the Islamic Republic of) 1969764499 (e-mail: h.r.jahangir@gmail.com); K. N. Toosi University of Technology, Tehran Iran (the Islamic Republic of) 1969764499 (e-mail: haniftayarani@gmail.com); K. N. Toosi University of Technology, Tehran Iran (the Islamic Republic of) 1969764499 (e-mail: baghalisina@gmail.com); Electrical Engineering, Bonab Iran (the Islamic Republic of) 5551761167 (e-mail: ali.ahmadian1367@gmail.com); University of Waterloo, 8430 Waterloo Canada N2L 3G1 (e-mail: aelkamel@uwaterloo.ca); Electrical Engineering, K. N. Toosi University of Technology, Tehran Iran (the Islamic Republic of) 131113345 (e-mail: golkar@kntu.ac.ir); Electronic Engineering, Technical University of Catalunya, Vilanova i la Geltr' Spain 08800 (e-mail: miquel.castilla@upc.edu)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","An accurate Electricity Price Forecasting (EPF) plays a vital role in the deregulated energy markets and has a specific effect on optimal management of the power system. Considering all the potent factors in determining the electricity prices - some of which have stochastic nature - makes this a cumbersome task. In this paper, first, Grey Correlation Analysis (GCA) is applied to select the effective parameters in EPF problem and eliminate redundant factors based on low correlation grades. Then, a deep neural network with Stacked Denoising Auto-Encoders (SDAEs) has been utilized to denoise data sets from different sources individually. After that, to detect the main features of the input data and putting aside the unnecessary features, Dimension Reduction (DR) process is implemented. Finally, the rough structure Artificial Neural Network (ANN) has been executed to forecast the day-ahead electricity price. The proposed method is implemented on the data of Ontario, Canada, and the forecasted results are compared with different structures of ANN, Support Vector Machine (SVM), Long Short-Term Memory (LSTM) - benchmarking methods in this field- and forecasting data reported by Independent Electricity System Operator (IESO) to evaluate the efficiency of the proposed approach. Furthermore, the results of this study indicate that the proposed method is efficient in terms of reducing error criterion and improves the forecasting error about 5 to 10 percent in comparison with IESO. This is a remarkable achievement in EPF field.","","","10.1109/TII.2019.2933009","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8788555","Price forecasting;Dimension reduction;Deep learning;Rough neuron;Denoising","Feature extraction;Forecasting;Neurons;Data mining;Artificial neural networks;Task analysis;Dimensionality reduction","","","","","","","","","","IEEE","IEEE Early Access Articles"
"An Unmanned Inspection System for Multiple Defects Detection in Photovoltaic Plants","X. Li; W. Li; Q. Yang; W. Yan; A. Y. Zomaya","College of Electrical Engineering, Zhejiang University, Hangzhou 310027, China (e-mail: lixiaoxia@zju.edu.cn).; Centre for Distributed and High Performance Computing, School of Computer Science, The University of Sydney, Camperdown, NSW 2006, Australia (e-mail: weiwilson.li@sydney.edu.au).; College of Electrical Engineering, Zhejiang University, Hangzhou 310027, China (e-mail: qyang@zju.edu.cn).; College of Electrical Engineering, Zhejiang University, Hangzhou 310027, China (e-mail: yanwenjun@zju.edu.cn).; Centre for Distributed and High Performance Computing, School of Computer Science, The University of Sydney, Camperdown, NSW 2006, Australia (e-mail: albert.zomaya@sydney.edu.au).","IEEE Journal of Photovoltaics","","2019","PP","99","1","9","Condition monitoring and fault diagnosis of photovoltaic modules are essential to ensure the efficient and reliable operation of large-scale photovoltaic plants. This article presents an algorithmic solution for the rapid and sensitive detection of photovoltaic modules with multiple visible defects by an image analyzing apparatus mounted onto an unmanned aerial vehicle. The proposed solution is composed of three stages to efficiently and accurately analyze various forms of module defects. First, the Kirsch operator is employed to identify the anomalous regions, which can significantly reduce the computational complexity, and error rate. Afterward, a deep convolutional neural network is adopted to extract defect features. Finally, a multiple classification support vector machine is developed to facilitate the defects detection decision-making. The proposed solution is extensively evaluated by the comprehensive dataset collected from real-world solar photovoltaic plants. The experimental results clearly demonstrate the effectiveness of our solution for photovoltaic modules diagnosis with multiple visible defects.","","","10.1109/JPHOTOV.2019.2955183","National Natural Science Foundation of China; Major Scientific Project of Zhejiang Lab; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8945396","Condition monitoring;convolutional neural network (CNN);deep learning;Kirsch operator;photovoltaic (PV) plant;support vector machine (SVM)","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"The Smart Image Recognition Mechanism for Crop Harvesting System in Intelligent Agriculture","G. Horng; M. Liu; C. Chen","Department of Computer Science and Information Engineering, Southern Taiwan University of Science and Technology, Tainan, Taiwan.; Institute of Manufacturing Information and Systems, Department of Computer Science and Information Engineering, National Cheng Kung University, Tainan 701, Taiwan.; Institute of Manufacturing Information and Systems, Department of Computer Science and Information Engineering, National Cheng Kung University, Tainan 701, Taiwan.","IEEE Sensors Journal","","2019","PP","99","1","1","This study proposed a harvesting system based on the Internet of Things technology and smart image recognition. Farming decisions require extensive experience; with the proposed system, crop maturity can be determined through object detection by training neural network models, and mature crops can then be harvested using robotic arms. Keras was used to construct a multilayer perceptron machine learning model and to predict multiaxial robotic arm movements and position. Following the execution of object detection on images, the pixel coordinates of the central point of the target crop in the image were used as neural network input, whereas the robotic arms were regarded as the output side. A MobileNet version 2 convolutional neural network was then used as the image feature extraction model, which was combined with a single shot multibox detector model as the posterior layer to form an object detection model. The model then performed crop detection by collecting and tagging images. Empirical evidence shows that the proposed model training had a mean average precision (mAP) of 84%, which was higher than that of other models; a mAP of 89% was observed from the arm picking results.","","","10.1109/JSEN.2019.2954287","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8906085","Internet of Things (IoT);multiaxial robotic arm control;deep learning;object detection in smart agriculture","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Novel IoT-Perceptive Human Activity Recognition (HAR) Approach Using Multi-Head Convolutional Attention","H. Zhang; Z. Xiao; J. Wang; F. Li; E. Szczerbicki","School of Cybersecurity, Chengdu University of Information Technology, Chengdu 610225, China.; School of Cybersecurity, Chengdu University of Information Technology, Chengdu 610225, China.; School of Cybersecurity, Chengdu University of Information Technology, Chengdu 610225, China.; School of Cybersecurity, Chengdu University of Information Technology, Chengdu 610225, China.; Gdansk University of Technology, Gdansk, Poland.","IEEE Internet of Things Journal","","2019","PP","99","1","1","Together with fast advancement of the Internet of Things (IoT), smart healthcare applications and systems are equipped with increasingly more wearable sensors and mobile devices. These sensors are used not only to collect data, but also, and more importantly, to assist in daily activity tracking and analyzing of their users. Various human activity recognition (HAR) approaches are used to enhance such tracking. Most of the existing HAR methods depend on exploratory case-based shallow feature learning architectures, which straggle with correct activity recognition when put into real life practice. To tackle this problem, we propose a novel approach that utilizes the convolutional neural networks (CNNs) and the attention mechanism for HAR. In the presented method, the activity recognition accuracy is improved by incorporating attention into multi-head convolutional neural networks for better feature extraction and selection. Proof of concept experiments are conducted on a publicly available dataset from Wireless Sensor Data Mining (WISDM) laboratory. The results demonstrate higher accuracy of our proposed approach in comparison with the current methods.","","","10.1109/JIOT.2019.2949715","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8883222","Internet of Things;human activity recognition;deep learning;attention mechanism.","Feature extraction;Activity recognition;Internet of Things;Convolutional neural networks;Wireless sensor networks;Computer architecture","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Grow and Prune Compact, Fast, and Accurate LSTMs","X. Dai; H. Yin; N. Jha","Electrical Engineering, Princeton University, Princeton, New Jersey United States (e-mail: xdai@princeton.edu); Electrical Engineering, Princeton University, Princeton, New Jersey United States 08544 (e-mail: hongxuy@princeton.edu); Electrical Engineering, Princeton University, Princeton, New Jersey United States 08544 (e-mail: jha@princeton.edu)","IEEE Transactions on Computers","","2019","PP","99","1","1","Long short-term memory (LSTM) has been widely used for sequential data modeling. Researchers have increased LSTM depth to improve performance. This incurs model redundancy, increases delay, and makes the LSTMs more prone to overfitting. To address these problems, we propose a hidden-layer LSTM (H-LSTM) that adds hidden layers to LSTM's original one-level nonlinear control gates. H-LSTM increases accuracy while reducing the number of parameters and run-time latency. We employ grow-and-prune (GP) training to learn both the weights and compact architecture of H-LSTM control gates. For the NeuralTalk architecture on the MSCOCO dataset, our three models reduce the number of parameters by 38.7×, run-time latency by 4.5×, and improve the CIDEr-D score by 2.8%. For the DeepSpeech2 architecture on the AN4 dataset, the first model we generated reduces the number of parameters by 19.4× and latency by 37.4%. The second model reduces the word error rate from 12.9% to 8.7%. For the encoder-decoder network on the IWSLT 2014 German-English dataset, the first model we generated reduces the number of parameters by 10.8× and latency by 14.2%. The second model increases the BLEU score from 30.02 to 30.98. Thus, GP-trained H-LSTMs can be seen to be compact, fast, and accurate.","","","10.1109/TC.2019.2954495","Division of Computer and Network Systems; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8907435","Deep learning;grow-and-prune training;long short-term memory;neural network","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Pose-Guided Representation Learning for Person Re-Identification","J. Li; S. Zhang; Q. Tian; M. Wang; W. Gao","EECS, Peking University, Beijing, Beijing China (e-mail: ljn-vmc@pku.edu.cn); School of EE & CS, Peking University, Beijing, Beijing China 100871 (e-mail: slzhang.jdl@pku.edu.cn); Department of Computer Science, University of Texas at San Antonio, San Antonio, Texas United States 78249 (e-mail: qitian@cs.utsa.edu); School of Computing, National University of Singapore, Singapore, Singapore Singapore 117417 (e-mail: eric.mengwang@gmail.com); CS, Peking University, Beijing, Beijing China (e-mail: wgao@pku.edu.cn)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","The large pose variations and misalignment errors exhibited by person images significantly increase the difficulty of person Re-Identification (ReID). Existing works commonly apply extra operations like pose estimation, part segmentation, etc., to alleviate those issues and improve the robustness of pedestrian representations. While boosting the ReID accuracy, those operations introduce considerable computational overheads and make the deep models complex and hard to tune. To chase a more efficient solution, we propose a Part-Guided Representation (PGR) composed of Pose Invariant Feature (PIF) and Local Descriptive Feature (LDF), respectively. We call PGR ""Part-Guided"" because it is trained and supervised by local part cues. Specifically, PIF approximates a pose invariant representation inferred by pose estimation and pose normalization. LDF focuses on discriminative body parts by approximating a representation learned with body region segmentation. In this way, extra pose extraction is only introduced during the training stage to supervise the learning of PGR, but is not required during the testing stage for feature extraction. Extensive comparisons with recent works on five widely used datasets demonstrate the competitive accuracy and efficiency of PGR.","","","10.1109/TPAMI.2019.2929036","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8764426","Person Re-Identification;Pose Variation;Misalignment;Pose-Guided Representation","Feature extraction;Training;Pose estimation;Robustness;Image segmentation;Body regions;Measurement","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Protein Complexes Detection based on Semi-Supervised Network Embedding Model","J. Zhu; Z. Zheng; M. Yang; G. Fung; C. Huang","South China Normal University, 12451 Guangzhou, Guangdong China (e-mail: jzhu@m.scnu.edu.cn); School of Computer Science, South China Normal University, 12451 Guangzhou, Guangdong China (e-mail: ztzheng@m.scnu.edu.cn); Shenzhen Institutes of Advanced Technology Chinese Academy of Sciences, 85411 Shenzhen, Guangdong China (e-mail: min.yang1129@gmail.com); School of SEEM, Chinese University of Hong Kong, 26451 New Territories, Hong Kong Hong Kong (e-mail: pcfung@se.cuhk.edu.hk); Department of Educational Technology, Zhejiang Normal University, 66344 Zhejiang, Zhejiang China (e-mail: cqhuang@zju.edu.cn)","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2019","PP","99","1","1","A protein complex is a group of associated polypeptide chains which plays essential roles in the biological process. Given a graph representing protein-protein interactions (PPI) network, it is critical but non-trivial to detect protein complexes, the subsets of proteins that are tightly coupled, from it. Network embedding is a technique to learn low-dimensional representations of vertices in networks. It has been proved quite useful for community detection in social networks in recent years. However, unlike social networks, PPI network does not contain rich metadata, so that existing network embedding methods cannot fully capture the network structure of PPI to improve the effect of protein complexes detection significantly. We propose a semi-supervised network embedding model by adopting graph convolutional networks to detect densely connected subgraphs effectively. We compare the performance of our model with state-of-the-art approaches on three popular PPI networks with various data sizes and densities. The experimental results show that our approach significantly outperforms other approaches on all three PPI networks.","","","10.1109/TCBB.2019.2944809","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8855005","Protein Complexes Detection;Network Embedding;Deep Learning","Proteins;Protein engineering;Clustering algorithms;Biological system modeling;Computational modeling;Social networking (online);Data models","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Multiview Scene Image Inpainting for Intelligent Vehicles Based on Conditional Generative Adversarial Networks","Z. Yuan; H. Li; J. Liu; J. Luo","School of Mechatronic Engineering and Automation, Shanghai University, Shanghai, Shanghai China (e-mail: yuanzefengde@163.com); School of Mechatronic Engineering and Automation, Shanghai university, shanghai, shanghai China (e-mail: lihengyu@shu.edu.cn); School of Mechatronic Engineering and Automation, Shanghai University, Shanghai, Shanghai China (e-mail: jingyiliu1991@foxmail.com); School of Mechatronic Engineering and Automation, Shanghai University, Shanghai, Shanghai China (e-mail: luojun@shu.edu.cn)","IEEE Transactions on Intelligent Vehicles","","2019","PP","99","1","1","With the help of a multiview system, an unmanned vehicle system can better understand the surrounding environment and choose a more accurate and safer path to avoid obstacles. This paper addresses the problems of inaccurate restored images and noise in the restored images by proposing an image restoration method that is applied to a multicamera system. We utilize different perspective images captured by different cameras to assist and constrain the restoration of the damaged image. This method restores the image by combining sample representations and sample distribution models which respectively based on self-encoder reconstruction loss learning and generative adversarial networks. In this method, the infrastructure is a conditional generative adversarial network, the condition is the images that are from the other perspectives, and the generator is a self-encoder structure with cross-layer connection, group convolution and feature map channel exchanged. This method was carried out on a dataset recorded in Zurich using a pair of cameras mounted on a mobile platform. The experimental results demonstrate that the proposed method is superior to the existing methods in terms of mean L1 Loss, mean L2 Loss and the peak signal to noise ratio (PSNR)","","","10.1109/TIV.2019.2955907","basic research project of Shanghai Municipal Science and Technology Commission; National Natural Science Foundation of China; Natural Science Foundation of Shanghai; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8911481","Convolutional neural network;deep learning;generative adversarial networks;image inpainting","Maintenance engineering;Image restoration;Generative adversarial networks;Cameras;Image reconstruction;Generators;Image coding","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Modified U-Net (mU-Net) with Incorporation of Object-Dependent High Level Features for Improved Liver and Liver-Tumor Segmentation in CT Images","H. Seo; C. Huang; M. Bassenne; R. Xiao; L. Xing","Laboratory of Artificial Intelligence in Medicine and Biomedical Physics, Medical Physics Division, Department of Radiation Oncology, School of Medicine, Stanford University, Stanford, CA, 94305, USA.; Department of Bioengineering, School of Engineering and Medicine, Stanford University, Stanford, CA, 94305, USA.; Laboratory of Artificial Intelligence in Medicine and Biomedical Physics, Medical Physics Division, Department of Radiation Oncology, School of Medicine, Stanford University, Stanford, CA, 94305, USA.; Laboratory of Artificial Intelligence in Medicine and Biomedical Physics, Medical Physics Division, Department of Radiation Oncology, School of Medicine, Stanford University, Stanford, CA, 94305, USA.; Laboratory of Artificial Intelligence in Medicine and Biomedical Physics, Medical Physics Division, Department of Radiation Oncology, School of Medicine and with the Department of Electrical Engineering, School of Engineering, Stanford University, Stanford, CA, 94305, USA.","IEEE Transactions on Medical Imaging","","2019","PP","99","1","1","Segmentation of livers and liver tumors is one of the most important steps in radiation therapy of hepatocellular carcinoma. The segmentation task is often done manually, making it tedious, labor intensive, and subject to intra-/inter-operator variations. While various algorithms for delineating organ-at-risks (OARs) and tumor targets have been proposed, automatic segmentation of livers and liver tumors remains intractable due to their low tissue contrast with respect to the surrounding organs and their deformable shape in CT images. The U-Net has gained increasing popularity recently for image analysis tasks and has shown promising results. Conventional U-Net architectures, however, suffer from three major drawbacks. First, skip connections allow for the duplicated transfer of low resolution information in feature maps to improve efficiency in learning, but this often leads to blurring of extracted image features. Secondly, high level features extracted by the network often do not contain enough high resolution edge information of the input, leading to greater uncertainty where high resolution edge dominantly affects the network’s decisions such as liver and liver-tumor segmentation. Thirdly, it is generally difficult to optimize the number of pooling operations in order to extract high level global features, since the number of pooling operations used depends on the object size. To cope with these problems, we added a residual path with deconvolution and activation operations to the skip connection of the U-Net to avoid duplication of low resolution information of features. In the case of small object inputs, features in the skip connection are not incorporated with features in the residual path. Furthermore, the proposed architecture has additional convolution layers in the skip connection in order to extract high level global features of small object inputs as well as high level features of high resolution edge information of large object inputs. Efficacy of the modified U-Net (mU-Net) was demonstrated using the public dataset of Liver tumor segmentation (LiTS) challenge 2017. For liver-tumor segmentation, Dice similarity coefficient (DSC) of 89.72 %, volume of error (VOE) of 21.93 %, and relative volume difference (RVD) of -0.49 % were obtained. For liver segmentation, DSC of 98.51 %, VOE of 3.07 %, and RVD of 0.26 % were calculated. For the public 3D Image Reconstruction for Comparison of Algorithm Database (3Dircadb), DSCs were 96.01 % for the liver and 68.14 % for liver-tumor segmentations, respectively. The proposed mU-Net outperformed existing state-of-art networks.","","","10.1109/TMI.2019.2948320","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8876857","Frequency analysis;deep learning;Liver segmentation;mU-Net;U-Net","Feature extraction;Liver;Convolution;Image segmentation;Tumors;Data mining;Biomedical imaging","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Contactless Body Movement Recognition during Sleep via WiFi Signals","Y. Cao; F. Wang; X. Lu; N. Lin; B. Zhang; Z. Liu; S. Sigg","School of Software, Zhengzhou University, Zhengzhou 450000, China.; School of Software, Zhengzhou University, Zhengzhou 450000, China.; School of Software, Zhengzhou University, Zhengzhou 450000, China.; School of Software, Zhengzhou University, Zhengzhou 450000, China.; School of Software, Zhengzhou University, Zhengzhou 450000, China.; Shizuoka University, Japan.; Aalto University, Espoo, Finland.","IEEE Internet of Things Journal","","2019","PP","99","1","1","Body movement is one of the most important indicators of sleep quality for elderly people living alone. Body movement is crucial for sleep staging and can be combined with other indicators such as breathing and heart rate to monitor sleep quality. Nevertheless, traditional sleep monitoring methods are inconvenient and may invade users’ privacy. To solve these problems, we propose contactless Body Movement Recognition (CBMR) method via WiFi signals. Firstly, CBMR uses commercial off-the-shelf WiFi devices to collect Channel State Information (CSI) data of body movement and segment the CSI data by sliding window. Then, the context information of the segmented CSI data is learned by a Bi-directional Recurrent Neural Network (Bi-RNN). Bi-RNN can fuse the forward and backward propogation information at some point, and input it into a deeper Independently Recurrent Neural Network (IndRNN) with residual mechanism to extract the deeper features and capture the time dependencies of CSI data. Finally, the type of body movement can be recognized and classified by the softmax function. CBMR can effectively reduce data preprocessing and the delay caused by manually extracting features. The results of an experiment conducted on a complex body movement dataset show that our method gives desirable performance and achieves average accuracy of greater than 93.5%, which implies a prospect application of CBMR.","","","10.1109/JIOT.2019.2960823","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8936937","body movement recognition;WiFi;CSI data;deep learning;RNN.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Single Day Outdoor Photometric Stereo","Y. Hold-Geoffroy; P. Gotardo; J. Lalonde","Research, Adobe Systems Inc, 58584 San Jose, California United States (e-mail: yannickhold@gmail.com); Research, Disney Research, 426847 Zurich, Zurich Switzerland (e-mail: paulo.gotardo@disneyresearch.com); electrical and computer engineering, Laval University, 4440 Quebec city, Quebec Canada (e-mail: jflalonde@gel.ulaval.ca)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Photometric Stereo (PS) under outdoor illumination remains a challenging, ill-posed problem due to insufficient variability in illumination. Months-long capture sessions are typically used in this setup, with little success on shorter, single-day time intervals. In this paper, we investigate the solution of outdoor PS over a single day, under different weather conditions. First, we investigate the relationship between weather and surface reconstructability in order to understand when natural lighting allows existing PS algorithms to work. Our analysis reveals that partially cloudy days improve the conditioning of the outdoor PS problem while sunny days do not allow the unambiguous recovery of surface normals from photometric cues alone. We demonstrate that calibrated PS algorithms can thus be employed to reconstruct lambertian surfaces accurately under partially cloudy days. Second, we solve the ambiguity arising in clear days by combining photometric cues with prior knowledge through a CNN-based, weakly-calibrated PS technique. Given a sequence of outdoor images captured during a single sunny day, our method robustly estimates the scene surface normals with unprecedented quality for the considered scenario. Our approach significantly outperforms several state-of-the-art methods on images with real lighting, showing that our CNN can combine efficiently learned priors and photometric cues available during a single sunny day.","","","10.1109/TPAMI.2019.2962693","Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8943966","photometric stereo;high dynamic range;deep learning;outdoor lighting","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Novel Feature Selection Method using Bhattacharyya Distance for Neural Networks based Automatic Modulation Classification","M. H. Shah; X. Dang","Communication and Information, Nanjing University of Aeronautics and Astronautics, 47854 Nanjing China (e-mail: maqsood@nuaa.edu.cn); Electronics and Information Engineering, Nanjing University of Aeronautics and Astronautics, 47854 Nanjing, Jiangsu China (e-mail: dang@nuaa.edu.cn)","IEEE Signal Processing Letters","","2019","PP","99","1","1","Feature selection holds a significant place in any machine learning problem because it can reduce the training complexity and improve the generalization. Neural networks based automatic modulation classifiers (AMC) have gained much attention in literature because of their ability to perform better in the blind scenarios. In this context some recent works have utilized multiple features to train the neural network. With an ultimate aim to develop a systematic approach of selecting the most diverse and unique features, we propose and demonstrate a novel method to select the most diverse (mC2) features from a larger feature set. Bhattacharyya distance metric for the dissimilarity between two probability distributions is utilized to select the features with the highest distance for all modulation pairs within a test pool. The proposed approach is analyzed for three different neural network based classifiers amidst AWGN and frequency-selective fading channels using two feature sets with different dimensions. A substantial reduction in computational complexity is achieved with an acceptable compromise on classification accuracy.","","","10.1109/LSP.2019.2957924","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8926373","Modulation classification;Bhattacharyya distance;Feature selection;Deep learning;RBFN;CNN","Modulation;Feature extraction;Training;Neural networks;Probability distribution;Signal processing algorithms;Complexity theory","","","","","","","","","","IEEE","IEEE Early Access Articles"
"DLT-Net: Joint Detection of Drivable Areas, Lane Lines, and Traffic Objects","Y. Qian; J. M. Dolan; M. Yang","Department of Automation, Shanghai Jiao Tong University, Shanghai 200240, China, and also with the Key Laboratory of System Control and Information Processing, Ministry of Education of China, Shanghai Jiao Tong University, Shanghai 200240, China.; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA 15213, USA.; Department of Automation, Shanghai Jiao Tong University, Shanghai 200240, China, and also with the Key Laboratory of System Control and Information Processing, Ministry of Education of China, Shanghai Jiao Tong University, Shanghai 200240, China (e-mail: mingyang@sjtu.edu.cn).","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","10","Perception is an essential task for self-driving cars, but most perception tasks are usually handled independently. We propose a unified neural network named DLT-Net to detect drivable areas, lane lines, and traffic objects simultaneously. These three tasks are most important for autonomous driving, especially when a high-definition map and accurate localization are unavailable. Instead of separating tasks in the decoder, we construct context tensors between sub-task decoders to share designate influence among tasks. Therefore, each task can benefit from others during multi-task learning. Experiments show that our model outperforms the conventional multi-task network in terms of the task-wise accuracy and the overall computational efficiency, in the challenging BDD dataset.","","","10.1109/TITS.2019.2943777","National Natural Science Foundation of China; International Chair on Automated Driving of Ground Vehicle; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8937825","Multi-task network;deep learning;traffic object detection;drivable area detection;lane line detection.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Automatic Symmetry Detection From Brain MRI Based on a 2-Channel Convolutional Neural Network","H. Wu; X. Chen; P. Li; Z. Wen","College of Computer Science and Software Engineering, Shenzhen University, Shenzhen 518000, China (e-mail: hswu@szu.edu.cn).; College of Computer Science and Software Engineering, Shenzhen University, Shenzhen 518000, China.; Department of Computing, Hong Kong Polytechnic University, Hong Kong.; College of Computer Science and Software Engineering, Shenzhen University, Shenzhen 518000, China.","IEEE Transactions on Cybernetics","","2019","PP","99","1","12","Symmetry detection is a method to extract the ideal mid-sagittal plane (MSP) from brain magnetic resonance (MR) images, which can significantly improve the diagnostic accuracy of brain diseases. In this article, we propose an automatic symmetry detection method for brain MR images in 2-D slices based on a 2-channel convolutional neural network (CNN). Different from the existing detection methods that mainly rely on the local image features (gradient, edge, etc.) to determine the MSP, we use a CNN-based model to implement the brain symmetry detection, which does not require any local feature detections and feature matchings. By training to learn a wide variety of benchmarks in the brain images, we can further use a 2-channel CNN to evaluate the similarity between the pairs of brain patches, which are randomly extracted from the whole brain slice based on a Poisson sampling. Finally, a scoring and ranking scheme is used to identify the optimal symmetry axis for each input brain MR slice. Our method was evaluated in 2166 artificial synthesized brain images and 3064 collected in vivo MR images, which included both healthy and pathological cases. The experimental results display that our method achieves excellent performance for symmetry detection. Comparisons with the state-of-the-art methods also demonstrate the effectiveness and advantages for our approach in achieving higher accuracy than the previous competitors.","","","10.1109/TCYB.2019.2952937","National Natural Science Foundation of China; Natural Science Foundation of Guangdong Province of China; Hong Kong Polytechnic University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8917648","2-channel convolutional neural network (CNN);brain MRI;deep learning;mid-sagittal plane (MSP) detection;symmetry detection","Brain;Feature extraction;Biomedical imaging;Image segmentation;Image analysis;Magnetic resonance imaging;Convolutional neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Generic Tracking and Probabilistic Prediction Framework and Its Application in Autonomous Driving","J. Li; W. Zhan; Y. Hu; M. Tomizuka","Department of Mechanical Engineering, University of California at Berkeley, Berkeley, CA 94720 USA (e-mail: jiachen_li@berkeley.edu).; Department of Mechanical Engineering, University of California at Berkeley, Berkeley, CA 94720 USA.; Department of Mechanical Engineering, University of California at Berkeley, Berkeley, CA 94720 USA.; Department of Mechanical Engineering, University of California at Berkeley, Berkeley, CA 94720 USA.","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","16","Accurately tracking and predicting behaviors of surrounding objects are key prerequisites for intelligent systems such as autonomous vehicles to achieve safe and high-quality decision making and motion planning. However, there still remain challenges for multi-target tracking due to object number fluctuation and occlusion. To overcome these challenges, we propose a constrained mixture sequential Monte Carlo (CMSMC) method in which a mixture representation is incorporated in the estimated posterior distribution to maintain multi-modality. Multiple targets can be tracked simultaneously within a unified framework without explicit data association between observations and tracking targets. The framework can incorporate an arbitrary prediction model as the implicit proposal distribution of the CMSMC method. An example in this paper is a learning-based model for hierarchical time-series prediction, which consists of a behavior recognition module and a state evolution module. Both modules in the proposed model are generic and flexible so as to be applied to a class of time-series prediction problems where behaviors can be separated into different levels. Finally, the proposed framework is applied to a numerical case study as well as a task of on-road vehicle tracking, behavior recognition, and prediction in highway scenarios. Instead of only focusing on forecasting trajectory of a single entity, we jointly predict continuous motions for interactive entities simultaneously. The proposed approaches are evaluated from multiple aspects, which demonstrate great potential for intelligent vehicular systems and traffic surveillance systems.","","","10.1109/TITS.2019.2930310","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8789525","Trajectory prediction;multi-target tracking;sequential Monte Carlo;probabilistic graphical models;deep learning;bahavior recognition.","Target tracking;Predictive models;Monte Carlo methods;Hidden Markov models;Probabilistic logic;Trajectory","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Transfer Learning to Model Inertial Confinement Fusion Experiments","K. D. Humbird; J. L. Peterson; B. K. Spears; R. G. McClarren","Lawrence Livermore National Laboratory, Livermore, CA 94550 USA, and also with the Department of Nuclear Engineering, Texas A&M University, College Station, TX 77843 USA (e-mail: humbird1@llnl.gov).; Lawrence Livermore National Laboratory, Livermore, CA 94550 USA.; Lawrence Livermore National Laboratory, Livermore, CA 94550 USA.; Department of Aerospace and Mechanical Engineering, University of Notre Dame, Notre Dame, IN 46556 USA.","IEEE Transactions on Plasma Science","","2019","PP","99","1","10","Inertial confinement fusion (ICF) experiments are designed using computer simulations that are approximations of reality and therefore must be calibrated to accurately predict experimental observations. In this article, we propose a novel technique for calibrating from simulations to experiments, or from low fidelity simulations to high fidelity simulations, via ``transfer learning'' (TL). TL is a commonly used technique in the machine learning community, in which models trained on one task are partially retrained to solve a separate, but related task, for which there is a limited quantity of data. We introduce the idea of hierarchical TL, in which neural networks trained on low fidelity models are calibrated to high fidelity models, then to experimental data. This technique essentially bootstraps the calibration process, enabling the creation of models which predict high fidelity simulations or experiments with minimal computational cost. We apply this technique to a database of ICF simulations and experiments carried out at the Omega laser facility. TL with deep neural networks enables the creation of models that are more predictive of Omega experiments than simulations alone. The calibrated models accurately predict future Omega experiments, and are used to search for new, optimal implosion designs.","","","10.1109/TPS.2019.2955098","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8932676","Inertial confinement;neural networks.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Khaos: An Adversarial Neural Network DGA with High Anti-Detection Ability","X. Yun; J. Huang; Y. Wang; T. Zang; Y. Zhou; Y. Zhang","Institute of Information Engineering, Chinese Academy of Sciences, Beijing 100093, China.; Institute of Information Engineering, Chinese Academy of Sciences, Beijing 100093, China and School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China.; Institute of Information Engineering, Chinese Academy of Sciences, Beijing 100093, China and School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China and Key Laboratory of Network Assessment Technology, Chinese Academy of Sciences, Beijing 1000195, China.; Institute of Information Engineering, Chinese Academy of Sciences, Beijing 100093, China and School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China and Key Laboratory of Network Assessment Technology, Chinese Academy of Sciences, Beijing 1000195, China.; Institute of Information Engineering, Chinese Academy of Sciences, Beijing 100093, China.; Institute of Information Engineering, Chinese Academy of Sciences, Beijing 100093, China and School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China and Key Laboratory of Network Assessment Technology, Chinese Academy of Sciences, Beijing 1000195, China.","IEEE Transactions on Information Forensics and Security","","2019","PP","99","1","1","A botnet is a network of remote-controlled devices that are infected with malware controlled by botmasters in order to launch cyber attacks. To evade detection, the botmaster frequently changes the domain name of his Command and Control (C&C) server. Notice that most of these types of domain names are generated by domain generation algorithms (DGAs). In this paper, we propose Khaos, a novel DGA with high anti-detection ability based on neural language models and the Wasserstein Generative Adversarial Network (WGAN). The key insight of our research is that real domain names are composed of readable syllables and acronyms, and thus we can arrange syllables and acronyms using neural language models to mimic real domain names. In Khaos, we first find the most common n-grams in real domain names, then tokenize these domain names into n-grams, and finally synthesize new domain names after learning arrangements of n-grams from real domain names. We carry out experiments using a variety of state-of-the-art DGA detection approaches: the statistics-based, the distribution-based, the LSTM-based and the graph-based detection approach. Our experimental results show that the average distance for detecting Khaos under the distribution-based detection approach is 0.64, the AUCs of Khaos under the statistics-based and the LSTM-based detection approach are 0.76 and 0.57, respectively, and the precision of Khaos under the graph-based detection approach is 0.68. Our work proves that the existing detection approaches have big troubles in detecting Khaos, and Khaos has better anti-detection ability than state-of-the-art DGAs. In addition, we find that training the existing detection approach on a dataset including the domain names generated by Khaos can improve its detection ability.","","","10.1109/TIFS.2019.2960647","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8936543","Domain Generation Algorithms;Generative Adversarial Network;Neural Language Models;Deep Learning;Cyber Security","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Lightweight Neural Network for Monocular View Generation with Occlusion Handling","S. Evain; C. Guillemot","SIROCCO, INRIA, Rennes, Brittany France 35042 (e-mail: simon.evain@irisa.fr); SIROCCO, INRIA, Rennes, Brittany France 35042 (e-mail: Christine.Guillemot@inria.fr)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","In this article, we present a very lightweight neural network architecture, trained on stereo data pairs, which performs view synthesis from one single image. With the growing success of multi-view formats, this problem is indeed increasingly relevant. The network returns a prediction built from disparity estimation, which fills in wrongly predicted regions using a occlusion handling technique. To do so, during training, the network learns to estimate the left-right consistency structural constraint on the pair of stereo input images, to be able to replicate it at test time from one single image. The method is built upon the idea of blending two predictions: a prediction based on disparity estimation, and a prediction based on direct minimization in occluded regions. The network is also able to identify these occluded areas at training and at test time by checking the pixelwise left-right consistency of the produced disparity maps. At test time, the approach can thus generate a left-side and a right-side view from one input image, as well as a depth map and a pixelwise confidence measure in the prediction. The work outperforms visually and metric-wise state-of-the-art approaches on the challenging KITTI dataset, all while reducing by a very significant order of magnitude (5 or 10 times) the required number of parameters (6.5 M).","","","10.1109/TPAMI.2019.2960689","H2020 European Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8936903","Computer vision;monocular;deep learning;stereo;view synthesis","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Dilated residual learning with skip connections for real-time denoising of laser speckle imaging of blood flow in a log-transformed domain","W. Cheng; J. Lu; X. Zhu; J. Hong; X. Liu; M. Li; P. Li","Britton Chance Center of Biomedical Photonics, Wuhan National Laboratory for Optoelectronics, Huazhong University of Science and Technology, and MoE Key Laboratory for Biomedical Photonics, School of Engineering Sciences, Huazhong University of Science and Technology, Wuhan, China.; Britton Chance Center of Biomedical Photonics, Wuhan National Laboratory for Optoelectronics, Huazhong University of Science and Technology, and MoE Key Laboratory for Biomedical Photonics, School of Engineering Sciences, Huazhong University of Science and Technology, Wuhan, China.; Britton Chance Center of Biomedical Photonics, Wuhan National Laboratory for Optoelectronics, Huazhong University of Science and Technology, and MoE Key Laboratory for Biomedical Photonics, School of Engineering Sciences, Huazhong University of Science and Technology, Wuhan, China.; Britton Chance Center of Biomedical Photonics, Wuhan National Laboratory for Optoelectronics, Huazhong University of Science and Technology, and MoE Key Laboratory for Biomedical Photonics, School of Engineering Sciences, Huazhong University of Science and Technology, Wuhan, China.; Britton Chance Center of Biomedical Photonics, Wuhan National Laboratory for Optoelectronics, Huazhong University of Science and Technology, and MoE Key Laboratory for Biomedical Photonics, School of Engineering Sciences, Huazhong University of Science and Technology, Wuhan, China.; Britton Chance Center of Biomedical Photonics, Wuhan National Laboratory for Optoelectronics, Huazhong University of Science and Technology, and MoE Key Laboratory for Biomedical Photonics, School of Engineering Sciences, Huazhong University of Science and Technology, Wuhan, China.; Britton Chance Center of Biomedical Photonics, Wuhan National Laboratory for Optoelectronics, Huazhong University of Science and Technology, MoE Key Laboratory for Biomedical Photonics, School of Engineering Sciences, Huazhong University of Science and Technology, Wuhan, China, and HUST-Suzhou Institute for Brainsmatics, Suzhou, China.","IEEE Transactions on Medical Imaging","","2019","PP","99","1","1","Laser speckle contrast imaging (LSCI) is a wide-field and noncontact imaging technology for mapping blood flow. Although the denoising method based on block-matching and three-dimensional transform-domain collaborative filtering (BM3D) was proposed to improve its signal-to-noise ratio (SNR) significantly, the processing time makes it difficult to realize real-time denoising. Furthermore, it is still difficult to obtain an acceptable level of SNR with a few raw speckle images given the presence of significant noise and artifacts. A feed-forward denoising convolutional neural network (DnCNN) achieves state-of-the-art performance in denoising nature images and is efficiently accelerated by GPU. However, it performs poorly in learning with original speckle contrast images of LSCI owing to the inhomogeneous noise distribution. Therefore, we propose training DnCNN for LSCI in a log-transformed domain to improve training accuracy and it achieves an improvement of 5.13 dB in the peak signal-to-noise ratio (PSNR). To decrease the inference time and improve denoising performance, we further propose a dilated deep residual learning network with skip connections (DRSNet). The image-quality evaluations of DRSNet with five raw speckle images outperform that of spatially average denoising with 20 raw speckle images. DRSNet takes 35 ms (i.e., 28 frames per second) for denoising a blood flow image with 486 W 648 pixels on an NVIDIA 1070 GPU, which is approximately 2.5 times faster than DnCNN. In the test sets, DRSNet also improves 0.15 dB in the PSNR than that of DnCNN. The proposed network shows good potential in real-time monitoring of blood flow for biomedical applications.","","","10.1109/TMI.2019.2953626","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8901154","","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Visual Saliency-Based Extended Morphological Profiles for Unsupervised Feature Learning of Hyperspectral Images","X. Liu; X. Yin; Y. Cai; M. Wang; Z. Cai; B. Huang","School of Automation, China University of Geosciences, Wuhan 430074, China, and also with the Hubei Key Laboratory of Advanced Control and Intelligent Automation for Complex Systems, China University of Geosciences, Wuhan 430074, China.; School of Automation, China University of Geosciences, Wuhan 430074, China, and also with the Hubei Key Laboratory of Advanced Control and Intelligent Automation for Complex Systems, China University of Geosciences, Wuhan 430074, China.; School of Computer Science, China University of Geosciences, Wuhan 430074, China (e-mail: caiyaom@cug.edu.cn).; School of Automation, China University of Geosciences, Wuhan 430074, China, and also with the Hubei Key Laboratory of Advanced Control and Intelligent Automation for Complex Systems, China University of Geosciences, Wuhan 430074, China.; School of Computer Science, China University of Geosciences, Wuhan 430074, China, and also with the Beibu Gulf Big Data Resources Utilisation Laboratory, Beibu Gulf University, Qingzhou 535000, China.; China Unicom Hubei Branch, Wuhan 430040, China.","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","Classification of hyperspectral images (HSIs) by making full use of the spectral and the spatial information has become a research hotspot in the field of remote sensing technology. Aiming at the problems of information redundancy and low utilization of spatial information, this letter proposes a visual saliency-based extended morphological profile (VS-EMP) scheme. First, the morphological features are extracted by the EMP from the HSIs on several principal components. Second, the local binary pattern (LBP) is performed to extract the texture features from morphological scenes. Third, saliency features are captured according to the texture features in an approach of Boolean mapping saliency (BMS). Finally, spectral-spatial features are constructed by feature fusion and are further used for the classification of the HSIs. A number of experiments are performed, including using different classifiers to verify the performance of the proposed scheme, comparing with related variant algorithms, comparing time with deep learning, and testing learning ability in the absence of labeled samples. Experimental results indicate that the proposed method is significantly superior to the previous methods.","","","10.1109/LGRS.2019.2957851","National Nature Science Foundation of China; National Nature Science Foundation of Hubei Province China; Fundamental Research Funds for National University China University of Geosciences Wuhan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8938660","Extended morphological profiles (EMP);feature extraction;hyperspectral image (HSI);visual saliency (VS).","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Sequence Generative Adversarial Networks for Wind Power Scenario Generation","J. Liang; W. Tang","Department of Electrical and Computer Engineering, North Carolina State University, Raleigh, NC 27695 USA.; Department of Electrical and Computer Engineering, North Carolina State University, Raleigh, NC 27695 USA.","IEEE Journal on Selected Areas in Communications","","2019","PP","99","1","1","With the rapid increase in distributed wind generation, considerable efforts have been devoted to the microgrid day-ahead scheduling. The effectiveness of those methods will highly depend on the selection of the uncertainty sets. We propose a distribution-free approach for wind power scenario generation, using sequence generative adversarial networks. To capture the temporal correlation, the model adopts the long short-term memory architecture and uses generative adversarial networks coupled with reinforcement learning, which, in contrast to the existing methods, avoids manual labeling and captures the complex dynamics of the weather. We conduct case studies based on the data from the Bonneville Power Administration and the National Renewable Energy Laboratory, and show that the generated scenarios can better characterize the variability of wind power and reduce the risk of uncertainties, compared with those produced by Gaussian distribution, vanilla long short-term memory, and multivariate kernel density estimation. Moreover, the proposed method achieves better performance when applied to the day-ahead scheduling of microgrids.","","","10.1109/JSAC.2019.2952182","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8895757","Deep learning;generative models;renewable energy integration;scenario generation","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"SCRATCH: A Scalable Discrete Matrix Factorization Hashing Framework for Cross-Modal Retrieval","Z. Chen; C. Li; X. Luo; L. Nie; W. Zhang; X. Xu","School of Software, Shandong University, Jinan 250101, China.; School of Software, Shandong University, Jinan 250101, China.; School of Software, Shandong University, Jinan 250101, China.; School of Computer Science and Technology, Shandong University, Qingdao 266237, China.; School of Control Science and Engineering, Shandong University, Jinan 250061, china.; School of Software, Shandong University, Jinan 250101, China.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","In this paper, we present a novel supervised cross-modal hashing framework, namely, Scalable disCRete mATrix faCtorization Hashing, SCRATCH for short. It first utilizes Collective Matrix Factorization on original features, together with label semantic embedding, to learn the latent representations in a shared laten space. Thereafter, it generates binary hash codes based on the latent representations. During optimization, it avoids using a large n×n similarity matrix and generates hash codes discretely. Besides, based on different objective functions, learning strategy and features, we further present three models in this framework, i.e., SCRATCH-o, SCRATCH-t and SCRATCH-d. The first one is a one-step method, learning the hash functions and the binary codes in the same optimization problem. The second is a two-step method, which first generates the binary codes, and then learns the hash functions based on the learnt hash codes; The third one is a deep version of SCRATCH-t which utilizes deep neural networks as hash functions. Extensive experiments on two widely-used benchmark datasets demonstrate that SCRATCH-o and SCRATCH-t outperform some state-of-the-art shallow hashing methods for cross-modal retrieval. SCRATCH-d also outperforms some state-of-the-art deep hashing models.","","","10.1109/TCSVT.2019.2911359","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8691805","Approximate Nearest Neighbor Search;Learning to Hash;Cross-modal Retrieval","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Hierarchical Two-Stream Growing Self-Organizing Maps with Transience for Human Activity Recognition","R. Nawaratne; D. Alahakoon; D. De Silva; H. Kumara; X. Yu","Research Centre for Data Analytics and Cognition, La Trobe University College of Arts Social Sciences and Commerce, 110555 Bundoora, Victoria Australia 3086 (e-mail: B.Nawaratne@latrobe.edu.au); La Trobe Business School, La Trobe University, Bundoora, Victoria Australia VIC 30186 (e-mail: D.Alahakoon@latrobe.edu.au); Bundoora, Victoria Australia 3086 (e-mail: d.desilva@latrobe.edu.au); La Trobe University, 2080 Bundoora, Victoria Australia 3086 (e-mail: harsz89@gmail.com); Research & Innovation, RMIT University, Melbourne, Victoria Australia 3001 (e-mail: x.yu@rmit.edu.au)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","The rapid growth in autonomous industrial environments has increased the need for intelligent video surveillance. As a predominant element of video surveillance, recognition of complex human movements is important in a wide range of surveillance applications. However, the current state-of-the-art video surveillance techniques use supervised deep learning pipelines for human activity recognition. A key shortcoming of such techniques is the inability to learn from unlabeled video streams. To operate effectively in natural environments, video surveillance techniques have to be able to handle huge volumes of unlabeled video data, monitor and generate alerts and insights derived from multiple characteristics such as spatial structure, motion flow, color distribution, etc. Furthermore, most conventional learning systems lack memory persistence capability which can reduce the influence of outdated information in memory-guided decision-making resulting in limiting plasticity and overfitting based on specific past events. In this paper, we propose a new adaptation of the Growing Self Organizing Map (GSOM) to address these shortcomings by (a) adopting two proven concepts of traditional deep learning, hierarchical and multi-stream learning, applied into GSOM self-structuring architecture to accommodate learning from unlabeled video data and their diverse characteristics, (b) address overfitting and the influence of outdated information on neural architecture by implementing a transience property in the algorithm. We demonstrate the proposed model using three benchmark video datasets and the results confirm its validity and usability for human activity recognition.","","","10.1109/TII.2019.2957454","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8922590","Self-Organizing Maps;Human Activity Recognition;Neural Networks;Forgetting;Hierarchical Learning","Neurons;Activity recognition;Self-organizing feature maps;Histograms;Video surveillance;Optical flow;Feature extraction","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Multi-Kernel Convolutional LSTM Networks and an Attention-Based Mechanism for Videos","S. Agethen; W. Hsu","Graduate Institute of Networking and Multimedia, National Taiwan University, Taipei City Taiwan (e-mail: d01944015@ntu.edu.tw); Graduate Institute of Networking and Multimedia, National Taiwan University, Taipei Taiwan 106 (e-mail: whsu@ntu.edu.tw)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","Action recognition greatly benefits motion understanding in video analysis. Recurrent networks such as long short-term memory (LSTM) networks are a popular choice for motion-aware sequence learning tasks. Recently, a convolutional extension of LSTM was proposed, in which input-to-hidden and hidden-to-hidden transitions are modeled through convolution with a single kernel. This implies an unavoidable trade-off between effectiveness and efficiency. Herein, we propose a new enhancement to convolutional LSTM networks that supports accommodation of multiple convolutional kernels and layers. This resembles a Network-in-LSTM approach, which improves upon the aforementioned concern. In addition, we propose an attention-based mechanism that is specifically designed for our multi-kernel extension. We evaluated our proposed extensions in a supervised classification setting on the UCF-101 and Sports-1M data sets, with the findings showing that our enhancements improve accuracy. We also undertook qualitative analysis to reveal the characteristics of our system and the convolutional LSTM baseline.","","","10.1109/TMM.2019.2932564","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8784296","","Kernel;Videos;Task analysis;Convolution;Feature extraction;YouTube;Mathematical model","","","","","","","","","","IEEE","IEEE Early Access Articles"
"DM-RIS: Deep Multi-model Rail Inspection System with Improved MRF-GMM and CNN","X. Jin; Y. Wang; H. Zhang; H. Zhong; L. Liu; Q. M. J. Wu; Y. Yang","College of Electrical and Information Engineering, Hunan University, Changsha 410082, China.; College of Electrical and Information Engineering, Hunan University, Changsha 410082, China.; College of Electrical and Information Engineering, Changsha University of Science and Technology, Changsha 410012, China and CVSS Lab, Department of Electrical and Computer Engineering, University of Windsor, Windsor, ON, Canada.; College of Electrical and Information Engineering, Hunan University, Changsha 410082, China.; College of Electrical and Information Engineering, Hunan University, Changsha 410082, China.; Department of Electrical and Computer Engineering, University of Windsor, Windsor, ON, Canada.; Department of Computer Science, Lakehead University, Thunder bay, Canada.","IEEE Transactions on Instrumentation and Measurement","","2019","PP","99","1","1","Rail inspection system (RIS) remains an emergent instrumentation for railway transportation, with its capacity of measuring surface defect on steel rail; however, detecting technique and interpretation of RIS constitute a challenging problem since traditional technologies are expensive and prone to errors. In this paper, a multi-model rail inspection system (DM-RIS) is established for surface defect where FRGMM is presented for segmentation proposal and Faster RCNN is utilized for objective location in a parallel structure. First, we incorporate spatial information between pixels into an improved Gaussian mixture model (FRGMM) based on Markov random field for accurate and rapid defect edge segmentation. Specifically, a direct parameter-learning in expectation-maximization (EM) algorithm is proposed. Meanwhile, to remove non-defect, numerous labeled samples with weak illumination, inequality reflection, external noise, rust and greasy dirt are fed into Faster RCNN so that DM-RIS is robust environmentally to various light, angle, background and acquisition equipment. Finally, the joint hit area refers to real defect. The experimental results demonstrate that proposed method performs well with 96.74% precision, 94.13% recall, 95.18% overlap and 0.485s/frame speed on average, and is robust compared with the related well-established approaches.","","","10.1109/TIM.2019.2909940","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8692707","Rail inspection;surface defect;improved Gaussian mixture model;Markov random field;Faster RCNN;visual detection","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Deep Robust Framework for Protein Function Prediction using Variable-Length Protein Sequences","A. Ranjan; M. S. Fahad; D. Fernandez-Baca; A. Deepak; S. Tripathi","Computer Science and Engineering, National Institute of Technology Patna, 230635 Patna, Bihar India 800005 (e-mail: ashish.cse16@nitp.ac.in); Computer Science and Engineering, National Institute of Technology Patna, 230635 Patna, Bihar India (e-mail: shah.cse16@nitp.ac.in); Computer Science, Iowa State University, 1177 Ames, Iowa United States (e-mail: fernande@iastate.edu); Computer Science and Engineering, National Institute of Technology Patna, 230635 Patna, Bihar India (e-mail: akshayd@nitp.ac.in); REC, Ambedkar Nagar, Uttar Pradesh India (e-mail: p.stripathi@gmail.com)","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2019","PP","99","1","1","The order of amino acids in a protein sequence enables the protein to acquire a conformation suitable for performing functions, thereby motivating the need to analyse these sequences for predicting functions. Although machine learning based approaches are fast compared to methods using BLAST, FASTA, etc., they fail to perform well for long protein sequences (with more than 300 amino acids). In this paper, we introduce a novel method for construction of two separate feature sets for protein using bi-directional long short-term memory network based on the analysis of fixed 1) single-sized segments and 2) multi-sized segments. The model trained on the proposed feature set based on multi-sized segments is combined with the model trained using state-of-the-art Multi-label Linear Discriminant Analysis (MLDA) features to further improve the accuracy. Extensive evaluations using separate datasets for biological processes and molecular functions demonstrate not only improved results for long sequences, but also significantly improve the overall accuracy over state-of-the-art method. The single-sized approach produces an improvement of +3.37% for biological processes and +5.48% for molecular functions over the MLDA based classifier. The corresponding numbers for multi-sized approach are +5.38% and +8.00%. Combining the two models, the accuracy further improves to +7.41% and +9.21% respectively.","","","10.1109/TCBB.2019.2911609","Young Faculty Research Fellowship of Visvesvaraya PhD Programme of Ministry of Electronics Information Technology MeitY Government of India; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8692646","Bi-Directional Long Short-Term Memory (Bi-LSTM);Protein Segment Vector;Multi-Label Linear Discriminant Analysis (MLDA);Long Protein Sequence","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Extracting Deep Personae Social Relations in Microblog Posts","Y. J. Du; F. H. Su; A. Z. Yang; X. Y. Li; Y. Q. Fan","School of Computer and Software Engineering, Xihua University, Chengdu 610039, China.; Sichuan Lewei Technology Co., Ltd.,Chengdu 610041, China.; School of Computer and Software Engineering, Xihua University, Chengdu 610039, China.; School of Computer and Software Engineering, Xihua University, Chengdu 610039, China.; School of Computer and Software Engineering, Xihua University, Chengdu 610039, China.","IEEE Access","","2019","PP","99","1","1","Numerous studies have been conducted to extract relationships from different documents. However, extracting relationships from microblog posts is rarely studied. In this paper, we improve a novel kernel-based learning algorithm to mine the personae social relationships from microblog posts by combining the syntax and semantic meanings of the dependency trigram kernels (DTK). To deeply extract the personal social relationships of microblog posts, we define the relation feature words, provide seven rules for extracting these feature words, and propose a rule-based approach that mines these relation feature words from microblog posts. We construct relation feature word dictionaries for different relation types because of the lack of prominent relation features in microblog posts. We propose an algorithm to classify relation feature words by considering two features of the relation feature words, namely, syntax and semantic similarities between relation feature words in microblog posts and by using relation feature word dictionaries. Experimental results show that the average recall, precision, and F-measure of our proposed approach outperforms the original DTK in sentence selection, personae social relation extraction, and personae social relation classification. Finally, the relation graphs of five topics clarify that our proposed approach is effective for extracting personae social relations from microblog posts.","","","10.1109/ACCESS.2019.2960659","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8936451","Personae relation;relation feature word;dependency trigram kernel;relation classification;knowledge graph;microblog post","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Learning How to Smile: Expression Video Generation with Conditional Adversarial Recurrent Nets","W. Wang; X. Alameda-Pineda; D. Xu; E. Ricci; N. Sebe","CVLab, Ecole Polytechnique Federale de Lausanne, 27218 Lausanne, VD Switzerland (e-mail: wangwei1990@gmail.com); Perception Team, Inria Centre de Recherche Grenoble Rhone-Alpes, 56521 Montbonnot France 38334 (e-mail: xavier.alameda-pineda@inria.fr); VGG, University of Oxford, 6396 Oxford, Oxfordshire United Kingdom of Great Britain and Northern Ireland (e-mail: dan.xu@unitn.it); Department of information engineering and computer science, University of Trento, 19034 Trento, Trentino-Alto Adige Italy (e-mail: eliricci@fbk.eu); Department of information engineering and computer science, University of Trento, Trento Italy (e-mail: sebe@disi.unitn.it)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","While several research studies have focused on analyzing human behavior and, in particular, emotional signals from visual data, the problem of synthesizing face video sequences with specific attributes (e.g. age, facial expressions) received much less attention. This paper proposes a novel deep generative model able to produce face videos from a given image of a neutral face and a label indicating a specific facial expression, e.g. spontaneous smile. Our framework consists of two main building blocks: an image generator and a frame sequence generator. The image generator is implemented as a deep neural model which combines generative adversarial networks and variational auto-encoders, while the sequence generator is a label-conditioned recurrent neural network. In the proposed framework, given as input a neural face and a label, the sequence generator outputs a set of hidden representations with smooth transitions corresponding to video frames. Then, the image generator is used to decode the hidden representations into the actual face images. To impose that the net generates videos consistent with the given label, a novel identity adversarial loss is proposed. Our experimental results demonstrate the effectiveness of the framework and the advantage of introducing an adversarial component into recurrent models for face video generation.","","","10.1109/TMM.2019.2963621","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8948254","video generation;gated recurrent unit;smile","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"ATMFN: Adaptive-threshold-based Multi-model Fusion Network for Compressed Face Hallucination","K. Jiang; Z. Wang; P. Yi; G. Wang; K. Gu; J. Jiang","School of Computer Science, Wuhan University, 12390 Wuhan China 430072 (e-mail: 2017282110506@whu.edu.cn); NERCMS, Wuhan University, 12390 Wuhan, Hubei China (e-mail: wzy_hope@163.com); National Engineering Research Center for Multimedia Software, School of Computer Science, Wuhan University, Wuhan, 430072, China, Wuhan University, 12390 Wuhan, Hubei China (e-mail: 2017202110008@whu.edu.cn); NERCMS, Wuhan University, 12390 Wuhan, Hubei China (e-mail: wangguangcheng0428@163.com); Faculty of Information Technology, Beijing University of Technology, 12496 Beijing China 100124 (e-mail: guke.doctor@gmail.com); Digital Content and Media Sciences Research Division, National Institute of Informatics, Tokyo, Tokyo Japan Tokyo (e-mail: junjun0595@163.com)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","Although tremendous strides have been recently made in face hallucination, the exiting methods based on a single deep learning framework can hardly satisfactorily provide fine facial features from tiny faces under complex degradation. This paper advocates an adaptive-threshold-based multi-model fusion network (ATMFN) for compressed face hallucination, which unifies different deep learning models to take advantages of their respective learning merits. First of all, we construct CNN-, GAN- and RNN-based underlying super-resolvers to produce candidate SR results. Further, the attention subnetwork is proposed to learn the individual fusion weight matrices capturing the most informative components of the candidate SR faces. Particularly, the hyper-parameters of the fusion matrices and the underlying networks are optimized together in an end-to-end manner to drive them for collaborative learning. Finally, a threshold-based fusion and reconstruction module is employed to exploit the candidates' complementarity and thus generate high-quality face images. Extensive experiments on benchmark face datasets and real-world samples show that our model outperforms the state-of-the-art SR methods in terms of quantitative indicators and visual effects.","","","10.1109/TMM.2019.2960586","National Key R and D Project; National Natural Science Foundation of China; Hubei Province Technological Innovation Major Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8936424","Threshold-based fusion network;attention mechanism;ensemble learning;compressed face hallucination","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Over-sampling Emotional Speech Data Based on Subjective Evaluations Provided by Multiple Individuals","R. Lotfian; C. Busso","Electrical and Computer Engineering, The University of Texas at Dallas, Richardson, Texas United States (e-mail: RXL099220@utdallas.edu); Electrical Engineering, The University of Texas at Dallas, Richardson, Texas United States 75080 (e-mail: busso@utdallas.edu)","IEEE Transactions on Affective Computing","","2019","PP","99","1","1","A common step in the area of speech emotion recognition is to obtain ground-truth labels describing the emotional content of a sentence. The underlying emotion of a given recording is usually unknown, so perceptual evaluations are conducted to annotate its perceived emotion. Each sentence is often annotated by multiple raters, which are aggregated with methods such as majority vote rules. This paper argues that several labels provided by different individuals convey more information than the consensus labels. We demonstrate that leveraging the information provided by separate evaluations collected by multiple raters can help in building more robust classifiers which maximize the utilization of labeled data. Motivated by the synthetic minority over-sampling technique(SMOTE), we present a novel over-sampling approach during training, where the samples with categorical emotion labels are over-sampled according to the labels assigned by multiple individuals. This approach (1)increases the number of sentences from classes with underrepresented consensus labels, and (2)utilizes sentences with ambiguous emotional content even if they do not reach consensus agreement. The experimental evaluation shows the benefits of the approach over a baseline classifier trained with consensus labels, which increases the F1-score by 5.2% (absolute) for the USC-IEMOCAP corpus, and 5.4% (absolute) for the MSP-IMPROV corpus.","","","10.1109/TAFFC.2019.2901465","Division of Information and Intelligent Systems; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8653857","Speech emotion recognition;synthetic over-sampling;data augmentation for deep neural network","Training;Emotion recognition;Speech recognition;Databases;Machine learning;Task analysis;Neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Spectro-Temporal Attenton-Based Voice Activity Detection","Y. Lee; J. Min; D. Han; H. Ko","Korea University, 34973 Seongbok-gu, Seoul Korea (the Republic of) 02841 (e-mail: yllee@ispl.korea.ac.kr); Seoul Korea (the Republic of) 0284 (e-mail: jkmin@ispl.korea.ac.kr); Office of Naval Research, Arlington United States (e-mail: ctmkhan@gmail.com); Electrical Engineering, Korea University, Seoul Korea (the Republic of) 136-701 (e-mail: hsko@korea.ac.kr)","IEEE Signal Processing Letters","","2019","PP","99","1","1","Voice Activity Detection (VAD) systems suffer from unexpected and non-stationary background noises at magnitudes sufficiently high to mask the speech signal. Although several methods of increasing the performance of VAD have been proposed, their approaches have yet to mitigate the influence of the background noise itself. This paper proposes an effective noise-robust VAD system approach. The proposed method uses spectral attention and temporal attention through applying a deep learning-based attention mechanism. The proposed method is demonstrated and compared with several other deep learning-based methods in terms of the area under the curve in experiments with either known or unknown noise-added, and real-world noisy data. The results show that the proposed method outperforms the other methods in all the scenarios considered, but moreover generalizes well in environments of unknown or unexpected noise.","","","10.1109/LSP.2019.2959917","Korea Environmental Industry and Technology Institute; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933025","Deep neural networks;attention mechanism;voice activity detection;speech activity detection;speech detection","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"An End-to-End Dense-InceptionNet for Image Copy-Move Forgery Detection","J. Zhong; C. Pun","Department of Computer and Information Science, University of Macau, Macau, China.; Department of Computer and Information Science, University of Macau, Macau, China.","IEEE Transactions on Information Forensics and Security","","2019","PP","99","1","1","A novel image copy-move forgery detection scheme using a Dense-InceptionNet is proposed in this paper. Dense-InceptionNet is an end-to-end, multi-dimensional dense-feature connection, Deep Neural Network (DNN). It is the first DNN model to autonomously learn the feature correlations and search the possible forgery snippets through the matching clues. The proposed Dense-InceptionNet consists of Pyramid Feature Extractor (PFE), Feature Correlation Matching (FCM), and Hierarchical Post-Processing (HPP) modules. The PFE module is proposed to extract multi-dimensional and multi-scale dense-features. The features of each layer in this extractor module are directly connected to the preceding layers. The FCM module is proposed to learn the high correlations of deep features and obtain three candidate matching maps. Finally, the HPP module which makes use of three matching maps to obtain a combination of cross-entropies is amenable to better training via backpropagation. Experiments demonstrate that the efficiency of the proposed Dense-InceptionNet is much better than the other state-of-the-art methods while achieving the relative best performance against most known attacks.","","","10.1109/TIFS.2019.2957693","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8926513","Copy-move forgery detection;Deep neural network;Dense-InceptionNet","Feature extraction;Forgery;Correlation;Training;Neural networks;Transforms;Data mining","","","","","","","","","","IEEE","IEEE Early Access Articles"
"FaceEngage: Robust Estimation of Gameplay Engagement from User-contributed (YouTube) Videos","X. Chen; L. Niu; A. Veeraraghavan; A. Sabharwal","Electrical & Computer Engineering, Rice University, Houston, Texas United States (e-mail: xc20@rice.edu); Department of Computer Science and Engineering, Shanghai Jiao Tong University, 12474 Shanghai, Shanghai China (e-mail: ustcnewly@sjtu.edu.cn); Department of Electrical and Computer Engineering, Rice University, 3990 Houston, Texas United States (e-mail: av21@rice.edu); Electrical and Computer Engineering, Rice University, Houston, Texas United States 77005 (e-mail: ashu@rice.edu)","IEEE Transactions on Affective Computing","","2019","PP","99","1","1","Measuring user engagement in interactive tasks can facilitate numerous applications toward optimizing user experience, ranging from eLearning to gaming. However, a significant challenge is the lack of non-contact methods that are robust in unconstrained environments. We present FaceEngage, a non-intrusive engagement estimator leveraging user facial recordings during actual gameplay in naturalistic conditions. Our contributions are three-fold. First, we show the potential of using front-facing videos as training data to build the engagement estimator. We compile FaceEngage Dataset with over 700 user-contributed YouTube picture-in-picture gaming videos (i.e., with full-screen game scenes and time-synchronized user facial recordings in subwindows). Second, we develop FaceEngage system which captures relevant gamer facial features from front-facing recordings to infer task engagement. We implement two pipelines: an estimator trained on user facial motion features inspired by prior psychological works, and a deep learning-enabled estimator. Lastly, we conduct extensive experiments and conclude: (i) certain user facial motion cues (e.g., blink rates) are engagement-indicative; (ii) our deep learning-enabled pipeline can automatically extract informative features, outperforming the facial motion feature-based pipeline; (iii) FaceEngage is robust to various video lengths and users/game genres. Despite the challenging nature of realistic videos, FaceEngage attains the accuracy of 83.8% and leave-one-user-out precision of 79.9%, both of which are superior to the face motion-based pipeline.","","","10.1109/TAFFC.2019.2945014","National Institutes of Health; National Science Foundation; Doerr Institute for New Leaders; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8859245","Engagement Estimation;Video Analysis;Deep Neural Networks","Videos;Task analysis;Atmospheric measurements;Particle measurements;Games;YouTube;Estimation","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Future-State Predicting LSTM for Early Surgery Type Recognition","S. Kannan; G. Yengera; D. Mutter; J. Marescaux; N. Padoy","ICube, University of Strasbourg, CNRS, IHU Strasbourg, France.; ICube, University of Strasbourg, CNRS, IHU Strasbourg, France.; University Hospital of Strasbourg, IRCAD, IHU Strasbourg, France.; University Hospital of Strasbourg, IRCAD, IHU Strasbourg, France.; ICube, University of Strasbourg, CNRS, IHU Strasbourg, France.","IEEE Transactions on Medical Imaging","","2019","PP","99","1","1","This work presents a novel approach for the early recognition of the type of a laparoscopic surgery from its video. Early recognition algorithms can be beneficial to the development of ’smart’ OR systems that can provide automatic context-aware assistance, and also enable quick database indexing. The task is however ridden with challenges specific to videos belonging to the domain of laparoscopy, such as high visual similarity across surgeries and large variations in video durations. To capture the spatio-temporal dependencies in these videos, we choose as our model a combination of a Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM) network. We then propose two complementary approaches for improving early recognition performance. The first approach is a CNN fine-tuning method that encourages surgeries to be distinguished based on the initial frames of laparoscopic videos. The second approach, referred to as ’Future-State Predicting LSTM ’, trains an LSTM to predict information related to future frames, which helps in distinguishing between the different types of surgeries. We evaluate our approaches on a large dataset of 425 laparoscopic videos containing 9 types of surgeries (Laparo425), and achieve on average an accuracy of 75% having observed only the first 10 minutes of a surgery. These results are quite promising from a practical standpoint and also encouraging for other types of image-guided surgeries.","","","10.1109/TMI.2019.2931158","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8772203","Laparoscopic Video;Early Detection;Surgery Recognition;Surgical Workflow;Deep Learning","Surgery;Laparoscopes;Task analysis;Feature extraction;Image recognition;Visualization;Computer vision","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"A Joint Framework for Athlete Tracking and Action Recognition in Sports Videos","L. Kong; D. Huang; J. Qin; Y. Wang","Beijing Advanced Innovation Center for Big Data and Brain Computing, Beihang University, Beijing 100191, China.; Beijing Advanced Innovation Center for Big Data and Brain Computing, Beihang University, Beijing 100191, China.; Inception Institute of Artificial Intelligence, Abu Dhabi, United Arab Emirates.; Beijing Advanced Innovation Center for Big Data and Brain Computing, Beihang University, Beijing 100191, China.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Sports video analysis has received increasing attention in recent years. Athlete tracking and action recognition are its two major issues that are highly related to each other; however, they are individually considered and processed in existing studies. In this paper, we propose a joint framework for athlete tracking and action recognition in sports videos. In athlete tracking, we propose a scaling and occlusion robust tracker, named SORT, to localize the position of the specific athlete in each frame. It follows the approach of Compressive Tracking (CT), but extends it in two aspects, i.e., scale refinement as well as occlusion recovery. For the former, an objectness method, Edge Box (EB), is adopted to generate proposals, which replace the fixed sampling boxes in CT and better fit the scales of the candidate objects. For the latter, a candidate obstruction based solution is presented, which brings in additional trackers to detect possible obstructions and relocate the target as occlusion ends. Regarding action recognition, we propose a Long-term Recurrent Region-guided Convolutional Network (LRRCN), which recognizes pre-defined actions by modeling discriminative temporal cues of the tracking results. We employ SPP-net to extract the robust feature of the tracked region of each frame. The features of all the frames are then fed into a stack of recurrent sequence models to capture the long-term region-level information. We extensively evaluate the proposed approach on a newly collected sports video benchmark and the off-the-shelf UIUC2 dataset, and the experimental results clearly show its effectiveness.","","","10.1109/TCSVT.2019.2893318","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8618380","sports video analysis;object tracking;action recognition;deep learning;recurrent neural networks","Videos;Sports;Target tracking;Object tracking;Task analysis;Feature extraction","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Recent Advances on HEVC Inter-frame Coding: From Optimization to Implementation and Beyond","Y. Zhang; C. Zhang; R. Fan; S. Ma; Z. Chen; C. -. J. Kuo","Beijing Key Laboratory of Digital Media, School of Computer Science and Engineering, and State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing, China, 100191.; Beijing Key Laboratory of Digital Media, School of Computer Science and Engineering, and State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing, China, 100191.; China Academy of Electronic and Information Technology, Beijing, China, 100041.; Institute of Digital Media, School of Electronics Engineering and Computer Science, Peking University, Beijing 100871, China.; University of Science and Technology of China, Hefei, Anhui, 230026, China.; University of Southern California, Los Angeles, CA 90089, USA.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","High Efficiency Video Coding (HEVC) has doubled the video compression ratio with equivalent subjective quality as compared to its predecessor H.264/AVC. The significant coding efficiency improvement is attributed to many new techniques. Inter-frame coding is one of the most powerful yet complicated techniques therein and has posed high computational burden thus main obstacle in HEVC-based real-time applications. Recently, plenty of research has been done to optimize the inter-frame coding, either to reduce the complexity for real-time applications, or to further enhance the encoding efficiency. In this paper, we provide a comprehensive review of the state-of-the-art techniques for HEVC inter-frame coding from three aspects, namely fast inter coding solutions, implementation on different hardware platforms as well as advanced inter coding techniques. More specifically, different algorithms in each aspect are further subdivided into sub-categories and compared in terms of pros, cons, coding efficiency and coding complexity. To the best of our knowledge, this is the first such comprehensive review of the recent advances of the inter-frame coding for HEVC and hopefully it would help the improvement, implementation and applications of HEVC as well as the ongoing development of the next generation video coding standard.","","","10.1109/TCSVT.2019.2954474","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8906164","High Efficiency Video Coding;Inter-frame Coding;Real-time Applications;Implementation;Affine Transform;Deep Learning","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A new localization objective for accurate fine-grained affordance segmentation under high-scale variations","M. Hassanin; S. Khan; M. Tahtali","School of Engineering and Information Technology, University of New South Wales at ADFA, Canberra, ACT 2610, Australia).; Australian National University, Canberra, ACT 2600 and Inception Institute of Artificial Intelligence, Abu Dhabi, UAE.; School of Engineering and Information Technology, University of New South Wales at ADFA, Canberra, ACT 2610, Australia).","IEEE Access","","2019","PP","99","1","1","Fine-grained affordance segmentation for object parts can greatly benefit robotics and scene understanding applications. In this work, we propose an instance-segmentation framework that can accurately localize functionality and affordance of individual object parts. We build on the standard Mask-RCNN framework and propose two novelties to the localization objective that can lead to improved part detection and affordance segmentation results. Specifically, we notice two problems with the conventional IOU based regression loss, (a) the small boxes, that are specially relevant for fine-grained detection, have a higher risk of being ignored during the optimization process and (b) a constant value of IOU for nonoverlapping candidates means no supervision is available to encourage the reduction in loss function. To address these limitations, we propose a novel Angular Intersection Over Larger (AIOL) measure. Our experiments show consistent improvement over other baselines and state of the art localization loss functions for the fine-grained affordance segmentation task.","","","10.1109/ACCESS.2019.2958608","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8930497","Affordance Labeling;Convolutional Neural Networks;Deep Learning;Instance Segmentation","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"MUGGLE: MUlti-stream Group Gaze Learning and Estimation","N. Zhuang; B. Ni; Y. Xu; X. Yang; W. Zhang; Z. Li; W. Gao","School of Shanghai Jiao Tong University, China.; School of Shanghai Jiao Tong University, China.; School of Shanghai Jiao Tong University, China.; School of Shanghai Jiao Tong University, China.; School of Shanghai Jiao Tong University, China.; School of Shanghai Jiao Tong University, China.; School of Peking University, China.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Being able to accurately predict the common gaze point of a group of persons is of particular interest to precise marketing and automatic group attention assessment. Group gaze estimation faces challenges including small face/head size and outlier observers. To address these challenges, we proposed a novel framework called Multi-stream Group Gaze Learning and Estimation (MUGGLE). The MUGGLE infrastructure includes two inference streams: 1) a holistic stream which utilizes fused attention map as input to a global deep convolutional structure to explore the global geometric configurations and contexts of interesting persons in the scene; and 2) an aggregative stream which robustly aggregates individual gazes via a recurrent structure (e.g., LSTM) to obtain outlier-tolerant estimation. Both streams are seamlessly integrated via a fusion network. Extensive experiments are performed on a fully annotated group gaze image dataset with 8,000+ images and 100,000+ faces (which is publicly releasable). The results demonstrate the effectiveness of the proposed MUGGLE framework in group gaze estimation.","","","10.1109/TCSVT.2019.2940479","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8832257","Group Gaze;LSTM;holistic;aggregative","Databases;Streaming media;Observers;Head;Aggregates;Cameras","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Crowdsourced wireless spectrum anomaly detection","S. Rajendran; V. Lenders; W. Meert; S. Pollin","Department ESAT, KU Leuven, Belgium.; armasuisse, Thun, Switzerland.; Department of Computer Science, KU Leuven, Belgium.; Department ESAT, KU Leuven, Belgium.","IEEE Transactions on Cognitive Communications and Networking","","2019","PP","99","1","1","Automated wireless spectrum monitoring across frequency, time and space will be essential for many future applications. Manual and fine-grained spectrum analysis is becoming impossible because of the large number of measurement locations and complexity of the spectrum use landscape. Detecting unexpected behaviors in the wireless spectrum from the collected data is a crucial part of this automated monitoring, and the control of detected anomalies is a key functionality to enable interaction between the automated system and the end user. In this paper we look into the wireless spectrum anomaly detection problem for crowdsourced sensors. We first analyze in detail the nature of these anomalies and design effective algorithms to bring the higher dimensional input data to a common feature space across sensors. Anomalies can then be detected as outliers in this feature space. In addition, we investigate the importance of user feedback in the anomaly detection process to improve the performance of unsupervised anomaly detection. Furthermore, schemes for generalizing user feedback across sensors are also developed to close the anomaly detection loop.","","","10.1109/TCCN.2019.2947512","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8869903","Deep learning;Anomaly detection;Crowdsourcing.","Anomaly detection;Feature extraction;Wireless communication;Detectors;Wireless sensor networks;Hidden Markov models","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Learning Discriminative and Generative Shape Embeddings for 3D Shape Retrieval","C. Xu; B. Leng; B. Chen; C. Zhang; X. Zhou","School of Computer Science and Engineering, Beihang University, Beijing China (e-mail: cxu@buaa.edu.cn); School of Computer Science and Engieering, Beihang University, 12633 Beijing China 100191 (e-mail: lengbiao@buaa.edu.cn); School of Sino-French Engineer, Beihang University, Beijing China (e-mail: florentchen@buaa.edu.cn); School of Computer Science, Carnegie Mellon University, Pittsburgh United States (e-mail: chengz2@andrew.cmu.edu); School of Engineering and Applied Science, Washington University, St. Louis United States (e-mail: zhouxiaochen@wustl.edu)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","As an important solution for 3D shape retrieval, a multi-view shape descriptor has achieved impressive performance. One crucial part of view-based shape descriptors is to interpret 3D structures through various 2D observations. Most existing methods like MVCNN believe that a strong classification model trained with deep learning, can often provide an efficient shape embedding for 3D shape retrieval. However, these methods pay much attention to discriminative models and none of them necessarily incorporate the underlying 3D properties of the objects from 2D images. In this paper, we present a novel encoder-decoder recurrent feature aggregation network (ERFA-Net) to address this problem. Aiming at emphasizing the 3D properties of 3D shapes in the fusion of multiple view features, 3D properties prediction tasks are introduced into the 3D shape retrieval. Specifically, an image sequence of the shape is recurrently aggregated into a discriminative shape embedding based on LSTM network, and then this latent shape embedding is trained to predict the original voxel grids and estimate images of unseen viewpoints. This generation task gives an effective supervision which makes the network exploit 3D properties of shapes through various 2D images. Our method achieves the state-of-the-art performance for 3D shape retrieval, on two large-scale 3D shape datasets, ModelNet and ShapeNetCore55. Extensive experiments show that the proposed 3D representation performs robust discrimination against view occlusion, and strong generation ability for various 3D shape tasks.","","","10.1109/TMM.2019.2957933","Natural Science Foundation of Beijing Municipality; National Natural Science Foundation of China; National Key R and D Program of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8931662","3D shape retrieval;Feature aggregation;Recurrent neural network","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Homecare-oriented Intelligent Long-term Monitoring of Blood Pressure Using Electrocardiogram Signals","X. Fan; H. Wang; F. Xu; Y. Zhao; K. Tsui","School of Data Science, Hong Kong SAR Hong Kong (e-mail: xifang@cityu.edu.hk); School of Data Science, City University of Hong Kong, 53025 Kowloon Hong Kong (e-mail: hailwang@cityu.edu.hk); School of Data Science, City University of Hong Kong, 53025 Kowloon Hong Kong (e-mail: fanxu8@cityu.edu.hk); School of Data Science, City University of Hong Kong, 53025 Kowloon Hong Kong (e-mail: yangzhao9-c@my.cityu.edu.hk); School of Data Science, City University of Hong Kong, 53025 Kowloon Hong Kong 000000 (e-mail: kltsui@cityu.edu.hk)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","Long-term blood pressure (BP) monitoring is a widely used approach in a homecare intelligent system. However, BP is usually measured using cuff-based devices with tedious operations in practice, which may not be cost-effective for continuous BP tracking. In this study, we propose a novel attention-based multitask network with weighting scheme for BP estimation by analyzing and modeling single lead electrocardiogram (ECG) signals. Experiment results demonstrate that the proposed method could achieve mean error of systolic blood pressure (SBP), diastolic blood pressure (DBP), and mean arterial pressure (MAP) estimation in level of 0.18 +/- 10.83 mmHg, 1.24 +/- 5.90 mmHg, and 0.84 +/- 6.47 mmHg, respectively. In comparison to other cutting-edge methods using ECG signals, the proposed method shows superior BP estimation performance. By integrating with a wearable/portable ECG monitoring device, the proposed model can be deployed to an embedded system or remote healthcare intelligent system to provide long-term BP monitoring service, which would help reduce the incidence of malignant events happened in hypertensive population.","","","10.1109/TII.2019.2962546","City University of Hong Kong; National Natural Science Foundation of China; RGC Theme-Based Research Scheme; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8943989","Blood pressure;deep learning;healthcare monitoring;electrocardiogram signals;multiple tasks;attention mechanism","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Primary Quantization Matrix Estimation of Double Compressed JPEG Images via CNN","N. Yakun; B. Tondi; Y. Zhao; M. Barni","Institute of Information Science, Beijing Jiaotong University, Beijing China (e-mail: niuyakun@bjtu.edu.cn); Dept. of Information Engineering, University of Siena, Siena, Siena Italy 53100 (e-mail: benedettatondi@gmail.com); Institute of Information Science, Beijing Jiaotong University, Beijing China 100044 (e-mail: yzhao@bjtu.edu.cn); Universita di Siena, Department of Information Engineering and Mathematics, Siena, Siena Italy 53100 (e-mail: barni@dii.unisi.it)","IEEE Signal Processing Letters","","2019","PP","99","1","1","Available model-based techniques for the estimation of the primary quantization matrix in double-compressed JPEG images work only under specific conditions regarding the relationship between the first and second compression quality factors, and the alignment of the first and second JPEG compression grids. In this paper, we propose a single CNN-based estimation technique that can work under a very general range of settings. We do so, by adapting a dense CNN network to the problem at hand. Particular attention is paid to the choice of the loss function. Experimental results highlight several advantages of the new method, including: i) capability of working under very general conditions, ii) improved performance in terms of MSE and accuracy especially in the non-aligned case, iii) better spatial resolution due to the ability of providing good results also on small image patches.","","","10.1109/LSP.2019.2962997","DARPA and Air Force Research Laboratory; National Basic Research Program of China (973 Program); China Scholarship Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8945385","Digital image forensics;deep learning for forensics;double JPEG compression;quantization matrix estimation","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Eyes in the Skies: A Data-Driven Fusion Approach to Identifying Drug Crops From Remote Sensing Images","A. Ferreira; S. C. Felipussi; R. Pires; S. Avila; G. Santos; J. Lambert; J. Huang; A. Rocha","Guangdong Key Laboratory of Intelligent Information Processing, the Shenzhen Key Laboratory of Media Security, College of Information Engineering, and the National Engineering Laboratory for Big Data System Computing Technology, Shenzhen University, Shenzhen 518060, China (e-mail: anselmo@szu.edu.cn).; Department of Computer Science, Universidade Federal de São Carlos, São Carlos 13565-905, Brazil (e-mail: siovani@hotmail.com).; Institute of Computing, University of Campinas (Unicamp), São Paulo 13083-852, Brazil (e-mail: pires.ramon@ic.unicamp.br).; Institute of Computing, University of Campinas (Unicamp), São Paulo 13083-852, Brazil (e-mail: sandraeliza@gmail.com).; Institute of Computing, University of Campinas (Unicamp), São Paulo 13083-852, Brazil (e-mail: geise.kss@gmail.com).; National Institute of Criminology, Brazilian Federal Police, Brasilia 70610-20, Brazil, and also with the Department of Mechatronics Systems, University of Brasilia, Brasilia 70910-900, Brazil (e-mail: lambert.jal@dpf.gov.br).; Guangdong Key Laboratory of Intelligent Information Processing, the Shenzhen Key Laboratory of Media Security, College of Information Engineering, and the National Engineering Laboratory for Big Data System Computing Technology, Shenzhen University, Shenzhen 518060, China (e-mail: jwhuang@szu.edu.cn).; Institute of Computing, University of Campinas (Unicamp), São Paulo 13083-852, Brazil (e-mail: anderson.rocha@ic.unicamp.br).","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2019","PP","99","1","14","Automatic classification of sensitive content in remote sensing images, such as drug crop sites, is a promising task, as it can aid law-enforcement institutions in fighting illegal drug dealers worldwide, while, at the same time, it can help monitor legalized crops in countries that regulate them. However, existing art on detecting drug crops from remote sensing images is limited in some key factors, not taking full advantage of the available hyperspectral information for analysis. In this paper, departing from these methods, we propose a data-driven ensemble method to detect drug sites from remote sensing images. Our method comprises different convolutional neural network architectures applied to distinct image representations, which are able to represent complementary characterizations of such crops. To validate the proposed approach, we considered in our experiments a dataset containing Cannabis Sativa crops, spotted by police operations in a Brazilian region called the Marijuana Polygon. The results in this dataset show that our ensemble approach outperforms other data-driven and feature-engineering methods in a real-world experimental setup, in which unbalanced samples are present and acquisitions from different places in the same region are used for training and testing the methods, highlighting the promising use of this solution to aid police operations in detecting and collecting evidence of such sensitive content properly.","","","10.1109/JSTARS.2019.2917024","National Science Foundation of China; Shenzhen Research and Development Program; Brazilian Coordination; FINEP; Brazilian National Council; Sao Paulo Research Foundation; FAPESP; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8726132","Convolutional neural networks (CNNs);deep learning;detection of drug crops;sensitive remote sensing analysis","Agriculture;Drugs;Remote sensing;Convolution;Training;Neural networks;Law enforcement","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Dense Dilated Network with Probability Regularized Walk for Vessel Detection","L. Mou; L. Chen; ∧. J. Cheng; Z. Gu; Y. Zhao; J. Liu","School of Computer Science and Technology, Wuhan University of Science and Technology, Wuhan 430081, China, Hubei Province Key Laboratory of Intelligent Information Processing and Real-time Industrial System, Wuhan University of Science and Technology, Wuhan 430081, China and also Cixi Institute of Biomedical Engineering, Chinese Academy of Sciences, Zhejiang 315201, China.; School of Computer Science and Technology, Wuhan University of Science and Technology, Wuhan 430081, China and Hubei Province Key Laboratory of Intelligent Information Processing and Real-time Industrial System, Wuhan University of Science and Technology, Wuhan 430081, China.; Cixi Institute of Biomedical Engineering, Chinese Academy of Sciences, Zhejiang 315201, China and also with UBTech Research, UBTech Robotics Corp Ltd, Guangdong 518055, China.; Cixi Institute of Biomedical Engineering, Chinese Academy of Sciences, Zhejiang 315201, China and also with UBTech Research, UBTech Robotics Corp Ltd, Guangdong 518055, China.; Cixi Institute of Biomedical Engineering, Chinese Academy of Sciences, Zhejiang 315201, China and also with UBTech Research, UBTech Robotics Corp Ltd, Guangdong 518055, China.; Department of Computer Science and Engineering, Southern University of Science and Technology, Guangdong 518055, China.","IEEE Transactions on Medical Imaging","","2019","PP","99","1","1","The detection of retinal vessel is of great importance in the diagnosis and treatment of many ocular diseases. Many methods have been proposed for vessel detection. However, most of the algorithms neglect the connectivity of the vessels, which plays an important role in the diagnosis. In this paper, we propose a novel method for retinal vessel detection. The proposed method includes a dense dilated network to get an initial detection of the vessels and a probability regularized walk algorithm to address the fracture issue in the initial detection. The dense dilated network integrates newly proposed dense dilated feature extraction blocks into an encoder-decoder structure to extract and accumulate features at different scales. A multi-scale Dice loss function is adopted to train the network. To improve the connectivity of the segmented vessels, we also introduce a probability regularized walk algorithm to connect the broken vessels. The proposed method has been applied on three public data sets: DRIVE, STARE and CHASE_DB1. The results show that the proposed method outperforms the state-of-the-art methods in accuracy, sensitivity, specificity and also area under receiver operating characteristic curve.","","","10.1109/TMI.2019.2950051","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8886468","Vessel segmentation;encoder-decoder;deep learning;regularized walk;vessel reconnection","Feature extraction;Retinal vessels;Image segmentation;Diseases;Blood vessels;Biomedical imaging","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Attention-Driven Loss for Anomaly Detection in Video Surveillance","J. T. Zhou; L. Zhang; Z. Fang; J. Du; X. Peng; X. Yang","Institute of High Performance Computing (IHPC), the Agency for Science, Technology and Research (A*STAR), Singapore.; Institute for Infocomm Research (I2R), the Agency for Science, Technology and Research (A*STAR), Singapore.; Guangdong Provincial Key Laboratory of Medical Image Processing, School of Biomedical Engineering, Southern Medical University, Guangzhou, China and School of Energy and Mechanical-electronic Engineering, Hunan University of Humanities, Science and Technology, Loudi, China.; Institute of High Performance Computing (IHPC), the Agency for Science, Technology and Research (A*STAR), Singapore.; College of Computer Science, Sichuan Univerisity, China.; National Key Laboratory of Science and Technology on Multi-Spectral Information Processing, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Recent video anomaly detection methods focus on reconstructing or predicting frames. Under this umbrella, the long-standing inter-class data-imbalance problem resorts to the imbalance between foreground and stationary background objects in video anomaly detection and this has been less investigated by existing solutions. Naively optimizing the reconstructing loss yields a biased optimization towards background reconstruction rather than the objects of interest in the foreground. To solve this, we proposed a simple yet effective solution, termed attention-driven loss to alleviate the foreground-background imbalance problem in anomaly detection. Specifically, we compute a single mask map that summarizes the frame evolution of moving foreground regions and suppresses the background in the training video clips. After that, we construct an attention map through the combination of the mask map and background to give different weights to the foreground and background region respectively. The proposed attention-driven loss is independent of backbone networks and can be easily augmented in most existing anomaly detection models. Augmented with attention-driven loss, the model is able to achieve AUC 86.0% on Avenue, 83.9% on Ped1, 96% on Ped2 datasets. Extensive experimental results and ablation studies further validate the effectiveness of our model.","","","10.1109/TCSVT.2019.2962229","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8943099","anomaly detection;deep learning;attention","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Modelling Taxi Drivers' Behaviour for the Next Destination Prediction","A. Rossi; G. Barlacchi; M. Bianchini; B. Lepri","Department of Information Engineering, University of Florence, 50139 Florence, Italy (e-mail: alberto.rossi@unifi.it).; Department of Information Engineering and Computer Science, University of Trento, 38122 Trento, Italy.; Department of Information Engineering and Mathematics, University of Siena, 53100 Siena, Italy.; Mobile and Social Computing Laboratory, Bruno Kessler Foundation, 38122 Trento, Italy.","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","10","In this paper, we study how to model taxi drivers' behavior and geographical information for an interesting and challenging task: the next destination prediction in a taxi journey. Predicting the next location is a well-studied problem in human mobility, which finds several applications in real-world scenarios, from optimizing the efficiency of electronic dispatching systems to predicting and reducing the traffic jam. This task is normally modeled as a multiclass classification problem, where the goal is to select, among a set of already known locations, the next taxi destination. We present a Recurrent Neural Network (RNN) approach that models the taxi drivers' behavior and encodes the semantics of visited locations by using geographical information from Location-Based Social Networks (LBSNs). In particular, the RNNs are trained to predict the exact coordinates of the next destination, overcoming the problem of producing, in output, a limited set of locations, seen during the training phase. The proposed approach was tested on the ECML/PKDD Discovery Challenge 2015 dataset--based on the city of Porto--, obtaining better results with respect to the competition winner, whilst using less information, and on Manhattan and San Francisco datasets.","","","10.1109/TITS.2019.2922002","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8741193","Taxi destination prediction;deep learning;LSTM;smart cities.","Public transportation;Urban areas;Trajectory;Predictive models;Recurrent neural networks;Task analysis;Vehicles","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Requirements-driven Test Generation for Autonomous Vehicles with Machine Learning Components","C. E. Tuncali; G. Fainekos; D. Prokhorov; H. Ito; J. Kapinski","CIDSE, Arizona State University, Tempe, Arizona United States 85281 (e-mail: etuncali@asu.edu); School of Computing, Informatics and Decision Systems Engineering, Arizona State University, Tempe, Arizona United States (e-mail: Georgios.Fainekos@asu.edu); TRI-NA, Toyota Motor North America, 116612 Ann Arbor, Michigan United States (e-mail: danil.prokhorov@toyota.com); TRI-NA, Toyota Motor North America, 116612 Ann Arbor, Michigan United States (e-mail: hisahiro.ito@toyota.com); TRI-NA, Toyota Motor North America, 116612 Ann Arbor, Michigan United States (e-mail: jimkapinski@gmail.com)","IEEE Transactions on Intelligent Vehicles","","2019","PP","99","1","1","Autonomous vehicles are complex systems that are challenging to test and debug. A requirements-driven approach to the development process can decrease the resources required to design and test these systems, while simultaneously increasing the reliability. We present a testing framework that uses signal temporal logic (STL), which is a precise and unambiguous requirements language. Our framework evaluates test cases against the STL formulae and additionally uses the requirements to automatically identify cases that fail to satisfy the requirements. One of the key features of our tool is the support for machine learning (ML) components in the system design, such as deep neural networks. Our framework includes evaluation of the control algorithms, including the ML components, and it also includes models of CCD camera, lidar, and radar sensors, as well as the vehicle environment. We use multiple methods to generate test cases, including covering arrays, which is an efficient method to search discrete variable spaces.The resulting test cases can be used to debug the controller design by identifying controller behaviors that do not satisfy requirements. The test cases can also enhance the testing phase of development by identifying critical corner cases that correspond to the limits of the system's allowed behaviors.","","","10.1109/TIV.2019.2955903","Division of Computer and Network Systems; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8911483","","Sensors;Autonomous vehicles;Laser radar;Test pattern generators;Charge coupled devices;Closed loop systems","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Vehicle Type Classification using an Enhanced Sparse-Filtered Convolutional Neural Network with Layer-Skipping Strategy","S. Awang; N. M. A. N. Azmi; M. A. Rahman","Soft Computing Intelligent Systems (SPINT), Faculty of Computing, Universiti Malaysia PAHANG, Kuantan 26300, Malaysia.; Soft Computing Intelligent Systems (SPINT), Faculty of Computing, Universiti Malaysia PAHANG, Kuantan 26300, Malaysia.; Soft Computing Intelligent Systems (SPINT), Faculty of Computing, Universiti Malaysia PAHANG, Kuantan 26300, Malaysia and IBM Center of Excellence, Universiti Malaysia PAHANG, Kuantan 26300, Malaysia and Earth Resources and Sustainability Center, Universiti Malaysia PAHANG, Kuantan 26300, Malaysia.","IEEE Access","","2019","PP","99","1","1","In this paper, a vehicle type classification approach is proposed by using an enhanced feature extraction technique based on Sparse-Filtered Convolutional Neural Network with Layer-Skipping strategy (SF-CNNLS). To extract rich and discriminant vehicle features, we introduce Three-Channels of SF-CNNLS (TC-SF-CNNLS) as the feature extraction technique. Local and global features of vehicles are extracted from three channels of an image which are, luminance and chromatic components. This technique is inspired by how human eyes differentiating objects that share almost similar features. TC-SF-CNNLS is tested with a benchmark dataset that provides frontal-view images to classify vehicle types of the bus, passenger car, taxi, minivan, SUV, and truck with Softmax Regression as a classifier. This test aims to observe the ability of this technique in differentiating vehicles with almost similar features but different classes. A test is also conducted with the self-obtained dataset (SPINT) to observe the effectiveness of this technique. The results are observed based on accuracy, precision, recall, and f-score, whereby, TCSF-NNLS has successfully recognized all the classes with an average accuracy of 0.905, precision is between 0.8629 to 0.9548, recall is between 0.83 to 0.96 and f-score is between 0.8564 to 0.9523. In addition, this technique is able to outperform other existing techniques with an average accuracy of 93.% compared to only 89.2% when 5 classes of vehicles are tested.","","","10.1109/ACCESS.2019.2963486","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8948021","Vehicle Type Recognition;Convolutions Neural Network;Deep Learning;Computational Intelligence","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Saliency-Guided Single Shot Multibox Detector for Target Detection in SAR Images","L. Du; L. Li; D. Wei; J. Mao","National Laboratory of Radar Signal Processing, Xidian University, Xi'an 710071, China (e-mail: dulan@mail.xidian.edu.cn).; National Laboratory of Radar Signal Processing, Xidian University, Xi'an 710071, China.; National Laboratory of Radar Signal Processing, Xidian University, Xi'an 710071, China.; National Laboratory of Radar Signal Processing, Xidian University, Xi'an 710071, China.","IEEE Transactions on Geoscience and Remote Sensing","","2019","PP","99","1","11","The single shot multibox detector (SSD), a proposal-free method based on convolutional neural network (CNN), has recently been proposed for target detection and has found applications in synthetic aperture radar (SAR) images. Moreover, the saliency information reflected in the saliency map can highlight the target of interest while suppressing clutter, which is beneficial for better scene understanding. Therefore, in this article, we propose a saliency-guided SSD (S-SSD) for target detection in SAR images, in which we effectively integrate the saliency into the SSD network not only to suggest where to focus on but also to improve the representation capability in complex scenes. The proposed S-SSD contains two separated convolutional backbone subnetwork architectures, one with the original SAR image as input to extract features, and the other with the corresponding saliency map obtained from the modified Itti's method as input to acquire refined saliency information under supervision. In addition, the dense connection structure, instead of the plain structure used in original SSD, is applied in the two convolutional backbone architectures to utilize multiscale information with fewer parameters. Then, for integrating saliency information to guide the network to emphasize informative regions, multilevel fusion modules are utilized to merge the two streams into a unified framework, thereby making the whole network end-to-end jointly trained. Finally, the convolutional predictors are used to predict targets. The experimental results on the miniSAR real data demonstrate that the proposed S-SSD can achieve better detection performance than state-of-the-art methods.","","","10.1109/TGRS.2019.2953936","National Science Foundation of China; 111 Project; Shaanxi Innovation Team Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8930938","Convolutional neural network (CNN);deep learning;saliency detection;single shot multibox detector (SSD);synthetic aperture radar (SAR);target detection.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Assembling Convolution Neural Networks for Automatic Viewing Transformation","H. Cai; L. Jiang; B. Liu; Y. Deng; Q. Meng","School of Computing, Loughborough University, 5156 Loughborough, Leicestershire United Kingdom of Great Britain and Northern Ireland LE11 3TU (e-mail: jlcaihaibin@gmail.com); Loughborough University, 5156 Loughborough, Leicestershire United Kingdom of Great Britain and Northern Ireland LE11 3TU (e-mail: l.jiang471533526@gmail.com); Loughborough University, 5156 Loughborough, Leicestershire United Kingdom of Great Britain and Northern Ireland LE11 3TU (e-mail: b.liu2@lboro.ac.uk); Hunan SukeIntel Co., Ltd, Changsha, Hunan China 410013 (e-mail: yiqi_deng@163.com); Computer Science, Loughborough University, Loughborough United Kingdom of Great Britain and Northern Ireland LE11 3TH (e-mail: q.meng@lboro.ac.uk)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","Images taken under different camera poses are rotated or distorted, which leads to poor perception experiences. This paper proposes a new framework to automatically transform the images to the conformable view setting by assembling different convolution neural networks. Specifically, a referential 3D ground plane is firstly derived from the RGB image and a novel projection mapping algorithm is developed to achieve automatic viewing transformation. Extensive experimental results demonstrate that the proposed method outperforms the state-of-the-art vanishing points based methods by a large margin in terms of accuracy and robustness.","","","10.1109/TII.2019.2940136","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8827292","Automatic Viewing Transform;Convolution Neural Networks;Deep Learning","Three-dimensional displays;Image segmentation;Cameras;Image sensors;Convolution;Neural networks;Transforms","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Coherence Constrained Graph LSTM for Group Activity Recognition","J. Tang; X. Shu; R. Yan; L. Zhang","School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, Jiangsu China 210094 (e-mail: tangjh1981@acm.org); School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, Jiangsu China 210094 (e-mail: shuxb@njust.edu.cn); School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, Jiangsu China (e-mail: ruiyan@njust.edu.cn); College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, 47854 Nanjing, Jiangsu China (e-mail: zhangliyan@nuaa.edu.cn)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","This work aims to address the group activity recognition problem by exploring human motion characteristics. Traditional methods hold that the motions of all persons contribute equally to the group activity, which suppresses the contributions of some relevant motions to the whole activity while overstates some irrelevant motions. To handle this problem, we present a Spatio-Temporal Context Coherence (STCC) constraint and a Global Context Coherence (GCC) constraint to capture the relevant motions and quantify their contributions to the group activity, respectively. Based on this, we propose a novel Coherence Constrained Graph LSTM (CCG-LSTM) with STCC and GCC to effectively recognize group activity, by modeling the relevant motions of individuals while suppressing the irrelevant motions. Specifically, to capture the relevant motions, we build the CCG-LSTM with a temporal confidence gate and a spatial confidence gate to control the memory state updating in terms of the temporally previous state and the spatially neighboring states, respectively. Besides, an attention mechanism is employed to quantify the contribution of a certain motion by measuring the consistency between itself and the whole activity at each time step. Finally, we conduct experiments on two widely-used datasets to illustrate the effectiveness of the proposed CCG-LSTM compared with the state-of-the-arts methods.","","","10.1109/TPAMI.2019.2928540","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8762119","group activity recognition;long short-term memory;fine-grained motion;deep learning","Coherence;Activity recognition;Logic gates;Motion measurement;Time measurement;Recurrent neural networks;Games","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Neural Attention Frameworks for Explainable Recommendation","O. Tal; Y. Liu; J. Huang; X. Yu; B. Aljbawi","Department of Physics and Computer Science, Wilfrid Laurier University, 8431 Waterloo, Ontario Canada (e-mail: talx6630@mylaurier.ca); Department of Physics and Computer Science, Wilfrid Laurier University, 8431 Waterloo, Ontario Canada (e-mail: yangliu@wlu.ca); School of Information Technology, York University, Toronto, Ontario Canada (e-mail: jhuang@yorku.ca); School of Information Technology, York University, 7991 Toronto, Ontario Canada (e-mail: xhyu05@gmail.com); Physics and Computer Science, Wilfrid Laurier University Faculty of Science, 192321 Waterloo, Ontario Canada (e-mail: aljb1640@mylaurier.ca)","IEEE Transactions on Knowledge and Data Engineering","","2019","PP","99","1","1","Neural attention, an emerging technique used to identify important inputs within neural networks, have become increasingly popular in the area of recommender systems. Not only allowing to better identify what defines users and items, attention-based recommender systems are further able to provide accompanying explanations. However, these representations usually capture only part of users' preferences and items' attributes, resulting in limited reasoning and accuracy. We therefore propose Dual Attention Recommender with Items and Attributes (DARIA), a novel approach able to combine two dependable neural attention mechanisms to better justify its suggestions. Utilizing the personalized history of users, DARIA identifies the most relevant past activities while considering the real-world features that contributed to the similarity. In addition, we adopt the novel approach of self-attention and introduce Self-Attention Recommender based on Attributes and History (SARAH). As a variation to DARIA, SARAH utilizes two self-attention components to describe users by their most characteristic past activities and items by their best depicting attributes. Various experiments establish the significant improvement of SARAH and DARIA over six key baselines in diverse recommendation settings. By comparing our two proposed frameworks, we demonstrate the potential benefit of applying self-attention in different scenarios.","","","10.1109/TKDE.2019.2953157","NSERC Discovery Grants; National Natural Science Foundation of China Grant; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8896879","Recommender Systems;Collaborative Filtering;Deep Learning;Neural Attention","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"CNN-Based Automatic Prioritization of Bug Reports","Q. Umer; H. Liu; I. Illahi","School of Computer Science and Technology, Beijing Institute of Technology, Beijing 100081, China (e-mail: qasimumer667@hotmail.com).; School of Computer Science and Technology, Beijing Institute of Technology, Beijing 100081, China (e-mail: liuhui08@bit.edu.cn).; School of Computer Science and Technology, Beijing Institute of Technology, Beijing 100081, China (e-mail: inamillahi@gmail.com).","IEEE Transactions on Reliability","","2019","PP","99","1","14","Software systems often receive a large number of bug reports. Triagers read through such reports and assign different priorities to different reports so that important and urgent bugs could be fixed on time. However, manual prioritization is tedious and time-consuming. To this end, in this article, we propose a convolutional neural network (CNN) based automatic approach to predict the multiclass priority for bug reports. First, we apply natural language processing (NLP) techniques to preprocess textual information of bug reports and covert the textual information into vectors based on the syntactic and semantic relationship of words within each bug report. Second, we perform the software engineering domain specific emotion analysis on bug reports and compute the emotion value for each of them using a software engineering domain repository. Finally, we train a CNN-based classifier that generates a suggested priority based on its input, i.e., vectored textual information and emotion values. To the best of our knowledge, it is the first CNN-based approach to bug report prioritization. We evaluate the proposed approach on open-source projects. Results of our cross-project evaluation suggest that the proposed approach significantly outperforms the state-of-the-art approaches and improves the average F1-score by more than 24%.","","","10.1109/TR.2019.2959624","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8946886","Bug reports;deep learning;prioritization;reliability","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Novel Method for Person Re-Identification: Conditional Translated Network based on GANs","R. Sun; W. M. Lu; Y. Zhao; J. Zhang; C. H. Kai","Key Laboratory of Knowledge Engineering with Big Data, Ministry of Education, Hefei University of Technology, Hefei 230009, China and School of Computer Science and Information Engineering, Hefei University of Technology, Hefei 230009, China and Anhui Province Key Laboratory of Industry Safety and Emergency Technology, Hefei 230009, China.; Key Laboratory of Knowledge Engineering with Big Data, Ministry of Education, Hefei University of Technology, Hefei 230009, China and School of Computer Science and Information Engineering, Hefei University of Technology, Hefei 230009, China and Anhui Province Key Laboratory of Industry Safety and Emergency Technology, Hefei 230009, China.; School of Computer Science and Information Engineering, Hefei University of Technology, Hefei 230009, China and Anhui Province Key Laboratory of Industry Safety and Emergency Technology, Hefei 230009, China.; School of Computer Science and Information Engineering, Hefei University of Technology, Hefei 230009, China and Anhui Province Key Laboratory of Industry Safety and Emergency Technology, Hefei 230009, China.; School of Computer Science and Information Engineering, Hefei University of Technology, Hefei 230009, China.","IEEE Access","","2019","PP","99","1","1","The main challenge of person re-identification (re-id) lies in the strikingly discrepancy between different camera views, including illumination, background and human pose. Existing person re-id methods rely mostly on implicit solutions, such as seeking robust features or designing discriminative distance metrics. Compared to these methods, human solutions are more straightforward. That is, imagine the appearance of the target person under different camera views before matching target person. The key idea is that human can intuitively implement viewpoint transfer, noting the association of the target person under different camera views but the machine failed. In this paper, we attempt to imitate such human behavior that transfer person image to certain camera views before matching. In practice, we propose a conditional transfer network (cTransNet) that conditionally implement viewpoint transfer, which transfers image to the viewpoint with the biggest domain gap through a variant of Generative Adversarial Networks (GANs). After that, we obtain hybrid person representation by fusing the feature of original image with the transferred image then perform similarity ranking according to cosine distance. Compared with former methods, we propose a human-like approach and obtains consistent improvement of the rank-1 precision over the baseline in Market-1501, DukeMTMC-ReID and MSMT17 dataset by 3% ,4%,4%, respectively.","","","10.1109/ACCESS.2019.2962301","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8943114","Person re-identification;conditional viewpoint translation;hybrid person representation;generative adversarial network;deep learning","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"NEIST: a Neural-Enhanced Index for Spatio-Temporal Queries","S. Wu; Z. Pang; G. Chen; Y. Gao; C. Zhao; S. Xiang","College of Computer Science, Zhejiang University, Hangzhou, Zhejiang China (e-mail: wusai@zju.edu.cn); College of Computer Science, Zhejiang University, Hangzhou, Zhejiang China (e-mail: zhifeipang@zju.edu.cn); Colleague of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang China 310058 (e-mail: cg@zju.edu.cn); College of Computer Science, Zhejiang University, Hangzhou, Zhejiang China 310027 (e-mail: gaoyj@zju.edu.cn); College of Computer Science, Zhejiang University, Hangzhou, Zhejiang China (e-mail: zhcj@zju.edu.cn); Data Mining, Institute for Infocomm Research, Singapore, Singapore Singapore (e-mail: sxiang@i2r.a-star.edu.sg)","IEEE Transactions on Knowledge and Data Engineering","","2019","PP","99","1","1","Previous work on the spatial-temporal index often adopts a simple linear model to predict the future positions of moving objects, which may generate numerous errors for complex road networks and fast moving objects. In this paper, we propose NEIST, a neural-enhanced index to process spatial-temporal queries with enhanced efficiency and accuracy, by intelligently leveraging the movement patterns among moving objects. NEIST applies a Recurrent Neural Network (RNN) model to predict future positions of moving objects based on observed trajectories. To reduce the prediction overhead, a suffix-tree is further built to index trajectories with similar suffixes, and thus similar objects within a given similarity bound are grouped together to share the same prediction result. A prediction result in NEIST represents possible positions of a group of moving objects in the next t time slots. Inside each time slot, traditional linear prediction model is then adopted and a TPR-Tree is built to support spatial-temporal queries. We use Singapore taxi trajectory dataset collected over one whole month to evaluate NEIST. Compared to previous approaches, NEIST achieves a much more efficient query performance and is able to produce about 30% more accurate results.","","","10.1109/TKDE.2019.2945947","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8861025","neural networks;spatio-temporal index;deep learning;query","Trajectory;Indexes;Predictive models;Public transportation;Roads;Recurrent neural networks;Computational modeling","","","","","","","","","","IEEE","IEEE Early Access Articles"
"MarVeLScaler: A Multi-View Learning based Auto-Scaling System for MapReduce","Y. Li; F. Liu; Q. Chen; Y. Sheng; M. Zhao; J. Wang","School of Computer Science & Technology, Huazhong University of Science and Technology, 12443 Wuhan, Hubei China (e-mail: fancypluss@gmail.com); School of Computer Science & Technology, Huazhong University of Science & Technology, Wuhan, Hubei China 430074 (e-mail: fangminghk@gmail.com); School of Computer Science and Technology, Huazhong University of Science and Technology, 12443 Wuhan, Hubei China 430074 (e-mail: qiongchen1028@gmail.com); Department of Computer Science, University of Toronto, 7938 Toronto, Ontario Canada (e-mail: yibing.sheng@mail.utoronto.ca); Media Lab of US Innovation Center, Huwei Technologies, Santa Clara, California United States (e-mail: mzhao.ny@gmail.com); Computer Science, City University of Hong Kong, Kowloon, Hong Kong Hong Kong 852 (e-mail: jianwang@cityu.edu.hk)","IEEE Transactions on Cloud Computing","","2019","PP","99","1","1","To promote cloud computing from current pay-per-request model to truly pay-per-use, tenants are crying for automatic tools to auto-estimate the amount of resources for MapReduce jobs. Such tools call for accurately quantifying the relationship among workload, resources and completion time. Various prediction models have been proposed. However, none of these models takes virtual machines' (VMs) performance variance during a job's execution into consideration, leading to underestimate the required resources and exceed the job's deadline. To address this problem, we propose a multi-view deep learning model to capture real-time performance variance and automatically scale out the cloud cluster whenever necessary. We implement MarVeLScaler, a prototype system including two useful modules, namely, Scale Estimator and Scale Controller. Scale Estimator preliminarily estimates the required cluster size for a MapReduce job with given a concrete workload and deadline. During the runtime, Scale Controller adjusts the scale of the cluster according to its real-time running status to guarantee the job finished on time. We evaluate the performance of MarVeLScaler based on Hadoop in Alibaba Cloud. Experiments show that MarVeLScaler can provide 98.4% accuracy of prediction in determining initial cluster size, and save 30.8% of expense while still guaranteeing similar performance compared with the state-of-the-art methods.","","","10.1109/TCC.2019.2944916","NSFC-Guangdong Joint Fund; National Program for Support of Top-notch Young Professionals in National Program for Special Support of Eminent Professionals; National Key Research and Development Plan; National Natural Science Foundation of China; Science Technology and Innovation Committee of Shenzhen Municipality; Fundamental Research Funds for the Central Universities; Hong Kong Research Grant Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8854222","Cloud Computing;Auto-scaling;Multi-view Neural Network","Cloud computing;Computational modeling;Predictive models;Degradation;Real-time systems;Computer science;Estimation","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Vertebrae Identification and Localization Utilizing Fully Convolutional Networks and a Hidden Markov Model","Y. Chen; Y. Gao; K. Li; L. Zhao; J. Zhao","School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, 200240, China and SenseTime Research.; SenseTime Research.; Associate Professor of Orthopaedics, New Jersey Medical School, and a graduate faculty member of Computer Science and Biomedical Engineering at Rutgers, The State University of New Jersey.; SenseTime Research.; School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, 200240, China.","IEEE Transactions on Medical Imaging","","2019","PP","99","1","1","Automated identification and localization of vertebrae in spinal computed tomography (CT) imaging is a complicated hybrid task. This task requires detecting and indexing a long sequence in a three-dimensional (3-D) image, and both image feature extraction and sequence modeling are needed to address the problem. In this paper, the powerful fully convolutional neural network (FCN) technique performs both of these tasks simultaneously because FCNs directly encode and decode the spatial interdependence of different components in images. The key module of our proposed framework is a 3-D FCN trained in an end-to-end manner at the spine level to capture the long-range contextual information in CT volumes. The large increase in the calculation due to the full-size image inputs is alleviated by the scale-down of the inputs and the use of an auxiliary FCN to compensate for the loss of details. The composite network pipeline design enables the integration of local image details and global image patterns. Furthermore, explicit spatial and sequential constraints are imposed by the hidden Markov model (HMM) for a higher robustness and a clearer interpretation of network outputs. The proposed framework is quantitatively evaluated on the public dataset from the MICCAI 2014 Computational Challenge on Vertebrae Localization and Identification and demonstrates an identification rate (within 20 mm) of 94.67%, a mean identification rate of 87.97% and a mean error distance of 2.56 mm on the test set, thus achieving the highest performance reported on this dataset.","","","10.1109/TMI.2019.2927289","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8756197","Automatic vertebrae identification and localization;CT image;deep learning;convolutional neural network;fully convolutional network","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"PicSys: Energy-Efficient Fast Image Search on Distributed Mobile Networks","N. Felemban; F. Mehmeti; H. Khamfroush; Z. Lu; S. Rallapalli; K. S. Chan; T. La Porta","Computer Science and Engineering, Pennsylvania State University - Main Campus, 311285 University Park, Pennsylvania United States 16802-1800 (e-mail: noor.f222@gmail.com); Computer Science and Engineering, Pennsylvania State University, 8082 University Park, Pennsylvania United States (e-mail: fzm82@cse.psu.edu); Computer Science, University of Kentucky, Lexington, Kentucky United States (e-mail: khamfroush@cs.uky.edu); Department of Computer Science and Engineering, Pennsylvania State University, University Park, Pennsylvania United States (e-mail: zongqing.lu@pku.edu.cn); IBM Research, IBM Research, Ossining, New York United States (e-mail: srallapalli@us.ibm.com); Computational and Information Sciences Directorate, U.S. Army Research Laboratory, Adelphi, Maryland United States (e-mail: kevin.s.chan.civ@mail.mil); EIC, Transactions on Mobile Computing, Pennsylvania State University, University Park, Pennsylvania United States 16802 (e-mail: tlp@cse.psu.edu)","IEEE Transactions on Mobile Computing","","2019","PP","99","1","1","Mobile devices collect a large amount of visual data that are useful for many applications. Searching for an object of interest over a network of mobile devices can aid human analysts in a variety of situations. However, processing the information on these devices is a challenge owing to the high computational complexity of the state-of-the-art computer vision algorithms that primarily rely on Convolutional Neural Networks (CNNs). Thus, this paper builds PicSys, a system that enables answering visual search queries on a mobile network. The objective of the system is to minimize the maximum completion time over all devices while taking into account the energy consumption of mobile devices as well. First, PicSys carefully divides the computation into multiple filtering stages, such that only a small percentage of images need to run the entire CNN pipeline. Splitting such CNN computation into multiple stages requires understanding the intermediate CNN features and systematically trading off accuracy for the computation speed. Second, PicSys determines where to run each of the stages of the multi-stage pipeline to fully utilize the available resources. Finally, through extensive experimentation, system implementation, and simulation, we show that PicSys performance is close to optimal and significantly outperforms other standard algorithms.","","","10.1109/TMC.2019.2963150","Army Research Laboratory; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8946323","Distributed systems;Deep learning;Crowdsourcing;Energy","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Fusing MFCC and LPC Features using 1D Triplet CNN for Speaker Recognition in Severely Degraded Audio Signals","A. Chowdhury; A. Ross","Department of Computer Science Engineering, Michigan State University, East Lansing, MI, 48823, USA.; Department of Computer Science Engineering, Michigan State University, East Lansing, MI, 48823, USA.","IEEE Transactions on Information Forensics and Security","","2019","PP","99","1","1","Speaker recognition algorithms are negatively impacted by the quality of the input speech signal. In this work, we approach the problem of speaker recognition from severely degraded audio data by judiciously combining two commonly used features: Mel Frequency Cepstral Coefficients (MFCC) and Linear Predictive Coding (LPC). Our hypothesis rests on the observation that MFCC and LPC capture two distinct aspects of speech, viz., speech perception and speech production. A carefully crafted 1D Triplet Convolutional Neural Network (1D-Triplet-CNN) is used to combine these two features in a novel manner, thereby enhancing the performance of speaker recognition in challenging scenarios. Extensive evaluation on multiple datasets, different types of audio degradations, multi-lingual speech, varying length of audio samples, etc. convey the efficacy of the proposed approach over existing speaker recognition methods, including those based on iVector and xVector.","","","10.1109/TIFS.2019.2941773","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8839817","Speaker Recognition;Degraded Audio;Deep Learning;MFCC;LPC;1-D CNN;Feature-level Fusion","Speaker recognition;Speech recognition;Noise measurement;Mel frequency cepstral coefficient;Speech processing;Feature extraction;Production","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Video Summarization with Attention-Based Encoder-Decoder Networks","Z. Ji; K. Xiong; Y. Pang; X. Li","School of Electrical and Information Engineering, Tianjin University, Tianjin 300072, China.; School of Electrical and Information Engineering, Tianjin University, Tianjin 300072, China.; School of Electrical and Information Engineering, Tianjin University, Tianjin 300072, China.; School of Computer Science and Center for OPTical IMagery Analysis and Learning, Northwestern Polytechnical University, Xi?an 710072, China.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","This paper addresses the problem of supervised video summarization by formulating it as a sequence-to-sequence learning problem, where the input is a sequence of original video frames, the output is a keyshot sequence. Our key idea is to learn a deep summarization network with attention mechanism to mimic the way of selecting the keyshots of human. To this end, we propose a novel video summarization framework named Attentive encoder-decoder networks for Video Summarization (AVS), in which the encoder uses a Bidirectional Long Short-Term Memory (BiLSTM) to encode the contextual information among the input video frames. As for the decoder, two attention-based LSTM networks are explored by using additive and multiplicative objective functions, respectively. Extensive experiments are conducted on two video summarization benchmark datasets, i.e., SumMe, and TVSum. The results demonstrate the superiority of the proposed AVS-based approaches against the state-of-the-art approaches, with remarkable improvements on both datasets.","","","10.1109/TCSVT.2019.2904996","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8667390","Video summarization;LSTM;encoder-decoder;attention mechanism","Decoding;Visualization;Recurrent neural networks;Additives;Indexes;Internet;Semantics","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Adaptive Neural Network Architectures for Power Aware Inference","S. Anderson; N. Challapalle; J. Sampson; V. Narayanan","School of Electrical Engineering and Computer Science, The Pennsylvania State University, State College, PA 16802 USA.; School of Electrical Engineering and Computer Science, The Pennsylvania State University, State College, PA 16802 USA.; School of Electrical Engineering and Computer Science, The Pennsylvania State University, State College, PA 16802 USA.; School of Electrical Engineering and Computer Science, The Pennsylvania State University, State College, PA 16802 USA.","IEEE Design & Test","","2019","PP","99","1","1","As an increasingly diverse array of edge devices become platforms for neural networks, the power and compute limitations of these platforms become key design constraints, often imposing trade-offs among performance, accuracy, and power/energy requirements for inference tasks. Moreover, in edge deployment scenarios, dynamic variability in both the power and computation capabilities of these platforms is an equally important driver of design decisions in matching a neural network model with a given end device and deployment scenario. In this work we propose a novel method for adaptive neural network architectures to boost performance as power becomes available without necessitating a complete reconfiguration of model parameters. We show that, due to the stochastic nature of neural networks, models can be constructed with enough independence to be effectively ensembled while sharing a common convolutional base. This allows for a trade-off between power consumption and model accuracy without redeploying an entirely new model. Our method is agnostic to the base network and can be added to existing networks with minimal retraining. We find this approach particularly well suited for IoT devices and distributed autonomous applications where available power and compute resources are time varying.","","","10.1109/MDAT.2019.2947258","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8868173","Neural Networks;Deep Learning;Semantic Segmentation;Power Aware Architecture","Decoding;Neural networks;Adaptation models;Task analysis;Semantics;Image segmentation;Computer architecture","","","","","","","","","","IEEE","IEEE Early Access Articles"
"BioTouchPass: Handwritten Passwords for Touchscreen Biometrics","R. Tolosana; R. Vera-Rodriguez; J. Fierrez","Tecnología Electrónica y de las Comunicaciones, Universidad Autonoma de Madrid Escuela Politecnica Superior, 73053 Madrid, Madrid Spain (e-mail: ruben.tolosana@uam.es); Escuela Politecnica Superior, Universidad Autonoma de Madrid, Madrid, Madrid Spain 28049 (e-mail: ruben.vera@uam.es); Escuela Politecnica Superior, Universidad Autonoma de Madrid, Madrid, Madrid Spain 28049 (e-mail: julian.fierrez@uam.es)","IEEE Transactions on Mobile Computing","","2019","PP","99","1","1","This work enhances traditional authentication systems based on Personal Identification Numbers (PIN) and One-Time Passwords (OTP) through the incorporation of biometric information as a second level of user authentication. In our proposed approach, users draw each digit of the password on the touchscreen of the device instead of typing them as usual. A complete analysis of our proposed biometric system is carried out regarding the discriminative power of each handwritten digit and the robustness when increasing the length of the password and the number of enrolment samples. The new e-BioDigit database, which comprises on-line handwritten digits from 0 to 9, has been acquired using the finger as input on a mobile device. This database is used in the experiments reported in this work and it has been released to the research community. Finally, we discuss specific details for the deployment of our proposed approach on current PIN and OTP systems, achieving results with Equal Error Rates (EERs) ca. 4.0% when the attacker knows the password by shoulder surfing. These results encourage the deployment of our proposed approach in comparison to traditional PIN and OTP systems where the attack would have 100% success rate under the same impostor scenario.","","","10.1109/TMC.2019.2911506","Cecabank; Spanish MECD; Fundacion BBVA; MINECO; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8691794","Biometrics;passwords;PIN;OTP;handwriting;touch biometrics;mobile;deep learning;RNN;LSTM;DTW;eBioDigit database","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Learning Low-rank and Sparse Discriminative Correlation Filters for Coarse-to-Fine Visual Object Tracking","T. Xu; Z. Feng; X. Wu; J. Kittler","School of Internet of Things Engineering, Jiangnan University, Wuxi, P.R. China and with the Centre for Vision, Speech and Signal Processing, University of Surrey, Guildford, GU2 7XH, UK.; Centre for Vision, Speech and Signal Processing, University of Surrey, Guildford, GU2 7XH, UK.; School of Internet of Things Engineering, Jiangnan University, Wuxi, P.R. China.; Centre for Vision, Speech and Signal Processing, University of Surrey, Guildford, GU2 7XH, UK.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Discriminative correlation filter (DCF) has achieved advanced performance in visual object tracking with remarkable efficiency guaranteed by its implementation in the frequency domain. However, the effect of the structural relationship of DCF and object features has not been adequately explored in the context of the filter design. To remedy this deficiency, this paper proposes a Low-rank and Sparse DCF (LSDCF) that improves the relevance of features used by discriminative filters. To be more specific, we extend the classical DCF paradigm from ridge regression to lasso regression, and constrain the estimate to be of low-rank across frames, thus identifying and retaining the informative filters distributed on a low-dimensional manifold. To this end, specific temporal-spatial-channel configurations are adaptively learned to achieve enhanced discrimination and interpretability. In addition, we analyse the complementary characteristics between hand-crafted features and deep features, and propose a coarse-to-fine heuristic tracking strategy to further improve the performance of our LSDCF. Last, the augmented Lagrange multiplier optimisation method is used to achieve efficient optimisation. The experimental results obtained on a number of well-known benchmarking datasets, including OTB2013, OTB50, OTB100, TC128, UAV123, VOT2016 and VOT2018, demonstrate the effectiveness and robustness of the proposed method, delivering outstanding performance compared to the state-of-the-art trackers.","","","10.1109/TCSVT.2019.2945068","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8854808","Visual object tracking;discriminative correlation filter;lasso regression","Target tracking;Visualization;Correlation;Object tracking;Neural networks;Task analysis;Feature extraction","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Time Series Classification using Fuzzy Cognitive Maps","W. Homenda; A. Jastrzebska","Faculty of Mathematics and Information Sciences, Warsaw University of Technology, 49566 Warszawa Poland (e-mail: homenda@mini.pw.edu.pl); Faculty of Mathematics and Information, Warsaw University of Technology, 49566 Warszawa Poland (e-mail: A.Jastrzebska@mini.pw.edu.pl)","IEEE Transactions on Fuzzy Systems","","2019","PP","99","1","1","The article presents a time series classification method based on Fuzzy Cognitive Maps. We advocate that Fuzzy Cognitive Maps provide a sound representation of time series and we can construct a classification mechanism based on them. The classifier has to distinguish maps constructed for time series belonging to different classes. The proposed classification procedure evaluates similarity of Fuzzy Cognitive Maps and it is done by comparing weight matrices based on the same set of concepts. A weight matrix describes relationships between concepts in a map. Concepts represent the underlying data, because they are extracted via a data-driven clustering procedure. Each data point of a time series is related to each concept and we evaluate the strength of relationships with a membership function. The paper investigates performance of the proposed approach on a suite of real-world data sets. We compare classification accuracy of our method with 37 state- of-the-art time series classification methods. Experiments show, that the proposed method is performing well. In many cases it is better than its competitors. Each data point of a time series is related to each concept and we evaluate the strength of relationships with a membership function. In the paper, we investigate performance of the proposed approach on a suite of real-world data sets. We compare classification accuracy of our method with 37 state-of-the-art time series classification methods. Experiments show, that the proposed method is performing well. In many cases, it is better than its competitors.","","","10.1109/TFUZZ.2019.2917126","H2020 Industrial Leadership; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8715465","Fuzzy Cognitive Maps;time series classification;fuzzy models;deep learning","Time series analysis;Fuzzy cognitive maps;Computational modeling;Standards;Feature extraction;Biological system modeling;Task analysis","","","","","","","","","","IEEE","IEEE Early Access Articles"
"PGA-Net: Pyramid Feature Fusion and Global Context Attention Network for Automated Surface Defect Detection","H. Dong; K. Song; Y. He; J. Xu; Y. Yan; Q. Meng","School of Mechanical Engineering & Automation, Northeastern University, 12434 Shenyang, Liaoning China 110819 (e-mail: donghongwenliran@163.com); Northeastern Univ, shenyang China 110819 (e-mail: songkc@me.neu.edu.cn); Shenyang China 110819 (e-mail: heyu142616@gmail.com); School of Mechanical Engineering and Automation, Shenyang, Liaoning China 110819 (e-mail: jing_xu@yeah.net); Northeastern University, 12434 Shenyang, Liaoning China 110819 (e-mail: yanyh@mail.neu.edu.cn); Computer Science, Loughborough University, Loughborough United Kingdom of Great Britain and Northern Ireland LE11 3TH (e-mail: q.meng@lboro.ac.uk)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","Surface defect detection is a critical task in industrial production process. Nowadays, there are lots of detection methods based on computer vision and have been successfully applied in industry, they also achieved good results. However, achieving full automation of surface defect detection remains a challenge, due to the complexity of surface defect, in intra-class, while the defects between inter-class contain similar parts, there are large differences in appearance of the defects. To address these issues, this paper proposes a pyramid feature fusion and global context attention network for pixel-wise detection of surface defect, called PGA-Net. In the framework, the multi-scale features are extracted at first from backbone network. Then the pyramid feature fusion module is used to fuse these features into five resolutions through some efficient dense skip connections. Finally, the global context attention module is applied to the fusion feature maps of adjacent resolution, which allows effective information propagate from low-resolution fusion feature maps to high-resolution fusion ones. In addition, the boundary refinement block is added to the framework to refine the boundary of defect and improve the result of predict. The final prediction is the fusion of the five resolutions fusion feature maps. The results of evaluation on four real-world defect datasets demonstrate that the proposed method outperforms the state-of-the-art methods on mean Intersection of Union and mean Pixel Accuracy (NEU-Seg: 82.15%, DAGM 2007: 74.78%, MT_defect: 71.31%, Road_defect: 79.54%).","","","10.1109/TII.2019.2958826","National Natural Science Foundation of China; National Basic Research Program of China (973 Program); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8930292","Surface defect detection;deep learning;deeply-supervised;pyramid feature fusion;global context attention;boundary refinement","Feature extraction;Production;Convolution;Computational modeling;Inspection;Fuses;Data mining","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Skin Lesion Classification Using CNNs with Patch-Based Attention and Diagnosis-Guided Loss Weighting","N. Gessert; T. Sentker; F. Madesta; R. Schmitz; H. Kniep; I. Baltruschat; R. Werner; A. Schlaefer","Institute of Medical Technology, Technische Universitat Hamburg-Harburg, 38987 Hamburg, Hamburg Germany 21073 (e-mail: nils.gessert@tuhh.de); University Medical Center Hamburg-Eppendorf, Hamburg, Hamburg Germany (e-mail: t.sentker@uke.de); Institute of Computational Neuroscience, University Medical Center Hamburg-Eppendorf, Hamburg, Hamburg Germany (e-mail: f.madesta@uke.de); Department of Interdisciplinary Endoscopy and Institute of Anatomy, University Medical Center Hamburg-Eppendorf, Hamburg, Hamburg Germany (e-mail: r.schmitz@uke.de); Department of Diagnostic and Interventional Neuroradiology, University Medical Center Hamburg-Eppendorf, Hamburg, Hamburg Germany (e-mail: h.kniep@uke.de); Institute for Biomedical Imaging, Technische Universitat Hamburg-Harburg, 38987 Hamburg, Hamburg Germany (e-mail: ivo-matteo.baltruschat@tuhh.de); Department of Computational Neuroscience, Universitätsklinikum Hamburg Eppendorf, Hmaburg, Hamburg Germany (e-mail: r.werner@uke.de); Institute of Medical Technology, Technische Universitat Hamburg-Harburg, 38987 Hamburg, Hamburg Germany (e-mail: schlaefer@tuhh.de)","IEEE Transactions on Biomedical Engineering","","2019","PP","99","1","1","Objective: This work addresses two key problems of skin lesion classification. The first problem is the effective use of high-resolution images with pretrained standard architectures for image classification. The second problem is the high class imbalance encountered in real-world multi-class datasets. Methods: To use high-resolution images, we propose a novel patch-based attention architecture that provides global context between small, high-resolution patches. We modify three pretrained architectures and study the performance of patch-based attention. To counter class imbalance problems, we compare oversampling, balanced batch sampling, and class-specific loss weighting. Additionally, we propose a novel diagnosis-guided loss weighting method which takes the method used for ground-truth annotation into account. Results: Our patch-based attention mechanism outperforms previous methods and improves the mean sensitivity by 7%. Class balancing significantly improves the mean sensitivity and we show that our diagnosis-guided loss weighting method improves the mean sensitivity by 3% over normal loss balancing. Conclusion: The novel patch-based attention mechanism can be integrated into pretrained architectures and provides global context between local patches while outperforming other patch-based methods. Hence, pretrained architectures can be readily used with high resolution images without downsampling. The new diagnosis-guided loss weighting method outperforms other methods and allows for effective training when facing class imbalance. Significance: The proposed methods improve automatic skin lesion classification. They can be extended to other clinical applications where high-resolution image data and class imbalance are relevant.","","","10.1109/TBME.2019.2915839","Forschungszentrum Medizintechnik Hamburg; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8710336","Skin Lesion Classification;Deep Learning;Attention;Dermoscopy","Lesions;Skin;Computer architecture;Medical diagnostic imaging;Image resolution;Sensitivity","","","","1","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Unsupervised Domain Adaptation via Importance Sampling","X. Xu; H. He; H. Zhang; Y. Xu; S. He","School of Computer Science and Engineering, South China University of Technology and Guangdong Provincial Key Lab of Computational Intelligence and Cyberspace Information, Guangdong, China.; School of Computer Science and Engineering, South China University of Technology, Guangzhou 510006, China.; School of Computer Science and Engineering, South China University of Technology, Guangzhou 510006, China.; School of Computer Science and Engineering, South China University of Technology, Guangzhou 510006, China.; School of Computer Science and Engineering, South China University of Technology, Guangzhou 510006, China.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Unsupervised domain adaptation aims to generalize a model from the label-rich source domain to the unlabeled target domain. Existing works mainly focus on aligning the global distribution statistics between source and target domains. However, they neglect distractions from the unexpected noisy samples in domain distribution estimation, leading to domain misalignment or even negative transfer. In this paper, we present an importance sampling method for domain adaptation (ISDA), to measure sample contributions according to their “informative” levels. In particular, informative samples, as well as outliers, can be effectively modeled using feature-norm and prediction entropy of the network. The importance of information is further formulated as the importance sampling losses in features and label spaces. In this way, the proposed model mitigates the noisy outliers while enhancing the important samples during domain alignment. In addition, our model is easy to implement yet effective, and it does not introduce any extra parameters. Extensive experiments on several benchmark datasets show that our method outperforms state-of-the-art methods under both the standard and partial domain adaptation settings.","","","10.1109/TCSVT.2019.2963318","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8946732","Domain adaptation;deep learning;distribution sampling","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Convolutional Networks with Dense Connectivity","G. Huang; Z. Liu; G. Pleiss; L. Van Der Maaten; K. Weinberger","Department of Automation, Tsinghua University, 12442 Beijing, Beijing China (e-mail: gaohuang@tsinghua.edu.cn); EECS, University of California Berkeley, 1438 Berkeley, California United States (e-mail: zhuangl@berkeley.edu); Department of Computer Science, Cornell University, 5922 Ithaca, New York United States (e-mail: geoff@cs.cornell.edu); Facebook AI Research, New York, New York United States (e-mail: lvdmaaten@fb.com); Department of Computer Science, Cornell University, 5922 Ithaca, New York United States (e-mail: kqw4@cornell.edu)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Recent work has shown that convolutional networks can be substantially deeper, more accurate, and efficient to train if they contain shorter connections between layers close to the input and those close to the output. In this paper, we embrace this observation and introduce the Dense Convolutional Network (DenseNet), which connects each layer to every other layer in a feed-forward fashion. Whereas traditional convolutional networks with L layers have L connections -- one between each layer and its subsequent layer -- our network has $\frac{L(L+1)}{2}$ direct connections. For each layer, the feature-maps of all preceding layers are used as inputs, and its own feature-maps are used as inputs into all subsequent layers. DenseNets have several compelling advantages: they alleviate the vanishing-gradient problem, strengthen feature propagation, encourage feature reuse, and substantially improve parameter efficiency. We evaluate our proposed architecture on four highly competitive object recognition benchmark tasks (CIFAR-10, CIFAR-100, SVHN, and ImageNet). DenseNets obtain significant improvements over the state-of-the-art on most of them, whilst requiring less parameters and computation to achieve high performance.","","","10.1109/TPAMI.2019.2918284","Office of Naval Research; Bill and Melinda Gates Foundation; SAP Inc. America; NSF TRIPODS Award; National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8721151","Convolutional neural network;deep learning;image classification","Convolution;Training;Computer architecture;Neural networks;Benchmark testing;Network architecture;Task analysis","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Review Semantic Generation for Rating Prediction","R. Cao; X. Zhang; H. Wang","School of Computer Science and Engineering, South China University of Technology, Guangzhou, 510006 China.; School of Computer Science and Engineering, South China University of Technology, Guangzhou, 510006 China.; School of Computer Science and Engineering, South China University of Technology, Guangzhou, 510006 China.","IEEE Access","","2019","PP","99","1","1","A review expresses the concerned aspects and corresponding assessment a customer has towards a particular item. Extracting the user’s profile and product’s property from their aggregated reviews and matching them together to predict the overall rating is a common paradigm in a review-based recommender. However such paradigm trains model on the aggregated historical review which grows with time and may have many conflicting semantic, thus the scalability and accuracy are comprised. In this paper, a novel neural network model is proposed to enhance the performance of the review-based recommender. It consists of three parts: In the first, a convolutional neural network(CNN) is used to extract the semantic features of a particular review text. Secondly, a memory-network liked structure use attention mechanism to simulate the decision-making process in which a user assesses each concerned aspect to generate the review semantic feature to approximate that extracted by CNN in the training. Third, the generated semantic feature is feed into a regression model to predict the overall rating. Experiments on a series of reality datasets show that the proposed model not only gains better performances than the state-of-art recommendation approaches in terms of accuracy and scalability but also has better interpretability.","","","10.1109/ACCESS.2019.2962075","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8941029","Recommender systems;deep learning","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Wiretap Code Design by Neural Network Autoencoders","K. Besser; P. Lin; C. R. Janda; E. A. Jorswieck","Communications Lab at Technische Universitdt Dresden, Germany and Institute of Communications Technology, Technische Universitdt Braunschweig, Germany.; Communications Lab at Technische Universitdt Dresden, Germany and Institute of Communications Technology, Technische Universitdt Braunschweig, Germany.; Communications Lab at Technische Universitdt Dresden, Germany and Institute of Communications Technology, Technische Universitdt Braunschweig, Germany.; Communications Lab at Technische Universitdt Dresden, Germany and Institute of Communications Technology, Technische Universitdt Braunschweig, Germany.","IEEE Transactions on Information Forensics and Security","","2019","PP","99","1","1","In industrial machine type communications, an increasing number of wireless devices communicate under reliability, latency, and confidentiality constraints, simultaneously. From information theory, it is known that wiretap codes can asymptotically achieve reliability (vanishing block error rate (BLER) at the legitimate receiver Bob) while also achieving secrecy (vanishing information leakage (IL) to an eavesdropper Eve). However, under finite block length, there exists a tradeoff between the BLER at Bob and the IL at Eve. In this work, we propose a flexible wiretap code design for degraded Gaussian wiretap channels under finite block length, which can change the operating point on the Pareto boundary of the tradeoff between BLER and IL given specific code parameters. To attain this goal, we formulate a multi-objective programming problem, which takes the BLER at Bob and the IL at Eve into account. We approximate the BLER by the mean square error and the IL by schemes based on Jensen’s inequality and the Taylor expansion and then solve the optimization problem by neural network autoencoders. Simulation results show that the proposed scheme can find codes outperforming polar wiretap codes with respect to both BLER and IL simultaneously. We show that the codes found by the autoencoders could be implemented with real modulation schemes with only small losses in performance.","","","10.1109/TIFS.2019.2945619","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8859269","physical layer security;wiretap codes;deep learning;autoencoders","Reliability;Computational modeling;Decoding;Artificial neural networks;Mutual information;Neurons","","","","","","","","","","IEEE","IEEE Early Access Articles"
"D-UNet: a dimension-fusion U shape network for chronic stroke lesion segmentation","Y. Zhou; W. Huang; P. Dong; Y. Xia; S. Wang","Shenzhen University, 47890 Shenzhen, Guangdong China (e-mail: yjzhou@szu.edu.cn); Biomedical Engineering, Shenzhen University, 47890 Shenzhen, Guangdong Province China 518060 (e-mail: 2170249218@email.szu.edu.cn); AI healthcare, Tencent, 508929 Shenzhen, Guangdong China (e-mail: dongpei_3203@hotmail.com); School of Computer Science, Northwestern Polytechnical University, 26487 Xi'an, Shaanxi China 710072 (e-mail: yxia@nwpu.edu.cn); Shenzhen Institutes of Advanced Technology, 85411 Shenzhen, Guangdong China (e-mail: sophiasswang@hotmail.com)","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2019","PP","99","1","1","Assessing the location and extent of lesions caused by chronic stroke is critical for medical diagnosis, surgical planning, and prognosis. In recent years, with the rapid development of 2D and 3D convolutional neural networks (CNN), the encoder-decoder structure has shown great potential in the field of medical image segmentation. However, the 2D CNN ignores the 3D information of medical images, while the 3D CNN suffers from high computational resource demands. This paper proposes a new architecture called dimension-fusion-UNet (D-UNet), which combines 2D and 3D convolution innovatively in the encoding stage. The proposed architecture achieves a better segmentation performance than 2D networks, while requiring significantly less computation time in comparison to 3D networks. Furthermore, to alleviate the data imbalance issue between positive and negative samples for the network training, we propose a new loss function called Enhance Mixing Loss (EML). This function adds a weighted focal coefficient and combines two traditional loss functions. The proposed method has been tested on the ATLAS dataset and compared to three state-of-the-art methods. The results demonstrate that the proposed method achieves the best quality performance in terms of $\mathrm{DSC} = 0.5349 \pm 0.2763$ and $\mathrm{precision} = 0.6331 \pm 0.295$).","","","10.1109/TCBB.2019.2939522","Youth Innovation Promotion Association Program of Chinese Academy of Sciences; National Natural Science Foundation of China; Basic Research Program of Shenzhen; Science and Technology Planning Project of Guangdong Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8826241","MRI;stroke segmentation;deep learning;dimensional fusion","Three-dimensional displays;Two dimensional displays;Lesions;Magnetic resonance imaging;Image segmentation;Feature extraction;Propagation losses","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Memristive LSTM Network for Sentiment Analysis","S. Wen; H. Wei; Y. Yang; Z. Guo; Z. Zeng; T. Huang; Y. Chen","School of Automation, Huazhong University of Science and Technology, Wuhan 430074, China, and also with the Key Laboratory of Image Processing and Intelligent Control of Education, Ministry of China, Huazhong University of Science and Technology, Wuhan 430074, China (e-mail: wenshiping226@hust.edu.cn).; School of Automation, Huazhong University of Science and Technology, Wuhan 430074, China, and also with the Key Laboratory of Image Processing and Intelligent Control of Education, Ministry of China, Huazhong University of Science and Technology, Wuhan 430074, China.; College of Science, Engineering and Technology, Hamad Bin Khalifa University, Doha, Qatar.; College of Mathematics and Econometrics, Hunan University, Changsha 410082, China.; School of Automation, Huazhong University of Science and Technology, Wuhan 430074, China, and also with the Key Laboratory of Image Processing and Intelligent Control of Education, Ministry of China, Huazhong University of Science and Technology, Wuhan 430074, China.; Science Program, Texas A&M University at Qatar, Doha, Qatar.; Department of Electrical and Computer Engineering, Duke University, Durham, NC 27708 USA.","IEEE Transactions on Systems, Man, and Cybernetics: Systems","","2019","PP","99","1","11","This paper presents a complete solution for the hardware design of a memristor-based long short-term memory (MLSTM) network. Throughout the design process, we fully consider the external and internal structures of the long short-term memory (LSTM), both of which are efficiently implemented by memristor crossbars. In the specific design of the internal structure, the parameter sharing mechanism is used between the LSTM cells to minimize the hardware design scale. In particular, we designed a circuit that requires only one memristor crossbar for each unit in the LSTM cell. The activation function, including sigmoid and tanh (hyperbolic tangent function), involved in each unit is approximated by a piecewise function, which is designed with the corresponding hardware. To verify the effectiveness of the system we designed, we test it on IMDB and SemEval datasets. Considering the huge impact of the dimensions of the input data on the scale of the hardware design, we use word2vector instead of one-hot encoding for the input data encoding. With the parameter sharing mechanism, the transformed vectors are input in different periods, so only 65 memristive crossbars are needed in the entire system to complete the sentiment analysis of the input text. The experimental results verify the effectiveness of our proposed MLSTM system.","","","10.1109/TSMC.2019.2906098","National Natural Science Foundation of China; National Priorities Research Program NPRP through the Qatar National Research Fund a member of Qatar Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8692753","Deep learning;long short-term memory (LSTM);memristor;sentiment analysis","Hardware;Memristors;Neural networks;Sentiment analysis;Task analysis;Training;Image coding","","","","3","","","","","","IEEE","IEEE Early Access Articles"
"AVDNet: A Small-Sized Vehicle Detection Network for Aerial Visual Data","M. Mandal; M. Shah; P. Meena; S. Devi; S. K. Vipparthi","Vision Intelligence Lab, Department of Computer Science and Engineering, Malaviya National Institute of Technology, Jaipur 302017, India; Vision Intelligence Lab, Department of Computer Science and Engineering, Malaviya National Institute of Technology, Jaipur 302017, India; Vision Intelligence Lab, Department of Computer Science and Engineering, Malaviya National Institute of Technology, Jaipur 302017, India; Vision Intelligence Lab, Department of Computer Science and Engineering, Malaviya National Institute of Technology, Jaipur 302017, India; Vision Intelligence Lab, Department of Computer Science and Engineering, Malaviya National Institute of Technology, Jaipur 302017, India (e-mail: skvipparthi@mnit.ac.in).","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","Detection of small-sized targets in aerial views is a challenging task due to the smallness of vehicle size, complex background, and monotonic object appearances. In this letter, we propose a one-stage vehicle detection network (AVDNet) to robustly detect small-sized vehicles in aerial scenes. In AVDNet, we introduced ConvRes residual blocks at multiple scales to alleviate the problem of vanishing features for smaller objects caused because of the inclusion of deeper convolutional layers. These residual blocks, along with enlarged output feature map, ensure the robust representation of the salient features for small-sized objects. Furthermore, we proposed a recurrent-feature aware visualization (RFAV) technique to analyze the network behavior. We also created a new airborne image data set (ABD) by annotating 1396 new objects in 79 aerial images for our experiments. The effectiveness of AVDNet is validated on VEDAI, DLR-3K, DOTA, and the combined (VEDAI, DLR-3K, DOTA, and ABD) data set. Experimental results demonstrate the significant performance improvement of the proposed method over state-of-the-art detection techniques in terms of mAP, computation, and space complexity.","","","10.1109/LGRS.2019.2923564","Department of Science and Technology Goverment of India through the Science and Engineering Research Board; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8755462","Aerial scenes;automatic target detection;deep learning;remote sensing;residual features;vehicle detection.","Feature extraction;Vehicle detection;Detectors;Object detection;Visualization;Computer architecture;Histograms","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Visual Analytics System for Exploring, Monitoring, and Forecasting Road Traffic Congestion","C. Lee; Y. Kim; S. M. Jin; D. Kim; R. Maciejewski; D. Ebert; S. Ko","Electrical & Computer Engineering, Ulsan National Institute of Science and Technology, 131639 Ulgu, Ulsan Korea (the Republic of) 44919 (e-mail: cglee@unist.ac.kr); Computer Engineering, Ulsan National Institute of Science and Technology, 131639 Ulsan, Ulsan Korea (the Republic of) 44919 (e-mail: yeonjunkim@unist.ac.kr); Business and Management, Nacional'nyj issledovatel'skij universitet Vyssaa skola ekonomiki, 68192 Moskva, Moskva Russian Federation 101000 (e-mail: dryjins@gmail.com); Computer Engineering, Ulsan National Institute of Science and Technology, 131639 Ulsan, Ulsan Korea (the Republic of) 44919 (e-mail: rocky112358@unist.ac.kr); Electrical and Computer Engineering, Purdue University, West Lafayette, Indiana United States 47906 (e-mail: rmacieje@asu.edu); School of ECE, Purdue University, west lafayette, Indiana United States 47906 (e-mail: ebertd@purdue.edu); Computer Engineering, Ulsan National Institute of Science and Technology, 131639 Ulsan, Ulsan Korea (the Republic of) 44919 (e-mail: sako@unist.ac.kr)","IEEE Transactions on Visualization and Computer Graphics","","2019","PP","99","1","1","We present an interactive visual analytics system that enables traffic congestion exploration, surveillance, and forecasting based on vehicle detector data. Through domain expert collaboration, we have extracted task requirements, incorporated the Long Short-Term Memory (LSTM) model for congestion forecasting, and designed a weighting method for detecting the causes of congestion and congestion propagation directions. Our visual analytics system is designed to enable users to explore congestion causes, directions, and severity. Congestion conditions of a city are visualized using a Volume-Speed Rivers (VSRivers) visualization that simultaneously presents traffic volumes and speeds. To evaluate our system, we report performance comparison results, wherein our model is more accurate than other forecasting algorithms. We demonstrate the usefulness of our system in the traffic management and congestion broadcasting domains through three case studies and domain expert feedback","","","10.1109/TVCG.2019.2922597","National Research Foundation of Korea; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8735916","Traffic;Road;Congestion;Visualization;Deep Learning;LSTM;Surveillance;Forecasting;Predictive Analysis","Roads;Forecasting;Data visualization;Surveillance;Task analysis;Urban areas","","","","","","","","","","IEEE","IEEE Early Access Articles"
"An Underwater Image Enhancement Benchmark Dataset and Beyond","C. Li; C. Guo; W. Ren; R. Cong; J. Hou; S. Kwong; D. Tao","Department of Computer Science, City University of Hong Kong, Kowloon 999077, Hong Kong SAR, China, and also with State Key Laboratory of Information Security, Institute of Information Engineering, Chinese Academy of Sciences, China.; School of Electrical and Information Engineering, Tianjin University, Tianjin, China.; State Key Laboratory of Information Security, Institute of Information Engineering, Chinese Academy of Sciences, China.; Institute of Information Science, Beijing Jiaotong University, Beijing 100044, China, and also with the Beijing Key Laboratory of Advanced Information Science and Network Technology, Beijing Jiaotong University, Beijing 100044, China.; Department of Computer Science, City University of Hong Kong, Kowloon 999077, Hong Kong SAR, China, and also with the City University of Hong Kong Shenzhen Research Institute, Shenzhen 51800, China.; Department of Computer Science, City University of Hong Kong, Kowloon 999077, Hong Kong SAR, China, and also with the City University of Hong Kong Shenzhen Research Institute, Shenzhen 51800, China.; UBTECH Sydney Artificial Intelligence Centre and the School of Information Technologies, the Faculty of Engineering and Information Technologies, the University of Sydney, 6 Cleveland St, Darlington, NSW 2008, Australia.","IEEE Transactions on Image Processing","","2019","PP","99","1","1","Underwater image enhancement has been attracting much attention due to its significance in marine engineering and aquatic robotics. Numerous underwater image enhancement algorithms have been proposed in the last few years. However, these algorithms are mainly evaluated using either synthetic datasets or few selected real-world images. It is thus unclear how these algorithms would perform on images acquired in the wild and how we could gauge the progress in the field. To bridge this gap, we present the first comprehensive perceptual study and analysis of underwater image enhancement using large-scale real-world images. In this paper, we construct an Underwater Image Enhancement Benchmark (UIEB) including 950 real-world underwater images, 890 of which have the corresponding reference images. We treat the rest 60 underwater images which cannot obtain satisfactory reference images as challenging data. Using this dataset, we conduct a comprehensive study of the state-of-the-art underwater image enhancement algorithms qualitatively and quantitatively. In addition, we propose an underwater image enhancement network (called Water-Net) trained on this benchmark as a baseline, which indicates the generalization of the proposed UIEB for training Convolutional Neural Networks (CNNs). The benchmark evaluations and the proposed Water-Net demonstrate the performance and limitations of state-of-the-art algorithms, which shed light on future research in underwater image enhancement. The dataset and code are available at.","","","10.1109/TIP.2019.2955241","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8917818","underwater image enhancement;real-world underwater images;comprehensive evaluation;deep learning","Image enhancement;Image color analysis;Benchmark testing;Image restoration;Electronic mail;Gallium nitride;Training","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"IFR-Net: Iterative Feature Refinement Network for Compressed Sensing MRI","Y. Liu; Q. Liu; M. Zhang; Q. Yang; S. Wang; D. Liang","Department of Electronic Information Engineering, Nanchang University, Nanchang, jiangxi China (e-mail: liuyiling@email.ncu.edu.cn); Department of Electrical and Computer Engineering, University of Calgary, 2129 Calgary, Alberta Canada T2N 1N4 (e-mail: liuqiegen@ncu.edu.cn); Department of Electronic Information Engineering, Nanchang University - Qianhu Campus, 47861 Nanchang China 330031 (e-mail: 641586077@qq.com); Nanchang China (e-mail: QingxinYang@email.ncu.edu.cn); Chinese Academy of Sciences, Paul C Lauterbur research center, Shenzhen China 518055 (e-mail: sophiasswang@hotmail.com); Paul C. Lauterbur Research Centre for Biomedical Imaging, Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen China 518055 (e-mail: dong.liang@siat.ac.cn)","IEEE Transactions on Computational Imaging","","2019","PP","99","1","1","To improve the compressive sensing MRI (CS-MRI) ap-proaches in terms of fine structure loss under high acceler-ation factors, we have proposed an iterative feature re-finement model (IFR-CS), equipped with fixed transforms, to restore the meaningful structures and details. Neverthe-less, the proposed IFR-CS still has some limitations, such as the selection of hyper-parameters, a lengthy reconstruction time, and the fixed sparsifying transform. To alleviate these issues, we unroll the iterative feature refinement pro-cedures in IFR-CS to a supervised model-driven network, dubbed IFR-Net. Equipped with training data pairs, both regularization parameter and the utmost feature refine-ment operator in IFR-CS become trainable. Additionally, inspired by the powerful representation capability of con-volutional neural network (CNN), CNN-based inversion blocks are explored in the sparsity-promoting denoising module to generalize the sparsity-enforcing operator. Ex-tensive experiments on both simulated and in vivo MR da-tasets have shown that the proposed network possesses a strong capability to capture image details and preserve well the structural information with fast reconstruction speed.","","","10.1109/TCI.2019.2956877","National Natural Science Foundation of China; Basic Research Program of Shenzhen; Innovation project for graduate students of nanchang university; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8918016","Compressed Sensing;undersampled image reconstruction;IFR-CS;deep learning;model-driven net-work","Transforms;Image reconstruction;Iterative methods;Image restoration;Biomedical imaging;Noise reduction","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Automated assessment of oral diadochokinesis in multiple sclerosis using a neural network approach: effect of different syllable repetition paradigms","K. Rozenstoks; M. Novotny; D. Horakova; J. Rusz","Department of Circuit Theory, Faculty of Electrical Engineering, Czech Technical University in Prague, Technická 2, 160 00 Prague 6, Czech Republic and also with the Institute of Biomedical Engineering and Nanotechnologies, Riga Technical University, P. Valdena 3/7, Riga, LV-1048, Latvia.; Department of Circuit Theory, Faculty of Electrical Engineering, Czech Technical University in Prague, Technická 2, 160 00 Prague 6, Czech Republic.; Department of Neurology and Centre of Clinical Neuroscience, First Faculty of Medicine, Charles University, Kateřinská 30, 120 00, Prague 2, Czech Republic.; Department of Circuit Theory, Faculty of Electrical Engineering, Czech Technical University in Prague, Technická 2, 160 00 Prague 6, Czech Republic and also with the Department of Neurology and Centre of Clinical Neuroscience, First Faculty of Medicine, Charles University, Kateřinská 30, 120 00, Prague 2, Czech Republic.","IEEE Transactions on Neural Systems and Rehabilitation Engineering","","2019","PP","99","1","1","Slow and irregular oral diadochokinesis represents an important manifestation of spastic and ataxic dysarthria in multiple sclerosis (MS). We aimed to develop a robust algorithm based on convolutional neural networks for the accurate detection of syllables from different types of alternating motion rate (AMR) and sequential motion rate (SMR) paradigms. Subsequently, we explored the sensitivity of AMR and SMR paradigms based on voiceless and voiced consonants in the detection of speech impairment. The four types of syllable repetition paradigms including /ta/, /da/, /pa/-/ta/-/ka/, and /ba/-/da/-/ga/ were collected from 120 MS patients and 60 matched healthy control speakers. Our neural network algorithm was able to correctly identify the position of individual syllables with a very high average accuracy of 97.8 %, with the correct temporal detection of syllable position of 87.8 % for 10 ms and 95.5 % for 20 ms tolerance value. We found significantly altered diadochokinetic rate and regularity in MS compared to controls across all types of investigated tasks (p < 0.001). MS patients showed slower speech for SMR compared to AMR tasks, whereas voiced paradigms were more irregular. Objective evaluation of oral diadochokinesis using different AMR and SMR paradigms may provide important information regarding speech severity and pathophysiology of the underlying disease.","","","10.1109/TNSRE.2019.2943064","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8846717","Cerebellar;dysarthria;speech disorder;acoustic;deep learning","Task analysis;Signal processing algorithms;Multiple sclerosis;Monitoring;Circuit theory;Electrical engineering","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"A Robust Approach for Securing Audio Classification Against Adversarial Attacks","M. Esmaeilpour; P. Cardinal; A. L. Koerich","Department of Software and IT Engineering, École de Technologie Supérieure (ÉTS), University of Quebec, Montreal, QC, Canada.; Department of Software and IT Engineering, École de Technologie Supérieure (ÉTS), University of Quebec, Montreal, QC, Canada.; Department of Software and IT Engineering, École de Technologie Supérieure (ÉTS), University of Quebec, Montreal, QC, Canada.","IEEE Transactions on Information Forensics and Security","","2019","PP","99","1","1","Adversarial audio attacks can be considered as a small perturbation unperceptive to human ears that is intentionally added to an audio signal and causes a machine learning model to make mistakes. This poses a security concern about the safety of machine learning models since the adversarial attacks can fool such models toward the wrong predictions. In this paper we first review some strong adversarial attacks that may affect both audio signals and their 2D representations and evaluate the resiliency of deep learning models and support vector machines (SVM) trained on 2D audio representations such as short time Fourier transform, discrete wavelet transform (DWT) and cross recurrent plot against several state-of-the-art adversarial attacks. Next, we propose a novel approach based on pre-processed DWT representation of audio signals and SVM to secure audio systems against adversarial attacks. The proposed architecture has several preprocessing modules for generating and enhancing spectrograms including dimension reduction and smoothing. We extract features from small patches of the spectrograms using the speeded up robust feature (SURF) algorithm which are further used to transform into cluster distance distribution using the K-Means++ algorithm. Finally, SURF-generated vectors are encoded by this codebook and the resulting codewords are used for training a SVM. All these steps yield to a novel approach for audio classification that provides a good tradeoff between accuracy and resilience. Experimental results on three environmental sound datasets show the competitive performance of the proposed approach compared to the deep neural networks both in terms of accuracy and robustness against strong adversarial attacks.","","","10.1109/TIFS.2019.2956591","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8922608","Spectrograms;Environmental Sound Classification;Adversarial Attack;K-Means++;Support Vector Machines (SVM);Convolutional Denoising Autoencoder","Support vector machines;Machine learning;Robustness;Perturbation methods;Predictive models;Optimization;Two dimensional displays","","","","","","","","","","IEEE","IEEE Early Access Articles"
"CNF+CT: Context Network Fusion of Cascade Trained Convolutional Neural Networks for Image Super-Resolution","H. Ren; M. El-Khamy; J. Lee","Samsung Semiconductor Inc, 140825 San Diego, California United States (e-mail: haoyu.ren@samsung.com); Samsung Semiconductor Inc USA, 497541 San Diego, California United States (e-mail: mostafa.e@samsung.com); Samsung Semiconductor Inc USA, 497541 San Diego, California United States (e-mail: jungwon2.lee@samsung.com)","IEEE Transactions on Computational Imaging","","2019","PP","99","1","1","A novel cascade learning framework to incrementally train deeper and more accurate convolutional neural networks is introduced. The proposed cascade learning facilitates the training of deep efficient networks with plain convolutional neural network (CNN) architectures, as well as with residual network (ResNet) architectures. This is demonstrated on the problem of image super-resolution (SR). We show that cascade-trained (CT) SR CNNs and CT-ResNets can achieve state-of-the-art results with a smaller number of network parameters. To further improve the network's efficiency, we propose a cascade trimming strategy that progressively reduces the network size, proceeding by trimming a group of layers at a time, while preserving the network's discriminative ability. We propose context network fusion (CNF) as a method to combine features from an ensemble of networks through context fusion layers. We show that CNF of an ensemble of CT SR networks can result in a network with better efficiency and accuracy than that of other fusion methods. CNF can also be trained by the proposed edge-aware loss function to obtain sharper edges and improve the perceptual image quality. Experiments on benchmark datasets show that our proposed deep convolutional networks achieve state-of-the-art accuracy and are much faster than existing deep super-resolution networks.","","","10.1109/TCI.2019.2956874","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8918046","Super-Resolution;Convolutional Neural Network;Cascade Learning;Trimming;Fusion","Training;Image resolution;Image edge detection;Computer architecture;Neural networks;Computed tomography","","","","","","","","","","IEEE","IEEE Early Access Articles"
"BS-Nets: An End-to-End Framework for Band Selection of Hyperspectral Image","Y. Cai; X. Liu; Z. Cai","School of Computer Science, China University of Geosciences, Wuhan 430074, China.; School of Automation, China University of Geosciences, Wuhan 430074, China, and also with the Hubei Key Laboratory of Advanced Control and Intelligent Automation for Complex Systems, China University of Geosciences, Wuhan 430074, China (e-mail: xbliu@cug.edu.cn).; School of Computer Science, China University of Geosciences, Wuhan 430074, China, and also with the Beibu Gulf Big Data Resources Utilization Laboratory, Qinzhou University, Qinzhou 535000, China (e-mail: zhcai@cug.edu.cn).","IEEE Transactions on Geoscience and Remote Sensing","","2019","PP","99","1","16","Hyperspectral image (HSI) consists of hundreds of continuous narrowbands with high spectral correlation, which would lead to the so-called Hughes phenomenon and the high computational cost in processing. Band selection (BS) has been proven to be effective in avoiding such problems by removing redundant bands. However, many existing BS methods separately estimate the significance for every single band and cannot fully consider the nonlinear and global interaction between spectral bands. In this article, by assuming that a complete HSI band set can be reconstructed from its few informative bands, we propose a unified BS framework, BS Network (BS-Net). The framework consists of a band attention module (BAM), which aims to explicitly model the nonlinear interdependences between spectral bands, and a reconstruction network (RecNet), which is used to restore the original HSI from the learned informative bands, resulting in a flexible architecture. The resulting framework is end-to-end trainable, making it easier to train from scratch and to combine with many existing networks. We implement two versions of BS-Nets, respectively, using fully connected networks (BS-Net-FC) and convolutional neural networks (BS-Net-Conv), and extensively compare their results with popular existing BS approaches on three real hyperspectral data sets, showing that the proposed BS-Nets can accurately select informative band subset with less redundancy and outperform the competitors in terms of classification accuracy with competitive time cost.","","","10.1109/TGRS.2019.2951433","National Natural Science Foundation of China; Fundamental Research Founds for National University China University of Geosciences Wuhan China; National Nature Science Foundation of Hubei Province; Open Research Project of Hubei Key Laboratory of Intelligent Geo-Information Processing; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8907858","Attention mechanism;band selection (BS);deep neural networks (DNNs);hyperspectral image (HSI);spectral reconstruction.","Hyperspectral imaging;Image reconstruction;Neural networks;Geology;Feature extraction;Task analysis","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Multiscale Refinement Network for Water-Body Segmentation in High-Resolution Satellite Imagery","L. Duan; X. Hu","School of Remote Sensing and Information Engineering, Wuhan University, Wuhan 430079, China.; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan 430079, China (e-mail: huxy@whu.edu.cn).","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","Water-body segmentation in high-resolution satellite imagery is challenging because of the significant variations in the appearance, size, and shape of water bodies. In this letter, a novel multiscale refinement network (MSR-Net) is proposed for water-body segmentation. Similar to most learning-based methods, the MSR-Net resorts to the multiscale information for segmentation, but it improves existing networks in two ways: First, it uses the multiscale information in a new perspective. Instead of the traditional one-off manner that concatenates features and conducts segmentation on one uniform scale, the MSR-Net adopts a new multiscale refinement scheme that makes full use of the multiscale features for more accurate water-body segmentation. In addition, a novel erasing-attention module is designed for an effective feature embedding during the refinement scheme. Experiments on the Gaofen Image Data Set and the DeepGlobe Data Set demonstrate the superiority of MSR-Net when compared with the other state-of-the-art semantic segmentation methods, including U-Net, SegNet, DeepLabv3+, and ExFuse.","","","10.1109/LGRS.2019.2926412","National Key Research and Development Program of China; National Nature Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8778790","Deep convolutional neural networks (CNNs);high-resolution satellite images;semantic segmentation;water body.","Image segmentation;Satellites;Indexes;Feature extraction;Rivers;Shape;Roads","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Spatial–Spectral Relation Network for Hyperspectral Image Classification With Limited Training Samples","M. Rao; P. Tang; Z. Zhang","Aerospace Information Research Institute, Institute of Remote Sensing and Digital Earth, Chinese Academy of Sciences, Beijing 100094, China, and also with the University of Chinese Academy of Sciences, Beijing 100049, China (e-mail: raomb@radi.ac.cn).; Aerospace Information Research Institute, Institute of Remote Sensing and Digital Earth, Chinese Academy of Sciences, Beijing 100094, China (e-mail: tangping@radi.ac.cn).; Aerospace Information Research Institute, Institute of Remote Sensing and Digital Earth, Chinese Academy of Sciences, Beijing 100094, China (e-mail: zhangzheng2035@163.com).","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","","2019","PP","99","1","15","Due to the data-hungry nature of deep neural networks and the high dimensionality of hyperspectral imagery (HSI) data, the scarcity of training samples remains a significant challenge for HSI classification based on deep learning. Recently, the pairing or recombining of samples has proven to be an efficient approach to increase the amount of input training data, and accordingly, the architecture of a network trained by these samples has to be redesigned, since the input is no longer a single sample. Following this strategy, in this article, we propose a spatial–spectral relation network (SS-RN) for HSI classification with limited training samples. The SS-RN takes advantage of the relation network architecture to precisely capture the profound similarity between samples. Additionally, to make SS-RN more suitable for HSI classification, an entire three-dimensional (3-D) neighborhood instead of the isolated pixel is considered to explore both spectral and spatial information thoroughly. Multiple support samples are also selected for each class to make sure that the extracted features are stable enough to avoid the intraclass similarity and interclass dissimilarity problem of HSI. The network is composed on the basis of 3-D convolutional neural network blocks with the aim of extracting spatial–spectral features. Extensive experiments on three widely used HSI datasets demonstrate that the proposed method can achieve better classification accuracy than conventional deep learning methods with limited labeled training samples.","","","10.1109/JSTARS.2019.2957047","National Natural Science Foundation of China; Strategic Priority Research Program of the Chinese Academy of Sciences; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8937776","Few-shot learning;hyperspectral image classification;relation network (RN);small sample size;three-dimensional (3-D) convolutional neural networks","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Progressively trained convolutional neural networks for deformable image registration","K. A. J. Eppenhof; M. W. Lafarge; M. Veta; J. P. W. Pluim","Department of Biomedical Engineering, Eindhoven University of Technology, P.O. Box 513, Eindhoven 5600 MB, Netherlands.; Department of Biomedical Engineering, Eindhoven University of Technology, P.O. Box 513, Eindhoven 5600 MB, Netherlands.; Department of Biomedical Engineering, Eindhoven University of Technology, P.O. Box 513, Eindhoven 5600 MB, Netherlands.; Image Sciences Institute, University Medical Center Utrecht, P.O. Box 85500, Utrecht 3508 GA, Netherlands and Department of Biomedical Engineering, Eindhoven University of Technology, P.O. Box 513, Eindhoven 5600 MB, Netherlands.","IEEE Transactions on Medical Imaging","","2019","PP","99","1","1","Deep learning-based methods for deformable image registration are attractive alternatives to conventional registration methods because of their short registration times. However, these methods often fail to estimate larger displacements in complex deformation fields, for which a multi-resolution strategy is required. In this paper, we propose to train neural networks progressively to address this problem. Instead of training a large convolutional neural network on the registration task all at once, we initially train smaller versions of the network on lower resolution versions of the images and deformation fields. During training, we progressively expand the network with additional layers that are trained on higher resolution data. We show that this way of training allows a network to learn larger displacements without sacrificing registration accuracy and that the resulting network is less sensitive to large misregistrations compared to training the full network all at once. We generate a large number of ground truth example data by applying random synthetic transformations to a training set of images, and test the network on the problem of intrapatient lung CT registration. We analyze the learned representations in the progressively growing network to assess how the progressive learning strategy influences training. Finally, we show that a progressive training procedure leads to improved registration accuracy when learning large and complex deformations.","","","10.1109/TMI.2019.2953788","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8902170","deformable image registration;progressive training;convolutional neural networks;machine learning;lung registration","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Bidirectional Backpropagation","O. Adigun; B. Kosko","Department of Electrical and Computer Engineering, University of Southern California, Los Angeles, CA 90089 USA.; Department of Electrical and Computer Engineering, University of Southern California, Los Angeles, CA 90089 USA (e-mail: kosko@usc.edu).","IEEE Transactions on Systems, Man, and Cybernetics: Systems","","2019","PP","99","1","13","We extend backpropagation (BP) learning from ordinary unidirectional training to bidirectional training of deep multilayer neural networks. This gives a form of backward chaining or inverse inference from an observed network output to a candidate input that produced the output. The trained network learns a bidirectional mapping and can apply to some inverse problems. A bidirectional multilayer neural network can exactly represent some invertible functions. We prove that a fixed three-layer network can always exactly represent any finite permutation function and its inverse. The forward pass computes the permutation function value. The backward pass computes the inverse permutation with the same weights and hidden neurons. A joint forward-backward error function allows BP learning in both directions without overwriting learning in either direction. The learning applies to classification and regression. The algorithms do not require that the underlying sampled function has an inverse. A trained regression network tends to map an output back to the centroid of its preimage set.","","","10.1109/TSMC.2019.2916096","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8751137","Backpropagation (BP) learning;backward chaining;bidirectional associative memory;function approximation;function representation;inverse problems","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Weakly-Supervised Sparse Coding with Geometric Prior for Interactive Texture Segmentation","Y. Quan; H. Teng; T. Liu; Y. Huang","School of Computer Science and Engineering, South China University of Technology, 26467 Guangzhou, Guangdong China (e-mail: csyhquan@scut.edu.cn); School of Computer Science and Engineering, South China University of Technology, 26467 Guangzhou, Guangdong China (e-mail: huan.teng.cs@foxmail.com); School of Computer Science and Engneering, South China University of Technology, 26467 Guangzhou, Guangdong China (e-mail: alexandliutao@gmail.com); School of Science and Engneering, South China University of Technology, 26467 Guangzhou, Guangdong China 510006 (e-mail: yyfeiyanzi@gmail.com)","IEEE Signal Processing Letters","","2019","PP","99","1","1","Texture segmentation is about dividing a texture-dominant image into multiple homogeneous texture regions. The existing unsupervised approaches for texture segmentation are annotation-free but often yield unsatisfactory results. In contrast, supervised approaches such as deep learning may have better performance but require a large amount of annotated data. In this paper, we propose a user-interactive approach to win the trade-off between unsupervised approaches and supervised deep approaches. Our approach requires the user to mark one pixel in each texture region, whose label is directly propagated to its neighbor region. Such labeled data are of very small amount and even partially erroneous. To effectively exploit such weakly-labeled data, we construct a weakly-supervised sparse coding model that jointly conducts feature learning and segmentation. In addition, the geometric constraints are developed for the model to exploit the geometric prior on the local connectivity of region boundaries. The experiments on two benchmark datasets have validated the effectiveness of the proposed approach.","","","10.1109/LSP.2019.2959225","Natural Science Foundation of Guangdong Province; National Natural Science Foundation of China; China Postdoctoral Science Foundation; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8930953","Texture segmentation;sparse coding;weaklysupervised learning;geometric constraints","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Unsupervised Adversarial Domain Adaptation Network for Semantic Segmentation","W. Liu; F. Su; X. Huang","Department of Information Engineering, School of Electronics and Information Engineering, Harbin Institute of Technology, Harbin 150001, China; Department of Information Engineering, School of Electronics and Information Engineering, Harbin Institute of Technology, Harbin 150001, China (e-mail: franklin_su@hit.edu.cn).; Wuhan Engineering Science and Technology Institute, Wuhan 430019, China.","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","With the rapid development of deep learning technology, semantic segmentation methods have been widely used in remote sensing data. A pretrained semantic segmentation model usually cannot perform well when the testing images (target domain) have an obvious difference from the training data set (source domain), while a large enough labeled data set is almost impossible to be acquired for each scenario. Unsupervised domain adaptation (DA) techniques aim to transfer knowledge learned from the source domain to a totally unlabeled target domain. By reducing the domain shift, DA methods have shown the ability to improve the classification accuracy for the target domain. Hence, in this letter, we propose an unsupervised adversarial DA network that converts deep features into 2-D feature curves and reduces the discrepancy between curves from the source domain and curves from the target domain based on a conditional generative adversarial networks (cGANs) model. Our proposed DA network is able to improve the semantic labeling accuracy when we apply a pretrained semantic segmentation model to the target domain. To test the effectiveness of the proposed method, experiments are conducted on the International Society for Photogrammetry and Remote Sensing (ISPRS) 2-D Semantic Labeling data set. Results show that our proposed network is able to stably improve overall accuracy not only when the source and target domains are from the same city but with different building styles but also when the source and target domains are from different cities and acquired by different sensors. By comparing with a few state-of-the-art DA methods, we demonstrate that our proposed method achieves the best cross-domain semantic segmentation performance.","","","10.1109/LGRS.2019.2956490","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8932673","Domain adaptation (DA);generative adversarial networks (GANs);remote sensing image;semantic segmentation;transfer learning.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Adversarial Training Towards Robust Multimedia Recommender System","J. Tang; X. Du; X. He; F. Yuan; Q. Tian; T. Chua","School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, Jiangsu China (e-mail: jinhuitang@njust.edu.cn); School of Computer Science and Engineering, Chengdu University of Information Technology, 47909 Chengdu, Sichuan China (e-mail: duxy.me@gmail.com); School of Computing, National University of Singapore, Singapore, Singapore Singapore 117417 (e-mail: xiangnanhe@gmail.com); Department of Computing Science, University of Glasgow, Glasgow, Scotland United Kingdom of Great Britain and Northern Ireland (e-mail: f.yuan.1@research.gla.ac.uk); Computer Science Department, University of Texas at San Antonio, San Antonio, Texas United States (e-mail: Qi.Tian@utsa.edu); School of Computing, National University of Singapore, 37580 Singapore, Singapore Singapore (e-mail: dcscts@nus.edu.sg)","IEEE Transactions on Knowledge and Data Engineering","","2019","PP","99","1","1","With the prevalence of multimedia content on the Web, developing recommender solutions that can effectively leverage the rich signal in multimedia data is in urgent need. Owing to the success of deep neural networks in representation learning, recent advance on multimedia recommendation has largely focused on exploring deep learning methods to improve the recommendation accuracy. To date, however, there has been little effort to investigate the robustness of multimedia representation and its impact on the performance of multimedia recommendation.","","","10.1109/TKDE.2019.2893638","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8618394","Multimedia Recommendation;Adversarial Learning;Personalized Ranking;Collaborative Filtering","Perturbation methods;Predictive models;Multimedia systems;Visualization;Feature extraction;Recommender systems;Robustness","","","","","","","","","","IEEE","IEEE Early Access Articles"
"GoogLeNet based Ensemble FCNet Classifier for Focal Liver Lesion Diagnosis","L. Balagourouchetty; J. K. Pragatheeswaran; B. Pottakkat; R. G","Electronics and Communication Engineering, Manakula Vinayagar Institute of Technology, 471222 Kalitheerthalkuppam, Puducherry India (e-mail: lakshmipriyaece@pec.edu); Electronics and Communication Engineering, Pondicherry Engineering College, 232511 Pillaichavady India (e-mail: jayanthi@pec.edu); Surgical Gastroenterology, Jawaharlal Institute of Post Graduate Medical Education, 29988 Puducherry India (e-mail: bijupottakkat@gmail.com); Radio Diagnosis, Jawaharlal Institute of Post Graduate Medical Education, 29988 Puducherry India (e-mail: gramk80@gmail.com)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","Transfer learning techniques are recently preferred for the computer aided diagnosis (CAD) of variety of diseases, as it makes the classification feasible from limited training dataset. In this work, an ensemble FCNet classifier is proposed to classify hepatic lesions from the deep features extracted using GoogleNet–LReLU transfer learning approach. In the existing GoogLeNet architecture three modifications are done: ReLU activation functions in the inception modules are replaced by leaky ReLU activation function; a stack of three fully connected layers are included before the classification layer; and deep features of different level of abstraction extracted from the output of every inception layer given as classifier input in order to significantly enhance the classifier performance. The performance of the proposed classifier by the virtue of the above mentioned modifications is tested on six classes of liver CT images namely normal, hepatocellular carcinoma, hemangioma, cyst, abscess and liver metastasis. The results presented in this work demonstrate the efficacy of the proposed classifier design in achieving better classification accuracy.","","","10.1109/JBHI.2019.2942774","University Grants Commission; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8845663","Contrast Enhanced Computed Tomography;GoogLeNet;Liver Pathologies;Multi-temporal Fusion;Transfer Learning","Liver;Lesions;Feature extraction;Computed tomography;Image segmentation;Biomedical imaging;Image color analysis","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Condition Monitoring of Machines using Fused Features from EMD based Local Energy with DNN","S. Maurya; V. Singh; N. K. Verma","Indian Institute of Technology Kanpur, U.P. 208016, India.; Indian Institute of Technology Kanpur, U.P. 208016, India.; Indian Institute of Technology Kanpur, U.P. 208016, India.","IEEE Sensors Journal","","2019","PP","99","1","1","Several data-driven methods such as signal processing and machine learning exist separately to analyze non-linear and non-stationary data but their performance degrades due to insufficient information in the real-time application. In order to improve the performance, this paper proposes a novel feature extraction method using fusion of hand-crafted (low-level) features and high-level features, followed by feature extraction/selection on fused features. Local energy based hand-crafted features have been derived from Empirical Mode Decomposition, and high-level features have been extracted from the deep neural network. A method is also proposed for reduction of massive data points in the samples. The proposed scheme has studied the effect of variation in the number of extracted/selected features. The effectiveness of the proposed scheme is validated through three case studies: a) on acoustic dataset collected from the reciprocating type air compressor, b) on vibration dataset collected from deep groove ball bearing, and c) on steel plate faults dataset. The classification accuracy on acoustic dataset are obtained as high as 100.0 %, 99.78 %, and 99.78 % using the random forest, linear support vector machine, and radial basis function support vector machine respectively with 5-fold cross-validation. Similarly, on vibration dataset obtained accuracies are 100.0 %. The proposed scheme has been compared with ten conventional methods on 5-fold cross-validation. These experimental results show considerable improvement in the prediction performance of machine conditions using the proposed scheme.","","","10.1109/JSEN.2019.2927754","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8758425","sensor data;condition monitoring;empirical mode decomposition;deep neural network;feature extraction;feature-fusion;fault recognition","Feature extraction;Sensors;Neural networks;Signal processing;Training;Real-time systems;Maintenance engineering","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Nonlinear Hybrid Impedance Control for Steering Control of Rack-Mounted Electric Power Steering in Autonomous Vehicles","Y. W. Jeong; C. C. Chung; W. Kim","Department of Electrical Engineering, Hanyang University, Seoul 04763, South Korea.; Division of Electrical and Biomedical Engineering, Hanyang University, Seoul 04763, South Korea.; School of Energy Systems Engineering, Chung-Ang University, Seoul 06974, South Korea (e-mail: whkim79@cau.ac.kr).","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","10","In this paper, we present an innovative approach to steering control, based on torque overlay, for the smooth and efficient transfer of the steering control from an autonomous driving system to the driver, and to control the pinion angle of the rack-mounted electric power steering for lateral control of an autonomous vehicle. The novelty of our approach lies in the formulation of hybrid impedance control, which employs steering control for both lateral and impedance controls. The proposed method, nonlinear hybrid impedance controller, consists of desired impedance pinion angle generator and a super-twisting sliding mode controller for pinion angle tracking. The desired impedance transfer function of the driver's torque to the steering wheel angle reflects the driver's torque to the steering control. The desired impedance pinion angle is generated using the desired impedance transfer function and the desired pinion angle derived by the lateral controller. The sliding mode control method is designed, based on a super-twisting algorithm for the pinion angle, to track the desired impedance pinion angle. Consequently, without the driver's torque, the proposed method is activated as a pinion angle tracking controller for lateral control of an autonomous vehicle. Moreover, with the driver's torque, the proposed method is activated as an impedance controller.","","","10.1109/TITS.2019.2921893","Institute for Information and communications Technology Promotion IITP grant funded by the Korean Government MSIT Development of Wide Area Driving Environment Awareness and Cooperative Driving Technology which are Based on V2X Wireless Communication; Industrial Source Technology Development Program funded by the Ministry of Trade Industry and Energy MOTIE Development of Deep Learning Based Open EV Platform Technology Capable of Autonomous Driving; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8743395","Autonomous vehicles;electric power steering (EPS) system;sliding mode control.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Error Correction Regression Framework for Enhancing the Decoding Accuracies of Ear-EEG Brain-Computer Interfaces","N. Kwak; S. Lee","Department of Brain and Cognitive Engineering, Korea University, Seoul 02841, South Korea.; Department of Artificial Intelligence, Korea University, Seoul 02841, South Korea, and also with the Department of Brain and Cognitive Engineering, Korea University, Seoul 02841, South Korea (e-mail: sw.lee@korea.ac.kr).","IEEE Transactions on Cybernetics","","2019","PP","99","1","14","Ear-electroencephalography (EEG) is a promising tool for practical brain-computer interface (BCI) applications because it is more unobtrusive, comfortable, and mobile than a typical scalp-EEG system. However, an ear-EEG has a natural constraint of electrode location (e.g., limited in or around the ear) for acquiring informative brain signals sufficiently. Achieving reliable performance of ear-EEG in specific BCI paradigms that do not utilize brain signals on the temporal lobe around the ear is difficult. For example, steady-state visual evoked potentials (SSVEPs), which are mainly generated in the occipital area, have a significantly attenuated and distorted amplitude in ear-EEG. Therefore, preserving the high level of decoding accuracy is challenging and essential for SSVEP BCI based on ear-EEG. In this paper, we first investigate linear and nonlinear regression methods to increase the decoding accuracy of ear-EEG regarding SSVEP paradigm by utilizing the estimated target EEG signals on the occipital area. Then, we investigate an ensemble method to consider the prediction variability of the regression methods. Finally, we propose an error correction regression (ECR) framework to reduce the prediction errors by adding an additional nonlinear regression process (i.e., kernel ridge regression). We evaluate the ECR framework in terms of single session, session-to-session transfer, and subject-transfer decoding. We also validate the online decoding ability of the proposed framework with a short-time window size. The average accuracies are observed to be 91.11±9.14%, 90.52±8.67%, 86.96±12.13%, and 78.79±12.59%. This paper demonstrates that SSVEP BCI based on ear-EEG can achieve reliable performance with the proposed ECR framework.","","","10.1109/TCYB.2019.2924237","Samsung Research Funding Center of Samsung Electronics; Institute for Information and Communications Technology Planning and Evaluation grant funded by the Korea Government Development of BCI Based Brain and Cognitive Computing Technology for Recognizing Users Intentions Using Deep Learning; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8758838","Brain-computer interface (BCI);ear-electroencephalography (EEG);nonlinear regression;steady-state visual evoked potential (SSVEP)","Electroencephalography;Decoding;Visualization;Electrodes;Ear;Estimation;Brain modeling","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Improving Brain E-health Services via High-Performance EEG Classification with Grouping Bayesian Optimization","H. Ke; D. Chen; B. Shi; J. Zhang; X. Liu; X. Zhang; X. Li","Wuhan University, Wuhan, Hubei China (e-mail: hengjin.ke@whu.edu.cn); Computer School, Wuhan University, 12390 Wuhan, HuBei China 430072 (e-mail: danjj43@hotmail.com); School of Computer Science and Technology, Nanjing Tech University, 91599 Nanjing, Jiangsu China (e-mail: benyunshi@outlook.com); Wuhan University, Wuhan, Hubei China (e-mail: 1928781021@qq.com); Peking University People's Hospital, 71185 Beijing, Beijing China (e-mail: lxz_121@hotmail.com); Peking University People's Hospital, 71185 Beijing, Beijing China (e-mail: zxh899@hotmail.com); National Key Laboratory of Cognitive Neuroscience and Learning, Beijing Normal University, 47836 Beijing, Beijing China (e-mail: xiaoli@bnu.edu.cn)","IEEE Transactions on Services Computing","","2019","PP","99","1","1","Online electroencephalograph (EEG) classification is a core service of recently booming brain e-health, but its performance often becomes unstable because (1) conventional end-to-end models (e.g., deep neural network, DNN) largely remain static, while brain states of diseases are highly dynamic and exhibits significant individuality; and (2) EEG analytics are too complicated and have to be sustained by advanced computing services. This study adopts an automatic machine learning method to construct a dual-CNN (convolutional neural network) of high performance in terms of both accuracy and efficiency. The model embraces the capability of neural architecture search (NAS), empowered by grouping Bayesian optimization. The model can optimize its hyperparameters continuously on its own initiative. Experimental results in the evaluation of depression using real EEG datasets indicate that (1) the proposed method executes 3.5 times faster compared with a conventional counterpart; (2) the dual-CNN gains a significant performance improvement (vs. manual calibration in averages) in identifying Major Depression Disorder (MDD) with accuracy, sensitivity, and specificity up to 98.81%, 98.36%, and 99.31% respectively; and those for treatment outcome are 99.52%, 99.63%, and 99.37% respectively, and (3) classification can be completed several hundred times faster than EEG being collected upon a COTS computer.","","","10.1109/TSC.2019.2962673","Major Project for Technological Innovation of Hubei Province; National Natural Science Foundation of China; Foundation for Innovative Research Groups of Hubei Province of China; Science and Technology Programme of Hubei Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8943983","Brain E-health;Bayesian Optimization;Hyperparameters;EEG Classification;Depression","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Anytime Recognition with Routing Convolutional Networks","Z. Jie; P. Sun; X. Li; J. Feng; W. Liu","Tencent AI Lab, Tencent AI Lab, SHENZHEN, GUANGDONG China (e-mail: zequn.nus@gmail.com); Reinforcement Learning Center, Tencent AI Lab, Shenzhen, Guangdong China (e-mail: pengsun000@gmail.com); Electrical Engineering, Tsinghua University, 12442 Beijing, Beijing China (e-mail: lixincn2015@gmail.com); ECE, National University of Singapore, 37580 Singapore, Singapore Singapore (e-mail: elefjia@nus.edu.sg); Electrical Engineering, Columbia University, New York, New York United States 10027 (e-mail: wl2223@columbia.edu)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","An automatic trade-off between accuracy and efficiency for a single deep neural network is highly desired in time-sensitive computer vision applications. To achieve anytime prediction, existing methods only embed fixed exits to neural networks and make the predictions with the fixed exits for all the samples. However, it is observed that the latest exit within a time budget does not always provide a more accurate prediction than the earlier exits for testing samples of various difficulties. Motivated by this, we propose to improve the anytime prediction accuracy by allowing each sample to adaptively select its own optimal exit within a specific time budget. Specifically, we propose a new Routing Convolutional Network (RCN). For any given time budget, it adaptively selects the optimal layer as exit for a specific testing sample following the learned policy of the Q-network at the exit, considering both potential information gain and time-cost. The exits and the Q-networks are optimized alternatively to mutually boost each other under the cost-sensitive environment. Apart from anytime image classification, RCN can also be adapted to pixel-wise prediction tasks, e.g., scene parsing. Extensive experimental results on CIFAR-10, CIFAR-100 and ImageNet and Cityscapes benchmarks demonstrate the efficacy of RCN for anytime recognition.","","","10.1109/TPAMI.2019.2959322","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8936396","Dynamic neural network;fast inference;image classification;semantic segmentation","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Defining Image Memorability using the Visual Memory Schema","E. Akagunduz; A. Bors; K. Evans","Computer Science, University of York, 8748 York, North Yorkshire United Kingdom of Great Britain and Northern Ireland YO10 5DD (e-mail: akagunduz@ieee.org); Computer Science, University of York, York, York United Kingdom of Great Britain and Northern Ireland YO10 5GH (e-mail: adrian.bors@york.ac.uk); Psychology, University of York, 8748 York, North Yorkshire United Kingdom of Great Britain and Northern Ireland (e-mail: karla.evans@york.ac.uk)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Memorability of an image is a characteristic determined by the human observers' ability to remember images they have seen. Yet recent work on image memorability defines it as an intrinsic property that can be obtained independent of the observer. The current study aims to enhance our understanding and prediction of image memorability, improving upon existing approaches by incorporating the properties of cumulative human annotations. We propose a new concept called the Visual Memory Schema (VMS) referring to an organization of image components human observers share when encoding and recognizing images. The concept of VMS is operationalised by asking human observers to define memorable regions of images they were asked to remember during an episodic memory test. We then statistically assess the consistency of VMSs across observers for either correctly or incorrectly recognised images. The associations of the VMSs with eye fixations and saliency are analysed separately as well. Lastly, we adapt various deep learning architectures for the reconstruction and prediction of memorable regions in images and analyse the results when using transfer learning at the outputs of different convolutional network layers.","","","10.1109/TPAMI.2019.2914392","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8704932","Image Memorability;Visual Memory Schema;Memory Experiments;Deep Features","Visualization;Observers;Semantics;Psychology;Organizations;Image recognition;Computer vision","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Direction-aware Spatial Context Features for Shadow Detection and Removal","X. Hu; C. Fu; L. Zhu; J. Qin; P. Heng","Department of Computer Science and Engineering, The Chinese University of Hong Kong, Shatin, N.T. Hong Kong (e-mail: xwhu@cse.cuhk.edu.hk); Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, Hong Kong Hong Kong (e-mail: philip.chiwing.fu@gmail.com); Department of Computer Science and Engineering, The Chinese University of Hong Kong, Shatin, Hong Kong Hong Kong (e-mail: lzhu@cse.cuhk.edu.hk); Centre for Smart Health, School of Nursing, Hong Kong Polytechnic University, 26680 Kowloon, Hong Kong Hong Kong (e-mail: harry.qin@polyu.edu.hk); Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, Hong Kong Hong Kong (e-mail: pheng@cse.cuhk.edu.hk)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Shadow detection and shadow removal are fundamental and challenging tasks, requiring an understanding of the global image semantics. This paper presents a novel deep neural network design for shadow detection and removal by analyzing the spatial image context in a direction-aware manner. To achieve this, we first formulate the direction-aware attention mechanism in a spatial recurrent neural network (RNN) by introducing attention weights when aggregating spatial context features in the RNN. By learning these weights through training, we can recover direction-aware spatial context (DSC) for detecting and removing shadows. This design is developed into the DSC module and embedded in a convolutional neural network to learn the DSC features at different levels. Moreover, we design a weighted cross entropy loss to make effective the training for shadow detection and further adopt the network for shadow removal by using a Euclidean loss function and formulating a color transfer function to address the color and luminosity inconsistencies in the training pairs. We employed two shadow detection benchmark datasets and two shadow removal benchmark datasets, and performed various experiments to evaluate our method. Experimental results show that our method performs favorably against the state-of-the-art methods for both shadow detection and shadow removal.","","","10.1109/TPAMI.2019.2919616","the Hong Kong Research Grants Council; the Shenzhen Science and Technology Program; the National Basic Program of China 973 Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8723605","Shadow detection;shadow removal;spatial context features;deep neural network","Feature extraction;Image color analysis;Training;Semantics;Benchmark testing;Recurrent neural networks","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Multi-user Physical Layer Authentication in Internet of Things with Data Augmentation","R. Liao; H. Wen; S. Chen; F. Xie; F. Pan; J. Tang; H. Song","National Key Laboratory of Science and Technology on Communications, University of Electronic Science and Technology of China (UESTC), Chengdu 611731, China.; (e-mail: sunlike@uestc.edu.cn); National Key Laboratory of Science and Technology on Communications, University of Electronic Science and Technology of China (UESTC), Chengdu 611731, China.; National Key Laboratory of Science and Technology on Communications, University of Electronic Science and Technology of China (UESTC), Chengdu 611731, China.; School of Information and Engineering, Sichuan Agricultural University, Yaan 625000, China.; School of Aeronautics and Astronautics, UESTC, Chengdu 611731, China.; School of Aeronautics and Astronautics, UESTC, Chengdu 611731, China.","IEEE Internet of Things Journal","","2019","PP","99","1","1","Unlike most of the upper layer authentication mechanisms, physical (PHY) layer authentication takes advantages of channel impulse response from wireless propagation to identify transmitted packages with low resource consumption and machine learning methods are effective ways to improve its implementation. However, the training of machine-learning-based PHY-layer authentication requires a large number of training samples, which makes the training process time consuming and computationally resources intensive. In this paper, we propose a data augmented multi-user PHY-layer authentication scheme to enhance the security of mobile edge computing system, an emergent architecture in the Internet of Things (IoT). Three data augmentation algorithms are proposed to speed up the establishment of authentication model and improve authentication success rate. By combining the deep neural network with data augmentation methods, the performance of the proposed multi-user PHY-layer authentication scheme is improved and the training speed is accelerated, even with fewer training samples. Extensive simulations are conducted under the real industry IoT environment and the figures illustrate the effectiveness of our approach.","","","10.1109/JIOT.2019.2960099","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8935162","Physical layer authentication;mobile edge computing (MEC);data augmentation;deep neural network (DNN).","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Generative Adversarial Networks for Classification of Micro-Doppler Signatures of Human Activity","I. Alnujaim; D. Oh; Y. Kim","Electrical and Computer Engineering Department, California State University, Fresno, CA 93740 USA (e-mail: youngkim@csufresno.edu).; Advanced Radar Research Division, Daegu Gyeongbuk Institute of Science and Technology, Daegu 42988, South Korea.; Electrical and Computer Engineering Department, California State University, Fresno, CA 93740 USA.","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","6","We propose using generative adversarial networks (GANs) for the classification of micro-Doppler signatures measured by the radar. Despite Deep Convolutional Neural Networks (DCNNs) having been used extensively in radar image classification in recent years, their performance could not be fully implemented in the radar field because of the deficiency of the training data set. This is a key issue because of the extremely high labor and monetary costs involved in obtaining radar images. As such, attempts have been made to resolve this issue via the production of radar data by simulation or by the use of transfer learning. In this letter, we propose the use of GANs to produce a large number of micro-Doppler signatures with which to increase the training data set. Once the GANs are trained, a large amount of similar data, with the same distribution as the original data, can be easily generated. The generated fake micro-Doppler images can then be included in the DCNN training process. The proposed method is applied to classifying human activities measured by the Doppler radar. For each human activity, corresponding GANs that generate micro-Doppler signatures for a particular activity are constructed. Using the micro-Doppler signatures produced by the GANs along with the original data, the DCNN is trained. According to the results, the use of GANs improves the accuracy of classification. Moreover, the use of GANs was found to be more effective than the use of transfer learning.","","","10.1109/LGRS.2019.2919770","Daegu Gyeongbuk Institute of Science and Technology DGIST Research and Development Program of the Ministry of Science and Information and Communications Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8738820","Deep convolutional neural networks DCNNs;generative adversarial networks GANs;human activity classification;micro-Doppler signatures","Gallium nitride;Radar imaging;Doppler radar;Generators;Neural networks;Training","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Fast Depth Prediction and Obstacle Avoidance on a Monocular Drone Using Probabilistic Convolutional Neural Network","X. Yang; J. Chen; Y. Dang; H. Luo; Y. Tang; C. Liao; P. Chen; K. Cheng","School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan 430074, China.; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan 430074, China.; College of Information Engineering, Zhejiang University of Technology, Hangzhou 310058, China.; School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan 430074, China.; College of Information Engineering, Zhejiang University of Technology, Hangzhou 310058, China.; HiScene Information Technology Company, Ltd., Shanghai 200120, China.; College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou 310058, China (e-mail: chenpeng@zjut.edu.cn).; School of Engineering, The Hong Kong University of Science and Technology, Hong Kong.","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","12","Recent studies employ advanced deep convolutional neural networks (CNNs) for monocular depth perception, which can hardly run efficiently on small drones that rely on low/middle-grade GPU(e.g. TX2 and 1050Ti) for computation. In addition, the methods which can effectively and efficiently produce probabilistic depth prediction with a measure of model confidence have not been well studied. The lack of such a method could yield erroneous, sometimes fatal, decisions in drone applications (e.g. selecting a waypoint in a region with a large depth yet a low estimation confidence). This paper presents a real-time onboard approach for monocular depth prediction and obstacle avoidance with a lightweight probabilistic CNN (pCNN), which will be ideal for use in a lightweight energy-efficient drone. For each video frame, our pCNN can efficiently predict its depth map and the corresponding confidence. The accuracy of our lightweight pCNN is greatly boosted by integrating sparse depth estimation from a visual odometry into the network for guiding dense depth and confidence inference. The estimated depth map is transformed into Ego Dynamic Space (EDS) by embedding both dynamic motion constraints of a drone and the confidence values into the spatial depth map. Traversable waypoints are automatically computed in EDS based on which appropriate control inputs for the drone are produced. Extensive experimental results on public datasets demonstrate that our depth prediction method runs at 12Hz and 45Hz on TX2 and 1050Ti GPU respectively, which is 1.8X~5.6X faster than the state-of-the-art methods and achieves better depth estimation accuracy. We also conducted experiments of obstacle avoidance in both simulated and real environments to demonstrate the superiority of our method to the baseline methods.","","","10.1109/TITS.2019.2955598","National Natural Science Foundation of China; Wuhan Science and Technology Bureau; Hubei Provicinal Natural Science Foundation; Fundamental Research Funds for the Central Universities; Program for HUST Acadamic Frontier Youth Team; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8924655","Depth prediction;convolutional neural network;adversarial learning;obstacle avoidance;drone platform.","Drones;Cameras;Estimation;Transmission line matrix methods;Collision avoidance;Probabilistic logic;Simultaneous localization and mapping","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Driver Drowsiness Recognition via 3D Conditional GAN and Two-level Attention Bi-LSTM","Y. Hu; M. Lu; C. Xie; X. Lu","School of Automation, Southeast University, Nanjing 210096, China and Key Laboratory of Measurement and Control of CSE, Ministry of Education, Southeast University, Nanjing 210096, China.; School of Automation, Southeast University, Nanjing 210096, China and Key Laboratory of Measurement and Control of CSE, Ministry of Education, Southeast University, Nanjing 210096, China.; College of Mechanical and Electronic Engineering, Nanjing Forestry University, Nanjing 210037, China.; School of Automation, Southeast University, Nanjing 210096, China and Key Laboratory of Measurement and Control of CSE, Ministry of Education, Southeast University, Nanjing 210096, China.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Driver drowsiness has currently been a severe issue threatening road safety, hence it is vital to develop an effective drowsiness recognition algorithm to avoid traffic accidents. However, recognizing drowsiness is still very challenging, due to the large intra-class variations in facial expression, head pose and illumination condition. In this paper, a new deep learning framework based on the hybrid of 3D conditional generative adversarial network and two-level attention bidirectional long short-term memory network (3DcGAN-TLABiLSTM) has been proposed for robust driver drowsiness recognition. Aiming at extracting short-term spatial-temporal features with abundant drowsiness-related information, we design a 3D encoder-decoder generator with the condition of auxiliary information to generate high-quality fake image sequences and devise a 3D discriminator to learn drowsiness-related representation from spatial-temporal domain. In addition, for long-term spatial-temporal fusion, we investigate the use of two-level attention mechanism to guide the bidirectional long short-term memory learn the saliency of short-term memory information and long-term temporal information. For experiment, we evaluate our 3DcGAN-TLABiLSTM framework on a public NTHU-DDD dataset. Experimental results show that the proposed approach achieves higher precision of drowsiness recognition compared to the state-of-the-art.","","","10.1109/TCSVT.2019.2958188","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8926344","Driver drowsiness;generative adversarial network;two-level attention mechanism;bidirectional long short-term memory","Generative adversarial networks;Vehicles;Three-dimensional displays;Gallium nitride;Feature extraction;Machine learning;Generators","","","","","","","","","","IEEE","IEEE Early Access Articles"
"DeepSeed Local Graph Matching for Densely Packed Cells Tracking","M. Liu; Y. Liu; W. Qian","College of Electrical and Information Engineering, Hunan University, Changsha, Hunan China (e-mail: liu_min@hnu.edu.cn); College of Electrical and Information Engineering, Hunan University, Changsha, Hunan China (e-mail: liu_yalan@hnu.edu.cn); College of Electrical and Information Engineering, Hunan University, Changsha, Hunan China (e-mail: weiliqian@hun.edu.cn)","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2019","PP","99","1","1","The tracking of densely packed plant cells across microscopy image sequences is very challenging, because their appearance change greatly over time. A local graph matching algorithm was proposed to track such cells by exploiting the tight spatial topology of neighboring cells, and then an iterative searching strategy was used to grow the correspondence from a seed cell pair. Thus, the performance of the existing tracking approach heavily relies on the robustness of finding seed cell pair. However, the existing local graph matching algorithm cannot guarantee the correctness of the seed cell pair, especially in unregistered image sequences or image sequences with large time intervals. In this paper, we propose a DeepSeed local graph matching model to find seed cell pair robustly, by combining local graph matching and CNN-based similarity learning, which uses cells spatial-temporal contextual information and cell pairs similarity information. The CNN-based similarity learning is designed to learn cells deep feature and measure cell pairs similarity. Compared with the existing plant cell matching method, the experimental results show that the DeepSeed local graph matching method can track most cells in unregistered image sequences. Moreover, the DeepSeed tracking algorithm can accurately track cells across image sequences with large time intervals.","","","10.1109/TCBB.2019.2936851","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8809785","Cell tracking;CNN-based similarity learning;Local graph matching;DeepSeed","Image sequences;Feature extraction;Microscopy;Image segmentation;Image edge detection;Cells (biology);Topology","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Towards New Retail: A Benchmark Dataset for Smart Unmanned Vending Machines","H. Zhang; D. Li; Y. Ji; H. Zhou; W. Wu; K. Liu","Computer Science, Harbin Institute of Technology, shenzhen China 518055 (e-mail: hjzhang@hit.edu.cn); Computer Science, Harbin Institute of Technology Shenzhen, 529484 Shenzhen, guangdong China 518055 (e-mail: lidonghai@stu.hit.edu.cn); Shenzhen Graduate School, Harbin Institute of Technology, 47822 Shenzhen China 518055 (e-mail: andrewchiyz@stu.hit.edu.cn); Computer Science, Harbin Institute of Technology Shenzhen, 529484 Shenzhen, guangdong China 518055 (e-mail: coldsummerday1211@gmail.com); School of Computer Science and Engineering, Southeast University, 12579 Nanjing China 211189 (e-mail: weiweiwu@seu.edu.cn); Computer Science, Chongqing University, Chongqing China 400040 (e-mail: liukai0807@cqu.edu.cn)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","Deep learning is a popular direction in computer vision and digital image processing. It is widely utilized in many fields, such as robot navigation, intelligent video surveillance, industrial inspection, and aerospace. With the extensive use of deep learning techniques, classification and object detection algorithms have been rapidly developed. In recent years, with the introduction of the concept of ""unmanned retail"", object detection and image classification play a central role in unmanned retail applications. However, open source datasets of traditional classification and object detection have not yet been optimized for application scenarios of unmanned retail. Currently, classification and object detection datasets do not exist that focus on unmanned retail solely. Therefore, in order to promote unmanned retail applications by using deep learning-based classification and object detection, we collected more than 30,000 images of unmanned retail containers using a refrigerator affixed with different cameras under both static and dynamic recognition environments. These images were categorized into 10 kinds of beverages. After manual labeling, the dataset images contained 155,153 instances, each of which was annotated with a bounding box. We performed extensive experiments on this dataset using 10 state-of-the-art deep learning-based models. Experimental results indicate great potential of using these deep learning-based models for real-world smart unmanned vending machines (UVMs).","","","10.1109/TII.2019.2954956","Fund of ZTE Corporation; National Key R and D Program of China; Shenzhen Science and Technology Program; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8908822","Unmanned retail;vending machine;object detection;benchmark dataset","Object detection;Cameras;Computer vision;Computational modeling;Cloud computing;Sensors;Benchmark testing","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Efficient Person Search via Expert-Guided Knowledge Distillation","Y. Zhang; X. Li; Z. Zhang","College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou 310027, China.; College of Computer Science and Technology, Zhejiang University, Hangzhou 310027, China (e-mail: xilizju@zju.edu.cn).; College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou 310027, China.","IEEE Transactions on Cybernetics","","2019","PP","99","1","12","The person search problem aims to find the target person in the scene images, which presents high demands for both effectiveness and efficiency. In this paper, we present a unified person search framework which jointly handles the two demands for real-world applications. We explore the technique of knowledge distillation (KD), which allows the student network to share capabilities of the deep expert networks with much fewer parameters and less computing time. To achieve this, we describe an efficient person search network and a set of deep and well-engineered expert networks, to build a tiny and compact model that can approximate the representations of the expert networks in a multitask learning manner. We present extensive experiments on three customized student networks with different scales of networks and show strong performance compared to the state-of-the-art methods on both mean average precision and top-1 accuracies. We further demonstrate the efficiency of the proposed network at 120 frames/s in the feedforward time with only a little sacrifice on the accuracy.","","","10.1109/TCYB.2019.2916158","Zhejiang Provincial Natural Science Foundation of China; National Basic Research Program of China; National Natural Science Foundation of China; Zhejiang Lab; Fundamental Research Funds for Central Universities in China; Zhejiang University K P Chaos High Technology Development Foundation; Artificial Intelligence Research Foundation of Baidu Inc; Key Program of Zhejiang Province China; HIKVision; Zhejiang University Converging Media Computing Lab; Tencent AI Lab Rhino Bird Joint Research Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8759990","Knowledge distillation;multi-task learning;person search","Search problems;Computational modeling;Task analysis;Feature extraction;Training;Knowledge engineering;Image matching","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Automatic Detection of Mind Wandering from Video in the Lab and in the Classroom","N. Bosch; S. D'Mello","School of Information Sciences, University of Illinois at Urbana-Champaign, 14589 Champaign, Illinois United States (e-mail: pnb@illinois.edu); Institute of Cognitive Science and Department of Computer Science, University of Colorado Boulder, 1877 Boulder, Colorado United States (e-mail: sidney.dmello@gmail.com)","IEEE Transactions on Affective Computing","","2019","PP","99","1","1","We report two studies that used facial features to automatically detect mind wandering, a ubiquitous phenomenon whereby attention drifts from the current task to unrelated thoughts. In a laboratory study, university students $(N = 152)$ read a scientific text, whereas in a classroom study high school students $(N = 135)$ learned biology from an intelligent tutoring system. Mind wandering was measured using validated self-report methods. In the lab, we recorded face videos and analyzed these at six levels of granularity: (1) upper-body movement; (2) head pose; (3) facial textures; (4) facial action units (AUs); (5) co-occurring AUs; and (6) temporal dynamics of AUs. Due to privacy constraints, videos were not recorded in the classroom. Instead, we extracted head pose, AUs, and AU co-occurrences in real-time. Machine learning models, consisting of support vector machines (SVM) and deep neural networks, achieved F1 scores of .478 and .414 (25.4% and 20.9% above-chance improvements, both with SVMs) for detecting mind wandering in the lab and classroom, respectively. The lab-based detectors achieved 8.4% improvement over the previous state-of-the-art; no comparison is available for classroom detectors. We discuss how the detectors can integrate into intelligent interfaces to increase engagement and learning by responding to wandering minds.","","","10.1109/TAFFC.2019.2908837","Division of Information and Intelligent Systems; Division of Research on Learning in Formal and Informal Settings; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8680698","Affective computing;computer vision;educational technology;human-computer interaction","Task analysis;Physiology;Heart rate;Cameras;Facial features;Support vector machines;Detectors","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Local Semantic Siamese Networks for Fast Tracking","Z. Liang; J. Shen","Beijing Laboratory of Intelligent Information Technology, School of Computer Science, Beijing Institute of Technology, Beijing 100081, P. R. China.; Beijing Laboratory of Intelligent Information Technology, School of Computer Science, Beijing Institute of Technology, Beijing 100081, P. R. China.","IEEE Transactions on Image Processing","","2019","PP","99","1","1","Learning a powerful feature representation is critical for constructing a robust Siamese tracker. However, most existing Siamese trackers learn the global appearance features of the entire object, which usually suffers from drift problems caused by partial occlusion or non-rigid appearance deformation. In this paper, we propose a new Local Semantic Siamese (LSSiam) network to extract more robust features for solving these drift problems, since the local semantic features contain more fine-grained and partial information. We learn the semantic features during offline training by adding a classification branch into the classical Siamese framework. To further enhance the representation of features, we design a generally focal logistic loss to mine the hard negative samples. During the online tracking, we remove the classification branch and propose an efficient template updating strategy to avoid aggressive computing load. Thus, the proposed tracker can run at a high-speed of 100 Frame-per-Second (FPS) far beyond real-time requirement. Extensive experiments on popular benchmarks demonstrate the proposed LSSiam tracker achieves the state-of-the-art performance with a high-speed. Our source code is available at.","","","10.1109/TIP.2019.2959256","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8935538","Visual object tracking;Siamese deep network;Local feature representation","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Poststack Seismic Data Denoising Based on 3-D Convolutional Neural Network","D. Liu; W. Wang; X. Wang; C. Wang; J. Pei; W. Chen","School of Information and Communication Engineering, Xi'an Jiaotong University, Xi'an 710049, China.; InvestBrain, DataYes, Shanghai 200085, China.; School of Information and Communication Engineering, Xi'an Jiaotong University, Xi'an 710049, China.; Exploration and Development Research Institute, Daqing Oilfield Company, Ltd., Daqing 163712, China.; Exploration and Development Research Institute, Daqing Oilfield Company, Ltd., Daqing 163712, China.; School of Information and Communication Engineering, Xi'an Jiaotong University, Xi'an 710049, China (e-mail: wencchen@xjtu.edu.cn).","IEEE Transactions on Geoscience and Remote Sensing","","2019","PP","99","1","32","Deep learning has been successfully applied to image denoising. In this study, we take one step forward by using deep learning to suppress random noise in poststack seismic data from the aspects of network architecture and training samples. On the one hand, poststack seismic data denoising mainly aims at 3-D seismic data. We designed an end-to-end 3-D denoising convolutional neural network (3-D-DnCNN) that takes raw 3-D cubes as input in order to better extract the features of the 3-D spatial structure of poststack seismic data. On the other hand, denoising images with deep learning require noisy-clean sample pairs for training. In the field of seismic data processing, researchers usually try their best to suppress noise by using complex processes that combine different methods, but clean labels of seismic data are not available. In addition, building training samples in field seismic data has become an interesting but challenging problem. Therefore, we propose a training sample selection method that contains a complex workflow to produce comparatively ideal training samples. Experiments in this study demonstrate that deep learning can directly learn the ability to denoise field seismic data from selected samples. Although the building of the training samples may occur through a complex process, the experimental results of synthetic seismic data and field seismic data show that the 3-D-DnCNN has learned the ability to suppress the Gaussian noise and super-Gaussian noise from different training samples. Moreover, the 3-D-DnCNN network has better denoising performance toward arc-like imaging noise. In addition, we adopt residual learning and batch normalization in order to accelerate the training speed. After network training is satisfactorily completed, its processing efficiency can be significantly higher than that of conventional denoising methods.","","","10.1109/TGRS.2019.2947149","National Natural Science Foundation of China; National Key R and D Plan; Fundamental Research Funds for the Central University; NSFC-SINOPEC Joint Key Project; National Science and Technology Major Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8892677","3-D;convolutional neural networks (CNNs);seismic data denoising;training sample selection.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Cross-Entropy Adversarial View Adaptation for Person Re-identification","L. Wu; R. Hong; Y. Wang; M. Wang","Computer Science and Information Engineering, Hefei University of Technology, Hefei 230000, China; The University of Queensland, St Lucia 4072, Australia.; School of Computer Science and Information Engineering, Hefei University of Technology, Hefei 230000, China.; School of Computer Science and Information Engineering, Hefei University of Technology, Hefei 230000, China.; School of Computer Science and Information Engineering, Hefei University of Technology, Hefei 230000, China.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Person re-identification (re-ID) is a task of matching pedestrians under disjoint camera views. To recognise paired snapshots, it has to cope with large cross-view variations caused by the camera view shift. Supervised deep neural networks are effective in producing a set of non-linear projections that can transform cross-view images into a common feature space. However, they typically impose a symmetric architecture, yielding the network ill-conditioned on its optimisation. In this paper, we learn view-invariant subspace for person re-ID, and its corresponding similarity metric using an adversarial view adaptation approach. The main contribution is to learn coupled asymmetric mappings regarding view characteristics which are adversarially trained to address the view discrepancy by optimising the cross-entropy view confusion objective. To determine the similarity value, the network is empowered with a similarity discriminator to promote features that are highly discriminant in distinguishing positive and negative pairs. The other contribution includes an adaptive weighing on the most difficult samples to address the imbalance of within/between-identity pairs. Our approach achieves notable improved performance in comparison to state-of-the-arts on benchmark datasets.","","","10.1109/TCSVT.2019.2909549","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8682087","Person re-identification;View adaptation;Adversarial learning;Entropy regularisation","Training;Cameras;Computer science;Probes;Extraterrestrial measurements;Adaptation models","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"A Robotic System for Warped Stitching Based Compressive Strength Prediction of Marbles","A. Selver","Electrical and Electronics Engineering, Dokuz Eylul University, Izmir Turkey 35210 (e-mail: aselver@gmail.com)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","The amount, distribution and morphology of the impurities in a marble block determine both its aesthetic quality and compressive strength (CS). Although the former property has been studied extensively, CS prediction is rarely investigated. The existing approaches either use expensive and tedious laboratory tests or employ image processing to individual surface images, which are shown to achieve limited performance. In this study, a new electro-mechanical system is designed for full automatic prediction of CS of a marble block on a conveyor belt using all visible surface images, which are acquired by a 3-D printed robotic arm. The images are used to generate unique reconstructions, which can represent the 3D structure of the marbles in 2D via developed warped stitching based visualizations. Moreover, a novel feature set is proposed for taking advantage of these reconstructions. 157 cubic marble blocks are collected to test the performance of the system using both conventional (neural networks) and emerging (deep) machine learning tools. Adverse effects of small sample size are compensated with data augmentation and transfer learning. It is shown that the system achieves the state-of-the-art prediction results","","","10.1109/TII.2019.2926372","Turkiye Bilimsel ve Teknolojik Aratirma Kurumu; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8753554","Marbles;machine learning;warping;stitching;compressive strength;automated inspection systems","Feature extraction;Surface morphology;Electronics packaging;Robots;Surface treatment;Discrete wavelet transforms;Three-dimensional displays","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Underwater Image Enhancement Using a Multiscale Dense Generative Adversarial Network","Y. Guo; H. Li; P. Zhuang","School of Electronic and Information Engineering, Nanjing University of Information Science and Technology, Nanjing 210044, China (e-mail: guo-yecai@163.com).; School of Electronic and Information Engineering, Nanjing University of Information Science and Technology, Nanjing 210044, China (e-mail: lihanyu1204@163.com).; School of Electronic and Information Engineering, Nanjing University of Information Science and Technology, Nanjing 210044, China (e-mail: zhuangpeixian0624@163.com).","IEEE Journal of Oceanic Engineering","","2019","PP","99","1","9","Underwater image enhancement has received much attention in underwater vision research. However, raw underwater images easily suffer from color distortion, underexposure, and fuzz caused by the underwater scene. To address the above-mentioned problems, we propose a new multiscale dense generative adversarial network (GAN) for enhancing underwater images. The residual multiscale dense block is presented in the generator, where the multiscale, dense concatenation, and residual learning can boost the performance, render more details, and utilize previous features, respectively. And the discriminator employs computationally light spectral normalization to stabilize the training of the discriminator. Meanwhile, nonsaturating GAN loss function combining $L_1$ loss and gradient loss is presented to focus on image features of ground truth. Final enhanced results on synthetic and real underwater images demonstrate the superiority of the proposed method, which outperforms nondeep and deep learning methods in both qualitative and quantitative evaluations. Furthermore, we perform an ablation study to show the contributions of each component and carry out application tests to further demonstrate the effectiveness of the proposed method.","","","10.1109/JOE.2019.2911447","National Natural Science Foundation of China; Nanjing University of Information Science and Technology; Jiangsu Higher Education Institutions; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8730425","Dense concatenation;generative adversarial network (GAN);multiscale;residual learning underwater image enhancement","Gallium nitride;Image color analysis;Generators;Image restoration;Feature extraction;Training;Image enhancement","","","","","","","","","","IEEE","IEEE Early Access Articles"
"High-Level Semantic Networks for Multi-Scale Object Detection","J. Cao; Y. Pang; S. Zhao; X. Li","School of Electrical and Information Engineering, Tianjin University, Tianjin 300072, China.; School of Electrical and Information Engineering, Tianjin University, Tianjin 300072, China.; Key Laboratory of Embedded System and Service Computing, Tongji University, Shanghai 201804, China, and also with the School of Software Engineering, Tongji University, Shanghai 201804, China.; School of Computer Science and Center for OPTical IMagery Analysis and Learning (OPTIMAL), Northwestern Polytechnical University, Xi’an 710072, P.R. China.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","To better solve scale variance problem, deep multi-scale methods usually detect objects of different scales by different in-network layers. However, the semantic levels of features from different layers are usually inconsistent. In this paper, we propose a multi-branch and high-level semantic network by gradually splitting a base network into multiple different branches. As a result, the different branches have same depth and the output features of different branches have similarly high-level semantics. Due to the difference of receptive fields, the different branches are suitable to detect objects of different scales. Meanwhile, the multi-branch network does not introduce additional parameters by sharing the convolutional weights of different branches. To further improve detection performance, skip-layer connections are used to add context to the branch of relatively small receptive field, and dilated convolution is incorporated to enlarge the resolutions of output feature maps. When they are embedded into Faster RCNN architecture, the weighted scores of proposal generation network and proposal classification network are further proposed. Experiments on three pedestrian datasets (i.e., the KITTI dataset, the Caltech dataset, and the Citypersons dataset), one face dataset (i.e., the WIDER FACE dataset), and two general object datasets (i.e., the COCO benchmark and the PASCAL VOC dataset) demonstrate the effectiveness and generality of proposed method. On these datasets, our method achieves state-of-the-art performance.","","","10.1109/TCSVT.2019.2950526","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8887288","Object detection;multi-branch network;high-level semantic features;receptive field","Semantics;Feature extraction;Object detection;Proposals;Face detection;Convolution;Face","","","","","","","","","","IEEE","IEEE Early Access Articles"
"ROSA: Robust Salient Object Detection Against Adversarial Attacks","H. Li; G. Li; Y. Yu","Department of Computer Science, University of Hong Kong, Hong Kong.; School of Data and Computer Science, Sun Yat-sen University, Guangzhou 510006, China (e-mail: liguanbin@mail.sysu.edu.cn).; Department of Computer Science, University of Hong Kong, Hong Kong, and also with AI Lab, Deepwise Healthcare, Beijing 100080, China.","IEEE Transactions on Cybernetics","","2019","PP","99","1","13","Recently, salient object detection has witnessed remarkable improvement owing to the deep convolutional neural networks which can harvest powerful features for images. In particular, the state-of-the-art salient object detection methods enjoy high accuracy and efficiency from fully convolutional network (FCN)-based frameworks which are trained from end to end and predict pixel-wise labels. However, such framework suffers from adversarial attacks which confuse neural networks via adding quasi-imperceptible noises to input images without changing the ground truth annotated by human subjects. To our knowledge, this paper is the first one that mounts successful adversarial attacks on salient object detection models and verifies that adversarial samples are effective on a wide range of existing methods. Furthermore, this paper proposes a novel end-to-end trainable framework to enhance the robustness for arbitrary FCN-based salient object detection models against adversarial attacks. The proposed framework adopts a novel idea that first introduces some new generic noise to destroy adversarial perturbations, and then learns to predict saliency maps for input images with the introduced noise. Specifically, our proposed method consists of a segment-wise shielding component, which preserves boundaries and destroys delicate adversarial noise patterns and a context-aware restoration component, which refines saliency maps through global contrast modeling. The experimental results suggest that our proposed framework improves the performance significantly for state-of-the-art models on a series of datasets.","","","10.1109/TCYB.2019.2914099","National Natural Science Foundation of China; Science and Technology Planning Project of Guangdong Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8718038","Adversarial attack;deep neural network;salient object detection","Object detection;Image segmentation;Labeling;Feature extraction;Neural networks;Training;Adaptation models","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Enhanced Diagnosis of Pneumothorax with an Improved Real-time Augmentation for Imbalanced Chest X-rays Data Based on DCNN","Y. Wang; L. L. Sun; Q. Jin","Hangzhou Dianzi University, 12626 Hangzhou, Zhejiang China 310018 (e-mail: echowyq0154@gmail.com); the Key Lab of RF Circuits and Systems of Ministry of Education, Microelectronics CAD Center, Hangzhou Dianzi University, 12626 Hangzhou, Zhejiang China (e-mail: sunll@hdu.edu.cn); Department of Human Informatics and Cognitive Sciences, Waseda University, Tokorozawa-shi, Saitama Japan 359-1192 (e-mail: jin@waseda.jp)","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2019","PP","99","1","1","Pneumothorax is a common pulmonary disease that can lead to dyspnea and can be life-threatening. X-ray examination is the main means to diagnose this disease. Computer-aided diagnosis of pneumothorax on chest X-ray, as a prerequisite for timely cure, has been widely studied, but it is still not satisfactory to achieve highly accurate results. In this paper, an image classification algorithm based on deep convolutional neural network (DCNN) is proposed for high-resolution medical image analysis of pneumothorax X-rays, which features a Network In Network (NIN) for cleaning the data, random histogram equalization data augmentation processing and a DCNN. The experimental results indicate that the proposed method can effectively increase the correct diagnosis rate of pneumothorax, and the Area under Curve (AUC) of the test verified in the experiment is 0.9844 on ZJU-2 test data and 0.9906 on the ChestX-ray14, respectively. In addition, a large number of atmospheric pleura samples are visualized and analyzed based on the experimental results and in-depth learning characteristics of the algorithm. The analysis results verify the validity of feature extraction for the network. Combined with the results of these two aspects, the proposed X-ray image processing algorithm can effectively improve the classification accuracy of pneumothorax photographs.","","","10.1109/TCBB.2019.2911947","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8693998","Deep Convolutional Neural Network (DCNN);Pneumothorax;Chest X-rays;Imbalanced Data;Visualization","X-rays;Diseases;Lung;Medical diagnostic imaging;Data visualization;Histograms","","","","","","","","","","IEEE","IEEE Early Access Articles"
"ΔNN: Power-efficient Neural Network Acceleration using Differential Weights","H. Mahdiani; A. Khadem; A. Ghanbari; M. Modarressi; F. Fattahi; M. Daneshtalab","University of Tehran, 48425 Tehran, Tehran Iran (the Islamic Republic of) (e-mail: hoda.mahdiani@ut.ac.ir); University of Tehran, 48425 Tehran, Tehran Iran (the Islamic Republic of) (e-mail: arkhadem@umich.edu); University of Tehran, 48425 Tehran, Tehran Iran (the Islamic Republic of) (e-mail: azmghanbari@gmail.com); Department of Electrical and Computer Engineering, University of Tehran, Tehran, Tehran Iran (the Islamic Republic of) (e-mail: modarressi@ut.ac.ir); University of Tehran, 48425 Tehran, Tehran Iran (the Islamic Republic of) (e-mail: m_plusplsu@yahoo.com); IT, University of Turku, Turku, Turku Sweden 16445 (e-mail: masoud.daneshtalab@mdh.se)","IEEE Micro","","2019","PP","99","1","1","The enormous and ever-increasing complexity of state-of-the-art neural networks has impeded the deployment of deep learning on resource-limited embedded and mobile devices. To reduce the complexity of neural networks, this paper presents ΔNN, a power-efficient architecture that leverages a combination of the approximate value locality of neuron weights and algorithmic structure of neural networks. ΔNN keeps a weight as its difference (Δ) to the nearest smaller weight: each weight reuses the calculations of the smaller weight, followed by a calculation on the Δ value to make up the difference. We also round up/down the Δ to the closest power of two number to further reduce complexity. The experimental results show that ΔNN boosts the average performance by 43% and reduces the average power consumption by 22% over two state-of-the-art neural network designs.","","","10.1109/MM.2019.2948345","The Swedish Foundation for International Cooperation in Research and Higher Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8877741","Deep neural network;Difierential computation;Hardware acceleration","Artificial neural networks;Neurons;Biological neural networks;Complexity theory;Quantization (signal);Computer architecture;Multiplexing","","","","","","","","","","IEEE","IEEE Early Access Articles"
"RDense: A protein-RNA binding prediction model based on bidirectional recurrent neural network and densely connected convolutional networks","Z. Li; J. Zhu; X. Xu; Y. Yao","School of Science, Zhejiang Sci-Tech University, Hangzhou, 310018, China.; School of Information Science and Technology, Zhejiang Sci-Tech University, Hangzhou, 310018, China.; Integrative Bioinformatics Group, National Institute of Environmental Health Sciences, National Institutes of Health, Research Triangle Park, North Carolina, USA.; School of Mathematics and Statistics, Hainan Normal University, Haikou, 571158, China.","IEEE Access","","2019","PP","99","1","1","Complexes formed by proteins binding to RNAs are essential in biological processes, and can also be useful for identifying causal disease variants, gene expression regulation and translation. Protein-RNA interactions identified in vivo can be affected by experimental condition, noise, and some bias, while in vitro experiments yield clearer signals. Therefore, accurately inferring RNA-protein binding models from in vitro data, to predict bound and unbound RNA transcripts in vivo, has become a key challenge. We constructed RDense, a novel deep neural network model. Using existing RNA sequences and secondary structure information, we introduced the pairwise probability feature extracted from the RNA secondary structure as the input. The bidirectional long and short memory neural network (Bi-LSTM) and densely connected convolutional neural networks (DenseNet) were then combined to learn protein-RNA binding preferences. We found that our prediction of in vitro binding was better than all current methods with a significant improvement in model accuracy. In addition, there was also some improvement when in vitro data-trained RNA binding models were used to predict in vivo binding. In summary, we have introduced new pairwise probability feature of RNA to improve the robustness of the model. By comparing the Deepbind and DLPRB methods based on CNN, our method combines the strength of Bi-LSTM and DenseNet, with better performance in accuracy and scalability of prediction.","","","10.1109/ACCESS.2019.2961260","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8937536","protein-RNA binding;deep neural network;RNA sequence and structure","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Feature Consistency Training with JPEG Compressed Images","S. Wan; T. Wu; H. Hsu; W. H. Wong; C. Lee","Institute of Electronics, National Chiao Tung University, Hsinchu, Taiwan.; Institute for Computational and Mathematical Engineering, Stanford University, Stanford, CA 94305, USA.; Institute of Electronics, National Chiao Tung University, Hsinchu, Taiwan.; Institute for Computational and Mathematical Engineering, Stanford University, Stanford, CA 94305, USA.; Institute of Electronics, National Chiao Tung University, Hsinchu, Taiwan.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Deep neural networks (DNNs) are recently found to be vulnerable to JPEG compression artifacts, which distort the feature representations of DNNs leading to serious accuracy degradation. Most existing training methods which aim to address this problem add compressed images to the training data to enhance the robustness of DNNs. However, their improvements are limited since these methods usually regard the compressed images as new training samples instead of distorted samples. The feature distortions between the raw images and the compressed images are not investigated. In this work, we propose a new training method, called Feature Consistency Training, that is designed to minimize the feature distortions caused by JPEG artifacts. At each training iteration, we simultaneously input a raw image and its compressed version with a randomly sampled quality into a DNN model and extract the features from the internal layers. By adding feature consistency constraint to the objective function, the feature distortions in the representation space are minimized in order to learn robust filters. Besides, we present a residual mapping block which takes the quality factor of the compressed image as an additional information to further reduce the feature distortion. Extensive experiments demonstrate that our method outperforms several existed training methods on JPEG compressed images. Furthermore, DNN models trained by our method are found to be more robust to unseen distortions.","","","10.1109/TCSVT.2019.2959815","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933151","Compression Artifacts;Deep Neural Network;JPEG Compression;Classification Robustness","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Classifying Depression Severity in Recovery from Major Depressive Disorder via Dynamic Facial Features","S. Harati; A. Crowell; Y. Huang; H. Mayberg; S. Nemati","Biomedical Informatics, Emory University, Atlanta, Georgia United States 30322 (e-mail: sahar.harati@emory.edu); Department of Psychiatry and Behavioral Sciences, Emory University, Atlanta, Georgia United States (e-mail: Andrea.Crowell@emory.edu); Department of Biostatistics and Bioinformatics, Emory University, Atlanta, Georgia United States (e-mail: yhuang5@emory.edu); Department of Psychiatry and Behavioral Sciences, Emory University, Atlanta, Georgia United States (e-mail: helen.mayberg@emory.edu); Biomedical Informatics, Emory University, 1371 Atlanta, Georgia United States 30322 (e-mail: shamim.nemati@emory.edu)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","Major Depressive Disorder is a common psychiatric illness. At present, there are no objective, non-verbal, automated markers that can reliably track treatment response. Here we explore the use of video analysis of facial expressivity in a cohort of severely depressed patients before and after deep brain stimulation (DBS), an experimental treatment for depression. We introduced a set of variability measurements to obtain unsupervised features from muted video recordings, which were then leveraged to build predictive models to classify three levels of severity in the patients' recovery from depression. Multiscale entropy (MSE) was utilized to estimate the variability in pixel intensity level at various time-scales. A dynamic latent variable model (DLVM) was utilized to learn a low dimensional representation of factors that describe the dynamic relationship between high-dimensional pixels in each video frame and over time. Finally, a novel elastic net ordinal regression model was trained to predict the severity of depression, as independently rated by standard rating scales. Our results suggest that unsupervised features extracted from these video recordings, when incorporated in an ordinal regression predictor, can discriminate different levels of depression severity during ongoing DBS treatment. Objective markers of patient response to treatment have the potential to standardize treatment protocols and enhance the design of future clinical trials.","","","10.1109/JBHI.2019.2930604","Hope for Depression Research Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8769961","Deep Brain Stimulation;Depression Severity Level;Facial Expression;Entropy;Linear Dynamical System","Feature extraction;Satellite broadcasting;Video recording;Interviews;Informatics;Biomedical measurement;Face","","","","","","","","","","IEEE","IEEE Early Access Articles"
"JointDNN: An Efficient Training and Inference Engine for Intelligent Mobile Cloud Computing Services","A. E. Eshratifar; M. S. Abrishami; M. Pedram","Electrical Engineering, University of Southern California Viterbi School of Engineering, 115098 Los Angeles, California United States (e-mail: erfaneshrati@gmail.com); Electrical Engineering, University of Southern California Viterbi School of Engineering, 115098 Los Angeles, California United States (e-mail: abri443@usc.eduu); EE, USC, Los Angeles, California United States 90089 (e-mail: pedram@usc.edu)","IEEE Transactions on Mobile Computing","","2019","PP","99","1","1","Deep learning models are being deployed in many mobile intelligent applications. End-side services, such as intelligent personal assistants, autonomous cars, and smart home services often employ either simple local models on the mobile or complex remote models on the cloud. However, recent studies have shown that partitioning the DNN computations between the mobile and cloud can increase the latency and energy efficiencies. In this paper, we propose an efficient, adaptive, and practical engine, JointDNN, for collaborative computation between a mobile device and cloud for DNNs in both inference and training phase. JointDNN not only provides an energy and performance efficient method of querying DNNs for the mobile side but also benefits the cloud server by reducing the amount of its workload and communications compared to the cloud-only approach. Given the DNN architecture, we investigate the efficiency of processing some layers on the mobile device and some layers on the cloud server. We provide optimization formulations at layer granularity for forward- and backward-propagations in DNNs, which can adapt to mobile battery limitations and cloud server load constraints and quality of service. JointDNN achieves up to 18 and 32 times reductions on the latency and mobile energy consumption of querying DNNs compared to the status-quo approaches, respectively.","","","10.1109/TMC.2019.2947893","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8871124","deep neural networks;intelligent services;mobile computing;cloud computing","Cloud computing;Computational modeling;Computer architecture;Mobile handsets;Collaboration;Servers;Training","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Coupled Adversarial Training for Remote Sensing Image Super-Resolution","S. Lei; Z. Shi; Z. Zou","Image Processing Center, School of Astronautics, Beihang University, Beijing 100191, China, with the Beijing Key Laboratory of Digital Media, Beihang University, Beijing 100191, China, and also with the State Key Laboratory of Virtual Reality Technology and Systems, School of Astronautics, Beihang University, Beijing 100191, China.; Image Processing Center, School of Astronautics, Beihang University, Beijing 100191, China, with the Beijing Key Laboratory of Digital Media, Beihang University, Beijing 100191, China, and also with the State Key Laboratory of Virtual Reality Technology and Systems, School of Astronautics, Beihang University, Beijing 100191, China (e-mail: shizhenwei@buaa.edu.cn).; Department of Computational Medicine and Bioinformatics, University of Michigan, Ann Arbor, MI 48109 USA (e-mail: zzhengxi@umich.edu).","IEEE Transactions on Geoscience and Remote Sensing","","2019","PP","99","1","11","Generative adversarial network (GAN) has made great progress in recent natural image super-resolution tasks. The key to its success is the integration of a discriminator which is trained to classify whether the input is a real high-resolution (HR) image or a generated one. Arguably, learning a strong discriminative prior is essential for generating high-quality images. However, in remote sensing images, we discover, through extensive statistical analysis, that there are more low-frequency components than natural images, which may lead to a ``discrimination-ambiguity'' problem, i.e., the discriminator will become ``confused'' to tell whether its input is real or not when dealing with those low-frequency regions, and therefore, the quality of generated HR images may be deeply affected. To address this problem, we propose a novel GAN-based super-resolution algorithm named coupled-discriminated GANs (CDGANs) for remote sensing images. Different from the previous GAN-based super-resolution models in which their discriminator takes in a single image at one time, in our model, the discriminator is specifically designed to take in a pair of images: a generated image and its HR ground truth, to make better discrimination of the inputs. We further introduce a dual pathway network architecture, a random gate, and a coupled adversarial loss to learn better correspondence between the discriminative results and the paired inputs. Experimental results on two public data sets demonstrate that our model can obtain more accurate super-resolution results in terms of both visual appearance and local details compared with other state of the arts. Our code will be made publicly available.","","","10.1109/TGRS.2019.2959020","National Basic Research Program of China (973 Program); National Natural Science Foundation of China; Natural Science Foundation of Beijing Municipality; National Defense Science and Technology Innovation Special Zone Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8946581","Coupled adversarial training;deep convolutional neural networks;generative adversarial networks (GANs);remote sensing images;super-resolution.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Heart Sound Segmentation using Bidirectional LSTMs with Attention","T. Fernando; H. Ghaemmaghami; S. Denman; S. Sridharan; N. Hussain; C. Fookes","electrical engineering and computer science, Brisbane, Queensland Australia 4000 (e-mail: t.warnakulasuriya@qut.edu.au); M3DICINE Pty Ltd, Brisbane, Queensland Australia (e-mail: houman@m3dicine.com); Queensland University of Technology Faculty of Science and Engineering, 95541 Brisbane, Queensland Australia (e-mail: s.denman@qut.edu.au); Queensland University of Technology Business School, 95540 Brisbane, Queensland Australia (e-mail: s.sridharan@qut.edu.au); M3DICINE Pty Ltd, Brisbane, Queensland Australia (e-mail: nayyar@m3dicine.com); Queensland University of Technology Business School, 95540 Brisbane, Queensland Australia (e-mail: c.fookes@qut.edu.au)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","Objective: This paper proposes a novel framework for the segmentation of phonocardiogram (PCG) signals into heart states, exploiting the temporal evolution of the PCG as well as considering the salient information that it provides for the detection of the heart state. Methods: We propose the use of recurrent neural networks and exploit recent advancements in attention based learning to segment the PCG signal. This allows the network to identify the most salient aspects of the signal and disregard uninformative information. Results: The proposed method attains state-of-the-art performance on multiple benchmarks including both human and animal heart recordings. Furthermore, we empirically analyse different feature combinations including envelop features, wavelet and Mel Frequency Cepstral Coefficients (MFCC), and provide quantitative measurements that explore the importance of different features in the proposed approach. Conclusion: We demonstrate that a recurrent neural network coupled with attention mechanisms can effectively learn from irregular and noisy PCG recordings. Our analysis of different feature combinations shows that MFCC features and their derivatives offer the best performance compared to classical wavelet and envelop features. Significance: Heart sound segmentation is a crucial pre-processing step for many diagnostic applications. The proposed method provides a cost effective alternative to labour extensive manual segmentation, and provides a more accurate segmentation than existing methods. As such, it can improve the performance of further analysis including the detection of murmurs and ejection clicks. The proposed method is also applicable for detection and segmentation of other one dimensional biomedical signals.","","","10.1109/JBHI.2019.2949516","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8883031","Heart sound segmentation;Deep Recurrent Neural Networks;Attention Models;Long Short Term Memory Networks;Biomedical Signal Processing;Phonocardiogram","Heart;Phonocardiography;Animals;Feature extraction;Noise measurement;Task analysis;Recurrent neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"FlyIT: Drosophila Embryogenesis Image Annotation based on Image Tiling and Convolutional Neural Networks","W. Long; T. Li; Y. Yang; H. Shen","Computer Science, Shanghai Jiao Tong University, 12474 Shanghai, Shanghai China 200240 (e-mail: longwei_cs@sjtu.edu.cn); Shanghai, Shanghai China (e-mail: litiange2016@sjtu.edu.cn); Computer Science, Shanghai Jiao Tong University, 12474 Shanghai, Shanghai China 200240 (e-mail: yangyang@cs.sjtu.edu.cn); Institute of Image Processing and Pattern Recognition, Shanghai Jiaotong University, Shanghai, ShangHai China 200240 (e-mail: hbshen@sjtu.edu.cn)","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2019","PP","99","1","1","With the rise of image-based transcriptomics, spatial gene expression data has become increasingly important for understanding gene regulations from the tissue level down to the cell level. Especially, the gene expression images of Drosophila embryos provide a new data source in the study of Drosophila embryogenesis. It is imperative to develop automatic annotation tools since manual annotation is labor-intensive and requires professional knowledge. Although a lot of image annotation methods have been proposed in the computer vision field, they may not work well for gene expression images, due to the great difference between these two annotation tasks. Besides the apparent difference on images, the annotation is performed at the gene level rather than the image level, where the expression patterns of a gene are recorded in multiple images. Moreover, the annotation terms often correspond to local expression patterns of images, yet they are assigned collectively to groups of images and the relations between the terms and single images are unknown. In order to learn the spatial expression patterns comprehensively for genes, we propose a new method, called FlyIT (image annotation based on Image Tiling and convolutional neural networks for fruit Fly). We implement two versions of FlyIT, learning at image-level and gene-level respectively. The gene-level version employs an image tiling strategy to get a combined image feature representation for each gene. FlyIT uses a pre-trained ResNet model to obtain feature representation and a new loss function to deal with the class imbalance problem. As the annotation of Drosophila images is a multi-label classification problem, the new loss function considers the difficulty levels for recognizing different labels of the same sample and adjusts the sample weights accordingly. The experimental results on the FlyExpress database show that both the image tiling strategy and the deep architecture lead to the great enhancement of the annotation performance. FlyIT outperforms the existing annotators by a large margin (over 9% on AUC and 12% on macro F1 for predicting the top 10 terms). It also shows advantages over other deep learning models, including both single-instance and multi-instance learning frameworks.","","","10.1109/TCBB.2019.2935723","National Key Research and Development Program of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8805355","Biological Image Understanding;Convolutional Neural Networks;Drosophila Embryo;Gene Expression Image","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"GANPOP: Generative Adversarial Network Prediction of Optical Properties from Single Snapshot Wide-field Images","M. T. Chen; F. Mahmood; J. A. Sweer; N. J. Durr","Department of Biomedical Engineering, Johns Hopkins University, Baltimore, MD 21218.; Department of Biomedical Engineering, Johns Hopkins University, Baltimore, MD 21218 and Harvard Medical School, Boston, MA 02115.; Department of Biomedical Engineering, Johns Hopkins University, Baltimore, MD, 21218 and Triple Ring Technologies, Newark, CA 94560.; Department of Biomedical Engineering, Johns Hopkins University, Baltimore, MD 21218.","IEEE Transactions on Medical Imaging","","2019","PP","99","1","1","We present a deep learning framework for wide-field, content-aware estimation of absorption and scattering coefficients of tissues, called Generative Adversarial Network Prediction of Optical Properties (GANPOP). Spatial frequency domain imaging is used to obtain ground-truth optical properties at 660 nm from in vivo human hands and feet, freshly resected human esophagectomy samples, and homogeneous tissue phantoms. Images of objects with either flat-field or structured illumination are paired with registered optical property maps and are used to train conditional generative adversarial networks that estimate optical properties from a single input image. We benchmark this approach by comparing GANPOP to a single-snapshot optical property (SSOP) technique, using a normalized mean absolute error (NMAE) metric. In human gastrointestinal specimens, GANPOP with a single structured-light input image estimates the reduced scattering and absorption coefficients with 60% higher accuracy than SSOP while GANPOP with a single flat-field illumination image achieves similar accuracy to SSOP. When applied to both in vivo and ex vivo swine tissues, a GANPOP model trained solely on structured-illumination images of human specimens and phantoms estimates optical properties with approximately 46% improvement over SSOP, indicating adaptability to new, unseen tissue types. Given a training set that appropriately spans the target domain, GANPOP has the potential to enable rapid and accurate wide-field measurements of optical properties.","","","10.1109/TMI.2019.2962786","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8943974","optical imaging;tissue optical properties;neural networks;machine learning;spatial frequency domain imaging","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Semi-Supervised Cross-Modal Retrieval with Label Prediction","D. Mandal; P. Rao; S. Biswas","Electrical Engineering, Indian Institute of Science, 29120 Bangalore, Karnataka India (e-mail: devrajm@iisc.ac.in); Electrical Engineering, Indian Institute of Science, 29120 Bangalore, Karnataka India (e-mail: pramodrameshr@iisc.ac.in); Electrical Engineering, Indian Institute of Science, 29120 Bangalore, Karnataka India (e-mail: somabiswas@iisc.ac.in)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","Cross-modal retrieval tasks with image-text, audio-image, etc. are gaining increasing importance due to abundance of data from multiple modalities. In general, supervised approaches give significant improvement over their unsupervised counterparts at the additional cost of labeling or annotation of the training data. Recently, semi-supervised methods are becoming popular as they provide an elegant framework to balance the conflicting requirement of labeling cost and accuracy. In this work, we propose a novel deep semi-supervised framework, which can seamlessly handle both labeled as well as unlabeled data. The network has two important components: (a) first, the labels for the unlabeled portion of the training data are predicted using the label prediction component and then (b) a common representation for both the modalities is learned for performing cross-modal retrieval. The two parts of the network are trained sequentially one after the other. Extensive experiments on three standard benchmark datasets, Wiki, Pascal VOC and NUS-WIDE demonstrate that the proposed framework outperforms the state- of-the-art for both supervised and semi-supervised settings.","","","10.1109/TMM.2019.2954741","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8907496","Semi-Supervised Learning;Multi-Label Prediction;Binary Cross Entropy Loss;Cross-Modal Retrieval","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"LSTM-Based ECG Classification for Continuous Monitoring on Personal Wearable Devices","S. Saadatnejad; M. Oveisi; M. Hashemi","Sharif University of Technology, 68260 Tehran, Tehran Iran (the Islamic Republic of) (e-mail: saeedsa@ee.sharif.edu); Sharif University of Technology, 68260 Tehran, Tehran Iran (the Islamic Republic of) (e-mail: oveisi@ee.sharif.edu); Sharif University of Technology, 68260 Tehran Iran (the Islamic Republic of) (e-mail: matin@sharif.edu)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","Objective: A novel ECG classification algorithm is proposed for continuous cardiac monitoring on wearable devices with limited processing capacity. Methods: The proposed solution employs a novel architecture consisting of wavelet transform and multiple LSTM recurrent neural networks (Fig. 1). Results: Experimental evaluations show superior ECG classification performance compared to previous works. Measurements on different hardware platforms show the proposed algorithm meets timing requirements for continuous and real-time execution on wearable devices. Conclusion: In contrast to many compute-intensive deep-learning based approaches, the proposed algorithm is lightweight, and therefore, brings continuous monitoring with accurate LSTM-based ECG classification to wearable devices. Significance: The proposed algorithm is both accurate and lightweight. The source code is available online [1].","","","10.1109/JBHI.2019.2911367","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8691755","Continuous cardiac monitoring;Electrocardiogram (ECG) classification;Machine learning;Long short-term memory (LSTM);Embedded and wearable devices","","","","","4","","","","","","IEEE","IEEE Early Access Articles"
"A Survey on Canonical Correlation Analysis","X. Yang; L. Weifeng; W. Liu; D. Tao","Advanced Analytics Institute (AAI), University of Technology Sydney, 1994 Sydney, New South Wales Australia 2007 (e-mail: Xinghao.Yang@student.uts.edu.au); College of Information and Control Engineering, China University of Petroleum, Qingdao, Shandong Province China (e-mail: liuwf@upc.edu.cn); Advanced Analytics Institute, University of Technology Sydney, 1994 Sydney, New South Wales Australia 2007 (e-mail: wei.liu@uts.edu.au); Engineering and Information Technologies, University of Sydney, 4334 Sydney, New South Wales Australia (e-mail: dacheng.tao@sydney.edu.au)","IEEE Transactions on Knowledge and Data Engineering","","2019","PP","99","1","1","In recent years, the advances in data collection and statistical analysis promotes canonical correlation analysis (CCA) available for more advanced research. CCA is the main technique for two-set data dimensionality reduction such that the correlation between the pairwise variables in the common subspace is mutually maximized. Over 80-years of developments, a number of CCA models have been proposed according to different machine learning mechanisms. However, the field lacks an insightful review for the state-of-art developments. This survey targets to provide a well-organized overview for CCA and its extensions. We first review the CCA theory from the perspective of both model formation and model optimization. Following that, we present a taxonomy of current progress and classify them into seven groups: 1) multi-view CCA, 2) probabilistic CCA, 3) deep CCA, 4) kernel CCA, 5) discriminative CCA, 6) sparse CCA and 7) locality preserving CCA. For each group, we demonstrate two or three representative mathematical models, identifying their strengths and limitations. We summarize the representative applications and numerical results of these seven groups in real-world practices, collecting the data sets and open-sources for implementation. In the end, we provide several promising future research directions that can improve the current state of the art.","","","10.1109/TKDE.2019.2958342","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8928538","Canonical Correlation Analysis;Survey;Machine Learning","Correlation;Kernel;Computational modeling;Probabilistic logic;Data models;Analytical models;Bayes methods","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Analyzing Associations Between Chronic Disease Prevalence and Neighborhood Quality Through Google Street View Images","M. Javanmardi; D. Huang; P. Dwivedi; S. Khanna; K. Brunisholz; R. Whitaker; Q. Nguyen; T. Tasdizen","Scientific Computing and Imaging Institute, University of Utah, Salt Lake City, UT.; Department of Epidemiology and Biostatistics, School of Public Health, University of Maryland, College Park, MD.; Department of Epidemiology and Biostatistics, School of Public Health, University of Maryland, College Park, MD.; Master’s in Telecommunications Program, University of Maryland, College Park, MD.; Healthcare Delivery Institute, Intermountain Healthcare, Salt Lake City, UT.; Scientific Computing and Imaging Institute, University of Utah, Salt Lake City, UT.; Department of Epidemiology and Biostatistics, School of Public Health, University of Maryland, College Park, MD.; Scientific Computing and Imaging Institute, University of Utah, Salt Lake City, UT.","IEEE Access","","2019","PP","99","1","1","Deep learning and, specifically, convoltional neural networks (CNN) represent a class of powerful models that facilitate the understanding of many problems in computer vision. When combined with a reasonable amount of data, CNNs can outperform traditional models for many tasks, including image classification. In this work, we utilize these powerful tools with imagery data collected through Google Street View images to perform virtual audits of neighborhood characteristics. We further investigate different architectures for chronic disease prevalence regression through networks that are applied to sets of images rather than single images. We show quantitative results and demonstrate that our proposed architectures outperform the traditional regression approaches.","","","10.1109/ACCESS.2019.2960010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933431","Set Regression;Multi-Task Learning;Permutation Invariant Network;Chronic Disease Prevalence;Google Street View Images","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Research on Inception Module Incorporated Siamese Convolutional Neural Networks to Realize Face Recognition","X. Xu; L. Zhang; C. Duan; Y. Lu","College of Electronics and Control Engineering, Chang’an University, Xi’an, Shaanxi, 710064, China.; College of Electronics and Control Engineering, Chang’an University, Xi’an, Shaanxi, 710064, China.; College of Electronics and Control Engineering, Chang’an University, Xi’an, Shaanxi, 710064, China.; College of Electronics and Control Engineering, Chang’an University, Xi’an, Shaanxi, 710064, China.","IEEE Access","","2019","PP","99","1","1","Face recognition is an active research subject of biometrics due to its significant research and application prospects. The performance of face recognition can be affected by a series of uncontrollable factors, such as illumination, expression, posture and occlusion, which restricts its real-world applications. Therefore, improving the robustness of face recognition to environmental changes became an urgent problem. In this paper, a simplified deep convolutional neural network structure having high robustness under unlimited conditions is designed for face recognition. This structure can improve training speed and face recognition accuracy, and be suitable for small-scale data sets. Inception Module Incorporated Siamese Convolutional Neural Networks (IMISCNN) is developed based on effective reduction of external interference and better features extraction by adopting the Siamese network structure. A cyclical learning rate strategy is also introduced in IMISCNN for better model convergence. Compared to classical face recognition algorithms, such as PCA, PCA and SVM, CNN, PCANet, and the original SNN et al. The accuracy of IMISCNN in CASIA-webface and Extended Yale B standard face database is 99.36% and 99.21%, respectively. Its feasibility and effectiveness have been verified in our experiments.","","","10.1109/ACCESS.2019.2963211","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8946634","Cyclical Learning Rate;Face Recognition;Inception Module;Siamese Convolutional Neural Networks","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Leveraging Virtual and Real Person for Unsupervised Person Re-identification","F. Yang; Z. Zhong; Z. Luo; S. Lian; S. Li","Department of Artificial Intelligence, Xiamen University, 12466 Xiamen, Fujian China (e-mail: yangfx@stu.xmu.edu.cn); Department of Artifical Intelligence, Xiamen University, 12466 Xiamen, Fujian China (e-mail: zhunzhong@stu.xmu.edu.cn); Post-doctoral mobile station of Information and Communication Engineering, Xiamen University, Xiamen, China, xiamen, Fujian China (e-mail: zhiming.luo@xmu.edu.cn); Department of Artifical Intelligence, Xiamen University, 12466 Xiamen, Fujian China (e-mail: lancerlian@stu.xmu.edu.cn); Department of Artifical Intelligence, Xiamen University, 12466 Xiamen, Fujian China (e-mail: szlig@xmu.edu.cn)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","Person re-identification (re-ID) is a challenging instance retrieval problem, especially when identity annotations are not available for training. Although modern deep re-ID approaches have achieved great improvement, it is still difficult to optimize the deep re-ID model and learn discriminative person representation without annotations in training data. To address this challenge, this study considers the problem of unsupervised person re-ID and introduces a novel approach to solve this problem by leveraging virtual and real data. Our approach includes two components: virtual person generation and training of the deep re-ID model. For virtual person generation, we learn a person generation model and a camera style transfer model using unlabeled real data to generate virtual persons with different poses and camera styles. The virtual data is formed as labeled training data, enabling subsequent training deep re-ID model in supervision. For training of the deep re-ID model, we divide it into three steps: 1) pre-training a coarse re-ID model by using virtual data; 2) collaborative filtering based positive pair mining from the real data; and 3) fine-tuning of the coarse re-ID model by leveraging the mined positive pairs and virtual data. The final re-ID model is achieved by iterating between step 2 and step 3 until convergence. Extensive experiments demonstrate the effectiveness of our method. Experimental results on two large-scale datasets, Market-1501 and DukeMTMC-reID, show the advantages of our method over state-of-the-art approaches in unsupervised person re-ID.","","","10.1109/TMM.2019.2957928","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8931652","Person Re-identification;Generative Adversarial Network;Collaborative Filtering","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"CED: Credible Early Detection of Social Media Rumors","C. Song; C. Yang; H. Chen; C. Tu; Z. Liu; M. Sun","Electronic Engineering, Tsinghua University, 12442 Beijing, Beijing China (e-mail: sch14@mails.tsinghua.edu.cn); Computer Science, Beijing University of Posts and Telecommunications School of Science, 528771 Beijing, Beijing China (e-mail: albertyang33@gmail.com); Department of Computer Science and Technology, Tsinghua University, 12442 Beijing, Beijing China (e-mail: chm15@mails.tsinghua.edu.cn); Computer Science and Technology, Tsinghua University, 12442 Beijing, Beijing China 100084 (e-mail: tucunchao@gmail.com); Computer Science and Technology, Tsinghua University, Beijing, Beijing China 100084 (e-mail: liuzy@tsinghua.edu.cn); Department of Computer Science and Technology, Tsinghua University, Beijing, Beijing China (e-mail: sms@mail.tsinghua.edu.cn)","IEEE Transactions on Knowledge and Data Engineering","","2019","PP","99","1","1","Rumors spread dramatically fast through online social media services, and people are exploring methods to detect rumors automatically. Existing methods typically learn semantic representations of all reposts to a rumor candidate for prediction. However, it is crucial to efficiently detect rumors as early as possible before they cause severe social disruption, which has not been well addressed by previous works. In this paper, we present a novel early rumor detection model, Credible Early Detection (CED). By regarding all reposts to a rumor candidate as a sequence, the proposed model will seek an early point-in-time for making a credible prediction. We conduct experiments on three real-world datasets, and the results demonstrate that our proposed model can remarkably reduce the time span for prediction by more than 85%, with better accuracy performance than all state-of-the-art baselines.","","","10.1109/TKDE.2019.2961675","Major Project of the National Social Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8939421","Rumor;Early Detection;Deep Neural Network;Social Media","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Convolutional Networks with Channel and STIPs Attention Model for Action Recognition in Videos","H. Wu; X. Ma; Y. Li","School of Control Science and Engineering, Shandong University, 12589 Jinan, Shandong China (e-mail: whbo@mail.sdu.edu.cn); School of Control Science and Engineering, Shandong University, 12589 Jinan China 250000 (e-mail: maxin@sdu.edu.cn); School of Control Science and Engineering, Shandong University, 12589 Jinan, Shandong China (e-mail: liyb@sdu.edu.cn)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","With the help of convolutional neural networks (CNNs), video-based human action recognition has made significant progress. CNN features that are spatial and channel-wise can provide rich information for powerful image description. However, CNNs lack the ability to process the long-term temporal dependency of an entire video and further cannot well focus on the informative motion regions of actions. Aiming at the two problems, we propose a novel video-based action recognition framework in this paper. We first represent videos with dynamic image sequences (DISs), which effectively describe videos by modeling the local spatial-temporal dynamics and dependencies. Then a channel and spatial-temporal interest points (STIPs) attention model (CSAM) based on CNNs is proposed to focus on the discriminative channels in networks and the informative spatial motion regions of human actions. Specifically, channel attention (CA) is implemented by automatically learning channel-wise convolutional features and assigning different weights for different channels. STIPs attention (SA) is encoded by projecting the detected STIPs on frames of dynamic image sequences into the corresponding convolutional feature map space. The proposed CSAM is embedded after CNN convolutional layers to refine the feature maps, followed by global average pooling to produce effective feature representations for videos. Finally frame-level video representations are fed into an LSTM to capture the temporal dependencies and make classification. Experiments on three challenging RGB-D datasets show that our method has better performance and outperforms the state-of-the-art approaches with only depth data.","","","10.1109/TMM.2019.2953814","Chinese National Programs for High Technology Research and Development; Chinese National Key Research and Development Plan; Chinese National Natural Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8902002","Action recognition;dynamic image sequence;channel attention;spatial-temporal interest points attention;deep networks","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"OctreeNet: A Novel Sparse 3-D Convolutional Neural Network for Real-Time 3-D Outdoor Scene Analysis","F. Wang; Y. Zhuang; H. Gu; H. Hu","School of Control Science and Engineering, Dalian University of Technology, Dalian 116024, China; School of Control Science and Engineering, Dalian University of Technology, Dalian 116024, China (e-mail: zhuang@dlut.edu.cn).; Faculty of Electronic Information and Electrical Engineering, Dalian University of Technology, Dalian 116024, China; School of Computer Science and Electronic Engineering, University of Essex, Colchester CO4 3SQ, U.K.","IEEE Transactions on Automation Science and Engineering","","2019","PP","99","1","13","Convolutional neural networks (CNNs) for 3-D data analyses require a large size of memory and fast computation power, making real-time applications difficult. This article proposes a novel OctreeNet (a sparse 3-D CNN) to analyze the sparse 3-D laser scanning data gathered from outdoor environments. It uses a collection of shallow octrees for 3-D scene representation to reduce the memory footprint of 3-D-CNNs and performs point cloud classification on every single octree. Furthermore, the smallest non-trivial and non-overlapped kernel (SNNK) implements convolution directly on the octree structure to reduce dense 3-D convolutions to matrix operations at sparse locations. The proposed neural network implements a depth-first search algorithm for real-time predictions. A conditional random field model is utilized for learning global semantic relationships and refining point cloud classification results. Two public data sets (Semantic3D.net and Oakland) are selected to test the classification performance in outdoor scenes with different spatial sparsity. The experiments and benchmark test results show that the proposed approach can be effectively used in real-time 3-D laser data analyses.","","","10.1109/TASE.2019.2942068","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8865629","Deep neural network;octree forest;point clouds;real-time classification;sparse convolution.","Octrees;Three-dimensional displays;Convolution;Real-time systems;Forestry;Robots;Task analysis","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Monocular Depth Estimation with Augmented Ordinal Depth Relationships","Y. Cao; T. Zhao; K. Xian; C. Shen; Z. Cao; S. Xu","University of Adelaide, SA 5005, Australia. Corresponding author: Y. Cao.; Tsinghua University, Beijing 100084, China.; Huazhong University of Science and Technology, Wuhan 430074, China. K. Xian’s contribition was made when he was visiting The University of Adelaide.; University of Adelaide, SA 5005, Australia. Corresponding author: Y. Cao.; Huazhong University of Science and Technology, Wuhan 430074, China. K. Xian’s contribition was made when he was visiting The University of Adelaide.; Shanghai Institute for Advanced Communications and Data Science, Shanghai University, Shanghai 200444, China.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Most existing algorithms for depth estimation from single monocular images need large quantities of metric ground-truth depths for supervised learning. We show that relative depth can be an informative cue for metric depth estimation and can be easily obtained from vast stereo videos. Acquiring metric depths from stereo videos is sometimes impracticable due to the absence of camera parameters. In this paper, we propose to improve the performance of metric depth estimation with relative depths collected from stereo movie videos using existing stereo matching algorithm. We introduce a new “Relative Depth in Stereo"" (RDIS) dataset densely labelled with relative depths. We first pretrain a ResNet model on our RDIS dataset. Then we finetune the model on RGB-D datasets with metric ground-truth depths. During our finetuning, we formulate depth estimation as a classification task. This re-formulation scheme enables us to obtain the confidence of a depth prediction in the form of probability distribution. With this confidence, we propose an information gain loss to make use of the predictions that are close to ground-truth. We evaluate our approach on both indoor and outdoor benchmark RGB-D datasets and achieve state-of-the-art performance.","","","10.1109/TCSVT.2019.2929202","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8764412","Depth estimation;RGB-D dataset;ordinal relationship;deep network","Estimation;Measurement;Videos;Training;Motion pictures;Task analysis;Labeling","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Trajectory Forecasting With Neural Networks: An Empirical Evaluation and A New Hybrid Model","Y. Wang; D. Zhang; Y. Liu; K. Tan","Department of Industrial and Systems Engineering and Management, National University of Singapore, Singapore 119077.; College of Computer Science and Technology, Zhejiang University, Hangzhou 310027, China (e-mail: zhangdongxiang@zju.edu.cn).; School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu 611731, China.; School of Computing, National University of Singapore, Singapore 119077.","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","10","Recent years have witnessed the advent and prevalence of deep learning that have provoked storms in ITS (Intelligent Transportation Systems). Consequently, traditional ML models in many applications have been replaced by the new learning techniques. In this paper, we focus on the problem of trajectory prediction, which is a cornerstone component to support many useful higher-level applications in ITS. We conduct so far the most comprehensive evaluation on various models proposed for trajectory prediction, including 5 statistic-based models and 10 deep-learning based networks. In addition, we propose a hybrid model that integrates MLP to extract local features and LSTM to capture long term dependency. It is also enhanced with a moving-state prediction model based on random forest to further reduce prediction error. We conduct extensive empirical evaluation on three real datasets with different motion patterns and reveal interesting findings. Furthermore, the experimental results show that our proposed hybrid model achieves superior performance over its competitors in all the datasets.","","","10.1109/TITS.2019.2943055","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8853392","Trajectory forecasting;neural networks;empirical evaluation.","Predictive models;Trajectory;Hidden Markov models;Neural networks;Kernel;Intelligent transportation systems;Data models","","","","","","","","","","IEEE","IEEE Early Access Articles"
"ARTS: Automotive Repository of Traffic Signs for the United States","F. Almutairy; T. Alshaabi; J. Nelson; S. Wshah","Computer Science Department, The University of Vermont, Burlington, VT 05405 USA (e-mail: fayha.almutairy@gmail.com).; Computer Science Department, The University of Vermont, Burlington, VT 05405 USA.; Vermont Agency of Transportation Asset Management Bureau, Barre, VT 05641 USA.; Computer Science Department, The University of Vermont, Burlington, VT 05405 USA.","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","9","Traffic signs recognition (TSR) is a crucial sub-domain of computer vision, particularly relevant to autonomous vehicles and autonomous driver-assistance systems (ADAS). TSR systems can further augment efforts in many other applications, such as highway asset maintenance and management. Despite the relative success of detectors with hand-crafted features in Europe, most, if not all, non-deep-learning based systems are not scalable to accurately recognize a large subset of traffic signs in the United States. The recent works in the domain of object detection using machine learning have shown the necessity of deep neural networks (DNNs) in TSR, whereby a DNN can learn features automatically without hand-crafting them. Due to the lack of datasets in the U.S. and the inefficient use of traditional methods for traffic sign recognition (TSR) in the U.S., we created the Automotive Repository of Traffic Signs (ARTS), a new dataset for traffic signs recognition in the U.S. ARTS covers a wide range of sign-types, including Regulatory, Guide, Warning, and Temporary signs as defined in the Manual on Uniform Traffic Control Devices (MUTCD). It also features geospatial data to localize signs using their GPS coordinates. Benchmarks are presented to assess the performance of state-of-the-art deep learning based detectors.","","","10.1109/TITS.2019.2958486","Federal Highway Administration Work Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8943972","Advanced driver-assistance;traffic sign recognition;computer-vision;object detection.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Bayes Risk Minimization Machine for Example-Dependent Cost Classification","M. Lázaro; A. R. Figueiras-Vidal","Department of Signal Theory and Communications, University Carlos III of Madrid, 28911 Madrid, Spain (e-mail: mlazaro@tsc.uc3m.es).; Department of Signal Theory and Communications, University Carlos III of Madrid, 28911 Madrid, Spain.","IEEE Transactions on Cybernetics","","2019","PP","99","1","11","A new method for example-dependent cost (EDC) classification is proposed. The method constitutes an extension of a recently introduced training algorithm for neural networks. The surrogate cost function is an estimate of the Bayesian risk, where the estimates of the conditional probabilities for each class are defined in terms of a 1-D Parzen window estimator of the output of (discriminative) neural networks. This probability density is modeled with the objective of allowing an easy minimization of a sampled version of the Bayes risk. The conditional probabilities included in the definition of the risk are not explicitly estimated, but the risk is minimized by a gradient-descent algorithm. The proposed method has been evaluated using linear classifiers and neural networks, with both shallow (a single hidden layer) and deep (multiple hidden layers) architectures. The experimental results show the potential and flexibility of the proposed method, which can handle EDC classification under imbalanced data situations that commonly appear in this kind of problems.","","","10.1109/TCYB.2019.2913572","CASI CAM CM Madrid C FEDER EUSF; MacroADOBE MINECO FEDER UE; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8713392","Bayesian risk;example-dependent cost (EDC);imbalanced classification;Parzen windows","Bayes methods;Training;Cost function;Neural networks;Microsoft Windows;Machine learning;Estimation","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Image Super-Resolution via Dense Discriminative Network","J. Ma; X. Wang; J. Jiang","Electronic Information School, Wuhan University, 12390 Wuhan, Hubei China (e-mail: jyma2010@gmail.com); Electronic Information School, Wuhan University, 12390 Wuhan, Hubei China (e-mail: wangxinya@whu.edu.cn); Department of Computer Science and Technology, Harbin Institute of Technology, 47822 Harbin, Heilongjiang China (e-mail: jiangjunjun@hit.edu.cn)","IEEE Transactions on Industrial Electronics","","2019","PP","99","1","1","Deep convolutional neural networks (CNNs) have recently made a considerable achievement in the single-image super-resolution (SISR) problem. Most CNN architectures for SISR incorporate long or short connections to integrate features, and treat them equally. However, they neglect the discrimination of features, and consequently, achieving relatively poor performance. To address this problem, we propose a dense discriminative network that is composed of several aggregation modules (AM). Specifically, the AM merges extraction and integration nodes in a tree structure, which can aggregate features progressively in an efficient way. In particular, we compress and rescale the densely connected information in the aggregation node by modelling the interaction between channels, which shares the same insight with the attention mechanism for improving the discriminative ability of network. Extensive experiments conducted on several publicly available datasets have demonstrated the superiority of our model over state-of-the-art in objective metrics and visual impressions.","","","10.1109/TIE.2019.2934071","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8799028","Super-resolution;convolutional neural network;aggregation;densely connection;attention mechanism","Feature extraction;Image reconstruction;Learning systems;Databases;Task analysis;Convolutional neural nets","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Hierarchical Attention Model for CTR Prediction Based on User Interest","Q. Wang; F. Liu; P. Huang; S. Xing; X. Zhao","School of Information Science and Engineering, Shandong Normal University, Jinan 250014, China (e-mail: wangqq_sdnu@163.com).; School of Information Science and Engineering, Shandong Normal University, Jinan 250014, China (e-mail: lfa_sdnu@163.com).; School of Physics and Electronics, Shandong Normal University, Jinan 250014, China (e-mail: pu.wong@139.com).; School of Information Science and Engineering, Shandong Normal University, Jinan 250014, China (e-mail: gaohan_sdnu@163.com).; School of Information Science and Engineering, Shandong Normal University, Jinan 250014, China, and also with the School of Mathematical Science, Shandong Normal University, Jinan 250014, China (e-mail: zhaoxh_sdnu@163.com).","IEEE Systems Journal","","2019","PP","99","1","10","The prediction of click-through rate is a challenging problem in the aspect of online advertising. Recently, researchers have proposed deep learning-based models that follow a similar embedding and multilayer perceptron paradigm. Although encouraging successes have been obtained, the importance of capturing the latent user interest behind user behavior data was ignored by most of the methods, which has the potential to effectively learn the feature interactions. In this article, we propose an attentive-deep-interest-based model to fill these gaps. Specifically, we capture the interest sequence in the interest extractor layer, and the auxiliary losses are employed to produce the interest state with deep supervision. First, we use the bidirectional long short-term memory network to model the dependence between behaviors. Next, an interest evolving layer is proposed to extract the interest evolving process that is related to the target. Then, the model learns highly nonlinear interactions of features based on stack autoencoders. An experiment is conducted using four real-world datasets. The experimental results show that the proposed model achieves 1.8% improvement in the Amazon datasets than the existing state-of-the-art models.","","","10.1109/JSYST.2019.2943914","National Natural Science Foundation of China; Natural Science Foundation of Shandong Province; Innovation Foundation of Science and Technology Development Center of Ministry of Education and New H3C Group; CERNET Innovation Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8882491","Advertising;attention mechanism;bidirectional long short-term memory (BLSTM) network;click-through rate (CTR)","Advertising;Predictive models;Feature extraction;Frequency modulation;Neural networks;Computational modeling;Task analysis","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Multispectral Change Detection With Bilinear Convolutional Neural Networks","Y. Lin; S. Li; L. Fang; P. Ghamisi","College of Electrical and Information Engineering, Hunan University, Changsha 410082, China, and also with the Key Laboratory of Visual Perception and Artificial Intelligence of Hunan Province, Changsha 410082, China.; College of Electrical and Information Engineering, Hunan University, Changsha 410082, China, and also with the Key Laboratory of Visual Perception and Artificial Intelligence of Hunan Province, Changsha 410082, China.; College of Electrical and Information Engineering, Hunan University, Changsha 410082, China, and also with the Key Laboratory of Visual Perception and Artificial Intelligence of Hunan Province, Changsha 410082, China (e-mail: fangleyuan@gmail.com).; Helmholtz-Zentrum Dresden-Rossendorf, Helmholtz Institute Freiberg for Resource Technology, 09599 Freiberg, Germany.","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","Recently, deep learning has been demonstrated to be an effective tool to detect changes in bitemporal remote sensing images. However, most existing methods based on deep learning obtain the ultimate change map by analyzing the difference image (DI) or the stacked feature vectors of input images, which cannot sufficiently capture the relationship between the two input images to obtain the change information. In this letter, a new method named bilinear convolutional neural networks (BCNNs) is proposed to detect changes in bitemporal multispectral images. The model can be trained end to end with two symmetric convolutional neural networks (CNNs), which are capable of learning the feature representation from bitemporal images and utilizing the relations between the two input images by a linear outer product operation in an effective way. Specifically, two sets of patches obtained from two multispectral images of different times are first input into two CNNs to extract deep features, respectively. Then, the matrix outer product is applied on the output feature maps to obtain the combined bilinear features. Finally, the ultimate change detected result can be produced by applying the softmax classifier on the combined features. Experimental results on real multispectral data sets demonstrate the superiority of the proposed method over several well-known change-detection approaches.","","","10.1109/LGRS.2019.2953754","National Natural Science Fund of China for International Cooperation and Exchanges; National Natural Science Foundation of China; Science and Technology Plan Project Fund of Hunan Province; Science and Technology Talents Program of Hunan Association for Science and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8915802","Bilinear convolutional neural networks (BCNNs) model;change detection;multispectral images.","Feature extraction;Training;Image color analysis;Convolutional neural networks;Remote sensing;Indexes;Kernel","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A novel MI-EEG imaging with the location information of electrodes","M. Li; J. Han; L. Duan","Faculty of Information Technology, Beijing University of Technology, Beijing 100124, China and Beijing Key Laboratory of Computational Intelligence and Intelligent System, Beijing 100124, China.; Faculty of Information Technology, Beijing University of Technology, Beijing 100124, China.; Faculty of Information Technology, Beijing University of Technology, Beijing 100124, China.","IEEE Access","","2019","PP","99","1","1","Combination of the Motor Imagery EEG (MI-EEG) imaging and Deep Convolutional Neural Network is a prospective recognition method in brain computer interface. Nowadays, the frequency or time-frequency analysis has been applied to each channel of MI-EEG signal to obtain a spatio-frequency or time-frequency image, and even the images from several channels are infused to generate a combined image. However, the real position information of channels or electrodes is lost in these MI-EEG images, and this is contradictory to the activation area of MI-tasks. In this paper, the MI period and the frequency band covered by μ and β rhythms are divided into ten time windows and three sub-bands, respectively. Then, for each electrode, Fast Fourier Transform (FFT) is employed to transform each time window to spectrum, and its inverse FFT is calculated for each sub-band. The time-domain powers of ten time windows are averaged for the same sub-band. So, three average powers are generated as the time-frequency features of each electrode of MI-EEG. They are further arranged to the electrode coordinate figure by using Clough-Tocher interpolation algorithm, and a complicated image, in which the time-frequency features are correctly located at the real position of each electrode, is obtained to embody the MI-EEG in detail. Furthermore, a VGG network is modified to perform effective recognition for MI-EEG image, and it is called mVGG. Extensive experiments are conducted on three publicly available datasets, and the 10-folds cross validation accuracies of 88.62%, 92.28% and 96.86% are achieved respectively, and they are higher than that of the state-of-the-art imaging methods. Kappa values and ROC curves demonstrate our method has lower class skew and error costs. The experimental results show that the effectiveness of proposed MI-EEG imaging method, and it is well-matched with mVGG.","","","10.1109/ACCESS.2019.2962740","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8944067","Brain Computer Interface;Convolutional neural network;Interpolation method;Machine Learning;MI-EEG imaging method","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Efficient Convolutional Neural Networks for Depth-Based Multi-Person Pose Estimation","A. Martínez-González; M. Villamizar; O. Canévet; J. Odobez","Idiap Research Institute, Switzerland AND École Polytechnique Fédérale de Lausanne (EPFL), Switzerland.; Idiap Research Institute, Switzerland.; Idiap Research Institute, Switzerland.; Idiap Research Institute, Switzerland AND École Polytechnique Fédérale de Lausanne (EPFL), Switzerland.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Achieving robust multi-person 2D body landmark localization and pose estimation is essential for human behavior and interaction understanding as encountered for instance in HRI settings. Accurate methods have been proposed recently, but they usually rely on rather deep Convolutional Neural Network (CNN) architecture, thus requiring large computational and training resources. In this paper, we investigate different architectures and methodologies to address these issues and achieve fast and accurate multi-person 2D pose estimation. To foster speed, we propose to work with depth images, whose structure contains sufficient information about body landmarks while being simpler than textured color images and thus potentially requiring less complex CNNs for processing. In this context, we make the following contributions. i) we study several CNN architecture designs combining pose machines relying on the cascade of detectors concept with lightweight and efficient CNN structures; ii) to address the need for large training datasets with high variability, we rely on semi-synthetic data combining multi-person synthetic depth data with real sensor backgrounds; iii) we explore domain adaptation techniques to address the performance gap introduced by testing on real depth images; iv) to increase the accuracy of our fast lightweight CNN models, we investigate knowledge distillation at several architecture levels which effectively enhance performance. Experiments and results on synthetic and real data highlight the impact of our design choices, providing insights into methods addressing standard issues normally faced in practical applications, and resulting in architectures effectively matching our goal in both performance and speed.","","","10.1109/TCSVT.2019.2952779","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8895819","Human Pose Estimation;Convolutional Neural Networks;Machine Learning","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"RhythmNet: End-to-end Heart Rate Estimation from Face via Spatial-temporal Representation","X. Niu; S. Shan; H. Han; X. Chen","Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences, Beijing 100190, China, and also with the University of Chinese Academy of Sciences, Beijing 100049, China.; Key Laboratory of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS, Beijing 100190, China, and Peng Cheng Laboratory, Shenzhen, China.; Key Laboratory of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS, Beijing 100190, China and University of Chinese Academy of Sciences, Beijing 100049, China, and he is a member of CAS Center for Excellence in Brain Science and Intelligence Technology.; Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences, Beijing 100190, China, and also with the University of Chinese Academy of Sciences, Beijing 100049, China.","IEEE Transactions on Image Processing","","2019","PP","99","1","1","Heart rate (HR) is an important physiological signal that reflects the physical and emotional status of a person. Traditional HR measurements usually rely on contact monitors, which may cause inconvenience and discomfort. Recently, some methods have been proposed for remote HR estimation from face videos; however, most of them focus on well-controlled scenarios, their generalization ability into less-constrained scenarios (e.g., with head movement, and bad illumination) are not known. At the same time, lacking large-scale HR databases has limited the use of deep models for remote HR estimation. In this paper, we propose an end-to-end RhythmNet for remote HR estimation from the face. In RyhthmNet, we use a spatial-temporal representation encoding the HR signals from multiple ROI volumes as its input. Then the spatial-temporal representations are fed into a convolutional network for HR estimation. We also take into account the relationship of adjacent HR measurements from a video sequence via Gated Recurrent Unit (GRU) and achieves efficient HR measurement. In addition, we build a large-scale multi-modal HR database (named as VIPL-HRVIPL-HR is available at: ), which contains 2,378 visible light videos (VIS) and 752 near-infrared (NIR) videos of 107 subjects. Our VIPL-HR database contains various variations such as head movements, illumination variations, and acquisition device changes, replicating a less-constrained scenario for HR estimation. The proposed approach outperforms the state-of-the-art methods on both the public-domain and our VIPL-HR databases.","","","10.1109/TIP.2019.2947204","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8879658","Remote heart rate estimation;rPPG;spatial-temporal representation;end-to-end learning","Heart rate;Estimation;Webcams;Databases;Skin;Image color analysis;Head","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Non-contact Sleep Stage Detection Using Canonical Correlation Analysis of Respiratory Sound","B. Xue; B. Deng; H. Hong; Z. Wang; X. Zhu; D. D. Feng","Nanjing China 210094 (e-mail: fzhshsh@163.com); Nanjing China (e-mail: dengboya1993@163.com); School of Electronic and Optical Engineering, Nanjing University of Science and Technology, Nanjing, Jiangsu China 210094 (e-mail: hongnju@njust.edu.cn); Sydney Australia (e-mail: zhiyong.wang@sydney.edu.au); School of Electronic and Optical Engineering, Nanjing University of Science and Technology, Nanjing, Jiangsu China (e-mail: zxh_njust@126.com); Department of Electronic and Information Engineering, The Hong Kong Polytechnic University, Hong Kong Hong Kong (e-mail: dagan.feng@sydney.edu.au)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","Respiratory sound is able to differentiate sleep stages and provide a non-contact and cost-effective solution for the diagnosis and treatment monitoring of sleep-related diseases. While most of the existing respiratory sound-based methods focus on a limited number of sleep stages such as Sleep/Wake and Wake/REM (Rapid Eye Movement)/NREM (Non-REM), it is essential to detect sleep stages at a finer level for sleep quality evaluation. In this paper we for the first time study a sleep stage detection method aiming at classifying sleep states into four sleep stages: wake, REM, light sleep and deep sleep from the respiratory sound. In addition to extracting time-domain features, frequency-domain features of respiratory sound, nonlinear features of snoring sound are devised to better characterize snoring related signals of respiratory sound. To effectively fuse the three sets of features, a novel feature fusion technique combining the generalized canonical correlation analysis (CCA) with the ReliefF algorithm is proposed for discriminative feature selection. Final stage detection is achieved with popular classifiers including Decision Tree, Support Vector Machines (SVM), KNearest Neighbor (KNN), and the ensemble classifier. To evaluate our proposed method, we built an in-house dataset which is comprised of 13 nights of sleep audio data from a sleep laboratory. Experimental results indicate that our proposed method outperforms existing related ones and is promising for large-scale non-contact sleep monitoring.","","","10.1109/JBHI.2019.2910566","Key Research and Development Plan of Jiangsu Province; Fundamental Research Funds for the Central Universities; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8688505","Sleep stage detection;nonlinear features;respiratory sound;canonical correlation analysis;machine learning","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Multi-Scale Spatial and Channel-wise Attention for Improving Object Detection in Remote Sensing Imagery","J. Chen; L. Wan; J. Zhu; G. Xu; M. Deng","School of Geosciences and Info-Physics, Central South University, Changsha 410000, China.; School of Geosciences and Info-Physics, Central South University, Changsha 410000, China.; School of Geosciences and Info-Physics, Central South University, Changsha 410000, China.; Exploration and Survey Institute, Wenzhou 325000, China.; School of Geosciences and Info-Physics, Central South University, Changsha 410000, China (e-mail: dengmin@csu.edu.cn).","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","The spatial resolution of remote sensing images is continuously improved by the development of remote sensing satellite and sensor technology. Hence, background information in an image becomes increasingly complex and causes considerable interference to the object detection task. Can we pay as much attention to the object in an image as human vision does? This letter proposes a multi-scale spatial and channel-wise attention (MSCA) mechanism to answer this question. MSCA has two advantages that help improve object detection performance. First, attention is paid to the spatial area related to the foreground, and compared with other channels, more attention is given to the feature channel with a greater response to the foreground region. Second, for objects with different scales, MSCA can generate an attention distribution map that integrates multi-scale information and applies it to the feature map of the deep network. MSCA is a flexible module that can be easily embedded into any object detection model based on deep learning. With the attention exerted by MSCA, the deep neural network can efficiently focus on objects of different backgrounds and sizes in remote sensing images. Experiments show that the mean average precision of object detection is improved after the addition of MSCA to the current object detection model.","","","10.1109/LGRS.2019.2930462","National Natural Science Foundation of China; Scientific Research Fund of Hunan Provincial Education Department; Fundamental Research Funds for the Central Universities of Central South University; Open Research Fund Program of Key Laboratory of Digital Mapping and Land Information Application Engineering; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8807319","Attention mechanism;multi-scale;object detection;remote sensing image;spatial and channel-wise.","Object detection;Remote sensing;Feature extraction;Convolution;Task analysis;Interference;Proposals","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Predicting in-vitro transcription factor binding sites using DNA sequence + shape","Q. Zhang; Z. Shen; D. Huang","Tongji University, 12476 Shanghai, Shanghai China 200092 (e-mail: 472765713@qq.com); SEIE, Tongji University, 12476 Shanghai, Shanghai China 200092 (e-mail: zzuliszhen@163.com); Computer Science Department, Tongji University, Shanghai, ShangHai China (e-mail: dshuang@tongji.edu.cn)","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2019","PP","99","1","1","Discovery of transcription factor binding sites (TFBSs) is essential for understanding the underlying binding mechanisms and cellular functions. Recently, Convolutional neural network (CNN) has succeeded in predicting TFBSs from the primary DNA sequences. In addition to DNA sequences, several evidences suggest that protein-DNA binding is partly mediated by properties of DNA shape. Although many methods have been proposed to jointly account for DNA sequences and shape properties in predicting TFBSs, they ignore the power of the combination of deep learning and DNA sequence + shape. Therefore we develop a deep-learning-based sequence + shape framework (DLBSS) in this paper, which appropriately integrates DNA sequences and shape properties, to better understand protein-DNA binding preference. This method uses a shared CNN to find their common patterns from DNA sequences and their corresponding shape features, which are then concatenated to compute a predicted value. Using 66 in-vitro datasets derived from universal protein binding microarrays (uPBMs), we show that our proposed method DLBSS significantly improves the performance of predicting TFBSs. In addition, we explore the performance of the proposed method when using a deep CNN, and figure out which shape features are important for predicting TFBSs, through a series of experiments.","","","10.1109/TCBB.2019.2947461","China Postdoctoral Science Foundation; National Natural Science Foundation of China; National Science and Technology Major Project for New Generation of Artificial Intelligence; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8869783","Convolutional neural network;DNA sequence + shape;Transcription factor binding sites prediction","Shape;DNA;Kernel;Feature extraction;Proteins;Neural networks;Encoding","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Aggregating Attentional Dilated Features for Salient Object Detection","L. Zhu; J. Chen; X. Hu; C. Fu; X. Xu; J. Qin; P. Heng","South China University of Technology and the Chinese University of Hong Kong.; South China University of Technology.; Chinese University of Hong Kong.; Chinese University of Hong Kong.; School of Computer Science and Engineering at South China University of Technology, and State Key Laboratory of Subtropical Building Science and Guangdong Provincial Key Lab of Computational Intelligence and Cyberspace Information.; Hong Kong Polytechnic University.; Chinese University of Hong Kong and Guangdong Provincial Key Laboratory of Computer Vision and Virtual Reality Technology, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, China.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","This paper presents a novel deep learning model to aggregate the attentional dilated features for salient object detection by exploring the complementary information between the global and local context in a convolutional neural network. There are two technical contributions to our network design. First, we develop an attentional dense atrous (dilated) spatial pyramid pooling (AD-ASPP) module to selectively use the local saliency cues captured by dilated convolutions with a small rate and the global saliency cues captured by dilated convolutions with a large rate. Second, taking the feature pyramid network as the backbone, we develop an aggregation network to integrate the refined features by formulating two consecutive chains of residual learning based modules: one chain from deep to shallow layers while another chain from shallow to deep layers. We evaluate our network on seven widely-used saliency detection benchmarks by comparing it against 21 state-of-the-art methods. Experimental results show that our network outperforms others on all the seven benchmark datasets.","","","10.1109/TCSVT.2019.2941017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8836095","","Feature extraction;Saliency detection;Object detection;Aggregates;Task analysis;Visualization;Benchmark testing","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Superpixel Embedding Network","U. Gaur; B. S. Manjunath","UCSB.; UCSB.","IEEE Transactions on Image Processing","","2019","PP","99","1","1","Superpixel segmentation is a fundamental computer vision technique that finds application in a multitude of high level computer vision tasks. Most state-of-the-art superpixel segmentation methods are unsupervised in nature and thus cannot fully utilize frequently occurring texture patterns or incorporate multiscale context. In this paper, we show that superpixel segmentation can be improved by leveraging the superior modeling power of deep convolutional autoencoders in a fully unsupervised manner. We pose the superpixel segmentation problem as one of manifold learning where pixels that belong to similar texture patterns are assigned near identical embedding vectors. The proposed deep network is able to learn image-wide and dataset-wide feature patterns and the relationships between them. This knowledge is used to segment and group pixels in a way that is consistent with a more global definition of pattern coherence. Experiments demonstrate that the superpixels obtained from the embeddings learned by the proposed method outperform the state-of-theart superpixel segmentation methods for boundary precision and recall values. Additionally, we find that semantic edges obtained from the superpixel embeddings to be significantly better than the contemporary unsupervised approaches.","","","10.1109/TIP.2019.2957937","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8931250","Superpixel;Embedding;Convolutional Neural Networks","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Guest Editorial: Special Section on ""Emerging Privacy and Security Issues brought by Artificial Intelligence in Industrial Informatics""","M. Qiu; H. Dai; A. K. Sangaiah; K. Liang; X. Zheng","Columbia University, 5798 New York, New York United States 10027-6902 (e-mail: qiumeikang@yahoo.com); Macau University of Science and Technology, 58816 Taipa United States 000000 (e-mail: hndai@ieee.org); School of Computing Scie, VELLORE India 632014 (e-mail: arunkumarsangaiah@gmail.com); Department of Computer Science, University of Surrey, 3660 Guildford United Kingdom of Great Britain and Northern Ireland GU2 7XH (e-mail: k.liang@surrey.ac.uk); Sydney Australia 2109 (e-mail: james.zheng@mq.edu.au)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","Artificial Intelligence (AI) based technologies have deeply changed people's daily lives. There are many AI-based applications used in industrial scenarios such as Internet of Things (IoT), smart grids, and edge computing. Although bringing AI into industrial scenarios could improve the performance in many aspects, new security and privacy issues are also introduced consequently. Subsequently, machine learning technologies require a training process which introduces the protection problems in the training data and algorithms. As many machine learning and deep learning models are vulnerable against well-designed adversarial input samples, outsourcing data and algorithms for training will require the integrity of the training data. Also, data privacy of the end users must be protected. On the other hand, traditional solutions for industrial system security could also be enhanced by these AI schemes. The papers in this special section focus on emerging privacy and security issues brought by Artificial Intelligence in industrial informatics.","","","10.1109/TII.2019.2953884","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8903246","","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Training Faster by Separating Modes of Variation in Batch-normalized Models","M. M. Kalayeh; M. Shah","Computer Science, University of Central Florida Department of Electrical Engineering and Computer Science, 209731 Orlando, Florida United States (e-mail: mahdi@eecs.ucf.edu); Center for Research in Computer Vision, University of Central Florida, Orlando, Florida United States 32792 (e-mail: shah@crcv.ucf.edu)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Batch Normalization (BN) is essential to effectively train state-of-the-art deep Convolutional Neural Networks (CNN). It normalizes the layer outputs during training using the statistics of each mini-batch. BN accelerates training procedure by allowing to safely utilize large learning rates and alleviates the need for careful initialization of the parameters. In this work, we study BN from the viewpoint of Fisher kernels that arise from generative probability models. We show that assuming samples within a mini-batch are from the same probability density function, then BN is identical to the Fisher vector of a Gaussian distribution. That means batch normalizing transform can be explained in terms of kernels that naturally emerge from the probability density function that models the generative process of the underlying data distribution. Consequently, it promises higher discrimination power for the batch-normalized mini-batch. However, given the rectifying non-linearities employed in CNN architectures, distribution of the layer outputs show an asymmetric characteristic. Therefore, in order for BN to fully benefit from the aforementioned properties, we propose approximating underlying data distribution not with one, but a mixture of Gaussian densities. Deriving Fisher vector for a Gaussian Mixture Model (GMM), reveals that batch normalization can be improved by independently normalizing with respect to the statistics of disentangled sub-populations. We refer to our proposed soft piecewise version of batch normalization as Mixture Normalization (MN). Through extensive set of experiments on CIFAR-10 and CIFAR-100, using both a 5-layers deep CNN and modern Inception-V3 architecture, we show that mixture normalization reduces required number of gradient updates to reach the maximum test accuracy of the batch normalized model by ∼31%-47% across a variety of training scenarios. Replacing even a few BN modules with MN in the 48-layers deep Inception-V3 architecture is sufficient to not only obtain considerable training acceleration but also better final test accuracy. We show that similar observations are valid for 40 and 100-layers deep DenseNet architectures as well. We complement our study by evaluating the application of mixture normalization to the Generative Adversarial Networks (GANs), where ""mode collapse"" hinders the training process. We solely replace a few batch normalization layers in the generator with our proposed mixture normalization. Our experiments using Deep Convolutional GAN (DCGAN) on CIFAR-10 show that mixture normalized DCGAN not only provides an acceleration of ∼58% but also reaches lower (better) ""Fréchet Inception Distance"" (FID) of 33.35 compared to 37.56 of its batch normalized counterpart.","","","10.1109/TPAMI.2019.2895781","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8627960","Batch Normalization;Convolutional Neural Networks;Generative Probability Models;Gaussian Mixture Model;Fisher Vector","Training;Kernel;Mathematical model;Transforms;Probability density function;Statistics;Acceleration","","","","","","","","","","IEEE","IEEE Early Access Articles"
"WSCNet: Weakly Supervised Coupled Networks for Visual Sentiment Classification and Detection","D. She; J. Yang; M. Cheng; Y. Lai; P. L. Rosin; L. Wang","College of Computer Science, Nankai University, 12538 Tianjin China (e-mail: sherry6656@163.com); College of Computer Science, Nankai University, 12538 Tianjin China (e-mail: yangjufeng@nankai.edu.cn); Computer Science, Nankai University, Tianjin, Tianjin China 300350 (e-mail: cmm@nankai.edu.cn); School of Computer Science and Informatics, Cardiff University, 2112 Cardiff, South Glamorgan United Kingdom of Great Britain and Northern Ireland (e-mail: laiy4@cardiff.ac.uk); Cardiff University, Dept. of Computer Science, Cardiff United Kingdom of Great Britain and Northern Ireland CF24 3AA (e-mail: paul.rosin@cs.cf.ac.uk); National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing China 100864 (e-mail: wangliang@nlpr.ia.ac.cn)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","Automatic assessment of sentiment from visual content has gained considerable attention with the increasing tendency of expressing opinions online. In this paper, we solve the problem of visual sentiment analysis, which is challenging due to the high-level abstraction in the recognition process. Existing methods based on convolutional neural networks learn sentiment representations from the holistic image, despite the fact that different image regions can have different influence on the evoked sentiment. In this paper, we introduce a weakly supervised coupled convolutional network (WSCNet). Our method is dedicated to automatically selecting relevant soft proposals from weak annotations (e.g., global image labels), thereby significantly reducing the annotation burden, and encompasses the following contributions. First, WSCNet detects a sentiment-specific soft map by training a fully convolutional network with the cross spatial pooling strategy in the detection branch. Second, both the holistic and localized information are utilized by coupling the sentiment map with deep features for robust representation in the classification branch. We integrate the sentiment detection and classification branches into a unified deep framework, and optimize the network in an end-to-end way. Through this joint learning strategy, weakly supervised sentiment classification and detection benefit each other. Extensive experiments demonstrate that the proposed WSCNet outperforms the state-of-the-art results on seven benchmark datasets.","","","10.1109/TMM.2019.2939744","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8825564","Visual sentiment analysis;weakly supervised detection;convolutional neural networks","Visualization;Proposals;Task analysis;Feature extraction;Sentiment analysis;Training;Convolutional neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Boundary-weighted Domain Adaptive Neural Network for Prostate MR Image Segmentation","Q. Zhu; B. Du; P. Yan","School of Computer Science, Wuhan University, Wuhan, China.; School of Computer Science and State Key Lab of Information Engineering on Survey, Mapping and Remote Sensing, Wuhan University, Wuhan, China.; Department of Biomedical Engineering and Center for Biotechnology and Interdisciplinary Studies at Rensselaer Polytechnic Institute (RPI), Troy, NY, USA 12180.","IEEE Transactions on Medical Imaging","","2019","PP","99","1","1","Accurate segmentation of the prostate from magnetic resonance (MR) images provides useful information for prostate cancer diagnosis and treatment. However, automated prostate segmentation from 3D MR images faces several challenges. The lack of clear edge between the prostate and other anatomical structures makes it challenging to accurately extract the boundaries. The complex background texture and large variation in size, shape and intensity distribution of the prostate itself make segmentation even further complicated. Recently, as deep learning, especially convolutional neural networks (CNNs), emerging as the best performed methods for medical image segmentation, the difficulty in obtaining large number of annotated medical images for training CNNs has become much more pronounced than ever. Since large-scale dataset is one of the critical components for the success of deep learning, lack of sufficient training data makes it difficult to fully train complex CNNs. To tackle the above challenges, in this paper, we propose a boundary-weighted domain adaptive neural network (BOWDANet). To make the network more sensitive to the boundaries during segmentation, a boundary-weighted segmentation loss is proposed. Furthermore, an advanced boundary-weighted transfer leaning approach is introduced to address the problem of small medical imaging datasets. We evaluate our proposed model on three different MR prostate datasets. The experimental results demonstrate that the proposed model is more sensitive to object boundaries and outperformed other state-of-the-art methods.","","","10.1109/TMI.2019.2935018","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8795525","Image segmentation;prostate MR image;domain adaptation;convolutional neural network;boundaryweighted loss","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Locality-aware GPU Register File","H. Jeon; H. A. Esfeden; N. B. Abu-Ghazaleh; D. Wong; S. Elango","San Jose State University, 7161 San Jose, California United States (e-mail: hyeran.jeon@sjsu.edu); University of California Riverside, 8790 Riverside, California United States (e-mail: hasgh001@ucr.edu); University of California Riverside, 8790 Riverside, California United States (e-mail: nael@cs.ucr.edu); University of California Riverside, 8790 Riverside, California United States (e-mail: danwong@ucr.edu); San Jose State University, 7161 San Jose, California United States (e-mail: sindhuja.ge@gmail.com)","IEEE Computer Architecture Letters","","2019","PP","99","1","1","In many emerging applications such as deep learning, large data set is essential to generate reliable solutions. In these big data workloads, memory latency and bandwidth are the main performance bottlenecks. In this paper, we propose a locality-aware GPU register file that enables data sharing for memory-intensive big data workloads on GPUs without relying on small on-chip memories. We exploit two types of data sharing patterns commonly found from the big data workloads and have warps opportunistically share data in physical registers instead of issuing memory loads separately and storing the same data redundantly in their registers as well as small shared memory. With an extended register file mapping mechanism, our proposed design enables warps to share data by simply mapping to the same physical registers or reconstructing from the data in the register file already. The proposed sharing not only reduces the memory transactions but also further decreases the register file usage. The spared registers make rooms for applying orthogonal optimizations for energy and performance improvement. Our evaluation on two deep learning workloads and matrixMul show that the proposed locality-aware GPU register file achieves over 2× speedup and saves register space up to 57%.","","","10.1109/LCA.2019.2959298","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8931588","Matrix Operations;Convolution Neural Network;GPU","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Hiding Images Within Images","S. Baluja","AI, Google, San Diego, California United States 92121 (e-mail: shumeet@google.com)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","We present a system to hide a full color image inside another of the same size with minimal quality loss to either image. Deep neural networks are simultaneously trained to create the hiding and revealing processes and are designed to specifically work as a pair. The system is trained on images drawn randomly from the ImageNet database, and works well on natural images from a wide variety of sources. Beyond demonstrating the successful application of deep learning to hiding images, we examine how the result is achieved and apply numerous transformations to analyze if image quality in the host and hidden image can be maintained. These transformation range from simple image manipulations to sophisticated machine learning-based adversaries. Two extensions to the basic system are presented that mitigate the possibility of discovering the content of the hidden image. With these extensions, not only can the hidden information be kept secure, but the system can be used to hide even more than a single image. Applications for this technology include image authentication, digital watermarks, finding exact regions of image manipulation, and storing meta-information about image rendering and content.","","","10.1109/TPAMI.2019.2901877","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8654686","Information Hiding;Image Verification;Image Trust","Containers;Neural networks;Image coding;Image reconstruction;Image color analysis;Training;Receivers","","","","1","","CCBY","","","","IEEE","IEEE Early Access Articles"
"A Hierarchical Features-Based Model for Freight Train Defect Inspection","L. Xiao; B. Wu; Y. Hu; J. Liu","NA; NA; NA; NA","IEEE Sensors Journal","","2019","PP","99","1","1","The diagnosis of freight train defects is essential for railway traffic safety. Recently, many freight train defect detection systems based on image processing were developed. However, most of them used hand-engineered features, whose performance was easily degraded by the low image quality and dynamic background. The deep learning method has the merit of extracting robust multi-scale information from images. In this paper, a hierarchical features-based instance detection (HID) model was developed for instance-level defect detections. A deep residual neural network model was firstly used to extract invariant and discriminative features. Then, acquired multi-scale features were processed by a region proposal neural network to generate a coarse defect region and make defect classification. Finally, instance-level predictions were made on the coarse defect region using acquired features. Experiments on the collected dataset that has six types of defects demonstrated the effectiveness of the HID. Additionally, comparisons with the state-of-the-art approaches further demonstrated its promising performance. We also verified its high performance in transfer learning.","","","10.1109/JSEN.2019.2954124","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8908783","Convolution neural network;Defect detection;Freight train;Hierarchical features;Instance prediction","Feature extraction;Neural networks;Convolution;Proposals;Fasteners;Sensors;Data mining","","","","","","","","","","IEEE","IEEE Early Access Articles"
"On Multi-Layer Basis Pursuit, Efficient Algorithms and Convolutional Neural Networks","J. Sulam; A. Aberdam; A. Beck; M. Elad","Biomedical Engineering, Johns Hopkins University, 1466 Baltimore, Maryland United States 21205 (e-mail: jsulam1@jhu.edu); Electrical Engineering, Technion Israel Institute of Technology, Haifa, North Israel (e-mail: aaberdam@campus.technion.ac.il); School of Mathematical Sciences, Tel Aviv University, Tel Aviv, Center Israel (e-mail: becka@tauex.tau.ac.il); Computer Science, Technion Israel Institute of Technology, Haifa, North Israel (e-mail: elad@cs.technion.ac.il)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Parsimonious representations are ubiquitous in modeling and processing information. Motivated by the recent Multi-Layer Convolutional Sparse Coding (ML-CSC) model, we herein generalize the traditional Basis Pursuit problem to a multi-layer setting, introducing similar sparse enforcing penalties at different representation layers in a symbiotic relation between synthesis and analysis sparse priors. We explore different iterative methods to solve this new problem in practice, and we propose a new Multi-Layer Iterative Soft Thresholding Algorithm (ML-ISTA), as well as a fast version (ML-FISTA). We show that these nested first order algorithms converge, in the sense that the function value of near-fixed points can get arbitrarily close to the solution of the original problem. We further show how these algorithms effectively implement particular recurrent convolutional neural networks (CNNs) that generalize feed-forward ones without introducing any parameters. We present and analyze different architectures resulting unfolding the iterations of the proposed pursuit algorithms, including a new Learned ML-ISTA, providing a principled way to construct deep recurrent CNNs. Unlike other similar constructions, these architectures unfold a global pursuit holistically for the entire network. We demonstrate the emerging constructions in a supervised learning setting, consistently improving the performance of classical CNNs while maintaining the number of parameters constant.","","","10.1109/TPAMI.2019.2904255","Israel Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8664165","Multi-Layer Convolutional Sparse Coding;Network Unfolding;Recurrent Neural Networks;Iterative Shrinkage Algorithms","Mathematical model;Convolution;Convolutional codes;Iterative algorithms;Dictionaries;Analytical models","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Implementation and Performance Evaluation of RNS Variants of the BFV Homomorphic Encryption Scheme","A. Qaisar Ahmad Al Badawi; Y. Polyakov; K. M. M. Aung; B. Veeravalli; K. Rohloff","ECE, National University of Singapore Faculty of Engineering, 106228 singapore, singapore Singapore 119077 (e-mail: ahmad@u.nus.edu); Computer Science, New Jersey Institute of Technology Department of Computer Science, 207081 Newark, New Jersey United States 07102-1982 (e-mail: polyakov@njit.edu); Data Storage Institute, A * STAR, Singapore, N/A Singapore (e-mail: mi_mi_aung@dsi.a-star.edu.sg); ECE, Dept of ECE, NUS, Singapore, Singapore Singapore 117576 (e-mail: elebv@nus.edu.sg); Computer Science, New Jersey Institute of Technology Newark College of Engineering, 122389 Newark, New Jersey United States (e-mail: rohloff@njit.edu)","IEEE Transactions on Emerging Topics in Computing","","2019","PP","99","1","1","Homomorphic encryption is an emerging form of encryption that provides the ability to compute on encrypted data without ever decrypting them. Potential applications include aggregating sensitive encrypted data on a cloud environment and computing on the data in the cloud without compromising data privacy. There have been several recent advances resulting in new homomorphic encryption schemes and optimized variants. We implement and evaluate the performance of two optimized variants, namely Bajard-Eynard-Hasan-Zucca (BEHZ) and Halevi-Polyakov-Shoup (HPS), of the most promising homomorphic encryption scheme in CPU and GPU. The most interesting (and also unexpected) result of our performance evaluation is that the HPS variant in practice scales significantly better (typically by 15%-30%) with increase in multiplicative depth of the computation circuit than BEHZ, implying that the HPS variant will always outperform BEHZ for most practical applications. For the multiplicative depth of 98, our fastest GPU implementation performs homomorphic multiplication in 51 ms for 128-bit security settings, which is faster by two orders of magnitude than prior results and already practical for cloud environments supporting GPU computations. Large multiplicative depths supported by our implementations are required for applications involving deep neural networks, logistic regression learning, and other important machine learning problems.","","","10.1109/TETC.2019.2902799","IARPA; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8657794","Secure Computation;Lattice-based Cryptography;Homomorphic Encryption;Residue Number System;BFV SHE;Parallel Processing","Encryption;Graphics processing units;Cloud computing;Cathode ray tubes;Seals","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Roof Classification From 3-D LiDAR Point Clouds Using Multiview CNN With Self-Attention","D. A. Shajahan; V. Nayel; R. Muthuganapathy","Department of Engineering Design, IIT Madras, Chennai 600036, India (e-mail: dimpleshaj@gmail.com).; Department of Electrical Engineering, IIT Madras, Chennai 600036, India.; Department of Engineering Design, IIT Madras, Chennai 600036, India.","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","Classification of light detection and ranging (LiDAR) point clouds of building roofs plays a vital role in various urban management applications and is significant in geographic information systems (GISs) and remote sensing. In this letter, a novel deep learning-based method is proposed for classifying roof point clouds, which outperforms the state-of-the-art methods. We use a view-based method called a multiview convolutional neural network with self-attention (MVCNN-SA), which takes the multiple views of a roof point cloud as input and outputs the category of the roof. Current view-based approaches treat all views equally and simply combine the view features into a single compact 3-D descriptor. Our adaptive weight-learning algorithm, which uses the SA block, discovers the relative importance of each view, thus assigning relative weights to the views. This enhances the shape descriptor, resulting in better classification performance. The effectiveness of the proposed method is then verified on the publicly available data set--RoofN3D--by comparing it with the current state-of-the-art methods.","","","10.1109/LGRS.2019.2945886","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8897042","Airborne laser scan (ALS);light detection and ranging (LiDAR);multiview convolutional neural network with self-attention (MVCNN-SA);point clouds;roof classification;self-attention","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Co-Prediction based Compression Scheme for Correlated Images","W. Yin; Y. Shi; W. Zuo; X. Fan","Computer Science and Technology, Harbin Institute of Technology, 47822 Harbin China 150001 (e-mail: ywb@hit.edu.cn); Faculty of Information Technology, Beijing University of Technology, 12496 Beijing China (e-mail: syhzm@bjut.edu.cn); Computer Science and Technology, Harbin Institute of Technology, 47822 Harbin, Heilongjiang China (e-mail: wmzuo@gmail.com); Computer Science and Technology, Harbin Institute of Technology, 47822 Harbin, Heilongjiang China (e-mail: fxp@hit.edu.cn)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","Deep learning has achieved a preliminary success in image compression due to the ability to learn the nonlinear spaces with compact features that training samples belong to. Unfortunately, it is not straightforward for the network based image compression methods to code multiple highly related images. In this paper, we propose a co-prediction based image compression (CPIC) which uses the multi-stream autoencoders to collaboratively code the multiple highly correlated images by enforcing the co-reference constraint on the multi-stream features. Patch samples fed into the multi-stream autoencoder, are generated through corresponding patch matching under permutation, which helps the autoencoder to learn the relationship among corresponding patches from the correlated images. Each stream network consists of encoder, decoder, importance map network and binarizer. In order to guide the allocation of local bit rate of the binary features, the important map network is employed to guarantee the compactness of learned features. A proxy function is used to make the binary operation for the code layer of the autoencoder differentiable. Finally, the network optimization is formulated as a rate distortion optimization. Experimental results prove that the proposed compression method outperforms JPEG2000 up to 1.5dB in terms of PSNR.","","","10.1109/TMM.2019.2949393","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8882275","Autoencoder;Correlated Images;Image Compression;Rate Distortion Optimization;Multi-Stream Networks","Image coding;Decoding;Transforms;Convolutional codes;Optimization;Transform coding;Image reconstruction","","","","","","","","","","IEEE","IEEE Early Access Articles"
"On Reliable Neural Network Sensorimotor Control in Autonomous Vehicles","A. Plebe; M. Da Lio; D. Bortoluzzi","Department of Information Engineering and Computer Science, University of Trento, 38122 Trento, Italy (e-mail: alice.plebe@unitn.it).; Department of Industrial Engineering, University of Trento, 38122 Trento, Italy.; Department of Industrial Engineering, University of Trento, 38122 Trento, Italy.","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","12","This paper deals with (deep) neural network implementations of sensorimotor control for automated driving. We show how to construct complex behaviors by re-using elementary neural network building blocks that can be trained and tested extensively; one of our goals is to mitigate the ``black box'' and verifiability issues that affect end-to-end trained networks. By structuring complex behaviors within a subsumption architecture, we retain the ability to learn (mostly at motor primitives level) with the ability to create complex behaviors by subsuming the (well-known) learned elementary perception-action loops. The learning process itself is simplified, since the agent needs only to learn elementary behaviors. At the same time, the structure imposed with the subsumption architecture ensures that the agent behaves in predictable ways (e.g., treating all obstacles uniformly). We demonstrate these ideas for longitudinal obstacle avoidance behavior, but the proposed approach can also be adapted to other situations.","","","10.1109/TITS.2019.2896375","European Commission through the EU Horizon 2020 Dreams4Cars Research and Innovation Action; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8643729","Autonomous vehicles;neural networks;longitudinal control;channel coding;layered control;subsumption architecture.","Neural networks;Autonomous vehicles;Reliability;Computer architecture;Safety;Automobiles;ISO Standards","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"LSTM Based Auto-Encoder Model for ECG Arrhythmias Classification","B. Hou; J. Yang; P. Wang; R. Yan","School of Instrument Science and Engineering Southeast University Nanjing, China.; School of Instrument Science and Engineering Southeast University Nanjing, China.; School of Instrument Science and Engineering Southeast University Nanjing, China.; School of Instrument Science and Engineering Southeast University Nanjing, China.","IEEE Transactions on Instrumentation and Measurement","","2019","PP","99","1","1","This paper introduces a novel deep learning-based algorithm that integrates a long short-term memory (LSTM) based auto-encoder network with support vector machine (SVM) for ECG arrhythmias classification. The LSTM based auto-encoder network (LSTM-AE) is used to learn the features from ECG arrhythmias signals and the SVM is used to classify those signals from the learned features. The LSTM-AE consists of an encoder model, which extracts high-level feature information from ECG arrhythmias signals through LSTM network, and a decoder model which outputs reconstruct ECG arrhythmias signals from high-level features through LSTM network. Experiments show that the proposed method can learn better features than traditional method without any prior knowledge, presenting a good potential for ECG arrhythmias classification. In classification of five heartbeats types, including normal, left bundle branch block (LBBB), right bundle branch block (RBBB), atrial premature complexes (APC), premature ventricular contractions (PVC), the proposed method achieved average accuracy, sensitivity, and specificity of 99.74%, 99.35% and 99.84%, respectively, in the beat-based cross-validation approach, and 85.20%, 62.99% and 90.75%, respectively, in the record-based cross-validation approach, in public MIT-BIH arrhythmia database. While based on the AAMI standards, the proposed method achieved average accuracy, sensitivity, and specificity of 99.45%, 98.63% and 99.66%, respectively, in the beat-based cross-validation approach.","","","10.1109/TIM.2019.2910342","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8688435","Electrocardiogram (ECG);heartbeat arrhythmia;cardiovascular diseases;recurrent neural networks (RNNs);auto-encoder;support vector machine","","","","","3","","","","","","IEEE","IEEE Early Access Articles"
"On Symbiosis of Attribute Prediction and Semantic Segmentation","M. M. Kalayeh; M. Shah","Center for Research in Computer Vision, University of Central Florida Department of Electrical Engineering and Computer Science, 209731 Orlando, Florida United States (e-mail: mahdi@eecs.ucf.edu); Center for Research in Computer Vision, University of Central Florida, Orlando, Florida United States 32792 (e-mail: shah@crcv.ucf.edu)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Attributes are semantically meaningful characteristics whose applicability widely crosses category boundaries. They are particularly important in describing and recognizing concepts for which no explicit training example is given, e.g., zero-shot learning. Additionally, since attributes are human describable, they can be used for efficient human-computer interaction. In this paper, we propose to employ semantic segmentation to improve person-related attribute prediction. The core idea lies in the fact that many attributes describe local properties. In other words, the probability of an attribute to appear in an image is far from being uniform in the spatial domain. We build our attribute prediction model jointly with a deep semantic segmentation network. This harnesses the localization cues learned by the semantic segmentation to guide the attention of the attribute prediction to the regions where different attributes naturally show up. As a result of this approach, in addition to prediction, we are able to localize the attributes despite merely having access to image-level labels (weak supervision) during training. We first propose semantic segmentation-based pooling and gating, respectively denoted as SSP and SSG. In the former, the estimated segmentation masks are used to pool the final activations of the attribute prediction network, from multiple semantically homogeneous regions. This is in contrast to global average pooling which is agnostic with respect to where in the spatial domain activations occur. In SSG, the same idea is applied to the intermediate layers of the network. Specifically, we create multiple copies of the internal activations. In each copy, only values that fall within a certain semantic region are preserved while outside of that, activations are suppressed. This mechanism allows us to prevent pooling operation from blending activations that are associated with semantically different regions. SSP and SSG, while effective, impose heavy memory utilization since each channel of the activations is pooled/gated with all the semantic segmentation masks. To circumvent this, we propose Symbiotic Augmentation (SA), where we learn only one mask per activation channel. SA allows the model to either pick one, or combine (weighted superposition) multiple semantic maps, in order to generate the proper mask for each channel. SA simultaneously applies the same mechanism to the reverse problem by leveraging output logits of attribute prediction to guide the semantic segmentation task. We evaluate our proposed methods for facial attributes on CelebA and LFWA datasets, while benchmarking WIDER Attribute and Berkeley Attributes of People for whole body attributes. Our proposed methods achieve superior results compared to the previous works. Furthermore, we show that in the reverse problem, semantic face parsing significantly improves when its associated task is jointly learned, through our proposed Symbiotic Augmentation, with facial attribute prediction. We confirm that when few training instances are available, indeed image-level facial attribute labels can serve as an effective source of weak supervision to improve semantic face parsing. That reaffirms the need to jointly model these two interconnected tasks.","","","10.1109/TPAMI.2019.2956039","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8913587","Attribute Prediction;Semantic Segmentation;Semantic Gating;Facial Attributes;Person Attributes","Semantics;Task analysis;Image segmentation;Facial features;Face;Training;Dogs","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Adaptive Region Proposal with Channel Regularization for Robust Object Tracking","X. Lu; C. Ma; B. Ni; X. Yang","School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University. C. Ma is also with MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Institute for Advanced Communication and Data Science, Shanghai Jiao Tong University, Shanghai 200240, China.; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University. C. Ma is also with MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Institute for Advanced Communication and Data Science, Shanghai Jiao Tong University, Shanghai 200240, China.; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University. C. Ma is also with MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Institute for Advanced Communication and Data Science, Shanghai Jiao Tong University, Shanghai 200240, China.; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University. C. Ma is also with MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Institute for Advanced Communication and Data Science, Shanghai Jiao Tong University, Shanghai 200240, China.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","In this paper, we propose an adaptive region proposal scheme with feature channel regularization to facilitate robust object tracking. We consider tracking as a linear regression problem and an ensemble of correlation filters is trained online to distinguish the foreground target from the background. Further, we integrate adaptively learned region proposals into an enhanced two-stream tracking framework based on correlation filters. For the tracking stream, we learn two-stage cascade correlation filters on deep convolutional features to ensure competitive tracking performance. For the detection stream, we employ adaptive region proposals, which are effective in recovering target objects from tracking failures caused by heavy occlusion or out-of-view movement. In contrast to traditional tracking-bydetection methods using random samples or sliding windows, we perform target re-detection over adaptively learned region proposals. Since region proposals naturally take the objectness information into account, we show that the proposed adaptive region proposals can handle the challenging scale estimation problem as well. In addition, we observe the channel redundancy and noisy of feature representation, especially for the convolutional features. Thus, we apply a channel regularization to the correlation filter learning. Extensive experimental validations on OTB, VOT and UAV-123 datasets demonstrate that the proposed method performs favorably against state-of-the-art tracking algorithms.","","","10.1109/TCSVT.2019.2944654","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8853333","Adaptive region proposals;channel regularization;correlation filters;robust object tracking","Target tracking;Correlation;Proposals;Visualization;Estimation;Object tracking","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Novel Siamese-based Approach for Scene Change Detection with Applications to Obstructed Routes in Hazardous Environments","M. Santana; L. Passos; T. Moreira; D. Colombo; V. H. C. De Albuquerque; J. Papa","Computer Science, UNESP, 28108 Sao Paulo, SP Brazil (e-mail: marcoscleison.unit@gmail.com); Computer Science, UNESP, 28108 Sao Paulo, SP Brazil (e-mail: leandro.passos@unesp.br); Computer Science, UNESP, 28108 Sao Paulo, SP Brazil (e-mail: thierryping@gmail.com); R&D, Petrobas Paulinia Refinery, 519699 Paulinia, State of São Paulo Brazil (e-mail: colombo.danilo@petrobras.com.br); Post-Graduation Program in Applied Informatics, Universidade de Fortaleza, 28128 Fortaleza, CE Brazil (e-mail: victor.albuquerque@unifor.br); Computer Science, UNESP, 28108 Sao Paulo, SP Brazil (e-mail: joao.papa@unesp.br)","IEEE Intelligent Systems","","2019","PP","99","1","1","The demand for automatic scene change detection has massively increased in the last decades due to its importance regarding safety and security issues. Although deep learning techniques have provided significant enhancements in the field, such methods must learn which object belongs to the foreground or background beforehand. In this paper, we proposed an approach that employs siamese U-Nets to address the task of change detection, such that the model learns to perform semantic segmentation using background reference frames only. Therefore, any object that comes up into the scene defines a change. The experimental results showed the robustness of the proposed model over the well-known public dataset CDNet2014. Additionally, we also considered a private dataset called ""PetrobrasROUTES"", which comprises obstruction or abandoned objects in escape routes in hazardous environments. Moreover, the experiments showed that the proposed approach is more robust to noise and illumination changes.","","","10.1109/MIS.2019.2949984","Petrobras; Fundacao de Amparo a Pesquisa do Estado de Sao Paulo; Conselho Nacional de Desenvolvimento Cientifico e Tecnologico; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8887271","Scene Change Detection;Siamese Convolutional Neural Networks;U-Nets;Route Obstruction Detection","Decoding;Image segmentation;Semantics;Training;Neural networks;Intelligent systems;Task analysis","","","","","","","","","","IEEE","IEEE Early Access Articles"
"High-quality Textured 3D Shape Reconstruction with Cascaded Fully Convolutional Networks","Z. Liu; Y. Cao; Z. Kuang; L. Kobbelt; S. Hu","Computer Science and Techology, Tsinghua University Department of Computer Science and Technology, 213644 Beijing, Beijing China 100084 (e-mail: lzhengning@gmail.com); School of Computer Science and Technology, Tsinghua University, Beijing, Beijing China (e-mail: caoyanpei@gmail.com); Computer Science and Technology, Tsinghua University, 12442 Beijing, Beijing China (e-mail: kzf15@mails.tsinghua.edu.cn); Computer Graphics Group, RWTH Aachen University, Aachen, NRW Germany 52074 (e-mail: kobbelt@cs.rwth-aachen.de); Computer Science and Technology, Tsinghua University, Beijing, Beijing China 100084 (e-mail: shimin@tsinghua.edu.cn)","IEEE Transactions on Visualization and Computer Graphics","","2019","PP","99","1","1","We present a learning-based approach to reconstructing high-resolution three-dimensional (3D) shapes with detailed geometry and high-fidelity textures. Albeit extensively studied, algorithms for 3D reconstruction from multi-view depth-and-color (RGB-D) scans are still prone to measurement noise and occlusions; limited scanning or capturing angles also often lead to incomplete reconstructions. Propelled by recent advances in 3D deep learning techniques, in this paper, we introduce a novel computation and memory efficient cascaded 3D convolutional network architecture, which learns to reconstruct implicit surface representations as well as the corresponding color information from noisy and imperfect RGB-D maps. The proposed 3D neural network performs reconstruction in a progressive and coarse-to-fine manner, achieving unprecedented output resolution and fidelity. Meanwhile, an algorithm for end-to-end training of the proposed cascaded structure is developed. We further introduce Human10, a newly created dataset containing both detailed and textured full body reconstructions as well as corresponding raw RGB-D scans of 10 subjects. Qualitative and quantitative experimental results on both synthetic and real-world datasets demonstrate that the presented approach outperforms existing state-of-the-art work in terms of visual quality and accuracy of reconstructed models.","","","10.1109/TVCG.2019.2937300","Joint NSFC-DFG Research Program; National Natural Science Foundation of China; China Postdoctoral Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812900","high-fidelity reconstruction;texture reconstruction;3D vision;cascaded architecture","Three-dimensional displays;Shape;Image reconstruction;Geometry;Image color analysis;Solid modeling;Surface reconstruction","","","","","","","","","","IEEE","IEEE Early Access Articles"
"State-Aware Rate Adaptation for UAVs by Incorporating On-Board Sensors","S. He; W. Wang; H. Yang; Y. Cao; T. Jiang; Q. Zhang","School of Electronic Information and Communications, Huazhong University of Science and Technology, 12443 Wuhan, Hubei China (e-mail: shiyue_he@hust.edu.cn); School of Electronic Information and Communications, Huazhong University of Science and Technology, 12443 Wuhan, Hubei China (e-mail: gswwang@connect.ust.hk); School of Electronic Information and Communications, Huazhong University of Science and Technology, 12443 Wuhan, Hubei China (e-mail: hangyang@hust.edu.cn); Huazhong University of Science and Technology, Wuhan, Hubei China 430074 (e-mail: ycao@hust.edu.cn); School of Electronics Information and Communications Engineering, Huazhong University of Science and Technology, Wuhan, Hubei China 430074 (e-mail: Tao.Jiang@ieee.org); Department of Computer Science and Engineering, Hong Kong University of Science and Technology, 58207 Kowloon, Hong Kong Hong Kong (e-mail: qianzh@cse.ust.hk)","IEEE Transactions on Vehicular Technology","","2019","PP","99","1","1","Nowadays unmanned aerial vehicles (UAVs) are being widely applied to a wealth of civil and military applications. Robust and high-throughput wireless communication is the crux of these UAV applications. Yet, air-to-ground links suffer from time-varying channels induced by the agile mobility and dynamic environments. Rate adaptation algorithms are generally used to choose the optimal data rate based on the current channel conditions. State-of-the-art approaches leverage physical layer information for rate adaptation, and they work well under certain conditions. However, the above protocols still have limitation under constantly changing flight states and environments for airto- ground links. To solve this problem, we propose StateRate, a state-optimized rate adaptation algorithm that fully exploits the characteristics of UAV systems using a hybrid deep learning model. The key observation is that the rate adaptation strategy needs to be adjusted according to motion-dependent channel models, which can be reflected by flight states. In this work, the rate adaptation protocol is enhanced with the help of the on-board sensors in UAVs. To make full use of the sensor data, we introduce a learning-based prediction module by leveraging the internal state to dynamically store temporal features under variable flight states. We also present an online learning algorithm by employing the pre-trained model that adapts the rate adaptation algorithm to different environments. We implement our algorithm on a commercial UAV platform and evaluate it in various environments. The results demonstrate that our system outperforms the best-known rate adaptation algorithm up to 53% in terms of throughput when the velocity is $2-6 \; m/s$.","","","10.1109/TVT.2019.2950285","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8886362","Rate adaptation;unmanned aerial vehicles (UAVs);on-board sensor fusion","Sensors;Heuristic algorithms;Prediction algorithms;Unmanned aerial vehicles;Receivers;Throughput;Transmitters","","","","","","","","","","IEEE","IEEE Early Access Articles"
"All-in-One: Emotion, Sentiment and Intensity Prediction using a Multi-task Ensemble Framework","S. Akhtar; D. Ghosal; A. Ekbal; P. Bhattacharyya; S. Kurohashi","Computer Science and Engineering, Indian Institute of Technology Patna, 250259 Patna, Bihar India (e-mail: shad.akhtar@gmail.com); Computer Science and Engineering, Indian Institute of Technology Patna, 250259 Patna, Bihar India (e-mail: deepanwayedu@gmail.com); Department of Computer Science and Engineering, IIT Patna, Patna, Bihar India 800013 (e-mail: asif.ekbal@gmail.com); Computer Science and Engineering, Indian Institute of Technology Patna, 250259 Patna, Bihar India (e-mail: aa@gmail.com); Graduate School of Informatics, Kyoto University Graduate School of Informatics, 304594 Kyoto, Kyoto Japan (e-mail: 12@gmail.com)","IEEE Transactions on Affective Computing","","2019","PP","99","1","1","We propose a multi-task ensemble framework that jointly learns multiple related problems. The ensemble model aims to leverage the learned representations of three deep learning models (i.e., CNN, LSTM and GRU) and a hand-crafted feature representation for the predictions. Through multi-task framework, we address four problems of emotion and sentiment analysis, i.e., ""emotion classification & intensity"", ""valence, arousal & dominance for emotion"", ""valence & arousal for sentiment"", and ""3-class categorical & 5-class ordinal classification for sentiment"". The underlying problems cover two granularity (i.e., coarse-grained and fine-grained) and a diverse range of domains (i.e., tweets, Facebook posts, news headlines, blogs, letters etc.). Experimental results suggest that the proposed multi-task framework outperforms the single-task frameworks in all experiments.","","","10.1109/TAFFC.2019.2926724","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8756111","Emotion Analysis;Sentiment Analysis;Intensity Prediction;Valence Prediction;Arousal Prediction;Dominance Prediction;Coarse-grained Emotion Analysis;Fine-grained Emotion Analysis;Fine-grained Sentiment Analysis;Multi-Layer Perceptron;Ensemble","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Time Series Prediction Using Sparse Autoencoder and High-order Fuzzy Cognitive Maps","K. Wu; J. Liu; P. Liu; S. Yang","Xidian University, Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, Xi'an, Shaanxi China 710071 (e-mail: kaiwu@stu.xidian.edu.cn); Xidian University, Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, Xi'an, Shaanxi China 710071 (e-mail: neouma@163.com); Xidian University, School of Artificial Intelligence, Xi an, Shaanxi China (e-mail: 523184685@qq.com); Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education, Xidian University, 47905 Xi'an, Shaanxi China 710071 (e-mail: yangshanchaoysc@gmail.com)","IEEE Transactions on Fuzzy Systems","","2019","PP","99","1","1","The problem of time series prediction based on fuzzy cognitive maps (FCMs) is unresolved. Although many methods have been proposed to cope with this issue, the performance of these methods is far from satisfactory. Traditional FCM-based predictors have three limitations. First, current feature extraction operators are incapable of learning good representations of original time series. Second, current methods use just the output of FCMs to predict the next value; they do not directly utilize the important information of the latent features. Third, current FCM-based predictors optimize each component individually, thereby leading to low prediction accuracy. For example, these methods first optimize the feature extraction operator and then learn the FCMs from the latent features; they do not simultaneously optimize the whole prediction model. In this paper, we develop a framework based on a sparse autoencoder (SAE) and a high-order FCM (HFCM) to address the time series prediction problem; we refer this framework as SAE-FCM. To overcome the first limitation of current methods, an SAE is employed to extract features from original time series. Unlike current FCM-based predictors, our method combines the output of both an SAE and an HFCM to calculate the predicted value, thereby overcoming the second limitation of traditional FCM-based predictors. In an application of the idea of “fine-tuning” in deep learning, the weights of SAE-FCM can be updated by the batch gradient descent method if the prediction errors are great. Thus, we can optimize SAE-FCM as a whole and overcome the third limitation. We validate the performance of SAE-FCM on ten datasets. Compared with the experimental results obtained by using state-of-the-art methods, the experimental results obtained by using SAE-FCM demonstrate the effectiveness of our method. Extensive experiments also show that SAE-FCM can effectively overcome the above limitations.","","","10.1109/TFUZZ.2019.2956904","Key Program of Fundamental Research Project of Natural Science of Shaanxi Province China; General Program of National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8918289","Fuzzy cognitive maps;Time series prediction;Sparse autoencoder;Fuzzy time series","Time series analysis;Predictive models;Feature extraction;Prediction algorithms;Computational modeling;Numerical models;Fuzzy cognitive maps","","","","","","","","","","IEEE","IEEE Early Access Articles"
"SAT: Single-shot Adversarial Tracker","Q. Wu; H. Wang; Y. Liu; L. Zhang; X. Gao","Computer Science Department, Xiamen University, 12466 Xiamen, Fujian China (e-mail: qiangwu@stu.xmu.edu.cn); Computer Science, Xiamen University, 12466 Xiamen China 361005 (e-mail: wang.hanzi@gmail.com); Computer Science Department, Xiamen University, 12466 Xiamen, Fujian China (e-mail: liuyi_xmu@163.com); Department of Computer and Information Science, University of Macau, 59193 Taipa, Macau China (e-mail: lmzhang@umac.mo); School of Electronic Engineering, Xidian University, 47905 Xian China 710071 (e-mail: xbgao@mail.xidian.edu.cn)","IEEE Transactions on Industrial Electronics","","2019","PP","99","1","1","Deep learning based tracking methods have shown favorable performance on multiple benchmarks. However, most of these methods are not designed for realtime video surveillance systems due to the complex online optimization process. In this paper, we propose a single-shot adversarial tracker (SAT) to efficiently locate objects of interest in surveillance videos. Specifically, we propose a lightweight convolutional neural network based generator, which fuses multi-layer feature maps to accurately generate the target probability map (TPM) for tracking. To more effectively train the generator, an adversarial learning framework is presented. During the online tracking stage, the learned TPM generator can be directly employed to generate the target probability map corresponding to the searching region in a single shot. The proposed SAT can lead to the average tracking speed of 212 FPS on a single GPU, while still achieving the favorable performance on several popular benchmarks. Furthermore, we also present a variant of SAT by considering both scale estimation and online updating in SAT, which achieves better accuracy than SAT while still maintaining very fast tracking speed (i.e., exceeding 100 FPS).","","","10.1109/TIE.2019.2955411","Multi-Year Research Grants of the University of Macau; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8917917","Visual object tracking;generative adversarial network;target probability map","Target tracking;Generators;Visualization;Task analysis;Real-time systems;Gallium nitride;Benchmark testing","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Improving Night-Time Pedestrian Retrieval with Distribution Alignment and Contextual Distance","M. Ye; Y. Cheng; X. Lan; H. Zhu","Hong Kong Hong Kong 999077 (e-mail: mangye16@gmail.com); Singapore Singapore 138632 (e-mail: chengyista@gmail.com); Department of Computer Science, Hong Kong Baptist Univ, Hong Kong Hong Kong 999077 (e-mail: xiangyuanlan@life.hkbu.edu.hk); Singapore Singapore 138632 (e-mail: hongyuanzhu.cn@gmail.com)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","Night-time pedestrian retrieval is a cross-modality retrieval task of retrieving person images between day-time visible images and night-time thermal images. It is a very challenging problem due to modality difference, camera variations and person variations, but it plays an important role in night-time video surveillance. Existing cross-modality retrieval usually focuses on learning modality sharable feature representations to bridge the modality gap. In this paper, we propose to utilize auxiliary information to improve retrieval performance, which consistently improves the performance with different baseline loss functions. Our auxiliary information contains two major parts: cross-modality feature distribution and contextual information. The former aligns the cross-modality feature distributions between two modalities to improve the performance, and the latter optimizes the cross-modality distance measurement with the contextual information. We also demonstrate that abundant annotated visible pedestrian images, which are easily accessible, helps to improve the cross-modality pedestrian retrieval as well. The proposed method is featured in two aspects: the auxiliary information does not need additional human intervention or annotation; it learns discriminative feature representations in an end-to-end deep learning manner. Extensive experiments on two cross-modality pedestrian retrieval datasets demonstrate the superiority of the proposed method, achieving much better performance than the state-of-the-arts.","","","10.1109/TII.2019.2946030","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8861378","Pedestrian Retrieval;Cross-modality;Distribution Alignment;Contextual Distance","Cameras;Training;Informatics;Task analysis;Face recognition;Neural networks;Visualization","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Multi-dimension End-to-End CNN Model for Rotating Devices Fault Diagnosis on High Speed Train Bogie","L. Kou; Y. Qin; X. Zhao; X. Chen","Beijing, Beijing China 100044 (e-mail: koull01@163.com); Beijing, Beijing China (e-mail: yqin@bjtu.edu.cn); Beijing, Beijing China (e-mail: 13118404@bjtu.edu.cn); Beijing, Beijing China (e-mail: 12120823@bjtu.edu.cn)","IEEE Transactions on Vehicular Technology","","2019","PP","99","1","1","With improvement of sensor techniques, and the urgent requirement of automatic fault diagnosis technologies, the intelligent perception system on high speed train is more popular than ever before. It records the devices' state information through a sensor network, and services for further analysis. However, Traditional machine learning algorithms are usually constrained by massive multi-sensor data and knowledge-based feature extraction in fault diagnosis. Therefore, this paper extended fault diagnosis methodology into tensor space to deal with multi-sensor monitoring data and take full use of available information. Moreover, the convolutional neural network (CNN) is used for automatic feature learning and classification without human intervention. The effectiveness and efficiency are validated by dataset of rolling element bearings obtained in lab and real-use case. Three features can be highlighted. First of all, the proposed model showed a good adaptability and high efficiency under various working condition by taking full use of the multi-sensor data. It has powerful ability in accuracy and convergence speed. Secondly, it is not as sensitive to data quantity as other deep learning algorithms do. Such superior characteristic made the model more suitable for practical application, because of the insufficient failure data. At last, it is an intelligent End-to-End model, performing automatic fault diagnosis without manual intervention and suitable for real-use case.","","","10.1109/TVT.2019.2955221","Open Research Fund Program of Beijing Key Laboratory of Performance Guarantee on Urban Rail Transit Vehicles; National Basic Research Program of China (973 Program); Open Research Fund Program of the State Key Laboratory of Rail Traffic Control and Safety; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8910402","Multi-sensor data;Automatic fault diagnosis;Bogie;End-to-End model;CNN","Fault diagnosis;Vibrations;Data models;Gears;Monitoring;Temperature sensors","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Neumann Networks for Linear Inverse Problems in Imaging","D. Gilton; G. Ongie; R. Willett","Department of Electrical and Computer Engineering, University of Wisconsin, Madison, WI, 53706 USA (e-mail: gilton@wisc.edu); Department of Statistics, University of Chicago, Chicago, IL, 60637 USA (e-mail: gongie@uchicago.edu); Department of Statistics and Computer Science, University of Chicago, Chicago, IL, 60637 USA (e-mail: willett@uchicago.edu)","IEEE Transactions on Computational Imaging","","2019","PP","99","1","1","Many challenging image processing tasks can be described by an ill-posed linear inverse problem: deblurring, deconvolution, inpainting, compressed sensing, and superresolution all lie in this framework. Traditional inverse problem solvers minimize a cost function consisting of a data-fit term, which measures how well an image matches the observations, and a regularizer, which reflects prior knowledge and promotes images with desirable properties like smoothness. Recent advances in machine learning and image processing have illustrated that it is often possible to learn a regularizer from training data that can outperform more traditional regularizers. We present an end-toend, data-driven method of solving inverse problems inspired by the Neumann series, which we call a Neumann network. Rather than unroll an iterative optimization algorithm, we truncate a Neumann series which directly solves the linear inverse problem with a data-driven nonlinear regularizer. The Neumann network architecture outperforms traditional inverse problem solution methods, model-free deep learning approaches, and state-of-theart unrolled iterative methods on standard datasets. Finally, when the images belong to a union of subspaces and under appropriate assumptions on the forward model, we prove there exists a Neumann network configuration that well-approximates the optimal oracle estimator for the inverse problem and demonstrate empirically that the trained Neumann network has the form predicted by theory.","","","10.1109/TCI.2019.2948732","National Science Foundation; Air Force Office of Scientific Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8878159","","Inverse problems;Training;Neural networks;Training data;Imaging;Iterative methods;Image reconstruction","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Contextualized CNN for Scene-Aware Depth Estimation from Single RGB Image","W. Song; S. Li; J. Liu; A. Hao; Q. Zhao; H. Qin","State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, 12633 beijing, APAC (Asia Pacific, Australia) China (e-mail: songwenfenga@gmail.com); Computer Science and Engineering School, Beihang University, Beijing China 100191 (e-mail: lishuai@buaa.edu.cn); State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, 12633 Beijing China (e-mail: liujiu@buaa.edu.cn); Computer Science, State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing, Beijing China (e-mail: ham@buaa.edu.cn); State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, 12633 Beijing China (e-mail: zhaoqp@buaa.edu.cn); Computer Science, Stony Brook University, 12301 Stony Brook, New York United States (e-mail: qin@cs.stonybrook.edu)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","Directly benefited from deep learning techniques, depth estimation from single image has gained great momentum in recent years. However, most of the existing approaches treat depth prediction as an isolated problem without taking into consideration high-level semantic context information, which results in inefficient utilization of training dataset and unavoidably requires a large number of captured depth data during the training phase. To ameliorate, this paper develops a novel scene-aware contextualized convolution neural network (CCNN), which characterizes the semantic context relationship at the class-level and refines depth at the pixel-level. Our newly-proposed CCNN is built upon the intrinsic exploitation of context-dependent depth association, including inner-object continuous depth and inter-object depth change priors nearby. Specifically, rather than conducting regression on depth in single CNN, we make the first attempt to integrate both class-level and pixel-level conditional random fields (CRFs) based probabilistic graphical model into the powerful CNN framework to simultaneously learn different-level features within the same CNN layer. With our CCNN, the former model will guide the latter one to learn the contextualized RGB-Depth mapping. Hence, CCNN has desirable properties in both class-level integrity and pixel-level discrimination, which makes it ideal to share such two-level convolutional features in parallel during the end-to-end training with the commonly-used back-propagation algorithm. We conduct extensive experiments and comprehensive evaluations on public benchmarks involving various indoor and outdoor scenes, and all the experiments confirm that, our method outperforms the state-of-the-art depth estimation methods, especially for the cases where only small-scale training data are readily available.","","","10.1109/TMM.2019.2941776","Fundamental Research Funds for the Central Universities and Beijing Natural Science Foundation-Haidian Primitive Innovation Joint Fund; National Key R and D Program of China; Applied Basic Research Program of Qingdao; National Science Foundation of USA; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8844120","Depth Estimation;CNN;Single RGB Image;Contextualization;Scene-Aware Algorithm","Estimation;Semantics;Training;Task analysis;Feature extraction;Decoding;Convolution","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A fusion model based Label Embedding and Self-Interaction Attention for Text Classification","Y. Dong; P. Liu; Z. Zhu; Q. Wang; Q. Zhang","School of Information Science and Engineering, Shandong Normal University, Jinan 250014, China.; School of Information Science and Engineering, Shandong Normal University, Jinan 250014, China.; School of Information Science and Electrical Engineering, Shandong Jiao Tong University, Jinan 250357, China.; School of Information Science and Engineering, Shandong Normal University, Jinan 250014, China.; School of Information Science and Engineering, Shandong Normal University, Jinan 250014, China.","IEEE Access","","2019","PP","99","1","1","Text classification is a pivotal task in NLP (Natural Language Processing), which has received widespread attention recently. Most of the existing methods leverage the power of deep learning to improve the performance of models. However, these models ignore the interaction information between all the sentences in a text when generating the current text representation, which results in a partial semantics loss. Labels play a central role in text classification. And the attention learned from text-label in the joint space of labels and words is not leveraged, leaving enough room for further improvement. In this paper, we propose a text classification method based on Self-Interaction attention mechanism and label embedding. Firstly, our method introduce BERT (Bidirectional Encoder Representation from Transformers) to extract text features. Then Self-Interaction attention mechanism is employed to obtain text representations containing more comprehensive semantics. Moreover, we focus on the embedding of labels and words in the joint space to achieve the dual-label embedding, which further leverages the attention learned from text-label. Finally, the texts are classified by the classifier according to the weighted labels representations. The experimental results show that our method outperforms other state-of-the-art methods in terms of classification accuracy.","","","10.1109/ACCESS.2019.2954985","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8908707","Text classification;Text representations;Label embedding","Text categorization;Semantics;Feature extraction;Natural language processing;Bit error rate;Task analysis;Neural networks","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Calibrated Multivariate Regression Networks","L. Zhang; Y. Du; X. Li; X. Zhen","College of Computer Science and Technology, Guangdong University of Petrochemical Technology, Guangdong, China.; College of Software, Beihang University, Beijing, China.; College of Computer Science and Technology, Guangdong University of Petrochemical Technology, Guangdong, China.; College of Computer Science and Technology, Guangdong University of Petrochemical Technology, Guangdong, China, and Inception Institute of Artificial Intelligence, United Arab Emirates.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","In this paper, we propose a new multi-layer learning architecture, the calibrated multivariate regression network (CMRN). Compared to previous multivariate models, the CMRN is able to simultaneously handle major challenges in multivariate regression including highly nonlinear input-output relationships, underlying inter-output correlations and calibration of multiple outputs within one single framework. The CMRN is comprised of a nonlinear module with cosine activations and a linear module with the low-rank expansion, which establishes a compact multivariate regression network. By seamlessly working with the l2,1 loss, the CMRN automatically calibrates multiple outputs with distinct noise levels to achieve improved performance. Being succinctly formulated but theoretically well-founded, the CMRN offers a compact multi-layer learning architecture that can be efficiently trained to scale up with massive datasets. We conduct extensive experimental evaluation on two representative large multivariate regression tasks for both machine learning and computer vision. The proposed CMRN can produce high performance on all tasks, which is better or competitive to stateof-the-art models. Extensive ablation studies offer deep insights into the effectiveness of the proposed CMRN.","","","10.1109/TCSVT.2019.2952646","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8895784","Multivariate Regression;Fourier Embedding;Kernel Approximation;Low Rank","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"MLFcGAN: Multilevel Feature Fusion-Based Conditional GAN for Underwater Image Color Correction","X. Liu; Z. Gao; B. M. Chen","Department of Electrical and Computer Engineering, National University of Singapore, Singapore 117583 (e-mail: xiaodongliu@u.nus.edu).; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan 430079, China (e-mail: gaozhinus@gmail.com).; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, Hong Kong, and also with the Department of Electrical and Computer Engineering, National University of Singapore, Singapore 117583.","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","Color correction for underwater images has received increasing interest, due to its critical role in facilitating available mature vision algorithms for underwater scenarios. Inspired by the stunning success of deep convolutional neural network (DCNN) techniques in many vision tasks, especially the strength in extracting features in multiple scales, we propose a deep multiscale feature fusion net based on the conditional generative adversarial network (GAN) for underwater image color correction. In our network, multiscale features are extracted first, followed by augmenting local features in each scale with global features. This design was verified to facilitate more effective and faster network learning, resulting in better performance in both color correction and detail preservation. We conducted extensive experiments and compared the results with state-of-the-art approaches quantitatively and qualitatively, showing that our method achieves significant improvements.","","","10.1109/LGRS.2019.2950056","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8894129","Conditional generative adversarial network (cGAN);feature extraction and fusion;image enhancement;underwater image color correction.","Feature extraction;Image color analysis;Gallium nitride;Loss measurement;Generative adversarial networks;Image restoration;Generators","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Ensemble Tracking based on Diverse Collaborative Framework with Multi-Cue Dynamic Fusion","Y. Han; P. Zhang; T. Zhuo; W. Huang; Y. Zha; Y. Zhang","School of Computer Science, Northwestern Polytechnical University, 26487 Xi'an, Shaanxi China (e-mail: yaminhan@mail.nwpu.edu.cn); Shool of Computer Science, Northwestern Polytechnical University, 26487 Xi'an, Shaanxi China (e-mail: zh0036ng@nwpu.edu.cn); School of Computing, National University of Singapore, 37580 Singapore Singapore (e-mail: zhuotao@nus.edu.sg); Information Engineering, Jiangxi Normal University, 12642 Nanchang, Jiangxi China (e-mail: huangwei@ncu.edu.cn); School of Computer Science, Northwestern Polytechnical University, 26487 Xi'an China (e-mail: zhayufei@126.com); School of Computer Science, Northwestern Polytechnical University, 26487 Xi'an China 710072 (e-mail: ynzhang@nwpu.edu.cn)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","Tracking with deep neural networks has been verified to arrive at a new level accuracy in many challenging scenarios, but the tracking robustness has been still challenged by model singularity and self-learning loop mechanism. As a promising solution for the limitations, to ensemble diverse tracking strategies into a highly-interactive framework has shown a potential effectiveness in recent studies. In this work, a collaborative tracking framework is proposed by exploiting both discriminative correlation filters and deep classifiers into an ensembling framework. With a multi-cue dynamic fusion scheme performed on all the ensembled members‘ outputs, a robust long-term tracking can be achieved by calculating the optimal robustness scores based on a dynamic weighted sum of multi-cue metrics. Meanwhile, the obtained reliable and diverse training samples are also utilized to adaptively update the tracker in each branch with heuristic frequency, which is able to alleviate the training samples‘ contamination and model corruption. Experiments on the OTB-2015, Temple color 128, UAV123, VOT2016, and VOT2018 benchmark datasets have shown superior performance in comparison to other state-of-the-art tracking approaches.","","","10.1109/TMM.2019.2958759","Natural Science Foundation of Jiangxi Province; National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8930063","Ensembling structure;Collaborative tracking framework;Multi-cue dynamic fusion;Heuristic frequency","Target tracking;Correlation;Robustness;Adaptation models;Training;Tracking loops;Collaboration","","","","","","","","","","IEEE","IEEE Early Access Articles"
"FilterNet: Adaptive Information Filtering Network for Accurate and Fast Image Super-Resolution","F. Li; H. Bai; Y. Zhao","Beijing Key Laboratory of Advanced Information Science and Network Technology, Beijing 100044, China and Institute Information Science, Beijing Jiaotong University, Beijing 100044, China.; Beijing Key Laboratory of Advanced Information Science and Network Technology, Beijing 100044, China and Institute Information Science, Beijing Jiaotong University, Beijing 100044, China.; Beijing Key Laboratory of Advanced Information Science and Network Technology, Beijing 100044, China and Institute Information Science, Beijing Jiaotong University, Beijing 100044, China.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Deep convolutional neural network (CNN) approaches have achieved impressive performance for image superresolution (SR). The main issue of image SR is to effectively recover the high-frequency detail of low-resolution (LR) input. However, existing CNN methods often inevitably exhibit a large amount of memory consumption and computational cost. In addition, in most SR networks, the low-frequency and highfrequency components of LR features are treated equally in the training process, which can ignore the local detailed information and hinder the representational capacity of networks. To solve these issues, in this paper, we propose a deep adaptive information filtering network (FilterNet) for accurate and fast image SR. In contrast to existing methods that adopt fully CNN methods to directly predict the HR images, the proposed FilterNet concentrates on more useful features and adaptively filters the redundant low-frequency information. In general, we present the dilated residual group (DRG), which consists of multiple dilated residual units. The DRGs can directly expand the receptive field of the network to efficiently exploit the contextual information of the LR input. In the dilated residual unit, a gated selective mechanism is proposed to adaptively learn more high-frequency information and filter the low-frequency information. Besides, we introduce a novel adaptive information fusion structure, which builds long scaling skip connections among the DRGs to rescale the hierarchical features and fuse more detailed information. The scaling weights can be deemed as the part parameters of our network and trained adaptively. Extensive evaluations on benchmark datasets demonstrate that our FilterNet achieves superior performance both on accuracy and speed compared to recent state-of-the-art methods.","","","10.1109/TCSVT.2019.2906428","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8672189","Image super-resolution;dilated convolution;gated selective mechanism;adaptive information fusion","Image reconstruction;Image resolution;Convolution;Information filters;Convolutional neural networks;Training","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Polyhedral Conic Classifiers for Computer Vision Applications and Open Set Recognition","H. Cevikalp; H. Saglamlar","Electrical and Electronics Engineering, Eskisehir Osmangazi University, Eskisehir, Eskisehir Turkey 26480 (e-mail: hakan.cevikalp@gmail.com); Electrical and Electronics Engineering, Eskisehir Osmangazi Universitesi Muhendislik Mimarlik Fakultesi, 111339 Eskisehir, Esk Turkey 26480 (e-mail: hsaglamlar@gmail.com)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","This paper introduces a family of quasi-linear discriminants that outperform current large-margin methods in sliding window visual object detection and open set recognition tasks. In these applications, the classification problems are both numerically imbalanced -- positive training and test windows are much rarer than negative ones -- and geometrically asymmetric -- the positive samples typically form compact, visually-coherent groups while negatives are much more diverse, including anything at all that is not a well-centered sample from the target class. For such tasks, there is a need for discriminants whose decision regions focus on tightly circumscribing the positive class, while still taking account of negatives in zones where the two classes overlap. To this end, we propose a family of quasi-linear polyhedral conic discriminants whose positive regions are distorted L1 or L2 balls. In addition, we also integrated the proposed classification loss into deep neural networks so that both the features and classifier can be learned simultaneously end-to-end fashion to improve the classification accuracies. The methods can be trained from either binary or positive-only samples using constrained quadratic programs related to SVMs. Our experiments show that they significantly outperform linear SVMs, deep neural networks using softmax loss function and existing one-class discriminants.","","","10.1109/TPAMI.2019.2934455","Tubitak; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798888","Polyhedral conic classifiers;object detection;large margin classifiers;open set recognition","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Sequential Factorized Autoencoder for Localizing the Origin of Ventricular Activation From 12-Lead Electrocardiograms","P. K. Gyawali; B. M. Horacek; J. L. Sapp; L. Wang","Golisano College of Computing and Information Sciences, Rochester Institute of Technology, 6925 Rochester, New York United States 14623-5603 (e-mail: pkg2182@rit.edu); School of Biomedical Engineering, Dalhousie University, Halifax, Nova Scotia Canada B3H 1X5 (e-mail: milan.horacek@dal.ca); Dept. of Medicine (Cardiology), Queen Elizabeth II Health Sciences Centre, 3686 Halifax, Nova Scotia Canada (e-mail: john.sapp@nshealth.ca); Computing and Information Sciences, Rochester, New York United States 14623 (e-mail: lxwast@rit.edu)","IEEE Transactions on Biomedical Engineering","","2019","PP","99","1","1","Objective: This work presents a novel approach to handle the inter-subject variations existing in the population analysis of ECG, applied for localizing the origin of ventricular tachycardia (VT) from 12-lead electrocardiograms (ECGs). Methods: The presented method involves a factor disentangling sequential autoencoder (f-SAE) – realized in both long shortterm memory (LSTM) and gated recurrent unit (GRU) networks – to learn to disentangle the inter-subject variations from the factor relating to the locaation of origin of VT. To perform such disentanglement, a pair-wise contrastive loss is introduced. Results: The presented methods are evaluated on ECG dataset with 1012 distinct pacing sites collected from scar-related VT patients during routine pace-mapping procedures. Experiments demonstrate that, for classifying the origin of VT into the predefined segments, the presented f-SAE improves the classification accuracy by 8.94% from using prescribed QRS features, by 1.5% from the supervised deep CNN network, and 5.15% from the standard SAE without factor disentanglement. Similarly, when predicting the coordinates of the VT origin, the presented f-SAE improves the performance by 2.25 mm from using prescribed QRS features, by 1.18 mm from the supervised deep CNN network and 1.6 mm from the standard SAE. Conclusion: These results demonstrate the importance as well as the feasibility of the presented f-SAE approach for separating inter-subject variations when using 12-lead ECG to localize the origin of VT. Significance: This work suggests the important research direction to deal with the well-known challenge posed by inter-subject variations during population analysis from ECG signals.","","","10.1109/TBME.2019.2939138","National Science Foundation; National Institute of Health; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8822994","Ventricular Tachycardia;Electrophysiology;Disentangled Representations;Sequential Autoencoder","Electrocardiography;Logic gates;Data models;Adaptation models;Heart;Standards;Recurrent neural networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Generic Anomaly Detection of Catenary Support Components Based on Generative Adversarial Networks","Y. Lyu; Z. Han; J. Zhong; C. Li; Z. Liu","School of Electrical Engineering, Southwest Jiaotong University, Chengdu 610031, China.; School of Electrical Engineering, Southwest Jiaotong University, Chengdu 610031, China.; School of Electrical Engineering, Southwest Jiaotong University, Chengdu 610031, China.; School of Electrical Engineering, Southwest Jiaotong University, Chengdu 610031, China.; School of Electrical Engineering, Southwest Jiaotong University, Chengdu 610031, China.","IEEE Transactions on Instrumentation and Measurement","","2019","PP","99","1","1","The goal of this paper is to develop a universal anomaly detection approach for catenary support components (CSCs) based on the generative adversarial networks (GANs). As the long-term operation of railway system, a wide range of failures which threaten the safe operation of vehicles perhaps happen to CSCs. But until now, it is hard to design a generic detection system to recognize all these kinds of failures because each defect needs a special detecting algorithm for different fault signatures. The lack of anomaly samples also makes it difficult for supervised learning methods to detect effectively. In this paper, a novel approach which combines deep convolution neural networks (DCNNs) with GANs is proposed to estimate whether failures happen and gives an alarm to stop the accident. First, an object location model is trained by DCNNs to obtain numerous samples of CSCs. Second, a generative model based on deep convolutional generative adversarial network (DCGAN) is constructed to find a good mapping from image space to high-dimensional feature spaces implicitly. Finally, an anomaly rating criterion is used to diagnose images. Two typical components of CSCs, the insulator which has big body and the isoelectric line which has tiny characters, are tested here. Experiments show that the proposed method can correctly judge anomalous images of CSCs and possess a good generic failure detection ability in this single framework.","","","10.1109/TIM.2019.2954757","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8907821","railway;catenary support components;generative adversarial networks;anomaly detection","Feature extraction;Anomaly detection;Training;Insulators;Wires;Detectors;Generative adversarial networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Augur: Modeling the Resource Requirements of ConvNets on Mobile Devices","Z. Lu; S. Rallapalli; K. S. Chan; S. Pu; T. La Porta","Department of Computer Science, Peking University, 12465 Beijing, Beijing China (e-mail: zongqing.lu@pku.edu.cn); N/A, IBM Thomas J Watson Research Center, 71353 Yorktown Heights, New York United States (e-mail: srallapalli@us.ibm.com); Computational and Information Sciences Directorate, U.S. Army Research Laboratory, Adelphi, Maryland United States (e-mail: kevin.s.chan.civ@mail.mil); Research Institute, Hikvision, Hangzhou, Zhejiang China (e-mail: pushiliang@hikvision.com); EIC, Transactions on Mobile Computing, Pennsylvania State University, University Park, Pennsylvania United States 16802 (e-mail: tlp@cse.psu.edu)","IEEE Transactions on Mobile Computing","","2019","PP","99","1","1","Convolutional Neural Networks (ConvNets/CNNs) have revolutionized the research in computer vision, due to their ability to capture complex patterns, resulting in high inference accuracies. However, the increasingly complex nature of these neural networks means that they are particularly suited for server computers with powerful GPUs. We envision that deep learning applications will be eventually widely deployed on mobile devices, e.g., smartphones, self-driving cars, and drones. Therefore, in this paper, we aim to understand the resource requirements of CNNs on mobile devices in terms of compute time, memory and power. First, by deploying several popular CNNs on different mobile CPUs and GPUs, we measure and analyze the performance and resource usage for the CNNs on a layerwise granularity. Our findings point out the potential ways of optimizing the CNN pipelines on mobile devices. Second, we model resource requirements of core computations of CNNs. Finally, based on the measurement, and modeling, we build and evaluate our modeling tool, Augur, which takes a CNN configuration (descriptor) as the input and estimates the compute time, memory, and power requirements of the CNN, to give insights about whether and how efficiently a CNN can be run on a given mobile platform.","","","10.1109/TMC.2019.2946538","Army Research Laboratory; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8863962","Convolutional neural networks;mobile devices;modeling","Mobile handsets;Computational modeling;Performance evaluation;Kernel;Graphics processing units;Task analysis;Training","","","","","","","","","","IEEE","IEEE Early Access Articles"
"MERIT: Tensor Transform for Memory-Efficient Vision Processing on Parallel Architectures","Y. Lin; W. Chen; S. Chien","Graduate Institute of Electronics Engineering, National Taiwan University, Taipei 10617, Taiwan. (e-mail: johnjohnlys@media.ee.ntu.edu.tw).; Skywatch Inc., Taipei 10084, Taiwan, and also with Inventec Inc., Taipei 11167, Taiwan.; Graduate Institute of Electronics Engineering, National Taiwan University, Taipei 10617, Taiwan.","IEEE Transactions on Very Large Scale Integration (VLSI) Systems","","2019","PP","99","1","14","Computationally intensive deep neural networks (DNNs) are well- suited to run on GPUs, but newly developed algorithms usually require the heavily optimized DNN routines to work efficiently, and this problem could be even more difficult for specialized DNN architectures. In this article, we propose a mathematical formulation that can be useful for transferring the algorithm optimization knowledge across computing platforms. We discover that data movement and storage inside parallel processor architectures can be viewed as tensor transforms across memory hierarchies, making it possible to describe many memory optimization techniques mathematically. Such transform, which we call memory-efficient ranged inner-product tensor (MERIT) transform, can be applied to not only DNN tasks but also many traditional machine learning and computer vision computations. Moreover, the tensor transforms can be readily mapped to existing vector processor architectures. In this article, we demonstrate that many popular applications can be converted to a succinct MERIT notation on GPUs, speeding up GPU kernels up to 20 times while using only half as many code tokens. We also use the principle of the proposed transform to design a specialized hardware unit called MERIT-z processor. This processor can be applied to a variety of DNN tasks as well as other computer vision tasks while providing comparable area and power efficiency to dedicated DNN application-specific integrated circuits (ASICs).","","","10.1109/TVLSI.2019.2953171","MediaTek Inc Hsinchu Taiwan; MultiTek Inc Hsinchu Taiwan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8926420","Neural network hardware;parallel programming;vector processors.","Transforms;Magneto electrical resistivity imaging technique;Computer architecture;Tensile stress;Task analysis;Graphics processing units;Optimization","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Contour-Aware Long-term Tracking with Reliable Re-detection","F. Tang; Q. Ling","Dept. of Automation, University of Science and Technology of China, Hefei, Anhui 230027, P. R. China.; Dept. of Automation, University of Science and Technology of China, Hefei, Anhui 230027, P. R. China.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Recently discriminative correlation filter (DCF) based methods have gained much popularity for their excellent performance and high efficiency. However, most of them perform poorly in long-term tracking as they are not equipped with an effective mechanism to evaluate the quality of tracking results and correct tracking errors. To resolve such issue, this paper proposes a long-term tracking method, which consists of two components, including tracking-by-detection and re-detection. The tracking-by-detection part is built upon the DCF framework by incorporating a contour constraint map, which could identify non-target samples and refine the tracking results efficiently in presence of some challenging situations, such as deformation and occlusion. Benefited by our proposed re-detection strategy, the missing/occluded target could be captured immediately after it reappears. Moreover, a re-detected result is allowed to replace the original tracking result only when it owns a performance gap against the original one, which can reduce the risk of wrong substitution and well enhance the long-term tracking robustness. Extensive experiments on OTB2015, Temple-Color, UAV20L and VOT-LT2018 show that the proposed long-term tracking method outperforms state-of-the-art hand-crafted based methods, and even some deep learning based methods.","","","10.1109/TCSVT.2019.2957748","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8924778","Long-term tracking;correlation filter;re-detection;contour information","Target tracking;Reliability;Detectors;Correlation;Color;Estimation","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Probabilistic Forecasting of Battery Energy Storage State-of-Charge under Primary Frequency Control","A. Mashlakov; L. Lensu; A. Kaarna; V. Tikka; S. Honkapuro","Laboratory of Electricity Market and Power Systems, School of Energy Systems, Lappeenranta-Lahti University of Technology LUT, Lappeenranta, 53850 Finland.; Computer Vision and Pattern Recognition Laboratory, School of Engineering Science, Lappeenranta-Lahti University of Technology LUT.; Computer Vision and Pattern Recognition Laboratory, School of Engineering Science, Lappeenranta-Lahti University of Technology LUT.; Laboratory of Electricity Market and Power Systems, School of Energy Systems, Lappeenranta-Lahti University of Technology LUT, Lappeenranta, 53850 Finland.; Laboratory of Electricity Market and Power Systems, School of Energy Systems, Lappeenranta-Lahti University of Technology LUT, Lappeenranta, 53850 Finland.","IEEE Journal on Selected Areas in Communications","","2019","PP","99","1","1","Multi-service market optimization of battery energy storage system (BESS) requires assessing the forecasting uncertainty arising from coupled resources and processes. For the primary frequency control (PFC), which is one of the highest-value applications of BESS, this uncertainty is linked to the changes of BESS state-of-charge (SOC) under stochastic frequency variations. In order to quantify this uncertainty, this paper aims to exploit one of the recent achievements in the field of deep learning, i.e. multi-attention recurrent neural network (MARNN), for BESS SOC forecasting under PFC. Furthermore, we extend the MARNN model for probabilistic forecasting with a hybrid approach combining Mixture Density Networks and Monte Carlo dropout that incorporate the uncertainties of the data noise and the model parameters in the form of prediction interval (PI). The performance of the model is studied on BESS SOC datasets that are simulated based on real frequency measurements from three European synchronous areas in Great Britain, Continental Europe, and Northern Europe and validated by three PI evaluation indexes. Compared with the state-of-theart quantile regression algorithms, the proposed hybrid model performed well with respect to the coverage probability of PIs for the different regulatory environments of the PFC.","","","10.1109/JSAC.2019.2952195","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8894041","Attention-based neural network;battery energy storage system (BESS);frequency control;mixture density networks;Monte Carlo dropout;prediction intervals;probabilistic forecasting;state-of-charge (SOC)","Forecasting;Uncertainty;Frequency control;Probabilistic logic;Predictive models;Data models;Batteries","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Federated Tensor Mining for Secure Industrial Internet of Things","L. Kong; X. Liu; H. Sheng; P. Zeng; G. Chen","Shanghai China 200240 (e-mail: linghe.kong@sjtu.edu.cn); Shanghai Jiao Tong University, Shanghai China 200240 (e-mail: yanglet@sjtu.edu.cn); Beihang University, 12633 Beijing China 100083 (e-mail: shenghao@buaa.edu.cn); Laboratory of Industrial Control Network and System, Shenyang Institute of Automation, Chinese Academy of Sciences, Shenyang, Liaoning China 110016 (e-mail: zp@sia.cn); Shanghai Jiao Tong University, 12474 Shanghai China 200240 (e-mail: gchen@cs.sjtu.edu.cn)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","In a vertical industry alliance, Internet of Things (IoT) deployed in different smart factories are similar. For example, most automobile manufacturers have the similar assembly lines and IoT surveillance systems. It is common to observe the industrial knowledge using deep learning and data mining methods based on the IoT data. However, some knowledge is not easy to be mined from only one factory's data because the samples are still few. If multiple factories within an alliance can gather their data together, more knowledge could be mined. However, the key concern of these factories is the data security. Existing matrix based methods can guarantee the data security inside a factory but do not allow the data sharing among factories, and thus their mining performance is poor due to lack of correlation. To address this concern, we propose the novel Federated Tensor Mining (FTM) framework to federate multisource data together for tensor based mining while guaranteeing the security. The key contribution of FTM is that every factory only needs to share its ciphertext data for security issue. And these ciphertext are adequate for tensor based knowledge mining due to its homomorphic attribution. Real-data driven simulations demonstrate that FTM not only mines the same knowledge compared with the plaintext mining, but also be able to defend the attacks from distributed eavesdroppers and centralized hackers. In our typical experiment, compared with the matrix based PPCS, FTM increases up to 24% on mining accuracy.","","","10.1109/TII.2019.2937876","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8815886","Industrial Internet of Things;Tensor based Data Mining;Security","Data mining;Servers;Production facilities;Encryption;Smart manufacturing","","","","","","","","","","IEEE","IEEE Early Access Articles"
"RGB-T Salient Object Detection via Fusing Multi-level CNN Features","Q. Zhang; N. Huang; L. Yao; D. Zhang; C. Shan; J. Han","Key Laboratory of Electronic Equipment Structure Design, Ministry of Education, Xidian University, Xi’an Shaanxi 710071, China, and also with Center for Complex Systems, School of Mechano-Electronic Engineering, Xidian University, Xi’an Shaanxi 710071, China.; Center for Complex Systems, School of Mechano-Electronic Engineering, Xidian University, Xi’an Shaanxi 710071, China.; Center for Complex Systems, School of Mechano-Electronic Engineering, Xidian University, Xi’an Shaanxi 710071, China.; Center for Complex Systems, School of Mechano-Electronic Engineering, Xidian University, Xi’an Shaanxi 710071, China.; Philips Research, High Tech Campus, 5656 AE, Eindhoven, The Netherlands.; WMG Data Science, University of Warwick, Coventry, CV4 7AL, U. K.","IEEE Transactions on Image Processing","","2019","PP","99","1","1","RGB-induced salient object detection has recently witnessed substantial progress, which is attributed to the superior feature learning capability of deep convolutional neural networks (CNNs). However, such detections suffer from challenging scenarios characterized by cluttered backgrounds, low-light conditions and variations in illumination. Instead of improving RGB based saliency detection, this paper takes advantage of the complementary benefits of RGB and thermal infrared images. Specifically, we propose a novel end-to-end network for multi-modal salient object detection, which turns the challenge of RGB-T saliency detection to a CNN feature fusion problem. To this end, a backbone network (e.g., VGG-16) is first adopted to extract the coarse features from each RGB or thermal infrared image individually, and then several adjacent-depth feature combination (ADFC) modules are designed to extract multi-level refined features for each single-modal input image, considering that features captured at different depths differ in semantic information and visual details. Subsequently, a multi-branch group fusion (MGF) module is employed to capture the cross-modal features by fusing those features from ADFC modules for a RGB-T image pair at each level. Finally, a joint attention guided bi-directional message passing (JABMP) module undertakes the task of saliency prediction via integrating the multi-level fused features from MGF modules. Experimental results on several public RGB-T salient object detection datasets demonstrate the superiorities of our proposed algorithm over the state-of-the-art approaches, especially under challenging conditions, such as poor illumination, complex background and low contrast.","","","10.1109/TIP.2019.2959253","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8935533","RGB-T salient object detection;Adjacent-depth feature combination;Multi-branch group fusion;Joint attention guided bi-directional message passing","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Group Cost-Sensitive BoostLR With Vector Form Decorrelated Filters for Pedestrian Detection","C. Zhou; M. Wu; S. Lam","School of Computer Science and Engineering, Nanyang Technological University, Singapore 639798 (e-mail: zhou0271@e.ntu.edu.sg).; School of Computer Science and Engineering, Nanyang Technological University, Singapore 639798.; School of Computer Science and Engineering, Nanyang Technological University, Singapore 639798.","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","14","Pedestrian detection has achieved notable progress in the field of computer vision over the past decade. However, existing top-performing approaches suffer from high computational complexity which prohibits their realization on embedded platforms with low computational capabilities. In this paper, we propose a robust and fast pedestrian detection framework which is based on the Filtered Channel Feature (FCF) approach. The proposed framework exploits vector-form decorrelated filters to extract more discriminative channel features while benefiting from low computational complexity. A novel group cost-sensitive BoostLR (Boosting with Loss Regularization) algorithm is proposed to train the classifier. The proposed training strategy provides more emphasis to the harder samples by exploring the variations of negatives selected from different rounds in hard negative mining processing, and hence is able to boost the overall detection performance. In addition, the proposed method also benefits from the BoostLR framework to achieve better generalization. Experiments on the well-known Caltech, INRIA and CityPersons pedestrian detection datasets show that our proposed approach achieves the best detection performance among all of the state-of-the-art non-deep learning methods and can run one order of magnitude faster than classical FCF methods (e.g. Checkerboards).","","","10.1109/TITS.2019.2948044","National Research Foundation Singapore under its Campus for Research Excellence and Technological Enterprise CREATE Programme with the Technical University of Munich at TUMCREATE; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8880687","Pedestrian detection;decorrelated channel feature;cost-sensitive;boosting.","Feature extraction;Decorrelation;Training;Computational complexity;Testing;Boosting","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Manifold Siamese Network: A Novel Visual Tracking ConvNet for Autonomous Vehicles","M. Gao; L. Jin; Y. Jiang; B. Guo","College of Transportation, Jilin University, Changchun 130022, China.; College of Transportation, Jilin University, Changchun 130022, China.; Department of Ophthalmology, China-Japan Union Hospital of Jilin University, Changchun 130033, China (e-mail: jiangyy@jlu.edu.cn).; College of Transportation, Jilin University, Changchun 130022, China.","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","12","Visual tracking is a vital component of autonomous driving perception system. Siamese networks have achieved great success in both accuracy and speed for visual tracking tasks. These Siamese trackers share a similar framework in which each tracker consists of two network branches for exploring semantic information. However, the performance of Siamese trackers is limited by an insufficient semantic template and an unsatisfactory updating strategy. To tackle these problems, we propose a manifold Siamese network for visual tracking that can simultaneously utilize semantic and geometric information. A manifold sample pool is constructed to exploit the manifold structure of image object sequences. This sample pool is dynamically learned via a fast Gaussian mixture model (GMM). After obtaining a manifold sample template, we design a deep architecture based on a correlation filter (CF) network and append a novel manifold feature branch. The network remains fully convolutional and can train a template to discriminate exemplar image and arbitrarily size search image. Then, a triplet occlusion score function cooperates with an effective update method that is established to prevent model drift. Extensive experiments show that the proposed tracking algorithm performs favorably compared with the state-of-the-art methods on three standard benchmark datasets at a high framerate, which is very suitable for autonomous driving.","","","10.1109/TITS.2019.2930337","National Natural Science Foundation of China; National Basic Research Program of China (973 Program); National Basic Research Program of China (973 Program); Electric Intelligent Vehicle Innovation Team of the Science and Technology Department of Jilin Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8795583","Autonomous vehicles;computer vision;Grassmann manifold;Siamese network;visual tracking.","Manifolds;Visualization;Correlation;Semantics;Target tracking;Autonomous vehicles;Computational modeling","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Real-Time Sensor Anomaly Detection and Identification in Automated Vehicles","F. van Wyk; Y. Wang; A. Khojandi; N. Masoud","Industrial and Systems Engineering Department, The University of Tennessee, Knoxville, TN 37996 USA.; Civil and Environmental Engineering Department, University of Michigan, Ann Arbor, MI 48109 USA.; Industrial and Systems Engineering Department, The University of Tennessee, Knoxville, TN 37996 USA (e-mail: khojandi@utk.edu).; Civil and Environmental Engineering Department, University of Michigan, Ann Arbor, MI 48109 USA.","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","13","Connected and automated vehicles (CAVs) are expected to revolutionize the transportation industry, mainly through allowing for a real-time and seamless exchange of information between vehicles and roadside infrastructure. Although connectivity and automation are projected to bring about a vast number of benefits, they can give rise to new challenges in terms of safety, security, and privacy. To navigate roadways, CAVs need to heavily rely on their sensor readings and the information received from other vehicles and roadside units. Hence, anomalous sensor readings caused by either malicious cyber attacks or faulty vehicle sensors can result in disruptive consequences and possibly lead to fatal crashes. As a result, before the mass implementation of CAVs, it is important to develop methodologies that can detect anomalies and identify their sources seamlessly and in real time. In this paper, we develop an anomaly detection approach through combining a deep learning method, namely convolutional neural network (CNN), with a well-established anomaly detection method, and Kalman filtering with a χ²-detector, to detect and identify anomalous behavior in CAVs. Our numerical experiments demonstrate that the developed approach can detect anomalies and identify their sources with high accuracy, sensitivity, and F1 score. In addition, this developed approach outperforms the anomaly detection and identification capabilities of both CNNs and Kalman filtering with a χ²-detector method alone. It is envisioned that this research will contribute to the development of safer and more resilient CAV systems that implement a holistic view toward intelligent transportation system (ITS) concepts.","","","10.1109/TITS.2019.2906038","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8684317","Cyber-physical systems;fault diagnosis;intelligent vehicles;intrusion detection;vehicle safety.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Towards Low-cost Sign Language Gesture Recognition Leveraging Wearables","T. Zhao; J. Liu; Y. Wang; H. Liu; Y. Chen","Computer & Information Sciences, Temple University, 6558 Philadelphia, Pennsylvania United States (e-mail: tum94362@temple.edu); Department of Electrical and Computer Engineering, Rutgers The State University of New Jersey, 242612 New Brunswick, New Jersey United States 08901-8554 (e-mail: jliu@utk.edu); Computer & Information Sciences, Temple University, 6558 Philadelphia, Pennsylvania United States (e-mail: y.wang@temple.edu); Electrical and Computer Engineering, Stevens Institute of Technology, Hoboken, New Jersey United States 07030 (e-mail: hl45@iupui.edu); ECE, Rutgers University, 242612 Piscataway, New Jersey United States 08854 (e-mail: yingche@scarletmail.rutgers.edu)","IEEE Transactions on Mobile Computing","","2019","PP","99","1","1","Different from traditional gestures, sign language gestures involve a lot of finger-level gestures without wrist or arm movements. They are hard to detect using existing motion sensors-based approaches. We introduce the first low-cost sign language gesture recognition system that can differentiate fine-grained finger movements using the Photoplethysmography (PPG) and motion sensors in commodity wearables. By leveraging the motion artifacts in PPG, our system can accurately recognize sign language gestures when there are large body movements, which cannot be handled by the traditional motion sensor-based approaches. We further explore the feasibility of using both PPG and motion sensors in wearables to improve the sign language gesture recognition accuracy when there are limited body movements. We develop a gradient boost tree (GBT) model and deep neural network-based model (i.e., ResNet) for classification. The transfer learning technique is applied to ResNet-based model to reduce the training effort. We develop a prototype using low-cost PPG and motions sensors and conduct extensive experiments and collect over 7000 gestures from 10 adults in the static and body-motion scenarios. Results demonstrate that our system can differentiate nine finger-level gestures from the American Sign Language with an average recognition accuracy over 98%.","","","10.1109/TMC.2019.2962760","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8944170","Sign Language Translation;Photoplethysmography (PPG);Wearables;Human-Computer Interaction (HCI)","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Query-Based Video Synopsis for Intelligent Traffic Monitoring Applications","S. A. Ahmed; D. P. Dogra; S. Kar; R. Patnaik; S. Lee; H. Choi; G. P. Nam; I. Kim","Department of Mathematics, National Institute of Technology Durgapur, Durgapur 713209, India (e-mail: arif.1984.in@ieee.org).; School of Electrical Sciences, IIT Bhubaneswar, Bhubaneswar 752050, India.; Department of Mathematics, National Institute of Technology Durgapur, Durgapur 713209, India.; Indo-Korea Science and Technology Center (IKST), Bengaluru 560064, India.; Indo-Korea Science and Technology Center (IKST), Bengaluru 560064, India, and also with the Imaging Media Research Center, Korea Institute of Science and Technology (KIST), Seoul 136791, South Korea.; Imaging Media Research Center, Korea Institute of Science and Technology (KIST), Seoul 136791, South Korea.; Imaging Media Research Center, Korea Institute of Science and Technology (KIST), Seoul 136791, South Korea.; Imaging Media Research Center, Korea Institute of Science and Technology (KIST), Seoul 136791, South Korea.","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","12","Synopsis of a long-duration video has many applications in intelligent transportation systems. It can help to monitor traffic with lesser manpower. However, generating meaningful synopsis of a long-duration video recording can be challenging. Often summarized outputs include redundant contents or activities that may not be helpful to the observer. Moving object trajectories are possible sources of information that can be used to generate the synopsis of long-duration videos. The synopsis generation faces challenges due to object tracking, grouping of the trajectories with respect to activity type, object category, and contextual information, and generating smooth synopsis according to a query. In this paper, we propose a method to generate meaningful and smooth synopsis of long-duration videos according to the users' query. We have tracked moving objects and adopted deep learning to classify the objects into known categories (e.g., car, bike, and pedestrians). We then identify regions in the surveillance scene with the help of unsupervised clustering. Each tube (spatiotemporal object trajectory) is represented by the source and the destination. In the final stage, we take a query from the user and generate the synopsis video by smoothly blending the appropriate tubes over the background frame through energy minimization. The proposed method has been evaluated on two publicly available datasets and our own surveillance datasets. We have compared the method with popular state-of-the-art techniques. The experiments reveal that the proposed method is superior to the existing techniques and it produces visually seamless video synopsis.","","","10.1109/TITS.2019.2929618","Korea Institute of Science and Technology KIST Flagship Project; NRF Project; Global Knowledge Platform GKP of Indo Korea Science and Technology Center IKST executed at IIT Bhubaneswar; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8777152","Surveillance;computer vision based traffic monitoring;video synopsis;query video.","Electron tubes;Surveillance;Intelligent transportation systems;Trajectory;Streaming media;Target tracking","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Structured Pruning for Efficient Convolutional Neural Networks via Incremental Regularization","H. Wang; X. Hu; Q. Zhang; Y. Wang; L. Yu; H. Hu","Information Science and Eletronic Engineering, Zhejiang University, 12377 Hangzhou, Zhejiang China 310027 (e-mail: huanw@zju.edu.cn); Information Science and Electronic Engineering, Zhejiang University, 12377 Hangzhou, Zhejiang China (e-mail: 11831021@zju.edu.cn); Computer Science, University of Sydney, Sydney Australia (e-mail: qzha2506@uni.sydney.edu.au); Department of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, Zhejiang China (e-mail: wyuehai@zju.edu.cn); Dept. of Information Science and Electronic Engineering, Zhejiang University, Hangzhou China 310027 (e-mail: yul@zju.edu.cn); Department of Information Science and Electronic Engineering, Zhejiang University, Hangzhou China 310027 (e-mail: haoji_hu@zju.edu.cn)","IEEE Journal of Selected Topics in Signal Processing","","2019","PP","99","1","1","Modern Convolutional Neural Networks (CNNs) are usually restricted by their massive computation and high storage. Parameter pruning is a promising approach for CNN compression and acceleration by eliminating redundant model parameters with tolerable performance degradation. Despite its effectiveness, existing regularization-based parameter pruning methods usually drive weights towards zero with $large\ and\ constant$ regularization factors, which neglects the fragility of the expressiveness of CNNs, and thus calls for a more gentle regularization scheme so that the networks can adapt during pruning. To achieve this, we propose a novel regularization-based pruning method, named $IncReg$, to $incrementally$ assign different regularization factors to different weights based on their relative importance. Empirical analysis on CIFAR-10 dataset verifies the merits of IncReg. Further extensive experiments with popular CNNs on CIFAR-10 and ImageNet datasets show that IncReg achieves comparable to even better results compared with state-of-the-arts. Moreover, to resolve the problem that column pruning cannot be directly applied to off-the-shelf deep learning libraries for acceleration, we generalize IncReg from column pruning to spatial pruning, which can equip existing structured pruning methods (such as channel pruning) for further acceleration with ignorable accuracy loss. Our source codes and trained models are available here: https://github.com/mingsun-tse/caffe\_increg.","","","10.1109/JSTSP.2019.2961233","Chongqing Research Program of Basic science and Frontier Technology; Natural Science Foundation of Zhejiang Province; Natural Key R and D Program of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8937758","Convolutional neural network;Model compression;Structured pruning","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Single Model CNN for Hyperspectral Image Denoising","A. Maffei; J. M. Haut; M. E. Paoletti; J. Plaza; L. Bruzzone; A. Plaza","Remote Sensing Laboratory, Department of Information Engineering and Computer Science, University of Trento, 38123 Trento, Italy.; Hyperspectral Computing Laboratory, Department of Technology of Computers and Communications, Escuela Politécnica, University of Extremadura, 10003 Cáceres, Spain (e-mail: juanmariohaut@unex.es).; Hyperspectral Computing Laboratory, Department of Technology of Computers and Communications, Escuela Politécnica, University of Extremadura, 10003 Cáceres, Spain.; Hyperspectral Computing Laboratory, Department of Technology of Computers and Communications, Escuela Politécnica, University of Extremadura, 10003 Cáceres, Spain.; Remote Sensing Laboratory, Department of Information Engineering and Computer Science, University of Trento, 38123 Trento, Italy.; Hyperspectral Computing Laboratory, Department of Technology of Computers and Communications, Escuela Politécnica, University of Extremadura, 10003 Cáceres, Spain.","IEEE Transactions on Geoscience and Remote Sensing","","2019","PP","99","1","14","Denoising is a common preprocessing step prior to the analysis and interpretation of hyperspectral images (HSIs). However, the vast majority of methods typically adopted for HSI denoising exploit architectures originally developed for grayscale or RGB images, exhibiting limitations when processing high-dimensional HSI data cubes. In particular, traditional methods do not take into account the high spectral correlation between adjacent bands in HSIs, which leads to unsatisfactory denoising performance as the rich spectral information present in HSIs is not fully exploited. To overcome this limitation, this article considers deep learning models--such as convolutional neural networks (CNNs)--to perform spectral-spatial HSI denoising. The proposed model, called HSI single denoising CNN (HSI-SDeCNN), efficiently takes into consideration both the spatial and spectral information contained in HSIs. Experimental results on both synthetic and real data demonstrate that the proposed HSI-SDeCNN outperforms other state-of-the-art HSI denoising methods. Source code: https://github.com/mhaut/HSI-SDeCNN","","","10.1109/TGRS.2019.2952062","Spanish Ministry; Junta de Extremadura; European Unions Horizon 2020 Research and Innovation Programme EOXPOSURE; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8913713","Convolutional neural networks (CNNs);denoising;hyperspectral images (HSIs);spatial-spectral information.","Noise reduction;Data models;Hyperspectral imaging;Correlation;Task analysis;Gray-scale","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Predicting Taxi and Uber Demand in Cities: Approaching the Limit of Predictability","K. Zhao; D. Khryashchev; H. Vo","Robinson College of Business, Georgia State University, Atlanta, USA. E-mail: kzhao4@gsu.edu; Graduate Center of the City University of New York, New York, USA. E-mail: dkhryashchev@gradcenter.cuny.edu; City College of the City University of New York, and the Center for Urban Science and Progress, New York University, New York, USA. E-mail: hvo@cs.ccny.cuny.edu.","IEEE Transactions on Knowledge and Data Engineering","","2019","PP","99","1","1","Utilizing large-scale urban data sets to predict taxi and Uber passengers demand in cities is valuable for designing better taxi dispatch system and improving taxi services. In this paper, we predict taxi and Uber demand using two real-world data sets. Our approach consists of two key steps. First, we use temporal-correlated entropy to measure the demand regularity and obtain the maximum predictability. Second, we implement and assess five well-known representative predictors (Markov, LZW, ARIMA, MLP and LSTM) in achieving the maximum predictability. The results show that, on average, the maximum predictability can be as high as 83%, indicating a high temporal regularity of taxi demand in cities. In areas with low maximum predictability ($\Pi^{max} < 0.83$), the deep learning predictor LSTM can achieve high prediction accuracy by capturing hidden long-term temporal dependency. In areas with high maximum predictability ($\Pi^{max} \geqslant 0.83$), the Markov predictor can infer taxi demand with 86% accuracy, 14% better than LSTM, while requiring only 0.02% computation time. These findings suggest that the maximum predictability can help determine which predictor to use in terms of the accuracy and computational costs.","","","10.1109/TKDE.2019.2955686","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8929011","Big data;human mobility;predictive algorithm;predictability;time-series","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Bit-level Optimized Neural Network for Multi-antenna Channel Quantization","C. Lu; W. Xu; S. Jin; K. Wang","National Mobile Communications Research Laboratory, Southeast University, Nanjing 210096, China.; National Mobile Communications Research Laboratory, Southeast University, Nanjing 210096, China.; National Mobile Communications Research Laboratory, Southeast University, Nanjing 210096, China.; Department of Computer and Information Sciences, Northumbria University, Newcastle upon Tyne, NE1 8ST, UK.","IEEE Wireless Communications Letters","","2019","PP","99","1","1","Quantized channel state information (CSI) plays a critical role in precoding design which helps reap the merits of multiple-input multiple-output (MIMO) technology. In order to reduce the overhead of CSI feedback, we propose a deep learning based CSI quantization method by developing a joint convolutional residual network (JC-ResNet) which benefits MIMO channel feature extraction and recovery from the perspective of bit-level quantization performance. Experiments show that our proposed method substantially improves the performance.","","","10.1109/LWC.2019.2942908","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8845636","Channel state information (CSI);quantization;neural network (NN);multiple-input multiple-output (MIMO).","Quantization (signal);Artificial neural networks;Convolution;MIMO communication;Decoding;Kernel","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Unifying Temporal Context and Multi-feature with Update-Pacing Framework for Visual Tracking","Y. Gao; Z. Hu; H. W. F. Yeung; Y. Y. Chung; X. Tian; L. Lin","College of Mathematics and Informatics, South China Agricultural University, Guangzhou, China.; School of Computer Science, the University of Sydney, Australia.; School of Computer Science, the University of Sydney, Australia.; School of Computer Science, the University of Sydney, Australia.; College of Mathematics and Informatics, South China Agricultural University, Guangzhou, China.; Sun Yat-sen University, Guangzhou, China.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Model drifting is one of the knotty problems that seriously restricts the accuracy of discriminative trackers in visual tracking. Most existing works usually focus on improving the robustness of the target appearance model. However, they are prone to suffer from model drifting due to the inappropriate model updates during the tracking-by-detection. In this paper, we propose a novel update-pacing framework to suppress the occurrence of model drifting in visual tracking. Specifically, the proposed framework first initializes an ensemble of trackers, each of which updates the model in a different update interval. Once the forward tracking trajectory of each tracker is determined, the backward trajectory will also be generated by the current model to measure the difference with the forward one, and the tracker with the smallest deviation score will be selected as the most robust tracker for remaining tracking. By performing such self16 examination on trajectory pairs, the framework can effectively preserve the temporal context consistency of sequential frames to avoid learning corrupted information. To further improve the performance of the proposed method, a multi-feature extension framework is also proposed to incorporate multiple features into the ensemble of the trackers. The extensive experimental results obtained on large-scale object tracking benchmarks demonstrate that the proposed framework significantly increases the accuracy and robustness of the underlying base trackers, such as DSST, Struck, KCF and CT, and achieves superior performance com26 pared to the state-of-the-art methods without using deep models.","","","10.1109/TCSVT.2019.2902883","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8660578","Object tracking;Model drifting;Trajectory selection;Multi-feature;Temporal context","Target tracking;Correlation;Visualization;Trajectory;Context modeling;Robustness;Object tracking","","","","","","","","","","IEEE","IEEE Early Access Articles"
"YOLOv3-DPFIN: A Dual-Path Feature Fusion Neural Network for Robust Real-time Sonar Target Detection","W. Kong; J. Hong; M. Jia; J. Yao; W. Cong; H. Hu; H. Zhang","College of Computer Science, Hangzhou Dianzi University, Hangzhou 310018, China.; College of Computer Science, Hangzhou Dianzi University, Hangzhou 310018, China.; College of Computer Science, Hangzhou Dianzi University, Hangzhou 310018, China.; College of Computer Science, Hangzhou Dianzi University, Hangzhou 310018, China.; Hangzhou Applied Acoustics Research Institute, Hangzhou 310023, China.; Hangzhou Normal University, Hangzhou 311121, China.; College of Underwater Acoustic Engineering, Harbin Engineering University, Harbin 150001, China.","IEEE Sensors Journal","","2019","PP","99","1","1","Real-time detection of sonar target plays a vital role in the underwater research field. Conventional deep learning methods need large quantities of sonar images as the sample for model training, and they cannot ensure detection speed and feature extraction ability simultaneously. For sonar dataset with small effective sample and low Signal-to-Noise Ratios (SNR), an improved YOLOv3 algorithm for real-time detection called as YOLOv3-DPFIN is proposed. The objective of the proposed YOLOv3-DPFIN is to accomplish the accurate detection of noise-intensive multi-category sonar targets with minimum time consumption. The proposed model conducts efficient feature extraction via the Dual-Path Network (DPN) module and the fusion transition module, and adopts a dense connection method to improve multi-scale prediction, which can complete precise object classification and location. The experimental results show that the algorithm achieves 84.4% mAP75 with 56fps on a Nvidia Titan Xp, when testing on the sonar dataset and using the new VOC2012 mAP standard, which can meet the requirement of robust real-time detection for both raw and noised sonar targets. Moreover, the precision and speed of the proposed YOLOv3- DPFIN are superior to the original YOLOv3 model and stateof- the-art improved SSD models.","","","10.1109/JSEN.2019.2960796","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8936940","Sonar target detection;Small effective sample;YOLOv3-DPFIN;Real-time;Robust","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Improving Urban Crowd Flow Prediction on Flexible Region Partition","X. Wang; Z. Zhou; Y. Zhao; X. Zhang; K. Xing; F. Xiao; Z. Yang; Y. Liu","School of Software, Tsinghua University, Beijing, Beijing China (e-mail: wangxu.93@hotmail.com); Computer Engineering and Networks Laboratory, Eidgenossische Technische Hochschule Zurich Departement Informatik, 31018 Zurich, ZH Switzerland (e-mail: zzhou@tik.ee.ethz.ch); School of Software, Tsinghua University, Beijing, Beijing China (e-mail: zhaoyi.yuan31@gmail.com); Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong, Hong Kong Hong Kong (e-mail: zhxlinse@gmail.com); Computer Science and Technology, University of Science and Technology of China, Hefei, Anhui China 230027 (e-mail: kxing@ustc.edu.cn); School of Computer, Nanjing University of Posts and Telecommunications, 12577 Nanjing, Jiangsu China (e-mail: xiaof@njupt.edu.cn); TNLIST, School of Software, Tsinghua University, Beijing, Beijing China (e-mail: hmilyyz@gmail.com); School of Software, Tsinghua University, 12442 Beijing, Beijing China (e-mail: yunhao@tsinghua.edu.cn)","IEEE Transactions on Mobile Computing","","2019","PP","99","1","1","Accurate forecast of citywide crowd flows on flexible region partition benefits urban planning, traffic management, and public safety. Previous research either fails to capture the complex spatiotemporal dependencies of crowd flows or is restricted on grid region partition that loses semantic context. In this paper, we propose DeepFlowFlex, a graph-based model to jointly predict inflows and outflows for each region of arbitrary shape and size in a city. Analysis on cellular datasets covering 2.4 million users in China reveals dependencies and distinctive patterns of crowd flows in not only the conventional space and time domains, but also the speed domain, due to the diverse transportation modes in the mobility data. DeepFlowFlex explicitly groups crowd flows with respect to speed and time, and combines graph convolutional long short-term memory networks and graph convolutional neural networks to extract complex spatiotemporal dependencies, especially long-term and long-distance inter-region dependencies. Evaluations on two big cellular datasets and public GPS trace datasets show that DeepFlowFlex outper- forms the state-of-the-art deep learning and big-data-based methods on both grid and non-grid city map partition.","","","10.1109/TMC.2019.2934461","National Natural Science Foundation of China; National Key Research Plan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8807281","","Urban areas;Poles and towers;Transportation;Mobile handsets;Spatiotemporal phenomena;Global Positioning System;Mathematical model","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Privacy-Preserving Object Detection for Medical Images with Faster R-CNN","Y. Liu; Z. Ma; X. Liu; S. Ma; K. Ren","School of Cyber Engineering, Xidian University, Xi’an 710071, China.; School of Cyber Engineering, Xidian University, Xi’an 710071, China.; College of Mathematics and Computer Science, Fuzhou University, Fuzhou, China.; Data 61, CSIRO, Marsfield Site, NSW, 2122.; Institute of Cyberspace Research, Zhejiang University, Zhejiang, China.","IEEE Transactions on Information Forensics and Security","","2019","PP","99","1","1","In this paper, we propose a lightweight privacy-preserving Faster R-CNN framework (SecRCNN) for object detection in medical images. Faster R-CNN is one of the most outstanding deep learning models for object detection. Using SecRCNN, healthcare centers can efficiently complete privacy-preserving computations of Faster R-CNN via the additive secret sharing technique and edge computing. To implement SecRCNN, we design a series of interactive protocols to perform the three stages of Faster R-CNN, namely feature map extraction, region proposal and regression and classification. To improve the efficiency of SecRCNN, we improve the existing secure computation sub-protocols involved in SecRCNN, including division, exponentiation and logarithm. The newly proposed sub-protocols can dramatically reduce the number of messages exchanged during the iterative approximation process based on the coordinate rotation digital computer algorithm. Moreover, the effectiveness, efficiency and security of SecRCNN are demonstrated through comprehensive theoretical analysis and extensive experiments. The experimental findings show that the communication overhead in computing division, logarithm and exponentiation decreases to 36.19%, 73.82% and 43.37%, respectively.","","","10.1109/TIFS.2019.2946476","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8864005","Privacy-preserving;Faster R-CNN;Medical Images;Additive Secret Sharing","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Clustering facial attributes: Narrowing the path from soft to hard biometrics","A. F. Abate; P. Barra; S. Barra; C. Molinari; M. Nappi; F. Narducci","University of Salerno, Salerno, 84084, ITALY.; University of Salerno, Salerno, 84084, ITALY. (e-mail: barra.silvio@gmail.com); University of Cagliari, Cagliari, 09124, ITALY.; NA; University of Salerno, Salerno, 84084, ITALY.; University of Naples Parthenope, Naples, 80143, ITALY.","IEEE Access","","2019","PP","99","1","1","Despite the success obtained in face detection and recognition over the last ten years of research, the analysis of facial attributes still represents a trend topic. Keeping the full face recognition aside, exploring the potentials of soft biometric traits, i.e. singular facial traits like the nose, the mouth, the hair and so on, is yet considered a fruitful field of investigation. Being able to infer the identity of an occluded face, e.g. voluntary occluded by sunglasses or accidentally due to environmental factors, can be useful in a wide range of operative fields where user collaboration cannot be considered as an assumption. This especially happens when dealing with forensic scenarios in which is not unusual to have partial face photos or partial fingerprints. In this paper, an unsupervised clustering approach is described. It consists in a neural network model for face attributes recognition based on transfer learning whose goal is grouping faces according to common facial features. Moreover, we use the features collected in each cluster to provide a compact and comprehensive description of the faces belonging to each cluster and deep learning as a mean for task prediction in partially visible faces.","","","10.1109/ACCESS.2019.2962010","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8941010","Clustering methods;Face Detection;Principal Component Analysis;Eigenfaces;Convolutional Neural Networks","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Hierarchical Taxonomy-Aware and Attentional Graph Capsule RCNNs for Large-Scale Multi-Label Text Classification","H. Peng; J. Li; S. Wang; L. Wang; Q. Gong; R. Yang; B. Li; P. Yu; L. He","State Key Laboratory of Software Development Environment, Beihang University, 12633 Beijing, Beijing China (e-mail: penghao@act.buaa.edu.cn); Beijing Advanced Innovation Center for Big Data and Brain Computing, Beihang University, 12633 Beijing, Beijing China (e-mail: lijx@act.buaa.edu.cn); Collage of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, Jiangsu China (e-mail: szwang@nuaa.edu.cn); Coordination Center of China, National Computer Network Emergency Response Technical Team, Beijing, Beijing China (e-mail: wlh@isc.org.cn); State Key Laboratory of Software Development Environment, Beihang University, 12633 Beijing, Beijing China (e-mail: allen_gong@buaa.edu.cn); School of Computing, University of Leeds, Leeds, West Yorkshire United Kingdom of Great Britain and Northern Ireland (e-mail: r.yang1@leeds.ac.uk); School of Computer Science & Engineering, Beihang University, Beijing, Beijing China (e-mail: libo@act.buaa.edu.cn); Computer Science, UIC, Chicago, Illinois United States (e-mail: psyu@uic.edu); Department of Biostatistics and Epidemiology, University of Pennsylvania, 6572 Philadelphia, Pennsylvania United States (e-mail: lih319@lehigh.edu)","IEEE Transactions on Knowledge and Data Engineering","","2019","PP","99","1","1","CNNs, RNNs, GCNs, and CapsNets have shown significant insights in representation learning and are widely used in various text mining tasks such as large-scale multi-label text classification. Most existing deep models for multi-label text classification consider either non-consecutive and long-distance semantics or sequential semantics. However, how to coherently take them into account is still far from studied. In addition, most existing methods treat output labels as independent medoids, ignoring the hierarchical relationships, which leads to a substantial loss of useful semantic information. In this paper, we propose a novel hierarchical taxonomy-aware and attentional graph capsule recurrent CNNs framework for large-scale multi-label text classification. Specifically, we first propose to model each document as a word order preserved graph-of-words and normalize it as a corresponding word matrix preserving both non-consecutive, long-distance and local sequential semantics. Then the word matrix is input to the proposed attentional graph capsule recurrent CNNs for effectively learning the semantic features. To leverage the hierarchical relations among the class labels, we propose a hierarchical taxonomy embedding method, and define a novel weighted margin loss by incorporating the label representation similarity. Extensive evaluations on three datasets show that our model significantly improves the performance by comparing with state-of-the-art approaches.","","","10.1109/TKDE.2019.2959991","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933476","Multi-label classification;document modeling;graph rcnn;attention network;capsule network;taxonomy embedding","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Subsidies-Free Renewable Energy Trading: A Meta Agent Approach","G. Longoria; A. Davy; L. Shi","Telecommunication Software and Systems Group, Waterford Institute of Technology, Waterford, Ireland (e-mail: glongoria@tssg.org); Telecommunication Software and Systems Group, Waterford Institute of Technology, Waterford, Ireland (e-mail: adavy@tssg.org); Carlow Institute of Technology, Carlow, Ireland (e-mail: lsh@tssg.org)","IEEE Transactions on Sustainable Energy","","2019","PP","99","1","1","Can we automate the energy exchange of a power trader’ To address this challenge, we present the Meta Agent Learner (MAL). The MAL is a tiered and multi-policy energy trader. It comprises data analytics (DA), a deep sequence-to-sequence recurrent neural network (DS2S) and reinforcement learning (RL). The DA phase draws knowledge out of the sheer flow of data. The DS2S phase creates wisdom and provides the intelligence for decision making. The RL phase senses and learns from the market to act strategically. We demonstrate the MAL in a scenario of a price-taker wind farm with a hydro plant. The testbed is real data from the NordPool and East Denmark (DK2). More specifically, electricity consumption, wholesale and balancing prices, cross border energy exchange, and weather conditions. The MAL optimizes the combined production of the wind farm and hydro pumped storage. Runs the hydro plant such that spillage of wind power is avoided or stores cheap market electricity. The performance is benchmarked with three traders.","","","10.1109/TSTE.2019.2937460","Science Foundation Ireland; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8818651","Electricity supply;energy trading;hybrid power generation;meta agent;recurrent neural network;sequenceto-sequence","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Restoration of Lossy JPEG-compressed Brain MR Images using Cross-domain Neural Networks","K. J. Chung; R. Souza; R. Frayne","Medical Biophysics, University of Western Ontario, 6221 London, Ontario Canada N6A 3K7 (e-mail: kjy.chung@gmail.com); Department of Radiology and Clinical Neuroscience, University of Calgary Cumming School of Medicine, 70401 Calgary, Alberta Canada (e-mail: roberto.medeirosdeso@ucalgary.ca); Department of Radiology and Clinical Neuroscience, University of Calgary Cumming School of Medicine, 70401 Calgary, Alberta Canada (e-mail: rfrayne@ucalgary.ca)","IEEE Signal Processing Letters","","2019","PP","99","1","1","Lossy image compression allows for efficient storage and transfer of image data with varying degrees of image degradation. However, lossy compression is not commonly used in medical imaging as the process may irreversibly remove information that defines clinically important image features. The lossy component of JPEG compression is represented as lost precision in the discrete cosine transform (DCT) domain after quantization on 8×8 image blocks and results in degradation of the image. We propose a cross-domain cascade of U-nets called the W-net. This network operates in the DCT domain to restore discarded DCT coefficients that leverages information from adjacent blocks, and the image domain to suppress compression artifacts at the image pixel level. For comparison, we adapted the Automated Transform by Manifold Approximation (AUTOMAP) method for JPEG decompression by learning the dequantization of individual 8×8 DCT coefficient blocks. These results were then transformed to the image domain and processed by a U-net. The deep learning models were able to suppress common compression artifacts at the expense of high spatial frequency detail. Both the W-net and AUTOMAP network structures were quantitatively superior to standard JPEG decompression, with the W-net outperforming AUTOMAP, suggesting that leveraging DCT coefficients from adjacent blocks improves JPEG decompression performance.","","","10.1109/LSP.2019.2961072","Amazon Web Services; Natural Sciences and Engineering Research Council of Canada; Nvidia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8937815","Convolutional Neural Network (CNN);Image Reconstruction;JPEG Decompression;Teleradiography","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"On the Importance of Visual Context for Data Augmentation in Scene Understanding","N. Dvornik; J. Mairal; C. Schmid","INRIA Grenoble, Inria Centre de Recherche Grenoble Rhone-Alpes, 56521 Montbonnot, Rhone-Alpes France (e-mail: Nikita.Dvornik@inria.fr); INRIA Grenoble, Inria Centre de Recherche Grenoble Rhone-Alpes, 56521 Montbonnot, Rhône-Alpes France (e-mail: julien.mairal@inria.fr); INRIA Grenoble, LEAR team, Montbonnot, Rhône-Alpes France (e-mail: cordelia.schmid@inria.fr)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Performing data augmentation for learning deep neural networks is known to be important for training visual recognition systems. By artificially increasing the number of training examples, it helps reducing overfitting and improves generalization. While simple image transformations can already improve predictive performance in most vision tasks, larger gains can be obtained by leveraging task-specific knowledge. In this work, we consider object detection, semantic and instance segmentation and augment training images by blending objects in existing scenes, using instance segmentation annotations. We observe that randomly pasting objects on images hurts the performance, unless the object is placed in the right context. To resolve this issue, we propose an explicit context model by using a convolutional neural network, which predicts whether an image region is suitable for placing a given object or not. In our experiments, we show that our approach is able to improve object detection, semantic and instance segmentation on the PASCAL VOC12 and COCO datasets, with significant gains in a limited annotation scenario. We also show that the method is not limited to datasets that come with expensive pixel-wise instance annotations and can be used when only bounding boxes are available, by employing weakly-supervised learning for instance masks approximation.","","","10.1109/TPAMI.2019.2961896","MACARON; ERC; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8941244","Convolutional Neural Networks;Data Augmentation;Visual Context;Object Detection;Semantic Segmentation","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Detection and Identification of Cyber and Physical Attacks on Distribution Power Grids with PVs: An Online High-Dimensional Data-driven Approach","F. Li; R. Xie; B. Yang; L. Guo; P. Ma; J. Shi; J. Ye; W. Song","Center for Cyber-Physical Systems, University of Georgia, Athens, GA 30602, USA.; Department of Statistics and Data Science, University of Central Florida, Orlando, FL 32816 USA.; Center for Cyber-Physical Systems, University of Georgia, Athens, GA 30602, USA.; Center for Cyber-Physical Systems, University of Georgia, Athens, GA 30602, USA.; Department of Statistics, University of Georgia, Athens, GA 30602, USA.; H. Milton Stewart School of Industrial and Systems Engineering, Georgia Institute of Technology, Atlanta, GA 30332, USA.; Center for Cyber-Physical Systems, University of Georgia, Athens, GA 30602, USA.; Center for Cyber-Physical Systems, University of Georgia, Athens, GA 30602, USA.","IEEE Journal of Emerging and Selected Topics in Power Electronics","","2019","PP","99","1","1","Cyber and physical attacks threaten the security of distribution power grids. The emerging renewable energy sources such as photovoltaics (PVs) introduce new potential vulnerabilities. Based on the electric waveform data measured by waveform sensors in the distribution power networks, in this paper, we propose a novel high-dimensional data-driven cyber physical attack detection and identification approach (HCADI). Firstly, we analyze the cyber and physical attack impacts (including cyber attacks on the solar inverter causing unusual harmonics) on electric waveforms in distribution power grids. Then, we construct a high dimensional streaming data feature matrix based on signal analysis of multiple sensors in the network. Next, we propose a novel mechanism including leverage score based attack detection and binary matrix factorization based attack diagnosis. By leveraging the data structure and binary coding, our HCADI approach does not need the training stage for both detection and the root cause diagnosis, which is needed for machine learning/deep learning-based methods. To the best of our knowledge, it is the first attempt to use raw electrical waveform data to detect and identify the power electronics cyber/physical attacks in distribution power grids with PVs.","","","10.1109/JESTPE.2019.2943449","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8847621","Attack Diagnosis;Distribution Power Grids;Solar Inverter;Leverage Score;Binary Matrix Factorization","Inverters;Sensors;Cyberattack;Feature extraction;Smart grids","","","","","","","","","","IEEE","IEEE Early Access Articles"
"AutoML for Architecting Efficient and Specialized Neural Networks","H. Cai; J. Lin; Y. Lin; Z. Liu; K. Wang; T. Wang; L. Zhu; S. Han","MIT, 2167 Cambridge, Massachusetts United States (e-mail: hancai@mit.edu); MIT, 2167 Cambridge, Massachusetts United States (e-mail: jilin@mit.edu); MIT, 2167 Cambridge, Massachusetts United States (e-mail: yujunlin@mit.edu); MIT, 2167 Cambridge, Massachusetts United States (e-mail: zhijian@mit.edu); MIT, 2167 Cambridge, Massachusetts United States (e-mail: kuanwang@mit.edu); MIT, 2167 Cambridge, Massachusetts United States (e-mail: usedtobe@mit.edu); MIT, 2167 Cambridge, Massachusetts United States (e-mail: ligeng@mit.edu); MIT, 2167 Cambridge, Massachusetts United States (e-mail: songhan@mit.edu)","IEEE Micro","","2019","PP","99","1","1","Efficient deep learning inference requires algorithm and hardware co-design to enable specialization: we usually need to change the algorithm to reduce memory footprint and improve energy efficiency. However, the extra degree of freedom from the neural architecture design makes the design space much larger: it's not only about designing the hardware architecture but also co-designing the neural architecture to fit the hardware architecture. It is difficult for human engineers to exhaust the design space by heuristics. We propose design automation techniques for architecting efficient neural networks given a target hardware platform. We investigate automatically designing specialized and fast models, auto channel pruning, and auto mixed-precision quantization. We demonstrate such learning-based, automated design achieves superior performance and efficiency than rule-based human design. Moreover, we shorten the design cycle by 200x than previous work, so that we can afford to design specialized neural network models for different hardware platforms.","","","10.1109/MM.2019.2953153","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8897011","AutoML;Neural Architecture Search;Channel Pruning;Mixed-Precision;Quantization;Specialization;Efficient Inference","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"End-to-end Optimized ROI Image Compression","C. Cai; L. Chen; X. Zhang; Z. Gao","Department of Electronic Engineering, Institute of Image Communication and Network Engineering, Shanghai Jiao Tong University, Shanghai 200240, China.; Department of Electronic Engineering, Institute of Image Communication and Network Engineering, Shanghai Jiao Tong University, Shanghai 200240, China.; Department of Electronic Engineering, Institute of Image Communication and Network Engineering, Shanghai Jiao Tong University, Shanghai 200240, China.; Department of Electronic Engineering, Institute of Image Communication and Network Engineering, Shanghai Jiao Tong University, Shanghai 200240, China.","IEEE Transactions on Image Processing","","2019","PP","99","1","1","Compressing an image with more bits automatically allocated to the region of interest (ROI) than to the background can both protect key information and reduce substantial redundancy. This paper models ROI image compression as an optimization problem of minimizing a weighted sum of the rate of the image and distortion of the ROI. The traditional framework solves this problem by cascading ROI prediction and ROI coding, through which achieving the optimized solution is impossible. To improve coding performance, we propose a novel deep-learning-based unified framework that can achieve rate distortion optimization for ROI compression. Specifically, the proposed framework includes a pair of ROI encoder and decoder convolutional neural networks and a learned entropy codec. The encoder network simultaneously generates multiscale representations that support efficient rate allocation and an implicit ROI mask that guides rate allocation. The proposed framework can automatically complete ROI image compression, and it can be optimized from data in an end-to-end manner. To effectively train the framework by back propagation, we develop a soft-to-hard ROI prediction scheme to make the entire framework differential. To improve visual quality, we propose a hierarchical distortion loss function to protect both pixel-level fidelity for ROI and structural similarity for the entire image. The proposed framework is implemented in two scenarios: salient-target and face-target ROI compression. Comparative experiments demonstrate the advantages of the proposed framework over the traditional framework, including considerably better subjective visual quality, significantly higher objective ROI compression performance and execution efficiency.","","","10.1109/TIP.2019.2960869","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8943263","Region of interest;Lossy image compression;Object segmentation;ROI coding;Rate distortion optimization;Convolutional neural network","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A hybrid global-local representation CNN model for automatic cataract grading","X. Xu; L. Zhang; J. Li; Y. Guan; L. Zhang","Beijing University of Technology, 12496 Beijing China 100022 (e-mail: gcaxuxi@163.com); Beijing University of Technology, 12496 Beijing China (e-mail: zhanglinglin0433@163.com); Faculty of Information Technology, Beijing University of Technology, 12496 Beijing China 100124 (e-mail: lijianqiang@bjut.edu.cn); Beijing University of Technology, 12496 Beijing China (e-mail: guanyu0010@126.com); Beijing Tongren Eye Center, Beijing Tongren Hospital, 117902 Beijing, Beijing China (e-mail: zhanglijye@126.com)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","Cataract is one of the most serious eye diseases leading to blindness. Early detection and treatment can reduce the rate of blindness in cataract patients. However, the professional knowledge of ophthalmologists is necessary for the clinical cataract detection. Therefore, the potential costs may make it difficult for the widespread use of cataract detection to prevent blindness. Artificial intelligence assisted diagnosis based on medical images has attracted more and more attention of researchers. Many studies have focused on the use of pre-defined feature sets for cataract classification, but the predefined feature sets can be incomplete or redundant. On account of the above issues, some studies have proposed deep learning methods to automatically extract image features, but all based on global features and none has analyzed the layer-by-layer transformation process of the middle-tier features. This paper uses Convolutional Neural Networks (CNN) to learn useful features directly from input data, and Deconvolution Network (DN) method is employed to investigate how CNN characterizes cataract layer-by-layer. We found that compared to the global feature set, the detail vascular information which is lost after multi-layer convolution calculation also plays an important role in cataract grading task. And this finding fits with the morphological definition of fundus image. Through the finding, we gained insights into the design of hybrid Global-local feature representation model to improve the recognition performance of automatic cataract grading.","","","10.1109/JBHI.2019.2914690","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8705272","cataract grading;Convolutional Neural Network;Deconvolution Network;hybrid global-local representation model","Cataracts;Feature extraction;Blindness;Task analysis;Medical diagnostic imaging;Lenses","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Recurrent Prediction with Spatio-temporal Attention for Crowd Attribute Recognition","Q. Li; X. Zhao; R. He; K. Huang","Center for Research on Intelligent System and Engineering, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China and University of Chinese Academy of Sciences, Beijing 100049, China.; Center for Research on Intelligent System and Engineering, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China and University of Chinese Academy of Sciences, Beijing 100049, China.; Center for Research on Intelligent Perception and Computing and the National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China and University of Chinese Academy of Sciences, Beijing 100049, China and the CAS Center for Excellence in Brain Science and Intelligence Technology, Shanghai 20031, China.; Center for Research on Intelligent System and Engineering and National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China and University of Chinese Academy of Sciences, Beijing 100049, China and the CAS Center for Excellence in Brain Science and Intelligence Technology, Shanghai 20031, China.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Crowd attribute recognition is a challenging task for crowd video understanding because a crowd video often contains multiple attributes from various types. Traditional deep learning based methods directly treat this recognition problem as a multiple binary classification problem, and represent video by vectorizing and fusing the separately learned spatial and temporal features in the fully connected layers. Therefore, the correlations between these attributes may not be well captured. In this paper, a bidirectional recurrent prediction model with a semantic aware attention mechanism is proposed to explore the spatio-temporal and semantic relations between attributes for more accurate recognition. The ConvLSTM is introduced for feature representation to capture the spatio-temporal structure of crowd videos and facilitate visual attention. A bidirectional recurrent attention module is proposed for sequential attribute prediction by associating each subcategory attributes to corresponding semantic related regions iteratively. Experiments and evaluations on the challenging WWW crowd video dataset not only show that our approach significantly outperforms state-ofthe-art methods, but also verify that our approach can effectively capture the spatio-temporal and semantic relations of the crowd attributes.","","","10.1109/TCSVT.2019.2923444","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8737965","Crowd video understanding;Attribute recognition;Attention mechanism;Multi-label classification","Semantics;Task analysis;Visualization;Context modeling;Correlation;Predictive models;Automation","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Novel Dynamic-Vision-Based Approach for Tactile Sensing Applications","F. B. Naeini; A. Alali; R. Al-Husari; A. Rigi; M. K. AlSharman; D. Makris; Y. Zweiri","Faculty of Science, Engineering and Computing, London SW15 3DW, UK.; Khalifa University Center for Autonomous Robotic Systems (KUCARS), Khalifa University, P.O. Box 127788, Abu Dhabi, UAE.; Khalifa University Center for Autonomous Robotic Systems (KUCARS), Khalifa University, P.O. Box 127788, Abu Dhabi, UAE.; University of Edinburgh, Scottish Microelectronics Centre, Edinburgh EH9 3JF.; Khalifa University Center for Autonomous Robotic Systems (KUCARS), Khalifa University, P.O. Box 127788, Abu Dhabi, UAE.; Faculty of Science, Engineering and Computing, London SW15 3DW, UK.; Faculty of Science, Engineering and Computing, London SW15 3DW, UK and Khalifa University Center for Autonomous Robotic Systems (KUCARS), Khalifa University, P.O. Box 127788, Abu Dhabi, UAE.","IEEE Transactions on Instrumentation and Measurement","","2019","PP","99","1","1","In this paper, a novel Vision-Based Measurement (VBM) approach is proposed to estimate the contact force and classify materials in a single grasp. This approach is the first event-based tactile sensor which utilizes the recent technology of neuromorphic cameras. This novel approach provides a higher sensitivity, a lower latency, and less computational and power consumption compared to other conventional visionbased techniques. Moreover, Dynamic Vision Sensor (DVS) has a higher dynamic range which increases the sensor sensitivity and performance in poor lighting conditions. Two time-series machine learning methods, namely, Time Delay Neural Network (TDNN) and Gaussian Process (GP) are developed to estimate the contact force in a grasp. A Deep Neural Network (DNN) is proposed to classify the object materials. Forty-eight experiments are conducted for four different materials to validate the proposed methods and compare them against a piezoresistive force sensor measurements. A leave-one-out cross-validation technique is implemented to evaluate and analyze the performance of the proposed machine learning methods. The contact force is successfully estimated with a mean squared error of 0.16 N and 0.17 N for TDNN and GP respectively. Four materials are classified with an average accuracy of 79.17% using unseen experimental data. The results show the applicability of eventbased sensors for grasping applications.","","","10.1109/TIM.2019.2919354","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8723387","Vision-Based Measurements;Force Estimation;Material Classification;Haptics;Dynamic Vision Sensor","Force;Tactile sensors;Force measurement;Cameras;Optical variables measurement;Optical sensors","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Affective Audio Annotation of Public Speeches with Convolutional Clustering Neural Network","J. Xu; B. Zhang; Z. Wang; Y. Wang; F. Chen; J. Gao; D. D. Feng","School of Computer Science, The University of Sydney, 4334 Sydney, New South Wales Australia (e-mail: jixu7952@uni.sydney.edu.au); School of Computer Science, The University of Sydney, 4334 Sydney, New South Wales Australia (e-mail: bzha8220@uni.sydney.edu.au); School of Computer Science, The University of Sydney, 4334 Sydney, New South Wales Australia (e-mail: zhiyong.wang@sydney.edu.au); Faculty of Engineering & Information Technology, University of Technology Sydney, 1994 Sydney, New South Wales Australia (e-mail: Yang.Wang@data61.csiro.au); Faculty of Engineering & Information Technology, University of Technology Sydney, 1994 Sydney, New South Wales Australia (e-mail: fang.chen@data61.csiro.au); Discipline of Business Analytics, The University of Sydney Business School, 67584 Sydney, New South Wales Australia (e-mail: junbin.gao@sydney.edu.au); School of Computer Science, The University of Sydney, 4334 Sydney, New South Wales Australia (e-mail: dagan.feng@sydney.edu.au)","IEEE Transactions on Affective Computing","","2019","PP","99","1","1","Public speaking is a critical skill in daily communication. While more practicing such as rehearsal is helpful to improve such a skill, lack of personalized feedback limits the effectiveness of practicing. Therefore, we formulate the task of personalized feedback as an affective audio annotation problem by learning knowledge from online public speech videos. Considering the great success of deep learning techniques such as convolutional neural networks in a wide range of applications including speech recognition and object recognition, we propose a novel convolutional clustering neural network (CCNN) to solve this multi-label classification problem. Instead of aggregating the features of different channels through pooling, we introduce a novel clustering layer to derive intermediate representation for improved annotation performance. In order to evaluate the performance of our proposed method, we purposely built an affective audio annotation dataset by collecting more than 2,000 video clips from the TED website. Experimental results on this dataset demonstrate that our proposed method outperforms traditional CNN-based approaches with a lower hamming loss for affective annotation.","","","10.1109/TAFFC.2019.2937028","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8818609","affective annotation;public speech;convolutional neural network;intermediate representation;clustering","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Low-Energy Acceleration of Binarized Convolutional Neural Networks using a Spin Hall Effect based Logic-in-Memory Architecture","A. Samiee; P. Borulkar; R. F. DeMara; P. Zhao; Y. Bai","Department of Computer Engineering, College of Engineering, Fullerton, California United States (e-mail: ashkan@csu.fullerton.edu); Department of Computer Engineering, College of Engineering, Fullerton, California United States (e-mail: payal@csu.fullerton.edu); Electrical Engineering and Computer Science, University of Central Florida, Orlando, Florida United States 32816-2362 (e-mail: ronald.demara@ucf.edu); Electrical Engineering, Chapman University Schmid College of Science and Technology, 293785 Orange, California United States (e-mail: zhao@chapman.edu); Department of Computer Engineering, College of Engineering, Fullerton, California United States 92831 (e-mail: ybai@fullerton.edu)","IEEE Transactions on Emerging Topics in Computing","","2019","PP","99","1","1","Deep Learning (DL) offers the advantages of high accuracy performance at tasks such as image recognition, learning of complex intelligent behaviors, and large-scale information retrieval problems such as intelligent web search. To attain the benefits of DL, the high computational and energy-consumption demands imposed by the underlying processing, interconnect, and memory devices on which software-based DL executes can benefit substantially from innovative hardware implementations. Logic-in-Memory (LIM) architectures offer potential approaches to attaining such throughput goals within area and energy constraints starting with the lowest layers of the hardware stack. In this paper, we develop a Spintronic Logic-in-Memory (S-LIM) XNOR neural network (S-LIM XNN) which can perform binary convolution with reconfigurable in-memory logic without supplementing distinct logic circuits for computation within the memory module itself. Results indicate that the proposed S-LIM XNN designs achieve 1.2-fold energy reduction, 1.26-fold throughput increase, and 1.4-fold accuracy improvement compared to the state-of-the-art binarized convolutional neural network hardware. Design considerations, architectural approaches, and the impact of process variation on the proposed hybrid spin-CMOS design are identified and assessed, including comparisons and recommendations for future directions with respect to LIM approaches for neuromorphic computing.","","","10.1109/TETC.2019.2915589","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8709815","In-memory computing;STT-MRAM;image processing;classifier systems;post-CMOS computing architectures","Convolution;Mathematical model;Writing;Computer architecture;Energy efficiency;Neural networks;Standards organizations","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Generic Quality Control Framework for Fetal Ultrasound Cardiac Four-chamber Planes","J. Dong; S. Liu; Y. Liao; H. Wen; B. Lei; S. Li; T. Wang","National-Regional Key Technology Engineering Laboratory for Medical Ultrasound & Guangdong Provincial Key Laboratory of Biomedical Measurements and Ultrasound Imaging & School of Biomedical Engineering, Health Science Center, Shenzhen University, 47890 Shenzhen, Guangdong China (e-mail: 995238847@qq.com); National-Regional Key Technology Engineering Laboratory for Medical Ultrasound & Guangdong Provincial Key Laboratory of Biomedical Measurements and Ultrasound Imaging & School of Biomedical Engineering, Health Science Center, Shenzhen University, 47890 Shenzhen, Guangdong China (e-mail: liusf2009@163.com); Department of Ultrasound, Shenzhen Maternity & Child Healthcare Hospital, Southern Medical University, 70570 Guangzhou, Guangdong China (e-mail: liaoyimei1987@qq.com); Department of Ultrasound, Shenzhen Maternity & Child Healthcare Hospital, Southern Medical University, 70570 Guangzhou, Guangdong China (e-mail: whxwell@126.com); National-Regional Key Technology Engineering Laboratory for Medical Ultrasound & Guangdong Provincial Key Laboratory of Biomedical Measurements and Ultrasound Imaging & School of Biomedical Engineering, Health Science Center, Shenzhen University, 47890 Shenzhen, Guangdong China (e-mail: leiby@szu.edu.cn); Department of Ultrasound, Shenzhen Maternity & Child Healthcare Hospital, Southern Medical University, 70570 Guangzhou, Guangdong China (e-mail: lishengli63@126.com); National-Regional Key Technology Engineering Laboratory for Medical Ultrasound & Guangdong Provincial Key Laboratory of Biomedical Measurements and Ultrasound Imaging & School of Biomedical Engineering, Health Science Center, Shenzhen University, 47890 Shenzhen, Guangdong China (e-mail: tfwang@szu.edu.cn)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","Quality control / assessment of ultrasound (US) images is an essential step in clinical diagnosis. This process is usually done manually, suffering from some drawbacks, such as dependence on operator's experience and extensive labors, as well as high inter- and intra-observer variation. Automatic quality assessment of US images is therefore highly desirable. Fetal US cardiac four-chamber plane (CFP) is one of the most commonly used cardiac views, which was used in the diagnosis of heart anomalies in the early 1980s. In this paper, we propose a generic deep learning framework for automatic quality control of fetal US CFPs. The proposed framework consists of three networks: (1) a basic CNN (B-CNN), roughly classifying four-chamber views from the raw data; (2) a deeper CNN (D-CNN), determining the gain and zoom of the target images in a multi-task learning manner; and (3) the aggregated residual visual block net (ARVBNet), detecting the key anatomical structures on a plane. Based on the output of the three networks, overall quantitative score of each CFP is obtained, so as to achieve fully automatic quality control. Experiments on a fetal US dataset demonstrated our proposed method achieved a highest mean average precision (mAP) of 93.52% at a fast speed of 101 frames per second (FPS). In order to demonstrate the adaptability and generalization capacity, the proposed detection network (i.e., ARVBNet) has also been validated on the PASCAL VOC dataset, obtaining a highest mAP of 81.2% when input size is approximately 300×300.","","","10.1109/JBHI.2019.2948316","National Basic Research Program of China (973 Program); National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8876642","Quality control;cardiac four-chamber planes (CFPs);convolutional neural network (CNN);real-time object detection;aggregated residual visual block (ARVB)","Quality control;Anatomical structure;Quality assessment;Ultrasonic imaging;Real-time systems","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Perceptual-aware Sketch Simplification Based on Integrated VGG Layers","X. Xu; M. Xie; P. Miao; W. Qu; W. Xiao; H. Zhang; X. Liu; T. Wong","Computer Science and Engineering, South China University of Technology, 26467 Guangzhou, Guangdong China (e-mail: xuemx@scut.edu.cn); Computer Science and Engineering, Chinese University of Hong Kong, 26451 New Territories, Hong Kong Hong Kong (e-mail: msxie@cse.cuhk.edu.hk); Computer Science and Engineering, South China University of Technology, 26467 Guangzhou, Guangdong China (e-mail: 201621032177@mail.scut.edu.cn); Computer Science and engineering, South China University of Technology, 26467 Guangzhou, Guangdong China (e-mail: csvivianqu@mail.scut.edu.cn); Computer Science and Engineering, South China University of Technology, 26467 Guangzhou, Guangdong China (e-mail: 201630599500@mail.scut.edu.cn); Computer Science and Engineering, South China University of Technology, 26467 Guangzhou, Guangdong China (e-mail: z.huaidong@mail.scut.edu.cn); Computing and Information Sciences, Caritas Institute of Higher Education, 66391 Hong Kong, Hong Kong Hong Kong (e-mail: xtliu@cse.cuhk.edu.hk); Computer Science and Engineering, Chinese University of Hong Kong, 26451 Shatin, Hong Kong Hong Kong (e-mail: ttwong@cse.cuhk.edu.hk)","IEEE Transactions on Visualization and Computer Graphics","","2019","PP","99","1","1","Deep learning has been recently demonstrated as an effective tool for raster-based sketch simplification. Nevertheless, it remains challenging to simplify extremely rough sketches. We found that a simplification network trained with a simple loss, such as pixel loss or discriminator loss, may fail to retain the semantically meaningful details when simplifying a very sketchy and complicated drawing. In this paper, we show that, with a well-designed multi-layer perceptual loss, we are able to obtain aesthetic and neat simplification results preserving semantically important global structures as well as fine details without blurriness and excessive emphasis on local structures. To do so, we design a multi-layer discriminator by fusing all VGG feature layers to differentiate sketches and clean lines. The weights used in layer fusing are automatically learned via an intelligent adjustment mechanism. Furthermore, to evaluate our method, we compare our method to state-of-the-art methods through multiple experiments, including visual comparison and intensive user study.","","","10.1109/TVCG.2019.2930512","Guangdong High-level Personnel of Special Support Program; National Natural Science Foundation of China; Guangdong RD key project of China; Natural Science Foundation of Guangdong Province; Guangzhou Key Project in Industrial Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8771128","Convolutional neural network;perceptual awareness;sketch simplification","Feature extraction;Semantics;Task analysis;Generative adversarial networks;Visualization;Lighting;Image segmentation","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Energy Compaction-Based Image Compression Using Convolutional AutoEncoder","Z. Cheng; H. Sun; M. Takeuchi; J. Katto","Computer Science and Communication Engineerings, Waseda University, 13148 Tokyo Japan 169-8555 (e-mail: zxcheng@asagi.waseda.jp); The Graduate School of Information,Production and Systems, Waseda University, Fukuoka Japan 808-0135 (e-mail: terrysun1989@akane.waseda.jp); Graduate School of Fundamental Science and Engineering, Waseda University, 13148 Shinjuku-ku, Tokyo Japan (e-mail: masaru-t@aoni.waseda.jp); Graduate School of Fundamental Science and Engineering, Waseda University, 13148 Shinjuku-ku, Tokyo Japan (e-mail: katto@waseda.jp)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","Image compression has been an important research topic for many decades. Recently, deep learning has achieved great success in many computer vision tasks, and its use in image compression has gradually been increasing. In this paper, we present an energy compaction-based image compression architecture using a convolutional autoencoder (CAE) to achieve high coding efficiency. Our main contributions include three aspects: 1) we propose a CAE architecture for image compression by decomposing it into several down(up)sampling operations; 2) for our CAE architecture, we offer a mathematical analysis on the energy compaction property and we are the first work to propose a normalized coding gain metric in neural networks, which can act as a measurement of compression capability; 3) based on the coding gain metric, we propose an energy compaction-based bit allocation method, which adds a regularizer to the loss function during the training stage to help the CAE maximize the coding gain and achieve high compression efficiency. The experimental results demonstrate our proposed method outperforms BPG (HEVC-intra), in terms of the MS-SSIM quality metric. Additionally, we achieve better performance in comparison with existing bit allocation methods, and provide higher coding efficiency compared with state-of-the-art learning compression methods at high bit rates.","","","10.1109/TMM.2019.2938345","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8820051","image compression;convolutional autoencoder;optimum bit allocation;energy compaction","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Applying Probabilistic Programming to Affective Computing","D. Ong; H. Soh; J. Zaki; N. Goodman","A*STAR Artificial Intelligence Initiative, Agency for Science Technology and Research, 54759 Singapore, Singapore Singapore (e-mail: desmond.c.ong@gmail.com); Department of Computer Science, National University of Singapore, 37580 Singapore, Singapore Singapore (e-mail: hsoh@comp.nus.edu.sg); Department of Psychology, Stanford University, 6429 Stanford, California United States (e-mail: jzaki@stanford.edu); Department of Psychology, Stanford University, 6429 Stanford, California United States (e-mail: ngoodman@stanford.edu)","IEEE Transactions on Affective Computing","","2019","PP","99","1","1","Affective Computing is a rapidly growing field spurred by advancements in artificial intelligence, but often, held back by the inability to translate psychological theories of emotion into tractable computational models. To address this, we propose a probabilistic programming approach to affective computing, which models psychological-grounded theories as generative models of emotion, and implements them as stochastic, executable computer programs. We first review probabilistic approaches that integrate reasoning about emotions with reasoning about other latent mental states (e.g., beliefs, desires) in context. Recently-developed probabilistic programming languages offer several key desidarata over previous approaches, such as: (i) flexibility in representing emotions and emotional processes; (ii) modularity and compositionality; (iii) integration with deep learning libraries that facilitate efficient inference and learning from large, naturalistic data; and (iv) ease of adoption. Furthermore, using a probabilistic programming framework allows a standardized platform for theory-building and experimentation: Competing theories (e.g., of appraisal or other emotional processes) can be easily compared via modular substitution of code followed by model comparison. To jumpstart adoption, we illustrate our points with executable code that researchers can easily modify for their own models. We end with a discussion of applications and future directions of the probabilistic programming approach","","","10.1109/TAFFC.2019.2905211","Ministry of Education - Singapore; Defense Advanced Research Projects Agency; National Institute of Mental Health; Science and Engineering Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8667687","Affective Computing;Artificial Intelligence;Emotion Theory;Modeling Human Emotion","Computational modeling;Probabilistic logic;Programming;Object oriented modeling;Cognition;Psychology;Affective computing","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Accelerating Sequential Minimal Optimization via Stochastic Subgradient Descent","B. Gu; Y. Shan; X. Quan; G. Zheng","Jiangsu Engineering Center of Network Monitoring, Nanjing University of Information Science and Technology, Nanjing 210012, China, and also with the School of Computer and Software, Nanjing University of Information Science and Technology, Nanjing 210012, China (e-mail: jsgubin@nuist.edu.cn).; School of Computer and Software, Nanjing University of Information Science and Technology, Nanjing 210012, China.; School of Computer and Software, Nanjing University of Information Science and Technology, Nanjing 210012, China.; School of Computer and Software, Nanjing University of Information Science and Technology, Nanjing 210012, China (e-mail: zgs@nuist.edu.cn).","IEEE Transactions on Cybernetics","","2019","PP","99","1","9","Sequential minimal optimization (SMO) is one of the most popular methods for solving a variety of support vector machines (SVMs). The shrinking and caching techniques are commonly used to accelerate SMO. An interesting phenomenon of SMO is that most of the computational time is wasted on the first half of iterations for building a good solution closing to the optimal. However, as we all know, the stochastic subgradient descent (SSGD) method is extremely fast for building a good solution. In this paper, we propose a generalized framework of accelerating SMO through SSGD for a variety of SVMs of binary classification, regression, ordinal regression, and so on. We also provide a deep insight about why SSGD can accelerate SMO. Experimental results on a variety of datasets and learning applications confirm that our method can effectively speed up SMO.","","","10.1109/TCYB.2019.2893289","Priority Academic Program Development of Jiangsu Higher Education Institutions; Natural Science Foundation; Six Talent Peaks Project in Jiangsu Province; 333 Project in Jiangsu Province; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8634909","Decomposition method;sequential minimal optimization (SMO);stochastic gradient descent (SGD);support vector machines (SVMs)","Acceleration;Kernel;Time complexity;Support vector machines;Buildings;Training;Static VAr compensators","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Computerized Classification of Prostate Cancer Gleason Scores from Whole Slide Images","H. Xu; S. Park; T. H. Hwang","Department of Quantitative Health Sciences, Cleveland Clinic, 2569 Cleveland, Ohio United States (e-mail: mxu@ualberta.ca); Department of Quantitative Health Sciences, Cleveland Clinic, 2569 Cleveland, Ohio United States (e-mail: parks@ccf.org); Department of Quantitative Health Sciences, Cleveland Clinic, 2569 Cleveland, Ohio United States (e-mail: hwangt@ccf.org)","IEEE/ACM Transactions on Computational Biology and Bioinformatics","","2019","PP","99","1","1","Histological Gleason grading of tumor patterns is one of the most powerful prognostic predictors in prostate cancer. However, manual analysis and grading performed by pathologists are typically subjective and time-consuming. In this paper, we present an automatic technique for Gleason grading of prostate cancer from H&E stained whole slide pathology images using a set of novel completed and statistical local binary pattern (CSLBP) descriptors. First the technique divides the whole slide image (WSI) into a set of small image tiles, where salient tumor tiles with high nuclei densities are selected for analysis. The CSLBP texture features that encode pixel intensity variations from circularly surrounding neighborhoods are extracted from salient image tiles to characterize different Gleason patterns. Finally, the CSLBP texture features computed from all tiles are integrated and utilized by the multi-class support vector machine (SVM) that assigns patient slides with different Gleason scores such as 6, 7 or >=8. Experiments have been performed on 312 different patient cases selected from the cancer genome atlas (TCGA) and have achieved superior performances over state-of-the-art texture descriptors and baseline methods including deep learning models for prostate cancer Gleason grading.","","","10.1109/TCBB.2019.2941195","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8836110","Prostate cancer;Medical image analysis;Texture features;Image classification","Tumors;Prostate cancer;Pathology;Feature extraction;Glands;Image segmentation","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Fast Pedestrian Detection With Attention-Enhanced Multi-Scale RPN and Soft-Cascaded Decision Trees","H. Wang; Y. Li; S. Wang","Institute for Artificial Intelligence, Tsinghua University (THUAI), Beijing 100084, China, with the Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing 100084, China, and also with the Department of Electronic Engineering, Tsinghua University, Beijing 100084, China.; Institute for Artificial Intelligence, Tsinghua University (THUAI), Beijing 100084, China, with the Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing 100084, China, and also with the Department of Electronic Engineering, Tsinghua University, Beijing 100084, China (e-mail: liyali13@mail.tsinghua.edu.cn).; Institute for Artificial Intelligence, Tsinghua University (THUAI), Beijing 100084, China, with the Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing 100084, China, and also with the Department of Electronic Engineering, Tsinghua University, Beijing 100084, China.","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","8","Pedestrian detection has attracted more attention in the fields of computer vision and artificial intelligence. A variety of real-world applications involving pedestrian detection have been promoted, such as Advanced Driving Assistant System (ADAS). Although both two-stage and single-stage deeply learned object detectors have shown outstanding performance for general object detection, they are still facing the problem of poor accuracy in single-class detection senario because they are designed to distinguish objects from different categories rather than pay attention to various appearances of pedestrians. Previous leading pedestrian detectors F-DNN and F-DNN v2 fuse several neural networks like SSD, VGG16 and GoogLeNet to generate ROIs and supress false alarms with cascaded structure, resulting in low miss rate but high complexity. In this paper we propose a novel framework called Attention-Enhanced Multi-Scale Region Proposal Network (AEMS-RPN) for ROI generation, which also acts as first-stage classification. Inspired by the success of traditional pedestrian detectors, we use soft-cascaded decision trees instead of cascaded deep neural networks to achieve high accuracy and fast detection speed simultaneously. The decision tree classifier is used and enables us to combine features from different layers with various resolutions for classification and incorporate effective bootstrapping for mining hard negatives. We test our method on several pedestrian detection datasets and the experimental results certify the effectiveness of the proposed AEMS-RPN. Compared with the state-of-the-art, we obtain the competitive accuracy with near real-time efficiency.","","","10.1109/TITS.2019.2948398","National Natural Science Foundation of China; State Key Development Program in 13th Five-Year; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8883216","Pedestrian detection;attention mechanism;multi-scale;soft-cascade;DNN.","Feature extraction;Convolution;Proposals;Decision trees;Detectors;Neural networks;Intelligent transportation systems","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"NetVision: On-Demand Video Processing in Wireless Networks","Z. Lu; K. Chan; R. Urgaonkar; S. Pu; T. L. Porta","Department of Computer Science, Peking University, Beijing 100871, China (e-mail: zongqing.lu@pku.edu.cn).; Army Research Laboratory, Adelphi, MD 20783 USA.; Amazon, Seattle, WA 98109-5210 USA.; Hikvision, Hangzhou 310051, China.; School of Electrical Engineering and Computer Science, Pennsylvania State University, University Park, PA 16802 USA.","IEEE/ACM Transactions on Networking","","2019","PP","99","1","14","The vast adoption of mobile devices with cameras has greatly contributed to the proliferation of the creation and distribution of videos. For a variety of purposes, valuable information may be extracted from these videos. While the computational capability of mobile devices has greatly improved recently, video processing is still a demanding task for mobile devices. We design an on-demand video processing system, NetVision, that performs distributed video processing using deep learning across a wireless network of mobile and edge devices to answer queries while minimizing the query response time. However, the problem of minimal query response time for processing videos stored across a network is a strongly NP-hard problem. To deal with this, we design a greedy algorithm with bounded performance. To further deal with the dynamics of the transmission rate between mobile and edge devices, we design an adaptive algorithm. We built NetVision and deployed it on a small testbed. Based on the measurements of the testbed and by extensive simulations, we show that the greedy algorithm is close to the optimum and the adaptive algorithm performs better with more dynamic transmission rates. We then perform experiments on the small testbed to examine the realized system performance in both stationary networks and mobile networks.","","","10.1109/TNET.2019.2954909","Network Science CTA; NSF China; Hikvision; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8931010","Video processing;edge computing;wireless networks.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"ADN: Artifact Disentanglement Network for Unsupervised Metal Artifact Reduction","H. Liao; W. Lin; S. K. Zhou; J. Luo","Department of Computer Science, University of Rochester, Rochester, NY 14627, USA.; Department of Electrical and Computer Engineering, University of Maryland, College Park, MD 20742, USA.; Institute of Computing Technology, Chinese Academy of Sciences, Beijing 100190, China and Peng Cheng Laboratory, Shenzhen, China.; Department of Computer Science, University of Rochester, Rochester, NY 14627, USA.","IEEE Transactions on Medical Imaging","","2019","PP","99","1","1","Current deep neural network based approaches to computed tomography (CT) metal artifact reduction (MAR) are supervised methods that rely on synthesized metal artifacts for training. However, as synthesized data may not accurately simulate the underlying physical mechanisms of CT imaging, the supervised methods often generalize poorly to clinical applications. To address this problem, we propose, to the best of our knowledge, the first unsupervised learning approach to MAR. Specifically, we introduce a novel artifact disentanglement network that disentangles the metal artifacts from CT images in the latent space. It supports different forms of generations (artifact reduction, artifact transfer, and self-reconstruction, etc.) with specialized loss functions to obviate the need for supervision with synthesized data. Extensive experiments show that when applied to a synthesized dataset, our method addresses metal artifacts significantly better than the existing unsupervised models designed for natural image-to-image translation problems, and achieves comparable performance to existing supervised models for MAR. When applied to clinical datasets, our method demonstrates better generalization ability over the supervised models. The source code of this paper is publicly available at.","","","10.1109/TMI.2019.2933425","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8788607","Image enhancement/restoration (noise and artifact reduction);neural network;X-ray imaging and computed tomography","Metals;Computed tomography;Decoding;Mars;X-ray imaging;Image reconstruction;Training","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Local Attention Networks for Occluded Airplane Detection in Remote Sensing Images","M. Zhou; Z. Zou; Z. Shi; W. Zeng; J. Gui","Image Processing Center, School of Astronautics, Beihang University, Beijing 100191, China, with the Beijing Key Laboratory of Digital Media, Beihang University, Beijing 100191, China, and also with the State Key Laboratory of Virtual Reality Technology and Systems, School of Astronautics, Beihang University, Beijing 100191, China.; Department of Computational Medicine and Bioinformatics, University of Michigan, Ann Arbor, MI 48109 USA.; Image Processing Center, School of Astronautics, Beihang University, Beijing 100191, China, with the Beijing Key Laboratory of Digital Media, Beihang University, Beijing 100191, China, and also with the State Key Laboratory of Virtual Reality Technology and Systems, School of Astronautics, Beihang University, Beijing 100191, China (e-mail: shizhenwei@buaa.edu.cn).; Department of Computational Medicine and Bioinformatics, University of Michigan, Ann Arbor, MI 48109 USA.; Department of Computational Medicine and Bioinformatics, University of Michigan, Ann Arbor, MI 48109 USA.","IEEE Geoscience and Remote Sensing Letters","","2019","PP","99","1","5","Despite the great progress of deep learning and target detection in recent years, the accurate detection of the occluded targets in remote sensing images still remains a challenge. In this letter, we propose a new detection method called local attention networks to improve the detection of occluded airplanes. Following the idea of ``divide and conquer,'' the proposed method is designed by first dividing an airplane target into four visual parts: head, left/right wings, body, and tail, and then considering the detection as the prediction of the individual key points in each of the visual parts. We further introduce an additional attention branch in the standard detection pipeline to enhance the features and make the model focus on individual parts of a target even if it is only partially visible in the image. Detection results and ablation studies on three remote sensing target detection data sets (including two publicly available ones) demonstrate the effectiveness of our method, especially for occluded airplane targets. In addition, our method outperforms the other state-of-the-art detection methods on these data sets.","","","10.1109/LGRS.2019.2924822","National Basic Research Program of China (973 Program); National Natural Science Foundation of China; Natural Science Foundation of Beijing Municipality; National Defense Science and Technology Innovation Special Zone Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8769873","Airplane detection;attention mechanism;remote sensing images;target occlusion.","Airplanes;Feature extraction;Remote sensing;Visualization;Object detection;Standards;Task analysis","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Improving Whole-heart CT Image Segmentation by Attention Mechanism","W. Wang; C. Ye; S. Zhang; Y. Xu; K. Wang","Bio-Computing Research Center, Harbin Institute of Technology, Shenzhen, 518055, China.; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, 150001, China.; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, 150001, China.; Bio-Computing Research Center, Harbin Institute of Technology, Shenzhen, 518055, China.; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, 150001, China.","IEEE Access","","2019","PP","99","1","1","Decent whole-heart segmentation from computed tomography (CT) can greatly contribute to the diagnosis and treatment of cardiovascular diseases. However, due to the difficulties such as blurred boundaries between neighbouring tissues and a large number of background voxels in medical images, automated whole-heart segmentation is still a challenging task. In this paper, we proposed three modified attention models, including simple negative example mining (SNEM), attention gate (AG) and U-CliqueNet (UCNet), to lead the deep learning network to focus on more salient information. These three attention modules were further implemented into a deeply-supervised 3D UNET separately and jointly, showing different degrees of improvement on the whole-heart segmentation task. Our experiments advised that SNEM was the most simple and effective attention mechanism for medical image processing among the three and the UCNet could reach the best performance. The combination of the attention mechanisms cannot always synergistically increase the accuracy, but joint models would have a positive influence in most cases. Finally, our network achieved a Dice score of 0.9112, which was a substantially higher performance than most of the state-of-the-art methods.","","","10.1109/ACCESS.2019.2961410","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8938714","medical image processing;CT image segmentation;attention mechanism;attention gate;feedback connection","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"Lip image segmentation based on a fuzzy convolutional neural network","C. Guan; S. Wang; A. W. Liew","The School of Electronic Information & Electrical Engineering, Shanghai Jiao Tong University, 12474 Shanghai China 200240 (e-mail: Gclalaboo@sjtu.edu.cn); The School of Electronic Information & Electrical Engineering, Shanghai Jiaotong University, Shanghai China (e-mail: wsl@sjtu.edu.cn); School of Information and Communication Technology, Griffith University, Gold Coast, Queensland Australia QLD 4222 (e-mail: a.liew@griffith.edu.au)","IEEE Transactions on Fuzzy Systems","","2019","PP","99","1","1","Research has shown that the human lip and its movements are a rich source of information related to speech content and speaker's identity. Lip image segmentation, as a fundamental step in many lip-reading and visual speaker authentication systems, is of vital importance. Because of variations in lip color, lighting conditions and especially the complex appearance of an open mouth, accurate lip region segmentation is still a challenging task. To address this problem, this paper proposes a new fuzzy deep neural network having an architecture that integrates fuzzy units and traditional convolutional units. The convolutional units are used to extract discriminative features at different scales to provide comprehensive information for pixel-level lip segmentation. The fuzzy logic modules are employed to handle various kinds of uncertainties and to provide a more robust segmentation result. An end-to-end training scheme is then used to learn the optimal parameters for both the fuzzy and the convolutional units. A dataset containing more than 48,000 images of various speakers, under different lighting conditions, was used to evaluate lip segmentation performance. According to the experimental results, the proposed method achieves state-of-the-art performance when compared with other algorithms.","","","10.1109/TFUZZ.2019.2957708","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8929014","fuzzy neural networks;convolutional neural network;lip region segmentation","Lips;Image segmentation;Image color analysis;Mouth;Convolutional neural networks;Image edge detection;Robustness","","","","","","","","","","IEEE","IEEE Early Access Articles"
"DiLSe: Lattice-based Secure and Dependable Data Dissemination Scheme for Social Internet of Vehicles","A. Gulati; G. S. Aujla; R. Chaudhary; N. Kumar; M. Obaidat; A. Benslimane","CSED, Thapar University, 29080 Patiala, Punjab India (e-mail: amuleengulati13@gmail.com); Computer Science & Engineering, Chandigarh University, 418665 Mohali, Punjab India 140413 (e-mail: gagi_aujla82@yahoo.com); CSED, Thapar University, 29080 Patiala, Punjab India (e-mail: rajatlibran@gmail.com); CSED, Thapar University, Patiala, Patiala, Punjab India (e-mail: neeraj.kumar@thapar.edu); CSSE, Monmouth University, W. Long Branch, New Jersey United States 07764 (e-mail: msobaidat@gmail.com); Computer Sciences LIA/CERI, University of Avignon, Avignon cedex 9, PACA France 84911 (e-mail: abderrahim.benslimane@univ-avignon.fr)","IEEE Transactions on Dependable and Secure Computing","","2019","PP","99","1","1","With the evolution of Internet of Vehicles (IoV), there has been an overwhelming increase in the number of connected vehicles in recent times. Due to this reason, massive amounts of data generated by connected vehicles makes traditional host centric approach inevitable in IoV ecosystem. Moreover, the existing TCP/IP-based congestion control mechanisms can not be directly applied in IoV environment as there is a requirement of content sharing among vehicles with reduced delay and high throughput. So, in this paper1, DiLSe: A Lattice-based Secure and Dependable Data Dissemination Scheme for Social Internet of Vehicles is designed, which works in three modules. The first module, i.e., deep learning based content centric data dissemination scheme, works in three phases; 1) In first phase, the connection probability of vehicles is computed to identify stable and reliable connections using Weiner process model, 2) In second phase, a convolutional neural network based scheme is presented for estimating the social relationship score among vehicle-to-vehicle pair, and 3) In third phase, a content centric data dissemination scheme is presented. However, the mobility of vehicles in IoV ecosystem gives them liberty to move in/out of the network without IP assignment.","","","10.1109/TDSC.2019.2953841","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8903470","Content Centric Networks;Convolutional Neural Networks;Data Dissemination;Internet of vehicles;Lattice","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Small Object Detection in Unmanned Aerial Vehicle Images Using Feature Fusion and Scaling-Based Single Shot Detector with Spatial Context Analysis","X. Liang; J. Zhang; L. Zhuo; Y. Li; Q. Tian","Faculty of Information Technology, Beijing University of Technology, 100 Ping Le Yuan, Chao Yang District, Beijing 100124, China and Beijing Key Laboratory of Computational Intelligence and Intelligent System, Beijing University of Technology.; Faculty of Information Technology, Beijing University of Technology, 100 Ping Le Yuan, Chao Yang District, Beijing 100124, China and Beijing Key Laboratory of Computational Intelligence and Intelligent System, Beijing University of Technology.; Faculty of Information Technology, Beijing University of Technology, 100 Ping Le Yuan, Chao Yang District, Beijing 100124, China and Beijing Key Laboratory of Computational Intelligence and Intelligent System, Beijing University of Technology and Collaborative Innovation Center of Electric Vehicles in Beijing, Beijing 100124, China.; Faculty of Information Technology, Beijing University of Technology, 100 Ping Le Yuan, Chao Yang District, Beijing 100124, China and Beijing Key Laboratory of Computational Intelligence and Intelligent System, Beijing University of Technology.; Noah’s Ark Lab, Huawei, China. and Department of Computer Science, University of Texas at San Antonio, TX 78249-1604, USA.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Objects in unmanned aerial vehicle (UAV) images are generally small due to the high photography altitude. Although many efforts have been made in object detection, how to accurately and quickly detect small objects is still one of the remaining open challenges. In this paper, we propose a feature fusion and scaling-based single shot detector (FS-SSD) for small object detection in UAV images. FS-SSD is an enhancement based on FSSD, a variety of the original single shot multibox detector (SSD). We add an extra scaling branch of the deconvolution module with an average pooling operation to form a feature pyramid. The original feature fusion branch is adjusted to be better suited to the small object detection task. The two feature pyramids generated by the deconvolution module and feature fusion module are utilized to make predictions together. In addition to the deep features learned by FS-SSD, to further improve the detection accuracy, spatial context analysis is proposed to incorporate the object spatial relationships into object redetection. The interclass and intraclass distances between different object instances are computed as spatial context, which proves effective for multiclass small object detection. Six experiments are conducted on the PASCAL VOC dataset and two UAV image datasets. The experimental results demonstrate that the proposed method can achieve a comparable detection speed but an accuracy superior to those of the six state-of-the-art methods.","","","10.1109/TCSVT.2019.2905881","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8672115","Unmanned aerial vehicle (UAV) image;small object detection;feature fusion;feature scaling;single shot detector;spatial context analysis","Object detection;Feature extraction;Detectors;Unmanned aerial vehicles;Deconvolution;Photography;Remote sensing","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Context-Aware Object Detection for Vehicular Networks Based on Edge-Cloud Cooperation","J. Guo; B. Song; S. Chen; F. R. Yu; X. Du; M. Guizani","State Key Laboratory of Integrated Services Networks, Xidian University, Xi’an Shaanxi Province, 710071, China.; State Key Laboratory of Integrated Services Networks, Xidian University, Xi’an Shaanxi Province, 710071, China.; State Key Laboratory of Integrated Services Networks, Xidian University, Xi’an Shaanxi Province, 710071, China.; Careleton University, Ottawa, K1S 5B6, Canada.; Depart. of Computer and Information Sciences, Temple University, Philadelphia, PA 19122, USA.; Department of College of Engineering, Qatar University, Qatar.","IEEE Internet of Things Journal","","2019","PP","99","1","1","Due to high mobility and high dynamic environments, object detection for vehicular networks is one of the most challenging tasks. However, the development of integration techniques, such as software-defined networking (SDN) and network function visualization (NFV), in networking, caching and computing provide us with new approaches. In this paper, we propose a novel context-aware object detection method based on edge-cloud cooperation. Specifically, an object detection model based on deep learning is established in the could server. Different from other methods, to further explore the underlying inner spatial features of collected images, the visual objects of images are regarded as nodes and the spatial relations between objects as edges, then a type of message passing method is employed to update the nodes’ features. In the mobile edge computing (MEC) servers, the context information and captured images of the vehicular environments are extracted and then are used to adjust the object detection model from the cloud server. In this way, cloud server cooperates with MEC servers to realize context-aware object detection, which improves the adaptation and performance of the detection model under different scenarios. Simulation results also demonstrate that the proposed method is more accurate and faster than previous methods.","","","10.1109/JIOT.2019.2949633","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8883194","Context-aware;object detection;edge-cloud cooperation;vehicular networks.","Object detection;Servers;Adaptation models;Feature extraction;Context modeling;Cloud computing;Computational modeling","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Countering Malicious URLs in Internet-of-Thing (IoT) using a knowledge-based approach and simulated expert","S. Anwar; F. Al-Obeidat; A. Tubaishat; S. Din; A. Ahmad; F. A. Khan; G. Jeon; J. Loo","Institute of Management Sciences, Peshawar, Pakistan.; College of Technological Innovation, Zayed University, Abu Dhabi, UAE.; College of Technological Innovation, Zayed University, UAE.; School of Computer Science and Engineering, Kyungpook National University, Korea.; Dipartimento di Informatica, Università degli Studi di Milano, Milan, Italy.; Institute of Management Sciences, Peshawar Pakistan.; School of Electronic Engineering, Xidian University, Xi’an, China and with Department of Embedded Systems Engineering, Incheon National University, Korea.; School of Computing and Engineering, University of West London, UK.","IEEE Internet of Things Journal","","2019","PP","99","1","1","This study proposes a novel methodology to detect malicious URLs using simulated expert (SE) and knowledge base system (KBS). The proposed study not only efficiently detects known malicious URLs, but also adapt countermeasure against the newly generated malicious URLs. Moreover, this study also explored which lexical features are more contributing in final decision using a factor analysis method and thus helped in avoiding involvement of human expert. Further, we applied the following state-of-the-art ML algorithms, i.e., Naïve Bayes (NB), Decision Tree (DT), Gradient Boosted Trees (GBT), Generalized Linear Model (GLM), Logistic Regression (LR), Deep Learning (DL), and Random rest (RF), and evaluated the performance of these algorithms on a large-scale real data set of data-driven Web application. The experimental results clearly demonstrated the efficiency of NB in the proposed model as NB outperformed when compared to the rest of aforementioned algorithms in term of average minimum execution time (i.e., 3 seconds) and was able to accurately classify the 107586 URLs with 0.2% error rate and 99.8% accuracy rate.","","","10.1109/JIOT.2019.2954919","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8908778","Malicious URLs;URLs Classification;Naïve Bayes;Simulated Experts;Feature Extraction.","Uniform resource locators;Feature extraction;Radio frequency;Classification algorithms;Phishing;Blacklisting;Internet of Things","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Omnidirectional Motion Classification With Monostatic Radar System Using Micro-Doppler Signatures","Y. Yang; C. Hou; Y. Lang; T. Sakamoto; Y. He; W. Xiang","School of Electrical and Information Engineering, Tianjin University, Tianjin 300072, China.; School of Electrical and Information Engineering, Tianjin University, Tianjin 300072, China.; School of Electrical and Information Engineering, Tianjin University, Tianjin 300072, China (e-mail: langyue@tju.edu.cn).; Graduate School of Engineering, Kyoto University, Kyoto 615-8510, Japan.; School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing 100876, China.; College of Science and Engineering, James Cook University, Cairns, QLD 4870, Australia.","IEEE Transactions on Geoscience and Remote Sensing","","2019","PP","99","1","14","In remote sensing, micro-Doppler signatures are widely used in moving target detection and automatic target recognition. However, since Doppler signatures are easily affected by the moving direction of the target, prior information of aspect angle is essential for spectral analysis. Thus, a micro-Doppler-based classifier is considered to be ``angle-sensitive.'' In this article, we propose an angle-insensitive classifier for the omnidirectional classification problem using the monostatic radar through a proposed new convolutional neural network. We further provide a sensible definition of ``angle sensitivity,'' and perform experiments on two data sets obtained through simulations and measurements. The results demonstrate that the proposed algorithm outperforms both feature-based and existing deep-learning-based counterparts, and resolve the issue of angle sensitivity in micro-Doppler-based classification.","","","10.1109/TGRS.2019.2958178","National Natural Science Foundation of China; Japan Society for the Promotion of Science JSPS KAKENHI; Japan Science and Technology Agency JST the Precursory Research for Embryonic Science and Technology PRESTO Japan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8944152","Angle sensitivity;convolutional neural network (CNN);human motion classification;micro-Doppler.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Spatio-Temporal Ensemble Method for Car-Hailing Demand Prediction","Y. Liu; C. Lyu; A. Khadka; W. Zhang; Z. Liu","Jiangsu Key Laboratory of Urban ITS, Jiangsu Province Collaborative Innovation Center of Modern Urban Traffic Technologies, School of Transportation, Southeast University, Nanjing 211189, China.; Jiangsu Provincial Key Laboratory of Networked Collective Intelligence, School of Mathematics, Southeast University, Nanjing 211189, China, and also with the School of Transportation, Southeast University, Nanjing 211189, China.; Jiangsu Key Laboratory of Urban ITS, Jiangsu Province Collaborative Innovation Center of Modern Urban Traffic Technologies, School of Transportation, Southeast University, Nanjing 211189, China.; Jiangsu Key Laboratory of Urban ITS, Jiangsu Province Collaborative Innovation Center of Modern Urban Traffic Technologies, School of Transportation, Southeast University, Nanjing 211189, China.; Jiangsu Key Laboratory of Urban ITS, Jiangsu Province Collaborative Innovation Center of Modern Urban Traffic Technologies, School of Transportation, Southeast University, Nanjing 211189, China (e-mail: zhiyuanl@seu.edu.cn).","IEEE Transactions on Intelligent Transportation Systems","","2019","PP","99","1","6","Accurate demand prediction plays a significant role in online car-hailing platforms. With ensemble learning, several models can be combined into a single demand predictive model, achieving low prediction error. Nevertheless, the existing ensemble methods are not intended for spatio-temporal data and thus cannot deal with it. In this article, a spatio-temporal data ensemble model is proposed to predict car-hailing demands. Treating the prediction results as various channels of an image, the proposed ensemble module first compresses and then restores the results using the fully convolutional network. Additionally, a skip connection is used to preserve both the fine-grained information in the shallow layers and the deep coarse information. Based on the principle of model as a service, any model can be plugged into our framework as base models to improve the prediction accuracy. Experimental results demonstrate the effectiveness of the presented model.","","","10.1109/TITS.2019.2948790","National Natural Science Foundation of China through the General Projects; National Natural Science Foundation of China through the Key Projects; Jiangsu Provincial Key Laboratory of Networked Collective Intelligence; Postgraduate Research and Practice Innovation Program of Jiangsu Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8884679","Car-hailing demand prediction;spatio-temporal ensemble;fully convolutional networks.","Predictive models;Public transportation;Urban areas;Time series analysis;Demand forecasting;Data models;Correlation","","","","","","","","","","IEEE","IEEE Early Access Articles"
"An End-to-end Steel Surface Defect Detection Approach via Fusing Multiple Hierarchical Features","Y. He; K. Song; Q. Meng; Y. Yan","School of Mechanical Engineering and Automation, Northeastern University, Shenyang, 110819, China and Key Laboratory of Vibration and Control of Aero-Propulsion Systems Ministry of Education of China, Northeastern University, Shenyang, Liaoning, 110819, China.; School of Mechanical Engineering and Automation, Northeastern University, Shenyang, 110819, China and Key Laboratory of Vibration and Control of Aero-Propulsion Systems Ministry of Education of China, Northeastern University, Shenyang, Liaoning, 110819, China.; Department of Computer Science, LoughboroughUniversity, Loughborough LE11 3TU, U.K.; School of Mechanical Engineering and Automation, Northeastern University, Shenyang, 110819, China and Key Laboratory of Vibration and Control of Aero-Propulsion Systems Ministry of Education of China, Northeastern University, Shenyang, Liaoning, 110819, China.","IEEE Transactions on Instrumentation and Measurement","","2019","PP","99","1","1","A complete defect detection task aims to achieve the specific class and precise location of each defect in an image, which makes it still challenging for applying this task in practice. The defect detection is a composite task of classification and location, leading to related methods are often hard to take into account the accuracy of both. And the implementation of defect detection depends on a special detection dataset which contains expensive manual annotations. In this paper, we proposed a novel defect detection system based on deep learning and focused on a practical industrial application: steel plate defect inspection. In order to achieve strong classification-ability, this system employs a baseline convolution neural network (CNN) to generate feature maps at each stage. And then the proposed multilevel-feature fusion network (MFN) combines multiple hierarchical features into one feature, which can include more location details of defects. Based on these multilevel features, a region proposal network (RPN) is adopted to generate regions of interest (ROIs). For each ROI, a detector, consisting of a classifier and a bounding box regressor, produces the final detection results. Finally, we set up a defect detection dataset NEU-DET for training and evaluating our method. On the NEU-DET, our method achieves 74.8/82.3 mAP with baseline networks ResNet34/50 by using 300 proposals. In addition, by using only 50 proposals, our method can detect at 20 fps on a single GPU and reach 92% of the above performance, hence the potential for real-time detection.","","","10.1109/TIM.2019.2915404","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8709818","Automated defect inspection;defect detection dataset (NEU-DET);defect detection network (DDN);multilevel-feature fusion network (MFN)","Feature extraction;Task analysis;Inspection;Detectors;Steel;Proposals;Training","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"CR-Unet: A Composite Network for Ovary and Follicle Segmentation in Ultrasound Images","H. Li; J. Fang; S. Liu; X. Liang; X. Yang; Z. Mai; M. The Van; T. Wang; Z. Chen; D. Ni","Medical UltraSound Image Computing (MUSIC) Lab, National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Provincial Key Laboratory of Biomedical Measurements and Ultrasound Imaging, School of Biomedical Engineering, Health Science Center, Shenzhen University, 47890 Shenzhen, Guanghdong China (e-mail: lihao.ming@163.com); Department of Ultrasound Medicine, Laboratory of Ultrasound Medicine and Artificial Intelligence,Experimental Center of Liwan Hospital,The Third Affiliated Hospital, Guangzhou Medical University, 26468 Guangzhou, Guangdong China (e-mail: jhfang2018@163.com); Medical UltraSound Image Computing (MUSIC) Lab, National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Provincial Key Laboratory of Biomedical Measurements and Ultrasound Imaging, School of Biomedical Engineering, Health Science Center, Shenzhen University, 47890 Shenzhen, Guangdong China (e-mail: liusf2009@163.com); Department of Ultrasound Medicine, Laboratory of Ultrasound Medicine and Artificial Intelligence,Experimental Center of Liwan Hospital,The Third Affiliated Hospital, Guangzhou Medical University, 26468 Guangzhou, Guangdong China (e-mail: 419969951@qq.com); Department of Computer Science and Engineering, Chinese University of Hong Kong, 26451 New Territories, Hong Kong Hong Kong (e-mail: yangxinknow@gmail.com); Department of Ultrasound Medicine, Laboratory of Ultrasound Medicine and Artificial Intelligence,Experimental Center of Liwan Hospital,The Third Affiliated Hospital, Guangzhou Medical University, 26468 Guangzhou, Guangdong China (e-mail: 610958234@qq.com); Medical UltraSound Image Computing (MUSIC) Lab, National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Provincial Key Laboratory of Biomedical Measurements and Ultrasound Imaging, School of Biomedical Engineering, Health Science Center, Shenzhen University, 47890 Shenzhen, Guangdong China (e-mail: manhthevan@tic.edu.vn); Medical UltraSound Image Computing (MUSIC) Lab, National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Provincial Key Laboratory of Biomedical Measurements and Ultrasound Imaging, School of Biomedical Engineering, Health Science Center, Shenzhen University, 47890 Shenzhen, Guangdong China (e-mail: tfwang@szu.edu.cn); Department of Ultrasound Medicine, Laboratory of Ultrasound Medicine and Artificial Intelligence,Experimental Center of Liwan Hospital,The Third Affiliated Hospital, Guangzhou Medical University, 26468 Guangzhou, Guangdong China (e-mail: winchen@vip.126.com); Medical UltraSound Image Computing (MUSIC) Lab, National-Regional Key Technology Engineering Laboratory for Medical Ultrasound, Guangdong Provincial Key Laboratory of Biomedical Measurements and Ultrasound Imaging, School of Biomedical Engineering, Health Science Center, Shenzhen University, 47890 Shenzhen, Guangdong China (e-mail: nidong@szu.edu.cn)","IEEE Journal of Biomedical and Health Informatics","","2019","PP","99","1","1","Transvaginal ultrasound (TVUS) is widely used in infertility treatment. The size and shape of the ovary and follicles must be measured manually for assessing their physiological status by sonographers. However, this process is extremely time-consuming and operator-dependent. In this study, we propose a novel composite network, namely CR-Unet, to simultaneously segment the ovary and follicles in TVUS. The CR-Unet incorporates the spatial recurrent neural network (RNN) into a plain U-Net. It can effectively learn multi-scale and long-range spatial contexts to combat the challenges of this task, such as the poor image quality, low contrast, boundary ambiguity, and complex anatomy shapes. We further adopt deep supervision strategy to make model training more effective and efficient. In addition, self-supervision is employed to iteratively refine the segmentation results. Experiments on 3204 TVUS images from 219 patients demonstrate the proposed method achieved the best segmentation performance compared to other state-of-the-art methods for both the ovary and follicles, with a Dice Similarity Coefficient (DSC) of 0.912 and 0.858, respectively.","","","10.1109/JBHI.2019.2946092","Medical Scientific Research Foundation of Guangdong Province China; Scientific and Technological Livelihood Projects of Liwan District; Shenzhen Peacock Plan; National Natural Science Foundation of China; National Key Research and Development Program of China; Young Scientists Fund of the National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8861329","Ovarian follicle;segmentation;transvaginal ultrasound;U-Net;recurrent neural network","Two dimensional displays;Image segmentation;Ultrasonic imaging;Shape;Task analysis;Biomedical imaging;Support vector machines","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Monitoring Enterprise DNS Queries for Detecting Data Exfiltration from Internal Hosts","J. Ahmed; H. H. Gharakheili; Q. Raza; C. Russell; V. Sivaraman","School of Electrical Engineering and Telecommunications, University of New South Wales, Sydney, 2052 Australia.; School of Electrical Engineering and Telecommunications, University of New South Wales, Sydney, 2052 Australia.; School of Electrical Engineering and Telecommunications, University of New South Wales, Sydney, 2052 Australia.; CSIRO Data61, Sydney, NSW 2015, Australia.; School of Electrical Engineering and Telecommunications, University of New South Wales, Sydney, 2052 Australia.","IEEE Transactions on Network and Service Management","","2019","PP","99","1","1","Enterprise networks constantly face the threat of valuable and sensitive data being stolen by cyber-attackers. Sophisticated attackers are increasingly exploiting the Domain Name System (DNS) service for exfiltrating data as well as maintaining tunneled command and control communications for malware. This is because DNS traffic is usually allowed to pass through enterprise firewalls without deep inspection or state maintenance, thereby providing a covert channel for attackers to encode low volumes of data without fear of detection. This paper develops and evaluates a real-time mechanism for detecting exfiltration and tunneling of data over DNS. Unlike prior solutions that operate off-line or in the network core, ours works in real-time at the enterprise edge. Our first contribution is to collect and analyze real DNS traffic from two organizations (a large University and a mid-sized Government Research Institute) over several days and extract numerous stateless attributes of DNS messages that can distinguish malicious from legitimate queries. Our second contribution is to develop, tune, and train a machine-learning algorithm to detect anomalies in DNS queries using a benign dataset of top rank primary domains. To achieve this, we have used 14 days-worth of DNS traffic from each organization. For our third contribution, we implement our scheme on live 10 Gbps traffic streams from the network borders of the two organizations, inject more than three million malicious DNS queries generated by two exfiltration tools, and show that our solution can identify them with high accuracy. We compare our solution with the two-class classifier used in prior work. We draw insights into anomalous DNS queries of two enterprise networks by their anomaly scores, the trace of query count over time, enterprise hosts querying them, and TTL and Type fields of their corresponding responses. Our tools and datasets are made available to the public for validation and further research.","","","10.1109/TNSM.2019.2940735","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8832271","DNS;Enterprise;Exfiltration;Anomaly Detection.","Malware;Organizations;Real-time systems;Tunneling;Tools;Credit cards;Command and control systems","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Multi-scale Spatial-temporal Attention Model for Person Re-identification in Videos","W. Zhang; X. He; X. Yu; W. Lu; Z. Zha; Q. Tian","School of Control Science and Engineering, Shandong University, Jinan, China.; School of Control Science and Engineering, Shandong University, Jinan, China.; School of Control Science and Engineering, Shandong University, Jinan, China.; School of Control Science and Engineering, Shandong University, Jinan, China.; School of Information Science and Technology, University of Science and Technology of China, Hefei, China.; Department of Computer Science, University of Texas at San Antonio (UTSA), Texas, USA.","IEEE Transactions on Image Processing","","2019","PP","99","1","1","In this paper, we propose a novel deep neural network based attention model to learn the representative local regions from a video sequence for person re-identification. Specifically, we propose a multi-scale spatial-temporal attention (MSTA) model to measure the regions of each frame in different scales from the perspective of whole video sequence. Compared to traditional temporal attention models, MSTA focuses on exploiting the importance of local regions of each frame to the whole video representation in both spatial and temporal domains. A new training strategy is designed for the proposed model by incorporating the image-to-image mode with the videoto- video mode. Extensive experiments on benchmark datasets demonstrate the superiority of the proposed model over state-ofthe- art methods.","","","10.1109/TIP.2019.2959653","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8941279","Video-based person re-id;Spatial-temporal attention;Multi-scale pooling","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Automatic Construction of Chinese Herbal Prescriptions From Tongue Images Using CNNs and Auxiliary Latent Therapy Topics","Y. Hu; G. Wen; H. Liao; C. Wang; D. Dai; Z. Yu","School of Computer Science and Engineering, South China University of Technology, Guangzhou 510000, China; School of Computer Science and Engineering, South China University of Technology, Guangzhou 510000, China (e-mail: crghwen@scut.edu.cn).; School of Computer Science and Engineering, South China University of Technology, Guangzhou 510000, China; Department of Chinese Medicine, Guangdong General Hospital, Guangzhou 510000, China.; School of Computer Science and Engineering, South China University of Technology, Guangzhou 510000, China; School of Computer Science and Engineering, South China University of Technology, Guangzhou 510000, China","IEEE Transactions on Cybernetics","","2019","PP","99","1","14","The tongue image provides important physical information of humans. It is of great importance for diagnoses and treatments in clinical medicine. Herbal prescriptions are simple, noninvasive, and have low side effects. Thus, they are widely applied in China. Studies on the automatic construction technology of herbal prescriptions based on tongue images have great significance for deep learning to explore the relevance of tongue images for herbal prescriptions, it can be applied to healthcare services in mobile medical systems. In order to adapt to the tongue image in a variety of photographic environments and construct herbal prescriptions, a neural network framework for prescription construction is designed. It includes single/double convolution channels and fully connected layers. Furthermore, it proposes the auxiliary therapy topic loss mechanism to model the therapy of Chinese doctors and alleviate the interference of sparse output labels on the diversity of results. The experiment use the real-world tongue images and the corresponding prescriptions and the results can generate prescriptions that are close to the real samples, which verifies the feasibility of the proposed method for the automatic construction of herbal prescriptions from tongue images. Also, it provides a reference for automatic herbal prescription construction from more physical information.","","","10.1109/TCYB.2019.2909925","Guangdong Province Higher Vocational Colleges and Schools Pearl River Scholar Funded Scheme; National Natural Science Foundation of China; Science and Technology Planning Projects of Guangdong Province; Guangzhou Science and Technology Planning Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8705645","Convolution channels;neural networks;prescriptions construction;therapy topics;tongue images","Tongue;Medical treatment;Medical diagnostic imaging;Convolution;Neural networks","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"LEDGE: Leveraging Edge Computing for Resilient Access Management of Mobile IoT","D. Wu; X. Huang; X. Xie; X. Nie; L. Bao; Z. Qin","ExponentiAI Innovation Lab, Hunan University, Changsha, Hunan China (e-mail: dwu3@ics.uci.edu); Department of Computer Engineering, Hunan University, Changsha, Hunan China (e-mail: xinhuang79@hnu.edu.cn); Department of Computer Engineering, Hunan University, Changsha, Hunan China (e-mail: xietls@hnu.edu.cn); Department of Computer Engineering, Hunan University, Changsha, Hunan China (e-mail: neo@hnu.edu.cn); Department of Computer Science, University of California, Irvine, Irvine, California United States (e-mail: imaginatiwoo@gmail.com); School of Electronic Engineering and Computer Science, Queen Mary University of London, London, London United Kingdom of Great Britain and Northern Ireland (e-mail: z.qin@qmul.ac.uk)","IEEE Transactions on Mobile Computing","","2019","PP","99","1","1","Due to the blooming of Internet of Things (IoT), heterogeneous IoT mobile devices emerge to connect the network infrastructure. Traditional mobile access system faces several challenges arising from these IoT devices: 1) centralized controllers are distant from the end devices, 2) inefficient access control of heterogeneous IoT devices, and 3) insufficient authentication and monitoring for IoT devices. In order to tackle the challenges from IoT devices on mobile access control and scalable access monitoring, we present LEDGE, an agile and secured software-defined edge computing system for resilient access management of mobile IoT. In a nutshell, our LEDGE is a synergy of an efficient location authentication method to secure communication between each IoT mobile device and access point (AP) pair, an optimal AP assignment scheme to satisfy IoT flow requests, a Personal AP protocol for scalable access, and a deep learning model for anomaly detection. We prototype our system, and realistic testbed experiments demonstrate that LEDGE could achieve promising results in mobile IoT.","","","10.1109/TMC.2019.2954872","HuXiang Youth Talent Program; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8908720","Internet of Things;mobile edge computing;multi-access authentication;network anomaly detection;software-defined networking","Internet of Things;Edge computing;Authentication;Access control;Mobile handsets;Control systems;Computer architecture","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Lightweight Privacy-Preserving CNN Feature Extraction Framework for Mobile Sensing","K. Huang; X. Liu; S. Fu; D. Guo; M. Xu","College of Computer, National University of Defense Technology, Changsha, Hunan China (e-mail: kai.huang@nudt.edu.cn); SCHOOL OF INFORMATION SYSTEMS, Singapore Management University, Singapore, Singapore Singapore (e-mail: snbnix@gmail.com); College of Computer, National University of Defense Technology, Changsha, Hunan China (e-mail: shaojing1984@163.com); School of Information System and Management, National University of Defense Technology, Changsha, Hunan China (e-mail: dekeguo@nudt.edu.cn); College of Computer, National University of Defense Technology, 58294 Changsha, Hunan China (e-mail: xuming@nudt.edu.cn)","IEEE Transactions on Dependable and Secure Computing","","2019","PP","99","1","1","The proliferation of various mobile devices equipped with cameras results in an exponential growth of the amount of images. Recent advances in the deep learning with convolutional neural networks (CNN) have made CNN feature extraction become an effective way to process these images. However, it is still a challenging task to deploy the CNN model on the mobile sensors, which are typically resource-constrained in terms of the storage space, the computing capacity, and the battery life. Although cloud computing has become a popular solution, data security and response latency are always the key issues. Therefore, in this paper, we propose a novel lightweight framework for privacy-preserving CNN feature extraction for mobile sensing based on edge computing. To get the most out of the benefits of CNN with limited physical resources on the mobile sensors, we design a series of secure interaction protocols and utilize two edge servers to collaboratively perform the CNN feature extraction. The proposed scheme allows us to significantly reduce the latency and the overhead of the end devices while preserving privacy. Through theoretical analysis and empirical experiments, we demonstrate the security, effectiveness, and efficiency of our scheme.","","","10.1109/TDSC.2019.2913362","the Open Foundation of State Key Laboratory of Cryptology; National Natural Science Foundation of China; the Research Project of National University of Defense Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8700229","Privacy-preserving;CNN;Feature Extraction;Mobile Sensing","","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Enhancing Sketch-Based Image Retrieval by CNN Semantic Re-ranking","L. Wang; X. Qian; Y. Zhang; J. Shen; X. Cao","SMILES Lab, Xi'an Jiaotong University, Xi'an 710049, China, and also with the School of Electronics and Information Engineering, Xi'an Jiaotong University, Xi'an 710049, China.; Ministry of Education Key Laboratory for Intelligent Networks and Network Security, Xi'an Jiaotong University, Xi'an 710049, China, and also with the SMILES Lab, Xi'an Jiaotong University, Xi'an 710049, China (e-mail: qianxm@mail.xjtu.edu.cn).; SMILES Lab, Xi'an Jiaotong University, Xi'an 710049, China, and also with the School of Electronics and Information Engineering, Xi'an Jiaotong University, Xi'an 710049, China.; School of Electronics, Electrical Engineering, and Computer Science, Queen's University Belfast, Belfast BT71NN, U.K..; Institute of Information Engineering, Chinese Academy of Sciences, Beijing 100093, China.","IEEE Transactions on Cybernetics","","2019","PP","99","1","13","This paper introduces a convolutional neural network (CNN) semantic re-ranking system to enhance the performance of sketch-based image retrieval (SBIR). Distinguished from the existing approaches, the proposed system can leverage category information brought by CNNs to support effective similarity measurement between the images. To achieve effective classification of query sketches and high-quality initial retrieval results, one CNN model is trained for classification of sketches, another for that of natural images. Through training dual CNN models, the semantic information of both the sketches and natural images is captured by deep learning. In order to measure the category similarity between images, a category similarity measurement method is proposed. Category information is then used for re-ranking. Re-ranking operation first infers the retrieval category of the query sketch and then uses the category similarity measurement to measure the category similarity between the query sketch and each initial retrieval result. Finally, the initial retrieval results are re-ranked. The experiments on different types of SBIR datasets demonstrate the effectiveness of the proposed re-ranking method. Comparisons with other re-ranking algorithms are also given to show the proposed method's superiority. Further, compared to the baseline systems, the proposed re-ranking approach achieves significantly higher precision in the top ten different SBIR methods and datasets.","","","10.1109/TCYB.2019.2894498","National Natural Science Foundation of China; National Basic Research Program of China (973 Program); World Class Universities Disciplines and the Characteristic Development Guidance Funds for the Central Univers; National Natural Science Foundation of China; Beijing Municipal Natural Science Foundation Cooperation Beijing Education Committee; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8667718","Classification;convolutional neural network (CNN);re-ranking;sketch-based image retrieval (SBIR)","Semantics;Feature extraction;Image edge detection;Image retrieval;Bridges;Noise measurement;Data mining","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Insitu Motor Fault Diagnosis Using Enhanced Convolutional Neural Network in an Embedded System","S. Lu; G. Qian; Q. He; F. Liu; Y. Liu; Q. Wang","National Engineering Laboratory of Energy-Saving Motor and Control Technology, College of Electrical Engineering and Automation, Anhui University, Hefei 230601, China, and the Traction Power State Key Laboratory, Southwest Jiaotong University, Chengdu 610031, China.; National Engineering Laboratory of Energy-Saving Motor and Control Technology, College of Electrical Engineering and Automation, Anhui University, Hefei 230601, China, and the Traction Power State Key Laboratory, Southwest Jiaotong University, Chengdu 610031, China.; State Key Laboratory of Mechanical System and Vibration, Shanghai Jiao Tong University, Shanghai 200240, PR China.; National Engineering Laboratory of Energy-Saving Motor and Control Technology, College of Electrical Engineering and Automation, Anhui University, Hefei 230601, China, and the Traction Power State Key Laboratory, Southwest Jiaotong University, Chengdu 610031, China.; National Engineering Laboratory of Energy-Saving Motor and Control Technology, College of Electrical Engineering and Automation, Anhui University, Hefei 230601, China, and the Traction Power State Key Laboratory, Southwest Jiaotong University, Chengdu 610031, China.; Collaborative Innovation Center of Industrial Energy-saving and Power Quality Control, Anhui University, Hefei 230601, China, and also the Engineering Research Center of Power Quality, Ministry of Education, Anhui University, Hefei 230601, China.","IEEE Sensors Journal","","2019","PP","99","1","1","Convolutional neural networks (CNNs) are one of the most efficient deep learning techniques and have been widely used in motor fault diagnosis. However, most of them are implemented in desktop computers to process offline signals. In this study, an insitu motor fault diagnosis method is proposed by implementing an enhanced CNN model into a designed embedded system consisting of a Raspberry Pi and a signal acquisition and processing circuit. To the best of our knowledge, this topic has not been investigated yet in the literature. First, the hardware, algorithms, and heterogeneous computing framework are introduced in detail. Then, the method effectiveness and efficiency are validated on a motor test rig. In particular, as the resources in an embedded system are limited, the algorithm accuracy and execution time are investigated. The robustness of the designed system is further validated by analyzing the motor signals with different signal-to-noise ratios. The contributions of this study include: 1) A heterogeneous computing framework is proposed and an integrated embedded system is designed. 2) The performance of the enhanced CNN in embedded system is validated. 3) The proposed method provides a solution to realize insitu motor fault diagnosis on a small-size, flexible, and convenient handheld device, by exploiting the artificial intelligence technique.","","","10.1109/JSEN.2019.2911299","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8692426","motor fault diagnosis;brushless direct current motor;CNN;embedded system;Raspberry Pi;vibration signal analysis;heterogeneous computing","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Facial Synthesis from Visual Attributes via Sketch using Multi-Scale Generators","X. Di; V. M. Patel","Whiting School of Engineering, Johns Hopkins University, 3400 North Charles Street, Baltimore, MD 21218-2608.; Whiting School of Engineering, Johns Hopkins University, 3400 North Charles Street, Baltimore, MD 21218-2608.","IEEE Transactions on Biometrics, Behavior, and Identity Science","","2019","PP","99","1","1","Automatic synthesis of faces from visual attributes is an important problem in computer vision and has wide applications in law enforcement and entertainment. With the advent of deep generative convolutional neural networks (CNNs), attempts have been made to synthesize face images from attributes and text descriptions. In this paper, we take a different approach, where we formulate the original problem as a stage-wise learning problem. We first synthesize the facial sketch corresponding to the visual attributes and then we generate the face image based on the synthesized sketch. The proposed framework, is based on a combination of two different Generative Adversarial Networks (GANs) – (1) a sketch generator network which synthesizes realistic sketch from the input attributes, and (2) a face generator network which synthesizes facial images from the synthesized sketch images with the help of facial attributes. Extensive experiments and comparison with recent methods are performed to verify the effectiveness of the proposed attribute-based two-stage face synthesis method.","","","10.1109/TBIOM.2019.2961926","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8943292","face synthesis;visual attributes;generative adversarial networks","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"2D Pose-based Real-time Human Action Recognition with Occlusion-handling","F. Angelini; Z. Fu; Y. Long; L. Shao; S. M. Naqvi","School of Engineering, Newcastle University, 5994 Newcastle upon Tyne, Tyne and Wear United Kingdom of Great Britain and Northern Ireland NE1 7RU (e-mail: F.Angelini2@newcastle.ac.uk); School Engineering, Newcastle University, Newcastle upon Tyne, United Kingdom of Great Britain and Northern Ireland, NE1 7RU (e-mail: z.fu2@ncl.ac.uk); Department of Computer Science, Durham University, Durham DH1 3LE, United Kingdom of Great Britain and Northern Ireland (e-mail: yang.long@durham.ac.uk); Inception Institute of Artificial Intelligence, Abu Dhabi, UAE (e-mail: ling.shao@ieee.org); School of Engineering, Newcastle University, Newcastle, Tyne and Wear United Kingdom of Great Britain and Northern Ireland NE1 7RU (e-mail: Mohsen.Naqvi@newcastle.ac.uk)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","Human Action Recognition (HAR) for CCTV-oriented applications is still a challenging problem. Real-world scenarios HAR implementations is difficult because of the gap between Deep Learning data requirements and what the CCTV-based frameworks can offer in terms of data recording equipments. We propose to reduce this gap by exploiting human poses provided by the OpenPose, which has been already proven to be an effective detector in CCTV-like recordings for tracking applications. Therefore, in this work, we first propose ActionXPose: a novel 2D pose-based approach for pose-level HAR. ActionXPose extracts low- and high-level features from body poses which are provided to a Long Short-Term Memory Neural Network and a 1D Convolutional Neural Network for the classification. We provide a new dataset, named ISLD, for realistic pose-level HAR in a CCTV-like environment, recorded in the Intelligent Sensing Lab. ActionXPose is extensively tested on ISLD under multiple experimental settings, e.g. Dataset Augmentation and Cross-Dataset setting, as well as revising other existing datasets for HAR. ActionXPose achieves state-of-the-art performance in terms of accuracy, very high robustness to occlusions and missing data, and promising results for practical implementation in real-world applications.","","","10.1109/TMM.2019.2944745","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8853267","Pose;LSTM;CNN;ISLD;CCTV","Feature extraction;Three-dimensional displays;Two dimensional displays;Target tracking;Detectors;Skeleton;Videos","","","","","","","","","","IEEE","IEEE Early Access Articles"
"CNN-based Intra-Prediction for Lossless HEVC","I. Schiopu; H. Huang; A. Munteanu","Department of Electronics and Informatics (ETRO), Vrije Universiteit Brussel (VUB), Pleinlaan 2, 1050 Brussels, Belgium.; Department of Electronics and Informatics (ETRO), Vrije Universiteit Brussel (VUB), Pleinlaan 2, 1050 Brussels, Belgium.; Department of Electronics and Informatics (ETRO), Vrije Universiteit Brussel (VUB), Pleinlaan 2, 1050 Brussels, Belgium.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","The paper proposes a novel block-wise prediction paradigm based on Convolutional Neural Networks (CNNs) for lossless video coding. A deep neural network model which follows a multi-resolution design is employed for block-wise prediction. Several contributions are proposed to improve neural network training. A first contribution proposes a novel loss function formulation for an efficient network training based on a new approach for patch selection. Another contribution consists in replacing all HEVC-based angular intra-prediction modes with a CNN-based intra-prediction method, where each angular prediction mode is complemented by a CNN-based prediction mode using a specifically trained model. Another contribution consists in an efficient adaptation of the CNN-based intra-prediction residual for lossless video coding. Experimental results on standard test sequences show that the proposed coding system outperforms the HEVC standard with an average bitrate improvement of around 5%. To our knowledge, the paper is the first to replace all the traditional HEVC-based angular intra-prediction modes with an intra-prediction method based on modern Machine Learning techniques for lossless video coding applications.","","","10.1109/TCSVT.2019.2940092","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8827579","","Image coding;High efficiency video coding;Training;Neural networks;Encoding;Standards","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Multi-Scale Position Feature Transform Network for Video Frame Interpolation","X. Cheng; Z. Chen","School of Remote Sensing and Information Engineering, Wuhan University, Wuhan 430072, China.; School of Remote Sensing and Information Engineering, Wuhan University, Wuhan 430072, China.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Given a video sequence, video frame interpolation aims to synthesize an in-between frame of two consecutive frames. In this paper, we propose a multi-scale position feature transform (MS-PFT) network for video frame interpolation where two parallel prediction networks and one optimization network are designed to predict the features of target frame and generate the final interpolation result, respectively. To increase the fidelity of the synthesised frames, we propose to apply a position feature transform (PFT) layer in the residual blocks of the prediction networks to estimate scaling factors which help evaluate different degrees of the importance of deep features around a target pixel. A PFT layer utilizes optical flow to extract and generate position features and then adjusts the learning process of our model. We further extend our model into a multi-scale structure in which each scale of the network shares the same parameters to maximise the efficiency of our network with model size unchanged. The experiments show that our method can handle the challenging scenarios like occlusion and large motion effectively and the proposed method outperforms those state-of-the-art approaches on different datasets.","","","10.1109/TCSVT.2019.2939143","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8823006","Video frame interpolation;position feature transform;multi-scale network","Interpolation;Transforms;Optical sensors;Optical imaging;Neural networks;Optical computing;Optical fiber networks","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Spatial-Temporal Dependency Modeling and Network Hub Detection for Functional MRI Analysis via Convolutional-Recurrent Network","M. Wang; C. Lian; D. Yao; D. Zhang; M. Liu; D. Shen","College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, 47854 Nanjing, Jiangsu China (e-mail: wml489@nuaa.edu.cn); Department of Radiology and BRIC, University of North Carolina at Chapel Hill, 2331 Chapel Hill, North Carolina United States (e-mail: chunfeng_lian@med.unc.edu); Brainnetome Center and National Laboratory of Pattern Recognition, Chinese Academy of Sciences, 12381 Beijing, Beijing China (e-mail: dongren_yao@med.unc.edu); Nanjing University of Aeronautics and Astronautics, 47854 Nanjing, Jiangsu China (e-mail: dqzhang@nuaa.edu.cn); Department of Radiology and BRIC, University of North Carolina at Chapel Hill, 2331 Chapel Hill, North Carolina United States (e-mail: mxliu@med.unc.edu); Department of Radiology and BRIC, University of North Carolina at Chapel Hill, 2331 Chapel Hill, North Carolina United States (e-mail: zhulan.xu@hotmail.com)","IEEE Transactions on Biomedical Engineering","","2019","PP","99","1","1","Early identification of dementia at the stage of mild cognitive impairment (MCI) is crucial for timely diagnosis and intervention of Alzheimer's disease (AD). Although several pioneering studies have been devoted to automated AD diagnosis based on resting-state functional magnetic resonance imaging (rs-fMRI), their performance is somewhat limited due to non-effective mining of spatial-temporal dependency. Besides, few of these existing approaches consider the explicit detection and modeling of discriminative brain regions (i.e., network hubs) that are sensitive to AD progression. In this paper, we propose a unique Spatial-Temporal convolutional-recurrent neural Network (STNet) for automated prediction of AD progression and network hub detection from rs-fMRI time series. Our STNet incorporates the spatial-temporal information mining and AD-related hub detection into an end-to-end deep learning model. Specifically, we first partition rs-fMRI time series into a sequence of overlapping sliding windows. A sequence of convolutional components are then designed to capture the local-to-global spatially-dependent patterns within each sliding window, based on which we are able to identify discriminative hubs and characterize their unique contributions to disease diagnosis. A recurrent component with long short-term memory (LSTM) units is further employed to model the whole-brain temporal dependency from the spatially-dependent pattern sequences, thus capturing the temporal dynamics along time. We evaluate our method on 174 subjects with 563 rs-fMRI scans, with results suggesting the effectiveness of our method in disease prediction and hub detection.","","","10.1109/TBME.2019.2957921","Royal Society-Academy of Medical Sciences Newton Advanced Fellowship; Fundamental Research Funds for the Central Universities; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8926342","Spatial-temporal dependency;neural network;Alzheimers disease;hub detection;resting-state functional MRI","Time series analysis;Convolution;Dementia;Functional magnetic resonance imaging;Brain modeling;Feature extraction","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Rapid Spiking Neural Network Approach with an Application on Hand Gesture Recognition","L. Cheng; Y. Liu; Z. Hou; M. Tan; D. Du; M. Fei","State Key Laboratory for Control and Management of Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China. The authors are with the School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing 100049, China.; State Key Laboratory for Control and Management of Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China. The authors are with the School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing 100049, China.; State Key Laboratory for Control and Management of Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China. The authors are with the School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing 100049, China.; State Key Laboratory for Control and Management of Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China. The authors are with the School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing 100049, China.; School of Mechatronic Engineering and Automation, Shanghai University, Shanghai 200072, China.; School of Mechatronic Engineering and Automation, Shanghai University, Shanghai 200072, China.","IEEE Transactions on Cognitive and Developmental Systems","","2019","PP","99","1","1","The spiking neural network is considered to be the third generation of neural networks featured by its low power consumption and high computing capability, which has great application potential in robotics. However, the present spiking neural network has two limitations: (1) the neuron’s spike firing time is calculated based on the iterative approach, which dramatically slows down the calculation rate of the spiking neural network; and (2) the existing learning algorithm is more suitable for the single-layer structure, which can hardly train the network with “deep structure”. To this end, this paper proposes a novel spike firing time search algorithm that can narrow the search interval. In addition, a pre-trained subnet spiking neural network is designed, which makes the spiking neural network have more hidden layers. This setting of the spiking neural network can effectively improve its performance in pattern recognition tasks. Furthermore, by using the surface electromyography signal (sEMG), the proposed spiking neural network is used to recognize the hand gestures. The experimental results show that: (1) the spike firing time search algorithm can significantly increase the forward propagation rate of the spiking neural network; and (2) the proposed spiking neural network can reach a satisfactory recognition accuracy ratio 97.4%, which is 0.9% higher than that of the fully connected spiking neural network.","","","10.1109/TCDS.2019.2918228","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8720035","Spiking neural networks;surface electromyography;hand gesture recognition;forward propagation.","Biological neural networks;Encoding;Neurons;Biological information theory;Sociology;Statistics;Membrane potentials","","","","","","","","","","IEEE","IEEE Early Access Articles"
"VoxSegNet: Volumetric CNNs for Semantic Part Segmentation of 3D Shapes","Z. Wang; F. Lu","Computer Science, Beihang University, 12633 Beijing, Beijing China 100191 (e-mail: wzjgintoki@buaa.edu.cn); Computer Science, Beihang University, 12633 Beijing, Beijing China (e-mail: lufeng@buaa.edu.cn)","IEEE Transactions on Visualization and Computer Graphics","","2019","PP","99","1","1","Volumetric representation has been widely used for 3D deep learning in shape analysis due to its generalization ability and regular data format. However, for fine-grained tasks like part segmentation, volumetric data has not been widely adopted compared to other representations. Aiming at delivering an effective volumetric method for 3D shape part segmentation, this paper proposes a novel volumetric convolutional neural network. Our method can extract discriminative features encoding detailed information from voxelized 3D data under limited resolution. To this purpose, a spatial dense extraction (SDE) module is designed to preserve spatial resolution during feature extraction procedure, alleviating the loss of details caused by sub-sampling operations such as max pooling. An attention feature aggregation (AFA) module is also introduced to adaptively select informative features from different abstraction levels, leading to segmentation with both semantic consistency and high accuracy of details. Experimental results demonstrate that promising results can be achieved by using volumetric data, with part segmentation accuracy comparable or superior to state-of-the-art non-volumetric methods.","","","10.1109/TVCG.2019.2896310","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8629927","shape analysis;semantic segmentation;convolutional neural networks;volumetric models","Three-dimensional displays;Feature extraction;Shape;Semantics;Convolution;Data mining;Task analysis","","","","","","","","","","IEEE","IEEE Early Access Articles"
"CANet: Cross-disease Attention Network for Joint Diabetic Retinopathy and Diabetic Macular Edema Grading","X. Li; X. Hu; L. Yu; L. Zhu; C. Fu; P. Heng","Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong.; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong.; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong.; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong.; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong.; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong.","IEEE Transactions on Medical Imaging","","2019","PP","99","1","1","Diabetic retinopathy (DR) and diabetic macular edema (DME) are the leading causes of permanent blindness in the working-age population. Automatic grading of DR and DME helps ophthalmologists design tailored treatments to patients, thus is of vital importance in the clinical practice. However, prior works either grade DR or DME, and ignore the correlation between DR and its complication, i.e., DME. Moreover, the location information, e.g., macula and soft hard exhaust annotations, are widely used as a prior for grading. Such annotations are costly to obtain, hence it is desirable to develop automatic grading methods with only image-level supervision. In this paper, we present a novel cross-disease attention network (CANet) to jointly grade DR and DME by exploring the internal relationship between the diseases with only image-level supervision. Our key contributions include the disease-specific attention module to selectively learn useful features for individual diseases, and the disease-dependent attention module to further capture the internal relationship between the two diseases. We integrate these two attention modules in a deep network to produce disease-specific and diseasedependent features, and to maximize the overall performance jointly for grading DR and DME. We evaluate our network on two public benchmark datasets, i.e., ISBI 2018 IDRiD challenge dataset and Messidor dataset. Our method achieves the best result on the ISBI 2018 IDRiD challenge dataset and outperforms other methods on the Messidor dataset. Our code is publicly available at https://github.com/xmengli999/CANet.","","","10.1109/TMI.2019.2951844","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8892667","Diabetic retinopathy;diabetic macular edema;joint grading;attention mechanism","Diabetes;Task analysis;Feature extraction;Retinopathy;Hemorrhaging;Biomedical imaging","","","","","","","","","","IEEE","IEEE Early Access Articles"
"OIDC-Net: Omnidirectional Image Distortion Correction via Coarse-to-fine Region Attention","K. Liao; C. Lin; Y. Zhao; M. Gabbouj; Y. Zheng","Beijing Jiaotong University, Institute of Informa- tion Science, Beijing China (e-mail: kang_liao@bjtu.edu.cn); Institute of information science, Beijing jiaotong University, beijing, beijing China 100044 (e-mail: cylin@bjtu.edu.cn); Institute of Information Science, Beijing Jiaotong University, Beijing China 100044 (e-mail: yzhao@bjtu.edu.cn); Tampere University of Technology, Tampre Finland (e-mail: moncef.gabbouj@tut.fi); Beijing China (e-mail: yang_zheng@bjtu.edu.cn)","IEEE Journal of Selected Topics in Signal Processing","","2019","PP","99","1","1","Omnidirectional cameras have recently received significant attention in panoramic imaging systems such as virtual reality (VR) technology; however, the strong geometric distortion in omnidirectional images severely affects the object recognition and semantic understanding. In this paper, we propose an automatic omnidirectional image distortion correction approach powered by a unified learning model (OIDC-Net). This approach is applicable for almost all types of omnidirectional cameras, requiring nothing more than a distorted image. A crucial and challenging ingredient for reconstructing the real physical scene is to estimate the heterogeneous distortion coefficients in an appropriate camera model. To address this issue, we present a novel coarse-to-fine region attention mechanism to alleviate the difficulty of predicting all coefficients simultaneously. With the proposed cascade structure and deep fusion strategy, the ambiguous relationship among these heterogeneous distortion coefficients has been incrementally perceived. Our experimental results show significant improvement over the state-of-the-art methods in terms of visual appearance, while maintaining a promising quantitative performance.","","","10.1109/JSTSP.2019.2955017","Fundamental Research Funds for the Central Universities; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8910406","Omnidirectional image distortion correction;Coarse-to-fine region attention;Incremental perception","Distortion;Cameras;Calibration;Semantics;Robot vision systems;Optical distortion;Image segmentation","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Detecting Small Objects Using a Channel-Aware Deconvolutional Network","K. Duan; D. Du; H. Qi; Q. Huang","School of Computer Science and Technology, University of Chinese Academy of Sciences, Beijing 101408, China, also with the Key Laboratory of Big Data Mining and Knowledge Management, University of Chinese Academy of Sciences, Beijing 100190, China.; Computer Science Department, University at Albany, State University of New York, Albany, NY 12222, USA.; School of Computer Science and Technology, University of Chinese Academy of Sciences, Beijing 101408, China, also with the Key Laboratory of Big Data Mining and Knowledge Management, University of Chinese Academy of Sciences, Beijing 100190, China.; School of Computer Science and Technology, University of Chinese Academy of Sciences, Beijing 101408, China, also with the Key Laboratory of Big Data Mining and Knowledge Management, University of Chinese Academy of Sciences, Beijing 100190, China and Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences, Beijing 100190, China.","IEEE Transactions on Circuits and Systems for Video Technology","","2019","PP","99","1","1","Detecting small objects is a challenging task due to their low resolution and noisy representation even using deep learning methods. In this paper, we propose a novel object detection method based on the channel-aware deconvolutional network (CADNet) for accurate small object detection. Speci?cally, we develop the channel-aware deconvolution (ChaDeConv) layer to exploit the correlations of feature maps in different channels across deeper layers, improving the recall rate of small objects at low additional computational costs. Following the ChaDeConv layer, the multiple region proposal sub-network (Multi-RPN) is employed to supervise and optimize multiple detection layers simultaneously to achieve better accuracy. The Multi-RPN module is only used in the training phase and does not increase the computation cost of the inference. Additionally, we design a new anchor matching strategy based on the center point translation (CPTMatching) of anchors to select more extending anchors as positive samples in the training phase. Extensive experiments on the PASCAL VOC 2007/2012, MS COCO and UAVDT datasets show that the proposed CADNet achieves stateof-the-art performance compared to existing methods.","","","10.1109/TCSVT.2019.2906246","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8669953","Small Object Detection;Channel-Aware Deconvolution;Multi-RPN;Anchor Matching","Object detection;Feature extraction;Training;Birds;Deconvolution;Proposals;Detectors","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Refined TV-L1 Optical Flow Estimation Using Joint Filtering","C. Zhang; L. Ge; Z. Chen; M. Li; W. Liu; H. Chen","School of Measuring and Optical Engineering, Nanchang Hangkong University, 139309 Nanchang, Jiangxi China (e-mail: zcxdsg@163.com); school of Measuring and Optical Engineering, Nanchang Hangkong University, 139309 Nanchang, Jiangxi China (e-mail: lygeah@163.com); Measuring and Optical Engineering, Nanchang Hangkong University, 139309 Nanchang China 330063 (e-mail: dr_chenzhen@163.com); Key Laboratory of Jiangxi Province for Image Processing and Pattern Recognition, Nanchang Hangkong University, 139309 Nanchang, Jiangxi China (e-mail: liming@nchu.edu.cn); Physical Therapy and Rehabilitation Science, University of Kansas, Kansas United States (e-mail: WLIU@kumc.edu); Key Laboratory of Jiangxi Province for Image Processing and Pattern Recognition, Nanchang Hangkong University, Nanchang China (e-mail: chenhaoshl@nchu.edu.cn)","IEEE Transactions on Multimedia","","2019","PP","99","1","1","Though the accuracy and robustness of optical flow has been dramatically enhanced over the past few years, the issue of edge-blurring near the image and motion boundaries has remained a challenge in flow field estimation. In this paper, we propose a refined total variation with L1 norm (TV-L1) optical flow estimation approach using joint filtering, named JOF. First, we divide the image into three categorized regions: mutual-structure regions, inconsistent structure regions and smooth regions. The mutual-structure guided filter for optical flow estimation is constructed by extracting the mutual- structure regions of the flow field. Second, the refined TV-L1 optical flow model is proposed by incorporating the non-local term and mutual-structure guided filter objective function into the classical TV-L1 energy function. Furthermore, the novel TV-L1 optical flow objective function is minimized using a joint filtering program composed of a weighted median filter and a mutual-structure guided filter to optimize the estimated flow field during the coarse-to-fine optical flow computation scheme. Finally, we compare the proposed JOF method with several state-of-the-art approaches including variational and deep learning based optical flow models using the Middlebury, MPI-Sintel and UCF101 test databases. The evaluation results indicate that the proposed method has high accuracy and good robustness for flow field computation, especially owns the significant benefit of edge-preserving.","","","10.1109/TMM.2019.2929934","National Natural Science Foundation of China; Natural Science Foundation of Jiangxi Province; Advantage Subject Team Project of Jiangxi Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8778682","optical flow;TV-L1 model;joint filtering;mutual-structure;edge-preserving","Optical flow;Filtering;Image edge detection;Estimation;Optical filters;Computer vision;Linear programming","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Relative Saliency and Ranking: Models, Metrics, Data and Benchmarks","M. Kalash; M. A. Islam; N. Bruce","Computer Science, University of Manitoba, 8664 Winnipeg, Manitoba Canada (e-mail: kalashm@cs.umanitoba.ca); Computer Science, Ryerson University, Toronto, Ontario Canada (e-mail: amirul@scs.ryerson.ca); Computer Science, Ryerson University, Toronto, Ontario Canada (e-mail: bruce@scs.ryerson.ca)","IEEE Transactions on Pattern Analysis and Machine Intelligence","","2019","PP","99","1","1","Salient object detection is a problem that has been considered in detail and many solutions have been proposed. In this paper, we argue that work to date has addressed a problem that is relatively ill-posed. Specifically, there is not universal agreement about what constitutes a salient object when multiple observers are queried. This implies that some objects are more likely to be judged salient than others, and implies a relative rank exists on salient objects. Initially, we present a novel deep learning solution based on a hierarchical representation of relative saliency and stage-wise refinement. Further to this, we present data, analysis and baseline benchmark results towards addressing the problem of salient object ranking. Methods for deriving suitable ranked salient object instances are presented, along with metrics suitable to measuring algorithm performance. In addition, we show how a derived dataset can be successively refined to provide cleaned results that correlate well with pristine ground truth in its characteristics and value for training and testing models. Finally, we provide a comparison among prevailing algorithms that address salient object ranking or detection to establish initial baselines providing a basis for comparison with future efforts addressing this problem. The source code and data are publicly available via our project page: ryersonvisionlab.github.io/cocosalrank","","","10.1109/TPAMI.2019.2927203","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8756097","Saliency;Saliency Ranking;Salient Instance;Salient Object Detection;Relative Rank;Dataset;Benchmark","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Vehicular Task Offloading via Heat-Aware MEC Cooperation: A Game-Theoretic Method with Correlated Equilibrium","Z. Xiao; X. Dai; H. Jiang; D. Wang; H. Chen; L. Yang; F. Zeng","College of Computer Science and Electronic Engineering, Hunan University, 410082, Changsha, China.; College of Computer Science and Electronic Engineering, Hunan University, 410082, Changsha, China.; College of Computer Science and Electronic Engineering, Hunan University, 410082, Changsha, China.; College of Computer Science and Electronic Engineering, Hunan University, 410082, Changsha, China.; Institute of Industrial Science, The University of Tokyo, Tokyo 153-8505, Japan.; College of Computer Science and Electronic Engineering, Hunan University, 410082, Changsha, China.; College of Computer Science and Electronic Engineering, Hunan University, 410082, Changsha, China.","IEEE Internet of Things Journal","","2019","PP","99","1","1","Mobile Edge Computing (MEC) has been witnessed as a promising solution for the vehicular task offloading. Due to the limited computing resource of individual MEC servers, it faces challenges when higher requirements are put forward for timely task processing of large amount of computations in the emerging vehicular applications. In this paper, we strive to realize the efficient vehicular task offloading via heat-aware MEC cooperation from the game theory perspective. Here the heat indicates the vehicle density and is tightly related to the requests of vehicle users when they drive through the hotzones. Specifically, a deep learning based prediction method is proposed, capturing the dynamic time-varying heat value of the hot zones based on the analysis of the real-world private car trajectory data. To identify the role of MEC in the cooperation, we take the time-delay constraint into consideration for the task offloading. To realize MEC grouping for task offloading in MEC cooperation, we formulate the MEC grouping as a utility maximization problem via designing a non-cooperative game-theoretic strategy selection based on regret-matching. Furthermore, we derive the correlated equilibrium and prove that the fast convergence can be achieved. Extensive simulation results validate the effectiveness of the proposed vehicular task offloading approach under various system parameters such as computation workload, time slots, and MEC servers number. The proposed method outperforms the existing methods, which is able to significantly reduce the task complete delay, and in the meantime enhance the MEC energy efficiency with end-users’ QoE guaranteed.","","","10.1109/JIOT.2019.2960631","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8936356","Vehicular task offloading;mobile edge computing;correlated equilibrium;private cars.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Visual Leader-Following Approach With a T-D-R Framework for Quadruped Robots","L. Pang; Z. Cao; J. Yu; P. Guan; X. Rong; H. Chai","State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China, and also with the School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing 100049, China.; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China, and also with the School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing 100049, China (e-mail: zhiqiang.cao@ia.ac.cn).; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China, and also with the State Key Laboratory for Turbulence and Complex System, Department of Mechanics and Engineering Science, BIC-ESAT, College of Engineering, Peking University, Beijing 100871, China.; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China, and also with the School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing 100049, China.; School of Control Science and Engineering, Shandong University, Jinan 250061, China.; School of Control Science and Engineering, Shandong University, Jinan 250061, China.","IEEE Transactions on Systems, Man, and Cybernetics: Systems","","2019","PP","99","1","13","The quadruped robot imitates the motions of four-legged animals with a superior flexibility and adaptability to complex terrains, compared with the wheeled and tracked robots. Its leader-following ability is unique to help a human to accomplish complex tasks in a more convenient way. However, long-term following is severely obstructed due to the high-frequency vibration of the quadruped robot and the unevenness of terrains. To solve this problem, a visual approach under a novel T-D-R framework is proposed. The proposed T-D-R framework is composed of a visual tracker based on correlation filter, a person detector with deep learning, and a person re-identification (re-ID) module. The result of the tracker is verified by the detector to improve tracking performance. Especially, the re-ID module is introduced to handle distractions and occlusion caused by other persons, where the convolutional correlation filter (CCF) is employed to discriminate the leader among multiple persons through recording the appearance information in the long run. By comparing the results of the tracker and the detector as well as their similarity scores with the leader identified by the re-ID module, a stable and real-time tracking of the leader can be guaranteed. Experiments reveal that our approach is effective in handling distractions, appearance changes, and illumination variations. A long-distance experiment on a quadruped robot indicates the validity of the proposed approach.","","","10.1109/TSMC.2019.2912715","Beijing Advanced Innovation Center for Intelligent Robots and Systems, Beijing Institute of Technology; National Natural Science Foundation of China; Key Technology Research and Development Program of Shandong; Open Foundation of the State Key Laboratory of Management and Control for Complex Systems CASIA; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8709995","Detector;leader following;long-term tracking;person re-identification (re-ID);quadruped robot","Visualization;Target tracking;Mobile robots;Correlation;Robot kinematics;Cameras","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Robust Visual Person-Following Approach for Mobile Robots in Disturbing Environments","L. Pang; Z. Cao; J. Yu; P. Guan; X. Chen; W. Zhang","State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China, and also with the School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, 100049, China (e-mail: panglei2015@ia.ac.cn).; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China, and also with the School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, 100049, China (e-mail: zhiqiang.cao@ia.ac.cn).; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China, and also with the State Key Laboratory for Turbulence and Complex System, Department of Mechanics and Engineering Science, BIC-ESAT, College of Engineering, Peking University, Beijing 100871, China (e-mail: junzhi.yu@ia.ac.cn).; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China, and also with the School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, 100049, China (e-mail: guanpeiyu2017@ia.ac.cn).; Beijing Advanced Innovation Center for Intelligent Robots and Systems, Beijing 100081, China, and also with the Intelligent Robotics Institute, Beijing Institute of Technology, Beijing 100081, China (e-mail: chenxuechao@bit.edu.cn).; Beijing Advanced Innovation Center for Intelligent Robots and Systems, Beijing 100081, China, and also with the Intelligent Robotics Institute, Beijing Institute of Technology, Beijing 100081, China (e-mail: zhwm@bit.edu.cn).","IEEE Systems Journal","","2019","PP","99","1","4","This article proposes a robust visual following approach with a deep learning-based person detector, a Kalman filter (KF), and a reidentification module. The KF is introduced to predict the position of the target person, and its state is updated by the associated detection result. To deal with severe distractions and even full occlusion, the reidentification module with an identification model, a verification model, and an appearance gallery is employed in multi-person disturbing environments. Without any customized markers, the proposed approach can follow the target person steadily, and it is robust to occlusion and posture changes of the target person. Experiments results validate the effectiveness of the proposed approach.","","","10.1109/JSYST.2019.2942953","Beijing Advanced Innovation Center for Intelligent Robots and Systems, Beijing Institute of Technology; National Natural Science Foundation of China; Key Technology Research and Development Program of Shandong; Institute of Automation, Chinese Academy of Sciences; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8863113","Kalman filter (KF);mobile robot;person detector;person-following;reidentification","Mobile robots;Detectors;Cameras;Visualization;Robot vision systems","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Wind Field-Based Short-Term Turbine Response Forecasting by Stacked Dilated Convolutional LSTMs","S. Woo; J. Park; J. Park; L. Manuel","Industrial and Systems Engineering, Korea Advanced Institute of Science and Technology, 34968 Daejeon Korea (the Republic of) 34141 (e-mail: ccc9663@kaist.ac.kr); Industrial and Systems Engineering, Korea Advanced Institute of Science and Technology, 34968 Daejeon Korea (the Republic of) (e-mail: junyoungpark@kaist.ac.kr); Industrial and Systems Engineering, Korea Advanced Institute of Science and Technology, 34968 Daejeon Korea (the Republic of) 305-701 (e-mail: jinkyoo.park@kaist.ac.kr); University of Texas at Austin, 12330 Austin, Texas United States (e-mail: lmanuel@mail.utexas.edu)","IEEE Transactions on Sustainable Energy","","2019","PP","99","1","1","Predicting a wind turbine's responses that correspond to a complex wind field is challenging because the responses are caused by the complex interaction between a dynamically operating mechanical system and a spatially and temporally coupled stochastic wind field. We propose a physics-inspired, data-driven prediction model called stacked dilated convolutional LSTMs (SDCL) that uses a sequence of wind fields (snapshots) as an input to predict future wind turbine responses. A SDCL is composed of a set of dilated convolutional neural networks (CNNs) combined with a long short-term memory (LSTM) to capture the spatial and temporal evolution of the turbulence structure in the input wind field. Notably, a dilated CNN with different dilation ratios along with a corresponding LSTM module, a single component of SDCL, is designed to capture the evolution of an eddy of a certain size in the turbulent wind field. Then SDCL effectively models the evolution of multiple eddies of different sizes. Through a simulation study, we have demonstrated that such a physics-inspired network architecture is effective in processing a complex wind field and thus predicting two representative future wind turbine responses, energy generation and blade root out-of-plane bending moment, more accurately than other standard deep learning architectures.","","","10.1109/TSTE.2019.2954107","National Research Foundation of Korea; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8903544","wind turbine responses;turbulent wind field;inductive biases;neural networks;spatio-temporal analysis","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Coincidence Filtering-based Approach for CNNs in EEG-based Recognition","Z. Gao; Y. Li; Y. Yang; N. Dong; X. Yang; C. Grebogi","Tianjin China 300072 (e-mail: zhongkegao@tju.edu.cn); Tianjin China 300072 (e-mail: 568033568@qq.com); Tianjin China 300072 (e-mail: yangyuxuan0324@tju.edu.cn); Tianjin China 300072 (e-mail: dongna@tju.edu.cn); Tianjin University, 12605 Tianjin China 300072 (e-mail: xiong.yang@tju.edu.cn); Aberdeen United Kingdom of Great Britain and Northern Ireland AB24 3UE (e-mail: grebogi@abdn.ac.uk)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","Electroencephalogram (EEG), obtained by wearable devices, can realize effective human health monitoring. Traditional methods based on artificially-designed features have achieved valid results in EEG-based recognition, and numerous studies start to apply deep learning techniques in this area. In this paper, we propose a coincidence filtering-based method to build a connection between artificial features-based methods and convolutional neural networks (CNNs), and design CNNs through simulating the information extraction pattern of artificial features-based methods. Based on this method, we propose a novel, simple, and effective CNNs structure for EEG-based classification. We implement two experiments to obtain EEG data, and perform experiments based on the two health monitoring tasks. The results illustrate that the proposed network can achieve prominent average accuracy on the emotion recognition and fatigue driving detection task. Due to its generality, the proposed framework design of CNNs is expected to be useful for broader applications in health monitoring areas.","","","10.1109/TII.2019.2955447","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8911225","Convolutional neural networks;Electroencephalogram;emotion recognition;fatigue driving detection","Feature extraction;Electroencephalography;Task analysis;Fatigue;Emotion recognition;Brain modeling;Convolution","","","","","","","","","","IEEE","IEEE Early Access Articles"
"FeatherCNN: Fast Inference Computation with TensorGEMM on ARM Architectures","H. Lan; J. Meng; C. Hundt; B. Schmidt; M. Deng; X. Wang; W. Liu; Y. Qiao; S. Feng","Tencent AI Lab, Tencent, 508929 Shenzhen, Guangdong China (e-mail: turbo0628@163.com); Tencent AI Lab, Tencent, 508929 Shenzhen, Guangdong China (e-mail: jt.meng@siat.ac.cn); Institute of Computer Science, Johannes Gutenberg Universitat Universitatsmedizin, 39068 Mainz, Rheinland-Pfalz Germany (e-mail: christian@metalabs.de); Institute of Computer Science, Johannes Gutenberg University Mainz, Mainz, Rheinland Palatine Germany (e-mail: bertil.schmidt@uni-mainz.de); Tencent AI Lab, Tencent, 508929 Shenzhen, Guangdong China (e-mail: danierdeng@tencent.com); Tencent AI Lab, Tencent, 508929 Shenzhen, Guangdong China (e-mail: xningwang@tencent.com); School of Computer Science and Technology, Shandong University, Jinan City, Shandong Province China (e-mail: weiguo.liu@sdu.edu.cn); Institute of Advanced Computing and Digital Engineering, Shenzhen Institutes of Advanced Technology Chinese Academy of Sciences, 85411 Shenzhen, Guangdong China (e-mail: yu.qiao@siat.ac.cn); High Performance Computing Center, Shenzhen Institutes of Advanced Technology Chinese Academy of Sciences, 85411 Shenzhen, Guangdong China (e-mail: sz.feng@siat.ac.cn)","IEEE Transactions on Parallel and Distributed Systems","","2019","PP","99","1","1","Deep Learning is ubiquitous in a wide field of applications ranging from research to industry. In comparison to time-consuming iterative training of convolutional neural networks (CNNs), inference is a relatively lightweight operation making it amenable to execution on mobile devices. Nevertheless, lower latency and higher computation efficiency are crucial to allow for complex models and prolonged battery life. Addressing the aforementioned challenges, we propose FeatherCNN -- a fast inference library for ARM CPUs -- targeting the performance ceiling of mobile devices. FeatherCNN employs three key techniques: 1) A highly efficient TensorGEMM (generalized matrix multiplication) routine is applied to accelerate Winograd convolution on ARM CPUs, 2) General layer optimization based on custom high performance kernels improves both the computational efficiency and locality of memory access patterns for non-Winograd layers. 3) The framework design emphasizes joint layer-wise optimization using layer fusion to remove redundant calculations and memory movements. Performance evaluation reveals that FeatherCNN significantly outperforms state-of-the-art libraries. A forward propagation pass of VGG-16 on a 64-core ARM server is 48, 14, and 12 times faster than Caffe using OpenBLAS, Caffe2 using Eigen, and NNPACK, respectively. In addition, FeatherCNN is 3.19 times faster than the recently released TensorFlow Lite library on an iPhone 7 plus. In terms of GEMM performance, FeatherCNN achieves 14.8% and 39.0% higher performance than Apple's Accelerate framework on an iPhone 7 plus and Eigen on a Samsung Galaxy S8, respectively. The source code of FeatherCNN library is publicly available at https://github.com/tencent/feathercnn.","","","10.1109/TPDS.2019.2939785","National Natural Science Foundation of China; Shenzhen Discipline Construction Project for Urban Computing and Data Intelligence Youth Innovation Promotion Association CAS to Yanjie Wei; National High Technology Research and Development Program of China; Shenzhen Fundamental Research Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8826372","","Convolution;Performance evaluation;Optimization;Computer architecture;Acceleration;Mobile handsets;Libraries","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Haptic Material Analysis and Classification Inspired by Human Exploratory Procedures","M. Strese; L. Brudermueller; J. Kirsch; E. Steinbach","Chair of Media Technology, Technical University of Munich, 9184 Munchen, Bayern Germany (e-mail: matti.strese@tum.de); Chair of Media Technology, Technical University of Munich, 9184 Munchen, Bayern Germany (e-mail: lara.brudermueller@tum.de); Chair of Media Technology, Technical University of Munich, 9184 Munchen, Bayern Germany (e-mail: jonas.kirsch@tum.de); Chair of Media Technology, Technical University of Munich, 9184 Munchen, Bayern Germany (e-mail: eckehard.steinbach@tum.de)","IEEE Transactions on Haptics","","2019","PP","99","1","1","We present a framework for the acquisition and parametrization of object material properties. The introduced acquisition device, denoted as Texplorer2, is able to extract surface material properties while a human operator is performing exploratory procedures. Using the Texplorer2, we scanned 184 material classes which we labeled according to biological, chemical, and geological naming conventions. Based on these real material recordings, we introduce a novel set of mathematical features which align with corresponding material properties defined in perceptual studies from related work and classify the materials using common machine learning techniques. Validation results of the proposed multi-modal features lead to an overall classification accuracy of 90.2% +/- 1.2% and an F1 score of 0.90 +/- 0.01 using a random forest classifier. For the sake of comparison, a deep neural network is trained and tested on images of the surfaces; it outperforms (91.3% +/- 0.7%) the hand-crafted feature-based approach yet leads to more critical misclassifications in terms of the proposed taxonomy.","","","10.1109/TOH.2019.2952118","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8894510","Surface Haptics;Material Scanning;Content-based Features","Haptic interfaces;Robot sensing systems;Databases;Material properties;Taxonomy;Metals","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Real-time Burst Photo Selection Using a Light-Head Adversarial Network","B. Wang; N. Vesdapunt; U. Sinha; L. Z. M. Corporation","Microsoft Corporation.; Microsoft Corporation.; Microsoft Corporation and Google.; Microsoft Corporation.","IEEE Transactions on Image Processing","","2019","PP","99","1","1","We present an automatic moment capture system that runs in real-time on mobile cameras. The system is designed to run in the viewfinder mode and capture a burst sequence of frames before and after the shutter is pressed. For each frame, the system predicts in real-time a goodness score, based on which the best moment in the burst can be selected immediately after the shutter is released. We develop a highly efficient deep neural network ranking model, which implicitly learns a latent relative attribute space to capture subtle visual differences within a sequence of burst images. The overall goodness is computed as a linear aggregation of the goodnesses of all the latent attributes. To obtain a compact model which can run on mobile devices in real-time, we have explored and evaluated a wide range of network design choices, taking into account the constraints of model size, computational cost, and accuracy. Extensive studies show that the best frame predicted by our model hit users’ top-1 (out of 11 on average) choice for 64.1% cases and top-3 choices for 86.2% cases. Moreover, the model (only 0.47M Bytes) can run in real time on mobile devices, e.g. 13ms on iPhone 7.","","","10.1109/TIP.2019.2955563","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8920214","Computational Photography;Generative Adversarial Network","Real-time systems;Mobile handsets;Head;Computational modeling;Cameras;Generative adversarial networks;Training","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Neural Attentive Network for Cross-Domain Aspect-level Sentiment Classification","M. Yang; W. Yin; Q. Qu; W. Tu; Y. Shen; X. Chen","Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, Guangdong China (e-mail: min.yang1129@gmail.com); Department of Computer and Information Science, University of Pennsylvania, Pennsylvania, Pennsylvania, Pennsylvania United States (e-mail: wenpeng@cis.lmu.de); Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, Guangdong China (e-mail: qiangqu.ai@gmail.com); Department of computer science, Shanghai University of Finance and Economics, Shanghai, Shanghai China (e-mail: tu.wenting@mail.shufe.edu.cn); School of Electronics and Computer Engineering, Peking University Shenzhen Graduate School, 429362 Nanshan, Guangdong China 518055 (e-mail: shenying@pkusz.edu.cn); College of Computer Science and Software, Shenzhen University, 47890 Shenzhen, Guangdong China 518060 (e-mail: xjchen@szu.edu.cn)","IEEE Transactions on Affective Computing","","2019","PP","99","1","1","This work takes the lead to study the aspect-level sentiment classification in the domain adaptation scenario. Given a document of any domains, the model needs to figure out the sentiments with respect to fine-grained aspects in the documents. Two main challenges exist in this problem. One is to build a robust document modeling across domains; the other is to mine the domain-specific aspects and make use of the sentiment lexicon. In this paper, we propose a novel approach NAACL (Neural Attentive model for cross-domain Aspect-level sentiment CLassification), which leverages the benefits of the supervised deep neural network as well as the unsupervised probabilistic generative model to strengthen the representation learning. NAACL is evaluated on both English and Chinese datasets with the out-of-domain as well as in-domain setups. Quantitatively, the experiments demonstrate that NAACL has robust superiority over the compared methods in terms of classification accuracy and F1 score. The qualitative evaluation also shows that the proposed model is capable of reasonably paying attention to those words that are important to judge the sentiment polarity of the input text given an aspect.","","","10.1109/TAFFC.2019.2897093","Shanghai Sailing Program; National Natural Science Foundation of China; SIAT Innovation Program for Excellent Young Researchers; CAS Pioneer Hundred Talents Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8632754","Aspect-level sentiment classification;Domain adaptation;Topic modeling;Multi-view attention","Adaptation models;Neural networks;Task analysis;Computational modeling;Probabilistic logic;Social networking (online);Semantics","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"Classifier Inconsistency based Domain Adaptation Network for Partial Transfer Intelligent Diagnosis","J. Jiao; M. Zhao; J. Lin; C. Ding","School of Mechanical Engineering, Xi'an Jiaotong University, Xian, Sha'anxi Province China 710049 (e-mail: jjy2015@stu.xjtu.edu.cn); Xian Jiaotong University, Xian China 710054 (e-mail: zhaomingxjtu@xjtu.edu.cn); Beihang University, 12633 Beijing China 100191 (e-mail: jinglin@mail.xjtu.edu.cn); School of Mechanical Engineering, Xian Jiaotong University, Xian, Sha'anxi Province China 710049 (e-mail: dingchuancang@stu.xjtu.edu.cn)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","Deep networks based mechanical intelligent diagnosis has been recently attracting considerable attentions with the development of Industry 4.0. Unfortunately, a more practical diagnostic scenario, i.e. unsupervised partial transfer diagnosis (UPTD), has not yet been well addressed. In view of this, a novel unsupervised intelligent diagnosis framework named Classifier Inconsistency based Domain Adaptation network (CIDA) is proposed in this work. In this approach, two discriminative one-dimensional convolutional networks are designed as the basic architecture. The source samples of the same categories as the target domain are then identified and emphasized to boost positive network training. Meanwhile, the classifier inconsistency is introduced to guide the model to learn discriminative and domain-invariant representations for the correct classification of unlabeled target data. Extensive experiments on two datasets are conducted to evaluate the proposed method. Additionally, five popular methods are selected for comparison. The comprehensive results validate the effectiveness and superiority of the proposed approach.","","","10.1109/TII.2019.2956294","National Natural Science Foundation of China; Defense Industrial Technology Development Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8917808","Unsupervised domain adaptation;partial transfer;convolutional neural network;intelligent fault diagnosis","Fault diagnosis;Training;Adaptation models;Kernel;Convolutional neural networks;Informatics;Industries","","","","","","","","","","IEEE","IEEE Early Access Articles"
"mVideo: Edge Computing Enabled Mobile Video Processing Systems","H. Sun; Y. Yu; K. Sha; B. Lou","School of Computer and Science, Anhui University, Hefei, China.; School of Computer and Science, Anhui University, Hefei, China.; Department of Computer Science, University of Houston-Clear Lake, Houston, USA.; School of Computer and Science, Anhui University, Hefei, China.","IEEE Access","","2019","PP","99","1","1","Computer vision (e.g., face recognition) is widely used in video processing systems to detect anomalies for public safety. Applying deep neural networks (DNNs) in computer vision can achieve high accuracy but it requires a huge amount of computing and storage resources. Thus, DNNs-based video analytics approaches are mostly deployed in the cloud. Meanwhile, existing video processing systems largely depend on video streams from stationary cameras. In this case, there are three issues: (1) In the cloud, DNNs models require amount of video data from cameras, which leads to high bandwidth consumption, latency, and privacy concerns. (2) Accurate DNNs cannot be deployed in the resource-limited edge devices where machine learning algorithms present low accuracy. (3) The stationary cameras collect a limited amount of video data; thus it hardly satisfies the needs of the real-time analytics in applications like public safety. We proposed a mobile edge computing-enabled video stream processing platform (i.e., mVideo) to analyze video with the collaboration of edge-cloud nodes. mVideo that is composed of a mobile edge computing unit with cameras and the cloud node makes full use of the computing resources on the collaborative edge-cloud nodes has two benefits: (1) Mobile Edge computing-enabled framework pre-processes video stream at the edge node using the lightweight Neural Network. The pre-processed result is uploaded to the upper-level node for further processing. Thus, mVideo reduces the latency of the video data transmission and relieves the network overhead. (2) mVideo with the edge-cloud collaborative nodes are designed to handle partitioned computation tasks according to its resources for video analytics. The flexibility of the system is enhanced in the new mobile video processing owing to the mobility. In experiment, an exemplified face recognition application is deployed on the mVideo platform to validate its performance in terms of transmission data volume, execution time, and power consumption.","","","10.1109/ACCESS.2019.2963159","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8945324","Mobile Video Analytics;Edge Computing;Mobile Cameras;Public Safety","","","","","","","CCBY","","","","IEEE","IEEE Early Access Articles"
"The Security of Autonomous Driving: Threats, Defenses, and Future Directions","K. Ren; Q. Wang; C. Wang; Z. Qin; X. Lin","Institute of Cyberspace Research, Zhejiang University, Hangzhou 310027, China, with the College of Computer Science and Technology, Zhejiang University, Hangzhou 310027, China, and also with the Alibaba-Zhejiang University Joint Institute of Frontier Technologies, Zhejiang University, Hangzhou 310027, China (e-mail: kuiren@zju.edu.cn).; School of Cyber Science and Engineering, Wuhan University, Wuhan 430072, China.; Department of Computer Science, City University of Hong Kong, Hong Kong.; Institute of Cyberspace Research, Zhejiang University, Hangzhou 310027, China, with the College of Computer Science and Technology, Zhejiang University, Hangzhou 310027, China, and also with the Alibaba-Zhejiang University Joint Institute of Frontier Technologies, Zhejiang University, Hangzhou 310027, China.; School of Computer Science, University of Guelph, Guelph, ON N1G 2W1, Canada.","Proceedings of the IEEE","","2019","PP","99","1","16","Autonomous vehicles (AVs) have promised to drastically improve the convenience of driving by releasing the burden of drivers and reducing traffic accidents with more precise control. With the fast development of artificial intelligence and significant advancements of the Internet of Things technologies, we have witnessed the steady progress of autonomous driving over the recent years. As promising as it is, the march of autonomous driving technologies also faces new challenges, among which security is the top concern. In this article, we give a systematic study on the security threats surrounding autonomous driving, from the angles of perception, navigation, and control. In addition to the in-depth overview of these threats, we also summarize the corresponding defense strategies. Furthermore, we discuss future research directions about the new security threats, especially those related to deep-learning-based self-driving vehicles. By providing the security guidelines at this early stage, we aim to promote new techniques and designs related to AVs from both academia and industry and boost the development of secure autonomous driving.","","","10.1109/JPROC.2019.2948775","NSFC; Zhejiang Key R and D Plan; NSFC; Equipment Pre Research Joint Fund of Ministry of Education of China Youth Talent; Outstanding Youth Foundation of Hubei Province; Fundamental Research Funds for the Central Universities; Research Grants Council of Hong Kong; NSFC; Major Scientific Research Project of Zhejiang Lab; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8890622","Autonomous vehicles (AVs);in-vehicle protocol;in-vehicle systems;security;sensors.","Laser radar;Sensors;Security;Global Positioning System;Autonomous vehicles;Jamming","","","","","","","","","","IEEE","IEEE Early Access Articles"
"A Convolutional Neural Network With Mapping Layers for Hyperspectral Image Classification","R. Li; Z. Pan; Y. Wang; P. Wang","School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an 710049, China.; School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an 710049, China, and also with the Research Institute, Xi'an Jiaotong University, Hangzhou 311215, China (e-mail: zbpan@mail.xjtu.edu.cn).; School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an 710049, China. He is now with the Department of Information Science, Xi'an University of Technology, Xi'an 710048, China.; School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an 710049, China, and also with the Research Institute, Xi'an Jiaotong University, Hangzhou 311215, China.","IEEE Transactions on Geoscience and Remote Sensing","","2019","PP","99","1","12","In this article, we propose a convolutional neural network with mapping layers (MCNN) for hyperspectral image (HSI) classification. The proposed mapping layers map the input patch into a low-dimensional subspace by multilinear algebra. We use our mapping layers to reduce the spectral and spatial redundancies and maintain most energy of the input. The feature extracted by our mapping layers can also reduce the number of following convolutional layers for feature extraction. Our MCNN architecture avoids the declining accuracy with increasing layers phenomenon of deep learning models for HSI classification and also saves the training time for its effective mapping layers. Furthermore, we impose the 3-D convolutional kernel on the convolutional layer to extract the spectral-spatial features for HSI. We tested our MCNN on three data sets of Indian Pines, University of Pavia, and Salinas, and we achieved the classification accuracy of 98.3%, 99.5%, and 99.3%, respectively. Experimental results demonstrate that the proposed MCNN can significantly improve classification accuracy and save much time consumption.","","","10.1109/TGRS.2019.2948865","National Key Research and Development Program of China; Zhejiang Provincial Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8896947","Convolutional neural network (CNN);dimension reduction;feature extraction;hyperspectral image (HSI) classification;mapping layers.","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Interactive Question-Posing System for Robot-Assisted Reminiscence from Personal Photos","Y. Wu; E. Gamborino; L. Fu","Department of Computer Science and Information Engineering, National Taiwan University, Taipei, Taiwan.; Center for Artificial Intelligence and Advanced Robotics, National Taiwan University, Taipei, Taiwan.; Department of Electrical Engineering, Department of Computer Science and Information Engineering and Center for Artificial Intelligence & Advanced Robotics, National Taiwan University, Taipei, Taiwan.","IEEE Transactions on Cognitive and Developmental Systems","","2019","PP","99","1","1","Reminiscence is a lifelong activity that happens throughout our lifespan. While memories can serve as topics in people’s every-day conversations, recalling the past can also help us build self-esteem and increase our level of happiness. In this paper, we aim to develop a robot companion that helps people to recollect their memories from personal photos. We focus on how a robot can associate concepts relevant to the content in the photos and evoke people’s memories by asking questions that are both relatable and engaging. To understand the content of a picture, we applied deep learning techniques in order to recognize events, objects, and scenes in it. Then, these observations and any user utterances are considered in a Markov Random Field-based algorithm that contains common sense knowledge of a number of events, with Loopy Belief Propagation being used to infer possible associated concepts and topics. Afterwards, the robot poses appropriate questions about the selected topics, guiding the user to reminisce through conversation. Our results show that the proposed system can pose related and appropriate questions to interact with the user, and has the potential guide the user to recall the past in an organized way.","","","10.1109/TCDS.2019.2917030","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8716707","Interactive Question-Posing;Knowledge Graph;Markov Random Fields;Reminiscence;Social Companion Robot.","Task analysis;Visualization;Robot sensing systems;Knowledge based systems;Data models","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Making Sense of Spatio-Temporal Preserving Representations for EEG-Based Human Intention Recognition","D. Zhang; L. Yao; K. Chen; S. Wang; X. Chang; Y. Liu","School of Computer Science and Engineering, University of New South Wales, Sydney, NSW 2052, Australia (e-mail: dalin.zhang@unsw.edu.au).; School of Computer Science and Engineering, University of New South Wales, Sydney, NSW 2052, Australia.; School of Computer Science and Engineering, University of New South Wales, Sydney, NSW 2052, Australia.; School of Information Technology and Electrical Engineering, University of Queensland, Brisbane, QLD 4072, Australia.; Faculty of Information Technology, Monash University, Clayton, VIC 3800, Australia.; School of Computer Science and Engineering, Michigan State University, East Lansing, MI 48823 USA","IEEE Transactions on Cybernetics","","2019","PP","99","1","12","Brain-computer interface (BCI) is a system empowering humans to communicate with or control the outside world with exclusively brain intentions. Electroencephalography (EEG)-based BCI is one of the promising solutions due to its convenient and portable instruments. Despite the extensive research of EEG in recent years, it is still challenging to interpret EEG signals effectively due to its nature of noise and difficulties in capturing the inconspicuous relations between EEG signals and specific brain activities. Most existing works either only consider EEG as chain-like sequences while neglecting complex dependencies between adjacent signals or requiring complex preprocessing. In this paper, we introduce two deep learning-based frameworks with novel spatio-temporal preserving representations of raw EEG streams to precisely identify human intentions. The two frameworks consist of both convolutional and recurrent neural networks effectively exploring the preserved spatial and temporal information in either a cascade or a parallel manner. Extensive experiments on a large scale movement intention EEG dataset (108 subjects, 3,145,160 EEG records) have demonstrated that the proposed frameworks achieve high accuracy of 98.3% and outperform a set of state-of-the-art and baseline models. The developed models are further evaluated with a real-world brain typing BCI and achieve a recognition accuracy of 93% over five instruction intentions suggesting good generalization over different kinds of intentions and BCI systems.","","","10.1109/TCYB.2019.2905157","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8698218","Brain-computer interface (BCI);electroencephalography (EEG);intention recognition;spatial information;temporal information","Electroencephalography;Electrodes;Brain modeling;Feature extraction;Biological neural networks;Recurrent neural networks","","","","1","","","","","","IEEE","IEEE Early Access Articles"
"GUI-Squatting Attack: Automated Generation of Android Phishing Apps","S. Chen; L. Fan; C. Chen; M. Xue; Y. Liu; L. Xu","School of Computer Science and Engineering, Nanyang Technological University, 54761 Singapore, Singapore Singapore (e-mail: ecnuchensen@gmail.com); School of Computer Science and Engineering, Nanyang Technological University, 54761 Singapore, Singapore Singapore (e-mail: ecnujanefan@gmail.com); Information Technology, Monash University, 2541 Melbourne, Victoria Australia (e-mail: chunyang.chen@monash.edu); School of Computer Science, The University of Adelaide, 1066 Adelaide, South Australia Australia (e-mail: minhuixue@gmail.com); School of Computer Engineering, Nanyang Technological University, 54761 Singapore, Singapore Singapore (e-mail: yangliu@ntu.edu.sg); Computer Science, New York University Shanghai, 447103 Shanghai, Shanghai China (e-mail: lihua.xu@nyu.edu)","IEEE Transactions on Dependable and Secure Computing","","2019","PP","99","1","1","Mobile phishing attacks, such as mimic mobile browser pages, masquerade as legitimate applications by leveraging repackaging or clone techniques, have caused varied yet significant security concerns. Consequently, detection techniques have been receiving increasing attention. However, many such detection methods are not well tested and may therefore still be vulnerable to new types of phishing attacks. In this paper, we propose a new attacking technique, named GUI-Squatting attack, which can generate phishing apps (phapps) automatically and effectively. Our method adopts image processing and deep learning algorithms, to enable powerful and large-scale attacks. We observe that a successful phishing attack requires two conditions, page confusion and logic deception during attacks synthesis. We directly optimize these two conditions to create a practical attack. Our experimental results reveal that existing phishing defenses are less effective against such emergent attacks and may therefore stimulate more efficient detection techniques. To further demonstrate that our generated phapps can not only bypass existing detection techniques, but also deceive real users, we conduct a human study and successfully steal users' login information. The human study also shows that different response messages after pressing the login button mislead users to regard phapps as functionality problems instead of security threats.","","","10.1109/TDSC.2019.2956035","National Natural Science Foundation of China; National Research Foundation Prime Ministers Office Singapore under its National Cybersecurity RD Program; National Satellite of Excellence in Trustworthy Software System; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8913495","Android phishing apps;Android GUI attacks;Android apps","Phishing;Graphical user interfaces;Cloning;Task analysis;Microsoft Windows;Malware","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Real-time Vision Based System of Fault Detection for Freight Trains","Y. Zhang; M. Liu; Y. Chen; H. Zhang; Y. Guo","National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210023, China.; School of Mechanical Science and Engineering, Huazhong University of Science and Technology, Wuhan 430074, China.; National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210023, China.; National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210023, China.; National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210023, China.","IEEE Transactions on Instrumentation and Measurement","","2019","PP","99","1","1","Real-time vision based system of fault detection (RVBS-FD) for freight trains aims to complete routine maintenance tasks efficiently for ensuring railway transportation security. However, most existing systems are designed to detect only one specific type of faults or even one fault, which fail to deal with multi-fault detection. Recently, the rapid development of deep learning techniques enables systems to provide a robust solution for the RVBS-FD of freight trains. But general convolutional neural networks (CNN) cannot fully meet the actual requirements in terms of the real-time, accuracy, and resource constrains for the RVBS-FD of freight trains. To solve these problems, we propose a CNN-based detector called Light FTI-FDet for the RVBS-FD of freight train. First, we use the multi-region proposal networks which extract a set of prior bounding boxes to achieve initial fault proposal generation. Then, a powerful multi-level region-of-interest pooling is presented for proposal classification and accurate detection. We finally design a reliable model reduction scheme to pursue fast speed with high detection accuracy in a simple manner. The experimental results on five typical fault benchmarks indicate that our Light FTI-FDet achieves higher accuracy and fast speed with about 17% model size of the well-known Faster R-CNN detector, substantially outperforming state-of-the-art methods.","","","10.1109/TIM.2019.2955799","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8911418","Real-time;vision based system;fault detection;freight train;convolutional neural network","Fault detection;Real-time systems;Detectors;Proposals;Cameras;Reduced order systems;Rail transportation","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Model Compression for IoT Applications in Industry 4.0 via Multi-scale Knowledge Transfer","S. Fu; Z. Li; K. Liu; S. Din; M. Imran; X. Yang","Chengdu China 610065 (e-mail: fushipeng97@gmail.com); Chengdu China 610065 (e-mail: zhenli1031@gmail.com); Sichuan Univ, Chengdu, Sichuan China 610065 (e-mail: kailiu@scu.edu.cn); Kyungpook National University, 34986 Daegu, Daegu Korea (the Republic of) 41566 (e-mail: saadia.deen@gmail.com); Riyadh Saudi Arabia 4545 (e-mail: cimran@ksu.edu.sa); Chengdu China 610065 (e-mail: arielyang@scu.edu.cn)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","Industry 4.0 has close relations with the Internet of Things (IoT). Convolutional Neural Networks (CNNs) have shown promising performance in many foundational services of the IoT applications. For the IoT applications with high-speed data streams and the requirement of time-sensitive actions, fast processing is demanded on small-scale platforms or even on IoT devices themselves. Therefore, it is inappropriate to employ cumbersome CNNs in IoT applications. In knowledge transfer, it is common to employ a deep, well-trained network, called teacher, to guide a shallow, untrained network, called student, to have better performance. Previous works have made many attempts to transfer single-scale knowledge from teacher to student. In this work, we introduce multi-scale representations to knowledge transfer. We divide student and teacher into several stages. Student learns from multi-scale knowledge provided by teacher at the end of each stage. Extensive experiments demonstrate the effectiveness of our proposed method on different tasks.","","","10.1109/TII.2019.2953106","National Natural Science Foundation of China; Science Foundation of Sichuan Science and Technology Department; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8907352","Industry 4.0;IoT;knowledge transfer;multiscale representations;single image super-resolution;image classification","","","","","","","","","","","IEEE","IEEE Early Access Articles"
"Guest Editorial: Special Section on ""Smart Process Manufacturing Driven by Artificial Intelligence"" in IEEE Transactions on Industrial Informatics","F. Qian; H. Gao; B. Huang; D. Bogle","Key Laboratory of Advanced Control and Optimization for Chemical Processes, East China University of Science and Technology, Shanghai, Shanghai China 200237 (e-mail: fqian@ecust.edu.cn); Research Institute of Intelligent Control and Systems, Harbin Institute of Technology, Harbin, Heilongjiang China 150080 (e-mail: hjgao@hit.edu.cn); Chemical and Materials Engineering, University of Alberta, Edmonton, Alberta Canada T6G2V4 (e-mail: biao.huang@ualberta.ca); DEPARTMENT OF CHEMICAL ENGINEERING, Imperial College London, 4615 London, London United Kingdom of Great Britain and Northern Ireland SW7 2AZ (e-mail: d.bogle@ucl.ac.uk)","IEEE Transactions on Industrial Informatics","","2019","PP","99","1","1","The papers in this special section examine smart process manufacturing that is driven by artificial intelligence (AI). As a fundamental industry, process industry mainly involves elementary raw material industries, such as petroleum, chemical, steel, nonferrous metal, and building. However, there are a series of problems existing in process industry such as inaccurate perception of industrial data, low production efficiency, high materials consumption and limitations in safety and environment protection. In order to solve these restriction problems, we must pursue the goal of efficient, green, and smart processes in manufacturing and marketing. On the other hand, artificial intelligence (AI) has powerful strengths in perception, knowledge representation, learning, reasoning and planning, so that it has been successfully utilized in diverse areas, such as autonomous vehicles and so on. It is promising to have deep and tight integration between artificial intelligence and process industry, to achieve “smart process industry”.","","","10.1109/TII.2019.2960014","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8933442","","Special issues and sections;Sensors;Artificial intelligence;Predictive control;Manufacturing processes;Process control;Informatics","","","","","","","","","","IEEE","IEEE Early Access Articles"
